
„Psychologia i życie” jest popularnie ujętym wykładem psychologii.  Przeznaczona jest w zasadzie dla osób studiujących tę dziedzinę wiedzy, ale polecamy ją wszystkim, którzy chcieliby wiedzieć, dlaczego w określonych sytuacjach człowiek działa tak, a nie inaczej; jaki wpływ na to mają jego cechy biologiczne, a jaki - szeroko rozumiane otoczenie. Kim jesteśmy - „dziećmi natury” czy „dziećmi środowiska społecznego”? Czym jest choroba psychiczna? Jak można modyfikować zachowanie człowieka? Dlaczego tak łatwo stajemy się marionetkami w cudzych rękach? Jakie prawa rządzą życiem społeczności, a jakie powinny nim rządzić?
Autorzy książki starają się rzetelnie i wyczerpująco odpowiedzieć na te pytania. Informacjom teoretycznym i szczegółowym opisom badań naukowych towarzyszą liczne „przykłady z życia”, anegdoty, cytaty z literatury pięknej oraz wskazówki, jak można wykorzystać wiedzę psychologiczną w różnorodnych dziedzinach i sferach naszej działalności.


Od Wydawcy

„Istnieje oczywiście mnóstwo innych przykładów, które moglibyśmy przytoczyć, a które świadczą o możliwościach wykorzystania psychologii dla dobra ludzi i społeczeństwa (...) Niektórzy psychologowie pracują nad podniesieniem poziomu moralnego strażników więziennych i więźniów, podczas gdy inni badają elementy składające się na te doznania, jakie przede wszystkim należałoby zapewnić dzieciom w tworzonych obecnie ośrodkach opieki nad dzieckiem (najpoważniejszy eksperyment społeczny lat siedemdziesiątych). Niektórzy próbują odkryć sposoby przezwyciężania poczucia nieśmiałości i osamotnienia, podczas gdy ich koledzy starają się ustalić, co jest podstawą trwałego zaangażowania i więzi uczuciowych (...).  Jesteśmy obecnie świadkami ciekawego łączenia się naukowego poszukiwania wiedzy, odkrywania prawidłowości i porządku zjawisk, z humanistycznym dążeniem do zrozumienia i akceptacji innych ludzi oraz osiągnięcia osobistego spełnienia. Nie ma żadnych powodów, aby nowoczesna psychologia nie mogła realizować obu tych celów”.


(z Epilogu)


Wiedzy nabywa się czytając książki, lecz wiedzę najpotrzebniejszą - znajomość świata - zdobywa się czytając w żywych ludziach i studiując wszystkie ich wydania.
Lord Chesterfield „Letters to His Son”, 16 marca 1752 (wyd. pol. „Sztuka szczęśliwego życia w społeczności”)

Z frontu badań:
Elliot Aronson „University of California, Santa Cruz”
Albert Bandura „Stanford University”
John D. |Bonvillian „Vassar College”
Robert Buckhout „Brooklyn College, C.U.N.Y”.
Ruth S. |Day „Hale University”
Jane Elliot „Riceville. Iowa, Public School”
Christiana Maslach „University of California, Berkeley”
Richard E. Nisbett „University of Michigan”
Erik Peper „San Francisco State University”
David L. „Rosenhan Stanford University”
Martin E. P. Seligman „University of Pennsylvania”
Philip Teitelbaum „University of Illinois”

Przedmowa do wydania polskiego

Wizja psychologii, którą znajdujemy w „Psychologii i życiu”, odbiega od klasycznego obrazu tej nauki. Jest to raczej przedstawienie psychologii jako sztuki rozwiązywania ludzkich problemów niż jako nauki, której celem jest skrzętne zbieranie poszczególnych faktów i ostrożne formułowanie uogólnień. Złożoność zagadnień, których rozwiązania oczekuje się od psychologów, sprawia, że niezwykle trudno jest precyzyjnie określić przedmiot psychologii oraz metody jego badania, toteż autorzy „Psychologii i życia” nawet nie próbują tego uczynić. Dzięki temu polski Czytelnik styka się z bogatym, niezwykle różnorodnym materiałem, ale jednocześnie, ze względu na zawarte w nim realia, może odnieść wrażenie, iż omawiane problemy są przede wszystkim problemami społeczeństwa amerykańskiego.
Warto się więc zastanowić, czy sprawy poruszane przez Zimbardo są istotne również dla polskiego społeczeństwa lat osiemdziesiątych oraz czy proponowane sposoby ich rozwiązania nie budzą wątpliwości.
Można się zgodzić, że różne formy dehumanizacji stosunków międzyludzkich, wynikające z frustracji ważnych potrzeb, z życia w zatłoczonych miastach, z narażenia na błędy grupowego myślenia i natrętne oddziaływania propagandy są także naszymi problemami. Według Zimbardo, ważnym sposobem ich rozwiązywania jest humanizacja społeczeństwa osiągana poprzez wnikliwe badania przeżyć i doznań innych ludzi, między innymi podczas różnego rodzaju treningów uwrażliwiających, a także eksperymentów społecznych. W rozdziale 13 jest na przykład szczegółowo opisany eksperyment, przeprowadzony przez |nauczycielkę, którego celem było pokazanie dzieciom, jak łatwo powstają uprzedzenia i jakie są ich konsekwencje. Eksperyment ten był bardzo ryzykowny - dzieci łatwo i szczerze uwierzyły, że ludzie o niebieskich oczach są „gorsi”. Autorce tego badania udało się jednak tak pokierować sytuacją, że dzieci wyniosły z niej wyraźne korzyści społeczne, mimo krótkotrwałego doznawania intensywnych, przykrych przeżyć, wynikających z przeświadczenia o swej „niższości”. Powodzenie tego typu przedsięwzięć wymaga jednak wysokiej kultury psychologicznej i pedagogicznej od osoby, która je podejmuje i systemu społecznego, który jednostkom i grupom uczestniczącym w tego rodzaju eksperymentach zapewnia poczucie dużego bezpieczeństwa osobistego. Nie sądzimy, aby w naszej obecnej rzeczywistości oba te warunki były spełnione.
Autorzy „Psychologii i życia” twierdzą, iż jest to książka w równej mierze o życiu, jak i psychologii. Naszym zdaniem, należałoby jednak uprzedzić Czytelnika, iż jest to książka o życiu człowieka rozpatrywanym przede wszystkim z perspektywy psychologii społecznej. Punktem wyjścia zawartych w niej rozważań są raczej codzienne sprawy niż teoretyczne problemy psychologii, a Autorzy są psychologami społecznymi, nic więc dziwnego, iż w książce uwzględnione są przede wszystkim społeczne aspekty funkcjonowania ludzi. Przejawia się to zarówno w bardziej szczegółowym przedstawieniu zagadnień tradycyjnie zaliczanych do psychologii społecznej, jak i w jednostronnym (z punktu widzenia tylko tej dyscypliny) interpretowaniu niektórych zjawisk. Znalazło to swój wyraz przede wszystkim w podejściu do problemów zdrowia psychicznego i zaburzeń psychicznych.  Autorzy krytykują medyczny model choroby psychicznej zakładając, iż choroba „tkwi” w pacjencie. Sami natomiast przyjmują, iż „szaleństwo” jest wytworem interakcji danej jednostki z jej środowiskiem społecznym, jej konieczności przystosowywania się do konfliktowych wymagań środowiska, nierozsądnych norm i patologicznych stosunków panujących w rodzinie, w szkole czy w pracy. Przedstawiając rozliczne dowody potwierdzające taką interpretację, Autorzy niemal zupełnie pomijają spotykane w literaturze dane świadczące o biologicznym podłożu zaburzeń psychicznych. O dominacji psychospołecznego punktu widzenia na życie człowieka świadczy też pewna powierzchowność prezentacji badań i rozstrzygnięć empirycznych dotyczących fizjologicznych podstaw przeżyć i zachowań jednostki (por. Rozdział 2).
Obok przejawów jednostronnej interpretacji znajdujemy w książce liczne przykłady szerokiego i wszechstronnego wyjaśnienia zachowania człowieka.  Szczególnie wyraźne jest to przy prezentacji różnych teorii osobowości (Rozdział 10). Autorzy poddając jedno i to samo zachowanie interpretacji w różnych systemach kategorii, w bardzo atrakcyjny sposób zwracają uwagę Czytelnika na różnorodność możliwych jego przyczyn.
„Psychologia i życie” jest przykładem dzieła, które ukazuje podstawowe dylematy psychologów uprawiających tę dyscyplinę. Oprócz problemów z selekcją pytań badawczych i doborem trafnych i rzetelnych metod, muszą oni jeszcze brać pod uwagę niebagatelne kwestie natury etycznej.
W wielu opisach badań prezentowanych przez Zimbardo spotykamy się z tym, iż badani byli przez psychologów okłamywani, głodzeni, straszeni i poddawani różnym innym przykrym oddziaływaniom. Na usprawiedliwienie badaczy stosujących tego typu metody można powiedzieć, iż naruszenie norm etycznych jest ceną za spełnienie rygorów metodologicznej ścisłości przy podejmowaniu ważnych społecznie, a skomplikowanych problemów. Ponadto cierpienia są wyrządzane niewielu osobom badanym po to, aby poprawić los dużych grup ludzi. Na przykład, drastyczne badanie Zimbardo nad efektem uwięzienia, które przyniosło przykre doświadczenia ochotniczo biorącym w nim udział studentom, posłużyło jako argument na rzecz poprawy sytuacji dużej zbiorowości więźniów amerykańskich.
Naszym zdaniem bilans strat i zysków, wynikających z prowadzenia wątpliwych etycznie badań, jest bardzo trudny do oszacowania i w każdym przypadku należałoby dążyć do tego, aby koszty psychologiczne ponoszone były przez uczestników tych badań minimalnie. Humanistyczną wydaje się reguła postępowania zaproponowana przez J. M. Carlsmitha, Ph. Ellswortha i E. Aronsona w pracy „Methods of research in socjal psychology” (Massachusetts 1976, Addison-Wesley): pamiętamy o tym, aby ludzie uczestniczący w badaniach psychologicznych nie byli po badaniu w gorszym stanie i nastroju, niż byli przed nim.
Są w „Psychologii i życiu” dane świadczące o tym, iż wiedza psychologiczna może być niebezpiecznym środkiem manipulacji czy wręcz maltretowania ludzi. To prawda. Jest to zresztą niebezpieczeństwo znane nie tylko psychologii. Podobnie jak na przykład w genetyce, w psychologii wyniki poznania naukowego mogą być wykorzystane przeciwko człowiekowi.  Świadomość tego faktu nie może być obca nikomu, kto studiuje i uprawia tę dyscyplinę.
Mamy nadzieję, iż lektura „Psychologii i życia” pozwoli Czytelnikom nie tylko pogłębić wiedzę o sobie i otoczeniu, ale także w sposób bardziej humanistyczny rozwiązywać problemy ludzi w ich środowisku naturalnym i społecznym.


Maria Materska,
Krystyna Skarżyńska
Warszawa, październik 1981




Kiedy piętnaście lat temu oddawałyśmy do druku pierwsze polskie wydanie „Psychologii i życia”, polska codzienność dostarczała ludziom wielu problemów, odmiennych od tych, które opisywali i wyjaśniali Autorzy. Zmiany polityczne, ekonomiczne, społeczne sprawiły, iż to, co kiedyś wydawało się odległe i mało znaczące - stało się również naszym problemem. Żyjemy coraz szybciej, stajemy się bardziej rywalizacyjni, poznajemy na własnej skórze natarczywość reklamy i innych manipulacji naszymi postawami w środkach masowego przekazu. Agresja i przemoc, niechęć do obcych i różnego rodzaju uprzedzenia stały się bardziej wyraziste. Wszystkie te kwestie są w „Psychologii i życiu” dokładnie analizowane. Z tego punktu widzenia - wznawiana teraz książka zyskała na aktualności.
W ostatnich latach znacznie poszerzył się krąg osób zainteresowanych psychologią. Kilkakrotnie wzrosła liczba studentów psychologii i nauk pokrewnych, w których wiedza psychologiczna znajduje szerokie zastosowanie.  Coraz więcej czytelników pragnie zdobyć wiedzę psychologiczną, poszukując klucza do zrozumienia osobistych problemów - swoich i swojego otoczenia.  Dla nich wszystkich wznawiana obecnie „Psychologia i życie” będzie użyteczną i ciekawą lekturą.
Piętnaście lat w historii nauki to dużo. Przez te lata pojawiły się i nowe teorie, i nowe fakty, nie do końca jeszcze wyjaśnione. Na polskim rynku wydawniczym pojawiają się publikacje przedstawiające nowości z tej i innych dziedzin, ale skupiają się one głównie na zagadnieniach szczegółowych i nierzadko dostępne są tylko dla wąskiego grona specjalistów. W tej sytuacji „Psychologia i życie” dobrze pełni funkcję ogólnego i najbardziej dostępnego podręcznika psychologii.


M. M. i K. S.
Warszawa, marzec 1996


Przedmowa

Cieszę się, że dziewiąte wydanie „Psychology and Life” („Psychologii i życia”) okazało się co najmniej równie popularne wśród szerokiego kręgu Czytelników, jak długi szereg poprzednich wydań cieszących się powodzeniem od 1937 roku (których autorem był początkowo tylko Floyd L. Ruch). Poważną rewizję tekstu podręcznika - a stąd nowe wydanie - podejmuje się tradycyjnie co cztery lata. Tym razem postanowiliśmy jednak spróbować innego rozwiązania.
Tekst został zaktualizowany i zmodyfikowany na podstawie nowych informacji, niedostępnych parę lat temu, gdy opracowywano dziewiąte wydanie. Poprawiono go także w wielu miejscach, uwzględniając konstruktywne uwagi przekazane mi przez studentów i wykładowców. Główną jednak innowacją, z jaką tu się zetkniesz, jest zbiór oryginalnych esejów napisanych przez interesujących badaczy, których prace i myśli reprezentują najnowsze osiągnięcia wiedzy psychologicznej. Znajdziesz tu zatem trzynaście esejów napisanych specjalnie dla naszej książki, których nie było w wydaniu z 1975 roku. Ponieważ zmiany te są znacznie większe niż w zwykłym przedruku, lecz nie tak gruntowne, jak te, których dokonam w dziesiątym wydaniu, niniejszy tekst określono jako „wydanie poprawione”.
Parę słów o wspomnianych esejach, zamieszczanych pod wspólnym nagłówkiem „Z frontu badań”. Po streszczeniu każdego z rozdziałów następuje krótki artykuł, o objętości czterech lub sześciu stron, którego tematyka wiąże się z zasadniczą treścią tego rozdziału. Niektóre z tych esejów przedstawiają nowe koncepcje teoretyczne, podczas gdy inne oferują udoskonaloną metodologię oraz systematyczne programy badań zmierzających do wykrywania prawd psychologicznych. Oprócz ścisłych, rygorystycznie zaplanowanych badań, są tu opracowania o charakterze bardziej spekulatywnym, refleksyjnym, analitycznym. Są szczegółowe obserwacje pojedynczego przypadku, jak również eksperymenty z tysiącami osób badanych. Niektóre eseje koncentrują się na badaniach podstawowych, podczas gdy inne na praktycznym zastosowaniu takich badań. Niektórzy z autorów należą do najwybitniejszych uczonych w swych specjalnościach, inni są dobrze zapowiadającymi się młodymi myślicielami, których idee zaczynają wywierać wpływ na reprezentowane przez nich dziedziny psychologii. 
Ludzie ci starali się poinformować cię w bezpośredni sposób o tym, co badają, dlaczego właśnie to zdecydowali się badać oraz co wykrywają.  Niełatwo jest zawrzeć esencję pracy całego życia, czy choćby jednego poważnego przedsięwzięcia badawczego, w krótkim artykule dostępnym dla osób stawiających pierwsze kroki w tak złożonej dziedzinie jak psychologia.  Będziesz więc musiał dać również coś z siebie: eseje te powinieneś czytać uważniej niż przywykłeś. Autorzy starali się przedstawić swoje prace możliwie najjaśniej, lecz bez nadmiernych uproszczeń. Mówią oni do ciebie w sposób osobisty, lecz nigdy nie starają się do ciebie zniżyć. Chciałbym wiedzieć, które eseje uważasz za najbardziej wartościowe, i jakie były twoje pozytywne i negatywne reakcje na pozostałe części tego podręcznika.
W obecnym najnowszym wydaniu „Psychologii i życia” postawiliśmy sobie za cel zachować te zasadnicze cechy, które zawsze odróżniały ten podręcznik od jego „rywali”, jednocześnie wzbogacając go o nowe wymiary, styl i sposób rozłożenia akcentów. Sądzimy, że wydanie to jest lepiej uporządkowane, bardziej ścisłe i ciekawsze niż jakiekolwiek poprzednie. Rozszerzyliśmy podstawę naukową w postaci danych empirycznych, na których oparte są wnioski, poświęcając jednocześnie większą uwagę zagadnieniom natury humanistycznej (dotyczącym człowieka), o których psychologia ma coś ważnego do powiedzenia. Staramy się mówić do naszego Czytelnika-studenta wprost, na poziomie odpowiednim dla każdego inteligentnego, zainteresowanego „nieprofesjonalisty”. Dołożyliśmy wiele starań, aby wykazać znaczenie analizy psychologicznej dla zrozumienia osobistych, społecznych i politycznych problemów interesujących dzisiejszych studentów. Ponadto, przedstawiamy wiele „najgorętszych” dziś tematów, ważnych dla psychologii, jako dyscypliny naukowej, pod względem teoretycznym i empirycznym. W obecnym wydaniu książki kładziemy wyraźny nacisk na poznanie dynamiki ludzkiego zachowania i świadomości. Opisując, w jaki sposób psychologowie zabierają się do tego zadania, staramy się wciągnąć naszego Czytelnika w realizację pasjonującego przedsięwzięcia. Jest to książka w równej mierze o życiu, jak i o psychologii. Mamy nadzieję, że będzie to dla Czytelnika zarówno przyjemne, jak i pożyteczne doświadczenie.


Jak posługiwać się tą książką


„Psychologia i życie” jest obszerną książką, w której niemało powiedzieliśmy. Sądzimy, że uznasz tę lekturę za wartą poświęconego jej czasu. Aby pomóc ci w pełniejszym przyswojeniu i lepszym opanowaniu przygotowanych przez nas materiałów, zastosowaliśmy szereg specjalnych zasobów, na które chcemy zwrócić twoją uwagę. Zalecamy, abyś czytając każdy „zadany” rozdział, zaczął od spisu treści, następnie zajrzał na koniec rozdziału i dokładnie przeczytał jego streszczenie, aby zorientować się, jaką zawiera on treść i jak jest ona uporządkowana, a potem przeczytał swobodnie cały rozdział, aby zaznajomić się z zasadniczym ujęciem tematu, pojęciami i wnioskami.
Następnie wróć na początek i przeczytaj rozdział dokładnie, |aktywnie zapoznając się z każdym spośród jego głównych działów. Aktywne czytanie, w którym stosuje się podkreślenia, robienie uwag na marginesie, a najlepiej sporządzanie notatek z tego, co się przeczyta, pozwala uzyskać w późniejszych sprawdzianach lepsze wyniki niż czytanie bierne. Zajmuje to początkowo więcej czasu, lecz ten zwiększony wysiłek znajdzie później odbicie w twoich stopniach.
Materiał zawarty w każdym z rozdziałów podzielono tak, aby ułatwić jego zrozumienie i studiowanie. Zwróć uwagę na krój i wielkość czcionek stosowanych w tytułach różnego rzędu, ponieważ informują one o strukturze rozdziału i związkach między tematami. Tytuły te organizują treść i pomagają rozplanować lekturę w każdym z okresów studiowania.
Odpowiednio operując czcionkami wyróżniono również ważne terminy i 
pojęcia oraz opisy interesujących lub znaczących badań - aby podkreślić ich
znaczenie. Ważnym elementem naszej książki są „Zbliżenia”, które pozwalają Czytelnikowi bliżej zapoznać się ze szczególnie interesującymi tematami.
W całym podręczniku pojawiają się odniesienia do źródeł naukowych, badawczych oraz informacji ze środków masowego przekazu. Nazwiska autorów i data publikacji będą wymieniane w nawiasach (na przykład: Zimbardo i Ruch, 1975), a kompletne dane bibliograficzne podane są w porządku alfabetycznym na końcu książki. Dane te stanowią podstawę naszych wniosków, a ponadto wskazują ci źródło bardziej wyczerpujących informacji, jeśli jesteś szczególnie zainteresowany jakimś tematem. Powinniśmy również zwrócić uwagę na inne, wartościowe z pedagogicznego punktu widzenia pomoce zamieszczone na końcu książki: „Dodatek” zawierający podstawowe informacje o pomiarze i statystyce oraz pełny „Słownik” terminów i pojęć psychologicznych używanych w „Psychologii i życiu”.
Po przeczytaniu tej książki dojdziesz do wniosku, że jest to nie tylko podstawowy podręcznik wprowadzający cię w dziedzinę psychologii, lecz także wartościowe, podręczne źródło informacji, które będzie przydatne w dalszych studiach z zakresu psychologii lub przy pisaniu prac z innych przedmiotów.  Na przykład, większość studentów specjalizujących się w psychologii przygotowuje się do egzaminu dyplomowego przeglądając wprowadzający podręcznik psychologii. Krótko mówiąc, powinieneś uważać tę książkę za część swej własnej biblioteki materiałów źródłowych.


Specjalne podziękowania


Każda książka o tych wymiarach i złożoności wymaga współpracy wielu ludzi, aby można ją było przedstawić w ostatecznej postaci, jaką tu widzisz. Poprosiliśmy badaczy, wykładowców i studentów, by ocenili mocne i słabe strony poprzedniego wydania naszego podręcznika, aby pomogli nam w początkowym przygotowaniu niektórych nowych materiałów, aby pomogli zestawić bibliografię oraz ocenili dydaktyczną i naukową adekwatność każdej części nowego rękopisu. Jesteśmy bardzo wdzięczni za tę nieocenioną pomoc następującym osobom: Karlowi Minkemu z University of Hawaii, Leonorze Tiefer z Colorado State University, Scottowi Fraserowi z University of Southern California, Richardowi Nisbettowi z University of Michigan oraz Arturowi Hastingsowi z firmy Hastings Associates. Oparliśmy się na ekspertyzach profesorów Jeffa Wine’a, Carla Pribrama, Edwarda Smitha, Barbary Sackitt, Ervina Stauba oraz Lee Rossa ze Stanford University, natomiast spośród studentów i absolwentów tej uczelni znaczną pomoc, o charakterze krytycznym i twórczym, okazali nam Trudy Solomon, Eileen Sobeck, Eugene Eberts, James Newton, Paul Pilkonis, Michael Jenninges, Thomas Devine, Paige Jenson, Gary Marshall oraz Dean Funabiki.
Mieliśmy to szczęście, że „Dodatek” statystyczny przygotował nam William W. Ruch z „Psychological Services Inc.”, a „Słownik” terminów - Eileen Sobeck. Rosanne Saussotte nie tylko przepisała na maszynie cały, często nieczytelny rękopis, lecz ponadto sprawnie organizowała i koordynowała różne części i stadia procesu opracowywania tego podręcznika. Wydawnictwo „Scott, „Foresman and Company” przydzieliło nam uprzejmie redaktorki: 
Louise Howe, Marguerite Clark i Joanne Tinsley, które odznaczały się nie tylko doskonałą znajomością psychologii i były ekspertami w sprawach edytorskich, lecz ponadto dbały przede wszystkim o dobro studenta, przyszłego Czytelnika tego podręcznika. I wreszcie Christina Maslach z pomocą University of California w Berkeley: służyła pomocą, radą i zachętą w każdej fazie przekształcania myśli w drukowane słowo jako doskonale poinformowana, krytyczna koleżanka, jako życzliwa i dodająca otuchy przyjaciółka i jako kochająca żona.


Phil Zimbardo


I. Podstawy

1. Wyjaśnianie tajemnic zachowania ludzi
2. Fizjologiczne podstawy zachowania
3. Zachowanie przystosowawcze: warunkowanie i uczenie się


Rozdział 1.
Wyjaśnianie tajemnic zachowania ludzi

„Wszyscy ludzie są zagadkowi, dopóki w końcu nie znajdziemy w jakimś słowie lub czynie klucza do danego mężczyzny lub kobiety: natychmiast wszystkie ich dotychczasowe słowa i uczynki ukazują nam się w pełnym świetle” (Przekładu większości cytatów z literatury pięknej dokonał Tłumacz tej książki - w pozostałych przypadkach autorzy przekładów podani są w przypisach (przyp. red.).


Ralph Waldo Emerson
„The Journals” 1842
(wyd. pol. „Dzienniki”)

Psychologia to naukowe badanie zachowania organizmów; jest ona nauką, która pozwala ustalić co „porusza” ludźmi i jak funkcjonuje ich psychika.  Psychologia to pewien sposób myślenia o tym, jak żywe stworzenia radzą sobie ze swoim środowiskiem i jak zachowują się względem siebie; jako taka jest dziedziną znajdującą się na przecięciu innych dyscyplin: filozofii, biologii, socjologii, fizjologii i antropologii. Psychologia zajmuje się tym, co odróżnia ludzi od maszyn. I wreszcie, co może najważniejsze, psychologia jest tym rodzajem wiedzy i sposobem ujmowania zjawisk, który można wykorzystać do podniesienia jakości ludzkiego życia.
Jest dziś prawie niemożliwe, aby czytając gazetę czy czasopismo, lub oglądając telewizję, nie zetknąć się z jakąś rzekomą prawdą psychologiczną, którą podaje ci się do wierzenia. W latach siedemdziesiątych nastała era psychologii - czas, gdy każdy jest swego rodzaju psychologiem. Również i ty, dążąc do tego, aby wydobyć z życia jak najwięcej, stałeś się już w pewnym sensie psychologiem. Niewątpliwie zastanawiałeś się nad swym własnym zachowaniem i nad tym, dlaczego inni niekiedy zachowują się zupełnie inaczej, niż ty zachowałbyś się w takich samych okolicznościach. Jeśli jesteś jednostką spostrzegawczą i wrażliwą, to zapewne często starasz się zrozumieć obserwowane formy czy wzorce zachowania i ich związek z cechami osobowości. Najprawdopodobniej doszedłeś do dość dobrych wyników, jeśli chodzi o przewidywanie następstw własnych działań, a także przewidywanie, jak będziesz postępował w różnych warunkach. To jednak nie wystarczy, abyś mógł przewidywać swoje zachowanie. Istnieje prawdopodobnie wiele sytuacji, kiedy chciałbyś lepiej panować nad tym, co sam czynisz i co czynią inne osoby, których działania ciebie dotyczą.
Psychologia zdrowego rozsądku w wielu wypadkach może być wystarczająca, lecz niekiedy może także doprowadzić cię do fałszywych wniosków i nieskutecznych działań. Przyczyną tego mogą być fałszywe założenia co do natury ludzkiej, kulturowe i osobiste uprzedzenia i przesądy, źle kontrolowane obserwacje lub bezkrytyczne przyjęcie informacji dostarczanych przez nasze zmysły, przez tak zwane autorytety lub przez środki masowego przekazu. Aby być dobrym psychologiem musisz nauczyć się, jak sprawdzać swoje przypuszczenia, dokładnie obserwować, obiektywnie oceniać dowody i wyciągać uzasadnione wnioski.
Jesteśmy przekonani, iż uważne przestudiowanie „Psychologii i życia” może przyczynić się do tego, że staniesz się sprawnie działającym psychologiem.  Osiągnięcie tego celu będzie oczywiście wymagać nie tylko dodatkowej lektury i regularnej pracy w toku studiów, lecz także nieustannej otwartości wobec nowych doświadczeń, idei i ludzi, jak również dociekliwości, która doprowadziłaby cię do możliwie najlepszego poznania własnej psychiki. Może to być podniecająca, jedyna w swoim rodzaju przygoda - przygoda, która pozwoli ci zrozumieć lepiej, dlaczego ludzie myślą, czują i działają w taki właśnie sposób, w jaki to czynią.

Zbliżenie

Dziedzina psychologii


„Istnieją dwa pytania dotyczące wiedzy ludzkiej: pierwsze - Co wiemy? i drugie - Skąd to wiemy? Na pierwsze z tych pytań odpowiada nauka, która stara się być tak bezosobowa i zdehumanizowana, jak to jest tylko możliwe.  Jest naturalne, że w wynikającym stąd ogólnym spojrzeniu na wszechświat, pierwsze miejsce zajmują astronomia i fizyka, których przedmiotem jest to, co wielkie i uniwersalne; życie i psychika, które są czymś rzadkim i które pozornie mają mały wpływ na przebieg zdarzeń, muszą zajmować drugorzędną pozycję w tym bezstronnym przeglądzie. Lecz jeśli chodzi o nasze drugie pytanie - mianowicie, jak zdobywamy naszą wiedzę - psychologia jest najważniejszą z nauk. Nie tylko konieczne jest psychologiczne badanie procesów, za których pośrednictwem wyciągamy wnioski, lecz także okazuje się, że wszystkie dane, na których powinniśmy opierać nasze wnioski, są natury psychologicznej - innymi słowy są doświadczeniami pojedynczych osobników. Pozornie publiczny charakter naszego świata po części jest złudzeniem, a po części opiera się na wnioskowaniu; cały surowy materiał naszej wiedzy składa się ze zdarzeń psychicznych zachodzących w życiu odrębnych ludzi. W tym więc obszarze psychologia zajmuje miejsce najwyższe”.


(Sir Bertrand Russell „Human Knowledge”, „Its Scope and Limits” 1948, ss. 
52-53).



Psychologia w akcji:
badania nad dwoma podstawowymi zagadnieniami dotyczącymi psychiki i zachowania


Aby ułatwić ci zawarcie bliższej znajomości z psychologią, postawimy dwa pytania o dużej doniosłości i rozpatrzymy sposoby, które zastosowali psychologowie w celu znalezienia na nie odpowiedzi. W ten sposób przygotowujemy pole do omówienia głównych zagadnień, jakimi zajmuje się psychologia, założeń, na których jest oparta, jej celów, jak również metod, jakimi się posługuje dla osiągnięcia tych celów i rozwiązywania zagadnień.  W następnych rozdziałach przedstawimy szerzej, a także przeanalizujemy dokładniej te zagadnienia, założenia, cele i metody.


Czy brak miłości i uczucia może przeobrazić dziecko w karła?


Czy miłość i uczucie są niezbędnym warunkiem dobrego stanu fizycznego i normalnego rozwoju, czy też wystarczyłoby dobre pożywienie i inne korzystne warunki bytowe? Pytanie to jest ważne nie tylko samo w sobie, lecz również dlatego, że jest częścią znacznie szerszego zagadnienia: Jaki jest związek między procesami psychicznymi i fizycznymi? Czy jeden z tych procesów rządzi drugim? Czy któryś z nich jest bardziej „realny)? niż drugi? Wiele badań psychologicznych wynika z przyjęcia takiego czy innego stanowiska w odniesieniu do tych problemów lub też rzuca na nie pewne światło.
W XIII wieku, na długo przed powstaniem psychologii jako nauki, panował na Sycylii Fryderyk II, który władał biegle wieloma językami. Był on przekonany, że każdy człowiek przychodzi na świat z wrodzoną znajomością jakiegoś starożytnego języka. Według niego, dziecko, osiągnąwszy odpowiedni wiek, zaczęłoby się posługiwać tym „wbudowanym” w nie językiem bez żadnego ćwiczenia czy wprawy. Uczenie się jest więc potrzebne tylko po to, aby doskonalić wrodzony język lub wzbogacić swój repertuar dodatkowymi językami.
W celu sprawdzenie swojej hipotezy Fryderyk przeprowadził eksperyment.  Pewną liczbę noworodków oddano pod opiekę grupie przybranych matek. Miały one opiekować się dziećmi w milczeniu, nigdy nie mówiąc do nich, ani nie pozwalając im usłyszeć ludzkiego głosu. Według Fryderyka, dzieci powinny w końcu przemówić swym naturalnym, wrodzonym językiem, ponieważ niczego nie można by tu przypisać ich wychowaniu.
Kroniki historyczne informują nas o nieoczekiwanych wynikach tego eksperymentu: „Lecz trudził się on na próżno, ponieważ wszystkie dzieci umarły. Nie mogły bowiem żyć bez pieszczot, radosnych twarzy i czułych słów swych przybranych matek”.
Bajka? Legenda? Nie wierzysz, że deprywacja emocjonalna może mieć takie poważne następstwa? W roku 1760 pewien hiszpański duchowny zapisał następujące słowa: „W domu podrzutków dzieci stają się osowiałe i wiele z nich umiera ze smutku”. W 1915 roku pewien lekarz ze szpitala Johna Hopkinsa podał, że mimo właściwej opieki fizycznej 90 procent niemowląt przyjętych do sierocińców w Baltimore umiera w ciągu pierwszego roku. W roku 1942 pewien badacz w New York University zaczął rejestrować, jaki wpływ ma na dzieci zabranie ich z domu do szpitala na długotrwałe leczenie. 
Dzieci stawały się apatyczne i przygnębione, a w krótkim czasie występowały u nich infekcje dróg oddechowych i gorączka niewiadomego pochodzenia; nie przybierały również na wadze w takim tempie, jakiego normalnie się oczekuje. Wszystko to działo się mimo tego, że sposób odżywiania dzieci był regulowany bardzo starannie. Gdy dzieci powracały ze szpitala do domu, objawy te znikały.
W swych trwających przez dziewięć lat (1935-43) badaniach nad hospitalizowanymi niemowlętami Margaret Ribble stwierdziła u nich objawy zaburzeń fizjologicznych (biegunka, zmniejszenie napięcia mięśniowego, brak apetytu), które były dostatecznie alarmujące, by skłonić ją do wysunięcia wniosku, że brak normalnej interakcji matki i dziecka jest „rzeczywistą deprywacją, która może wyrządzić niemowlęciu szkodę, zarówno o charakterze psychologicznym, jak i biologicznym”. W jednym z badań, przeprowadzonych w niemieckich sierocińcach po II wojnie światowej, ustalono związek między zmianami wagi ciała u dzieci a jakością opieki (ryc. 1.1).

* * *

Ryc. 1.1. Eksperyment Naturalny Nad Wpływem Dobroci Ludzkiej.
O doniosłym znaczeniu, jakie ma jakość opieki, świadczy poniższy opis obrazujący przyrost ciężaru ciała u dzieci w dwóch niemieckich sierocińcach po II wojnie światowej.
Przez pierwszych 26 tygodni dwie grupy dzieci otrzymywały takie same podstawowe racje żywności, jednakże u dzieci w sierocińcu A, mających łagodną i czułą przełożoną, przyrost wagi był większy niż w sierocińcu B, gdzie przełożona była szorstka i surowa. Surową przełożoną przeniesiono następnie do sierocińca A, gdzie jednocześnie zaczęto dawać lepsze wyżywienie; mimo że w sierocińcu B wyżywienie pozostało takie samo jak przedtem, to jednak przyrosty wagi zwiększyły się tam wyraźnie.

* * *

Nieco później Rene Spitz i Katherine Wolf (1946) dokładnie przeanalizowali historię 91 niemowląt przebywających w domach dla dzieci porzuconych w Stanach Zjednoczonych i w Kanadzie. Uzyskali oni wiarygodne dane o występowaniu u tych niemowląt niepokoju, przygnębienia, opóźnienia rozwoju fizycznego, bezsenności, „odrętwienia” oraz patologicznej niedowagi. „Pomimo dobrego wyżywienia i troskliwej opieki lekarskiej” 34 niemowlęta spośród 91 zmarły - większość w okresie od 7 do 12 miesiąca życia.
Niedawno Lytt Gardner (1972) z Upstate Medical Center w Syracuse opisał intensywne badania nad sześcioma „cherlawymi karłami” (thin dwarfs) - dziećmi o niskim wzroście, niedowadze i opóźnionym rozwoju kości; ich „wiek kostny” był znacznie niższy od ich wieku życia. Wszystkie te dzieci pochodziły ze środowisk rodzinnych charakteryzujących się zobojętnieniem emocjonalnym, brakiem normalnej więzi uczuciowej między rodzicami i dziećmi. Stan ten nazwano karłowatością deprywacyjną (deprivation dwarfism). Gardner wykazał, że jest ona rzeczywiście fizycznym następstwem deprywacji emocjonalnej. Stwierdził on, że dzieci takie przybierają na wadze i zaczynają rosnąć, gdy się je zabierze z wrogiego otoczenia, i że rozwój ich zostanie ponownie zahamowany, gdy do niego powrócą. Długotrwałe podleganie takiej deprywacji we wczesnym okresie życia pozostawia jednakże trwałe ślady na wzroście dziecka, jego intelekcie i osobowości.
Nie tylko wykazano istnienie związku między deprywacją emocjonalną a nieprawidłowym rozwojem fizycznym, lecz także znaleziono więź fizjologiczną między nimi. Więź tę tworzą dwie struktury znajdujące się w mózgu: w przypadku deprywacji emocjonalnej okolica zwana |podwzgórzem (która odgrywa główną rolę we wzbudzeniu emocjonalnym) nie wywiera swego zwykłego pobudzającego wpływu na |przysadkę mózgową (która wydziela hormony wzrostowe). W wyniku działania takiego mechanizmu brak miłości i ludzkiej troski w krytycznych okresach rozwoju niemowlęcia może oddziaływać na jego organizm powodując karłowatość deprywacyjną u tych niemowląt, którym w ogóle udało się utrzymać przy życiu. Gardner konkluduje: „Karłowatość deprywacyjna stanowi konkretny przykład - „eksperyment natury””, jeśli tak można powiedzieć - który ukazuje subtelność, złożoność i decydujące znaczenie interakcji niemowlę-rodzice” (1972, s. 82).
Nowsze badania prowadzą do wniosku, że zahamowanie wzrostu spowodowane wpływem niesprzyjającego środowiska społecznego jest częstsze niż przypuszczamy. Najlepszym dowodem zależności przyczynowej między działaniem stresu a niskim wzrostem jest fakt, że gdy dzieci te umieści się w rodzinie zastępczej lub w sanatorium rosną one blisko 207cm w ciągu roku, podczas gdy norma wynosi 67cm. Nie znamy jeszcze dokładnie procesu, który prowadzi do karłowatości deprywacyjnej. Wydaje się jednak, że wiąże się ona z wpływem napięcia emocjonalnego na wytwarzanie hormonu wzrostowego i innych hormonów przysadki mózgowej. Hormon wzrostowy jest wydzielany przede wszystkim podczas snu, a dzieci te zapewne nie śpią tyle, ile trzeba, w swych pełnych stresu domach.


Czy poraziłbyś śmiertelnie prądem elektrycznym obcego człowieka, gdyby cię o to poprosił?


Nasze drugie pytanie jest zupełnie inne niż pierwsze, lecz także reprezentuje pewne wciąż powracające w psychologii zagadnienie: w jakim stopniu przyczyną zachowania są cechy danej osoby, a w jakim - warunki środowiskowe?
Co sprawiło, że Eichmann i inni hitlerowcy postępowali wobec Żydów właśnie tak, jak to czynili? Jak mogli oni pozwolić sobie na systematyczne wymordowanie milionów ludzi w komorach gazowych obozaów koncentracyjnych?  Jak ludzie cywilizowani - studenci amerykańskich uczelni w latach siedemdziesiątych - mogą zrozumieć podłoże tych masowych mordów? Czy u Niemców występował jakiś defekt charakteru i dlatego byli oni ślepo posłuszni władzy, wypełniając ochoczo rozkazy Adolfa Hitlera, nawet jeśli rozkazy te gwałciły ich własne wartości i przekonania?
Jak inaczej można by to wyjaśnić? Czy można sobie wyobrazić, że omawiane tu postępki nie były charakterystyczne jedynie dla tych ludzi, którzy dopuszczali się ich w hitlerowskich Niemczech, lecz były raczej wynikiem warunków środowiskowych, w których ci ludzie się znaleźli? Czy ty mógłbyś postępować w ten sam sposób?
Z pewnością nie jest to myśl zbyt przyjemna, lecz wskazuje ona możliwość zupełnie innego podejścia do problemu zapobiegania takim zachowaniom w przyszłości. Jeśli istnieją sytuacje, które zwiększają prawdopodobieństwo, że ty lub ja będziemy postępować w taki sposób, jak Eichmann w Niemczech lub porucznik Calley w My Lai, to trzeba zidentyfikować te warunki, abyśmy mogli unikać ich lub podejmować działania zmierzające do ich zmiany, tak żeby nie oddziaływały one również na innych ludzi. Wynikałoby stąd, że zamiast się zastanawiać, co trzeba zrobić z „anormalnymi ludźmi”, należy się zastanowić, jak powinniśmy zmienić anormalne sytuacje, które u każdego z nas mogą powodować takie psychologiczne i społeczne następstwa.
W jaki sposób można rozdzielić czynniki, wymieniane w obu tych konkurencyjnych, alternatywnych wyjaśnieniach, tak aby udało się zbadać ich wpływ? Często oddziaływania wewnętrzne i zewnętrzne są ze sobą beznadziejnie splątane.
Stanley Milgram (1965, 1974) z City Univeristy of New York, postanowił zbadać to zagadnienie. W tym celu opracował sposób mierzenia uległości wobec autorytetu oraz procedurę, dzięki której mógł zmieniać różne czynniki działające w danej sytuacji i dokonywać pomiaru cech osobowości. Osobami badanymi byli zgłaszający się na ochotnika mężczyźni, którym płacono po 4,5 dolara za wzięcie udziału w eksperymencie. Początkowo byli to studenci z Yale University, ale później Milgram rozszerzył skład grupy badanej tak, aby reprezentowała zróżnicowany przekrój ludności: od 20 do 50 roku życia, od robotników niewykwalifikowanych do pracowników umysłowych i przedstawicieli wolnych zawodów, wreszcie od osób z nieukończoną szkołą podstawową do ludzi mających doktorat.
W badanych wzbudzano przekonanie, że celem eksperymentu jest ustalenie wpływu kar na zapamiętywanie. Każdemu badanemu mówiono, że będzie „nauczycielem” i że jego zadaniem będzie wymierzanie kary (wstrząsu elektrycznego) „uczniowi” za każdym razem, gdy popełni on błąd w tekście uczenia się. Uczeń, „Mr. Wallace”, był sympatycznym mężczyzną o miłym obejściu, w wieku około 50 lat, z zawodu - księgowym. Sytuację aranżowano w taki sposób, aby wydawało się, że o wyznaczeniu osobie badanej roli nauczyciela bądź ucznia decydowało losowanie.
Na wstępie badany „nauczyciel” otrzymywał próbny wstrząs prądem o napięciu 45 woltów i oglądał „ucznia” przywiązanego do „krzesła elektrycznego” w sąsiednim pomieszczeniu, po czym rozpoczynał się właściwy eksperyment. Badanemu pokazano, jak posługiwać się trzydziestoma wyraźnie oznaczonymi przyciskami: od przycisku z napisem „Słaby wstrząs” (15 woltów) do przycisku oznaczonego słowami: „Niebezpieczeństwo: silny wstrząs” (450 woltów); następnie polecono mu zwiększyć napięcie wstrząsu o 15 woltów za każdym razem, gdy uczeń popełni błąd lub nie zareaguje. Ponieważ uczeń popełniał wiele błędów, poziom kar podnosił się szybko.
Protesty ofiary, dobiegające z głośnika systemu łączności wewnętrznej, wzmagały się wraz ze wzrostem napięcia wstrząsów, jakim była ona poddawana.  Przy 75 woltach „uczeń” zaczynał jęczeć; przy 150 woltach domagał się, aby go zwolnić z udziału w eksperymencie; przy 180 woltach krzyczał, że nie może już dłużej wytrzymać bólu. Gdy napięcie osiągnęło 300 woltów, wołał, że nie może dłużej brać udziału w eksperymencie i musi być uwolniony.  Krzyczał, że ma chore serce, wył, a następnie, przez ostatnie serie prób, nie reagował w ogóle.
Jeśli badany wahał się lub protestował, nie chcąc wymierzyć następnego wstrząsu, eksperymentator mówił mu: „Nie masz innego wyboru: musisz działać dalej! Twoje zadanie polega na karaniu ucznia za popełnianie błędów”.  Eksperymentator podkreślał, że brak reakcji również musi być karany, ponieważ przyjęto zasadę, iż należy to uważać za błąd.
Gdy poproszono 40 psychiatrów, aby przewidzieli, jak będą się zachowywać badani w tym eksperymencie, to oszacowali oni, że większość badanych nie przekroczy 150 woltów, że przy 300 woltach mniej niż 4% badanych będzie nadal posłusznych i że tylko około 0,1% dojdzie do 450 woltów - oczywiście tylko te nieliczne jednostki, które są pod jakimś względem anormalne. W jakiej mierze twoje przewidywania są zbliżone do przewidywań psychiatrów?
Jak łatwo możesz sobie wyobrazić, sytuacja ta nie była przyjemna dla badanych. W istocie wielu z nich bardzo cierpiało - wymierzanie niewinnemu, obcemu człowiekowi wstrząsów elektrycznych o tak dużym napięciu było oczywiście aktem skrajnego gwałtu zadawanego innej istocie ludzkiej.

* * *

Ryc. 1.2. Eksperymentator poucza osobę badaną, jak obsługiwać generator służący do wymierzania wstrząsów elektrycznych. „Ofiara” przywiązywana jest do aparatu, przez który będzie otrzymywać wstrząsy. Wyobraź sobie przez chwilę, że jesteś badanym - „nauczycielem”. Jak daleko posunąłbyś się wymierzając wstrząsy? Który z trzydziestu poziomów napięcia byłby tą granicą, której nie zgodziłbyś się przekroczyć? Jak daleko, według ciebie, posunął się w rzeczywistości „przeciętny badany” w eksperymencie Milgrama?  Zaznacz poniżej swoje oceny.
1. Odmówiłbym wymierzania innej osobie wstrząsu o napięciu powyżej (zaznacz jedną z liczb) woltów:
0 - 15 - 30 - 45 - 60 - 75 - 90 - 120 - 135 - 160 - 165 - 180 - 195 - 210 
- 225 - 240 - 255 - 270 - 285 - 300 - 315 - 330 - 345 - 360 - 375 - 390 - 
405 - 420 - 435 - 400
2. „Przeciętna osoba badana” - prawdopodobnie zatrzymała się przy ...  woltach.


* * *

Większość badanych narzekała i protestowała. Gdy uświadamiali sobie, że mogą nawet zabić „ucznia”, jeśli jakiś wstrząs wywoła u niego atak serca, to nalegali, aby zwolnić ich z wypełnienia owego zadania. Poniższy fragment zapisu wypowiedzi jednego z badanych świadczy wyraźnie, że sytuacja eksperymentalna wzbudzała silny konflikt:
Podano 180 woltów: „On nie może tego wytrzymać!. Nie myślę zabić tego człowieka! Czy nie słyszysz, że on krzyczy? On krzyczy. Co będzie, jeśli coś mu się stanie?... Kto weźmie odpowiedzialność, jeśli coś stanie się temu dżentelmenowi?”” (eksperyment bierze na siebie odpowiedzialność). „W porządku””.
Podano 195 woltów: „Przecież on krzyczy. Posłuchaj tego. Ojej, ja nie wiem...”” (eksperymentator mówi: „Eksperyment wymaga, abyś działał dalej””). „Wiem o tym, proszę pana, ale myślę - hmm - że on nie wie, czego od niego chcemy. On doszedł już do 195 woltów...””
Podano 240 woltów: „O, nie. Myślisz, że dojdę do końca tej skali? Nie, proszę pana. Nie zamierzam zabić tego człowieka. Nie myślę podać mu 450 woltów”” (1965, s. 67).
Gdy w pokoju „ucznia” zapadła złowieszcza cisza, trwająca przez kilka prób, wówczas niektórzy badani wołali nawet do niego, aby reagował, domagając się poprawnej reakcji, żeby nie musieli nadal wymierzać mu wstrząsów, przy czym przez cały czas głośno protestowali wobec eksperymentatora.


„W naturze człowieka nie istnieje nic takiego, jak zdecydowanie i swobodne opowiedzenie się czy to za dobrem, czy za złem - z wyjątkiem momentu egzekucji”.

Nathaniel Hawthorne „Twice-Told Tales”, 1837


Większość badanych - studenci zupełnie podobni do ciebie, starsi ludzie zupełnie podobni do nas - sprzeciwiała się, protestowała, |lecz |nie |odmawiała |posłuszeństwa. Prawie dwie trzecie badanych (62%) naciskało po kolei wszystkie przełączniki, aż do ostatniego przycisku, który włączał 450 woltów, największą możliwą karę!
Nawet przy uwzględnieniu mniejszości, która odmówiła podporządkowania się autorytetowi, średni poziom najsilniejszego wymierzanego wstrząsu wynosił blisko 370 woltów. Żaden z badanych, który doszedł do piątego przycisku od końca, nie odmówił dojścia do samego końca. Opór ich był już wówczas złamany; rozwiązywali oni swój własny konflikt.
Później, gdy eksperyment ten powtórzono w sytuacji społecznej, która zwiększała prestiż i autorytet eksperymentatora (uczniów szkoły średniej badano na Uniwersytecie Princeton) do samego końca skali doszła zdumiewająca większość - 85% badanych (Rosenhan, 1969).
We wszystkich tych badaniach „ofiara” była w rzeczywistości pomocnikiem eksperymentatora, a jej protesty były znormalizowanymi, nagranymi na taśmie reakcjami na wstrząsy o różnym napięciu - przy czym żadnego z tych wstrząsów naprawdę nie otrzymała. Badani byli jednak przekonani o realności wstrząsów.
Testy osobowości, jakie wykonywali badani, |nie |ujawniły żadnych cech, którymi osoby posłusznie wypełniające polecenia eksperymentatora różniłyby się od osób odmawiających ich wykonania. Testy te nie wykazały również żadnego zaburzenia psychicznego ani anormalności u posłusznych „wykonawców egzekucji”. 
Na podstawie wyników tych badań oraz wyników różnych wariantów zasadniczego schematu eksperymentalnego, stosowanych przez Milgrama i innych badaczy (co zostanie dokładniej omówione w Rozdziale 14), musimy dojść do wniosku, że czynniki sytuacyjne mogą brać górę nad naszymi podstawami i uznawanymi wartościami oraz skłonić nas do robienia rzeczy, których możliwości popełnienia nie potrafilibyśmy nawet wyobrazić sobie przed znalezieniem się w danej sytuacji.
W powyższych badaniach czynnikami sytuacyjnymi były: obecność „uprawnionego” autorytetu, który przyjmuje odpowiedzialność za następstwa działań danej osoby, fizyczne oddalenie ofiary, przyjęcie roli podwładnego, którego postępowaniem rządzą pewne reguły i wreszcie zgoda na przyjęcie „roli elementu systemu społecznego”, w którym zachowanie powszechnie uznanych zwyczajów i przepisów postępowania jest ważniejsze niż osobiste wartości i prywatne przekonania.
Eksperyment tego rodzaju jest wartościowy nie tylko dlatego, że dostarcza określonych odpowiedzi, lecz również z tego powodu, iż stawia nowe pytania i zmusza nas do przemyślenia od nowa niektórych naszych założeń dotyczących natury ludzkiej. Rozwiewa on mit, że zło jest czymś obcym przeciętnemu człowiekowi i czai się jedynie w jakichś szczególnych ludziach, którzy są inni niż my. Wykazuje przekonująco, że w pewnych, możliwych do określenia warunkach społecznych „zjawisko Eichmanna” mogłoby powtórzyć się w przypadku większości zwykłych obywateli amerykańskich.
Wyniki tego eksperymentu powinny także skłonić cię do zastanowienia się, dlaczego oceniałeś (prawdopodobnie) zbyt nisko procent ludzi, którzy będą ślepo posłuszni. A co z twoim złudzeniem odporności, które karze ci wierzyć, że |ty potrafiłbyś się oprzeć wpływowi czynników społecznych, nawet gdyby nie potrafiła tego większość twoich rówieśników? Jakie doświadczenia w domu i szkole przygotowują nas do tego, abyśmy byli „dobrymi, małymi konformistami”, tak łatwo podporządkowującymi się autorytetom i regułom? W jakich warunkach mogłaby większość badanych odmówić w ogóle wymierzania wstrząsów lub przestać to czynić na długo przed zadaniem ofierze ostatniego ciosu?
Metoda zastosowana w tym badaniu |nie |jest |typowa dla przeciętnego eksperymentu, w którym możesz wziąć udział jako osoba badana. Większość badań psychologicznych nie wymaga wprowadzenia w błąd ani takiego skomplikowanego scenariusza. A jeśli zaniepokoiła cię strona etyczna takiego badania, to zainteresuje cię informacja, że wielu psychologów niepokoi ona także. W American Psychological Association (Amerykańskie Towarzystwo Psychologiczne - naczelna organizacja zawodowa psychologów amerykańskich) specjalna grupa opracowuje obecnie dokładne zalecenia dotyczące tego problemu, a także innych zagadnień związanych ze sposobem traktowania badanych w eksperymentach psychologicznych. Jest to zawiły problem. Badanych trzeba chronić, nie hamując jednak nadmiernie poszukiwania wiedzy. W innych miejscach tej książki, a zwłaszcza w „Epilogu”, powiemy więcej o problemach etycznych i moralnych, jakie powstają w związku z badaniami eksperymentalnymi, terapią oraz innymi formami interweniowania w nasze życie.
Dwa przedstawione tu problemy: Czy brak uczucia może zahamować rozwój fizyczny? Jakie warunki mogą uformować Eichmanna? - ilustrują szeroki zakres zagadnień, jakie badają psychologowie. Czy jest jakiś wspólny mianownik ich poszukiwań?


Założenia i podstawowe problemy


Psychologowie zaczynają od przyjęcia pewnych założeń dotyczących przyrody, ludzi, zachowania, psychiki oraz odpowiednich metod ich badania.  W odniesieniu do niektórych założeń istnieje powszechna zgoda; inne reprezentują ciągle jeszcze nie rozwiązane problemy psychologii.
Założenia dotyczące porządku w przyrodzie, determinizmu i empiryzmu.  Poniższe dwa twierdzenia przedstawiają w przejrzysty sposób punkt wyjścia badań naukowych:


„Szachownica to świat, pionki i figury - to zjawiska zachodzące na tym świecie, reguły gry są tym, co nazywamy prawami Przyrody”.

Thomas H. Huxley „A Liberal Education”, 1868

„Przyroda podąża własną drogą, a wszystko to, co nam wydaje się wyjątkiem, jest w rzeczywistości zgodne z porządkiem rzeczy”.

Johann Wolfgang Goethe (Johann P.Eckermann „Gesprache mit Goethe”), 1824 (wyd. pol. „Dzieła wybrane”; „Rozmowy z Goethem”)


Uczony zakłada istnienie w przyrodzie organizującego porządku, to jest systemu zdarzeń, procesów i zjawisk, które są możliwe do przewidzenia, ponieważ powtarzają się z pewną regularnością. Celem badań jest więc odkrycie tej prawidłowości oraz układów systematycznych zależności, które stanowią podłoże - pozornie niepowtarzalne - nie powiązanych ze sobą zdarzeń. Chodzi o to, aby zajrzeć pod powierzchnię różnic oraz szczegółów i dostrzec podstawę - podobieństwo i zasady ogólne.
Ten sposób podejścia jest zdecydowanie odmienny od stanowiska reprezentowanego przez wielu poetów i artystów, którzy przyjmują założenie, że natura jest w samej swej istocie tajemnicza, nieustannie zmieniająca się, chaotyczna, płynna. Według nich, zadanie sztuki polega na tym, aby tej ulotnej zmienności narzucić sztuczną strukturę i trwałość (ryc. 1.3).

* * *

Ryc. 1.3. Uczony widzi naturę jako uporządkowany system i stara się ustalić jego podstawową strukturę. Artysta widzi naturę jako zmienną i podlegającą zmianom i może starać się narzucić jej nowy porządek, jak na tym obrazie Marca Chagalla zatytułowanym „I and the village” („Ja i wieś”), 1911.


* * 

Z przyjmowanym przez naukowców założeniem, dotyczącym uporządkowania wszechświata, wiążą się dwa następne założenia - o determinizmie i przyczynowości. Zakłada się, że wszystkie zdarzenia mają przyczyny - warunki, które poprzedzają je i determinują to, co się stanie. Zakłada się, że te warunki poprzedzające i ich związki z następującymi po nich zdarzeniami są stałe (invariant), a więc w teorii poznawalne i przewidywalne. Gdybyśmy znali wszystkie istotne warunki, czyli tak zwane |zmienne (variables), to powinno być możliwe determistyczne przewidywanie, kiedy i jak wystąpi dane zdarzenie lub zjawisko. Obecnie nie dysponujemy jednak w dziedzinie psychologii taką absolutną wiedzą i psychologowie muszą się wypowiadać w kategoriach probabilistycznych: „Istnieje prawdopodobieństwo X procent, że przyczyna A spowoduje skutek B w Warunkach Y”.
Czy jest możliwe, żebyśmy kiedykolwiek znali naprawdę wszystkie istotne zmienne, które determinują dane zachowanie? To, co robisz w określonej sytuacji - na przykład gdy ktoś ci zagraża - jest zdeterminowane przez historię twojego gatunku, twoją przynależność do określonej kultury, twoje wyposażenie dziedziczne, twoje cechy fizyczne i psychiczne, twoje wychowanie i inne przeszłe doświadczenia, dostępność lub niedostępność broni, obowiązujące prawa, przewidywane przez ciebie następstwa własnych działań oraz przez tysiąc innych rzeczy. Oddziałuje tyle czynników determinujących, że wydaje się niemożliwe, abyśmy kiedykolwiek znali wszystkie. To jednak |nie oznacza, że nie determinują one w pełni zachowania i że zachowanie jest kwestią „wolnej woli” lub „swobodnego wyboru”.
Filozoficzny spór między „determinizmem” i „wolną wolą” toczy się od stuleci i nie można go rozstrzygnąć za pomocą argumentów logicznych. Trzeba po prostu zdawać sobie sprawę, że psychologowie, podobnie jak inni uczeni, |muszą akceptować założenia determinizmu i przyczynowości, jeśli mają nadal studiować naturę ludzką za pomocą badań eksperymentalnych. Jeśli nie przyjmie się założeń regularności i przewidywalności, to poszukiwanie „praw zachowania” nie ma sensu.
Psychologowie przyjmują ponadto założenie, że w nauce jedynym uznawanym rodzajem wiedzy jest wiedza empiryczna: informacje o otoczeniu, zdarzeniach i działaniach, które uzyskuje się za pośrednictwem doświadczeń zmysłowych - wzrokowych, słuchowych, dotykowych, węchowych i smakowych. Te empiryczne informacje muszą także być tego rodzaju, aby mogły być zweryfikowane przez jednego lub wielu niezależnych obserwatorów czy też wykryte przez odpowiednie przyrządy.
Stwierdzenia lub zagadnienia metafizyczne - które zawierają pojęcia wychodzące poza zakres tego, co daje się zaobserwować i sprawdzić empirycznie - są w nauce nie do przyjęcia. Jeśli jakiegoś zjawiska nie można z przyczyn zasadniczych zmierzyć ani zademonstrować, to zjawisko to dla nauki nie istnieje.
W odniesieniu do „rzeczywistości” teologicznej lub metafizycznej nauka zajmuje stanowisko agnostyczne - po prostu nic nie wie na ten temat. Nie ma nic do powiedzenia, ponieważ danych tych nie można sprawdzić za pomocą zmysłów. Trzeba jednak podkreślić, że prywatnie wielu psychologów wierzy w jakiś Boski Cel czy ponadludzką Siłę Stwórczą - ta religijna wiara koegzystuje z przyjmowanymi przez nich w pracy naukowej założeniami determinizmu, przyczynowości i empiryzmu.
Przeciwstawne założenia dotyczące „natury ludzkiej”. Chociaż psychologowie-badacze (research psychologists) są zgodni, co do podstawowych założeń, którymi muszą się kierować w swych naukowych poszukiwaniach, to jednak różnią się znaczenie swymi poglądami na szereg zagadnień dotyczących „natury ludzkiej”  - jakie ujęcie natury ludzkiej jest najtrafniejsze, w jaki sposób można zmienić nasze zachowanie - jeśli istotnie jest to możliwe (Dokładniejsze omówienie tych problemów można znaleźć w pracy M. Wertheimera (1972) i W. D. Hitta (1969)).

„Psychika a organizm”.
 Wyniki badań nad karłowatością deprywacyjną są sprzeczne z często przyjmowanym przez psychologów założeniem, że zjawiska zachodzące w świadomości są po prostu |epifenomenami, ubocznymi produktami zdarzeń rzeczywistych - procesów neurologicznych - nie odgrywającymi żadnej roli w łańcuchu przyczynowym. Zgodnie z tym założeniem i na skutek nacisku, jaki kładziono na zewnętrzne, dające się zaobserwować zachowanie, terminy |psychika i |procesy |psychiczne zyskały sobie złą opinię, a studentów psychologii uczono, aby nigdy ich nie używali.
Jednakże od pewnego czasu prowadzi się badania w wielu kierunkach, które są niezgodne z tym założeniem. Badania nad wpływem stresów życiowych na zdrowie fizyczne, badania nad rozwojem percepcyjnym, poznawczym i rozwojem języka (dotyczące procesów, a nie jedynie wytworów), badania nad stanami świadomości i oddziaływaniem leków psychotropowych, badania nad wpływem takich czynników, jak poczucie bezradności, oczekiwania i aspiracje - wszystkie te prace wzbudziły od nowa zainteresowanie procesami „psychicznymi” i skłoniły badaczy do przyjęcia poglądu, że adekwatny opis zachowania musi uwzględnić również i te procesy. Chociaż nie można ich obserwować bezpośrednio, to jednak można zobaczyć ich skutki i wnioskować pośrednio o ich działaniu na podstawie wielu obserwowanych procesów.  Jednakże większości psychologów nadal wygodniej jest nazywać je „procesami psychologicznymi” lub „procesami poznawczymi”, niż „procesami psychicznymi”, a wielu psychologów nadal nie widzi potrzeby badania ich w ogóle.
„Natura czy wychowanie”. W jakiej mierze jesteś „wytworem” swego wyposażenia dziedzicznego, w jakiej zaś - swoich doświadczeń życiowych? To podstawowe zagadnienie, dyskutowane od wielu stuleci przez filozofów, nadal jest przedmiotem gorących sporów. John Locke wysunął ideę, że w chwili narodzin jesteśmy jedynie czystą tablicą (tabula rasa), na której zostawiają ślady nasze doświadczenia. Zwolennicy tego stanowiska (określanego jako |enwironmentalizm - ang. environmentalism, od ang.  environment - środowisko), kładą nacisk na wychowanie jako czynnik decydujący o naszej indywidualności. Przeciwne stanowisko zajmują |natywiści, według których, o tym jacy jesteśmy decydują nasze geny, układ nerwowy, budowa ciała, zaś wszystkie te cechy są wrodzone; ich zdaniem, wychowanie jedynie rozwija naturę, z jaką się rodzimy.
Ten podstawowy problem przybiera wiele różnych postaci. Na przykład toczą się spory, co do względnego udziału czynników wrodzonych i związanych z uczeniem się w determinowaniu inteligencji i osobowości, a także spory dotyczące znaczenia, jakie dla rozwoju umiejętności mają procesy dojrzewania w porównaniu z uczeniem się i specyficznym ćwiczeniem.
Zagadnienie to jest ważne, ponieważ zwolennicy skrajnie natywistycznego stanowiska uważają, że możliwość modyfikowania zachowań, osiągnięć i umiejętności przez uczenie się, wiedzę, ćwiczenie i kształcenie jest bardzo ograniczona. Społeczno-polityczne implikacje takiego stanowiska są następujące: jeśli niektórzy ludzie rodzą się „głupi”, to nie ma sensu marnować pieniędzy (podatników) na próby kształcenia ich. Natomiast zwolennicy poglądu przypisującego główną rolę wpływowi środowiska uważają, że natura ludzka jest z gruntu podatna na zmiany, daje się modyfikować i doskonalić. Taki pogląd był podstawą sposobu podejścia przyjętego przez psychologów, którzy centralnym pojęciem amerykańskiej psychologii uczynili uczenie się. Jest to pogląd o charakterze demokratycznym, gdyż przyznaje wszystkim dzieciom te same szanse w chwili urodzenia się - zakładając oczywiście, że będą one miały dostęp do tego samego, bogatego i nagradzającego środowiska. Jeśli ideał ten jest fałszywy, to niebezpieczeństwo polega nie tyle na trwonieniu funduszy, ile na zawiedzeniu oczekiwań milionów dzieci, które wierzą, że mogą zostać tym, czym chcą, ponieważ „ćwiczenie prowadzi do doskonałości” (practice makes perfect).
„Czy z natury jesteśmy źli, czy dobrzy?” Religijne wątki zła i dobra, grzechu i łaski, Boga i szatana znajdują swe odbicie w przeciwstawnych poglądach na temat tego, jacy właściwie jesteśmy i co motywuje nas do postępowania w taki sposób, w jaki postępujemy.
Ci, którzy skłonni są dostrzegać przede wszystkim ciemne strony rzeczywistości, uważają, iż natura ludzka jest z gruntu zła - |hedonistyczna (dążąca do przyjemności), skoncentrowana na sobie, kierująca się irracjonalnymi impulsami, mechanistyczna, materialistyczna, dążąca do władzy, panowania nad innymi, wywyższania się i niszczenia. Zadaniem państwa i instytucji społecznych jest więc okiełznanie naszej zwierzęcej natury, ponieważ w przeciwnym razie rozpętałoby się piekło.


„Jedziemy przez życie na bestii, jaka jest w nas. Możesz bić to zwierzę, lecz nie możesz zmusić go do myślenia”.
Luigi Pirandello „Il piacere dell’ onesta”, 1917


Cóż jednak z niewinnością młodości, poświęceniem męczenników, darem altruistycznego zainteresowania dobrem innych, cóż z rzeszami tych, którzy w życiu swym kierują się zasadami etycznymi? Czy to nie wyczyny nielicznych złoczyńców urobiły tę złą opinię człowiekowi, chociaż życie wielu ludzi, nie rzucających się nikomu w oczy, jest pełne spokoju i dobroci? Wielu psychologów odrzuca pesymistyczny pogląd, że jesteśmy z gruntu źli, że rządzi nami przeznaczenie i irracjonalne impulsy, że działamy tylko po to, aby uniknąć cierpienia i zaspokoić zwierzęce popędy. Według nich, natura ludzka jest |potencjalnie dobra, o ile nie została wypaczona. Pełnia życia polega na stawaniu się, tworzeniu oraz realizowaniu swego potencjału rozwoju, piękna i radości. Zachowanie może być wynikiem racjonalnego wyboru, umysł może przekraczać ograniczenia biologicznej materii, a życie może być procesem odkrywania swobody tam, gdzie społeczeństwo często nakłada przymusowe restrykcje. Zgodnie z ich poglądem, rola instytucji społecznych powinna polegać na stwarzaniu możliwości, a nie ograniczeń.

„Uniwersalne prawa czy wyjątkowość jednostki”.

 Prawa psychologiczne są uogólnieniami dotyczącymi przyczyn i ich następstw. Czy mogą one wyjaśnić, dlaczego, jak i kiedy jednostka czyni to, co czyni? Psychologowie pracujący w poradnictwie i zajmujący się terapią zakładają na ogół, że aby zrozumieć indywidualny przypadek, muszą poznać jedyne w swoim rodzaju minione doświadczenia danej osoby, jej pogląd na świat oraz inne szczególne okoliczności, które sprawiają, że jest ona kimś niepowtarzalnym. Ten sposób podejścia określa się jako podejście |idiograficzne. Oczywiście stwierdza się wiele podobieństw i możliwych do przewidzenia następstw, lecz każdy przypadek jest pod pewnymi względami jedyny w swoim rodzaju.
Inni psychologowie przyjmują podejście |nomotetyczne, starając się ustalić ogólne zależności między zachowaniem a jego uwarunkowaniami, zależności dotyczące nas wszystkich. Testy psychologiczne w większości reprezentują podejście nomotetyczne, gdyż określają szereg cech czy wymiarów, za pomocą których można opisać każdego z nas, przy czym różnilibyśmy się tylko naszą pozycją na każdej ze skal testowych. Przyjmuje się, że profil wyników danej osoby na tych skalach stanowi jej wystarczający opis.
Psychologowie stosujący podejście idiograficzne badają, dlaczego ludzie zachowują się różnie w tej samej sytuacji, podczas gdy psychologowie reprezentujący kierunek nomotetyczny dociekają, co sprawia, że pozornie tak różni ludzie, jak my wszyscy, w wielu sytuacjach zachowują się tak podobnie.
„Przyczyny w danej osobie czy przyczyny w środowisku”?
 Gdzie będziemy szukać sprężyn ludzkiego działania? Czy determinanty zachowania można znaleźć w danej osobie, w jej charakterze, cechach osobowości i dyspozycjach do działania? Czy też są one „na zewnątrz”, w sytuacji? Czy przyczyną naszego zachowania jesteśmy my sami, czy nasze otoczenie?  Psychologowie posługują się terminami |atrybucja |dyspozycyjna i |atrybucja |sytuacyjna dla wskazania, że przyczyny zachowania przypisuje się czynnikom tkwiącym w danej osobie lub też w sytuacji zewnętrznej.
Wielu psychologów, którzy starają się określać i diagnozować „typy” ludzkie bądź przeprowadzają terapię zaburzeń osobowości i zachowania niedostosowanego społecznie, przyjmuje, że przyczyny mają charakter dyspozycyjny, czyli tkwią w danej osobie. Takie stanowisko w psychologii przyniosło w rezultacie ustawodawstwo polityczne i instytucje społeczne mające za zadanie zidentyfikowanie „trudnych ludzi”, których wolność jest zagrożeniem dla większości lub których uważa się za potrzebujących jakiegoś rodzaju leczenia. Skoro raz stwierdzi się, że dany problem (przemoc, zbrodnie, zboczenia czy jakiekolwiek antyspołeczne zachowania) wiąże się nierozłącznie z pewnym typem ludzi i ogranicza się do nich, to proponowane rozwiązania wynikają w sposób całkowicie naturalny; reedukować, poprawiać, rehabilitować, leczyć, hospitalizować, izolować, więzić, karać czy wreszcie tracić.
Jednakże wyniki większości współczesnych badań przemawiają za sytuacyjną atrybucją przyczyn i wskazują, że cechy osobowości są złymi predyktorami zachowania (Mischel, 1968). Co więcej, wielu psychologów wykazuje w swych badaniach, że określone zmienne środowiskowe mogą wywoływać pewne czynności, podtrzymywać je i zmieniać bez względu na to jakie dyspozycje tkwią osobie działającej. Za przykład mogą posłużyć badania Milgrama nad posłuszeństwem. Spór ten ma ważne implikacje dla programów kształcenia, terapii oraz reform społecznych, jak również dla dokładnego zrozumienia przyczyn zachowania człowieka.

„Czy pojedyncza osoba, czy grupa ma być jednostką w badaniach”?

 Biorąc pod uwagę obowiązującą w Stanach Zjednoczonych ekonomiczną doktrynę indywidualnej przedsiębiorczości i kapitalizmu oraz historię amerykańskiego społeczeństwa i powszechną w nim tradycję zatwardziałego indywidualizmu, nie należy się dziwić, że psychologia w Ameryce jest psychologią jednostki, psychologią ego. Badania nad specyfiką każdej jednostki, reakcjami indywidualnymi i osobowością stanowią jeden z dominujących wątków w psychologii, od jej początków. Co więcej, sama popularność psychologii jako dziedziny badań w Stanach Zjednoczonych wynika po części z jej znaczenia dla zrozumienia „problemów osobistych”. W społeczeństwie, w którym uważa się, „że ja muszę być sobą”, jest naturalne, iż ludzie chcą psychologii dociekającej, jak się „jest sobą”.
Aczkolwiek psychologia społeczna stanowi częściową korektę tego nadmiernego zainteresowania jednostką, ponieważ bada zachowanie jednostek pod kątem wpływu na nie innych ludzi, to jednak i w tej gałęzi psychologii występowała tendencja do ignorowania ważnych zmiennych działających na poziomie wyższym niż poziom pojedynczego organizmu. Do niedawna nie dostrzegano zmiennych ekologicznych (przestrzeń, czas i miejsce), ani zmiennych systemowych (władza, autorytet, reguły instytucjonalne itd.), ponieważ główny nacisk kładziono na poszczególne osoby, nie na ludzi.
Tam, gdzie podstawową jednostką badań nie jest pojedynczy osobnik, lecz grupa, społeczeństwo, rodzina czy kultura, rozwija się psychologia bardzo odmienna od amerykańskiej. Na przykład w Japonii grupowe działanie uważa się za lepsze od inicjatywy indywidualnej, ponieważ minimalizuje ono jednostkową odpowiedzialność za porażkę, zwiększając jednocześnie szanse na wspólny sukces. W kraju tym mniej uwagi poświęca się badaniom nad poczuciem winy (zjawisko indywidualne) niż nad wstydem (zjawisko o bardziej społecznym charakterze). Podobnie psychologia afrykańska w centrum swych zainteresowań stawia raczej przetrwanie plemienia niż sukcesy jednostki.


Zbliżenie

Plemię Nijakjusa interweniuje tam, gdzie obawiają się wkroczyć  psychiatrzy


„W naszym społeczeństwie osobę przeżywającą trudności emocjonalne rodzina i przyjaciele często dopingują słowami: „Weź się w garść!” Jeśli, jak to się często zdarza, osoba ta nie jest w stanie tego uczynić, nieraz zostaje odrzucona przez bliskich przy pierwszych oznakach „dziwnego” zachowania.  Jak podano, tak właśnie było w przypadku L. H. Oswalda (późniejszego zabójcy prezydenta Kennedy’ego), któremu przyjaciele niechcący pomogli przeistoczyć się w wyalienowanego samotnika, unikając go, gdy zaczął zachowywać się w niezwykły sposób. Cierpiąca osoba przeżywa zatem nie tylko stres, który powoduje problemy emocjonalne lub zaburzenia zachowania, lecz ponadto musi czuć się „anormalna”, odrzucona i winna, że ma w ogóle jakieś problemy.
Często skłania ją to do prób ukrycia tych problemów przed innymi, zamiast do szukania porady. Społeczeństwo i psychiatra wkraczają |dopiero |wtedy, gdy problem stał się już poważny.
Zupełnie inaczej postępuje afrykańskie plemię Njakjusa, społeczność licząca blisko ćwierć miliona ludzi. W tej rolno-hodowlanej kulturze występuje stała troska o |zapobieganie chorobom psychicznym, ze względu na ich szkodliwe skutki dla całego społeczeństwa. Gdy tylko powstaje sytuacja, która mogłaby spowodować u kogoś poważny kryzys, członkowie tej społeczności interweniują natychmiast, przeprowadzając ustalone obrzędy.  Obrzędy te nie tylko wpływają terapeutycznie, lecz ponadto obciążają odpowiedzialnością za powstały problem siły spoza danej jednostki.
Monika Wilson (1970), która jako antropolog badała dokładnie te obrzędy przez wiele lat, podaje, iż zdają się one spełniać swoją rolę tak dobrze, że w zasadzie nie występują tam zachowania, które można by scharakteryzować jako „szaleńcze”, „obłąkańcze” lub „psychotyczne”. Należałoby się zastanowić, czy wzrost liczby zachorowań na choroby psychiczne w Stanach Zjednoczonych nie wynika po części z naszego poczucia osobistej odpowiedzialności za nasze niepowodzenia, kłopoty, frustracje i strapienia, w połączeniu z „aspołeczną” reakcją naszych przyjaciół i bliskich, z jaką spotykamy się właśnie wtedy, gdy potrzebujemy ich najbardziej.
Co i jak badać? Od sposobu stawiania pytań zależy to, jakiego rodzaju odpowiedzi będzie można otrzymać. Różne pytania prowadzą do rozpatrywania bardzo różnych zjawisk, co oznacza opracowywanie różnych narzędzi i strategii badawczych, zbieranie różnych danych i w końcu dochodzenie do radykalnie odmiennych poglądów na temat losu człowieka. Na przykład sposób postawienia pytania badawczego decyduje o tym, czy badacz:
a) studiuje tylko |zachowanie |zewnętrzne, widoczne dla wszystkich, czy |procesy |psychiczne, takie, jak myśli i uczucia;
b) uznaje tylko |obiektywne, behawioralne dane, czy uwzględnia także dokonywaną przez badanych |subiektywną analizę ich własnych doznań;
c) bada wszelkie żywe, „zachowujące się” |organizmy, czy tylko ludzi;
d) kładzie nacisk na |precyzję i |prostotę, czy też na |złożoność i |bogactwo opisu i wyjaśniania;
e) rozkłada zachowanie na najmniejsze funkcjonalne |części, czy też rozpatruje |całościowe, zintegrowane systemy zachowania;
f) koncentruje się na |przeszłości danej jednostki, czy na warunkach |obecnych;
g) zbiera |dane bez teoretycznego ukierunkowania, czy przyjmuje za punkt wyjścia jakąś |teorię, którą kieruje się przy zbieraniu danych służących do zweryfikowania lub rozwinięcia tej teorii;
h) prowadzi badania ze względu na ich własną intelektualną, |naukową |wartość, czy też ze względu na możliwość |zastosowania ich do rozwiązania problemów praktycznych;
i) bada |przebieg zjawisk psychicznych (rozumowanie, rozwiązywanie problemów), czy ich |wynik (sukces, niepowodzenie).
Nierzadko spotyka się psychologów, których pracę określa się jako naukowe badanie zachowania organizmów i którzy zbierają dane w postaci obiektywnych, zewnętrznych, specyficznych, zlokalizowanych reakcji na specyficzne bodźce, przy czym te reakcje i bodźce są precyzyjnie mierzone, a zależności między nimi są na ogół proste. Psychologów takich nazywamy |behawiorystami. Są oni przekonani, że podstawę rzeczywistości stanowi obiektywny, materialny świat fizycznych działań. Szukają przewidywalnych zależności między specyficznymi reakcjami a warunkami w otoczeniu i nie widzą potrzeby poszukiwania przyczyn w danej osobie.
Ponieważ jednostką stosowaną w badaniach jest związek między bodźcem (stimulus) a reakcją (response), behawioryzm znany jest także jako |psychologia |S-|R. Behawioryści skłaniają się ku „ściśle naukowemu” podejściu do psychologii: wolą „mocne” liczbowe dane od danych „słabych”, jakościowych i na ogół zbierają je w kontrolowanych eksperymentach laboratoryjnych z wielką liczbą badanych, posługując się aparaturą elektroniczną i komputerami do podawania bodźców i rejestrowania reakcji.  Przywiązują oni dużą wagę do ścisłych definicji, specjalnego słownictwa i rygorystycznych reguł zbierania materiału dowodowego: często przeprowadzają swe badania na zwierzętach, ponieważ kontrola może być wówczas pełniejsza niż w przypadku ludzi, a ponadto badane procesy występują w prostrzej postaci.
Wcześni behawioryści, tak jak Clark Hull, Kenneth Spence i Edward Guthrie, opracowali skomplikowane teorie, które dały początek wielu „czystym” badaniom przeprowadzanym głównie na niższych organizmach (takich jak biały szczur) w sztucznie tworzonych, uproszczonych środowiskach.  Później, ze względu na nieprzydatność tych teorii do wyjaśniania złożonego zachowania ludzi w warunkach naturalnych, behawioryści zrezygnowali z wielkich modeli tego rozwoju na rzecz „mini-teorii”. Teorie takie służą do wyjaśnienia organicznego zbioru zależności, przy czym kładzie się nacisk na zastosowanie wykrywanych zasad uczenia się do zmiany określonych zachowań ludzi w różnych „zinstytucjonalizowanych” środowiskach - szkołach, szpitalach psychiatrycznych, więzieniach czy w wojsku. Znany współczesny behawiorysta B. F. Skinner z Harvard University nie widzi w ogóle potrzeby jakiejkolwiek teorii, niemniej jednak opiera swe badania na założeniach, zgodnie z którymi przyczyn zachowania należy szukać w środowisku.  Przeciwieństwem behawiorystów są pod wieloma względami |fenomenolodzy, według których podstawą rzeczywistości jest subiektywny świat doznań indywidualnych. Największą wagę przywiązują oni do zrozumienia świadomości, a nie do kontroli zachowania. Domeną ich są procesty psychiczne i introspekcyjne opisy nieobserwowalnych, jedynych w swym rodzaju doświadczeń. Bogactwo natury ludzkiej badają nie przez analizowanie jej elementów, lecz traktując ją jako całościowy, powiązany wzajemnymi zależnościami system - dynamiczny system potencjalnych możliwości.
Angielski eseista William Hazlitt uchwycił podstawową zasadę tego sposobu uprawiania psychologii, gdy pisał:
„Nie poznajemy natury oczyma, lecz rozumem i sercem”.
William Hazlitt „On Taste”, 1839


Zbliżenie

Rewolucja humanistyczna


Psychologia humanistyczna ma wiele wspólnego z fenomenologią, lecz w mniejszym stopniu jest empirycznym sposobem podejścia do uprawiania psychologii, a w większym - programem ideałów wskazujących, na czym powinno polegać uprawianie psychologii. Jest ona reakcją zarówno na behawioryzm, jak i na freudowską psychoanalizę. Zwolennicy psychologii humanistycznej twierdzą, że deterministyczne poglądy Freuda na człowieka prowadzą do pesymistycznego obrazu - zależności od irracjonalnych sił, zaprogramowanych w różnych stadiach naszego rozwoju (psychoseksualnego). Jesteśmy przedstawiani jako „ofiary-widzowie” ślepych sił oddziałujących z naszego wnętrza i kierujących naszym myśleniem i działaniem. Również w behawioryzmie przyjmuje się, że istnieją siły kierujące nami, lecz działają one na nas z zewnątrz, ze środowiska.
Poprzedni prezes American Association for Humanistic Psychology (Amerykańskiego Towarzystwa Psychologii Humanistycznej), Floyd Matson, zaatakował wielu aktywnych zawodowo psychologów, gdy powiedział:
„Nie znam większego braku szacunku dla człowieka-podmiotu, niż traktować go jako przedmiot; chyba że jeszcze większym lekceważeniem jest dalsze poniżenie tego przedmiotu przez dzielenie go na popędy, cechy, odruchy i inne mechaniczne elementy konstrukcyjne” (1971, s. 7).
Krótko mówiąc, psychologia humanistyczna to: głębokie zainteresowanie procesem samorealizacji człowieka (human becoming), nacisk na integralność i specyficzność jednostki, troska o polepszenie losu ludzkiego, jak również o zrozumienie jednostki. Psychologowie reprezentujący tę humanistyczną tradycję, tacy jak Rollo May, Carl Rogers i Abraham Maslow, są przekonani, że badania psychologiczne powinny być ukierunkowane na zrozumienie własnej tożsamości, wyboru, wolności, pewności, nadziei i samospełnienia - a także na środki służące osiągnięciu tych celów czy optymalizacji tych procesów w nas samych”.
Istnieją też ważne sposoby badania procesów psychologicznych; ich zwolennicy również zajmują stanowisko wobec tych odwiecznych zagadnień. Na przykład, w ortodoksyjnym psychoanalitycznym podejściu freudowskim rolę zasadniczych czynników wpływających na życie dorosłego człowieka doświadczenia z wczesnego okresu życia i dawne zdarzenia traumatyczne.  Dane, które rozpatruje psychoanalityk, pochodzą z niekontrolowanych źródeł, jakich jak sny, marzenia, wywiady, badanie przypadków i psychoterapia indywidualna. W tym analitycznym podejściu poświęca się wiele uwagi |procesowi, w wyniku którego wytwarzają się pewne przekonania, wartości czy symptomy chorobowe.
Podobne analityczne podejście, w innej gałęzi psychologii, stosuje szwajcarski psycholog Jean Piaget. Intensywne badania Piageta nad tym, |w |jaki |sposób u dziecka rozwija się myślenie, spostrzeganie i mowa dostarczają nam nieco informacji o procesach poznawczych zachodzących w umyśle dziecka w czasie rozwiązywania problemu, a nie tylko o tym, czy dane dziecko rozwiązało problem czy nie.
Wymienione tu zagadnienia i różne sposoby ich ujmowania będą powracać w tej książce pod rozmaitymi postaciami. Mamy nadzieję, że przedstawiony powyżej ich krótki zarys pomoże ci lepiej zrozumieć niektóre alternatywne sposoby uprawiania psychologii. Powinien także stworzyć podstawę dla zrozumienia i przewidywania twojego własnego zachowania, a więc dla uzyskania większych możliwości kierowania swym życiem.


Cele psychologii

Co właściwie starają się osiągnąć psychologowie? Jakie są cele, które stanowią podstawę całej ich działalności?
Dla psychologa-badacza celami tymi są: opisywanie, wyjaśnianie, przewidywanie i sterowanie (control). Dla psychologa działającego w zakresie psychologii stosowanej, który przeprowadza badania nad praktycznymi problemami lub wykorzystuje w praktyce wyniki uzyskane w innych badaniach, istnieje jeszcze piąty cel - podniesienie jakości ludzkiego życia. W miarę jak psychologiczne techniki oddziaływania stają się coraz skuteczniejsze, upowszechnia się przekonanie, że również psycholog-badacz musi brać pod uwagę ten piąty cel.


Opisywanie tego, co dzieje się naprawdę


W sądzie wymaga się, aby materiał dowodowy przedstawiany zarówno przez oskarżenie, jak i obronę, był obiektywny i konkretny. Chociaż materiał ten ma skłonić sędziego i ławę przysięgłych do opowiedzenia się za stanowiskiem jednej bądź drugiej strony, to jednak każdy dowód musi być „faktem” - nie może być czyjąś interpretacją faktów. „Res ipsa loquitur” - fakt mówi sam za siebie. Materiał dowodowy albo musi być opisany w taki sposób, aby różni przysięgli mogli uzgodnić swoje poglądy na temat tego, co ów materiał przedstawia, albo też musi być on dostępny im osobiście. To „co zdarzyło się” i to „co jest” odróżnia się starannie od tego „co mogłoby być” i tego „co zdaje się być”. W opisie faktów wnioskowanie jest niedopuszczalne.
W nauce również pierwszym zadaniem jest „poznać fakty”. Istnieje szereg analogii między normami, jakim musi odpowiadać materiał dowodowy w sądzie oraz dane naukowe. W nauce wnioski też muszą być oparte na obiektywnej obserwacji. Obserwacje zaś muszą być opisane w taki sposób, aby wiedza innych o tym, co opisujesz, była możliwie najbardziej zbliżona do twojej i aby odpowiadała obserwacjom, jakie by inni poczynili, gdyby mięli dostęp do tych samych zdarzeń.
„Dane i fakty”. W nauce materiał dowodowy składa się z |danych. Dane są opisami lub pomiarami obserwowanych zdarzeń. Są one cegiełkami, z których powstaje psychologia i każda inna nauka. Dane są tym, co odróżnia nauki ścisłe od dociekań logicznych, filozoficznych, matematycznych czy religijnych.
Każde ziarnko pisaku na plaży, każdy uśmiech nieznajomego, każda chwila milczenia w czasie rozmowy są potencjalnym źródłem danych. Czyjeś sny nie są danymi, ponieważ tylko osoba śniąca ma do nich bezpośredni dostęp.  Natomiast |sprawozdania zawierające opisy snów mogą służyć jako dane, podobnie jak zmiany w czynności bioelektrycznej mózgu lub ruchy oczu w tych okresach snu, w których u ludzi - według ich sprawozdań - występowały marzenia senne. Takie dane, gdy się je zgromadzi, mogą być analizowane i oceniane przez niezależnych badaczy.
Psycholog musi stale mieć się na baczności, aby oddzielać |obserwacje („Ręce pacjenta drżały i nie utrzymywał kontaktu wzrokowego z terapeutą”) od |wniosków, które wychodzą poza te obserwacje („U pacjenta obserwowano niepokój”). Jeśli pacjent uskarża się na ból głowy, to wszyscy obecni muszą usłyszeć to stwierdzenie i zgodzić się, że pacjent je wypowiedział, lecz mogliby nie być zgodni co do tego, czy rzeczywiście boli go głowa.
Aby opisać jakieś zdarzenie, takim jakim ono jest, obserwator musi odrzucić swe oczekiwania i przypuszczenia, a także zminimalizować ograniczenia nakładane nań przez jego własną przeszłość, kulturę i uznawane wartości. Jest to wymaganie trudne, jeśli nie niemożliwe do spełnienia, pomimo naszych najlepszych zamiarów i starań.
Hugo Munsterberg, jeden z pierwszych psychologów prowadzących badania w Harvard University, daje godny uwagi opis różnych obserwacji dokonanych przez reporterów, którzy wysłuchali jego przemówienia na temat pokoju, jakie wygłosił przed licznym audytorium w Nowym Jorku:
„Reporterzy siedzieli tuż przy podium. Jeden z nich napisał, że słuchacze byli tak zaskoczeni moim przemówieniem, iż wysłuchali go w zupełnym milczeniu; inny zanotował, że wciąż przerywały je gromkie brawa, a gdy skończyłem mówić, oklaski trwały kilka minut. Jeden napisał, że w czasie przemówienia mego przeciwnika uśmiechałem się nieustannie; inny zauważył, że moja twarz pozostawała surowa i bez uśmiechu. Jeden stwierdził, że wskutek podniecenia moja twarz stała się purpurowo-czerwona, a drugi doniósł, że zbladłem jak kreda. Jeden poinformował czytelników, że mówca, który mnie krytykował, w trakcie swego przemówienia wchodził na podium i schodził z niego; inny - że mówca ów stał cały czas obok mnie i klepał mnie ojcowsko po ramieniu (1908, s. 35-36).
Z pewnością, któryś opis nie był zgodny z rzeczywistością. Dane stają się faktami posiadającymi znaczenie, gdy potwierdzają (lub podważają) to, co uważamy za prawdziwe. Aczkolwiek dane zbierane są w sposób obiektywny, to jednak często - a może zawsze - wybiera się je i przedstawia dla poparcia swego poglądu. To, co zostało zebrane i opisane, może być zatem tylko częścią tego, co dałoby się zobaczyć.
Psychologowie dobrze zdają sobie sprawę ze słuszności starego powiedzonka: „Znajdziesz to, czego szukasz”. Przy planowaniu swych eksperymentów starają się zabezpieczyć przed tą tendencją. Na przykład psychologowie, badając skutki stosowania jakiegoś środka farmakologicznego lub innego sposobu leczenia, przeprowadzają tak zwane |podwójne |ślepe (double-blind) próby. Organizują je w taki sposób, aby osoby oceniające zachowanie badanego nie wiedziały, aż do zakończenia próby, którzy badani byli poddani leczeniu, a którzy nie. Również sami badani nie wiedzą w której znaleźli się grupie ani nawet tego, że są dwie, odmiennie traktowane grupy.
Zwłaszcza w nowych dziedzinach badań trudno jest badaczom zachować obiektywizm. Im bliżej są oni odkrycia, które mogłoby spowodować prawdziwy przełom, tym trudniej im zachować bezstronność obserwacji i uchronić interpretację danych przed wpływem tego, co chcieliby stwierdzić - bez względu na to, jak dobre mają intencje. Gdy czytamy o „zadziwiających, nowych odkryciach w psychologii”, lub w jakiejkolwiek innej nauce, dobrze jest być ostrożnym z przyjmowaniem ich za dobrą monetę, dopóki czas nie wykaże ich wartości.
Operacjonizm. Jeśli zjawiska wewnętrzne, takie jak sny, „lęk”, czy „frustracja”, nie mogą służyć jako dane, to w jaki sposób można je badać?  Stwierdzasz, że czujesz się „onieśmielony”; jeden obserwator opisuje twoje zachowanie jako „wyniosłe”, drugi jako „introwertywne”, a trzeci jako „pełne urazy”. Jakie ono jest?
Fizyk Percy Brielgman (1927) zaproponował podejście zwane |operacjonizmem, które ma na celu uwolnienie terminów i pojęć od niejasności i wieloznaczności. Polega ono na tym, że dane pojęcie definiuje się za pomocą operacji stosowanych przy pomiarze. Na przykład głód jest zjawiskiem wewnętrznym, które nie może być obserwowane bezpośrednio przez osobę postronną. Jeśli jednak zdefiniujesz głód operacyjnie, jako pewną liczbę godzin bez pożywienia, to każda osoba czytająca o twoich badaniach będzie wiedzieć dokładnie, co masz na myśli mówiąc, że badani byli „głodni”. Ktoś inny będzie mógł powtórzyć twój eksperyment mając pewność, że zastosował podobne warunki. Jeśli nie istnieją operacje pozwalające określić jakieś pojęcie, to nie można się nim posługiwać w sposób naukowy, chociaż nadal może ono być użyteczne w filozofii lub w zwykłej rozmowie.
W odniesieniu do wielu pojęć, które stosuje się w psychologii, używano w różnych badaniach różnych procedur pomiarowych. Na przykład w badaniach nad „stresem psychologicznym” do zdefiniowania stresu służyło kilka różnych rodzajów pomiarów. Ważne jest, żeby badacze przekazując wyniki badania podawali, jakich procedur operacyjnych użyli dla zdefiniowania swych pojęć, abyśmy przy porównywaniu rezultatów różnych badań wiedzieli, czy istotnie dotyczyły one tego samego pojęcia. W przeciwnym razie badania nad „stresem” mogłyby odnosić się do zupełnie odmiennych procesów. Na przykład, gdyby jeden badacz posłużył się „napięciem mięśniowym” jako definicją stresu, drugi zaś wykorzystał w tym celu „bóle głowy” lub „dni opuszczone w pracy”, to mierzyliby oni co innego i mogliby uzyskać zupełnie odmienne wyniki dotyczące „stresu”.
Czasami, kiedy żadna pojedyncza definicja operacyjna nie obejmuje całego pojęcia, można używać kilku łącznie; w takim wypadku, aby określić, co mamy na myśli stosując dane pojęcie, posługujemy się czymś w rodzaju „procesu triangulacji”: „pobudzenie emocjonalne” można na przykład zdefiniować za pomocą pewnej kombinacji sprawozdań dotyczących samego siebie, ocen wyszkolonych obserwatorów, danych o zmianach fizjologicznych oraz wyników uzyskiwanych w określonych zadaniach wykonaniowych („performance tasks”).


Wyjaśnienie tego, co się dzieje

Chcemy wiedzieć nie tylko to, co się dzieje, lecz także to, w jaki sposób związane są ze sobą dwa zdarzenia lub większa ich liczba. Celem nauki jest poszukiwanie prawidłowości, stałych zależności. Właśnie w wyniku tych poszukiwań nauka odkrywa „fakty”, czerpiąc je z prehistorycznych rysunków na ścianach jaskiń, kul staczających się z równi pochyłej, pleśni na chlebie, ślinienia się psów na dźwięk dzwonka czy też zmian w elektrycznej oporności skóry.
„|Co” |i „|jak”, |a |nie „|dlaczego”. Chociaż procesy wyjaśniania zaczyna się od prób ustalenia „Dlaczego?”, to jednak badanie naukowe ma na celu odpowiedzenie na pytania „Co?” i „Jak?”, na które można udzielić odpowiedzi opisowych. Pytanie „Dlaczego?” nie jest akceptowane z naukowego punktu widzenia, ponieważ nie można na nie odpowiedzieć zadawalająco, dopóki jest jeszcze możliwe postawienie następnego „Dlaczego?”. Pytania te wymagają niekończącego się zagłębiania w coraz bardziej podstawowe „Dlaczego?”, a w końcu docierania do ostatecznych, absolutnych przyczyn i metafizycznych prawd, które znajdują się poza zasięgiem empirycznych dowodów, a więc poza dziedziną nauki.
Typy wyjaśnień stosowane w psychologii. Wiele różnych rodzajów wyjaśnień może dopomóc w wytłumaczeniu określonego zdarzenia, doświadczenia lub problemu osobistego. Jeden z nich polega na wnioskowaniu o przyczynach natury |mentalistycznej czy |psychicznej (mentalistic or psychic), takich jak uczucia czy pragnienia. Rozpatrzmy następujące „wyjaśnienie”, zaproponowane przez biochemika Myrona Tumblesona dla wytłumaczenia nawyku upijania się u świń, którym dawano mieszaninę alkoholu i soku pomarańczowego. Świnie te, zani jeszcze zapoznały się z alkoholem, ustanowiły w stadzie hierarchię (analogiczną do „porządku dziobania” u kurcząt), która określała kolejność, w jakiej układały się w pomieszczeniu - dominująca świnia zawsze zajmowała najbardziej cenione miejsce w rogu, następnie kładły się zwierzęta znajdujące się coraz niżej w hierarhii, kończąc na „najniższej” świni, która zawsze musiała wystawiać pośladki na świeże powietrze.
„Król świń pił tak dużo, że stracił swoją pozycję w ciągu 24 godzin” podaje Tubleson. „Świnia numer 3 piła bardzo mało i została królem świń”.  Jednakże następnego ranka świnia, która pierwotnie była numerem 1 przyszła do siebie i w ciągu 72 godzin wróciła na szczyt hierarchii. Tumbleson stwierdził, że „nie upiła się ona już nigdy więcej”.
Po tym doświadczeniu świnie wytworzyły takie formy picia, które były 
najwyraźniej zdeterminowane ich uczuciami w stosunku do własnej pozycji 
społecznej. „Największą pijaczką była świnia zajmująca szóstą pozycję w 
hierarchii społecznej złożonej z siedmiu świń” wyjaśnił Tumblesom, 
„najwyraźniej jest ona sfrustrowana z powodu swej pozycji i ucieka w 
alkoholizm”. Eksperyment ten przyniósł także dobrą wiadomość dla wiecznie 
przegrywających: świnia zajmująca najniższą pozycję w zagrodzie 
najwyraźniej nie czuła żadnej potrzeby, aby zalewać swe smutki. „Świnia 
numer 7 wiedziała, że jest ostatnia”, powiedział badacz z Missouri, „i 
zaakceptowała to”

(„Newsweek”, 30 lipca 1973).


Każą nam tu uwierzyć, że niektóre świnie doznawały uczucia frustracji, że niektóre były świadome zmian swej pozycji społecznej, a inne były zdolne przyjąć z rezygnacją, a nawet zaakceptować świadomość, że są najpodlejszymi ze stworzeń. Jest to skrajny przykład zarówno |antropomorfizmu, to znaczy przypisywania cech ludzkich zwierzętom, jak i wyjaśniania w kategoriach przyczyn psychicznych.
W wyjaśnieniach tego rodzaju za przyczyny zachowania uznaje się powody wewnętrzne - pragnienia, życzenia, impulsy i zamiary: ktoś zrobił to, co zrobił, ponieważ pragnął to zrobić. Jeśli jednak jego pragnień nie można zaobserwować, to stwierdzenie „On zrobił to, co zrobił, ponieważ pragnął to zrobić”, nie dodaje żadnej informacji do stwierdzenia, że ktoś coś zrobił.  Jak jednak już wspominaliśmy, wzrasta obecnie zainteresowanie badaniem zjawisk świadomości w sposób naukowy, przez szczegółowe określenie operacji, czyli widocznych zachowań, którymi można się posłużyć jako obiektywnymi wskaźnikami zjawisk wewnętrznych, będących przedmiotem wnioskowania.
Innego rodzaju wyjaśnienia są formułowane w kategoriach zjawisk |fizjologicznych zachodzących w mózgu, komórkach nerwowych, gruczołach i innych niezliczonych narządach organizmu. Wielu studentów wstępnego kursu psychologii jest przekonanych, że fizjologia jest kluczem do zrozumienia wszelkiego zachowania: że kiedy wiemy dostatecznie dużo o fizjologii i reakcjach biochemicznych, to nic więcej nie pozostaje do wyjaśnienia.
Lecz chociaż wyjaśnienia fizjologiczne mogą wytłumaczyć dane zachowanie, to jednak często pozostaje nierozstrzygnięte zagadnienie, w jaki sposób działa dany proces fizjologiczny i co go wywołuje.
Istnieją także zjawiska z zakresu zachowania, których zakres jest zbyt szeroki, aby można je było sensownie wyjaśnić na wysoce specyficznym poziomie fizjologii mózgu. Jeśli ktoś szuka wytłumaczenia, dlaczego wiceprezydent Stanów Zjednoczonych rzekomo brał łapówki, to nie zadowoli go wyjaśnienie, w jaki sposób mięśnie ręki kurczą się, aby uchwycić wsunięte w nią pieniądze. Wyjaśnienie musi być odpowiednie do poziomu postawionego pytania.
Inną formą wyjaśniania jest użycie |analogii. Nowe zjawisko wyjaśnia się przez ukazanie jego podobieństwa do już znanych, powszednich zjawisk. Ta forma wyjaśnienia traci wiele ze swej wartości, gdy owo powszednie zjawisko samo nie jest dobrze rozumiane lub gdy podobieństwo między zjawiskiem nowym a zjawiskiem znanym jest ograniczone lub nieistotne. Zastosowanie analogii jest dość typowe dla wyjaśnień podawanych przez dzieci. Przykładem mogą być odpowiedzi udzielane przez nie na pytanie „Jak myślisz, co to jest kac?”, w których podawały na przykład, że jest to coś podobnego do kłopotu po kłótni.
W tych podawanych przez dzieci wyjaśnieniach pojęcia kaca występuje także i inna forma, którą przyjmuje wiele wyjaśnień naukowych, a mianowicie |wyliczenie |warunków |granicznych, w jakich dane zjawisko występuje i ulega zmianom. Tak więc kac jest określany jako zjawisko spotykane częściej u dorosłych, występujące rano (po pewnych przeżyciach z poprzedniego wieczoru) oraz jako pewien stan przeżywany przez jednostkę, który pogarsza się pod wpływem hałasu, podczas gdy zażycie lekarstwa zwanego „klinem” przynosi ulgę. Takie empiryczne stwierdzenia mogą nie być ścisłe, lecz przynajmniej można je łatwo sprawdzić i zweryfikować (O’Hara, 1972).
Pokrewna, chociaż bardziej wyrafinowana odmiana tego sposobu podejścia nosi nazwę wyjaśnienia |funkcjonalnego. Zachowanie wyjaśnia się określając warunki bodźcowe, których jest ono funkcją. Ustalenie warunków bodźcowych dających się zaobserwować i zmierzyć, które są w stały sposób związane z pewną dającą się zaobserwować i zmierzyć reakcją, uważa się za wystarczające wyjaśnienie tej reakcji. Jeśli istnieje na przykład stały związek między częstością występowania pewnego zachowania a przyjemnymi lub nieprzyjemnymi konsekwencjami, jakie to zachowanie miało w przeszłości dla organizmu, to mówi się, że jest ono wyjaśnione przez te konsekwencje (tzn.  jest ich funkcją). Nie trzeba szukać żadnych innych przyczyn. Takie stanowisko reprezentuje B. F. Skinner, który głosi, że wyjaśnienie funkcjonalne jest jedyną możliwą do zaakceptowania formą wyjaśnienia.
Takie wyjaśnienie nie mówi nam, |jak są ze sobą związane dwa zjawiska, a tylko wskazuje, że |są one związane, że jedno następuje regularnie po drugim.
Zachowanie można również wyjaśniać za pomocą modeli i symulacji.  Wyjaśnienie przy użyciu modelu polega na zastosowaniu jakiejś struktury pojęciowej lub teoretycznej, opracowanej w jeden dziedzinie wiedzy, dla ukierunkowania badań i dociekań w dziedzinie mniej rozwiniętej. Na przykład Zygmunt Freud dążąc do wyjaśnienia anormalnego zachowania posłużył się modelem energetycznym zapożyczonym z fizyki („energia psychiczna”) i modelem hydraulicznym zaczerpniętym z techniki, aby pokazać, w jaki sposób siły napędowe w „id” przypuszczalnie kierują wieloma formami naszego zachowania - na przykład, jak nie dające się zaakceptować impulsy, wyparte ze świadomości, ujawniają się w psychopatii życia codziennego: pewnych typach zapominania, przejęzyczeniach, „przypadkach” itp. Jednakże modele takie w rzeczywistości nie wyjaśniają zachowania; dzięki nim wydaje się ono jedynie bardziej znajome.
Wraz z pojawieniem się komputerów powstała nowa forma wyjaśniania, a mianowicie |symulacja danego procesu behawioralnego. W połowie lat pięćdziesiątych Newell, Shaw i Simon z Instytutu Technologicznego Carnegie wpadli na myśl, że ponieważ komputery są maszynami operującymi symbolami, przeto można by ich użyć dla zademonstrowania procesów, dzięki którym ludzie operują symbolami wtedy, gdy myślą czy rozwiązują problemy. Od tego czasu zrealizowano wiele symulacji komputerowych. Opracowuje się na przykład model uczenia się lub pamięci, a następnie programuje się według niego komputer, który przetwarza nowe informacje w sposób określony przez ten model. Proces ten i jego wynik porównuje się z wynikami eksperymentów na żywych osobach badanych. Przyjmuje się, że jeśli istnieje duża zgodność miedzy wynikami obu tych procesów, to model symulacji komputerowej dostarcza adekwatnego wyjaśnienia tego, co prawdopodobnie zachodzi w „czarnej skrzynce” ludzkiego mózgu.
Przy budowie modeli psychologicznych „tym, co w gruncie rzeczy staramy się symulować (...) nie jest (jedynie) obserwowane zachowanie organizmu, lecz raczej repertuar zachowań, z którego pochodzi to obserwowane zachowanie” (Fodor, 1968, s. 133). „Siła wyjaśniająca” („explanatory power”) modelu jest większa, gdy oprócz rzeczywistego, przeszłego zachowania organizmu pozwala ona opisać także jego potencjalne zachowanie.
Najpoważniejszą próbą wyjaśnienia są |wyjaśnienia |teoretyczne. Wyjaśniać za pomocą teorii - to dedukować szczególny przypadek z ogólniejszych zasad, niekiedy nawet przed zaobserwowaniem go - szuka się wówczas potwierdzenia w obserwacji i prowadzonych eksperymentach.
W języku potocznym często używa się słowa „teoria” zamiennie ze słowem „wyjaśnienie”, jak na przykład wtedy, gdy pytamy: „Jaką masz teorię na temat tego, że na egzaminach wstępnych do college’u kobiety uzyskują lepsze wyniki w testach werbalnych niż mężczyźni?”. W psychologii natomiast teoria przedstawia w sformalizowanej, usystematyzowanej postaci związki między różnymi założeniami, pewnymi regułami zachowania, rozmaitymi wnioskami oraz zbiorem zaobserwowanych istotnych faktów. Wartość teorii ocenia się biorąc pod uwagę jej zdolność do a) nadawania znaczenia znanym faktom i do podporządkowania ich, b) ujawniania związków między pojęciami i obserwacjami uprzednio uważanymi za nie związane ze sobą oraz c) generowanie nowych idei, które można będzie sprawdzać w dalszych badaniach.
Teoria decyduje o tym, które obserwacje staną się „danymi” i które dane „zasługują” na to, aby stać się istotnymi faktami. Kiedy pojawią się nowe fakty niezgodne z daną teorią, to albo modyfikuje się teorię, żeby ją do nich dostosować, albo też - co jest rozwiązaniem częstszym, choć mniej naukowym - po prostu ignoruje się fakty. Prawie nigdy nie zdarza się, żeby fakty sprzeczne z teorią spowodowały jej obalenie i odrzucenie.  Bezwartościowe teorie nadal żyją swym własnym życiem, dopóki nie zastąpią ich inne, które okazały się mniej wątpliwe. Przykładem tej niechęci do odrzucenia starej teorii na rzecz nowej jest utrzymanie się teorii Ptolomeusza, głoszącej, iż Ziemia jest środkiem wszechświata, jeszcze przez długi czas po tym, jak empirycznie i logicznie udowodniono, że heliocentryczna teoria Kopernika jest lepszym modelem ruchu planet.


„Taka jest natura teorii, że gdy tylko człowiek ją wymyśli, to przyswaja ona wszystko jako właściwy dla siebie pokarm; zwykle od pierwszej chwili, gdy ją powołałeś do życia, rośnie w siłę dzięki wszystkiemu co widzisz, słyszysz, czytasz lub poznajesz”.
Laurence Sterne „Tristram Shandy”, 1759-67 (wyd. pol. „Tristram Shandy”)


Tak więc drugi cel psychologa - wyjaśnianie zachowania - polega na znajdowaniu porządku, prostoty i regularności w pozornym chaosie, złożoności i przypadkowości obserwowanych zdarzeń.


Przewidywanie tego, co się zdarzy


Przez cały kres swych dziejów ludzie nie tylko pragnęli zrozumieć naturę, lecz także usiłowali poznać przyszłość - przewidywać zawczasu wydarzenia i przygotować się na nie. W czasach starożytnych wróżbici i wieszczowie cieszyli się wielkim poważaniem, ponieważ przypisywano im ponadnaturalną zdolność odsłaniania przyszłości dzięki odczytywaniu znaków dawanych przez bóstwa. Obecnie, jeśli chodzi o przewidywanie przyszłości, polegamy głównie na nauce. Dokładne przewidywanie pozwala nam kierować naszym obecnym postępowaniem w taki sposób, aby uniknąć niebezpieczeństw, przykrości i rozczarowań, zapewniając sobie bezpieczeństwo, przyjemność i zadowolenie.  Trafne przewidywanie zmniejsza niepewność i daje poczucie, że rozumiemy to, co dzieje się dookoła i wewnątrz nas (ryc. 1.4)


* * *

Ryc. 1.4. Stonehenge, masywna budowla na równinie Salisbury w Anglii, pochodząca z okresu neolitu, jest niemym świadectwem ludzkiej pasji przewidywania tajemniczych zjawisk przyrody. O brzasku dnia przesilenia letniego (24 czerwca) pierwsze promienie wschodzącego Słońca padają przez szczelinę łuku prosto na olbrzymi głaz (heel stone). Na podstawie dokładnych badań astronom Gerald Hawkins (1965) doszedł do wniosku, że Stonehenge jest w rzeczywistości dokładnym, choć prymitywnym komputerem, zdolnym nie tylko przewidywać coroczne przesilenia, lecz także przepowiadać najbardziej przerażające ze zjawisk niebieskich - zaćmienie Księżyca i Słońca.


* * *

Podczas gdy niektórym psychologom wystarczy zrozumienie i wyjaśnienie jako cel badań, inni podkreślają że jeśli nie potrafisz przewidzieć, w jakich warunkach dane zachowanie będzie występować lub zmieniać się, to znaczy, że po prostu nie zrozumiałeś go. Według nich, operacyjnym sprawdzianem wyjaśnienia jest przewidzenie tego, co się zdarzy lub możność spowodowania, aby się to wydarzyło, albo też jedno i drugie.
Przewidywanie szacunkowe a przewidywanie w wyniku zrozumienia. Niektóre przewidywania są to wartości przeciętne, otrzymane na podstawie zależności zaobserwowanych w przeszłości. Tego typu przewidywania pozwalają nam określić, ilu motocyklistów zginie w wypadkach drogowych w ciągu najbliższego weekendu. Przewidywania takie zwane są przewidywaniami |szacunkowymi (actuarial predictions). Dotyczą one grup, nie zaś jednostek.  Cała koncepcja ubezpieczeń na życie oparta jest na tym, że można przewidzieć bardzo dokładnie przeciętną długość życia różnych kategorii ludzi. Przewidywanie szacunkowe nie wymaga zrozumienia zjawisk życia i śmierci, lecz jedynie zaobserwowania przeszłych zależności.
Jednakże celem większości przewidywań naukowych jest tak dobre zrozumienie związków przyczynowo-skutkowych, aby można było określić dokładnie warunki, w których dane zjawisko wystąpi lub nawet przewidzieć zjawisko, które nie było poprzednio obserwowane.
Hipotezy dotyczące zależności. Każde badanie zmierzające do ustalenia przyczyn zaczyna się od postawienia hipotezy. |Hipoteza jest to stwierdzenie określające, w jaki sposób mogą być ze sobą związane dwa zjawiska lub dwie zmienne (albo też większa ich liczba). Niektóre hipotezy mają charakter ogólny i stwierdzają tylko, że pewien związek istnieje; inne są bardziej szczegółowe i określają, jak są ze sobą związane dwie zmienne.  Oto przykład hipotezy tego drugiego rodzaju: W miarę wzrostu anonimowości wzrasta liczba aktów przemocy. Hipotezy muszą być sformułowane tak, aby można je było sprawdzić w drodze obserwacji lub logicznego wnioskowania albo też obydwoma tymi sposobami.
Kiedy związek wskazuje na istnienie zależności przyczynowej? Tylko kilka spośród możliwych odpowiedzi na to pytanie podano poniżej.


Zbliżenie

O przyczynowości

„Przyczyna jest ukryta, skutek jest znany”.


Ovidius „Metamorphoses”, 8 r. n.e. (wyd. pol. „Przemiany”)


„W naturze każda rzecz jest przyczyną, z której wynika pewien skutek”.
Baruch Spinoza „Ethica”, 1677 (wyd. pol. „Etyka”)

„Przypadek jest to słowo pozbawione sensu;
Nic nie może istnieć bez przyczyny”.
Voltaire „Dictionnaire philosophique”, 1764

„Nic nie może się zdarzyć bez wystarczającego powodu”.
Gottfried Wilhelm „Leibniz Monadologie”, 1714

„Spójrz na jakieś dwie rzeczy, które nazywamy przyczyną i skutkiem i obracaj je na wszystkie strony, aby odnaleźć to znamię, które wywołuje wrażenie tak cudownej konsekwencji”.
David Hume „A Treatise of Human Nature”, 1739-40 (wyd. pol. „Traktat o naturze ludzkiej”)

„Najważniejsze wydarzenia często wynikają z bardzo błahych przyczyn”.
Marcus Tullius Cicero „Orationes Philippicae”, 43 r. p.n.e. (wyd. pol. 
„Filipki”)

„Każdy skutek staje się przyczyną”.
Maksyma buddyjska


„W naturze istnieje coś takiego, jak analogiczne przypadki; to, co zdarzyło się raz, w wystarczająco podobnych okolicznościach wydarzy się znowu”.
John Stuart Mill „A System of Logic”, 1843 (wyd. pol. „System logiki”)




„Skutek: drugie spośród dwóch zjawisk, które zawsze występują razem w tym samym porządku. O pierwszym z nich, zwanym |Przyczyną, mówi się, że wywołuje drugie - co ma nie więcej sensu, niż miałoby oświadczenie kogoś, kto nigdy nie widział psa inaczej niż w pogoni za królikiem, że królik jest przyczyną psa”.
Ambrose Bierce „The Devil’s Dictionary”, 1911




Wykrywanie związków przyczynowych jest jednym z głównych celów badań psychologicznych. Ponadto odwiecznym problemem analizowanym przez filozofów było ustalenie warunków, które stanowią kryteria związku przyczynowego. Aby zjawiska można było uznać za związane przyczynowo, muszą one występować razem (być niezmiennie skojarzone ze sobą: jeśli A, to zawsze B), przy czym przyjmuje się, że „przyczyna” musi występować przed „skutkiem” lub równocześnie z nim. Zależność ustalona w badaniu oznacza jednak tylko, że dane zjawiska występowały razem w określony sposób. Wszelkie wyjaśnienie określające, |jak są ze sobą związane dwie zmienne, jest interpretacją teoretyczną, którą trzeba ocenić w zestawieniu z innymi możliwymi interpretacjami. Prawie zawsze istnieje więcej niż jedno możliwe wyjaśnienie tego, |jak są ze sobą związane dwa zjawiska. Sam związek przyczynowy jest pojęciem; nie widzi się go, lecz jedynie wnioskuje się o nim.
Dla badacza lub uczonego decydującym zadaniem jest próba ustalenia wszystkich możliwych hipotez, które mogłyby wyjaśnić dane zjawisko. Każdą z nich sprawdza się przez porównanie z dostępnymi informacjami, najnowszymi teoriami lub wynikami nowych eksperymentów; w wyniku systematycznej eliminacji wszystkie hipotezy, prócz jednej, zostają odrzucone jako niezadowalające. Gdy fałszywe hipotezy zostały wyeliminowane, wówczas badacz pozostaje z jedną hipotezą, która wydaje się lepsza od swych rywalek.
Pewność nie jest jednak nigdy absolutna. Materiał dowodowy może dostarczyć poparcia dla danej hipotezy, lecz nigdy nie może wykazać, że jest ona prawdziwa. Nawet wtedy, gdy hipotezy zostały poparte przez wyniki wielu badań i uzyskały w ten sposób wysoką rangę „praw” rządzących zachowaniem, nie uznaje się ich za dowiedzione w jakimś absolutnym sensie.  Nadal uważa się je za jedynie tymczasowe - za najlepszą wiedzę dostępną w danym czasie. Tak więc badania psychologiczne przekształcają „niepewność” w „prowizoryczność” (tentativeness), dążąc w kierunku nieziszczalnego ideału „pewności”, lecz nigdy go całkowicie nie osiągając.


Korelacja w związek przyczynowy. Przewidywania oparte na związku między przyczyną a skutkiem są tylko jedną z form, jaką mogą przyjmować przewidywania i w dodatku nie są formą najczęstszą ani najbardziej znaną.  „Powodzenie w studiach” przewiduje się na podstawie wyników uzyskanych w teście College Entrance Examination Board (Komisji Egzaminów Wstępnych do College’ów), lecz wyniki te nie są przyczyną powodzenia. W większości przypadków przewidujesz swoje przyszłe zachowanie na podstawie swego obecnego zachowania. To, jak wypadniesz na końcowym egzaminie, oceniasz opierając się na wynikach uzyskanych na kolokwiach. W zależności od tego, jak bardzo podobała ci się partnerka na pierwszej randce, przewidujesz, jak będą wyglądać następne spotkania i kontynuujesz lub zrywasz tę znajomość.  Psychologowie zajmujący się badaniem różnic indywidualnych między ludźmi - pod względem inteligencji, osobowości, osiągnięć, zdolności czy jakichkolwiek innych cech - opracowują testy, których wyniki służą do przewidywania pewnych interesujących ich zachowań.
We wszystkich tych przykładach przewidywanie oparte jest raczej na związku między warunkami środowiskowymi, a zachowaniem. Są to korelacje, czyli po prostu stwierdzenia dotyczące istnienia związku. Aczkolwiek na podstawie danych korelacyjnych można formułować dokładne przewidywania, to jednak |nigdy nie jest uzasadnione przyjęcie założenia, iż dane takie opisują bezpośrednie związki przyczynowe. Jeśli stwierdzimy, że zjawiska A i B są wysoko skorelowane ze sobą, to zaobserwowana korelacja może być wynikiem każdego z następujących związków przyczynowych: A może powodować B, B może powodować A. A może powodować X, które z kolei powoduje B lub na odwrót. X może powodować zarówno A, jak i B. X może powodować A, Y może powodować B, a X i Y mogą na ogół występować razem. I wreszcie zawsze istnieje szansa, że A i B występują razem jedynie w wyniku przypadku.


Zbliżenie

Spokojni Teksańczycy i pobudliwi despoci: korelacje a zawiązek  przyczynowy


„Wykryto”, że w El Paso, mieście położonym w stanie Teksas, miejscowa woda wpływa na mieszkańców jak środek uspokajający, sprawiając, że mają oni zdrowszy pogląd na życie i rzadziej zapadają na choroby psychiczne niż mieszkańcy Dallas. Pierwiastek chemiczny lit, stosowany w leczeniu psychicznie chorych, występuje w dużym stężeniu w wodzie używanej w El Paso, ponieważ pochodzi ona ze studni głębinowych. Dallas natomiast jest zaopatrywane w wodę z płytszych studni, która zawiera mało litu.
Pewien biochemik na zjeździe American Medical Association (Amerykańskiego Towarzystwa Lekarskiego) w 1971 roku doniósł o stwierdzeniu „matematycznie udowodnionej” zależności między zawartością litu w wodzie a liczbą pacjentów przyjętych do szpitali psychiatrycznych w miastach stanu Teksas.  Liczba pacjentów z Dallas była przeszło dziesięć razy większa niż liczba pacjentów przyjętych z El Paso. W roku 1970 odpowiednie liczby wynosiły 2697 i 238; dane przekonywujące, lecz cóż ze związkiem przyczynowym?
„Źródła przyczynowe” są zmącone przez następujące dodatkowe dane: 
najbliższy szpital psychiatryczny jest oddalony o 350 mil od El Paso i tylko 35 mil od Dallas; jest wiele różnic między tymi miastami pod względem statusu społeczno-ekonomicznego mieszkańców i gęstości zaludnienia; wreszcie, chociaż lit uspokaja ludzi chorych na psychozę maniakalno-depresyjną, to jednak nie stwierdzono, aby miał kojący wpływ na ludzi „normalnych”. Tyle, jeśli chodzi o związek przyczynowy! (Komunikat Associated Press, 2 września 1971).
Badacze z Yerkes Primate Center (Ośrodka Badań nad Naczelnymi w Yerkes) w stanie Georgia wykazali istnienie korelacji między pozycją danego osobnika w grupie społecznej małp a występującym u niego poziomem testosteronu, męskiego hormonu wydzielanego przez gruczoły płciowe. Chociaż kilka czynników wpływa na poziom testosteronu u dorosłych samców, to jednak u samców o wyższej pozycji społecznej poziom tego hormonu był na ogół wyższy.  Stwierdzenie tej korelacji pozostawia jednak otwarte pytanie, czy przywódca zostaje przywódcą dzięki wyższemu poziomowi hormonu, czy też poziom testosteronu wzrasta u niego, gdy zostanie on przywódcą.
Próby znalezienia odpowiedzi na to pytanie polegały na eksperymentalnym usuwaniu z grupy samców o wyższej pozycji, aby podporządkowane im osobniki mogły zostać przywódcami oraz na umieszczeniu poprzednich przywódców grup w nowych grupach, gdzie mogły one osiągnąć jedynie podrzędne pozycje.
Rezultaty były jednoznaczne: zmiany pod względem pozycji społecznej powodowały zmiany w poziomie męskiego hormonu. Badacze, Irwin Bernstein, Tom Gordon i Bob Rose, stwierdzają zgodnie:
„Jeśli usuniesz przywódcę ze stanowiska, spada u niego poziom 
testosteronu; jeśli uczynisz któregoś samca przywódcą, poziom ten u niego 
rośnie”
Bernstein, 1974


Istnieje korelacja między ilością lodów zjedzonych przez studentów Uniwersytetu Delaware a liczbą zgonów w Kalkucie, lecz nie jest to związek przyczynowy. Każdy z dwóch elementów tego związku jest wytworzony niezależnie od pozostałego, jako funkcja nasilenia upałów. „Surgeon General’s Report”, 1964 (Raport Ministerstwa Zdrowia) głosi, że ustalono „wyraźny związek” między liczbą wypalanych papierosów a prawdopodobieństwem zapadnięcia na raka i inne śmiertelne choroby. Firmy produkujące papierosy odrzuciły pogląd, że korelacja między tymi dwoma zjawiskami jest związkiem przyczynowym: być może ludzie, którzy palą więcej, są od początku bardziej nerwowi i pobudliwi, a ta pobudliwość nerwowa sprawia, że są oni bardziej podatni na choroby i narażeni na przedwczesną śmierć, jak też bardziej skłonni do palenia.
Można zapytać, dlaczego robi się tyle szumu z powodu tej różnicy? Staje się ona ważna, gdy przystępuje się do sformułowania zaleceń, jak wpływać na przewidywane zjawisko przez zmianę zachowania służącego do jego przewidywania. Jeśli na przykład palenie papierosów powoduje raka, to zaprzestanie palenia zmniejszy prawdopodobieństwo zapadnięcia na tę chorobę. Jeśli, z drugiej strony, pobudliwość nerwowa jest przyczyną obu zjawisk, to zaprzestanie palenia mogłoby narazić daną osobę na jeszcze większy stres i zwiększyć prawdopodobieństwo wystąpienia choroby. Jedynie wyeliminowanie alternatywnych wyjaśnień, po zebraniu całej „sieci” korelacyjnych danych, umożliwiło badaczom z American Cancer Society (Amerykańskiego Towarzystwa Badań nad Rakiem) sformułowanie przewidywania, że zaprzestanie palenia zmniejszy prawdopodobieństwo zapadnięcia na choroby dróg oddechowych i układu krążenia, dzięki czemu mogli wydać zalecenia, że powinno się przestać palić. Ogólnie biorąc, związków przyczynowych szuka się raczej między warunkami bodźcowymi a zachowaniem niż między dwoma zachowaniami.


Sterowanie tym, co się dzieje


Psychologowie nie zadawalają się dążeniem do zrozumienia i przewidywania zachowania, lecz starają się także nauczyć, jak nim sterować (control), czyli jak wpływać na nie. Jest to najwyższy i ostateczny cel wielu prac psychologów, a to z dwóch powodów.
Po pierwsze, ostateczny sprawdzian trafności przyczynowego wyjaśnienia zachowania polega na możności zademonstrowania warunków, które pozwalają wywołać, zahamować, podtrzymać lub zmienić dane zachowanie. To właśnie w ten sposób potrafimy dowieść, że znamy |konieczne i |wystarczające |warunki wystąpienia danego zachowania. Na przykład, istnieje korelacja między ilością światła słonecznego, jaką otrzymuje roślina, a jej wzrostem; lecz samo tylko światło słoneczne nie wystarczy. Jest ono koniecznym, ale nie wystarczającym warunkiem regulowania wzrostu roślin - woda i substancje odżywcze zawarte w glebie, to inne warunki konieczne. Podobnie pragnienie, by przestać palić, pić lub zażywać heroinę może być warunkiem koniecznym, aby rzeczywiście zaprzestać tych zachowań, lecz zwykle musi być uzupełnione przez różne zmiany w środowisku, zanim zachowanie to będzie mogło zostać opanowane. Aby umieć opanować niepożądane zachowanie, trzeba zwykle wiedzieć nie tylko to, od czego się ono zaczęło, lecz także, co je podtrzymuje - dzięki czemu trwa nadal.
Drugie uzasadnienie tego nacisku na sterowanie zachowaniem w mniejszym stopniu wiąże się z „czystą wiedzą”, a w większym z użytecznością praktyczną. Psychologia jest dyscypliną o charakterze praktycznym i pragmatycznym; często zajmuje się niepożądanymi zachowaniami i sytuacjami, a także sposobami ich zmiany na lepsze. Strach, lęk, choroby psychiczne, samobójstwo, trudności w nauce, konflikty z pracownikami, maltretowanie dzieci, anomalie seksualne, rasizm, konformizm - to tylko kilka tematów i „problemów” spośród tych, które badają psychologowie z zamiarem zmiany istniejącego stanu rzeczy.
W interesującej książce „The Human Use of Human Beings” („Jak ludzie posługują się ludźmi”) Norbert Wiener (1964) zdefiniował sterowanie jako „nic innego, jak tylko nadawanie informacji”, które skutecznie zmieniają zachowanie odbiorcy. Miał on na myśli sposób, w jaki termostat steruje piecem elektrycznym odbierając informacje o temperaturze w pokoju i nadając informacje, które uruchamiają przekaźniki elektryczne włączając piece.  Proces ten nosi nazwę sterowania |cybernetycznego lub sterowania za pomocą |sprzężenia |zwrotnego. Posługujesz się nim za każdym razem, gdy w czasie tańca starasz się nie nadeptywać na palce swego partnera czy partnerki.
Istnieje wiele innych form sterowania zachowaniem, na przykład zmienianie otoczenia w celu wywołania pożądanego zachowania, wydawanie słownych poleceń, ustanawianie reguł i praw czy wreszcie podanie środków uspokajających lub pobudzających. Na nas wszystkich oddziałuje nieskończona liczba fizjologicznych, społecznych, środowiskowych, prawnych, religijnych i politycznych procesów i czynników. W istocie rzadko zdajemy sobie sprawę z tego, w jakim stopniu nasze zachowanie jest pod kontrolą subtelnych zmiennych sytuacyjnych. Podczas rozruchów, jakie przed niewielu laty miały miejsce w Watts, gdy ludzie pozbywali się zwykłych hamulców, wybijając szyby, wzniecając pożary i walcząc z policją, zaobserwowano, że wielu spośród tych samych ludzi „zatrzymywało się przed światłami regulującymi ruch i ostrożnie prowadziło samochód. W wywiadach przeprowadzanych dla celów badawczych podawano przykłady osobników plądrujących sklepy, którzy przepraszali się grzecznie, gdy wpadli na siebie” (Bernstein, 1970, s.  199).
„Sterowanie” stało się terminem obciążonym ujemnymi konotacjami, kojarząc się z robotami, z kierowaniem za pomocą elektrod wprowadzonych od mózgu, z podprogowymi poleceniami nadawanymi w telewizji i z otępiającymi chemikaliami wsypywanymi do kawy. Lecz chociaż nie znosimy, by nami sterowano, kupujemy w milionach egzemplarzy opublikowane przez D.  Carnegie’ego recepty „How to Win Friends and Influence People” („Jak zdobyć przyjaciół i wpływ na ludzi - tzn. sterować nimi”). Wszyscy jesteśmy skłonni przekonywać i namawiać. Niektórzy z nas zabiegają o wprowadzenie lepszych szkół, inni - bardziej humanitarnych więzień, jeszcze inni - surowszych praw, mniej tolerancyjnych sędziów, wyeliminowania aktów przemocy z telewizyjnych programów dziecięcych itd. We wszystkich tych przykładach występuje dążenie do oddziaływania społecznego.


Zbliżenie

Wykład na rogu ulicy: Psychologia oddziaływania na ludzi


„Billa Wellsa można nazwać kolekcjonerem monet - jest on zawodowym żebrakiem, który w swym fachu posługuje się całkiem skutecznie „psychologią uliczną”.
„Oczywiście, jestem żebrakiem”, mówi wyzywająco. „Co w tym złego?”.
„Nic a nic”, odpowiadasz, dając mu kilka monet w zamian za tajemnicę jego sukcesów.
„Stań teraz tu, w tej bramie, i popatrz, jak to się robi”.
Bill wybiera biznesmena w eleganckim garniturze i stosuje swoją zwykłą metodę: fachowe połączenie kłamstw, pochlebstw i mimiki, które ma jednocześnie pochlebiać i napominać.
„Czy mógłby pan wspomóc biedaka? Nic dzisiaj nie jadłem”. Po ostatnim słowie ręka wyciąga się dłonią do góry, a Bill pochyla się trochę, aby wydać się odpowiednio małym w oczach swego ewentualnego dobroczyńcy.
Bill nazywa to metodą „na głód”. Rzeczywiście wygląda on na głodnego, bez względu na to, czy jadł śniadanie czy nie (a zwykle jada).
Biznesmen w eleganckim garniturze patrzy na Billa chłodno i przechodzi nie zatrzymując się. Dwaj następni mężczyźni zagadnięci przez Billa zachowują się podobnie, lecz trzeci z kolei szybko sięga do kieszeni i wyjmuje z niej ćwierć dolara. Bill zdobył punkt.
Stosowanej przez niego formułce brak na pozór stylu i oryginalności.  Słowa są banalne i oceniasz jego działalność jako pozbawioną oznak prawdziwego talentu. Jednakże przynosi mu ona więcej niż dolara na godzinę, zapytaj go więc, dlaczego tak się dzieje.
„Dobrze”, zgadza się Bill, „Jeśli postawisz mi jednego, to wytłumaczę ci to. I przy szklance dżinu z sokiem cytrynowym wyjaśnia:
„Widzisz, to ma solidne podstawy psychologiczne. Musi być duży kontrast między naszym wyglądem. Moje ubranie jest stare, choć czyste, jest ono zbyt obszerne, a moje buty wyglądają, jakby każdy był z innej pary.
Dobrze ubrany mężczyzna dumny jest ze swego wyglądu i od razu zauważa ten kontrast. A teraz druga sprawa:
Ja nie proszę o jakąś określoną ilość pieniędzy, jak na przykład 10 centów czy ćwierć dolara. Wielkość datku pozostawiam do uznania ofiarodawcy, a to daje mu sposobność podjęcia decyzji, gdy wkłada rękę do kieszeni. Mężczyźni lubią podejmować decyzje.
Następnie zwróć uwagę, iż informuję go, że nic dziś nie jadłem, a to jest napomnienie, ponieważ on prawdopodobnie jadł śniadanie, był na kawie i myśli już o tym, gdzie by zjeść obiad.
Zauważ wreszcie, iż powiedziałem mu, że jestem biedakiem. To nie ulega 
wątpliwości, lecz moje przyznanie się, że mi się w życiu nie powiodło, 
podnosi jego samopoczucie i stawia go wyżej. „Czy mógłby pan wspomóc 
biedaka? Nic dzisiaj nie jadłem””. Zastanów się nad tymi słowami. Mówią one 
bardzo wiele”
Blake, 1972


Co jednak sądzisz o następującym rodzaju sterowania? Co zaleciłbyś zatroskanemu ojcu, który napisał do działu porad amerykańskiego magazynu przytoczony niżej list?
„Jestem amerykańskim patriotą. Mam małego synka i żywię nadzieję, że kiedy dorośnie wstąpi do wojska, do któregoś z rodzajów broni. Aby tego dopiąć, wpadłem na pomysł, że będę mówił do niego, gdy śpi - nie żadne wielkie przemówienie, lecz trochę patriotyzmu i sugestia, że kariera wojskowa byłaby dobra. Czy tego typu sugestia może pomóc czy też spowoduje, że syn zbuntuje się przeciw niej?”
(McCall’s, listopad 1969, s. 65)


Czyż nie oczekujemy, że dzieci będą sterowane przez rodziców, jak również
przez nauczycieli, duchownych, policję i lekarzy? Kiedy to sterowanie jest czymś dobrym, a kiedy złym? Z każdą próbą sterowania zachowaniem innych ludzi wiążą się poważne problemy natury etycznej - bez względu na to, czy dzieje się to w laboratorium psychologicznym, w trakcie psychoterapii, czy też w sytuacjach codziennych, w których inni ludzie sterują nami lub my sterujemy nimi.


Zbliżenie
Sterowanie zachowaniem


„Narzędzia psychologii, podobnie jak wszelkie inne narzędzia, mogą służyć dobru lub złu - mogą dopomagać w osiągnięciu naszych celów, zaspokajaniu potrzeb, a mogą też poniżać godność człowieka. Sterowanie naszymi ruchami przez inne osoby w wielu codziennych sytuacjach jest niezbędne, nie zagrażające i akceptowane przez wszystkich, jak na przykład kierowanie ruchem ulicznym przez policjanta lub przez sygnalizację świetlną. Z drugiej strony, idea elektronicznego sterowania przez komputer za pomocą elektrod implantowanych w mózgu wydaje się przerażającą perspektywą. 
Jednakże techniki takie umożliwiają małpie podniesienie sparaliżowanej skądinąd łapy; tak więc stwarzają ogromne możliwości, jeśli chodzi o przywracanie ludziom z kalectwem fizycznym władzy nad funkcjami ich ciała - na przykłąd niewidomi mogliby „widzieć” za pośrednictwem sygnałów elektronicznych.
Sterowanie ma także swe humorystyczne aspekty, o czym świadczy zamieszczony wcześniej żart rysunkowy (ryc. 1.9).
* * *
Ryc. 1.9. Jeden szczur do drugiego: „Stary, naprawdę uwarunkowaliśmy już tego faceta. Ilekroć nacisnę dźwignię, on wrzuca tu porcję żarcia”.

* * *

Najpotężniejszy nawet dyktator jest zależny od swych poddanych w tym sensie, że może utrzymać swą władzę tylko tak długo, jak długo potrafi uzyskać od nich potrzebne mu reakcje; podobnie sterowanie w laboratorium jest w gruncie rzeczy relacją wzajemną, w której psycholog i osobnik badany „sterują” sobą nawzajem.
Znany fizyk, Robert Oppenheimer, powiedział w swym przemówieniu na zjeździe Amerykańskiego Towarzystwa Psychologicznego:
„(...) psychologowi trudno jest zrobić cokolwiek nie uświadamiając sobie, że zdobywanie wiedzy otwiera przed nim najbardziej przerażające perspektywy sterowania tym, co ludzie robią, jak myślą, jak się zachowują i co czują.  Dotyczy to tych wszystkich spośród was, którzy zajmują się praktyką; mogę sądzić, że w miarę jak psychologowie będą nabywać pewności siebie, przenikliwości i umiejętności, to apele fizyków, aby ich odkrycia były wykorzystywane humanitarnie i mądrze, będą wydawać się raczej mało ważne w porównaniu z tymi apelami, które wy będziecie musieli ogłaszać i za które będziecie musieli być odpowiedzialni” (1956, s. 128).


Podnoszenie jakości życia przez zmienianie tego, co się dzieje


Bezstronność i obiektywizm są niezbędne przy zbieraniu i interpretowaniu danych. Jednakże reguły metody naukowej mówią ci tylko to, jak uzyskać materiał dowodowy, do którego możesz mieć zaufanie. Nie powiedzą ci, jakiego materiału dowodowego szukać, ani jak spożytkować uzyskaną wiedzę i skonstruowane narzędzia. Wobec tego psychologowie, w miarę jak ich wiedza rozwija się, a narzędzia stają się doskonalsze, w coraz większym stopniu przyjmują na siebie odpowiedzialność za dopilnowanie, aby narzędzia te były używane dla wzbogacania ludzkiego życia, a nie pogarszania go.
Do niedawna reprezentanci psychologii akademickiej nie byli skorzy do zajmowania się wartościami, po części w wyniku przekonania, że nie byłoby to „obiektywne” ani „naukowe”, a po części z poczucia skromności - z niepewności, czy psychologia jest naprawdę gotowa, by wnieść swój wkład w ogólnospołeczne dobro. Chociaż bowiem „psychologia ma długą przeszłość, ma ona krótką historię”. Pierwsze prawdziwe naukowe laboratorium eksperymentalne założył sto lat temu - w 1879 roku - Wilhelm Wundt w Lipsku, w Niemczech. Wiele najbardziej fascynujących i najistotniejszych dziedzin badań w psychologii pojawiło się dopiero w ostatnich dziesięciu czy dwudziestu latach. „Nauka ostrożnie idzie naprzód” - oto ostrzeżenie tych, którzy głoszą, że psychologowie muszą wiedzieć więcej, znacznie więcej, zanim będą tak pewni siebie, aby próbować sformułować rozwiązanie problemów społecznych.
„Gotowi, czy nie, przystępujcie do działania!” brzmią okrzyki z różnych stron. Naglące potrzeby społeczne i jednostkowe dnia dzisiejszego nie mogą czekać do jutra. George Miller w swym wystąpieniu z okazji objęcia stanowiska przewodniczącego Amerykańskiego Towarzystwa Psychologicznego stwierdził, że psychologowie nie tylko powinni być dobrymi naukowcami, lecz także muszą zabiegać o podniesienie jakości ludzkiego życia. W swym „rewolucyjnym” przemówieniu Miller (1969) stwierdził:
„(...) Zmienianie zachowania jest bezsensowne, gdy brak jakiegoś logicznego planu, jak powinno się je zmieniać. Społeczeństwo chce wiedzieć, jaki jest nasz plan stosowania metod sterowania zachowaniem. Zbyt często, obawiam się, psychologowie zakładają, że możliwe do zaakceptowania sposoby wykorzystywania tych metod są albo oczywiste, albo można je spokojnie pozostawić mądrości i dobrej woli ludzi będących u władzy. Psychologowie nie powinni tak łatwo zrzekać się funkcji planowania (...). Wkład, jaki musi wnieść psychologia w diagnozę osobistych i społecznych problemów powinien być co najmniej taki sam, a może i większy, jak jej wkład w sterowanie zachowaniem (...).
(...) Chciałbym spróbować wykazać, że zrozumienie i przewidywanie są lepszymi celami dla psychologii niż sterowanie - lepszymi zarówno dla psychologii, jak i ze względu na poprawienie losu ludzi - ponieważ skłaniają nas one do myślenia nie w kategoriach przymusu ze strony elity władzy, lecz w kategoriach diagnozy problemów i opracowywania programów, które mogą wzbogacić życie każdego obywatela (...).
(...) prowadźmy zatem dalej naszą walkę o rozwój psychologii jako środka do poprawienia losu ludzi, każdy na swój własny sposób. Jeśli jednak chodzi o mnie, to nie potrafię sobie wyobrazić niczego, co moglibyśmy uczynić, a co miałoby większe znaczenie dla pomyślności ludzi i stanowiłoby większe zadanie dla następnej generacji psychologów niż odkrycie, w jaki sposób najlepiej „sprzedać” psychologię (ss. 1068-74).


Badanie naukowe i metoda eksperymentalna


Naukowe badanie, jeśli się je obedrze ze wszystkich jego uroków, nie jest niczym innym, jak sposobem pozwalającym ograniczyć fałszywe wnioskowanie o zjawiskach natury. Ten pozornie prosty cel jest niezmiernie trudny do osiągnięcia. Wymaga to szczególnej konstelacji postaw badacza, a także stosowania wyraźnie określonych procedur formułowania, sprawdzania i oceniania twierdzeń, które mają stać się wnioskami ogólnymi. Te postawy, nastawienia i procedury razem wzięte są tym, co określa się jako |metodę |naukową.


Zbliżenie
Prawda dzięki wierze czy zmysłom?


„Chociaż większość ludzi uznaje obecnie doświadczenie zmysłowe za właściwą podstawę zdobywania wiedzy o przyrodzie, to jednak nie zawsze tak było. Prawda została objawiona przez Boga w Piśmie Świętym - na tym dogmacie wiary wielu ludzi opierało swoje poglądy na wszechświat. Proces Galileusza przypomina o czasach, gdy panowała ta filozofia. Dane, zebrane przez Galileusza w wyniku dokładnych obserwacji, musiały być odrzucone, ponieważ potwierdzały heliocentryczną teorię Kopernika (według której Słońce stanowi centrum wszechświata). W tym czasie Kościół głosił, że wszechświat jest geocentryczny - centralnym punktem jest człowiek i jego Ziemia. W roku 1615 Kościół oskarżył Galileusza o głoszenie heretyckich poglądów, a gdy ten nie zaprzestał swej działalności, został w 1633 roku postawiony przed sądem. Wyrok sądu oraz uroczyste wyrzeczenie się „błędów” przez Galileusza stanowią dla nas cenną lekcję, która nie wymaga dalszych komentarzy.

‘ty
Wyrok Trybunału Najwyższej Inwkizycji przeciw Galileo Galilei wydany 22  dnia czerwca roku 1633


„Jest prawdą, że ty, Galileo, syn zmarłego Vincenzio Galilei i Florentyny, mającej obecnie lat siedemdziesiąt, zostałeś oskarżony w tym Świętym Officium w 1615 roku:
Że uznajesz za prawdziwą fałszywą doktrynę głoszoną przez człowieka, iż Słońce stanowi centrum wszechświata i jest nieruchome, i że Ziemia porusza się i ma także ruch dzienny; że w tej samej sprawie prowadziłeś korespondencję z pewnymi matematykami niemieckimi; że spowodowałeś wydrukowanie pewnych listów zatytułowanych „Istoria e dimostrazioni intorno alle macchie solari” („O plamach na Słońcu...”), w których dowodziłeś, iż rzeczona doktryna jest prawdziwa (...).
Ten Święty Trybunał pragnąc zapobiec zamieszaniu i szkodom, które stąd wynikły i które stale rosły z uszczerbkiem dla wiary Świętej, z polecenia naszego Pana (Papieża) i najdostojniejszych Panów Kardynałów tej najwyższej i powszechnej Inkwizycji, te dwa twierdzenia o nieruchomości Słońca i ruchu Ziemi osądził przez kwalifikowanych teologów jak następuje:
Że Słońce jest środkiem wszechświata i nie porusza się ze swego miejsca jest twierdzeniem absurdalnym, fałszywym filozoficznie i formalnie heretyckim, będącym w wyraźnej sprzeczności z Pismem Świętym; że Ziemia nie jest środkiem wszechświata ani że nie jest nieruchoma, lecz się porusza, nawet ruchem dziennym, podobnie jest twierdzeniem absurdalnym i fałszywym filozoficznie - uważanym w teologii za szkodliwy błąd w wierze.
My stwierdzamy, orzekamy, wyrokujemy i ogłaszamy, że ty rzeczony Galileo, w wyniku spraw dowiedzionych w trakcie tego procesu i wyznanych przez ciebie jak wyżej, stałeś się silnie podejrzany o herezję przez to Święte Officium, to jest o uznawanie i wyznawanie doktryny, która jest fałszywa i sprzeczna z Pismem Świętym, z rozumem: że Słońce jest środkiem wszechświata i że nie porusza się ono ze wschodu na zachód, i że Ziemia porusza się i nie jest środkiem wszechświata, i że pogląd ten można uznawać i bronić go jako prawdopodobny, po określeniu go i ogłoszeniu za sprzeczny z Pismem Świętym; i w następstwie naraziłeś się na wszelkie nagany i kary przewidziane w Świętych Kanonach i innych Dekretach, zarówno ogólnych, jak i szczegółowych, przeciw takim winowajcom wydanych i ogłoszonych”.

Uroczyste wyrzeczenie się błędów przez Galileusza

„Ja, Galileo Galilei, (...) po otrzymaniu napomnienia od tego Świętego Officium, aby wyrzec się całkowicie fałszywej doktryny, że Słońce jest środkiem wszechświata i jest nieruchome, i że Ziemia nie jest środkiem tegoż, i że się porusza, i aby nie wyznawać ani bronić, ani nauczać w żaden sposób, ani ustnie ani też pisemnie rzeczonej fałszywej doktryny; i po otrzymaniu orzeczenia, iż rzeczona doktryna jest sprzeczna z Pismem Świętym, napisałem i spowodowałem wydrukowanie książki, w której omawiam rzeczoną, już potępioną doktrynę i wysuwam na jej rzecz argumenty o dużej sile (...).
Ze szczerym sercem i nieudawaną wiarą wyrzekam się, przeklinam i nienawidzę rzeczonych błędów i herezji, i w ogóle wszystkich błędów i sekt przeciwstawiających się Świętemu Kościołowi Katolickiemu. I przysięgam, że w przyszłości nie wypowiem ani nie stwierdzę, w mowie ani w piśmie, takich rzeczy, które mogą narazić mnie na podobne podejrzenie (...)”


Badanie naukowe składa się z czterech głównych etapów: znalezienia godnej uwagi idei, sprawdzenia jej, wyciągnięcia wniosków oraz opisania tego, co stwierdzono, w taki sposób, aby inny badacz mógł |powtórzyć to badanie w celu zweryfikowania lub podważenia jego wyników. Każdy badacz może więc budować na tym, co wnieśli inni i udostępniać nowe stwierdzenie jako punkt wyjścia dla następnych badaczy.
Nie ma wytycznych wskazujących, jak znaleźć dobre idee - jest to twórczy aspekt nauki, element sztuki w tym procesie. To zależy od wiedzy naukowca, jego zdolności twórczych, zdolności analizowania i syntetyzowania, a niekiedy - jak się przekonamy - również od czystego przypadku. Lecz nawet wtedy, gdy dużą rolę w odkryciu odgrywa szczęście lub przypadek (np.  odkrycie przez Fleminga penicyliny dzięki zaobserwowaniu pleśni na chlebie lub odkrycie Pawłowa zjawiska warunkowania klasycznego na podstawie obserwacji psów śliniących się na widok pokarmu), „przypadek sprzyja tylko umysłowi przygotowanemu”, jak stwierdził Ludwik Pasteur.
Idee formułowane w postaci sprawdzalnych hipotez pochodzące z wielu źródeł, takich jak: a) wnioski wyprowadzone z teorii, b) niezgodne ze sobą obserwacje lub wnioski, c) zagadkowe zjawisko, które podważa tradycyjny sposób myślenia, d) potrzeba zmiany pewnych warunków życia (infekcja, lęk, skażenie środowiska), e) przypadkowe zdarzenia lub obserwacje, zwane szczęśliwym trafem, f) intensywna analiza doświadczeń i zachowania. Nic nie może zastąpić wrażliwości psychologa na zmiany ludzkiego zachowania, konieczności obserwacji ludzi, rygorystycznej autoanalizy i troski o polepszenie losu ludzkiego.


Podstawowe zasady zbierania danych

Gdy już wiesz, co chcesz badać, musisz zdecydować, jak zdefiniować i mierzyć te rzeczy, których zależności chcesz ustalić. Gdybyś na przykład chciał zbadać związek między podlizywaniem a powodzeniem w szkole, potrzebne były by ci miary jednego i drugiego. Dla „powodzenia w szkole” użyłbyś prawdopodobnie ocen, chociaż mógłbyś się posłużyć również innymi miarami.

* * *

Ryc. 1.10. Stosunek sygnału do szumu jest podobny do relacji między figurą a tłem. Jasna figura odcina się wyraźnie od szarego tła, lecz im bardziej ustrukturalizowane i różnorodne staje się tło, tym trudniej jest rozpoznać zarysy figury i odróżnić ją wyraźnie od tła.
Zmienne stanowiące przedmiot badań psychologicznych są podobne do figur na obrazkach. Często, zwłaszcza w „życiu realnym”, nie wyodrębniają się one na tyle wyraźnie z kontekstu, w którym obserwujemy ich działanie, abyśmy mogli zidentyfikować je i zmierzyć. Badając je w laboratorium, zyskujemy tę korzyść, że eliminujemy „szum” tła, lecz ponosimy również stratę: musimy tworzyć „figurę” sztucznie, co może spowodować, że będzie ona niedokładną lub niepełną reprezentacją tej zmiennej, która występuje w naturalny sposób poza laboratorium.

* * *

Dla „podlizywania się” mógłbyś zastosować jako miarę, „liczbę minut w ciągu dnia poświęconych na pomaganie nauczycielowi”.
Szukając zależności między tymi dwoma zjawiskami będziesz wypatrywać dwóch sygnałów (lizusostwo i powodzenie w szkole) na tle |szumu, czyli wszystkich innych rzeczy jakie zdarzają się w tym samym czasie. W twoim badaniu będą dwa szczególnie kłopotliwe źródła zakłóceń - warunki czy zjawiska, które zagłuszają prawdziwy sygnał zwiększając szum oraz warunki lub zjawiska wywołujące złudzenie, że występuje prawdziwy sygnał, podczas gdy w rzeczywistości obecny jest tylko szum. Na przykład, gdyby wszyscy uczniowie często współpracowali aktywnie z nauczycielem, to byłoby trudno odróżnić sygnał „podlizywania się” od szumu w postaci wszystkich innych rodzajów kontaktu, jakie się zdarzają (ryc. 1.10). Dobrym przykładem wykrywania nieistniejącego sygnału była słynna sprawa Mądrego Hansa.

Zbliżenie
Koński rozum (czyli, jak Mądry Hans wystukał sobie pozycję gwiazdora)


„Jak to było możliwe, że koń, zwany Mądrym Hansem, potrafił oszukać nie tylko swego trenera, lecz także szacowną, stosującą naukowe podejście Komisję Badawczą w Berlinie, której członkowie przyszli nastawieni sceptycznie do jego mądrości, a wyszli przekonani, że jest to koń niepodobny do innych? Wydawało się, że Hans ma doskonałą pamięć, że potrafi czytać, literować słowa, rozumieć złożone pytania, liczyć i wykonywać działania matematyczne. Badacze starannie obserwowali wyczyny konia, lecz nie potrafili znaleźć żadnego rozmyślnego oszustwa, ponieważ koń wykonywał swoje sztuki równie dobrze w ich obecności, jak i swego trenera. Doszli oni do wniosku, że koń potrafi rozumować i myśleć przynajmniej tak dobrze, jak większość ludzi. Czy po przeczytaniu, czego Hans potrafił dokonać, będziesz umiał wykryć, w jaki sposób to robił i zalecisz niezbędne środki kontroli, które pozwoliłyby Komisji skorygować jej obserwacje?
„(...) To okazałe zwierzę, rosyjski kłusak, stał jak grzeczny uczeń; kierowano nim nie za pomocą bata, lecz łagodnej zachęty i częstych nagród w postaci chleba lub marchwi. Odpowiadał on poprawnie na prawie wszystkie pytania, które zadawano mu po niemiecku. Jeśli zrozumiał pytanie, niezwłocznie dawał o tym znać skinieniem głowy, jeśli nie udało mu się uchwycić jego sensu - informował o tym fakcie potrząsając głową.  Powiedziano nam, że pytający musi ograniczyć się do pewnego słownictwa, lecz było ono stosunkowo bogate i koń rozszerzał jego zakres codziennie, bez specjalnego nauczania, lecz po prostu dzięki kontaktowi ze swym otoczeniem (...).
Nasz inteligentny koń nie potrafił oczywiście mówić - jego podstawowym sposobem porozumiewania się było stukanie prawą przednią nogą. Wiele wyrażał także ruchami głowy: „tak” wyrażał skinieniem, „nie” - powolnym ruchem w jedną i drugą stronę, a „w górę”, „wyżej”, „na dół”, „na prawo”, „na lewo” wskazywał zwracając głowę w tych kierunkach (...).
Przejdźmy teraz do opisu niektórych szczególnych jego umiejętności. 
Najwyraźniej opanował on całkowicie liczebniki główne od 1 do 100 i 
liczebniki porządkowe co najmniej do 10. Na żądanie liczył on przedmioty 
wszelkiego rodzaju, obecne osoby, nawet z rozróżnieniem płci. Następnie 
kapelusze, parasolki i okulary (...). Małe liczby podawał stukając powoli 
prawą nogą. Przy większych liczbach zwiększał szybkość, a często stukał 
bardzo szybko od samego początku (...). Po ostatnim stuknięciu jego prawa 
noga - którą posługiwał się przy liczeniu - powracała do pierwotnej pozycji 
(...).

Lecz Hans potrafił nie tylko liczyć, potrafił on także rozwiązywać zadania arytmetyczne. Doskonale znał cztery podstawowe działania. Ułamki zwykle zamieniał na dziesiętne i na odwrót (...).
Ponadto Hans potrafił z łatwością czytać słowa w języku niemieckim, czy to pisane czy drukowane.
(...) jeśli przed koniem umieszczono szereg arkuszy z napisanymi na nich słowami, potrafił podejść i pokazać nosem każde ze słów, jakiego od niego żądano. Potrafił nawet przeliterować niektóre z tych słów. Dokonywał tego za pomocą tablicy opracowanej przez pana von Osten; każda litera alfabetu, jak również szereg dwugłosek, miała tam swoje miejsce, które koń mógł określić za pośrednictwem pary liczb (...)” („Pfungs”, 1911, ss.18-24).
Działo się to na jakiś czas przedtem, zanim Komisja stwierdziła, że Hans nie potrafi rozwiązywać żadnych zadań, jeśli ma założone „końskie okulary”, jeśli trener stoi za nim lub jeśli osoba, która postawiła pytanie, sama nie zna odpowiedzi. Te |środki |kontroli, zastosowane prze obserwacji zachowania Hansa, ujawniły natychmiast, że Hans reagował jedynie na subtelne, niezamierzone sygnały wzrokowe dostarczane przez pytającego, które informowały go, kiedy powinien zacząć stukać, a kiedy powinien przestać. Hans nauczył się robić to, co świadomie robią „czytając w myślach” artyści estradowi.
Dzięki przypadkom tego rodzaju, jak opisany powyżej, uczony dowiaduje się, że „to, co widzi” jest tylko jednym ze źródeł danych o rzeczywistości.  Trzeba je sprawdzić przez porównanie z różnymi innymi obserwacjami tego samego zjawiska. Jak przekonasz dziecko, że Ziemia nie jest płaska lub że Słońce nie wędruje po niebie ze wschodu na zachód?”


Gdy już zdefiniowałeś te rzeczy, których związek zamierzasz badać, to następnym krokiem powinno być sformułowanie sprawdzalnej hipotezy - na przykład, że uczniowie, którzy poświęcają więcej niż X czasu dziennie na podlizywanie się otrzymują lepsze stopnie niż uczniowie, którzy tego nie czynią. W rzeczywistości, dla większej wygody w późniejszym stosowaniu testów statystycznych, hipotezę formułuje się zwykle w postaci negatywnej - jako tak zwaną |hipotezę |zerową - w tym wypadku stwierdzałaby ona, że podlizywanie się |nie jest związane z wysokością ocen. Jednakże materiał dowodowy, jaki będziesz zbierać, jest taki sam.
Kiedy badasz wpływ pewnego warunku bodźcowego (S) na reakcję ®, ten pierwszy jest zwany |zmienną |niezależną, a ta druga, która podlega wpływowi, nosi nazwę |zmiennej |zależnej. Zmienną niezależną albo się manipuluje (np. mógłbyś systematycznie aranżować sytuację w taki sposób, aby różni uczniowie spędzili różną ilość czasu na podlizywaniu się), albo mierzy się ją taką, jaka występuje w sytuacjach naturalnych, a następnie używa się jej jako predyktora zmiennej zależnej. Powodzenie w szkole jest w tym przykładzie zmienną zależną, tą, której zmiany będą twoim zdaniem |zależne od zmian w podlizywaniu.
Jeśli jesteś w tym szczęśliwym położeniu, że możesz manipulować zmienną niezależną, to zastosujesz |metodę |eksperymentalną, która daje ci znacznie lepszą sposobność do znalezienia zależności przyczynowych. Utrzymując stałe wartości wszystkich innych zmiennych, które mogłyby wpływać na zachowanie, a następnie zmieniając systematycznie zmienną niezależną, możesz stwierdzić, które jej aspekty są konieczne i wystarczające dla wystąpienia określonej formy zmiennej zależnej (reakcji) w danym zbiorze warunków.  („Zmienianie zmiennej niezależnej” mogłoby oznaczać albo poddanie jednej grupy badanych jej wpływowi, a drugiej nie, albo porównywanie wpływu różnych wartości zmiennej niezależnej).
Zasadnicze elementy typowego eksperymentu psychologicznego to: losowe przydzielanie badanych do różnych grup, manipulowanie jedną lub wieloma zmiennymi niezależnymi oraz dokładne mierzenie reakcji. Aby sprawdzić swoją hipotezę o wpływie podlizywania się, mógłbyś losowo przydzielić niektórych uczniów do grupy, „eksperymentalnej”, w której otrzymaliby polecenie, aby podlizywać się tyle a tyle minut dziennie, a innych uczniów do „grupy kontrolnej”, gdzie nie dostaliby żadnych specjalnych poleceń, a prawdopodobnie nie wiedzieliby nawet, że są w jednej z twoich grup.
Uczniów powinieneś przydzielić do każdej grup losowo, abyś był pewien, że obie grupy na początku eksperymentu były podobne. Gdyby w jednej z grup było więcej uczniów zdolnych, wymownych lub już wcześniej lubianych przez nauczyciela, to nie mógłbyś być pewny, że późniejsze różnice między grupami (pod względem ocen) są spowodowane samym tylko podlizywaniem się.
Gdybyś nie mógł manipulować naturalnym zachowaniem w taki sposób, aby skłonić jedną grupę do podlizywania się, to musiałbyś zidentyfikować pewną liczbę naturalnych lizusów, dobrać inną grupę uczniów, którzy by nie byli lizusami, lecz poza tym byliby zrównani (matched) z nimi pod możliwie wieloma względami, a następnie porównać wyniki obu grup określone za pomocą twojej miary powodzenia w szkole.
Musiłabyś także starać się uzyskać największą pewność, że wszystkie inne czynniki, które mogłyby oddziaływać na stopnie, były stałe (oddziaływały w podobny sposób na obie grupy) w okresie obserwacji. Kontrola wszystkich warunków, które mogłyby przeszkodzić w wyraźnym, jednoznacznym sprawdzeniu hipotezy jest najistotniejszą cechą eksperymentu.
Te i inne środki kontroli zostaną przedstawione dokładniej w dalszych rozdziałach tej książki, gdy będziemy analizować poszczególne eksperymenty.  Niestety, zmiennych wpływających na zachowanie organizmów nie da się łatwo rozdzielić dla celów analizy. Główny zarzut, jaki wysuwa się przeciw większości eksperymentów, dotyczy nieprowadzenia grupy kontrolnej, czyli procedury, która jest logicznie niezbędna w celu wykluczenia alternatywnej hipotezy.

Zbliżenie
Typowy plan eksperymentu


„Z tej samej populacji wybiera się losowo dwie grupy. Z obydwiema przeprowadza się taki sam pretest i posttest, w czasie których wszystkie istotne zmienne (instrukcje, warunki fizyczne w pomieszczeniu, czas na wykonanie zadań itd.) są takie same dla obu grup. Jedyną różnicą (wiadomą badaczowi) między tymi grupami, jaka występuje w okresie między pretestem a posttestem, jest różnica w postaci manipulacji eksperymentalnej. Zmiany w wynikach uczenia się w każdej z grup określa się odejmując wyniki pretestu od wyników posttestu. Jeśli w grupie eksperymentalnej wystąpiły większe zmiany niż w grupie kontrolnej, to różnicę tę przypisuje się manipulacji eksperymentalnej. Czy wiesz, co tu jest zmienną niezależną, a co zmienną zależną?

* * *
Ryc. 1.11. Populacja
Studenci I r. uczelni X
1. grupa kontrolna:
uczenie się fragmentu A - uczenie się fragmentu B - zmiana w grupie 
kontrolnej
2. grupa eksperymentalna:
uczenie się fragmentu A - (witaminy przez miesiąc) - uczenie się 
fragmentu B - zmiana w grupie kontrolnej




Wyciąganie wniosków


„Nic tak nie psuje dobrego wniosku, jak niepożądane dane” - jest to pogląd, który podziela wielu psychologów ze szkoły „psychologii babcinej”.  Psychologia ta reprezentuje mądrość zdrowego rozsądku, intuicję oraz skłonność do decydowania, co jest słuszne, przed poznaniem wszystkich (a czasami jakichkolwiek) faktów. Zastanów się, jakiego rodzaju danych potrzebowałbyś, aby przekonać swoją babcię, że twoja sympatia, którą ona uważa za nie dość dobrą dla Ciebie, jest w istocie wystarczająco dobra.
No cóż, niekiedy naukowcy są równie mocno zainteresowani wykazaniem, że mają słuszność, jak rodzice, prawnicy czy politycy. Jednakże badacze są nieco bardziej skrupulatni w swych dążeniach, aby pozwolić danym rozstrzygać; aby wnioski następowały po danych, a nie uprzedzały ich.
Bez sformalizowanej i standartowej procedury wyciągania wniosków na podstawie danego zbioru nie mogłoby być żadnego obiektywnego i bezstronnego sposobu ustalania, kiedy wynik jest „istotny” lub różnica rzeczywiście udowodniona.
Przyjmijmy, że dane były zbierane właściwie i że wystąpiła różnica między wynikami grupy eksperymentalnej i grupy kontrolnej. Czy możemy wyciągnąć wniosek, że zmienna niezależna jest odpowiedzialna za tę różnicę, a więc, że hipoteza eksperymentalna uzyskała poparcie? Włożywszy w badania tyle czasu, energii, inteligencji i pieniędzy nasz obiektywny naukowiec mógłby być skłonny do uznania każdej różnicy za „rzeczywistą”, choćby była ona przypadkowa czy nieznaczna. Przed pokusą taką chroni przyjęcie zawczasu pewnej konwencji, uznawanej przez wszystkich psychologów, która określa, co uważa się za |różnicę |istotną.
Jak pamiętamy, eksperyment zaczyna się od sformułowania |hipotezy |zerowej - głoszącej, że po manipulacji eksperymentalnej nie będzie żadnej różnicy między obydwoma grupami. Jeśli jednak stwierdziłeś jakąś różnicę, to chciałbyś wiedzieć, czy jest ona dostatecznie duża, aby uznać ją za różnicę rzeczywistą, czy też mogła wystąpić przypadkowo. Jeśli można ją przypisać przypadkowi, to nie możesz wyciągać żadnych wniosków co do związku między twoimi zmiennymi. Tylko wtedy, gdy różnica ta jest dostatecznie duża, możesz odrzucić hipotezę zerową i wyciągnąć wniosek, że różnica jest rzeczywista (np. w naszym wcześniejszym przykładzie - że prawdopodobnie istnieje związek między podlizywaniem się a powodzeniem w szkole).
Stosuje się różne testy statystyczne, zależnie od charakteru zebranych danych, lecz wszystkie one dają w końcu to samo - |ocenę |prawdopodobieństwa, że różnica jest wynikiem przypadku. Ta ocena prawdopodobieństwa jest właśnie tym, co pozwala psychologom przyjąć wspólną regułę rozstrzygającą, kiedy eksperyment „wyszedł”. Różnicę uznaje się za rzeczywistą i określa jako „istotną statystycznie” tylko wtedy, gdy prawdopodobieństwo (p), że różnica ta mogła wystąpić przypadkowo, jest mniejsze niż pięć setnych (stwierdzenie „prawdopodobieństwo jest mniejsze niż 5 procent” zapisuje się następująco: p < 0,05). Jest to „łagodniejszy” dopuszczalny poziom istotności - nie do przyjęcia w przypadku niektórych problemów. Surowsze wymagania stawia się wtedy, gdy następstwa wyciągnięcia fałszywego wniosku są poważniejsze. Na przykład w przypadku przewidywania samobójstwa badacz mógłby wymagać poziomu istotności 0,01 0,001 lub jeszcze wyższego.
Te i inne techniki statystyczne pozwalające określić stopień zaufania, jaki można mieć do uzyskanych wyników, są opisane w „Dodatku”. Istnieją także techniki pozwalające ustalić, w jakim stopniu możesz uogólnić swoje stwierdzenie, dotyczące określonej próbki badanych, na innych osobników należących do tej samej ogólnej kategorii. Musisz wiedzieć, jak dalece reprezentatywna jest twoja próbka dla większej grupy, zanim będziesz mógł uogólnić swoje stwierdzenia na tę grupę jako całość.

Zbliżenie
Średnia, zmienność i korelacja


Przy omawianiu wyników badań używamy niekiedy terminów |średnia, |zmienność i |korelacja. Obecnie przedstawimy pokrótce ich znaczenie.  Pełniejsze wyjaśnienie terminów statystycznych i zasad wnioskowania statystycznego można znaleźć w „Dodatku”.
1. Aby opisać wyniki pewnej grupy (i móc porównać je z wynikami innej grupy) potrzebujesz dwóch rzeczy: pojedynczej liczby dostatecznie |typowej, aby reprezentowała cały zbiór wyników oraz liczby, która informuje, jak dalece wyniki te różnią się między sobą, tj. jak duża jest ich |zmienność.
a. Najbardziej typową liczbą jest |miara |tendencji |centralnej, czyli |przeciętna. Najczęściej stosowane są trzy rodzaje tej miary, a mianowicie, |średnia |arytmetyczna (suma wyników podzielona przez liczbę wyników, oznaczona symbolem M lub X), |mediana (środkowy wynik, gdy wszystkie wyniki uporządkuje się według ich wartości liczbowej) oraz |modalna (wynik najczęściej występujący).
b. Miary zmienności informują nas, czy wyniki są ciasno skupione, czy też ich rozrzut jest znaczny. Najczęściej używane miary zmienności to |obszar |zmienności (od najniższego do najwyższego) oraz |odchylenie |standardowe, miara przeciętnego oddalenia poszczególnych wyników od średniej w danej grupie. Im większe odchylenie standardowe, tym bardziej wyniki odbiegają od wyniku średniego.
2. Aby opisać zależności między dwoma zbiorami wyników dla tych samych osób (np. ilorazy inteligencji i stopnie szkolne), należy posłużyć się wzorem pozwalającym obliczyć |współczynnik |korelacji ®. Statystyka ta informuje o tym, czy związek jest pozytywny czy negatywny, a także o tym, czy jest on silny czy słaby.
Współczynniki korelacji wahają się od - 1,0, co oznacza całkowitą |ujemną korelację (im wyższa inteligencja, tym gorsze stopnie), poprzez 0, co oznacza brak jakiejkolwiek korelacji, do +1,0, co oznacza całkowitą |dodatnią korelację (im wyższa inteligencja, tym lepsze stopnie). Całkowitą korelację stwierdza się rzadko. Można przyjąć, że „umiarkowana” korelacja (dodatnia lub ujemna) wynosi od 0,25 do 0,60, a „wysoka” korelacja od 0,60 do 0,99.


Dwa dalsze ostrzeżenia przydadzą się jeszcze w tym krótkim i z konieczności uproszczonym opisie stosowania metody eksperymentalnej i wyciągania trafnych wniosków z danych. Przypuśćmy, że stwierdziłeś istotną statystycznie różnicę i odrzuciłeś hipotezę zerową, wyciągając wniosek, że zastosowana przez ciebie manipulacja zmienną niezależną rzeczywiście zmieniła dane zachowanie. Nie masz jednak podstaw, by powiedzieć, że zmienna niezależna powoduje to zachowanie, lecz jedynie, że zmiany zmiennej niezależnej powodują zmiany w zachowaniu. Nie możesz również powiedzieć, że zmienna niezależna jest jedynym czynnikiem wpływającym na zachowanie (czy jedyną jego przyczyną), lecz jedynie, że to, co stwierdziłeś, jest prawdą wtedy, gdy wszystkie inne istotne zmienne, które mogłyby wpływać na to zachowanie, są utrzymane na pewnym stałym poziomie. Gdyby były one na innych poziomach, to zastosowane przez ciebie zmiany zmiennej niezależnej mogłyby mieć odmienne skutki. Gdybyś zaś twoją zmienną niezależną utrzymywał na stałym poziomie, a manipulował którąś z innych zmiennych, to mógłbyś stwierdzić równie silny związek między tą nową zmienną niezależną a zmienną zależną.
Jeśli na przykład uczysz jakieś zwierzę wykonywania określonej reakcji, to możesz stwierdzić, że nagroda w postaci pewnego rodzaju pokarmu znacznie skuteczniej skłania zwierzę do wykonywania tej reakcji niż inny rodzaj pożywienia, jeśli poziom głodu przy wypróbowaniu różnych rodzajów pożywienia jest podobny. Gdybyś jednak podawał te same rodzaje pokarmu zwierzęciu, które w ogóle nie jest głodne, to mógłbyś uzyskać zupełnie inne rezultaty. Gdybyś zaś zastosował jako nagrodę tylko jeden rodzaj pokarmu i zmieniał stopień wygłodzenia zwierzęcia, to prawdopodobnie doszedłbyś do wniosku, że poziom głodu jest ważną zmienną wpływającą na szybkość, z jaką zwierzę uczy się tej reakcji.
Oto inny przykład ukazujący, w jaki sposób postawione przez ciebie pytanie decyduje o tym, jakiego rodzaju odpowiedź otrzymasz. Psycholog prowadzący badania nad uczeniem się i działaniem nagród utrzymuje motywację na stałym poziomie i skupia uwagę na różnych formach nagród, wszystkie wnioski dotyczą więc wpływu nagród na uczenie się. Psycholog badający motywację stosuje stałą nagrodę, natomiast zmienia motywację; w tym przypadku wnioski dotyczą różnych stanów motywacyjnych i ich wpływu na zachowanie. Podobnie psycholog badający osobowość utrzymuje czynniki sytuacyjne bez zmiany; psycholog badający wpływ czynników sytuacyjnych dba o to, aby cechy osobowości były stałe. W związku z tym dojdą oni do różnych wniosków.
Ta starannie opracowana procedura zbierania danych i wnioskowania jest tym, co odróżnia wnioski naukowe od wniosków, jakie wyciągają filozofowie, teologowie i dziennikarze, a także my wszyscy w naszym życiu codziennym, gdy usiłujemy ustalić, co jest, czego nie ma, w co powinniśmy wierzyć i co popierać. Niestety nie wszystkie wnioski, które - zdaniem innych - powinniśmy uznać, są tak dobrze uzasadnione; w gruncie rzeczy wiele z nich - między innymi i takie, które rzekomo są oparte na „faktach naukowych” - stanowią niebezpieczne psychologiczne pułapki.

Pułapki psychologiczne

Jeśli wydaje ci się, że łatwo jest „zbierać tylko obiektywne informacje i wyciągać wnioski zgodnie z ustalonymi zawczasu regułami”, to zapoznaj się z następującymi przykładami pułapek, w które codziennie zwabia się miliony ludzi.

Co jest prawdą w reklamach?


Ogłoszenia mają wyraźnie na celu manipulowanie nie tylko zachowaniem, lecz i przekonaniami.
Czy ogłoszenia potrafią wywieść w pole?
Jeśli na przykład potrzebujesz pigułki na uśmierzenie zwykłego bólu głowy, na jaki uskarżają się miliony Amerykanów, to czy doszedłbyś do wniosku, że aspiryna Bayera naprawdę jest najlepsza, ponieważ „próby przeprowadzone przez państwo wykazały, że żaden środek przeciwbólowy nie jest silniejszy ani bardziej skuteczny niż aspiryna Bayera”?
Ogłoszenia tego typu nie wspominają, że próby państwowe przeprowadzone pod patronatem Federal Trade Commission (Federalnej Komisji Handlu) i opublikowane w czasopiśmie „Journal of the American Medical Association”, nie wykazały w rzeczywistości |żadnej w ogóle |różnicy między pięcioma badanymi środkami przeciw bólowi głowy ani pod względem szybkości, ani skuteczności usuwania bólu z głowy. To prawda, że żaden z badanych środków nie był bardziej skuteczny niż aspiryna Bayera, ale żaden z tych środków nie był też mniej skuteczny. Dodanie drugiego porównania ukazuje ten wniosek w zupełnie innym świetle.
A co z twoimi zębami? Powinieneś dowiedzieć się niezwłocznie, że „stwierdzono, iż ludzie, którzy używają regularnie pasty Crest, mają o 38% |mniej ubytków w uzębieniu”. Jest więc rzeczą rozsądną podjąć zalecane działanie i kupić tubkę pasty Crest, czyż nie? Może tak, a może nie.  Należałoby najpierw ustalić: |mniej |niż |kto? Niż ludzie, którzy używają pasty Crest |nieregularnie? Niż dzieci, które |nigdy nie myją zębów? Niż ci, którzy myją zęby, lecz nie kontrolują regularnie ich stanu i nie leczą ich? Niż |szympansy, które regularnie używają pasty Crest?
W telewizji amerykańskiej regularnie ukazywały się ogłoszenia reklamujące „Forda LTD” jako wóz o „cichszej pracy silnika niż silniki w najkosztowniejszych nawet wozach importowanych” (co sugerowało porównanie ze słynnym ze swej cichobieżności Rolls Roycem). Gdy Generalna Komisja Handlu poleciła przeprowadzić niezależną kontrolę zasadności tego i innych twierdzeń podawanych przy reklamowaniu samochodów, wówczas wykryto, iż testy porównawcze wykazały, że nowy Ford pracował ciszej niż Daimler z 1963 roku, z przebiegiem 37225 mil i ciszej niż Jaguar z 1964 roku, stary, ale jary, mający ponad 20000 mil na liczniku („United Press”, 7 października 1972 r.).
|Morał: Całość jest prawdziwsza niż część.

„Radykalizacja” poglądów politycznych ochotników VISTA


(National Vista Alliance (NVA) - organizacja społeczna, założona w roku 1970, której członkowie są ochotnikami - niosą oni pomoc grupom upośledzonym społecznie (przyp. red.).


„Zapoznanie tysięcy młodych Amerykanów z klasy średniej z nędzą przez zwerbowanie ich do akcji VISTA spowodowało silną „radykalizację” mniej więcej trzeciej części i przesunięcie pozostałych w kierunku bardziej lewicowej postawy społecznej i politycznej, co stwierdzono w badaniach finansowanych przez rząd” („The New York Times” Service, 24 maja 1971). 


Zanim wyciągniesz wniosek, że VISTA jest programem indoktrynacji komunistycznej realizowanym za pieniądze podatników, zapytaj o grupę porównawczą. Zmiany, jakie nastąpiły u ochotników VISTA oceniono przez porównanie z grupą ochotników VISTA, którzy „odpadli” - z różnych powodów nie odsłużyli jednego roku, na jaki się zaciągnęli.
W rzeczywistości dane wykazują, że (zgodnie z odpowiedziami badanych) 6% procent tej grupy kontrolnej zmieniło poglądy z „konserwatywnych” lub „umiarkowanych” na „liberalne” lub „radykalnie lewicowe”, podczas gdy odpowiednia liczba dla grupy VISTA wynosiła 17% - tak więc różnica wynosiła tylko 11% i trudno mówić o „silnej radykalizacji trzeciej części grupy”.
|Morał: Porównaj, zanim wyciągniesz wniosek.

Dym w oczy

W jaki sposób się zorientować, kiedy można wierzyć w to, co się czyta w gazetach? Jaki wniosek wyciągnąłbyś na podstawie artykułu relacjonującego wyniki badań przeprowadzonych na University of Illinois, w których wykazano, że palący studenci pierwszego roku uzyskują gorsze stopnie niż niepalący? Jeśli studenci pierwszego roku chcą mieć nadzieję na powodzenie w studiach, to czy muszą rzucić palenie?
Nie musimy tu kwestionować ani danych, ani korelacji między tymi dwoma zbiorami zachowań (paleniem papierosów przez studentów i stopniami, stawianymi tym studentom przez wykładowców). Musimy raczej skupić uwagę na sugerowanym związku przyczynowym. Co do czego prowadzi? Czy oceny będą wyższe, jeśli studenci będą palić mniej? Nastąpi to tylko wówczas, jeśli oba te nazwiska są bezpośrednio związane przyczynowo. Jednakże możemy z łatwością wskazać kilka równie prawdopodobnych sekwencji przyczynowych, które „pasują” do zaobserwowanej zależności. Po pierwsze, być może palenie istotnie jest przyczyną złych stopni. Jeśli tak, to liczba wypalonych papierosów powinna wykazywać ujemną korelację ze średnią oceną, a zmianom intensywności palenia powinny towarzyszyć zmiany wysokości otrzymywanych ocen. Przypuśćmy jednak, że to złe stopnie mogą być przyczyną palenia.  Istotnie, autorka cytowanego artykułu zauważa, „że u studentów mających niskie oceny występuje „pewna reakcja psychologiczna””, która często prowadzi do nerwowych nawyków, takich jak palenie czy obgryzanie paznokci”.  Jeśli sprawa tak się przedstawia, to zmiana skutku (palenie) nie zmieniłaby przyczyny (złe stopnie).
Jest też możliwe, że obydwa zjawiska są spowodowane przez jakiś trzeci czynnik, na przykład „pobudliwość nerwową”. Czynnik ten prowadziłby do powstania nałogu palenia, a także do ukształtowania się niewłaściwych nawyków uczenia się, dających w efekcie niskie oceny. Jeśliby przyjąć takie założenie, to zredukowanie palenia mogłoby zwiększyć nerwowość, co z kolei spowodowałoby większe roztargnienie w czasie nauki i w rezultacie gorsze stopnie. Moglibyśmy więc dojść do wniosku (gdybyśmy byli na służbie firmy produkującej papierosy), że palenie jest „klapą bezpieczeństwa” i pomaga niektórym studentom uzyskać przeciętną ocenę 5,0.
Gdybyśmy nie posiadali żadnych dodatkowych danych na ten temat, to różne wyjaśnienia byłyby równie prawdopodobne. W powyższym przykładzie moglibyśmy dodać przynajmniej jeszcze jedno wyjaśnienie (czy potrafisz znaleźć jeszcze inne?). Być może wykładowcy nie lubią studentów, którzy palą podczas zajęć (wydają się oni mniej pochłonięci wykładem, mało pilni itd.), a zatem są skłonni dawać palaczom gorsze oceny. W takim wypadku rzucenie palenia mogłoby prowadzić do lepszych stopni, ale nie wskutek bezpośredniej zmiany nawyków uczenia się, postaw czy zdrowia psychicznego studentów, lecz dzięki zmianie sposobu spostrzegania ich przez wykładowców.
|Morał: Jedna korelacja nie oznacza związku przyczynowego.


Seks może przyprawić cię o szaleństwo

W innym artykule zamieszczonym w prasie codziennej przytoczono stwierdzenie pewnego psychiatry uniwersyteckiego, który podał, że 86% grupy studentek będących pacjentkami poradni psychiatrycznej utrzymywało stosunki płciowe, podczas gdy w grupie studentek tego samego uniwersytetu, które nie leczyły się u psychiatry, tylko 22% prowadziło życie seksualne. Liczby te uzyskano w wyniku badań kwestionariuszowych, a gazeta cytuje wniosek psychiatry, że jego pacjentki są „ofiarami rewolucji seksualnej”. Czy opierając się na przytoczonych informacjach, zgodziłbyś się z tym wnioskiem?
Mamy tu dwa twierdzenia: a) znacznie wyższy procent pacjentek niż nie leczących się studentek miał stosunki płciowe, oraz b) aktywność seksualna pacjentek była czynnikiem przyczynowym w wypadku ich problemów emocjonalnych. I znów wniosek ten może być prawdziwy, lecz zanim zaakceptujesz go (i zanim pozwolisz twoim rodzicom uzbroić się w nowe, „zaczerpnięte od autorytetów” argumenty, w jaki sposób chronić twe zdrowie psychiczne) musisz postawić kilka pytań.
Po pierwsze, jaka była liczebność wspomnianej grupy pacjentek poradni psychiatrycznej? Zaskakująco wysoka liczba „86 procent” może oznaczać zaledwie sześć kobiet na ogólną liczbę siedmiu. Sformułowany wniosek nie ogranicza się bynajmniej do pierwotnej próbki ankietowanych studentek - generalizuje się go na całą |populację studentek, a nie wiemy, jak duża była ta próbka i czy była ona reprezentatywna dla ogółu studentek.
Jest także prawdopodobne, że studentki nie będące pacjentkami dawały bardziej „pożądane społecznie” odpowiedzi, zatajając swe pozamałżeńskie stosunki seksualne, podczas gdy studentki będące pod opieką psychiatryczną były bardziej szczere lub bardziej skłonne do przechwałek. Wniosek psychiatry nie dotyczył |wypowiedzi tych kobiet o sobie, lecz |zachowania opisywanego w tych wypowiedziach; nigdy jednak nie możemy zakładać, że |wypowiedzi |o |sobie i |rzeczywiste |zachowanie są takie same. Różnice między wypowiedziami obu grup mogą odzwierciedlać różnice nie pod względem rozpatrywanego zachowania, lecz pod względem tego, co grupy te chciały przekazać o sobie. W rzeczywistości studentki z grupy pacjentek mogły nawet uważać swoją aktywność seksualną za jeden z niewielu zdrowych aspektów swego życia i mogły szukać pomocy psychiatrycznej z zupełnie innych powodów. Wiemy więc w końcu tylko tyle, że w grupie pacjentek więcej kobiet przyznawało się do utrzymywania stosunków seksualnych niż w grupie nie leczących się studentek.
|Morał: Istnieje wielka przepaść między stwierdzeniami wypowiedzi a generalizacjami odnoszącymi się do czynów.


Wyż noworodków w wyniku awarii elektrowni
(czyli „Co robić, dopóki znów nie zapali się światło?”)

Jest godne uwagi, jak wiele rzeczy jest skorelowanych w naturze i jak liczba tych rzeczy wzrasta, gdy wchodzą w grę istoty ludzkie. W sierpniu 1966 roku nowojorskie gazety obwieściły o niezwykłym wzroście liczby urodzeń „w kilku największych szpitalach”, „po dziewięciu miesiącach od awarii sieci elektrycznej w 1965 roku”. Stwierdzenie to przyjęto powszechnie bez powątpiewania i ludzie przystąpili do prób wyjaśniania go.
Wśród 30 milionów mieszkańców Wschodniego Wybrzeża, dotkniętych tą awarią dnia 9 listopada 1965 roku, byli i tacy, którzy później teoretyzowali, „że pod wpływem klęsk naturalnych ludzie zwracają się ku sobie. Na przykład wykopaliska w Pompei odsłoniły pary, które spoczywały w uścisku w czasie wybuchu wulkanu”. Matka w Brookdale Hospital powiedziała: „Po ciemku nie poszłabym sama do łóżka”, świeżo upieczony ojciec przypisał wzrost liczby urodzeń temu, że „Nowojorczycy są bardzo romantyczni - przyczyną było światło świec”. Bardziej melancholijną ocenę przedstawił urzędnik Planned Parenthood Federation of America (Amerykańskie Towarzystwo Planowania Rodziny).

„Seks jest bardzo potężną siłą, a ludzie będą zawsze zajmować się seksem, jeśli nie będą mieli nic innego do roboty. Wszystko, co mogłoby zastąpić seks - spotkania, odczyty, gra w karty, teatr, bary - zostało wyeliminowane tego wieczoru. Cóż innego mogli robić?” („The New York Times”, 11 sierpnia 1966).

I znów obserwujemy wnioskowanie o związku przyczynowym na podstawie korelacji dwóch zjawisk. Częstość, z jaką występuje ten typ myślenia, świadczy o naszej skłonności do wychodzenia poza obserwacje i poszukiwania prawidłowości, które - naszym zdaniem - muszą je wyjaśniać. Są to usiłowania godne podziwu, lecz niekiedy reprezentują one jedynie inteligentne wyjaśnienie nieistniejącego faktu. W przykładzie tym wchodzą w grę dwie możliwości, których nie rozpatrywaliśmy w poprzednich przypadkach: a) do danych tych nie można mieć zaufania lub b) zależność jest pozorna.
Aczkolwiek w jednym ze szpitali nowojorskich (św. Łukasza) liczba urodzeń w każdym z siedmiu kluczowych dni była trzykrotnie większa od przeciętnej, to jednak liczby te były niewielkie - mniej więcej tylko 10 niemowląt dziennie „ponad normę”. Szesnaście innych szpitali zarejestrowało w sumie wzrost tylko o 47 urodzeń - 2,9 niemowlęcia na szpital. Wynik ten wydaje się jeszcze mniej istotny, gdy uprzytomnimy sobie, że w Nowym Jorku owej listopadowej nocy znalazło się w ciemnościach około 3 milionów kobiet zdolnych do rodzenia dzieci. Czy możemy przyjąć, że wszystkie te kobiety, które rodziły w sierpniu przebywały na obszarze objętym awarią dziewięć miesięcy wcześniej?
Aby ustalić, czy w rzeczywistości zdarzył się fakt, który należałoby wyjaśnić, pewien statystyk (J. Richard Udrey ze School of Public Health, University of North Carolina) porównał „awaryjny” wskaźnik urodzeń z analogicznymi wskaźnikami dla lat poprzednich. Nie było |żadnej |różnicy między odsetkiem ogólnej rocznej liczby urodzeń, przypadającym na okres od 27 czerwca do 14 sierpnia (tzn. mniej więcej po dziewięciu miesiącach od 9 listopada jako daty poczęcia) a odsetkiem urodzeń przypadającym na ten okres w każdym z pięciu poprzednich lat.
Epilogu dla tej historii dostarczyły doświadczenia, jakie zebrano w następnym roku w Chicago. Na podstawie doniesień z Nowego Jorku chicagowskie szpitale przygotowały się na „wyż noworodków”, jaki powinien wystąpić jesienią 1967 roku w wyniku burzy śniegowej (23 cale opadu), która nawiedziła to miejsce w styczniu tegoż roku. Jednakże statystyki dla trzech jesiennych miesięcy, w porównaniu ze statystykami z tych samych miesięcy w roku poprzednim i - jak potem stwierdzono - następnym, wykazały jedynie nieznaczne fluktuacje, przy czym liczba urodzeń była nieco mniejsza niż w poprzednim roku i nieco większa niż w roku następnym. 
Takie mity ustępują powoli, ponieważ stają się częścią „mądrości ludowej”, a większość ludzi nigdy nie zetknęła się z przeciwstawnym materiałem dowodowym. Po siedmiu latach po awarii oświetlenia w Nowym Jorku twierdzenie to pojawiło się ponownie, w przesadnej postaci, w komunikacie agencji United Press. Podano w nim, że członek Rady Miejskiej Los Angeles, Donald Lorenzen, kłopocząc się tym, iż z powodu kryzysu energetycznego może nie być światła ani telewizji, powiedział: „Wiem, co zdarzyło się w Nowym Jorku, gdy mieli tam awarię sieci elektrycznej: wszyscy poszli do łóżka i zerowy przyrost naturalny diabli wzięli. Urodziło się potem więcej dzieci niż w jakimkolwiek innym czasie”. („United Press”, 23 listopada 1973).
„Morał: Starannie opracowane wyjaśnienia nie istniejących faktów są jak cukrowa wata: usta pełne, lecz w brzuchu pusto.


Ach, żeby tak być Murzynem, teraz, gdy policja bije białych


„Biali są bardziej poszkodowani niż Murzyni” w wyniku nieuzasadnionego użycia siły przez policję - tak głosił artykuł opublikowany w prasie w lipcu 1968 roku. „Uprzedzenia rasowe nie są głównym powodem bicia biednych ludzi przez policję (...) policja częściej traktuje brutalnie białych niż Murzynów”. Trzydziestu sześciu obserwatorów, którzy pracowali razem z policjantami w Bostonie, Waszyngtonie i Chicago w ciągu lata 1966 podało, że spośród 643 podejrzanych białych 27 uderzono niepotrzebnie (wskaźnik 41,9 na 1000).

* * *
Ryc. 1.12.
Rozmowa dwóch policjantów:
„Przynajmniej nie można nas oskarżyć o rasizm - bicie białych było równie zabawne jak bicie czarnych”.

* * *
Spośród 751 podejrzanych Murzynów tylko 17 uderzono niepotrzebnie (wskaźnik 22,9 na 1000). Oskarżenia o brutalność w stosunku do Murzynów, wysuwane pod adresem policji przez ugrupowania broniące praw obywatelskich, nie znajdują zatem potwierdzenia w tych danych.
Jednakże dane te, takie jakie są, mogą mieć przynajmniej trzy interpretacje: a) mogą być ścisłe, jak podano w sprawozdaniu, b) mogą być efektem działania zasady nieoznaczoności, c) mogą być wynikiem tendencyjności lub niedokładności obserwatora.
|Zasadę |nieoznaczoności, która głosi, że akt mierzenia pewnego procesu może zmienić sam ów proces, zawdzięczamy fizykowi Heisenbergowi. Chociaż mówił on o szybkości i umiejscowieniu elektronu w korze mózgowej, to jednak jego zasada jest często prawdziwa także w odniesieniu do pomiaru psychologicznego. Gdy ludzie zdają sobie sprawę z tego, że są obserwowani, wpływa to na mierzone zachowanie i obserwator nie otrzymuje już dokładnego obrazu. Pomiar może być zniekształcony przez próby oszukiwania, chęć zaprezentowania się w korzystnym świetle, zaprotestowania przeciw roli „królika doświadczalnego” czy chęć „przechytrzenia” obserwatora - badani starają się demonstrować takie cechy lub zachowania, jakie ich zdaniem są pożądane. Zatem, podczas badań nad brutalnością policji, jej funkcjonariusze mogli zmienić praktykowany przez siebie sposób walenia po łbach, ponieważ wiedzieli, że są bacznie śledzeni przez obserwatorów jeżdżących z nimi w wozach patrolowych”.
Również przyjęte przez obserwatorów definicje „niepotrzebnego zastosowania przemocy” mogły wpłynąć na wyniki. Być może stosowali oni różne definicje dla białych i czarnych podejrzanych. Jest możliwe, że policja biła tylu czarnych podejrzanych, co i białych - może nawet więcej - lecz bicie Murzynów mogło być częściej uważane za „niezbędne” przez obserwatorów.
|Morał: Kiedy opisujemy „jak jest”, naprawdę oznacza to „jak się nam wydaje”, w zależności od tego, na co nauczyliśmy się zwracać uwagę, jak definiujemy i mierzymy przedmiot naszych zainteresowań i co inni chcą, żebyśmy zobaczyli.


Tyrania liczb: czy statystyka może kłamać?


Przestępczość jest jedną z najpoważniejszych bolączek narodowych w Stanach Zjednoczonych, o czym świadczą wyniki większości przeprowadzanych obecnie badań opinii publicznej. Jak dalece zła jest jednak sytuacja w tej dziedzinie? Odpowiedź zależy od statystyki, która pozwala porównać liczbę przestępstw kryminalnych w ostatnich latach. Zależy jednak również od tego, czy chcemy, żeby statystyka dowiodła, iż a) sytuacja pogarsza się (może to być potrzebne, gdy chodzi o przyznanie większych środków na walkę z przestępczością lub gdy atakuje się obecny rząd), czy też, że b) sytuacja polepsza się (aby usprawiedliwić wydatkowanie w ubiegłych latach pieniędzy podatników na walkę z przestępczością lub dowieść, że stosowana przez rząd polityka opanowania przestępczości była skuteczna).
Wzrost przestępczości stwierdzony przez FBI ma jednoznaczną wymowę: 
Ratunku! Jednakże Prokuratura Generalna kwestionuje słuszność tego pesymistycznego poglądu („The New York Times”, 18 września 1971) i za pomocą statystyki dowodzi, że wysoka uprzednio (pod rządami Demokratów) przestępczość maleje w wyniku realizacji programu Nixona „Law and Order” („Prawo i Porządek”).
Chociaż statystyka FBI ujawniła, że liczba poważnych przestępstw wzrosła z 4,4 miliona w 1968 roku do 5,5 miliona w 1970 roku, to znaczy o 25% więcej, jednak program Ministerstwa Sprawiedliwości przyniósł sukces. Jakim sposobem? - zapytasz. No cóż, według statystyki Prokuratury Generalnej nie ulega wątpliwości, że tempo wzrostu przestępczości maleje. W roku 1976 wskaźnik przestępczości wzrósł o 16% w stosunku do roku 1966, w następnym roku o 17%, a potem o 12% w 1969 roku i o 11% w 1970 roku. Tak więc wzrost wskaźnika przestępczości, który można odczuć na własnej skórze, oznacza jednocześnie rzeczywisty spadek tempa wzrostu przestępczości w danym okresie. (Można się tym pocieszać, zamknąwszy drzwi na trzy solidne zamki, prawda?).
|Morał: Statystyka jest liczbą, dopóki nie zechcesz, aby udowodniła słuszność tego wniosku - wtedy jest bronią.


Historia pewnego przypadku, czyli, jak błyskawicznie tworzy się autorytet naukowy


Jako ostatnią ostrzegawczą opowieść w naszym przeglądzie niebezpieczeństw, związanych z przyjmowaniem za dobrą monetę doniesień o tym, co „nauka” rzekomo odkryła, proponujemy następującą „osobistą” historyjkę.

„Według danych opublikowanych przez wybitnych psychologów, w ciągu ostatnich paru lat gwałtownie wzrosło użycie sprośnych słów przez kobiety: zarówno młode dziewczęta z Nowej Lewicy, jak i szanowane matrony na eleganckich coctail-parties na Manhattanie”.

Tak brzmi początek artykułu w „The York Timesie” (Leo, 1968), który, jak łatwo sobie możesz wyobrazić, wzbudził znaczne zainteresowanie w społeczeństwie. Najbardziej interesujący z naszego punktu widzenia jest fakt, że sławnym „wybitnym autorytetem” w zakresie tego zagadnienia był jeden z autorów „Psychologii i życia”. W dalszej części artykułu omówione są jego spostrzeżenia:

„Philip Zimbardo, psycholog ze Stanford University, powiedział, że obserwując przez dłuższy okres podnieconych pacjentów w dwóch szpitalach psychiatrycznych Wschodniego Wybrzeża, zauważył, iż kobiety posługiwały się bardziej sprośnym językiem niż mężczyźni”.

Doniesienie to, podchwycone przez agencje prasowe, zostało przedrukowane w różnych postaciach w prasie całego kraju, opublikowane w sensacyjnej formie w „Newsweeku” pod nagłówkiem „Rozmowa dziewcząt”: ... xxx ...  skomentowane przez dr Joyce Brothers w jej rubryce publikowanej jednocześnie w licznych magazynach, a wreszcie zamieszczone w ramkach w kolumnie „Forum Wiadomości” znanego magazynu „Playboy”! Po opublikowaniu artykułu w „The New York Times” posypały się propozycje dla „autorytetu”, aby wystąpił w radiowych i telewizyjnych programach dyskusyjnych, jak również mnóstwo próśb o odbitki jego prac na ten temat (niektóre aż z Południowej Ameryki). Mamy tu jedyną w swoim rodzaju sposobność, aby prześledzić losy tego szeroko rozpowszechnionego i w pełni zaakceptowanego wniosku od jego niepewnego, spekulatywnego źródła, aż do ostatecznej, przekonywującej autorytatywnej postaci „faktu dotyczącego natury ludzkiej”.
Wydaje się, że jeden z wydawców „The New York Timesa” został na przyjęciu sklęty przez jakąś panią, po czym szybko wysłał reportera, aby ustalił, czy było to zdarzenie wyjątkowe, czy przejaw regularnie powtarzającego się z zjawiska społecznego, czy też w nim samym było coś takiego, co nie spodobało się tej pani.
Reporter zatelefonował do kilku przedstawicieli nauk społecznych, którzy mogli wiedzieć coś w tej kwestii; jeden z nich (z jakiegoś niewiadomego powodu) skierował go do Zimbardo. Nie pomogły protesty, że brak jakichkolwiek danych na ten temat ani stwierdzenia, że nikt nie prowadził badań nad tym szczególnym problemem - reportaż musiał być gotowy najpóźniej następnego dnia. Reporter dowiedział się więc, że „wiele lat temu (ściśle mówiąc, dziesięć), w dwóch szpitalach psychiatrycznych w Connecticut, w których prowadzono nieformalną obserwację na salach, gdzie przebywali chroniczni schizofrenicy, sale żeńskie sprawiały wrażenie bardziej hałaśliwych, obserwowano na nich więcej przejawów ekshibicjonizmu i sprośności niż na salach męskich”.

Obserwator nie zarejestrował żadnych innych danych poza swymi ogólnymi wrażeniami, ponieważ nie weryfikował żadnej hipotezy dotyczącej sprośności.  Nie było żadnej weryfikacji tych samych danych przez innych obserwatorów, żadnej sprecyzowanej definicji sprośności, nie zapewniano też porównywalności okresów obserwacji mężczyzn i kobiet. Jest możliwe, że obserwator po prostu lepiej uświadomił sobie sprośność kobiet, ponieważ zwykle spotyka się ja rzadziej w życiu codziennym: być może w szpitalach występowała ona z taką samą (a może nawet mniejszą) częstotliwością jak wśród schizofreników-mężczyzn. A może na sali tej było po prostu parę bardzo hałaśliwych, sprośnych kobiet. W każdym razie, wobec braku systematycznie zbieranych i rejestrowanych danych, nie możemy oddzielić zniekształceń we wspomnieniach Zimbarda (po dziesięciu latach) zarówno od jego pierwotnych obserwacji, jak i rzeczywistego zachowania pacjentów.
W artykule „The New York Timesa” to, co przypadkowo „zaobserwowano wiele lat temu”, zmieniło się w „obserwacje dokonywane przez długi okres”, a „chroniczni schizofrenicy” stali się „podnieconymi pacjentami”. Pierwotne, przypadkowe obserwacje, w stosunku do których w artykule „... Timesa” użyto słowa „zauważył”, w „Nesweeku” stały się zależnością, którą „stwierdzono” - „pacjentki w szpitalach psychiatrycznych używają sprośnych słów dużo częściej niż mężczyźni” (proszę zwrócić uwagę na dodanie słowa „dużo”). W rubryce prowadzonej przez dr Brothers „chroniczne schizofreniczki” stały się „pacjentkami psychiatrycznymi” - termin ten mogłby dotyczyć także pacjentek z lżejszymi zaburzeniami.
Współczesny autorytet we wszystkich sprawach seksualnych - „Playboy” - uprościł to zagadnienie dla swych czytelników, formułując zbyt szerokie uogólnienie, że „wielu psychologów, jak podaje „The New York Times”, stwierdziło, iż kobiety ze wszystkich warstw społecznych stają się coraz bardziej rozhamowane, jeśli chodzi o posługiwanie się sprośnym językiem” („Playboy”, 1969). Jedynym wzmiankowanym psychologiem jest dobrze znany obecnie autorytet, Philip Zimbardo, którego wyczerpujące badania „potwierdzają” powyższą zasadę ludzkiego zachowania.
Ostatnim przyczynkiem do tego zanieczyszczania środowiska jest fakt, że niepotwierdzona, stronnicza (być może tendencyjnie „antyfeministyczna”) obserwacja przeszła obecnie do wzniosłego królestwa generalizacji naukowej - wkrótce stanie się solidną prawdą. Czy uwierzyłbyś w następujący opis typu „Kto chce niech wierzy”, zamieszczony w popularnej rubryce w „San Francisco Chronicle” (13 listopada 1971)?

Wędka szczęścia
„Każdy czegoś się boi”. L. M. Boyd


|Pytanie |otwarte: Jest faktem dowiedzionym, że pacjentki w szpitalach psychiatrycznych klną na czym świat stoi, znacznie częściej niż pacjenci mężczyźni. Jak byś to wytłumaczył?

Niestety, reguły tej gry zabraniają jakiejkolwiek osobie dowolnej płci, która przeczytała powyższy tekst, przedstawiania wyjaśnień tego „dowiedzionego faktu”.
|Morał: Autorytety są godne zaufania w takim tylko stopniu, jak ich najsłabsze materiały dowodowe, ich najbardziej wątpliwe przesłanki i ich wątpiący krytycy.

Poziomy analizy psychologicznej

Badacz studiujący dane zjawisko czy proces może zadawać pytania, stosować techniki i zbierać dane odpowiadające różnym poziomom analizy - od wysoce szczegółowych, drobiazgowych i specyficznych do ogólnych, szerokich i całościowych. W psychologicznych badaniach można wyróżnić trzy poziomy analizy: poziom mikroskopowy, poziom molekularny i poziom molarny.
Na poziomie |mikroskopowym zainteresowanie skupia się na możliwie najdrobniejszych częściach, zdarzeniach i subjednostkach organizmu.  Precyzja, szczegółowość, rygorystyczne metody zbierania danych oraz analiza ilościowa - oto charakterystyczne cechy badań przeprowadzanych na tym poziomie. Badacz studiujący przemiany chemiczne w komórkach oka podczas przekazywania impulsu nerwowego działałby na poziomie mikroskopowym.
Na poziomie |molekularnym również występuje zainteresowanie szczegółami - małymi, policzalnymi jednostkami pomiaru. Jednakże studiuje się tu większe jednostki niż na poziomie mikroskopowym, ponieważ przedmiotem badania są procesy mniej szczegółowe, które same składają się z subjednostek.  Psychologowie, którzy pracują na przykład w dziedzinie uczenia się, spostrzegania, psycholingwistyki czy przekazywania informacji, prawdopodobnie najczęściej działają na poziomie molekularnym. Często starają się oni formułować prawa przyczynowe ukazujące związek między procesami wewnętrznymi (takimi jak widzenie barw czy pamięci) a zewnętrznymi zmiennymi podlegającymi manipulacji).
Na poziomie |molarnym, przedmiotem badania jest albo cały funkcjonujący organizm, albo system zachowań, w które zaangażowana jest znaczna część całego organizmu. Do tych, którzy stosują molarny poziom analizy, należą psychologowie osobowości, psychologowie kliniczni (zajmujący się diagnozą i leczeniem zaburzeń psychicznych i emocjonalnych) oraz psychologowie społeczni. Na tym poziomie dane mają często charakter bardziej jakościowy niż ilościowy, metody badawcze są mniej rygorystyczne i słabiej kontrolowane, zaś wnioski są dużo ogólniejsze, lecz mniej ścisłe niż na poziomie mikroskopowym czy molekularnym. Psychologowie, którzy działają na tym poziomie, skłonni są wnioskować o nieobserwowalnych zjawiskach i procesach (np. wartościach, superego, deprywacji kulturowej) i wyjaśniać zachowanie przyczynami natury historycznej, psychicznej, środowiskowej, społecznej czy nawet politycznej.
Mimo powszechnej zgody co do celów psychologii oraz standardów rzetelnego zbierania danych i wyciągania wniosków, psychologowie nie są zgodni co do tego, który poziom analizy jest najlepszy. Z reguły badacz działa głównie na tym poziomie, który odpowiada najlepiej jego zainteresowaniom, przygotowaniu i zdolnościom. Istnieje również wzajemna zależność między przyjmowanymi założeniami, co do przyczyn i następstw zachowania ludzkiego, a stosowanym poziomem analizy. Jeśli zakładasz, że zachowanie jest determinowane głównie przez czynniki genetyczne, to nie badasz podstaw, wzorców wychowywania dzieci ani samoświadomości. Jeśli funkcjonujesz na „swobodniejszym”, mniej specyficznym poziomie molarnym, to jest mniej prawdopodobne, abyś interesował się procesami fizjologicznymi, a bardziej prawdopodobne, że przyjmiesz, iż ważnych wyznaczników zachowania należy szukać w środowisku społecznym jednostki.
Chociaż wybór określonego poziomu analizy może być po prostu sprawą preferencji osobistych, wielu badaczy dochodzi do przekonania, że „ich” poziom jest najlepszym lub nawet jedynym właściwym sposobem uprawiania psychologii. Historia psychologii pełna jest nazw „szkół” psychologicznych, które powstały dla obrony takiego lub innego zbioru założeń określających, czym powinna się zajmować psychologia i (lub) w jaki sposób należy prowadzić badania psychologiczne. Nazwy takie jak „strukturalizm”, „funkcjonalizm”, „introspekcjonizm”, „behawioryzm” i inne określają różne sposoby podejścia do psychologii jako nauki. Terminy te są zdefiniowane w „Słowniku” na końcu tej książki i omówione w odpowiednich miejscach tekstu.  Nasze własne podejście będzie eklektyczne - to znaczy będziemy się starali przedstawić jak najszerszy przegląd najlepszych dostępnych badań, teorii i dociekań, niezależnych od nastawienia czy poziomu analizy przyjętego przez badaczy-empiryków i bez względu na filozoficzne i polityczne założenia teoretyków.
Przy rozpatrywaniu zagadnienia poziomów analizy może być przydatne posłużenie się analogią w postaci różnych rodzajów map, jakich potrzebowałbyś, aby z akademika dostać się do różnych miejsc. Gdybyś chciał znaleźć budynek administracji lub klub sportowy, to najodpowiedniejsza byłaby mapa osiedla uniwersyteckiego, na której zaznaczono każdy budynek.  Gdybyś jednak chciał pojechać rowerem do miasta, żeby pójść do kina, to wtedy bardziej przydałaby się mapa pokazująca ulice miasta. Wyjazd na ferie do pobliskiego miasteczka wymagałaby mapy przedstawiającej szosy okręgowe i stanowe, podczas gdy w motocyklowej wycieczce po kraju potrzebna byłaby mapa Stanów Zjednoczonych z zaznaczonymi granicami stanów, miastami, szosami łączącymi poszczególne stany itd.
Chociaż każda mapa może przedstawiać dokładnie i rzetelnie zawarte w niej informacje, to jednak może być całkowicie nieodpowiednia, jeśli nie potrzebujesz tych informacji w związku z konkretną wycieczką. Aby mapa, którą się posługujesz, była „odpowiednia”, musi ona być na poziomie szczegółowości lub ogólności stosownym do wymagań, jakie jej stawiasz. Tak więc podróż z twojego miejsca pobytu w Stanach do Stambułu wymaga całego zestawu map; między innymi byłyby tam lokalne mapy początkowego i końcowego odcinka podróży, lecz także mapy świata, które pozwalają wyznaczyć ogólny kierunek i dają pojęcie o całej trasie.
Mapy różnią się nie tylko wielkością podziałki (stopniem szczegółowości), lecz także rodzajem cech, jakie przedstawiają. Mapa fizyczna, przedstawiająca rzeźbę powierzchni, może nie pokazywać miast ani szos.  Różnice takie mogą odpowiadać w psychologii różnicy między badaniem zjawisk fizykalnych a badaniem świadomości doznań. Niektórzy psychologowie nie zgodziliby się z tym poglądem, wierząc, że w końcu wszystkie zjawiska psychiczne uda się opisywać w kategoriach neurologicznych lub biochemicznych. Stanowisko to nosi nazwę |redukcjonizmu.

W niniejszej książce zapoznasz się z badaniami reprezentującymi wszystkie te sposoby podejścia. Będziesz miał sposobność sam poszukać odpowiedzi na pytanie, który poziom analizy jest najlepszy dla zrozumienia i wyjaśnienia tego, co robimy i odczuwamy - czy też, być może, do różnych celów trzeba stosować różne jej poziomy.
Układ książki jest taki, że przechodząc z rozdziału do rozdziału będziesz zarazem przechodził z poziomu mikroskopowego, poprzez poziom molekularny, do coraz ogólniejszych, molarnych poziomów analizy. Rozdział 2, poświęcony psychologii fizjologicznej, rejestruje poziom najbardziej szczegółowy, podczas gdy w ostatnich dwóch rozdziałach, dotyczących patologii społecznej i psychologii ekologicznej, próbujemy opisać los człowieka przy zastosowaniu najogólniejszych poziomów analizy. Między tymi dwiema skrajnościami nie będziemy tracić z oczu ostatecznego celu naszej podróży, żeby nie zabłąkać się w plątaninie bocznych ścieżek; jednocześnie będziemy starali się dostrzegać i doceniać charakterystyczne cechy obszarów lokalnych, co uczyni naszą wspólną wyprawę interesującą i niezwykłą.


Streszczenie rozdziału

Psychologia to naukowe badanie zachowania organizmów. Dzięki studiowaniu psychologii uzyskujemy wiedzę o wzajemnym oddziaływaniu, czyli interakcji, między żywymi istotami (z ludźmi włącznie) a ich środowiskiem, a także między nimi nawzajem. Każdy z nas nieformalnie pełni funkcje „psychologa” - oceniając i przewidując własne zachowanie innych ludzi. W książce tej zapoznamy się z metodami, dzięki którym psychologowie sformalizowali badania nad zachowaniem, sprawdzając swe założenia, dokonując ścisłych obserwacji, oceniając obiektywnie materiał dowodowy i wyciągając uzasadnione wnioski.
Wszyscy psychologowie przyjmują za punkt wyjścia pewne założenia, co do natury świata: 1. Podobnie jak inni naukowcy zakładają oni, że w naturze istnieje zasadniczy |porządek i że można wykryć układy systematycznych zależności. 2. Przyjmują założenia |determinizmu, to znaczy zakładają, że wszystkie zdarzenia mają przyczyny i że zrozumienie tych przyczyn pozwala przewidywać wystąpienie przyszłych zdarzeń. 3. Zajmują się jedynie wiedzą |empiryczną: informacjami, które można uzyskać za pomocą obiektywnej obserwacji i zweryfikować w sposób niezależny.
Chociaż psychologowie są zgodni co do zasadniczych założeń stanowiących podstawę badań naukowych, to jednak mogą oni w swej działalności opierać się na różnych założeniach dotyczących natury ludzkiej i zachowania człowieka. Psychologowie mają różne poglądy na temat istnienia - i doniosłości - procesów |poznawczych czy procesów |psychicznych w ogóle.  Mają różne zdania o tym, czy ważniejsza jest |natura (wpływ dziedziczności) czy |wychowanie (wpływ środowiska). Różnią się swym stanowiskiem w kwestii, czy natura ludzka jest w gruncie rzeczy |dobra czy też |zła. Niektórzy psychologowie przyjmują podejście |nomotetyczne, poszukując praw uniwersalnych, które wyjaśniają zachowanie wszystkich ludzi. Inni preferują podejście |idiograficzne starając się ustalić, dlaczego ludzie różnią się pod względem swego zachowania. Niektórzy szukają przyczyn |dyspozycyjnych w ludziach. Inni szukają przyczyn |sytuacyjnych w środowisku. Niektórzy koncentrują się na badaniu |jednostek; inni zajmują się zachowaniem |grup.
Sposób, w jaki psycholog stawia pytania, decyduje o tym, jakiego rodzaju odpowiedzi otrzyma. Psychologowie zainteresowani badaniem zewnętrznych reakcji na wyraźnie określone bodźce są zwani |behawiorystami. Ci, którzy wolą studiować subiektywne doznania jednostek, znani są jako |fenomenolodzy. Przed psychologiem-badaczem stoją cztery podstawowe cele: 
|opisywanie, |wyjaśnianie, |przewidywanie i |sterowanie. W psychologii stosowanej dołącza się do tych celów jeszcze piąty: wykorzystanie wyników badań do podniesienia jakości ludzkiego życia.
|Opisywanie wymaga obiektywnych obserwacji. Oznacza to zbieranie danych: opisów lub pomiarów obserwowanych zjawisk. Przy zbieraniu danych ważne jest, aby odróżniać to, co się rzeczywiście |obserwuje, od tego, o czym się jedynie |wnioskuje. Aby uchronić swe dane od wieloznaczności, psychologowie stosują podejście zwane |operacjonizmem. Formułują |definicje |operacyjne polegające na tym, że pojęcia definiuje się w kategoriach specyficznych operacji stosowanych przy pomiarze.
|Wyjaśnianie w psychologii polega na szukaniu odpowiedzi na pytania „Co?” i „Jak?”, a nie „Dlaczego?”. Stosuje się wiele różnych typów wyjaśnień, w zależności od tego, jakie zjawisko się wyjaśnia. Na ogół psychologowie unikają tak zwanych wyjaśnień mentalistycznych, w których wnioskuje się o uczuciach lub pragnieniach. Wielu psychologów wyjaśnia natomiast specyficzne jednostki zachowania w kategoriach procesów |fizjologicznych, takich, jak aktywność komórek nerwowych itd. Niektórzy czynią użytek z |analogii, wyjaśniając dane zjawisko przez ukazanie jego podobieństwa do jakiegoś lepiej znanego zjawiska czy procesu. W przypadku wyjaśnień |funkcjonalnych zachowanie wyjaśnia się w kategoriach warunków bodźcowych, których jest ono funkcją. |Modele, czyli struktury teoretyczne zapożyczone z jednej dziedziny wiedzy mogą być pomocne w próbach wyjaśniania zachowania w innej dziedzinie, lecz nie mogą służyć jako całkowite wyjaśnienie.  Technika komputerowa dała początek nowej formie wyjaśniania, a mianowicie symulacji procesów behawioralnych. Opracowując operujące symbolami programy komputerowe psychologowie mogą dowiedzieć się wiele o przetwarzaniu informacji przez człowieka. Najbardziej zaawansowaną formą wyjaśniania naukowego są wyjaśniania |teoretyczne. |Teoria to sformułowane zależnościmiędzy zbiorem założeń, zasad, wniosków i obserwacji.
Na podstawie formułowanych przez siebie teorii psychologowie starają się przewidywać wystąpienie i (lub) następstwa danego zachowania. Punktem wyjścia dla przewidywania jest sformułowanie |hipotezy: twierdzenia dotyczącego możliwej zależności między dwiema lub więcej |zmiennymi.  Hipotezy sprawdza się w eksperymentach i, chociaż mogą zostać potwierdzone ze znacznym stopniem pewności, nigdy nie uważa się ich za rzeczywiście dowiedzione.
|Korelacje są użytecznym narzędziem przewidywań psychologicznych.  Korelacja jest dokładnym, statystycznym określeniem związku między dwiema zmiennymi. Należy pamiętać, że korelacja między dwiema zmiennymi |nie musi oznaczać, iż jedna z nich |powoduje drugą, a tylko, że istnieje między nimi współzmienność.
|Sterowanie zachowaniem własnym i innych możliwe jest tylko wtedy, gdy można poznać i przewidzieć warunki, w których takie zachowanie występuje.  Ważnym elementem w sterowaniu jest |sprzężenie |zwrotne dotyczące wyników zachowania. Psychologowie coraz bardziej troszczą się o to, aby ich umiejętności w zakresie przewidywania zachowania i sterowania nim były wykorzystywane w taki sposób, który pozwoli podnieść, a nie obniżyć, jakość ludzkiego życia.
|Metoda |eksperymentalna stanowi podstawę badań naukowych. Metoda ta składa się z czterech głównych etapów: sformułowania hipotezy, sprawdzenia jej, wyciągnięcia wniosków i opisania wyników w taki sposób, aby inni naukowcy mogli |powtórzyć eksperyment. Na początek badacz rozstrzyga, jak należy zdefiniować i mierzyć zmienne, które ma zamiar badać, oraz formułuje hipotezę. Zmienna, której wpływ bada, nosi nazwę |zmiennej |niezależnej.  Jest to ta zmienna, którą eksperymentator modyfikuje, czyli |manipuluje |nią. Zmienną zależną jest to zachowanie, którego zmian się oczekuje, gdy manipuluje się zmienną niezależną.
W typowym eksperymencie biorą udział dwie grupy badanych: |grupa |eksperymentalna i |grupa |kontrolna. Zmienną niezależną manipuluje się w grupie eksperymentalnej, natomiast w grupie kontrolnej utrzymuje się ją na stałym poziomie (wszystkie inne zmienne, które mogłyby wpływać na wyniki, utrzymuje się na stałym poziomie w obu grupach). Jeśli zmienna zależna zmienia się w grupie eksperymentalnej, a nie zmienia w kontrolnej, to różnicę tę można przypisać zmianom zmiennej niezależnej. W rzeczywistości większość zachowań ma wielorakie przyczyny i całą sieć powiązanych wzajemnie skutków. Tam, gdzie zmiennych nie można utrzymywać na stałym poziomie, kontrolę eksperymentalną realizuje się innymi środkami.  Najistotniejszym elementem w przeprowadzaniu eksperymentów jest |losowe przydzielanie badanych do różnych grup eksperymentalnych.
Ważne jest, aby wiedzieć, czy istnieje |istotna |różnica między wynikami grup, czy też różnica ta mogła wystąpić przypadkowo. Trzeba to ustalić za pomocą testów statystycznych, które pozwalają uzyskać |ocenę |prawdopodobieństwa, że dana różnica wystąpiła przypadkowo. Jeśli to prawdopodobieństwo jest wystarczająco małe (np. mniejsze niż 5/100), to odrzuca się hipotezę o wyniku przypadkowym i różnicę uważa się za |istotną |statystycznie - spowodowaną nie przez przypadek, lecz przez eksperymentalną manipulację zmiennymi.
Wnioski wyciągane z eksperymentów naukowych są w takim tylko stopniu godne zaufania, jak dane, na których zostały oparte, i obiektywizm, z jakim się je interpretuje. Każdego dnia środki masowego przekazu zarzucają nas rzekomymi „wnioskami naukowymi”, których wartość musimy umieć krytycznie ocenić, jeśli chcemy uniknąć wpadnięcia w psychologiczne „pułapki”.
Badania psychologiczne, które będziemy studiować w tej książce, można sklasyfikować według stosowanego w nich |poziomu |analizy. Badania dotyczące poszczególnych elementów organizmu, na przykład zachowania pojedynczych komórek, reprezentują na ogół |mikroskopowy poziom analizy.  Badania większych jednostek zachowania, na przykład procesów spostrzegania czy przetwarzania informacji, to poziom |molekularny. Ogólniejsze badania dotyczące zachowania całego organizmu lub grup organizmów są prowadzone na |molarnym poziomie analizy.
Poziom analizy, na którym działa dany psycholog, jest zdeterminowany przez przyjmowane przez niego założenia teoretyczne i przez charakter badanych procesów. W niniejszej książce przyjmiemy podejście |elektyczne do uprawiania psychologii, korzystając w miarę potrzeby z różnych założeń teoretycznych i różnych poziomów analizy.

Rozdział 2.
Fizjologiczne podstawy zachowania


„Jak doskonałym tworem jest człowiek? jak wielkim przez rozum! jak wielkim przez rozum! jak niewyczerpanym w swych zdolnościach! jak szlachetnym postawą i w poruszeniach!* (*Przekład Józefa Paszkowskiego.  William Szekspir „Dzieła dramatyczne”. Warszawa 1980).
William Szekspir „Hamlet” - Ii; 2


Znajdujemy się w sali operacyjnej Instytutu Neurologicznego w Montrealu, gdzie obserwujemy operację chirurgiczną mózgu. Operowanym jest Buddy, młody mężczyzna cierpiący na ataki padaczki, których nie można opanować w inny sposób. Chirurg chce przeprowadzić operację w celu usunięcia guza mózgu, lecz najpierw musi ustalić, jakie będą następstwa usunięcia różnych fragmentów tkanek mózgu otaczających guz. W tym celu musi sporządzić |mapę części mózgu pacjenta - mapę ukazującą związek między poszczególnymi okolicami mózgu a funkcjami psychicznymi, na które one wpływają lub którymi sterują. Dlatego też Buddy został poddany jedynie miejscowemu znieczuleniu i jest utrzymywany w stanie świadomości, aby mógł opisywać doznania, jakich będzie doświadczał, gdy chirurg będzie badał jego mózg.
Gruba warstwa kostna czaszki, która osłania i chroni delikatny narząd znajdujący się wewnątrz, została usunięta. Możemy teraz zobaczyć zewnętrzną, głęboko pofałdowaną powierzchnię mózgu, zwaną |korą. Koniuszek cienkiego drutu, trzymanego jak ołówek wprawną ręką chirurga, delikatnie dotyka pewnego obszaru kory, drażniąc ją słabym prądem elektrycznym.
„Nic, nic, żadnej widocznej reakcji”, stwierdza pielęgniarka. Chirurg przenosi więc ostrożnie elektrodę w inne miejsce, odległe jedynie o kilka milimetrów. „Zaciska pięść, podnosi rękę, widzę skurcze mięśni”. Chirurg ponownie drażni ten sam obszar, a pielęgniarka opisuje podobną reakcję ruchową. Procedura ta, polegająca na drażnieniu jednego obszaru powierzchni mózgu po drugim, przy jednoczesnej obserwacji zmian wywoływanego w ten sposób zachowania, pozwala powoli sporządzić mapę, którą posłuży się chirurg, by poprowadzić właściwie swój skalpel przez niezliczone zakręty i rowki kory mózgu pacjenta.
Nagle występuje nieoczekiwana reakcja.
„Pacjent szczerzy zęby, śmieje się, otwiera oczy podczas drażnienia tego obszaru”.
„Buddy, co się stało, co odczuwałeś przed chwilą?”
„Doktorze, usłyszałem piosenkę, a właściwie część piosenki, melodię”.
„Buddy, czy słyszałeś ją kiedykolwiek przedtem?”
„Tak, pamiętam, że słyszałem ją dawno temu, nie mogę przypomnieć sobie tytułu tej piosenki”.
W czasie drażnienia innej okolicy mózgu pacjent przypomina sobie z żywymi szczegółami przerażające przeżycie z okresu dzieciństwa.
W trakcie podobnej operacji u pewnej pacjentki „odżyły” przeżycia jakie miała przy porodzie swego dziecka. Jak za dotknięciem przycisku elektronicznej pamięci, dr Wilder Penfield wywołał wspomnienia spoczywające spokojnie latami w zakamarkach mózgów jego pacjentów (Penfield i Baldin, 1952; ryc. 2.1).

* * *
Ryc. 2.1. Zdjęcie przedstawia korę mózgową prawej półkuli pacjentki chorej na padaczkę. Kora ta została odsłonięta w celu przeprowadzenia zabiegu chirurgicznego; pacjentka zachowywała w tym czasie pełną świadomość. Liczby oznaczają punkty, których drażnienie prądem elektrycznym wywołało pozytywne reakcje - proste reakcje sensoryczne i ruchowe w punktach 2, 3, 7, 4 i 8 oraz migawkowe doznania minionych zdarzeń (flash back experiences) w punktach 11, 12, 15 i 14. Gdy drażniono na przykład punkt 11, wówczas pacjentka podawała, że słyszy sąsiadkę wołającą swego małego synka. Zidentyfikowała ona to doznanie jako „coś, co zdarzyło się przed laty” (Penfield, 1958).

* * *
Skąd jednak wydobyto te wspomnienia? Jak były one przechowywane w mózgu, że można je było ożywić tak szybko? W jaki właściwie sposób ten sam rodzaj stymulacji elektrycznej w jednej części mózgu wywołuje reakcję ruchową, w drugiej - reakcję sensoryczną, w trzeciej - reakcję pamięciową itd. Czy każdy z tysiąca bilionów bitów informacji, które - jak się ocenia - nasze zmysły odbierają z otoczenia w czasie trwania życia, jest przechowywany gdzieś w naszym mózgu? Jeszcze bardziej zagadkowe jest to, w jaki sposób potrafimy „odczytywać” i opisywać treści zawarte w naszym własnym mózgu - skąd wiemy jak uświadamiamy sobie to, co właśnie w tej chwili zachodzi tam poza naszymi oczami?
Jest to zaledwie kilka pytań spośród tych, które mógłbyś zadać badaczowi zajmującemu się |psychologią fizjologiczną, to znaczy psychologowi, którego interesują przede wszystkim związki między zachowaniem i doznaniami a biologicznym funkcjonowaniem organizmu. W tym rozdziale zaczniemy systematyczne poznawanie genetycznych i fizjologicznych podstaw zachowania; naszym celem będzie dążenie do zrozumienia zachowania i procesów „psychicznych”. Aby jednak tego dokonać, będziemy musieli pamiętać, że w gruncie rzeczy jesteśmy istotami biologicznymi, złożonymi z bardzo wielu gruczołów, mięśni i innych struktur oraz posiadającymi układ nerwowy, który koordynuje działanie tych elementów i sprawia, że całe to „przedsiębiorstwo” funkcjonuje całkiem nieźle. Zrozumiawszy, jak elementy te rozwinęły się i jak funkcjonują, będziemy - być może - kiedyś zdolni ukierunkować przyszłość naszego gatunku w sposób bardziej konstruktywny i harmonijny.

Fizjologia otwiera „czarną skrzynkę”

Przez niezliczone stulecia filozofowie, teolodzy i laicy zadawali sobie pytanie, w jaki sposób świat zewnętrzny jest spostrzegany i reprezentowany w świadomości człowieka. Czy istnieje jakaś „dusza zwierzęca” (animal spirit) czy „fluid życiowy”, który pozwala „psychice” (mind) kontaktować się z właściwościami świata fizycznego? Średniowieczni uczeni borykali się z fałszywie postawionym zagadnieniem: w jaki sposób dusza człowieka kieruje jego spostrzeganiem. Ich usiłowania były nieuchronnie skazane na niepowodzenie - przede wszystkim dlatego, że zaczęli od postawienia niewłaściwych pytań i nie zdawali sobie sprawy z różnic między zagadnieniami z zakresu fizyki, fizjologii i psychologii.


Descartes i Helmholtz

Tym, który zaczął stawiać właściwie pytania w początkach XVII wieku, był francuski filozof i matematyk Rene Descartes (Kartezjusz), często zwany twórcą psychologii fizjologicznej. Za punkt wyjścia przyjął on pogląd, że organizm jest „zwierzęcą maszyną”, którą można poznać metodami naukowymi.  Descartes poruszał więc często fizjologiczne zagadnienia - problematykę mechanizmów funkcjonowania ciała - którą można oddzielić od zagadnień psychologicznych dotyczących tego, jak ludzie odczuwają, poznają czy doświadczają właściwości świata. Zrozumienie fizjologii widzenia wymagało zatem znajomości praw fizycznych, które rządzą przechodzeniem światła przez soczewki. Nacisk, jaki Descartes kładł na sprowadzenie złożonych procesów sensorycznych do ich fizycznego podłoża, określa się jako |mechanistyczne podejście do badania procesów fizjologicznych.
Współczesny Descartesowi był astronom Kepler, którego dokładne, oparte na matematycznych obliczeniach obserwacje ruchów ciał niebieskich dostarczyły mocnego poparcia dla rewolucyjnej teorii Kopernika. Kepler napisał o swych badaniach nad ruchem planet następujące słowa:
„Moim celem jest wykazanie, że niebieska maszyneria nie jest czymś w rodzaju żywej boskiej istoty, lecz jest podobna do mechanizmu zegarowego” (zob. Crombie, 1964).

Ponieważ Descartes był głęboko religijnym człowiekiem, nie mógł pominąć duszy w swej teorii funkcjonowania organizmu. Jednakże ze względu na swe przekonanie, iż właściwe jest mechanistyczne ujęcie percepcji i innych procesów zmysłowych, nie zgodził się z tym, że dusza kieruje tymi procesami. W jaki więc sposób udało mu się rozwiązać ten dylemat?
Rozwiązaniem postulowanym przez Descartesa był |dualizm, który miał na celu oddzielenie funkcji mechanistycznej ciała i mózgu od funkcji spirytualistycznej duszy i efemerycznej psychiki, dzięki czemu organizm i jego procesy stały się dostępne dla badań przyrodniczych. Chociaż zakładał on, że dusza jest zjednoczona z całym ciałem, to jednak nie mogła ona oddziaływać na wszystkie części ciała ani też podlegać oddziaływaniu wszystkich części. Gdyby mogła, to ciało nie byłoby doskonałą maszynerią, lecz raczej jakimś „nieobliczalnym mechanizmem”.
Descartes uważał, iż dusza i ciało oddziałują na siebie w jedynej części mózgu, która nie jest powtórzona w obu półkulach mózgowych, a mianowicie w |szyszynce. Zgodnie z jego poglądem, dusz oddziałuje na rozległą substancję ciała tylko w jednym miejscu, chociaż nie jest ograniczona do tego jedynie obszaru.

Zbliżenie
Stara szyszynka w nowym świetle


„Descartes, zgodnie z tym, co przedstawia zamieszczony obok drzeworyt z 1686 roku, był przekonany, iż informacje o świecie zewnętrznym są odbierane za pośrednictwem oczu i przez „postronki w mózgu” przekazywane do szyszynki. Gruczoł ten - wyjaśniał Descartes - jest napełniony „zwierzęcymi hormonami” (tzn. płynami organicznymi), które wylewają się, gdy bodziec świetlny dojdzie do szyszynki, powodując jej przechylenie się. Wówczas humory płyną przez „puste rurki” (włókna nerwowe) do mięśni, powodując ich rozkurczanie się lub kurczenie w odpowiedzi na bodźce napływające z otoczenia.
Od czasów Descartesa większość fizjologów było skłonna uważać szyszynkę jedynie za bezużyteczną pozostałość ewolucji - spełniającą jakieś funkcje we wcześniejszym okresie historii gatunku, lecz obecnie już niepotrzebną.  Jednakże nowsze badania wskazują, że Descartes, pomimo używania obrazowych pojęć („postronki”, „rurki”) mógł być bliski prawdy. W wyniku zakrojonej na szeroką skalę serii eksperymentów, które rozpoczęli w latach sześćdziesiątych Julius Axelrod i Richard Wurtman, powoli wyjaśniają się tajemnice tego maleńkiego, lekceważonego gruczołu skrytego w środku mózgu.  Podstawowe stwierdzenia tych badaczy nie tylko potwierdzają niektóre „prymitywne” idee Descartesa, lecz idą jeszcze dalej, przypisując szyszynce zadziwiająco szeroki zakres funkcji fizjologicznych.
Szyszynka zdaje się działać jako „biologiczny synchronizator”, który utrzymuje dostrojenie zwierzęcia do (jego) otoczenia, zmieniając procesy chemiczne zachodzące w mózgu stosownie do tego, czy jest dzień czy noc” (Luce, 1970). Stwierdzono, że ilość światła w otoczeniu zwierzęcia wpływa na wielkość szyszynki i jej czynność wydzielniczą. Lecz w jaki sposób światło może dojść do tego gruczołu ukrytego w ciemnościach mózgu?  Ustalono, że gdy światło wpada do oczu, sygnał wędruje okrężną trasą przez specjalny wzrokowy układ nerwowy (dolny szlak wzrokowy) i poprzez pośrednie „stacje przekaźnikowe” w pniu mózgu i niższych częściach mózgu dociera do szyszynki, wpływając na jej aktywność.
Szyszynka jest jedynym gruczołem wydzielającym |melatoninę, która wpływa na barwę skóry i sekrecję hormonów płciowych.

Stwierdzono ponadto, że gruczoł ten wytwarza wiele innych ważnych biologicznie substancji, między innymi |serotoninę - która odgrywa ważną rolę w wywoływaniu snu nocnego - oraz |noradrenalinę - niezbędną w przekazywaniu informacji sensorycznej przez układ nerwowy. Przypuszcza się, że związki te służące szyszynce jako substancje przekaźnikowe czy „posłańcy” (messengers), za pośrednictwem których informuje ona resztę mózgu o zmianach w czasie. Ten malutki biologiczny zegarek może zatem odgrywać decydującą rolę w oddziaływaniu na procesy chemiczne zachodzące w organizmie, emocje i zachowanie człowieka - wszystko to bowiem podlega zmianom, gdy po dniu następuje noc, a po jednej porze roku - inna (Wurtman, Axelrod i Kelly, 1968; Axelrod i Wurtman, 1970).

Jednakże aż do XIX wieku, to znaczy do czasu odkrycia (przez Galvaniego i Voltę) sposobu wytwarzania i przechowywania energii elektrycznej, nie można było wykazać, że „wola” działania i „działanie” są odrębnymi zjawiskami.  Drażniąc prądem elektrycznym kolejne punkty wzdłuż nerwu żaby, niemiecki fizjolog Helmholtz zmierzył okres opóźnienia między bodźcem a skurczem odpowiedniego mięśnia. Drażnił on również palec u nogi i udo człowieka, stwierdzając, że istnieje różnica między czasem potrzebnym do zareagowania na jeden i drugi bodziec. W obu wypadkach stwierdził, że trzeba było |czasu, aby bodziec wywołał reakcję - a w dodatku więcej czasu, gdy odległość była większa. Ku zaskoczeniu wszystkich, okazało się, że szybkość przesyłania impulsu nerwowego jest w istocie stosunkowo mała (mniej niż 27 m/s w nerwie ruchowym żaby). Do tego czasu wielu ludzi było przekonanych, że szybkość ta jest olbrzymia, większa nawet od szybkości światła.
Współczesny eksperymentator i historyk psychologii, E. A. Boring, napisał o doświadczeniu Helmholtza: „Wykazanie, że istnieje odstęp w czasie między ruchem a aktem woli, który go spowodował, było w pewnym sensie oddzieleniem ciała od psychiki i niemal od osobowości czy „jaźni” (1950, s.42).  Helmholtz utorował drogę badaniom, w których mierzy się czas reakcji w celu określenia, jak długo trwa namysł i inne zjawiska psychiczne (zob. Rozdział 5). Poruszył on także następne, bardziej złożone zagadnienia: nie ulegało wątpliwości, że reakcja na bodźce zostaje opóźniona w układzie nerwowym.  Lecz gdzie i w jaki sposób? Współcześni badacze, pracujący w dziedzinie psychologii fizjologicznej, ciągle jeszcze poszukują odpowiedzi na te pytania.

Redukcjonizm i inne podejścia

Zanim zapoznamy się z niektórymi fascynującymi badaniami i ideami w tej dziedzinie, warto może rozpatrzyć pokrótce pewne podstawowe różnice między sposobami podejścia, jakie w celu zrozumienia, przewidywania i sterowania zachowaniem stosują psychofizjologowie oraz psychologowie reprezentujący inne kierunki.
Psychofizjologowie w swym dążeniu do zrozumienia mózgu skłonni są dzielić go na części. Rozkładają zatem wszystko na części składowe - odruchy, impulsy nerwowe, reakcje chemiczne itd. Badacze, którzy pracują w tej dziedzinie, zakładają na ogół, że w ten właśnie sposób uzyska się ostateczne odpowiedzi.
Podejście to nosi nazwę |redukcjonizmu. Zakłada się w nim, że złożone akty i procesy najlepiej można zrozumieć przez badanie prostszych, neurologicznych lub biochemicznych jednostek analizy. W ten sposób badanie zachowania ludzkiego staje się analizą licznych struktur mózgowych, zbudowanych z komórek nerwowych, które z kolei składają się z substancji biochemicznych, i tak aż do atomów oraz elektronów.
Z podejściem redukcjonistycznym związane jest jednak pewne niebezpieczeństwo. W skutek wyodrębniania części z całości powstają nowe struktury, odmienne procesy i jedyne w swoim rodzaju zjawiska: części usunięte ze swego zwykłego kontekstu mogą już nie zachowywać się w ten sam sposób. Niektórzy psychologowie przyjmują więc podejście |holistyczne, utrzymując, że zachowanie powinno się studiować w kategoriach całego organizmu, a nie jego funkcjonujących części.
Wielu psychologów eksperymentalnych, na przykład profesor B. F. Skinner z Harvard Unieversity, zajmuje inne stanowisko, które jednak również jest niezgodne z redukcjonizmem fizjologicznym. Nie potrzeba, argumentuje Skinner, zaglądać do wnętrza „czarnej skrzynki” (organizmu zwierzęcego lub ludzkiego), aby móc przewidywać zachowanie i sterować nim. Czy musisz zaglądać do wnętrza swego radia lub telewizora i znać się na plątaninie przewodów w ich wnętrzu, aby sterować ich działaniem, ku swemu zadowoleniu?  Wcale nie. Wystarczy wiedzieć, które klawisze naciskać i którymi gałkami kręcić. Jeśli jednak z jakiegoś powodu aparat nie funkcjonuje właściwie, |ktoś będzie musiał wiedzieć, |jak dostać się do środka i naprawić go, abyś |ty mógł pozwolić sobie na pozostawanie w niewiedzy, co do zasad jego działania. Psychofizjolog jest jednym z wielu reprezentantów nauk medycznych, których interesuje przede wszystkim przedostanie się do wnętrza ludzkiej „czarnej skrzynki” w celu zrozumienia, jak ona funkcjonuje oraz co się dzieje wtedy, gdy coś jest nie w porządku.
Przedstawiciele jeszcze innego podejścia utrzymują, że zjawisk psychologicznych nie można przełożyć na fizjologiczne, ponieważ zjawisk świadomości nie można wyrazić w pełni w kategoriach neurologicznych. Z pewnością zjawiska biochemiczne i impulsy nerwowe stanowią podłoże doznań takich, jak piękno, zachwyt czy miłość, lecz czy są z nimi identyczne?  Jeśli nie, to coś zostaje utracone przy tym przykładzie.

Środowisko wyznacza zadania


„Życie nie jest nigdy materiałem, substancją do kształtowania. Jeśli chcecie wiedzieć - życie jest istotą samoodnawiania się; stale odnawia się i odtwarza, zmienia się i przekształca”.
Borys Pasternak
„Doctor Zhivago”, 1958

Aby zrozumieć zdolność przystosowawczą jakiegokolwiek gatunku, musimy zapytać, jaką umiejętność w sobie przyswoił, a to oznacza pytanie, jakie wymagania stawiało środowisko danemu organizmowi i w czasie, gdy ta umiejętność się rozwijała. Współczesna biologia uważa środowisko za aktywną siłę, która nieustannie wyznacza zadania organizmowi, zadania, które mogą zmieniać się radykalnie wraz z upływem czasu (Dobzhansky, 1957). Ze stu milionów gatunków zwierząt i roślin, które zamieszkiwały powierzchnię Ziemi od czasu pojawienia się pierwszych organizmów, zaledwie 2% utrzymało się dotąd przy życiu. Pozostałym nie udało się sprostać wymaganiom środowiska i wymarły, podobnie jak olbrzymie dinozaury.
Gdy jakiś gatunek ulega przekształceniom w nowym środowisku, nie dzieje się tak dlatego, że środowisko zmieniło genetyczną strukturę jednostek, jak kiedyś sądzono. Jeśli jednak potrzebne geny występują już u niektórych osobników, to ich potomstwo może przejść pomyślnie ten nowy środowiskowy test (sprawdzający, kto może przetrwać), podczas gdy inne osobniki tego gatunku lub inne gatunki giną.
Opisany powyżej ciąg zdarzeń można było obserwować niedawno w związku z zastosowaniem DDT. Większość owadów ginęła w zabójczym środowisku stwarzanym przez ten środek, lecz nieliczne z nich miały „wbudowaną” odporność genetyczną. Owady te przetrwały w środowisku nasyconym DDT i skojarzyły się w pary, podczas gdy inne osobniki tego gatunku zginęły. Geny wywołujące odporność zostały z kolei przekazane potomstwu. W ten sposób został „stworzony” odporny na DDT na szczep owadów.
Czy gatunek ludzki może przetrwać testy środowiskowe, które sam stwarza, wypełniając atmosferę promieniowaniem jądrowym, chemicznymi odpadami przemysłowymi, smogiem, promieniami Roentgena? Nie wiemy. Niestety, wszystkie te czynniki mogą powodować nie tylko choroby i śmierć, lecz także uszkodzenia genetyczne, które są przekazywane przyszłym pokoleniom.


Geny i mutacje


W jądrze każdej z miliardów komórek w organizmie człowieka występują |chromosomy. Bardziej poetycznie nazywa się je |nićmi |życia, ponieważ kierują one czynnościami komórek oraz umożliwiają wzrost i rozwój jednostki od jej poczęcia do wieku dojrzałego. To właśnie dzięki ich zdolności samopowielania się możliwe jest tworzenie nowych komórek w organizmie, jak również całych nowych osobników.
Chromosomy składają się głównie z DNA (kwasu dezoksyrybonukleinowego) i białek. Budowa chemiczna DNA jest prosta - są to długie łańcuchy składające się z par zasad nukleotydowych ułożonych w kształcie skręconej drabiny lub spiralnych schodów. Watson i Crick, którzy pierwsi zbadali budowę DNA, określili ją jako „podwójną spiralę” (1968).

* * *
Ryc. 2.3. Struktura DNA. Cząsteczka DNA w procesie replikacji rozkręca się, rozdziela wzdłuż, podobnie jak długi zamek błyskawiczny oraz wychwytuje odpowiednie nowe elementy z otaczającego ją płynu. Cząsteczka DNA jest tak maleńka, że wszystkie nitki DNA z komórek jajowych, które dały początek około 3 miliardom ludzi żyjących obecnie na świecie, zmieściłyby się w sześcianie o boku 37mm (Beadle, 1964).

* * *

|Geny są to łańcuchy tych zasad nukleotydowych, które funkcjonują jako jednostki dostarczające wielu rodzajów „instrukcji” dla rozwoju i funkcjonowania organizmu; istnieją tylko cztery takie zasady - |guanina, która wiąże się z |cytozyną oraz |adenina wiążąca się z |tyminą - lecz pojedynczy gen może zawierać tysiące tych jednostek połączonych w długi łańcuch.
Aby utworzyć nową komórkę, DNA w istniejącej komórce rozkręca się i rozdziela wzdłuż jak zamek błyskawiczny. Każda połówka spełnia następnie rolę matrycy i zestawia we właściwej kolejności uzupełniające zasady, które wybiera spośród nie związanych zasad znajdujących się w otaczającej cytoplazmie. Gdy proces ten zakończy się, komórka dzieli się na dwie nowe komórki, z których każda ma kompletny zestaw DNA. DNA zawiera także instrukcje dla wytwarzania białek, które są elementami składowymi organizmu.
Możemy snuć przypuszczenia na temat rozwoju życia i ewolucji, w świetle następującej „bio-logiki”. W pewnym punkcie czasu musiały się utworzyć pasma DNA złożone z sekwencji zasad - zdolne do wytwarzania użytecznych białek. Białka te umożliwiły komórce uzyskiwanie energii z rozkładu substancji odżywczych oraz reprodukcję - a więc utrzymanie się, wzrost oraz wystąpienie w ciągu wieków wielu rodzajów zmian w DNA.
Takie zmiany w DNA zwane są |mutacjami. Zmiana w pojedynczej zasadzie zawartej w cząsteczce DNA zmienia odpowiadającą zasadzie zawartej w cząsteczce DNA zmienia odpowiadającą jej sekwencję aminokwasów w białkach formowanych przez tę cząsteczkę. Niektóre mutacje powstają samorzutnie, inne są powodowane przez czynniki wywołujące skażenie środowiska. Mutacje mogą być korzystne, szkodliwe lub zgubne (letalne) dla organizmu lub jego potomstwa; większość mutacji jest szkodliwych.
W wypadku ludzi, większość strat wynikających z tych genetycznych „niewypałów” występuje w okresie po zapłodnieniu i we wczesnych stadiach ciąży, powodując znaczną śmiertelność płodów. Wśród dzieci, które utrzymały się przy życiu do czasu urodzenia się, u około 2% występuje wyraźne, dające się rozpoznać uszkodzenie genetyczne. Jest to tylko widoczny szczyt góry lodowej: dziedziczny charakter wielu pospolitych chorób sugeruje, że od ? do ? |wszystkich chorób jest pochodzenia genetycznego, istnieją bowiem znaczne różnice we wrażliwości ludzi nawet na skrajnie niekorzystne wpływy środowiskowe (Lederberg, 1971, s. 10).
Ponieważ każda komórka organizmu jest programowana przez DNA danego osobnika, przeto każda komórka jest podatna na mutację. Jeśli mutacja nastąpi w |komórkach |somatycznych, dotknie ona daną osobę, lecz nie będzie mieć żadnego wpływu na jej potomstwo. Podejrzewa się, że takie mutacje występują w białaczce, a także w procesie starzenia się; mogą one działać poprzez dezorganizację coraz większej liczby komórek somatycznych, w miarę jak tworzą się nowe, kalekie komórki. Gdy mutacja nastąpi w |komórkach |rozrdoczych - plemnikach lub komórkach - wówczas nie ma ona wpływu na organizm danej jednostki, lecz może przejść na jej potomstwo drogą reprodukcji płciowej.

Zbliżenie
Niedokrwistość sierpowata w dwóch środowiskach


Niedokrwistość sierpowata jest chorobą, w której czerwone ciałka krwi, rozprowadzające z krwiobiegiem tlen po organizmie, przybierają kształt sierpowaty zamiast zaokrąglonego. Sierpowate ciała krwi nie mogą prześlizgiwać się gładko przez naczynia włosowate, powodują zablokowanie ich, co w końcu pozbawia tkanki organizmu dopływu substancji odżywczych.  Większość osób dotknięta tą chorobą umiera młodo, często przed dwudziestym rokiem życia.
Ta śmiertelna choroba ma charakter dziedziczny; występuje ona prawie wyłącznie wśród Murzynów i tylko u tych jednostek, które otrzymały geny komórek sierpowaty od obojga swych rodziców. Dlatego też geny te są zwane genami „recesywnymi”, ponieważ u ludzi, którzy noszą tylko jeden taki gen, choroba ta nigdy się nie rozwija. Zgodnie z teorią genetyczną, każdy gen, który powoduje śmiertelną chorobę, powinien stać się rzadki, lecz w rzeczywistości anemia sierpowata występuje dość często. W niektórych regionach Afryki aż 35% ludzi jest jej nosicielami. Około 50 tysięcy Murzynów amerykańskich ma dwa geny sierpowatych ciałek krwi, a zatem cierpi na tę chorobę, a prawie 10% jest - jak się ocenia - jej nosicielami.
Teoria genetyczna stwierdza również, że kiedy jakiś stan tak zgubny jest jednocześnie tak powszechny, to musi on przynosić jakąś specjalną korzyść.  Na podstawie badań przeprowadzonych w ciągu ostatnich dwudziestu lat przyjmuje się obecnie powszechnie, że posiadanie jednego genu sierpowatych ciałek krwi zabezpiecza przed malarią. Niestety, cecha ta, która jest wysoce przystosowawcza w Afryce w związku z dużą liczbą zachorowań na malarię, może być bardziej niż bezużyteczna dla Murzynów w Ameryce.
Istnieją już testy diagnostyczne, które wykrywają obecność genu sierpowatych ciałek krwi; przyszli rodzice mogą więc uzyskać informacje, które pomogą im zadecydować, czy chcą podjąć ryzyko, że ich dziecko zapadnie na tę chorobę. W społeczności murzyńskiej w Ameryce istnieje kontrowersja co do celów, jakim miało służyć rozpowszechnienie tych testów.  Niektórzy mówią, że zapobiegają one tragicznemu marnotrawieniu ludzkiego życia; inni twierdzą, że wprowadzono je jako uzasadniony naukowo sposób obniżenia przyrostu naturalnego ludności murzyńskiej. Niedokrwistość sierpowata staje się zatem dość wyjątkowym zjawiskiem w medycynie, a mianowicie chorobą polityczną (Powledge, 1973).


Rozmnażanie płciowe a zdolność adaptacji


W czasie zapłodnienia dwie żywe |komórki |rozrodcze, męska - |plemnik i żeńska - |komórka |jajowa, łączą się dając początek nowej istocie. Komórki rozrodcze, męska i żeńska, w terminologii biologicznej są określane jako |gamety, a pojedyncza komórka, która powstaje z nich w chwili zapłodnienia - i z której rozwija się nowy organizm - nosi nazwę |zygoty. Zygota człowieka zawiera 46 chromosomów - po 23 od każdego z rodziców. Gdy z zygoty, w wyniku wielokrotnych podziałów, powstaje coraz to większa liczba komórek, wówczas przy każdym podziale chromosomy podwajają się, dzięki czemu w każdej nowej komórce nadal jest 46 chromosomów. Jedynym wyjątkiem od tej reguły są komórki rozrodcze, które w swym ostatnim podziale nie podwajają najpierw swych chromosomów, lecz po prostu dzielą je na połowę, tak, że każda nowa komórka ma połowę ogólnej liczby chromosomów. Te 23 chromosomy, znajdujące się w każdej komórce jajowej lub plemniku, reprezentują najrozmaitsze kombinacje spośród 46 dostępnych chromosomów.  Ogólna liczba możliwych kombinacji tłumaczy duże różnice genetyczne między dziećmi tych samych rodziców.
To właśnie związki płciowe między osobnikami różniącymi się pod względem niektórych swych genów są przyczyną ogromnej różnorodności, jaka istnieje w populacji. Ta |hybrydyzacja - kojarzenie się niepodobnych osobników - powoduje swobodne rozdzielanie istniejących genów i ich łączenie się w nowe układy. To właśnie seks zapewnia taką różnorodność wśród osobników wchodzących w życie, która w większości przypadków wystarczy, aby zagwarantować, że przynajmniej niektórzy przeżyją najsurowsze testy środowiskowe. Rozmnażanie płciowe można uznać za źródło nieskończonej różnorodności, oryginalności i indywidualności ludzi.
Każda zdrowa istota jest żywym świadectwem sukcesów, jeśli odnieśli jej przodkowie borykając się z zadaniami stawianymi im przez środowisko. Jej własna zdolność przystosowania się do wymagań środowiska jest po części zależna od złożonego zbioru interakcji, jakie zachodziły we wcześniejszych pokoleniach jej gatunku. Ewolucyjny charakter tej zdolności przystosowania się ilustrują powtarzające się cykliczne przebiegi, przedstawione schematycznie na rycinie 2.4.

Ewolucja - od „czegoś” do ciebie

Gdy obserwujesz organizm jednokomórkowy, na przykład pantofelka (paramecium), pływającego w mikroskopijnym zbiorniku wodnym, wydaje się nieprawdoodobne, że coś tak złożonego jak ty - z miliardami komórek (sam mózg zawiera 10ó,; komórek) - rozwinęło się z czegoś pozornie tak prostego. Nasi przodkowie uważali to również za nieprawdopodobne.  Holenderski badacz, Hartosoeker, obserwując w 1694 roku plemnik przez prymitywny mikroskop uznał, że to, co widzi, jest całkowicie ukształtowaną, miniaturową postacią ludzką, czyli homunculusem. Ta istota potrzebowała tylko pożywienia i czasu, aby rozwinąć się w dorosłego człowieka. Co więcej, sądzono, że w każdym homunculusie są malutkie komórki rozrodcze z jeszcze mniejszymi homunculusami; te z kolei zawierają jeszcze mniejszsze homunculusy i tak dalej; wyjaśniono w ten sposób zarówno rozwój indywidualny, jak i następstwo pokoleń.
Pociągająca prostota takich idei znalazła również swój wyraz w teoriach głoszących, że wszelkie organizmy zostały kiedyś „zawarte” w pierwotnej komórce, aby „ujawniać się” później w miarę rozwoju gatunków.

* * *
Ryc. 2.4. Ewolucja Zdolności Przystosowawczej. Wpływ dziedziczności i środowiska kumulują się i przeplatają ze sobą nawzajem. Środowisko nieustannie stawia istniejący gatunek wobec swych wymagań. Tylko te jednostki, które zdolne są sprostać tym wymaganiom, utrzymują się przy życiu i rozmnażają - inne nie. W miarę upływu czasu zachodzą nowe mutacje, niektóre letalne, niektóre szkodliwe, przystosowawcze, niektóre bez żadnych bezpośrednich skutków. Ponieważ reprodukcja seksualna łączy te stopniowo zmieniające się geny w coraz to nowe kombinacje, więc gatunek stopniowo zmienia się. Środowisko nadal stawia swe wymagania, często stwarzając nowe problemy, i znów tylko te jednostki, które potrafią utrzymać się przy życiu i rozmnażać się, przekazują potomstwu swe dziedziczne wyposażenie.

Ryc. 2.5. Ten rysunek plemnika, wykonany przez Niklaasa Hartsoekera, przedstawia kompletnie ukształtowaną, miniaturową istotę ludzką.
Zdjęcie ukazuje rzeczywisty wygląd plemników silnie powiększonych za pomocą nowoczesnych technik fotograficznych.

Ryc. 2.6. Fotografie te pokazują rozwijający się zarodek ludzki w 34 i 44 dni od chwili poczęcia. W 34 dniu zaczynają się rozwijać rysy twarzy, ręce i stopy oraz kształtują się narządy wewnętrzne. Gdy zarodek ma 44 dni, wówczas posiada już wszystkie te części ciała i narządy, które będzie mieć jako dorosły człowiek, chociaż nie ma jeszcze cala (2,57cm) długości.  Widoczne są zaczątki palców u rąk i nóg, gałek ocznych, zębów i języka. Po 150 dniach płód będzie kompletnie ukształtowany. Przez dalsze cztery miesiące, do chwili urodzenia się, będzie on nadal rósł i dojrzewał.

* * *
Teorie takie uznają ewolucję za stopniowe ujawnianie się utajonych form preegzystującego życia, który to proces nosi nazwę |ortogenezy.
Arystoteles wysunął alternatywny pogląd, bardziej zgodny z tym, co odkryto w badaniach nad rozwojem zarodkowym. Sądził on, iż narządy kształtują się stopniowo z prostych, początkowo niezróżnicowanych substancji znajdujących się w zapłodnionej komórce jajowej. Nazwał ten proces |epigenezą, który to termin jest nadal używany przez embriologów.
Zanim przystąpimy do rozpatrywania epigenetycznych interakcji, które przez zróżnicowanie zapłodnionej komórki jajowej prowadzą do powstania wyspecjalizowanych tkanek organizmu, moglibyśmy zapytać, dlaczego pierwsze organizmy nie pozostały jednokomórkowcami, lecz w wyniku ewolucji przekształciły się w pierwotniaki, robaki, ryby, gady, ssaki i ludzi.

Zbliżenie
Z niebios w dół... czy z błota w górę?


Publikując w 1859 roku swą słynną książkę „The Origin of Species by Natural Selection” („O powstawaniu gatunków drogą doboru naturalnego”), Karol Darwin wstrząsnął podstawami uznawanych ówcześnie poglądów na pochodzenie życia na naszej planecie - a zwłaszcza na pochodzenie człowieka. Przedstawiona przez Darwina teoria ewolucji była sprzeczna z ideą boskiego aktu stworzenia ukazanego w „Biblii w Księdze Genezis”:
„Na początku Bóg stworzył niebo i ziemię (...). Potem rzekł Bóg: Niech wyda ziemia istotę żywą według rodzaju jej: bydło, płazy i dzikie zwierzęta według rodzajów ich. I tak się stało (...). Potem rzekł Bóg: Uczyńmy człowieka na obraz nasz, podobnego do nas i niech panuje nad rybami morskimi i nad ptactwem niebios i nad wszelkim bydłem i nad całą ziemią* (*Tłumaczenie Komisji Przekładu. Warszawa 1979.) (...)” („Genezis” I: 1, 24, 26).
Ci, którzy interpretują biblijny opis stworzenia dosłownie, są przekonani, że Ziemia jest stosunkowo młoda - w jednej chwili powołana do bytu zaledwie sześć tysięcy lat temu z całym kompletem roślin i zwierząt.  Dane dotyczące rozpadu radioaktywnego, które wskazują, że Ziemia ma blisko trzy miliardy lat, są przez tych kreacjonistów lekceważone, jako wynik „specjalnych procesów stwórczych”, które sprawiają, że to się tylko wydaje w ten sposób” (Zob. Dolinar, 1973).
Ewolucjoniści wierzą w powolny, stopniowy proces rozwoju złożonych organizmów z jednokomórkowych przodków na zasadzie mutacji, który umożliwiał im przystosowanie do drastycznych zmian środowiskowych (w sposób naszkicowany już poprzednio). Głoszą oni teorię, iż życie powstało w oceanach już przed miliardami lat: (...) „pod zabójczym słońcem, w nasyconym amoniakiem oceanie nakrytym trującą atmosferą, w zawiesinie organicznych cząsteczek powstała przypadkowo cząsteczka kwasu nukleinowego, która mogła w jakiś sposób powołać do istnienia inną podobną do siebie” (Asimov, 1960).
Ostatecznie z cząsteczek tych ukształtowały się proste organizmy, z których w drodze ewolucji powstały ryby. Niektóre ryby mające płuca opuściły mroczne morza i wyszły na ląd, gdzie przekształciły się w gady; niektóre gady przekształciły się w ptaki, niektóre w ssaki; niektóre ze ssaków były małpami, a niektóre z nich przekształciły się w ludzi. Teoria ewolucji nie tylko zatem sugeruje, że „pochodzimy od małp”, lecz ponadto przedstawia nas jako istoty, które swą ciężką drogę „ku górze” rozpoczęły niegdyś, przed wiekami wychodząc z błota i mułu. „Zapisy” w postaci skamielin, które służą do poparcia tej teorii, są przekonywującym materiałem dowodowym dla jej zwolenników, natomiast kreacjoniści uważają, że w materiale tym jest pełno luk.
Na podstawie dostępnych danych większość uczonych sądzi, że teoria ewolucji oferuje bardziej prawdopodobne wyjaśnienie pochodzenia człowieka.  Wielu ludzi, zarówno naukowców jak i nienaukowców, jest przekonanych, że uznanie procesu ewolucyjnego nie wyklucza bynajmniej wiary w istnienie boskiego Stwórcy - bez względu na to, czy proces tworzenia został zakończony w siedem dni czy też trwał trzy miliardy lat.

Pojedyncza komórka

Organizm jednokomórkowy zdaje się zawierać wszystko, co potrzebne dla przetrwania: a) |cytoplazmę, substancję, w której zachodzi większość biochemicznych reakcji komórki i w której następuje przemiana substancji odżywczych w energię organizmu (|metabolizm); b) |błonę zewnętrzną, która oddziela wnętrze komórki od środowiska zewnętrznego i której skurcze umożliwiają przenoszenie się z miejsca na miejsce; c) |jądro, które kieruje czynnościami cytoplazmy, wytwarzając różne kwasy nukleinowe. Komórka może także dzielić się, dzięki czemu rozmnaża się i „unieśmiertelnia”.
Jednakże pojedyncza komórka nie ma możliwości przystosowania się do zmian w otoczeniu, które zakłócają jej zwykłe funkcjonowanie: ruchliwość komórki jest zbyt ograniczona, w sytuacjach gdy potrzebna jest szybka zmiana miejsca pobytu; komórka może mieć trudności z odżywianiem, ponieważ nie jest dość elastyczna, by syntetyzować nowe substancje (gdy nie ma dostępu do swego zwykłego źródła pożywienia), a nowe, powielone pojedyncze komórki, które wytwarza, będą nie lepiej przystosowane do zmieniającego się, wrogiego otoczenia niż komórka macierzysta.

Organizm wielokomórkowy

Jedynym rozwiązaniem, zapewniającym większą złożoność i elastyczność działania, jest organizm wielokomórkowy z wyspecjalizowanymi komórkami.  Każda komórka w twoim ciele również ma cytoplazmę, błonę komórkową i jądro, które spełniają ogólne funkcje opisane powyżej, lecz czynności tych komórek, a więc także ich budowa i sposób funkcjonowania, są wyspecjalizowane.


Zróżnicowanie, specjalizacja i redundacja komórek. Zróżnicowanie komórkowe ma charakter wysoce specyficzny: jeden system komórek wytwarza pewien odrębny produkt końcowy (np. nerki lub wątrobę), podczas gdy inny system wytwarza inny produkt końcowy (np. tkankę nerwową). W dodatku każdy system potrafi wytworzyć swój normalny produkt końcowy nawet wtedy, gdy warunki w trakcie jego rozwoju są nieco anormalne (ta regulacja oczywiście zawodzi, jeśli warunki |zanadto odbiegają od normy).
W obrębie tych systemów różne komórki przystosowały się do wypełniania znacznie różniących się funkcji. Receptory zmysłowe wyspecjalizowały się zatem w wykrywaniu na przykład bodźców wzrokowych, dźwięków i zapachów.  Komórki gruczołów wydzielania wewnętrznego wyspecjalizowały się w rozwijaniu skutecznych sposobów syntetyzowania hormonów za pośrednictwem działania enzymów. Błona komórki nerwowej wyspecjalizowała się w przenoszeniu informacji w taki sposób, że sama fizycznie się nie porusza. I tak dalej.
Te wysoce wyspecjalizowane funkcje poszczególnych typów komórek są powielane wielokrotnie w licznych komórkach, co stanowi swego rodzaju „margines bezpieczeństwa” - gwarantujący, że określone zadanie zostanie wykonane, nawet jeśli niektóre komórki ulegną uszkodzeniu.  Psychofizjologowie odkryli zatem, że nie tylko jest więcej zespołów komórek w mózgu i całym organizmie, niż ich potrzeba dla wykonywania różnych funkcji, lecz że istnieje również wiele funkcji niezbędnych dla utrzymania się przy życiu, które mogą być wykonywane nawet po usunięciu znacznej części mózgu.
To zwielokrotnienie czyli |redundancja zwiększa elastyczność organizmu, podczas gdy specjalizacja komórek zwiększa zakres sytuacji, na które może one reagować lub do których może się przystosować.
Lecz jakim kosztem „głupiutka” zrazu komórka uzyskała te pozytywne cechy? 
Jaką cenę trzeba było zapłacić za te korzyści?


Wymagania, jakie musi spełnić organizm wielokomórkowy. Gdy liczba komórek wzrasta i zaczynają one spełniać wyspecjalizowane funkcje, powstają nowe problemy. Zasadnicza trudność polega na tym, że komórki nie mogą już funkcjonować niezależnie od siebie, lecz muszą działać w sposób skoordynowany. Rozpatrzmy pewną analogię - wykonywanie pracy rocznej zupełnie samodzielnie lub wykonywanie jej wraz z grupą innych studentów.  Niektórzy w grupie mogą gromadzić literaturę przedmiotu, niektórzy - przeprowadzać badania w laboratorium lub wykonywać obliczenia statystyczne.  Niektórzy mogą wiedzieć, jak napisać pracę , inni potrafią pisać na maszynie. Gdy przygotowujesz pracę sam, wówczas wszystkie te czynności musisz wykonać samodzielnie; jeśli jednak praca jest wykonywana przez grupę, to ktoś musi koordynować indywidualne funkcje, aby produkt końcowy nie zawierał błędów i był gotowy na czas.
Albo też weźmy skromniejszy przykład, dżdżownicę pełzającą do przodu. 
Receptory znajdujące się w jej głowie wykrywają nagle szkodliwe bodźce.  Jeśli informacja ta nie będzie mogła być szybko przekazana do ogona, to ogon będzie poruszał się nadal, popychając głowę ku zgubie.


|Sprawnie |pracujące |i „szybko reagujące” neurony. Problem koordynacji i szybkiej komunikacji wewnętrznej, istotny dla złożonych, wielokomórkowych organizmów, został rozwiązany dzięki ewolucji wyspecjalizowanych komórek zwanych |komórkami |nerwowymi czyli |neuronami.  Neurony mają wszelkie ogólne cechy innych komórek i w dodatku są wysoce wyspecjalizowane w odbieraniu, przenoszeniu i przekazywaniu informacji w postaci elektrochemicznej. Te komunikaty o stanie środowiska zewnętrznego lub o reakcjach organizmu na to środowisko noszą nazwę |impulsów |nerwowych.
Neurony mają jedyną w swoim rodzaju zdolność przekazywania informacji na dużą odległość, bez zmniejszenia siły sygnału od chwili nadania go do czasu, gdy w końcu osiągnie on miejsce przeznaczenia. |Neurony |ruchowe sygnalizują mięśniom, aby rozkurczały się lub kurczyły, a gruczołom - by wydzielały; |neurony |czuciowe przekazują do mózgu informacje o zmianach w otoczeniu, dostarczone przez oczy, uszy, nos, skórę itd. Pośrodku, w mózgu i rdzeniu kręgowym, są różne rodzaje neuronów łączących i koordynujących.  Rozmaite typy neuronów różnią się znacznie wielkością i kształtem. Na rycinie 2.7. pokazano części „typowego” neuronu.

* * *
Ryc. 2.7. Anatomia Neuronu. |Ciało |komórkowe neuronu ma w przybliżeniu kształt sferyczny i zawiera w sobie |jądro. Z ciała komórkowego wychodzą dwa rodzaje włóknistych wypustek: jeden |akson i kilka |dendrytów. Akson jest to długie włókno, niekiedy rozgałęzione, które kończy się |stopkami |końcowymi (nazywane są one także |kolbkami |synaptycznymi). Długość aksonów różni się znacznie, zależnie od typu neuronu, niektóre mają kilka metrów długości. Akson przekazuje impulsy nerwowe z ciała komórkowego do dendrytów lub do ciał komórkowych innych neuronów, albo do mięśni. Duże aksony często są pokryte |osłonką |mielinową zbudowaną z substancji tłuszczowatej, która izoluje akson i przyspiesza przekazywanie impulsów nerwowych. Osłonki tej brak jest w punktach zwanych |przewężeniami |Ranviera. (Średnice aksonu i osłonki mielinowej są na rysunku znacznie przesadzone w porównaniu z długością aksonu).
Dendryty są zwykle krótkie, liczne i rozgałęzione. Ich funkcja polega na odbieraniu impulsów nerwowych i przekazywaniu ich do ciała komórkowego.  Neurony tworzące łańcuch w rzeczywistości nie stykają się ze sobą. Między stopkami końcowymi jednego neuronu a dendrytami lub ciałem komórkowym drugiego znajduje się mikroskopijna szczelina, zwana |synapsą, przez którą impuls nerwowy musi „przeskoczyć”.

* * *
Przekazywanie przez kanały


Układ nerwowy można uważać za niezmiennie złożoną sieć komunikacyjną, która rozwinęła się aby zaspokoić potrzebę koordynacji wewnętrznej, gdy nastąpiła specjalizacja komórek. Jeśli przyjmiemy, że komunikacja jest niezbędna, to nasuwa się pytanie: „|W |jaki właściwie sposób różne części układu nerwowego porozumiewają się między sobą?”.
Aby lepiej zrozumieć ten układ, który wytworzył się w procesie ewolucji, można by rozpatrzyć wymagania, jakie musi spełniać godny zaufania system komunikacyjny. Przede wszystkim różne części tego systemu muszą być zdolne do wysyłania i odbierania informacji na dalekie odległości, szybko i dokładnie, bez strat lub zniekształceń. To wymaga jednego (lub więcej) wspólnego języka dla komunikacji pomiędzy częściami systemu. Po drugie, muszą być też środki umożliwiające przetwarzanie i integrację wielu różnych informacji.


Czy odebrano komunikat?

Chociaż szczegóły procesu przetwarzania informacji są bardzo skomplikowane (i jeszcze nie w pełni poznane), to jednak mechanizmy, dzięki którym komórka nerwowa reaguje na bodziec i przekazuje wiadomość innym komórkom, można opisać w dość prosty sposób.
Każdy neuron czuciowy jest zaprogramowany tak, by przekazywać informacje o pewnym specyficznym rodzaju energii (ciśnieniu, temperaturze, świetle, dźwięku) pochodzącej z bezpośredniego otoczenia. Energię tę wykrywa sam neuron czuciowy lub specjalne komórki receptorowe. Następnie jest ona przekształcana na „wspólny język” układu nerwowego, to znaczy |impuls |nerwowy. Impulsy nerwowe, przenoszące informacje o ciśnieniu, temperaturze, świetle i dźwięku, są zatem wszystkie do siebie podobne, gdy biegną wzdłuż wypustek neuronów czuciowych. To ich miejsce przeznaczenia w mózgu decyduje o tym, czy pod wpływem odbieranych bodźców widzimy, słyszymy, czy też odczuwamy zapach. Oprócz tych informacji w otoczeniu jest także mnóstwo energii pozbawionej znaczenia (irrelevant), zwanej |szumem.  Szczęściem dla nas, energia dochodząca do komórek receptorowych musi przekroczyć określony poziom, czyli |próg |pobudzenia, zanim neuron czuciowy zacznie się nią zajmować. Jeśli jednak już się nią zajmie, to zajmie się naprawdę.

Przewodzenie przez aksony. W każdej komórce nerwowej jony dwóch różnych pierwiastków chemicznych, sodu i potasu, znajdują się po obu stronach błony aksonu. Błona ta jest selektywnie przepuszczalna; jony potasu mogą przechodzić przez nią łatwiej niż jony sodu. W wyniku selektywnej przepuszczalności stężenie jonów sodu jest znacznie wyższe po stronie zewnętrznej, podczas gdy stężenie jonów potasu jest znacznie wyższe we wnętrzu aksonu. Z pewnych skomplikowanych powodów prowadzi to do powstania różnicy potencjałów między wnętrzem komórki a środowiskiem zewnętrznym, przy czym wnętrze aksonu przez większość czasu ma potencjał ujemny w stosunku do zewnętrznej powierzchni błony komórkowej. W tym stanie komórka jest w spoczynku; mówi się, że jest |spolaryzowana.
Gdy energia bodźca przekracza próg pobudzenia, wówczas następuje zmiana przepuszczalności błony komórkowej; jony sodu wnikają do wnętrza komórki, powodując |depolaryzację. Impuls nerwowy, odpowiadający tej depolaryzacji, biegnie wzdłuż aksonu jak ogień po żarzącym się loncie (z tą różnicą, że nagła zmiana dotyczy różnicy potencjałów, a nie temperatury).
Przez kilka milisekund po obudzeniu aksonu błona jest chwilowo niepobudliwa i akson nie może zostać pobudzony znowu, niezależnie od siły bodźca. Faza ta zwana jest |okresem |refrakcji |bewzględnej. Tuż przed powrotem błony do normalnego stanu następuje krótki okres, w czasie którego bodziec musi być silniejszy niż zwykle, aby wywołać następny impuls; nazywa się to |okresem |refrakcji |względnej.
Przewodzenie impulsów przez aksony jest szybsze wtedy, gdy średnica aksonu jest większa i gdy jest on otoczony tak zwaną |osłonką |mielinową.  Dla zwiększenia niezawodności i szybkości przewodzenia sygnałów przez aksony istnieje nawet specjalna |komunikacja ekspresowa”, dzięki której impulsy mogą przeskakiwać z jednego punktu do drugiego wzdłuż aksonu lub nawet omijać niektóre „przystanki” (są to punkty, gdzie osłonka mielinowa jest przerwana - noszą one nazwę |przewężeń |Ranviera; Tasaki, 1953).  Proces ten aktywizuje, prawie jednocześnie, kilka punktów wzdłuż aksonu.
Jeśli siła bodźca jest większa od progowej - trochę większa czy dużo większa - to akson reaguje zawsze tak samo. Akson albo zostaje pobudzony w pełni, albo wcale nie zostaje pobudzony; określa się to jako zasadę „|wszystko |albo |nic” Amplituda impulsu nerwowego jest dla danego aksonu zawsze taka sama, bez względu na siłę bodźca - dopóki bodziec jest nadprogowy. Cecha ta gwarantuje, że komunikat nie zaniknie, gdy wędruje z jednego końca włókna nerwowego w drugi - na tym systemie komunikacji możesz polegać.
Jeśli jednak sprawa tak się przedstawia, to niewątpliwie zastanawiasz się, w jaki sposób neuron przekazuje informacje o bodźcach |różnej intensywności. Trafne pytanie. Jedynie aktywność aksonu stosuje się do zasady „wszystko albo nic”. Napływające bodźce o różnej sile są koordynowane w postaci serii impulsów; wszystkie one mają tę samą amplitudę, lecz odstęp w czasie między nimi zmienia się; silniejszemu bodźcowi odpowiada więcej impulsów na sekundę. Ponadto, im silniejszy bodziec, tym więcej neuronów pobudzi.

* * *
Ryc. 2.8. Aksonowe Przewodzenie Impulsów.
Impuls wędruje wzdłuż aksonu, gdyż „zastawki” błony komórkowej są otwarte, dzięki czemu jony sodu mogą przenikać do wnętrza błony depolaryzując ją. Po przejściu impulsu ujemny potencjał zostaje przywrócony.
Szczyt „iglicy” odpowiada momentowi, w którym potencjał elektryczny staje się na tyle dodatni, by nastąpiło tak zwane „wyładowanie” (firing) aksonu.  Tuż po wyładowaniu, wtedy gdy wypływają z wnętrza komórki jonu potasu, następuje krótki okres refrakcji, kiedy to potencjał elektryczny błony staje się jeszcze bardziej ujemny niż zwykle. W tym okresie wyładowanie się aksonu jest trudne lub niemożliwe.
Informacja przekazywana jest w postaci liczby impulsów na sekundę i liczby aktywowanych neuronów. Gdy impuls raz zacznie biec wzdłuż aksonu, jego siła w zasadzie się nie zmniejsza.

* * *

Zbliżenie
Układ nerwowy a ryba najeżka


„|Neurotoksyny są to trucizny, które zabijają przez zaburzenie funkcji układu nerwowego. Żyjąca u wybrzeży Japonii ryba najeżka (puffer fish), z rodziny Tetraodontidae, ma w swej wątrobie i jajnikach niezmiernie silną neurotoksynę zwaną |tetradotoksyną, czyli TTX. Cząsteczki TTX „zatykają” malutkie „przejścia” w aksonie komórki nerwowej, umożliwiające normalnie jonom sodu wnikanie do wnętrza aksonu w czasie przepływu impulsu nerwowego; w ten sposób TTX blokuje wszelkie przewodzenie nerwowe. Ponieważ ta ogólna blokada obejmuje także mięśnie niezbędne dla oddychania, przeto już mała ilość TTX może spowodować śmierć przez uduszenie.
Ryba ta jest w Japonii uważana za przysmak. Podaje się ją w specjalnych restauracjach, a wszelkie prace przy jej przyrządzaniu wykonują kucharze licencjonowani przez państwo, którzy są specjalistami w usuwaniu trujących organów. Niemniej jednak każdego roku umiera kilkoro ludzi wskutek reakcji na maleńką ilość trucizny, jaka zwykle występuje w potrawach z tej ryby.  Podobno prawdziwy smakosz delektuje się uczuciem lekkiego zdrętwienia i mrowienia w ustach, jakiego doznaje się podczas spożywania potraw z najeżki: zdrętwienie to jest spowodowane częściową blokadą niektórych nerwów czuciowych. (Jeśli zdrętwienie utrzymuje się lub rozszerza, zgłoś się natychmiast do lekarza!).”

Przekazywanie przez synapsy. Przewodzenie imuplsów przez aksony jest ważne ze względu na szybkie, bezbłędne dostarczenie zakodowanej informacji; jednakże prawdziwym kluczem do zrozumienia złożoności i subtelności informacji przesyłanej przez nasz układ nerwowy są czynności zachodzące w |synapsach - mikroskopijnych szczelinach między stopkami końcowymi jednego neuronu a |dendrytami lub ciałem komórki następnego neuronu (lub neuronów).  Na naszych uproszczonych wykresach i w podręcznikowych opisach przedstawiamy zwykle pojedynczy neuron wysyłający coś w rodzaju komunikatu zakodowanego alfabetem Morse’a („kropka-kropka-kropka”), który to komunikat powiadamia, iż pojawił się bodziec. Zastanów się jednak przez chwilę nad twymi odmiennymi reakcjami na ten sam bodziec w postaci błyskającego światła wozu policyjnego, w zależności od tego, czy przekroczyłeś dozwoloną prędkość, czy też potrzebujesz pomocy. Energia bodźcowa jest identyczna w obu przypadkach - komunikaty krążące w twoim układzie nerwowym z pewnością identyczne nie są. Albo też - w jaki sposób wykraczamy poza wykrywanie obecności bodźca (typu „tak/nie”) i spostrzegamy piękno letniego zachodu słońca, twarz przyjaciela w zatłoczonej sali wykładowej, wzór na tkaninie dekoracyjnej lub różnice między muzyką Mozarta, Mantovaniego i Rolling Stonesów?
Częściowym wyjaśnieniem tego jakościowego bogactwa przekazywanej informacji i naszych reakcji na nią jest fakt, że układ nerwowy to sieć złożona z astronomicznej liczby miliardów neuronów, z których każdy ma setki punktów odbiorczych na swym ciele komórkowym i dendrytach. W każdym z tych punktów zakodowana informacja przychodząca z poprzedniego aksonu może zostać zahamowana, przekazana szybciej lub wolniej do następnego neuronu, dodana do podobnej informacji dochodzącej w tym samym czasie do synapsy z innych aksonów lub odjęta od niej.
Synapsa, mikroskopijna szczelina o szerokości około 0,0001 mm, jest w 
istocie może najbardziej zadziwiającym wynalazkiem natury. Dzięki temu, że 
nie ma bezpośredniego połączenia między dwoma neuronami, lecz każdy jest 
połączony za pośrednictwem synaps z setkami innych, natura umożliwiła 
równoczesne przekazywanie bardziej złożonych komunikatów do wielu części 
całego systemu, a także funkcjonowanie tego systemu nawet wtedy, jeśli 
wiele neuronów zostało uszkodzonych. Istnieje pewna analogia między tymi 
„urządzeniami odbiorczymi” a dużymi centralami telefonicznymi, które mogą
jednocześnie przyjmować setki wywołań.

Nawet jeśli kilka kabli wchodzących do centrali zostało przeciętych, zerwanych lub uszkodzonych, wiadomość może jednak zostać przekazana.
Impuls nerwowy dochodząc do stopek końcowych (kolbek synaptycznych) na końcu aksonu, powoduje wydzielanie znikomych ilości chemicznych |substancji |przekaźnikowych (ryc. 2.9). Substancje te dyfundują przez szczelinę synaptyczną i oddziałują na specjalne obszary receptorowe znajdujące się na błonach sąsiednich neuronów. Mogą one wływać |pobudzająco lub hamująco na |błonę |postsynaptyczną następnego neuronu. Sygnał może być przesłany wzdłuż nowego aksonu, lub też depolaryzacja błony może ulec zahamowaniu, co nie pozwala przekazać sygnału dalej.

* * *
Ryc. 2.9. Wykonanie zdjęcia było możliwe dzięki nowej technice: 
skanningowej mikroskopii elektronowej specjalnie przygotowanej tkanki.  Pokazuje ono stopki końcowe wielu aksonów stykające się z czymś, co zdaje się być ciałem komórkowym.
Na drugim zdjęciu mamy znacznie powiększony obraz jednej synapsy, na którym widzimy stopkę końcową aksonu, dendryt innego neuronu oraz wąziutką szczelinę między nimi. Możesz także dostrzec skupisko pęcherzyków, w których znajduje się chemiczna substancja przekaźnikowa. Tego rodzaju skupiska pęcherzyków pozwalają badaczom określić, w jakim kierunku impuls może przepływać przez synapsę.

* * *
Jednakże „nieobecność” części przychodzącego komunikatu również jest informacją, podobnie jak jest nią czerń („nieobecność” światła) w czarno-białym wzorze.
Chociaż mówiliśmy, że jeden neuron aktywuje drugi, w rzeczywistości jest nieco inaczej. Ilość chemicznej substancji przekaźnikowej, wydzielonej na skutek pojedynczego impulsu nerwowego, nie wystarcza na ogół do wywołania drugiego impulsu. Drugi neuron bywa zwykle aktywowany przez więcej niż jedno czynne zakończenie nerwowe. Pobudzenia otrzymywane z kilku różnych aksonów sumuje się, dzięki czemu może powstać wystarczająco duży potencjał postsynaptyczny. |Sumowanie |przestrzenne obejmuje kilka pobudzeń, które pojawiają się jednocześnie, natomiast sumowanie czasowe obejmuje kilka pobudzeń, które pojawiają się w krótkich odstępach czasu jedno po drugim.  Przy przekazywaniu przez synapsę wchodzą zatem w grę pobudzenia o różnej sile; mówi się, że stosuje się ona do |zasady „|więcej |albo |mniej”.
Ta konieczność sumowania w procesie przekazywania synaptycznego oznacza, że informacja z wielu różnych neuronów zostaje zintegrowana i przesłana dalej w nowej postaci. Możliwych jest oczywiście wiele różnych rodzajów interakcji między oddziaływaniami pobudzającymi i hamującymi, co w uproszczeniu pokazano na rycinie 2.10.

Gdy substancja przekaźnikowa wykona już swoje zadanie, wówczas konieczne jest usunięcie jej z synapsy, gdyż inaczej nadal oddziaływałaby na błonę ciała komórkowego. Zostaje więc wydzielony enzym, który niszczy substancję przekaźnikową rozkładając ją na części składowe. Następnie, z części tych znowu jest syntetyzowana substancja przekaźnikowa i cały proces może zacząć się od początku - co najmniej setki razy na sekundę!
Dotychczas nie wiadomo dokładnie, ile różnych substancji przekaźnikowych funkcjonuje w układzie nerwowym; może być ich pięć lub więcej, lecz dostępny materiał dowodowy potwierdza zdecydowanie szerokie rozpowszechnienie dwóch - |noradrenaliny (zwanej także norepinefryną) i |acetylocholiny.
Zmiany w stężeniu tych substancji chemicznych mogą wpływać na to, czy dana jednostka na zadania stawiane jej przez środowisko reaguje szybko i skutecznie, czy też zbyt silnie i nieproduktywnie. Anomalie w występowaniu tych i podobnych substancji biochemicznych mogą wywoływać u ludzi predyspozycje do poważnych zaburzeń psychicznych i emocjonalnych.


Ruch jednokierunkowy. W przekazywaniu jednego „komunikatu” mogą brać udział setki lub tysiące neuronów, a zasadniczy typ aktywności pojedynczej komórki nerwowej nieustannie powtarza się we wszystkich częściach ciała w związku z wieloma przebiegającymi jednocześnie komunikatami. Ponieważ liczba wzajemnych powiązań i interakcji sprawia, że złożoność układu nerwowego jest naprawdę zadziwiająca, musi zatem istnieć jakiś mechanizm, który nie pozwoliłby tym komunikatom rozchodzić się we wszystkich kierunkach i przeobrażać się w bezsensowny chaos informacyjny. Istotnie, aktywność wszystkich neuronów stosuje się do |prawa |przewodzenia |jednokierunkowego. Zakodowana informacja w postaci impulsów nerwowych wędruje tylko w jednym kierunku: od aksonu przez synapsę do dendrytów i ciała komórkowego następnego neuronu. Nie może ona przekroczyć synapsy w odwrotnym kierunku - od dendrytów do aksonów, ponieważ substancje przekaźnikowe, niezbędne dla przesłania impulsu przez szczelinę synaptyczną, znajdują się tylko w stopkach końcowych aksonu.

* * *
Ryc. 2.10. Wpływ Wejść Pobudzających i Wejść Hamujących. Różne wielkości i zestawienia wejść (inputs) oddziałujących na neuron ruchowy wywołują różne skutki. Pokazano tu w uproszczonej formie cztery możliwości.
(A - pierwsze włókno pobudzające; B - drugie włókno pobudzające; C - włókno hamujące; D - akson (wyjście); imp. - impuls; b.imp. - brak impulsu)
1. A-imp. B-b.imp. C-b.imp. D-b.imp. (wejście zbyt słabe)
2. A-imp. B-imp. C-b.imp. D-imp. (sumowanie)
3. A-imp. B-imp. C-imp. D-b.imp. (znoszenie się)
4. A-b.imp. B-b.imp. C-b.imp. D-b.imp. (próg podwyższony)
Zjawiska elektryczne w neuronach są takie same - niezależnie od tego, czy impulsy są przekazywane przez włókna pobudzające czy hamujące. Ich oddziaływania na następny neuron są różne, ponieważ na synapsie wydzielane są różne substancje chemiczne.
* * *

Sieć  wejścia-wyjścia: obwodowy układ nerwowy

Innym mechanizmem, pozwalającym uniknąć potencjalnego chaosu w tym gigantycznym systemie komunikacyjnym, jest zorganizowanie neuronów w obrębie układu nerwowego. W zasadzie układ nerwowy składa się z dwóch podsystemów, ośrodkowego i obwodowego. |Ośrodkowy |układ |nerwowy składa się z mózgu i rdzenia kręgowego. Jego funkcja polega na wiązaniu oraz integrowaniu - to dzięki niemu różne części ciała współdziałają ze sobą.  |Obwodowy |układ |nerwowy składa się z włókien nerwowych, które łączą ośrodkowy układ nerwowy z komórkami wrażliwymi na energię bodźców (|receptorami) oraz z mięśniami i gruczołami (|efektorami), które realizują przystosowawcze działania organizmu (ryc. 2.11).

* * *
Ryc. 2.11. Układ Nerwowy. Wszystkie neurony (lub części neuronów) |w |obrębie mózgu i rdzenia kręgowego tworzą ośrodkowy układ nerwowy; wszystkie neurony znajdujące się |poza |nimi składają się na obwodowy układ nerwowy. Wiele neuronów zaczyna się więc w jednym układzie, a kończy się w drugim.
Dwanaście ważnych nerwów układu obwodowego bierze początek w samym mózgu i dlatego noszą one nazwę nerwów |czaszkowych (chociaż jeden z nich, nerw |błędny, wędruje przez ciało i po drodze unerwia większość narządów wewnętrznych). Inne główne nerwy obwodowe łączą się z rdzeniem kręgowym między coraz to niższymi kręgami i mają bardziej zlokalizowane funkcje.

* * *
Często szereg aksonów (czyli |włókien nerwowych, jak się je zwykle nazywa) jest zebranych w wiązki, które wychodzą z tego samego punktu i biegną do wspólnego miejsca przeznaczenia. W ośrodkowym układzie nerwowym wiązki takie noszą nazwę |dróg lub |szlaków |nerwowych. Wiązki, które łączą ośrodkowy układ nerwowy z innymi częściami ciała, nazywają się |pniami |nerwowymi lub po prostu |nerwami i zawierają zarówno włókna czuciowe, jak i ruchowe.
Są także w mózgu pewne miejsca, zwane |jądrami, gdzie skupione są ciała komórkowe (a więc i ich jądra). Wreszcie cały ten zbiór neuronów jest opleciony siecią neurogleju złożonego z |komórek |glejowych, które odżywiają i chronią delikatne neurony. Niektórzy sądzą, że te (najpóźniej odkryte) komórki glejowe również odgrywają istotną rolę w funkcjonowaniu układu nerwowego, jednakże nie zostało to jeszcze dowiedzione.
Obwodowy układ nerwowy zawiera zarówno komponenty |somatyczne, którym podlegają mięśnie szkieletowe, jak i komponenty |trzewne (wisceralne), które zawiadują działaniem gruczołów, mięśnia sercowego oraz mięśni wewnętrznych. Wszystkie synapsy neuronów wchodzących w skład układu somatycznego znajdują się w mózgu i w rdzeniu kręgowym; neurony części trzewnej zawsze mają synapsy |poza ośrodkowym układem nerwowym. Ośrodki kontrolujące oba te układy są zlokalizowane w mózgu, z tą ważną różnicą, że trzewne ośrodki kontroli znajdują się głównie w niższych, ewolucyjnie starszych częściach mózgu, podczas gdy somatyczne ośrodki kontroli znajdują się w strukturach wyższych (aczkolwiek starsze struktury również mają wpływ na czynności ruchowe). Kierowanie mięśniami szkieletowymi może być zatem albo dowolne, albo odruchowe, natomiast bez specjalnego treningu dowolne kierowanie funkcjami trzewnymi jest możliwe jedynie w bardzo małym stopniu.  Zasady tego specjalnego „treningu trzewnego” zostaną opisane w następnym rozdziale.

Komponenty somatyczne. Chociaż neurony czuciowe i ruchowe wysyłają impulsy w przeciwnych kierunkach - neurony czuciowe do rdzenia kręgowego, neurony ruchowe od rdzenia - to jednak przez większą część swej długości biegną one w tych samych pniach nerwowych. Wchodzą one zatem do rdzenia kręgowego lub wychodzą z niego na tym samym poziomie, a włókna ruchowe kończą się w mięśniach lub w pobliżu mięśni niezbyt odległych od receptorów, które aktywizują komponenty czuciowe.
Ciała komórkowe neuronów czuciowych leżą w pobliżu rdzenia kręgowego, a ich aksony wchodzą do rdzenia.

Oznacza to, że dendryty niektórych neuronów czuciowych, takich jak te, które biegną z rąk lub nóg, będą bardzo długie. Większość innych neuronów, jak widzieliśmy, ma bardzo krótkie dendryty i dłuższe aksony. Dendryty i ciała komórkowe neuronów ruchowych mieszczą się w rdzeniu kręgowym; jedynie ich aksony wychodzą na zewnątrz rdzenia (ryc. 2.12).
* * *
Ryc. 2.12. Rodzaje Neuronów. Przedstawiono tu trzy rodzaje neuronów: a) neuron czuciowy (aferentny), różniący się od większości neuronów tym, że ma długi dendryt i stosunkowo krótki akson; b) neuron pośredniczący (interneuron) z wieloma drobnymi rozgałęzieniami, dobrze dostosowany do swej funkcji - zapewniania wielorakich połączeń między wieloma neuronami, wreszcie c) neuron ruchowy, z długim aksonem przebiegającym większość drogi w tym samym pniu nerowym, co akson neuronu czuciowego i kończącym się w efektorach, blisko źródła wejścia sensorycznego. Z tego rodzaju łuku: wejście sensoryczne - wyjście ruchowe, wszystkie synapsy znajdują się w rdzeniu kręgowym.
* * *
Komponenty trzewne. Część trzewna obwodowego układu nerwowego nosi nazwę |autonomicznego |układu |nerwowego. Chociaż niektóre funkcje kontrolowane przez ten układ, na przykład trawienie, są istotnie autonomiczne i regulują się same, to jednak inne funkcje, zwłaszcza związane z odczuwaniem i wyrażaniem |emocji, nie są autonomiczne.
Układ autonomiczny dzieli się na dwie części - |układ |sympatyczny (|współczulny) i |parasympatyczny (przywspółczulny), które biorą początek w różnych odcinkach pnia mózgu i rdzenia kręgowego i których funkcje są często wzajemnie przeciwstawne.

„Układ sympatyczny” (współczulny). W tej części układu autonomicznego włókna nerwowe biorą swój początek jedynie w środowym odcinku rdzenia kręgowego - w segmentach znajdujących się między szyjnym a dolnym odcinkiem kręgosłupa. Nerwy te dochodzą jedynie do pobliskiego pionowego łańcucha |zwojów |nerwowych (skupiska ciał komórkowych neuronów); po każdej stronie rdzenia kręgowego leży jeden taki łańcuch. Następnie włókna biegną w górę i w dół tego łańcucha, łącząc się synapsami z neuronami, które prowadzą do narządów wewnętrznych.
Nazwa układu sympatycznego wynika stąd, iż dawni anatomowie byli przekonani, że to dzięki niemu narządy wewnętrzne działają zgodnie i harmonijnie. Układ ten, gdy zostaje aktywowany, istotnie funkcjonuje zwykle jako skoordynowana całość („wprowadza do gry” wszystkie funkcje, którymi kieruje, lub ich większość). Układ sympatyczny można uznać za „pogotowie awaryjne”, które przystępuje do akcji w przypadku nagłej potrzeby. Działa on wtedy, gdy zagrożone jest życie, w trakcie wytężonego wysiłku lub intensywnych ćwiczeń, a także wtedy, gdy doznajemy tak silnych emocji, jak strach czy gniew. W gruncie rzeczy układ ten przygotowuje organizm do działania, przyspiesza rytm serca, powoduje uwolnienie przez wątrobę cukru, który może być wykorzystany przez mięśnie, pobudza wydzielanie adrenaliny, wstrzymuje procesy trawienne, dzięki czemu krew płynącą do żołądka może być skierowana do mięśni itd.

„Układ parasympatyczny” (przywspółczulny). W tym układzie włókna wychodzą z ośrodkowego układu nerwowego powyżej i poniżej włókien układu sympatycznego; stąd wywodzi się nazwa |parasympatyczny (para oznacza „obok”). Większość funkcji tego układu jest kontrolowana przez włókna, które biorą początek w pniu mózgu.
Układ parasympatyczny zawiaduje większością podstawowych funkcji życiowych. Zasadniczo zajmuje się on „pracami gospodarskimi” organizmu, takimi, jak trawienie, wydalanie produktów odpadkowych, ochrona układu wzrokowego i w ogóle zachowanie energii. W przeciwieństwie do układu sympatycznego układ parasympatyczny nie reaguje jako całość, lecz aktywizuje te funkcje, które są niezbędne w danym czasie.

„Koordynacja obu układów - sympatycznego i parasympatycznego”. Do większości narządów wewnętrznych w klatce piersiowej i jamie brzusznej docierają włókna nerwowe z obu układów, w takich wypadkach działanie ich jest zawsze przeciwstawne (antagonistyczne).

Jeśli jeden układ pobudza dany organizm do wzmożonej aktywności, to drugi hamuje czy osłabia jego aktywność. Na przykład układ sympatyczny hamuje procesy trawienne, podczas gdy układ parasympatyczny pobudza je. Jednakże są wypadki, gdy oba te układy są aktywne i działają kolejno. Przykładem takiego współdziałania jest męska reakcja seksualna: wymaga ona najpierw erekcji (funkcja parasympatyczna), a następnie ejakulacji (funkcja sympatyczna).

Połączenia: ośrodkowy układ nerwowy


Miliardy neuronów i synaps (wraz z substancjami przekaźnikowymi) zorganizowanych w funkcjonalne struktury w obrębie mózgu i rdzenia kręgowego tworzą |ośrodkowy |układ |nerwowy (OUN). Układ ten umożliwia łączenie ogromnej sieci receptorów zmysłowych i wstępujących, |aferentnych włókien nerwowych ze zstępującymi, |eferentnymi włóknami nerwowymi prowadzącymi do mięśni i gruczołów. Wejściowe drogi sensoryczne i wyjściowe drogi ruchowe są powiązane ze sobą w OUN siecią neuronów |asocjacyjnych (zwanych także neuronami |pośredniczącymi).
OUN nie jest jednak tylko czymś w rodzaju łącznicy telefonicznej czy tablicy rozdzielczej, ponieważ ponadto integruje i koordynuje „wejście”, to znaczy odbierane bodźce, z „wyjściem” - wykonywanymi reakcjami. Im wyższe miejsce w hierarchii ewolucyjnej zajmuje dany gatunek, tym wyżej rozwinięte są mechanizmy integracji i koordynacji. Pewne gatunki, u których rozwinął się wysoce wyspecjalizowany OUN, dysponują mechanizmami neuronalnymi pozwalającymi przechowywać zarówno informację sensoryczną, jak i informację dotyczącą konsekwencji przeszłych działań. Możliwe jest wówczas porównywanie przechowywanej informacji z aktualnym wejściem, a także reorganizowanie zarówno wejścia jak i wyjścia (twórczość) oraz przyszłego działania (przewidywanie).
Pewne części tego systemu są również zdolne do spontanicznej aktywności, bez względu na to, czy obecne jest wejście sensoryczne. W jaki sposób powstają „zmartwienia”, „marzenia”, „zadowolenie z siebie”, „nostalgia” i inne stany |wewnętrzne nie związane z bodźcami? Odpowiedzi na te pozornie proste pytania są bardzo złożone i jeszcze nie w pełni poznane.

Łuk czuciowo-ruchowy. Reakcja na bodziec przebiega według pewnego podstawowego wzorca. Najpierw bodziec jest wykrywany przez odpowiednie receptory; na przykład lekkie dotknięcie zostaje wykryte przez specjalne komórki w skórze. Potem |czuciowe |komórki |nerwowe przekazują tę informację do rdzenia kręgowego, gdzie zaczyna się proces ośrodkowego przetwarzania. Przetworzona informacja jest zwykle przekazywana do mózgu; tu podlega dalszemu przetworzeniu i zostaje „wybrana” określona reakcja.  Decyzja ta jest z kolei przesłana za pośrednictwem |ruchowych |komórek |nerwowych do odpowiednich efektorów, które wykonują reakcję behawioralną (na przykład dłoń odsuwa się od sprawiającego ból bodźca). Ten podstawowy wzorzec: |wejście sensoryczne - |ośrodkowy |układ |nerwowy - |wyjście |behawioralne znany jest jako |łuk czuciowo-ruchowy; w rzeczywistości powtarza się on wiele razy w każdym pojedynczym akcie bodziec-reakcja (ryc.  2.14).

* * *
Ryc. 2.14. Łuk Czuciowo-Ruchowy. Reakcja na bodziec wymaga wszystkich pięciu „kroków”, z wyjątkiem rzadkich przypadków, w których brak neuronu pośredniczącego w rdzeniu kręgowym. Reakcja nie będzie mogła wystąpić, jeśli bodziec jest zbyt słaby lub takiego rodzaju, na który receptory nie są wrażliwe, lub jeśli impuls nerwowy nie zdoła przejść przez którąkolwiek z synaps w łańcuchu, lub jeśli impuls dochodzący w końcu do mięśni albo gruczołów jest zbyt słaby, aby je aktywować, lub jeśli mięśnie nie są w stanie zareagować (na przykład z powodu zmęczenia).
Przedstawiono tu pojedynczy łańcuch z jednym neuronem pośredniczącym. W rzeczywistości ten prosty łuk powtarza się wiele razy w akcie bodziec-reakcja i zwykle neurony pośredniczące powodują zaangażowanie segmentów rdzenia kręgowego powyżej i poniżej tego segmentu.
Nie uwzględniono tu pewnej istotnej cechy zachowania sekwencyjnego - a większość naszych zachowań jest w rzeczywistości ciągłym działaniem, a nie tylko jednym układem bodziec-reakcja. Cechą tą jest |sensoryczne |sprzężenie |zwrotne, które wskazuje na konsekwencje naszego aktualnego „wyjścia ruchowego” lub na inne zmiany w otoczeniu. Sprzężeniem zwrotnym kierujemy się nieustannie - regulując nasze „wyjście” tak, aby sprostać zmieniającym się wymaganiom.

* * *
Odruchowa czynność rdzenia kręgowego. W przebiegu ewolucji rozwój „myślącego” mózgu nastąpił po ukształtowaniu się bardziej prymitywnego rdzenia kręgowego. Funkcje chronienia organizmu przed uszkodzeniem, podtrzymywania działalności narządów wewnętrznych i utrzymywania podstawy ciała mają podstawowe znaczenie dla przetrwania organizmu. Dlatego też funkcje te nie mogły czekać na rozwój mózgu i zostały wbudowane w rdzeń kręgowy. Można więc zrozumieć, dlaczego zwierzęta, którym chirurgicznie oddzielono mózg od rdzenia kręgowego (tzw. |odkorowanie) nadal mogą reagować na bodźce, a nawet występuje u nich proste uczenie się.
Jeśli uszczypnie się palec niemowlęcia, cofnie ono całą rękę.  Zlokalizowany bodziec (potencjalne niebezpieczeństwo) powoduje aktywację mięśni na dużym obszarze ciała dzięki sieci neuronów w rdzeniu kręgowym.  Sieć ta spełnia cztery zadania: a) umożliwia impulsom z pojedynczego receptora dotarcie do wielu mięśni (dywergegncja), b) sprawia, że ten sam mięsień może być użyty w odruchach zapoczątkowanych przez bodźce działające na wiele punktów skóry (konweregncja), c) rozciąga reakcję w czasie (dzięki pętlom sprzężenia zwrotnego) oraz d) powoduje, że impulsy zostają przesłane do mózgu (ryc. 2.15).

* * *
Ryc. 2.15. Koordynacja W Rdzeniu Kręgowym. Rdzeń kręgowy jest elastycznym układem rozdzielczym, w którym pierwszy stopień stanowi neuron uczuciowy.  Akson tego neuronu wchodząc do rdzenia kręgowego dzieli się na części wstępującą i zstępującą, od których odchodzą kolaterale (odgałęzienia) na każdym poziomie rdzenia kręgowego. Z kolei każde z tych odgałęzień może łączyć się z |neuronem |pośredniczącym, którego wypustki także biegną w górę i w dół rdzenia, na każdym poziomie wysyłając kolaterale do |neuronów |ruchowych. Ten typ rozdziału impulsów zwany jest |dywergencją.
Odwrotna zasada działania zwana jest |konwergencją. Impulsy z wielu neuronów aferentnych mogą w końcu dojść do tego samego neuronu ruchowego, przy czym system ten działa podobnie jak lejek. Dzięki konwergencji to samo włókno mięśniowe może uczestniczyć w wielu różnych odruchach.
Niektóre z neuronów pośredniczących tworzą |obwody |samowzbudzające |się.  Dzięki takim obwodom rewerberacyjnym, czyli |pętlom |sprzężenia |zwrotnego, chwilowy bodziec może powodować reakcję, która trwa długo po ustaniu tego bodźca. Wpływ takiej pętli sprzężenia zwrotnego może być albo pobudzający, albo hamujący.
Ponadto niektóre neurony pośredniczące i kolaterale neuronów aferentnych (wstępujących) tworzą długie obwody przekazujące impulsy do mózgu. W ten sposób mózg („kwatera główna”) jest informowany na bieżąco i może modyfikować aktywność prostszych łuków odruchowych.

* * *
Na jakiej podstawie układ nerwowy decyduje, który z wielu jednoczesnych komunikatów zostanie przekazany najszybciej, a które zostaną opóźnione czy wstrzymane? Na przykład można być głodnym, zmęczonym, znudzonym, mieć bolący ząb i zostać użądlonym przez pszczołę - wszystko w tym samym czasie.  Który komunikat otrzymałby priorytet i w jaki sposób? Prosta odpowiedź jest następująca: pierwszeństwo mają bodźce bólowe, silne bodźce lub bodźce o szczególnym znaczeniu dla organizmu, natomiast bodziec ciągle działający przestaje nas pobudzać, a powtarzana reakcja może ustąpić reakcji konkurencyjnej. Pełniejsza odpowiedź wymaga zapoznania się z tajemnicami |orientacji i |habituacji.


Reagować czy przyzwyczaić się? Oto jest pytanie


W świecie pełnym niezmiernie licznych i różnorodnych dźwięków, świateł, zapachów i innych bodźców nieustannie oddziałujących na nasze receptory zmysłowe potrzebny jest nam system detekcji środowiskowej, który by alarmował nas w wypadkach możliwego zagrożenia, nie reagując jednocześnie na szum ani na bezużyteczne nonsensy. Orientacja i habituacja są mechanizmami, które służą tym potrzebom. Chociaż reakcja orientacyjna występuje w pewnej formie u wszystkich gatunków, to jednak u zwierząt wyżej rozwiniętych zaznacza się ona wyraźniej niż u organizmów prostszych.

Ponadto wyższe zwierzęta wykazują także szybszą habituację, ponieważ są w stanie uzyskać więcej informacji z jednej ekspozycji bodźca.

Reakcja orientacyjna, czyli reakcja „co to takiego?” Mechanizm, dzięki któremu organizm zwraca uwagę na zmiany w stymulacji środowiskowej, nosi nazwę |reakcji |orientacyjnej.

„Komponenty reakcji orientacyjnej”. Pozornie prostemu zwróceniu się w stronę źródła stymulacji towarzyszy wiele zmian wewnętrznych. Spełniają one podwójną rolę, a mianowicie zwiększają maksymalnie wrażliwość na napływającą informację, jednocześnie przygotowując organizm do natychmiastowego działania. Do komponentów reakcji orientacyjnej należą:
1. |Wzrost |wrażliwości. Progi: słuchowy i wzrokowy zostają obniżone (dzięki czemu reakcja występuje na słabsze bodźce niż te, które są zazwyczaj potrzebne), źrenice rozszerzają się, aby wpuścić więcej światła, zwiększa się też zdolność rozróżniania podobnych bodźców.
2. |Zmiany |w |określonych |mięśniach |szkieletowych. Zależnie od gatunku działają różne mięśnie, które skierowują narządy zmysłowe; odwracają głowę, ześrodkowują oczy, nadstawiają uszy itd.
3. |Ogólne |zmiany |mięśniowe. Wykonywane w danym momencie czynności ulegają zawieszeniu, wzrasta ogólny tonus mięśniowy, nasila się aktywność elektryczna w mięśniach.
4. |Zmiany |w |czynności |bioelektrycznej |mózgu. Rytm czynności elektrycznej mózgu zmienia się - dominują fale o stosunkowo wysokiej częstotliwości i niskiej amplitudzie - charakterystyczne dla zwiększonego pobudzenia.
5. |Zmiany |w |narządach |wewnętrznych. Naczynia krwionośne w kończynach zwężają się, natomiast w głowie - rozszerzają się. Wystęuje reakcja skórno-galwaniczna (RSG), to znaczy zmiana oporności elektrycznej skóry, oddychanie staje się głębsze i powolniejsze, a tempo pracy serca (u człowieka i niektórych zwierząt) maleje.

„Warunki wywołujące reakcję orientacyjną”. Dla uproszczenia możemy wyróżnić trzy klasy bodźców, które wywołują reakcje orientacyjne (na podstawie klasyfikacji opracowanej przez Barlyne’a, 1960).
1. |Bodźce |nowe |lub |złożone. Zjawiska różne od tych, które występowały w niedawnych doświadczeniach lub następujące po sobie w nowej kolejności, stanowiące „niespodziankę”, wywołują reakcję orientacyjną. U małp, które nauczono znajdować banan pod miseczką, występowała silna reakcja orientacyjna, gdy zamiast banana znajdowały tam sałatę (Tinklepaugh, 1928).
Reakcję orientacyjną wywołują ponadto bodźce o średniej lub dużej sile, bodźce różnobarwne, a także figury złożone lub niespójne.
2. |Bodźce |konfliktowe. Gdy organizm musi dokonać trudnego rozróżnienia percepcyjnego między podobnymi zjawiskami bodźcowymi, z których jedno zostało skojarzone z konsekwencjami pozytywnymi, a drugie z negatywnymi, wówczas występują silne reakcje orientacyjne. Konflikt między wymaganymi reakcjami ruchowymi lub werbalnymi może również wywołać reakcję orientacyjną.
3. |Bodźce |znaczące (|sygnałowe). Gdy pewien bodziec uzyskał specjalne znaczenie dla danej jednostki, wówczas jego pojawienie się wywołuje reakcję orientacyjną. Co więcej, wywołuje ją, mimo że się powtarza, nie jest nowy i nie powoduje żadnego konfliktu. Twoje własne imię, „Uwaga” i „Niebezpieczeństwo” (czy to w postaci napisu czy wypowiedzianego słowa) - oto przykłady tej klasy bodźców, które nie przestają wywoływać reakcji orientacyjnej, podczas gdy wiele bodźców pozbawionych znaczenia, które są podawane równie często, nie wywołuje żadnej reakcji.
O doniosłości reakcji orientacyjnej dla przetrwania świadczy fakt, że dla każdego gatunku istnieją bodźce o specjalnym znaczeniu, które nieodmiennie wywołują zachowanie orientacyjne. Na przykład szelesty wywołują u zajęcy silną reakcję orientacyjną, która nie słabnie w ciągu 20 powtarzajnych prób, podczas gdy psy domowe reagują na takie bodźce bardzo słabo. Podobnie sowy nie przestają wykazywać reakcji orientacyjnej na widok kotów, bobry - na dźwięk rozłupującego się drzewa, a ryby - na dźwięk pluskających fal (Klimowa, 1958). Nie wiadomo, czy takie reakcje są wbudowane genetycznie, czy też są skutkiem uczenia się we wczesnym okresie życia.

Habituacja: reakcja „cóż w tym nowego?”. Większość bodźców przestaje wywoływać reakcję orientacyjną, jeśli powtarzają się w identycznej postaci.  W wyniku takiego powtarzania organizm niejako |przyzwyczaja |się do bodźca, zarówno fizjologicznie jak i psychicznie, i przestaje na niego reagować.  Dzieje się tak, jak gdyby bodziec przestawał istnieć, gdy już nie przynosi nowej ani znaczącej informacji, mającej potencjalną wartość dla organizmu.
Powtarzające się bodźce, nawet o umiarkowanym natężeniu, mogą wywoływać senność a w końcu sen (musiałeś tego doświadczyć w czasie czytania niektórych podręczników lub słuchania wykładów, wygłaszanych jednostajnie i monotonnie). Wykazano, że wiele osób dorosłych, normalnych i dobrze wypoczętych, zapada w sen już po ośmiu minutach oddziaływania powtarzających się bodźców (Gastant i Bert, 1961).
Osłabienie reakcji na ciągle działający bodziec jest niekiedy wynikiem adaptacji receptorów (zwanej |adaptacją |sensoryczną) lub zmęczenia mięśni.  |Habituację definiuje się natomiast jako zmniejszenie intensywności reakcji spowodowane pewnego rodzaju zmianą w ośrodkowym układzie nerwowym, nie zaś w receptorach lub efektorach obwodowych. Można ją mierzyć rejestrując spadek siły lub amplitudy ruchu ciała albo też zmiany w czynności bioelektrycznej mózgu, lub zmiany w ciśnieniu krwi. Habituacja, określona w najprostszych terminach fizjologicznych, oznacza, że przekazywanie informacji sensorycznej przez drogi ośrodkowe jest zredukowane.
Taka redukcja przekazywania ośrodkowego może dojść do skutku tylko dwoma sposobami: albo występuje pewien rodzaj swoistego |zmęczenia w samych drogach, lub też droga przekazywania jest |zablokowana przez oddziaływanie hamujące zainicjowanie w jakiejś części mózgu. Większość uzyskanych dotychczas danych fizjologicznych przemawia za pierwszym wyjaśnieniem. 
„Zmęczenie” to zdaje się występować w połączeniach synaptycznych - określa się je jako |depresję |synaptyczną.
Materiał dowodowy dostarczający poparcia dla tego mechanizmu habituacji uzyskano w badaniach nad zwierzętami tak różnymi, jak raki i koty. Wyniki badań nad różnymi bezkręgowcami wskazują, że w trakcie habituacji wydziela się mniejsza ilość chemicznych substancji przekaźnikowych - gdy zaś nie ma substancji przekaźnikowych, to żadna wiadomość nie przejdzie przez synapsę.

Mózg jako regulator. Ponieważ habituacja może występować u zwierząt mających jedynie rdzeń kręgowy, to mózg nie jest oczywiście niezbędny do wystąpienia habituacji. Jest jednak możliwe, że istnieje pewien rodzaj habituacji, w którym działa korowa regulacja hamująca.
Zjawiskiem stwierdzonym w badaniach, którego nie można wyjaśnić w kategoriach prostej koncepcji swoistego zmęczenia, jest tak zwany efekt |brakującego bodźca. Badanemu prezentuje się szereg powtarzających się bodźców; w którymś miejscu szeregu opuszcza się jeden z nich, po czym kontynuuje się podawanie bodźców. Może to być na przykład czytanie na głos szeregu trójek, co sekundę jedną:


3-3-3-3-3-3-3-3-3-3- -3-3-3


Gdy następuje luka, pojawia się wzmożona reakcja, nagły zanik habituacji. 
Mówi się, że wystąpiła |dyshabituacja.


Zbliżenie
Wykrywanie przy użyciu dyshabituacji

„Zjawisko dyshabituacji umożliwiło stworzenie pomysłowej techniki, którą Lewis Lipsitt i jego współpracownicy (1963, 1966) opracowali w celu badania zdolności niemowląt do rozróżniania zapachów. Gdy niemowlętom, mającym zaledwie kilka dni, podaje się pewne bodźce węchowe, wówczas reagują one ruchami ciała oraz zmianami w oddychaniu i rytmie pracy serca.

Bodziec taki podaje się wielokrotnie, dopóki nie wystąpi habituacja; wtedy eksperymentator podaje inny bodziec. Jeśli niemowlę potrafi wykryć różnicę, to następuje dyshabituacja i reakcja na bodziec węchowy pojawia się znowu. Jeśli nowy bodziec jest spostrzegany jako „nie inny” od poprzedniego, to habituacja będzie trwać nadal.
Na wykresie pokazano krzywą habituacji niemowlęcia na mieszaninę trzech substancji chemicznych. Siły reakcji na tę mieszaninę maleją z każdą kolejną jej prezentacją w ciągu pięciu serii prób. Kiedy jednak zostanie podany osobno jeden ze składników tej mieszanki, ponownie występuje silna reakcja, świadcząca o dyshabituacji oraz - w drodze wnioskowania - o zdolności niemowlęcia do rozróżniania między pierwotną mieszaniną a jej pojedynczym składnikiem”.

Aby wyjaśnić to zjawisko, trzeba przyjąć, że istnieje mechanizm eliminujący informację, co do której |oczekuje |się, iż będzie identyczna z poprzednią informacją (a zatem mało ważna), a jednocześnie reagujący na zakłócenie tego wzorca. Radziecki psycholog Sokołow (1960) zaproponował elegancki model wyjaśniający, w jaki sposób mózg kieruje całym tym procesem; model ten, ogólnie biorąc, znalazł potwierdzenie w danych neurofizjologicznych. Zasadniczym elementem zaproponowanego przez Sokołowa wyjaśnienia jest system pozwalający porównywać zachodzące zdarzenia ze zdarzeniami uprzednio doświadczonymi. Tłumaczy to habituację zarówno w odniesieniu do pojedynczych bodźców, jak i sekwencji bodźców, a zatem pozwala przewidzieć „efekt brakującego bodźca” (ryc. 2.17).

* * *
Ryc. 2.17. Model Mózgowego Mechanizmu Regulacyjnego. Jest to uproszczony schemat modelu Sokołowa, wyjaśniającego to, co zachodzi w mózgu w czasie reakcji orientacyjnej i habituacji.
1. Wejście czuciowe w postaci układów bodźcowych jest analizowane w korze mózgowej i zostaje utworzony model neuronalny.
2. Nowy bodziec zostaje porównany z tym modelem.
3. Jeśli nowy bodziec jest różny od przechowywanego modelu, to występuje |niedopasowanie; hipokamp przestaje hamować siatkowaty układ aktywujący i wywołane zostają reakcje orientacyjne.
4. Jeśli nowe wejście bodźcowe i model zgadza się ze sobą, to hipokamp hamuje układ siatkowaty, blokując wejście z nerwów aferentnych, co prowadzi do habituacji.

* * *
Model Sokołowa ma interesującego historycznego prekursora o którym warto tu wspomnieć. Francuski fizjolog Xavier Bichat, żyjący pod koniec XVIII wieku, rozróżniał funkcje wegetatywne o podstawowym znaczeniu dla pierwotnych potrzeb życiowych (takie, jak przemiana materii, trawienie i wydalanie) oraz funkcje animalne - istotne dla spostrzegania, reagowania, ruchu i emocji. W swym klasycznym dziele (zatytułowanym skromnie: 
„Recherches physiologiques sur la vie et sur la mort” - „Badania fizjologiczne nad życiem i śmiercią”) przewidział on również proces korowy porównywania nowych wrażeń z wrażeniami doświadczanymi uprzednio.

„Działanie umysłu wobec każdego uczucia przykrości lub przyjemności wypływającego z wrażenia polega na porównywaniu tego wrażenia z tymi, które je poprzedziły. Im większa różnica między wrażeniami: obecnym i przeszłym, tym bardziej płomienne będzie uczucie. Najsilniej odczujemy to wrażenie, którego nie doświadczyliśmy nigdy przedtem (...)
Natura przyjemności i przykrości jest więc taka, że niszczą one same siebie, przestają istnieć, ponieważ istniały. Sztuka przedłużania czasu trwania naszych przyjemności polega na zmienianiu ich przyczyn” (Bichat, 1809). 

Interesujące badanie przeprowadzone na małpach wykazało, że uczenie się wpływa na habituację - a stąd wynika wniosek, że mózg ma wpływ na to, kiedy wystąpi habituacja i czy w ogóle wystąpi.

„Najpierw umieszczono mikroelektrody w izolowanych komórkach kory słuchowej mózgu w celu rejestrowania wywołanych potencjałów występujących w odpowiedzi na różne bodźce akustyczne. Następnie, jedną grupę ćwiczono w naciskaniu klucza przy pojawieniu się sygnału świetlnego i w zwalnianiu go po rozpoczęciu działania bodźca słuchowego. Porcja duszonych jabłek służyła jako wzmocnienie „dobrego” wykonania i zachęcała małpy, by uważały na bodźce i szybko reagowały. Drugiej grupy nie ćwiczono w tym zadaniu.
Następnie mierzono reakcje obu grup na powtarzające się bodźce akustyczne, stwierdzono znaczne różnice pod względem habituacji aktywności korowej między zwierzętami ćwiczonymi i niećwiczonymi. U zwierząt niećwiczonych więcej niż 85% pojedynczych komórek, w których przeprowadzono pomiary, wykazało oczekiwaną habituację, często już po czterech ekspozycjach bodźca. Natomiast małpy ćwiczone nie wykazały żadnych oznak habituacji wobec powtarzających się bodźców słuchowych - pojedyncze komórki ich kory słuchowej nadal reagowały tak jak przedtem.
Nawet gdy z wyćwiczonymi zwierzętami przeprowadzono próby kontrolne w warunkach, w których nie wymagano żadnej zewnętrznej reakcji, komórki kory wykazywały niewielkie oznaki habituacji wobec powtarzających się dźwięków, chociaż szybkość występowania w nich pobudzenia była nieco mniejsza.
Badacze wyciągnęli stąd wniosek, że aktywność komórki korowej najwyraźniej zależy nie tylko od warunków fizjologicznych, lecz także od uprzedniego ćwiczenia i aktualnego stanu behawioralnego (J. M. Miller i wsp. 1972).


Kwintesencja esencji: mózg


Wyobraź sobie mały, przenośny komputer, ważący niewiele ponad kilogram, o następujących właściwościach: pamięć o olbrzymiej pojemności, pozwalającej przechować chyba wszystkie ważne informacje, jakie otrzyma w ciągu siedemdziesięciu lub więcej lat; zdolności różnicowania na tyle różnorodne, by wykryć rok produkcji wina, różnicę między dwoma zapachami perfum oraz rozpoznać, czy piłka lecąca z wielką szybkością upadnie na linię, czy „na aut”, zdolność planowania swej własnej reprodukcji oraz wiedza o tym, jak zyskiwać przyjaciół i wpływać na ludzi. Na koniec, czy możesz wyobrazić sobie komputer, który potrafiłby zaprogramować zniszczenie siebie samego i unicestwienie swego gatunku? Mózg ludzki jest masą tkanki zorganizowanej w taki właśnie komputerowy system - który to system pozwala także tobie wyobrazić sobie jego własne „szczytowe osiągnięcia” a naukowcom pozwala badać jego nie wykorzystane dotąd możliwości.


Metody badania tajemnic mózgu


Sekrety funkcjonowania mózgu, ukrytego jak wielki skarb pod grubym sklepieniem, przez wieki broniły się przed odkryciem dzięki jego bezpiecznemu położeniu. Chroni go gruba warstwa kości czaszki, a nawet gdy czaszkę się otworzy, odsłoni się jedynie powierzchnia |kory - reszta pozostaje ukryta pod nią. Oczywiście dzięki anatomom, którzy przeprowadzili wiele sekcji mózgów pochodzących ze zwłok ludzkich i zwierzęcych, znamy wygląd tego narządu. Jednakże badacz zajmujący się psychofizjologią, którego interesują zależności między procesami zachodzącymi w mózgu a zachowaniem, musi badać organizm przejawiający różne zachowania, a więc |żywy.
Badanie procesów mózgowych u żywych osobników stało się możliwe dopiero wtedy, gdy dokonano pewnych wynalazków technicznych. Większość tych osiągnięć metodologicznych dokonano dopiero w ostatnich paru dziesiątkach lat, lecz już powstała dzięki nim ogromna dziedzina fascynującej wiedzy o tym, jak pracują nasze mózgi. Trzy podstawowe techniki stosowane w badaniu aktywności nerwowej mózgów żywych ludzi i zwierząt są następujące: a) uszkodzenia wybranych struktur mózgu (lezje), b) elektryczne rejestrowanie aktywności tkanki nerwowej, c) bezpośrednie elektryczne lub chemiczne drażnienie różnych okolic mózgu.

Lezje. |Lezja polega na zniszczeniu komórek nerwowych mózgu na pewnym obszarze. Niekiedy lezje powstają w sposób naturalny - w wyniku chorób, guzów, wypadków lub ran odniesionych na wojnie. We wczesnym okresie rozwoju neurofizjologii badania polegały niemal wyłącznie na ustalaniu związku miedzy umiejscowieniem takich przypadkowych lezji a towarzyszącymi im zaburzeniami w zachowaniu. Jednakże niewątpliwie słabą stroną takich badań jest to, że często ogólny stan badanego osobnika w czasie analizy zachowania jest gorszy niż zwykle. Badacz nie dysponuje żadnymi danymi dotyczącymi uprzedniego poziomu jego funkcjonowania, które mogłyby służyć za podstawę porównań, i nie zna ogólnego wpływu lezji i związanego z nią szoku. Ponadto badania, w których trzeba oczekiwać na „naturalne” wypadki lub katastrofy, w których nie ma żadnego wpływu na miejsce lezji, są mało efektowne.
Karl Lashley (1929) był jednym z pionierów zastosowania eksperymentalnie dokonywanych lezji w badaniach nad związkami między mózgiem a zachowaniem.  Aby przekonać się, jakie zaburzenia w zachowaniu wynikają z utraty określonych partii tkanki mózgowej, w systematyczny sposób niszczył różne ilości tej tkanki, w różnych okolicach mózgu u szczurów laboratoryjnych, a następnie, w różnych odstępach czasu, przeprowadzał z tymi zwierzętami testy behawioralne.
Lashley stwierdził, że chociaż zniszczenie pewnych okolic powodowało trwałą utratę danej funkcji, to jednak uszkodzenie innych okolic wywoływało jedynie czasową jej utratę. W niektórych wypadkach utrata funkcji wydawała się mniej uzależniona od |lokalizacji usuniętej tkanki mózgowej niż od ogólnej |ilości usuniętej tkanki.
W porównaniu z wczesnym okresem surowego empiryzmu, gdy stawiano sobie pytanie: „Ciekaw jestem, co się stanie, jeśli wytnę tę część mózgu?”, metoda ta została udoskonalona do tego stopnia, że można dokonywać lezji bardzo specyficznych struktur i mierzyć subtelne zmiany w zachowaniu.  Zadawane obecnie pytania (zob. M. Wilson, 1973; P. Meyer, 1973) dotyczą zagadnień związanych z poznawaniem ściśle określonych procesów mózgowych, które normalnie leżą u podstawy danego zachowania. Jeśli obserwuje się jakąś zmianę, to czy ogranicza się ona tylko do jednej modalności zmysłowej (np. wzroku czy słuchu), czy też jest bardziej ogólna? Czy jest ona chwilowa, czy trwała? Czy ubytki w zachowaniu można wyrównać stosując leczenie środkami farmakologicznymi, ćwiczenie lub inne metody? Główną wadą stosowania lezji jako metody badawczej jest oczywiście fakt, że niektóre jej skutki są trwałe i zwierzę może pozostać upośledzone przez resztę życia.

Elektryczne rejestrowanie aktywności mózgu. Metoda elektrycznego rejestrowania impulsów nerwowych stała się jednym z najskuteczniejszych sposobów badania funkcji mózgu. Jeśli wzmocni się aktywność elektryczną pobudzonych neuronów, to wydają one odgłosy podobne do dźwięku strzałów karabinu maszynowego, gdyż wytwarzają serie następujących po sobie potencjałów czynnościowych typu „wszystko albo nic”. Pierwsi badacze słuchali wzmocnionych impulsów nerwowych przez głośniki; nowoczesna technika elektroniczna pozwala jednak badaczowi oglądać impuls nerwowy „w działaniu” - na ekranie (podobnym do telewizyjnego) przyrządu zwanego |oscyloskopem.


Zbliżenie
Obserwacja impulsów nerwowych na oscyloskopie


„Jednym z najważniejszych przyrządów stosowanych przez naukowców, którzy badają czynności mózgu, jest oscyloskop. Na fluorescencyjnym ekranie tego przyrządu można obserwować impulsy nerwowe i mierzyć precyzyjnie ich właściwości. Fotografie lub wykresy przedstawiające „wyładowanie” neuronu, czyli przekazywanie impulsu nerwowego uzyskano za pomocą oscyloskopu.
Wyobraź sobie, że skierowałeś cienką wiązkę światła z latarki w ten sposób, że tworzy jasny punkt na ekranie, a następnie szybko poruszasz nią - w poprzek ekranu, w górę i w dół. Zobaczyłbyś poziomą, a potem pionową linię. Podobnie w oscyloskopie jest ruchoma plamka świetlna, którą wytwarza wiązka elektronów. W miejscu, gdzie wiązka ta padnie na pokryty fosforem ekran oscyloskopu, powstaje świecący punkt.
Elektrony są to cząsteczki naładowane |ujemnie (-), które są przyciągane przez dodatnie (+) ładunki elektryczne i odpychane przez inne ładunki ujemne.

Wiązka przemieszcza się szybko ku lewej płytce, jeśli przełoży się tam potencjał dodatni. Przesuwa się na prawo, jeśli lewa płytka uzyska potencjał ujemny, a prawa dodatni. Szybkość, z jaką wiązka wędruje po ekranie, zależy od względnej wielkości ładunków po obu stronach. Oczywiście wiązka może poruszać się także w płaszczyźnie pionowej, jeśli ładunek elektryczny pojawi się na górnej lub na dolnej płytce, lub po linii falistej, gdy zmieniają się ładunki na obu parach płytek.
Rejestrując procesy elektryczne zachodzące w neutronach mózgu, eksperymentator ustala, z jaką szybkością wiązka elektronów wędruje z prawa na lewo i z lewa na prawo; szybkość tego ruchu jest miarą |czasu. Ruch wiązki w pionie reprezentuje zmiany potencjału błony komórkowej badanego neuronu. Gdy w neutronie następuje „wyładowanie”, wówczas pojawia się chwilowa zmiana potencjału, tak szybka, że wiązka odchyla się i powraca do pierwotnego położenia w ciągu milisekundy - jednej tysięcznej części sekundy (zmiana potencjału musi być wzmocniona tysiące razy zanim będzie mogła oddziaływać na wiązkę elektronów w oscyloskopie). Gdy wiązka elektronów wędruje powoli przez ekran z lewa na prawo, wówczas nagła zmiana potencjału w „wyładowującym się” neuronie wywołuje wychylenie wyglądające na ekranie jak „iglica” czy nagły „impuls” (ryc. F). Terminy: impuls nerwowy, potencjał iglicowy i potencjał czynnościowy stosuje się zamiennie”.

Elektryczne rejestrowanie stosuje się łącznie z metodą „potencjałów wywołanych”. Podaje się mianowicie bodziec świetlny lub dźwiękowy, który |wywołuje impulsy nerwowe; impulsy te wędrują następnie do mózgu, gdzie wykrywa się je jako lokalne zmiany |potencjału elektrycznego za pomocą elektrod umieszczonych w różnych okolicach mózgu. Gdziekolwiek wystąpi zmiana potencjału, jest ona wzmacniana elektronicznie i przedstawiana w postaci obrazu na oscyloskopie. Uprzednio stosowano jedynie elektrody powierzchniowe, lecz obecnie jest możliwe wprowadzenie elektrod głęboko do wnętrza mózgu i wykrywanie wyładowań nawet w pojedynczych komórkach (zob.  Thompson, Robertson i Mayers, 1973).

Bezpośrednie drażnienie mózgu. Stymulacja mózgu słabym prądem elektrycznym doprowadzanym za pomocą mikroelektrod stała się bardzo popularną psychofizjologiczną techniką umożliwiającą opracowanie „map” funkcji mózgu. Drażni się różne okolice w różnych warunkach, rejestrując wywoływane w ten sposób wrażenia lub zachowania. Początkiem „ery nowoczesnej” w dziedzinie drażnienia mózgu były badania W. R. Hessa; w badaniach tych, przeprowadzonych na prawie 500 kotach, poddano stymulacji ponad 4500 punktów mózgu przy użyciu precyzyjnego oprzyrządowania. Dzięki temu można było badać całkowicie przytomne zwierzęta, których zdolność poruszania się była tylko w minimalnym stopniu ograniczona przez kable łączące źródło stymulacji z elektrodami implantowanymi na stałe w ich mózgach (opis badań Hessa można znaleźć w pracy Gloora, 1954).
Na początku tego rozdziału opisaliśmy, jak Wilder Penfield, w celu sporządzenia mapy funkcji okolic mózgu, stosował drażnienie prądem elektrycznym u chorych na padaczkę przed poddaniem ich operacji mózgu. Na Tulane University Robert Heath i jego współpracownicy od 1951 roku badali w ten sposób głęboko położone okolice mózgu schizofreników (Heath i Mickle, 1960).
Do szerokiego rozpowszechnienia się badań prowadzonych przy zastosowaniu metody drażnienia mózgu najbardziej chyba przyczyniło się odkrycie Jamesa Oldsa z University of Michigan. Stwierdził on, że jeśli implantuje się elektrody w pewne okolice mózgu szczura, to szczur ten będzie ciężko pracować lub nawet znosić ból, aby tylko dosięgnąć dźwigni, której naciśnięcie powoduje elektryczne drażnienie jednej z tych okolic. W istocie, szczury aplikują sobie samym te bodźce w tempie 7000 naciśnięć na godzinę, nie zwracając nawet uwagi na pokarm i wodę, mimo że są głodne i spragnione.
Olds nazwał te okolice „ośrodkami przyjemności” (Olds i Milner, 1954; 
Olds, 1973). Drażenienie innych okolic mózgu szczura zdaje się działać karząco jeszcze innych - wydaje się być jednocześnie przyjemne i bolesne.  Podobne okolice wykryto także u innych gatunków, z ludźmi włącznie. Stosuje się także chemiczne drażnienie mózgu.

Ma ono wiele zalet, gdy chodzi o badanie związków między określonymi okolicami mózgu a pamięcią, uczeniem się, jedzeniem, piciem oraz innymi procesami behawioralnymi. W porównaniu z drażnieniem prądem elektrycznym skutki wstrzyknięcia substancji chemicznych do mózgu są bardziej długotrwałe; w przeciwieństwie do lezji skutki te są odwracalne.  Oddziaływanie substancji chemicznych na obszary znajdujące się pod ich bezpośrednim wpływem można obserwować na oscyloskopie, gdy zastosuje się elektrody rejestrujące. Jednakże główną przyczyną popularności badania mózgu za pomocą wstrzykiwania substancji chemicznej jest to, że w wielu miejscach złożone drogi nerwowe biegną bardzo blisko siebie i jest rzeczą trudną lub niemożliwą badać te obszary metodami lezji lub drażnienia elektrycznego - obie oddziaływują na zbyt wiele warstw komórek.
Sebastian Grossman (1967) opracował technikę pobudzania lub tłumienia aktywności dróg nerwowych w głębokich regionach mózgu przez mikroiniekcje substancji chemicznych, które zmieniają stężenie synaptycznych substancji przekaźnikowych. Technika ta polega w zasadzie na trwałej implantacji podwójnej rurki (cannula) w czaszce zwierzęcia. Wewnętrzną rurkę wyciąga się, sterylizuje, wypełnia kryształkami danej substancji i ponownie wprowadza przez zewnętrzną rurkę do obszaru mózgu będącego obiektem badania. Za pomocą tej samej implantowanej rurki Grossman potrafił w systematyczny sposób wywoływać czynność jedzenia przez wprowadzenie jednej substancji, a czynność picia - przez wprowadzenie drugiej substancji.  Ponieważ mózg składa się głównie z płynów i różnych substancji biochemicznych, przeto technika drażnienia chemicznego jest szczególnie przydatna do czasowego wprowadzania zmian w procesach mózgowych w precyzyjny sposób.


Lokalizacja funkcji


W początkach dziewiętnastego wieku rozwinął się kierunek badań, zwany |frenologią. Zgodnie z jego podstawową zasadą, umysł nie stanowi całości, lecz składa się z różnych, odrębnych „władz”. Władze te, twierdzili twórcy frenologii, Gall i Spurzheim, można zlokalizować w różnych „narządach” mózgu. Stosowana przez nich metoda określania władz umysłu polegała na lokalizowaniu wypukłości na głowie danego człowieka: każda wypukłość wskazywała miejsce, gdzie znajdował się narząd danej władzy. Osobowość każdego człowieka można więc było rzekomo określić na podstawie kształtu jego głowy.

Współcześni neurofizjolodzy doszli do tego samego ogólnego wniosku - nie w odniesieniu do władz umysłu, ani też postulowanego przez frenologów związku między wypukłościami na głowie a naiwnie określonymi kategoriami zachowań i osobowości, lecz co do faktu istnienia wyspecjalizowanych funkcji.


Jak jednak się przekonamy, sprawa ta jest znacznie bardziej złożona niż sądzili frenolodzy. W niniejszym podrozdziale zaczniemy od naszkicowania ogólnego zarysu anatomii mózgu, następnie opiszemy pokrótce, jakie funkcje spełniają poszczególne części mózgu.
Chociaż będziemy mówili o różnych częściach mózgu tak, jak gdyby były to odrębne struktury, to w rzeczywistości jest inaczej. Przede wszystkim trzeba pamiętać, że mózg składa się z grup neuronów spełniających tę samą funkcję. Często (nie zawsze) ich jądra są położone blisko siebie, lecz ich aksony mogą biec do odległych okolic. Części mózgu, które przy sekcji |wydają |się odrębnymi strukturami, nie są zatem tak odrębne jak wyglądają, ponieważ mogą zawierać części wielu neuronów, których jądra znajdują się gdzie indziej. Zapewne nie dałoby się określić dokładnych granic między rzeczywistymi funkcjonalnymi grupami neuronów. Nazwy, jakie nadajemy poszczególnym częściom mózgu, są odzwierciedleniem faktu, że przedmiotem najwcześniejszych badań były te jego części, które można było odróżnić za pomocą wzroku. W późniejszych badaniach stwierdzono, że najściślej związane ze sobą funkcjonalnie mogą być zupełnie inne części, niż wynikałoby to z tych optycznych podziałów. Ponadto granice między częściami, które występują w mózgach o prostszej budowie, często zacierają się w miarę rozwoju ewolucyjnego mózgów bardziej złożonych.

Nowe mózgowie: kora nowa. Gdybyś spojrzał z góry na mózg pacjenta, odsłonięty w czasie operacji chirurgicznej, zobaczyłbyś masę szarej tkanki podzieloną na dwie części, pokryte pozwijanymi bruzdami i fałdami, bardzo podobne do ogromnego orzecha włoskiego. Części te noszą nazwę |półkul |mózgowych (cerebral hemispheres); ich pofałdowana powierzchnia zewnętrzna jest warstwą grubości kilku milimetrów, zwaną |korą (cortex). Tkana ta składa się głównie z dendrytów i szarych ciał komórkowych neuronów, których aksony sięgają niższych części mózgu.
Kora mózgowa jest także nazywana |korą |nową (neocortex), ponieważ jest ona stosunkowo nowym wytworem ewolucji. U ryb kora nowa nie występuje, podczas gdy płazy, gady i ptaki (w tym porządku) mają jej coraz więcej. U ssaków kora nowa jest już znacznie bardziej rozwinięta, aż wreszcie u człowieka zajmuje największą powierzchnię.
Dwie półkule mózgowe w rzeczywistości nie są rozdzielone; komunikacja między nimi zachodzi przede wszystkim poprzez wiązkę włókien nerwowych zwaną spoidłem wielkim albo |ciałem |modzelowatym (corpus callosum). Każdą półkulę można podzielić funkcjonalnie na cztery płaty, których położenie określa się względem dwóch głębokich bruzd. Każdy z tych płatów stanowi obszar, w którym dominują pewne funkcje.
Pod warstwą kory leży większa część nowego mózgowia, które prawie w całości jest barwy białej, a to ze względu na obecność białych osłonek mielinowych okrywających niezliczone aksony. Niektóre z tych włókien są włóknami czuciowymi biegnącymi do kory z rdzenia kręgowego, inne łączą jedną okolicę kory z inną jej okolicą na tej samej półkuli, z okolicami znajdującymi się po przeciwnej stronie mózgu lub z różnymi odrębnymi strukturami podkorowymi.


Zbliżenie
Iluminacja mózgu


Badacze szwedzcy opracowali bardzo efektowną technikę uwidocznienia neuronów. Polega ona na wywoływaniu reakcji chemicznej między drobinami neuronowej substancji przekaźnikowej i parami formaldehydu; w ten sposób otrzymuje się fluoryzujący związek, dzięki któremu neurony jarzą się jasno, gdy napromieniuje się je światłem ultrafioletowym. Reakcja ta zachodzi jedynie z określonymi substancjami przekaźnikowymi, które występują w odrębnych drogach nerwowych w mózgu, a zatem technika ta umożliwia śledzenie, którędy te drogi biegną przez mózg.
Gdy ogląda się pod mikroskopem skrawek tkanki mózgowej „iluminowanej” w ten sposób, to przypomina ona widok z samolotu w nocy. Jasno jarzące się aksony przecinają pole widzenia jak szosy, a skupiska ciał komórkowych w jądrach przywodzą na myśl światła miasteczek. Technika ta ma wielkie znaczenie, ponieważ wiąże trzy dziedziny badań - anatomię, neurofizjologię komórkową i psychofarmakologię; umożliwia ponadto uzyskanie dokładniejszego obrazu układu nerwowego.

Stare mózgowie: struktury podkorowe. Usytuowanie kory mózgowej na „najwyższym piętrze” układu nerwowego oraz wyższy stopień jej rozwoju u wyższych gatunków - a także jej dostępność dla badań chirurgicznych i badań metodą drażnienia - doprowadziły początkowo badaczy do fałszywego wniosku, że ona sama zawiaduje prawie całym złożonym zachowaniem adaptacyjnym.  Później jednak okazało się, że u ludzi, podobnie jak u wielu innych zwierząt, stare mózgowie nadal kieruje wieloma funkcjami życiowymi. Nasze pożądania (głód, pragnienie, popęd seksualny), awersje (obawy), zachowania konsumpcyjne (jedzenie, picie, czynności seksualne), sen, czuwanie, regulacja ciepłoty ciała - wszystko to znajduje się pod wpływem struktur podkorowych. I wreszcie w tych pierwotnych strukturach ukryte są ośrodki, które odgrywają zasadniczą rolę w przebiegu zjawisk emocjonalnych. Drogi, prowadzące do kory i z kory, przechodzą przez stare mózgowie; istnieje dobrze rozwinięta dwustronna komunikacja między nim a ośrodkami wyższymi.
Niedawno kilku badaczy zaproponowało model organizacji i funkcjonowania mózgu, w którym to modelu korę nową traktuje się jako nowszy, sprawny system pełniący wszelkie funkcje z zakresu różnicowania, podczas gdy stare mózgowie uważane jest za system mniej wyspecjalizowany, odbierający niespecyficzne, różnorodne informacje wejściowe. Według tego modelu niektóre procesy mózgowe przebiegają niezależnie od siebie w paralelnych układach, podczas gdy inne są ściślej od siebie uzależnione (Semmes, 1969; 
Gross, 1973).
Stare mózgowie dzieli się na kilka części. Najwięcej uwagi poświęcimy tu dwom częściowo zachodzącym na siebie strukturom, znanym jako |pień |mózgu i |układ |limbiczny (rąbkowy).

„Pień mózgu” (brain stem). Tą ogólną nazwą obejmuje się zbiór mniejszych struktur, które łączą nowe mózgowie z rdzeniem kręgowym; były one pierwotnym zaczątkiem „centralnego kierownictwa” układu nerwowego. Główne części pnia mózgu to |wzgórze, |podwzgórze i |twór |siatkowaty. W mózgu człowieka wzgórze (thalamus) jest usytuowane niemal w samym środku. Jest ono ważną stacją przekaźnikową dla informacji czuciowych przychodzących ze wszystkich części ciała. Bezpośrednio pod wzgórzem znajduje się połączone z nim |podwzgórze (hypothalamus), w którym zlokalizowane są ważne ośrodki regulujące przemianę materii, temperaturę ciała, odczuwanie głodu, pragnienia oraz przebieg zjawisk emocjonalnych. Wykazano, że drażnienie tylnej części podwzgórza powoduje reakcję układu sympatycznego (przyspieszenie pracy serca, wzrost ciśnienia krwi), podczas gdy drażnienie części przedniej wywołuje reakcję układu parasympatycznego (spowolnienie pracy serca, rozszerzenie się naczyń krwionośnych w jelitach i żołądku).  Podwzgórze jest wrażliwe na te zmiany w środowisku zewnętrznym, które wymagają albo walki, albo ucieczki. Jest ono także wrażliwe na wewnętrzne potrzeby organizmu i odgrywa ważną rolę w utrzymaniu wymiany energii między organizmem a jego otoczeniem.
„Twór siatkowaty” (reticular formation) jest to splątana masa grup komórek i włókien, znajdująca się w samym środku pnia mózgu, nieco powyżej rdzenia kręgowego. Zarówno włókna biegnące |do kory, jak i |z kory, przechodzą przez twór siatkowaty, który spełnia dwie ważne funkcje.  Reagując na impulsy dopływające włóknami z różnych wyższych ośrodków, działa on hamująco na odbiór pewnych informacji sensorycznych, a torująco - na odbiór innych. Za pośrednictwem włókien wstępujących, biegnących z z tworu siatkowatego do wszystkich wyższych ośrodków, działa on jako układ ogólnego wzbudzenia: drażnienie tej okolicy powoduje, że śpiące zwierzę budzi się, a czuwające - staje się bardziej czujne. Jest on więc zwany |siatkowatym |układem |aktywującym (reticular activating system).

„Układ limbiczny” (rąbkowy). Inny ważny region starego mózgowia, określany jako układ limbiczny (limbic system), tworzy jakby obwódkę wokół górnego krańca pnia mózgu. Początkowo sądzono, że jest to po prostu „mózg węchowy”, służący jako „analizator zapachów”, ponieważ do części tego układu, zwanej |węchomózgowiem (rhinencephalon) dochodzą włókna nerwowe z receptorów węchowych. Obecnie wiemy, że poza tym ma on części służące funkcjom tak różnym, jak uwaga, emocje i pamięć. Jeden z badaczy (MacLean, 1958) doszedł do wniosku, że w układzie limbicznym są zlokalizowane dwie podstawowe funkcje życiowe - zachowanie własnego życia i zachowanie gatunku.
Drażnienie wielu spośród struktur układu limbicznego wywołuje |reakcję |uwagi - zwierzę czujnie bada swe otoczenie.

Drażnienie jednej z nich, zwanej |ciałem |migdałowatym (amygdala), wywołuje reakcję ucieczki i obrony. Lezje dokonywane w ciele migdałowatym lub innej strukturze, |zakręcie |obręczy (cingulate gyrus), mogą dzikie zwierzę uczynić łagodnym, podczas gdy uszkodzenie pobliskiej |przegrody (septal area) może spowodować wystąpienie reakcji wściekłości u łagodnego poprzednio zwierzęcia. Wykazano także, że układ limbiczny odgrywa istotną rolę w selektywnym inicjowaniu lub hamowaniu zachowania związanego z przystosowaniem się do wymagań ze strony środowiska.
Jeszcze inna część układu limbicznego, |hipokamp (hippocampus), ma udział w regulacji co najmniej dwóch bardzo różnych zachowań - zachowania seksualnego i zapamiętywania. Elektryczne drażnienie tej okolicy może spowodować u męskich osobników erekcję członka. Pacjenci z uszkodzeniem hipokampa mają wielkie trudności z zapamiętywaniem nowych wydarzeń, o ile nie koncentrują na nich swej uwagi. Chociaż wykazują normalną inteligencję i zdolność porozumiewania oraz dysponują normalnym zasobem słów, cierpią jednak na |niepamięć |wsteczną. Jest to defekt pamięci, przy którym stare nawyki i zdarzenia pamięta się dobrze, natomiast nowsze są zapamiętywane coraz gorzej.
Podobne zjawisko zdaje się towarzyszyć starości: wraz z wiekiem i twardnieniem tętnic (oraz gorszym nadtlenianiem mózgu) następuje utrata pamięci, zwłaszcza w odniesieniu do informacji otrzymanych później. Badania zdają się wykazywać, że codzienne aplikowanie dawki czystego tlenu zapobiega tej utracie pamięci u ludzi starszych (Jacobs, Winter, Alvis i Small 1969).

Te zmiany w funkcjonowaniu przypominają nam, że pamięć jest w zasadzie procesem fizykalnym, związanym w pewien sposób z fizjologią impulsów nerwowych.

Móżdżek. |Móżdżek (cerebellum), ukryty pod półkulami mózgowymi, jest z psychologicznego punktu widzenia najmniej interesującą częścią mózgu, ponieważ jego zasadniczą funkcją zdaje się być przede wszystkim utrzymanie równowagi, postawy, oddychania i innych podstawowych mechanizmów regulacyjnych. Nowsze badania wskazują jednak, że móżdżek odgrywa także pewną rolę w inicjowaniu ruchów dowolnych, a także w uczeniu się ruchowym i w przystosowaniu się do funkcjonowania w sytuacji otrzymywania zniekształconych danych sensorycznych.
* * *
Ryc. 2.23. Jose Delgado jest pionierem w zakresie implantacji do mózgu elektrod aktywowanych przez radio. Potrafi on tak dokładnie znajdować właściwe miejsce w mózgu zwierzęcia, że może zawierzyć tej umiejętności swe życie. Mimo że byk zaczął już atakować, Delgado potrafi zatrzymać go, nadając przez radio „komunikat” do elektrod implantowanych w mózgu zwierzęcia. Po kilkakrotnym powtórzeniu takich doświadczeń, zwierzę staje się na stałe mniej agresywne.
* * *

Funkcjonowanie mózgu


Gdy już omówiliśmy anatomię mózgu i fizjologię przekazywania nerwowego, wówczas zasadnicze pytanie brzmi, jakie mamy korzyści z mózgu? Dla wygody funkcje jego można zgrupować w trzy kategorie: funkcje |czuciowe, |ruchowe i |kojarzeniowe. Szczególnie będzie nas tu interesować rola, jaką w przypadku tych funkcji odgrywa nowe mózgowie.

Funkcje czuciowe. Chociaż drażnienie różnych nerwów czuciowych powoduje powstawanie różnego rodzaju wrażeń, to jednak przyczyną tego zjawiska nie jest zróżnicowanie impulsów. Jak już się przekonaliśmy, impulsy nerwowe różnią się jedynie amplitudą i szybkością, z jaką są przekazywane. Wywołują one różne wrażenia dzięki temu, że dochodzą do różnych miejsc w mózgu.
Najwyżej rozwinięte okolice mózgu, umożliwiające najdokładniejsze różnicowania, znajdują się w korze mózgowej. Wszystkie zmysły są jednak reprezentowane także w większym lub mniejszym stopniu w niższych ośrodkach czuciowych. Jeśli więc wyższe ośrodki zostaną zniszczone, wówczas niższe mogą, przynajmniej w części, przejąć na siebie dekodowanie napływających informacji.
Sygnały czuciowe z różnych części powierzchni ciała przechodzą na drugą stronę rdzenia kręgowego lub mózgu i docierają do |somatycznych |pól |czuciowych (ryc. 2.24). Główne pole somatyczno-czuciowe rozciąga się ku tyłowi od bruzdy Rolanda, która oddziela je od głównych ośrodków ruchowych.  Reprezentacja czuciowa ciała jest odwrócona „do góry nogami”, przy czym twarz i ręce są reprezentowane przez znacznie większą powierzchnię kory niż reszta ciała. Ośrodki smakowe znajdują się blisko ośrodków wrażliwości dotykowej dla języka.

* * *
Ryc. 2.24. Główne Pola Ruchowe i Czuciowe. Główne pola ruchowe i czuciowe kory leżą wzdłuż bruzdy Rolanda: pole ruchowe tuż przed nią, pole czuciowe zaś tuż za nią. Poszczególne części ciała są reprezentowane przez odpowiadające im punkty po obu stronach bruzdy, przy czym reprezentacja ta jest „do góry nogami”: to jest jej nogi i stopy są reprezentowane u góry i na wewnętrznej powierzchni między półkulami, niżej - ręce i ramiona, a na dole - głowa. Większa wrażliwość i precyzja kontroli, jaka cechuje głowę i ręce w porównaniu z innymi częściami ciała, znajduje swe odbicie w większej powierzchni ich reprezentacji korowej.

* * *
Najwyższe ośrodki wzrokowe leżą w płacie potylicznym, w tylnej części mózgu. Zniszczenie tych okolic powoduje u ludzi utratę wzroku, może z wyjątkiem prymitywnej zdolności mało dokładnego rozróżniania jasności i ciemności. Natomiast u zwierząt zdolność zróżnicowania wzrokowego po uszkodzeniu kory zostaje zachowana w większym stopniu.
Ośrodki słuchowe leżą wzdłuż bruzdy Sylwiusza w górnej części płata skroniowego. Znajdują się one w pobliżu niektórych okolic dotykowych, a nawet są z nimi w pewnym stopniu splecione. Jak już wspomniano uprzednio, zapachy są dekodowane w |węchomózgowiu - zlokalizowanym głęboko wewnątrz półkul mózgowych.

Oprócz głównych pól czuciowych, pokazanych na rycinie 2.24 również różne pola sąsiednie - a w niektórych wypadkach nawet pola położone w pewnej odległości - biorą udział w analizie i organizowaniu napływającej informacji sensorycznej, a więc w złożonych procesach percepcyjnych. Na przykłąd, chociaż główne pole słuchowe rozciąga się wzdłuż dolnej powierzchni bruzdy Sylwiusza w górnej części płata skroniowego, to jednak pacjenci z uszkodzeniami wielu innych części mózgu mogą także mieć trudności w rozpoznawaniu dźwięków.
Poważnym problemem metodologicznym, występującym przy określaniu funkcji sensorycznych, jest ustalenie, jakiego rodzaju |testy |behawioralne należy zastosować w celu zmierzenia skutków lezji czy drażnienia. Na przykład, określenie pewnej części mózgu jako po prostu „wzrokowego pola sensorycznego” oznacza nieuwzględnienie różnicy między wzrokowym różnicowaniem form, wzrokowym różnicowaniem intensywności światła, pamięcią wzrokową, różnicowaniem barw, wzrokowym różnicowaniem przestrzennym, wzrokowym różnicowaniem zdarzeń i jeszcze innymi funkcjami. Określenie, jakie funkcje zachodzą w danej okolicy mózgu jest w końcu zależne od zastosowania testów behawioralnych dostatecznie różnorodnych, dokładnych i subtelnych, by mogły ujawnić złożoność procesów korowych.


Zbliżenie
Czy w mózgu istnieją „komórki babcine?”


W początkach lat sześćdziesiątych badacze układu nerwowego zaczęli znajdować w systemach wzrokowych zwierząt neurony, które reagowały jedynie na bardzo specyficzne bodźce. Na przykład mała, ciemna plamka, poruszająca się chaotycznie w polu widzenia żaby, powodowała wyładowanie w pewnej komórce, mimo że żaden inny bodziec (taki, jak zapalenie i gaszenie lampek lub tańcząca mała plamka światła) nie wywoływał takiego skutku. Jerome Lettvin z Massachusetts Institute of Technology nazwał te komórki „wykrywaczami robaków” i wysunął sugestię, że w mózgu mogą znajdować się komórki o niezmiernie skomplikowanych „wymaganiach” pod adresem bodźca.  Jako skrajny przykład wysunął on pół żartem przypuszczenie, co do istnienia „komórki babcinej”: neuronu w mózgu, który reagowałby tylko na rysy twarzy babci danej osoby. 
Ostatnio jednak badacze z Princeton odkryli w mózgu małpy komórkę, która reagowała najlepiej na sylwetkę małpiej ręki. Bodźce zastosowane w tym badaniu, uszeregowane od lewej do prawej według coraz większej zdolności do wywoływania reakcji (Gross i wsp., 1972).

W rozdziale 6 będziemy mieli więcej do powiedzenia o takich „przygotowanych zawczasu” obwodach.

|Funkcje ruchowe. Główne pole ruchowe leży tuż przed bruzdą Rolanda, naprzeciw pola somatyczno-czuciowego.

Stopy są reprezentowane w górnej części pola, niżej tułów i ręce; ośrodki nerwowe zawiadujące ruchami twarzy i języka są zlokalizowane najniżej.
Długie aksony z tego pola mózgu prowadzą przez rdzeń kręgowy, bezpośrednio lub poprzez neurony pośredniczące, do neuronów ruchowych zawiadujących mięśniami tułowia i kończyn po przeciwnej stronie ciała. Gdy więc drażni się jakiś punkt w tej okolicy mózgu, wówczas reaguje pewna grupa mięśni prążkowanych po drugiej stronie ciała, a uszkodzenie pewnego obszaru w tej części mózgu powoduje odpowiednie upośledzenie ruchów dowolnych.
Ze względu na wyraźny związek między tą okolicą a czynnością mięśni prążkowanych, przez dłuższy czas panowało przekonanie, że w regionie tym koncentrują się ośrodki kontroli tych mięśni. Jednakże Łuria (1970) wykazał, że przyjęcie takiego założenia byłoby podobne do przypuszczenia, że wszystkie towary eksportowane z danego portu zostały w nim wyprodukowane. W rzeczywistości, ważną rolę w organizowaniu ruchów dowolnych odgrywa kilka części mózgu. Na przykład:
1. Sprzężenie zwrotne z pola czuciowego poprzez bruzdę Rolanda jest niezbędne dla precyzyjnej regulacji ruchu. Bez takiego sprzężenia zwrotnego pary mięśni antagonistycznych byłyby pobudzane w sposób niezróżnicowany i zorganizowany ruch byłby niemożliwy.
2. Właściwa organizacja działania w przestrzeni wymaga czynności komórek położonych dalej ku tyłowi, w okolicy ciemieniowo-potylicznej. Osoba z uszkodzeniami w tym regionie może mylić prawą stronę z lewą lub zabłądzić w znanym sobie miejscu. Czy jednak reakcje wzrokowo-ruchowe są kontrolowane całkowicie przez tę właśnie okolicę mózgu? Wyniki opisanego niżej badania wskazują, że nie.

„Koty z rozległymi lezjami kory nowej nie były w stanie położyć we właściwy sposób swych przednich łap na stole - zadanie to wymagało koordynacji wzrokowo-ruchowej. Wydawało się więc, że lezje zniszczyły okolicę niezbędną do wykonania tej reakcji ruchowej. Gdy jednak zwierzętom wstrzyknięto pewien środek farmakologiczny (dR-amfetaminę), wówczas utracona reakcja pojawiła się znowu, lecz ponownie zanikła, gdy środek ten przestał działać. Najwidoczniej aktywowane farmakologicznie drogi podkorowe dostarczały dostatecznej ilości informacji wzrokowo-ruchowej do wykonania nawykowej reakcji” (Meyer, Horel i Meyer, 1963).

3. Zrealizowanie skoordynowanej sekwencji czynności wymaga zakończenia każdej z czynności składowych tak, aby mogła być wykonana następna. Po lezji w okolicy leżącej przed głównym polem ruchowym osobnik może nieustannie powtarzać pierwszą część działania.
4. Planowanie i wykonanie skoordynowanej sekwencji wymaga działania pola położonego jeszcze dalej ku przodowi płata czołowego. Jeśli to pole jest uszkodzone, osobnik powtarza wykonane już czynności składowe lub reaguje impulsywnie na bodźce zewnętrzne, nie potrafi wykonać celowego (ukierunkowanego na cel) działania (Łuria, 1970).
Oprócz wszystkich wymienionych tu pól korowych (i być może jeszcze innych), również struktury podkorowe odgrywają pewną rolę w organizowaniu ruchów dowolnych - na przykład filtrując lub wzmacniając napływające informacje, zapewniając określony poziom mobilizacji energii oraz działając innymi sposobami, które się dopiero odkrywa. Istnieje znaczne wzajemne oddziaływanie między poziomami: korowym i podkorowym, zarówno w analizowaniu „wejścia” (input) czuciowego, jak i kształtowania przystosowawczego „wyjścia” (output) ruchowego.

Funkcje kojarzeniowe. Gdybyśmy sporządzili rysunek kory mózgowej człowieka i zakreskowali pola związane z funkcjami ruchowymi i czuciowymi, to okazałoby się, że znaczną część kory pozostała nietknięta naszym ołówkiem. Część ta, to |pola |kojarzeniowe, nazwane tak, ponieważ pierwotnie przyjmowano, że to tutaj właśnie tworzy się nowe „skojarzenia” - to znaczy odbywa się uczenie. Chociaż wiele jeszcze trzeba się dowiedzieć o tych okolicach, to jednak zdajemy sobie już sprawę, że obraz ten jest zbyt uproszczony. Pola kojarzeniowe po każdej stronie kory mózgowej połączone są ze sobą, z polami czuciowymi i ruchowymi, z odpowiednimi polami po przeciwnej stronie oraz z wewnętrznymi częściami mózgu. Uważa się, że wiążą one i integrują prostsze funkcje pól czuciowych i ruchowych. Jak już się przekonaliśmy, pola czuciowe funkcjonują w zasadzie jako „wrota wejściowe” do kory, a pola ruchowe - jako „wyjścia”. Uszkodzenia kory poza głównym polem wzrokowym, lecz w jego pobliżu, nie powodują zatem ślepoty, ale upośledzają świadomość głębi i wzrokowe rozpoznawanie przedmiotów.
Proces chorobowy w pewnych polach kojarzeniowych lub uszkodzenie tych pól wywołuje stan, w którym chory nie potrafi dotykiem rozpoznawać przedmiotów.  Może on w nieskończoność obmacywać znany przedmiot, taki, jak klucz do drzwi lub ołówek, a jednak nie rozpoznaje go. Pacjenci wykazujący zaburzenia tego typu mogą nadal doświadczać normalnych wrażeń elementarnych; ich trudności wiążą się z organizowaniem tych elementów w normalne spostrzeżenia.
Podobne zaburzenia spostrzegania stwierdza się także w odniesieniu do innych zmysłów. Zaburzenia te zwane są |agnozjami, czyli |niezdolnością do rozpoznawania” i klasyfikuje się je według charakteru funkcji, która została upośledzona. Podobne zaburzenia dotyczące mowy noszą nazwę |afazji.  Przykładem może być niezdolność do rozpoznawania wymawianych słów, zwana niekiedy „głuchotą słowną” (word deafness). Agnozje i afazje towarzyszą lezjom w tych okolicach kojarzeniowych, które leżą w pobliżu pól czuciowych kory.


Zbliżenie
Jak skłoniono milczącą korę, aby przemówiła


„Okolice kory położone między głównymi polami czuciowymi, gdzie nie występowały potencjały wywołane w odpowiedzi na stymulację obwodową, zwano zwykle |korą |milczącą (silent cortex) i przypisywano jej rozmaite funkcje.  Richard Thompson z Harvard University potrafił skłonić tę milczącą korę do mówienia, a wtedy powiedziała nam ona pewne zadziwiające rzeczy.
Podejrzewając, że barbituran, stosowany poprzednio w badaniach kory jako środek znieczulający, tłumił potencjały wywołane, Thompson zastąpił go innych środkiem znieczulającym. I rzeczywiście, przy użyciu tego środka znalazł wkrótce okolice, które reagowały na stymulację sensoryczną innych części ciała. Nazwał je |reagującymi |polami |kojarzeniowymi (association response areas).
Przeprowadzone przez Thompsona dokładne badania wykazały, że gdy koty poddaje się działaniu bodźców wzrokowych (błyski), słuchowych (trzaski) i czuciowych (wstrząsy elektryczne wymierzane w łapy), to 82% komórek w reagujących polach kojarzeniowych istotnie reaguje na wszystkie trzy rodzaje bodźców. Niektóre komórki jednak częściej reagują na ten lub inny rodzaj bodźca. Gdy stosuje się różne kombinacje i serie bodźców, wówczas wiele komórek wykazuje także |plastyczność |reakcji - reagują one raczej w sposób zmienny niż stały.
Ponadto Thompson znalazł komórki „nowości” (novelty cells), które reagują tylko wtedy, gdy odstępy między bodźcami wynoszą 30 sekund lub więcej (dla porównania - zwykłe komórki reagują ponownie po upływie sekundy lub mniej) oraz komórki „kodujące liczby”, z których każda reaguje na określony kolejny bodziec w szeregu. Na przykład, w danej komórce wyładowanie wystąpi jedynie wówczas, gdy prezentowany jest siódmy z kolei bodziec serii bez względu na modalność bodźca czy odstęp czasu między bodźcami” (Thompson, Robertson i Mayers, 1973).

W polach korowych przyporządkowanych danej funkcji są zespoły komórek, które ją wykonują. Takie „dublowanie (redundacja) funkcji sprawia, że ważne funkcje mogą być wypełniane w sposób niezawodny, nawet jeśli niektóre komórki w danym polu ulegną zniszczeniu, inne bowiem nadal wykonują swoje zadania.
Jednakże staje się coraz bardziej oczywiste, ze chociaż jedno pole może normalnie odgrywać główną rolę w zakresie danej funkcji, to jednak różne okolice mózgu są w dużym stopniu zintegrowane i funkcja ta jest reprezentowana w więcej niż w jednym miejscu. Chociaż zatem podział pól i funkcji kory mózgowej na „czuciowe”, „ruchowe” i „kojarzeniowe” może być dogodny, to jednak takie rozróżnienia nie są uzasadnione, w jakimś absolutnym sensie. Po dokonaniu przeglądu ponad 400 sprawozdań z badań nad rolą kory w zachowaniu, autor niedawno opublikowanej pracy na ten temat zmuszony był stwierdzić w konkluzji: „Każde niemal cytowane tutaj sprawozdanie wykazuje, sugeruje lub mówi o tym, że w polach czuciowych występują też funkcje niesensoryczne, w polach ruchowych - funkcje niemotoryczne, a w polach kojarzeniowych - funkcje niekojarzeniowe...  (Jeśli nie zostanie opracowane alternatywne ujęcie o podobnym stopniu ogólności), to można mieć tylko nadzieję, że tych przestarzałych terminów nie będą brać poważnie ani osoby nie zajmujące się tą dziedziną nauki, ani zwłaszcza nowe pokolenia badaczy” (Masterton i Berkeley, 1974, s. 294-295).


Zbliżenie
Hologramy w głowie


„Prawdziwie nowatorską koncepcję sposobu zorganizowania „magazynu pamięciowego” w mózgu wysunął Karl Pribram, który zaproponował |hologram jako model mózgu. Hologram jest to swego rodzaju filtr, w którym obraz zostaje rozproszony w taki sposób, że każdy fragment filtru zawiera elementy z każdego innego fragmentu. Jedną z cech takiego filtru jest to, że gdy zachodzi proces odwrotny do dyfuzji (rozproszenia), to cały obraz można zrekonstruować z każdej jego części.
Istnieją dane, które można by uznać za potwierdzenie koncepcji - „mózgu holograficznego”. Nawet pacjent, u którego atak apopleksji uszkodził znaczną część mózgu, nie zapomina pewnych informacji o swej rodzinie, części języka itp. Reszta mózgu przejmuje funkcje całości. Istnieją także inne, bardziej bezpośrednie dane dotyczące przebiegu procesów elektrycznych w mózgu - informacje odbierane przez każdy ze zmysłów są reprezentowane i rozprowadzane na rozległych obszarach mózgu.
Jak więc pracuje mózg przy obsłudze tych „magazynów pamięciowych?” Ze względu na rozproszone przechowywanie informacji w mózgu muszą działać mechanizmy, które w razie potrzeby „składają to wszystko razem”. Wykazano, że takie programy sterujące działają podobnie jak w komputerze, gdzie program wejściowy wybiera z różnych części to, co ma istotne znaczenie dla tego programu.
Oto niektóre nowe implikacje, jakie wynikają z modelu holograficznego: a) pozornie niezorganizowane (wyglądające na przypadkowe) systemy fizyczne mogą w istocie być wysoce zorganizowane na zasadach holograficznych; b) zasady takie mogą mieć zastosowanie nie tylko w odniesieniu do mózgu (mikrokosmosu jednostki), lecz także do organizacji społecznej; nawet gdy „robisz swoje” odzwierciedlasz w pewnym stopniu działanie całej organizacji, której jesteś elementem”.

Dominacja i specjalizacja półkul mózgowych. Jak wiemy, nowe mózgowie składa się z dwóch półkul mózgowych, z których każda otrzymuje wejściowe dane („wejścia”) czuciowe z przeciwnej strony ciała, a także steruje reakcjami organizmu po tej przeciwnej stronie. Lewa półkula ma pola czuciowe i ruchowe dla prawej połowy pola widzenia i prawej strony ciała, podczas gdy prawa półkula ma podobne pola dla lewej połowy pola widzenia i lewej strony ciała. Obie półkule wymieniając informacje poprzez ciało modzelowate, co umożliwia integrację oddzielnych „wejść” i „wyjść” w skoordynowaną percepcję i zachowanie.
Rywalizacji między dwoma półkulami unika się normalnie dzięki dominacji jednej półkuli nad drugą. Ta asymetria funkcji mózgu jest bardzo podobna do asymetrii, jaka występuje u większości ludzi w pisaniu lewą i prawą ręką.  Napisz poniżej swoje nazwisko posługując się prawą ręką, a następnie zrób to samo lewą ręką.

Prawa ręka ...
Lewa ręka  ...

Czy jest jakaś różnica w wysiłku potrzebnym do wykonania każdego z tych zadań lub w wyglądzie twoich podpisów? Czy jeden z nich nie przypomina nieco pisma dziecka (tak jest u większości ludzi)? Podobnie jak jedna ręka (zwykle prawa) dominuje nad drugą, tak jedna półkula (zwykle lewa) dominuje w sterowaniu mową, czytaniem, pisaniem i obliczeniami matematycznymi.  Podporządkowana półkula jest milczącą, mało elokwentną partnerką. Jest ona okropnie słaba w arytmetyce, lecz doskonała w zadaniach percepcyjnych z zakresu orientacji przestrzennej, rozpoznaje kształty i powierzchnie o różnego rodzaju fakturze, ma dobrą pamięć muzyczną (Sperry, Gazzaniga i Bogen, 1969). Każda z półkul jest więc wyspecjalizowana w wykonywaniu pewnych zadań, których druga nie potrafi wypełniać w ogóle lub wypełnia słabo.
Aby badać funkcjonowanie każdej z półkul u osób pełnosprawnych, z nienaruszonymi połączeniami między półkulami, badacze zaczęli ostatnio mierzyć aktywność elektryczną obu półkul podczas wykonywania różnych zadań.  Amplituda fal mózgowych rejestrowana osobno dla każdej z półkul zmienia się w zależności od charakteru zadania, co wskazuje, która ze stron jest dominującą dla danej czynności (Galin i Ornstein, 1972).
Wydaje się, że dominująca półkula (czy to prawa, czy lewa) reprezentuje aspekt intelektualny, analityczny, krytyczny, podczas gdy druga półkula jest bardziej intuicyjna, artystyczna i być może, także bardziej zmysłowa.  Mózg zdaje się funkcjonować najlepiej, gdy jedna strona chwilowo próżnuje, podczas gdy druga pracuje „na cały regulator”. Są jednak prawdopodobnie ludzie, którzy nauczyli się zbytnio polegać na jednostronnej aktywności mózgu i nie potrafią skutecznie zastosować takiego sposobu działania, jaki jest najodpowiedniejszy w danej sytuacji.


Zbliżenie
Przepołowienie mózgu: dwa umysły w jednym ciele


„Czasami, gdy napady padaczki są zbyt silne i nie można ich opanować za pomocą środków farmakologicznych, przeprowadza się operację polegającą na przecięciu ciała modzelowatego - połączenia między półkulami mózgowymi. Bez takiej operacji napady mogłyby doprowadzić do śmierci chorego, a tak pacjent zostaje uwolniony od napadów i stwierdza, że czuje się lepiej.
Produktem ubocznym tej operacji jest eksperyment naturalny - otrzymuje się niejako dwa mózgi funkcjonujące w jednym ciele. Każda połowa działa niezależnie od drugiej i każda zdaje się mieć swoje własne wrażenia, spostrzeżenia i wspomnienia, jak również własne doświadczenia poznawcze i emocjonalne.
Aczkolwiek pacjenci z przepołowionym mózgiem szybko uczą się sposobów kompensowania utraty koordynacji, to jednak, jak wykazał eksperymentalnie Roger Sperry, żyją oni z dwoma oddzielnie funkcjonującymi mózgami.  Koordynacja wzrokowo-ruchowa u pacjentów z przepołowionym mózgiem jest normalna wtedy, gdy posługują się oni lewą ręką przy szukaniu i dobieraniu takiego samego przedmiotu, jaki pojawił się w lewej połowie ich widzenia, gdy jednak poprosi się ich, aby dotykając przedmiotów prawą ręką znaleźli gruszkę taką jak ta, którą widzą w lewej połowie swego pola widzenia, to nie potrafią tego dokonać.

W tym wypadku pacjent błędnie spostrzega filiżankę jako identyczną z widzianą gruszką. Wszystkie sygnały z prawej ręki pacjenta idą do lewej półkuli mózgowej, która nie ma już połączenia z korą wzrokową prawej półkuli.
Jednakże są pewne sytuacje, w których dwa mózgi byłyby lepsze niż jeden - na przykład wtedy, gdy musisz reagować na dwa zbiory bodźców. Potrzeba ci mniej czasu, by zareagować, gdy w grę wchodzi pojedynczy bodziec, a więcej, gdy musisz nacisnąć jeden przycisk prawą ręką po zapaleniu się lampki z lewej strony, a drugi przycisk lewą ręką po zapaleniu się lampki z prawej strony. Pacjent z przepołowionym mózgiem - w sytuacji badania czasu reakcji z wyborem - reaguje równie szybko, jak przy badaniu czasu reakcji prostej.  Jedna z reakcji jest niezależna od drugiej; nie traci więc on czasu na namysł, czyli koordynację tego, co dzieje się w każdej z półkul mózgowych.  Jest to przypadek, gdy istotnie lepiej jest, że „nie wie prawica, co czyni lewica” (Gazzaniga, 1970).

Obecnie prowadzi się badania mające ustalić, czy ludzie mogą się wyćwiczyć w dowolnym zwiększaniu lub hamowaniu aktywności jednej lub drugiej półkuli. Jeśli mogą, to jaki to będzie miało wpływ na ich uczenie się i zdolności twórcze, jak również na ich poczucie zadowolenia z siebie i ze swego naturalnego otoczenia? Odpowiedź na te fascynujące pytania może przynieść dopiero następny etap badań psychofizjologicznych.

Eferentne sterowanie aferentnym wejściem. Wejście czuciowe (tzw.  informacje przychodzące |do układu nerwowego) wpływa oczywiście na działanie i kieruje nim, czy jednak samo podlega oddziaływaniom o odwrotnym kierunku? Czy można wykazać, że mózg wpływa na fizjologiczny przebieg aktywności aferentnej (wejściowej) w samych receptorach lub w jakimś innym miejscu drogi, którą informacja sensoryczna zdąża do mózgu? W jakiej mierze układ nerwowy jest raczej arterią dwukierunkową niż siecią niezależnych jednokierunkowych ulic?
Karl Pribram ze Stanford University badał to zagadnienie, uzyskując fascynujące rezultaty. Zgromadził on przekonywujące dowody, że aktywność kory czuciowej i ruchowej oraz pierwszego pola kojarzeniowego (dolnej części kory skroniowej) może wpływać na impuls nerwowy, generowany w oku przez błysk światła.

„Zastosowana technika polegała na mierzeniu okresu refrakcyjnego, który upływał między dwoma kolejnymi błyskami światła wytwarzającymi potencjał wywołany w głównej korze wzrokowej. W jednej sytuacji, w tym samym czasie co kora wzrokowa, drażniona była, niezależnie od niej, także kora kojarzeniowa. W innej sytuacji drażniona była jedynie kora wzrokowa. Okres refrakcji był dłuższy, gdy drażniono także korę kojarzeniową, co wskazuje, że aktywność w jednej części mózgu wpływa na procesy w drugiej jego części.  Były też inne przejawy eferentnej kontroli nad aferentnym wejściem - wykazano, że skutki drażnienia tych pól kojarzeniowych wpływają na |przychodzące impulsy nerwowe już w nerwie wzrokowym (nerw, który przewodzi impulsy z siatkówki do mózgu).

Pozostaje zatem niewiele wątpliwości, co do tego, że aktywność kory kojarzeniowej może wpływać na przetwarzanie bodźców wzrokowych w głównym układzie czuciowym (Spinelli i Pribram, 1967).
Późniejsze eksperymenty wykazały, że czynność bioelektryczna mózgu (fale mózgowe), zainicjowana przez określone wejście sensoryczne, również zmienia się z czasem w wyniku wpływu uprzednich reakcji na tę sensoryczną informację (Rothblat i Pribram, 1972).

„W czasie, gdy małpy uczyły się różnicowania, we wzrokowej korze kojarzeniowej rejestrowano reakcje wywołane w odpowiedzi na bodźce wzrokowe. Małpy miały nauczyć się reagować albo na barwę, albo na kształt barwnego wzoru i hamować reakcję na drugą z tych cech. Jedna grupa otrzymywała wzmocnienie za pozytywne reagowanie na barwę, druga grupa - za pozytywne reagowanie na kształt.
Gdy małpy nauczyły się tego różnicowania, wówczas wzorce ich czynności nerwowej były różne nawet wtedy, gdy bodźce działające na siatkówkę były takie same. Ponadto, ta zróżnicowana czynność nerwowa występowała wyraźnie około 5 milisekund przed reakcją zewnętrzną, podczas gdy we wczesnym etapie uczenia się aktywność fal mózgowych była identyczna przed obydwoma reakcjami. Na aktywność wzrokowej kory kojarzeniowej wpływa najwyraźniej nie tylko aktualna stymulacja siatkówki, lecz także konsekwencje uprzednich reakcji. Takie sprzężenie zwrotne zostało prawdopodobnie w jakiś sposób zmagazynowane w mózgu”.

Implikacje, jakie ma dla psychologii ten nowy pogląd na sposób funkcjonowania mózgu, wielu badaczy uważa za rewolucyjne. W latach dwudziestych, trzydziestych a nawet pięćdziesiątych modelem funkcjonowania ośrodkowego układu nerwowego, wyznaczającym kierunek badań i dociekań teoretycznych, był rygorystyczny model bodziec - reakcja, wejście - wyjście, model łuku odruchowego. Wynikiem był klasyczny behawioryzm tego okresu, przyjmujący, że zachowaniem organizmu kieruje wyłącznie „wejście” środowiskowe, to znaczy warunki bodźcowe. Wraz ze zrewidowaniem poglądu na układ nerwowy - który pojmowany jest obecnie jako sterujący, cybernetyczny, wyposażony w sprzężenie zwrotne mechanizm - zdano sobie sprawę, że receptory zmysłowe są w równym stopniu uzależnione od mózgu, jak i od środowiska (Miller, Galanter i Pribram, 1960; Pribram, 1971). Od lat sześćdziesiątych głównym przedmiotem dociekań stały się zatem procesy poznawczego sterowania zachowaniem; w ich badaniu bardzo pomocna była nowa metoda - symulacja komputerowa.

Fale mózgowe. Od okresu przed urodzeniem aż do momentu śmierci mózg nigdy nie przerywa swej stałej aktywności, nigdy nie „odpoczywa” - nawet przez minutę. Rejestrując czynność bioelektryczną mózgu (|elektroencefalogram, EEG) za pomocą elektrod przymocowanych do skóry czaszki, ustalono, że nawet w czasie snu mózg nieustannie utrzymuje wysoki poziom aktywności elektrycznej. Te elektroencefalogramy spontanicznej czynności mózgu, podobnie jak potencjały wywołane za pomocą drażnienia, o których była mowa wcześniej, można obserwować na ekranie oscyloskopu. Różnica polega na tym, że w wypadku EEG poszukuje się charakterystycznych cech aktywności, a zapis reprezentuje złożoną, ciągłą przeciętną wielu sygnałów, a nie odrębną reakcję na określony bodziec.
Czym |są fale mózgowe i co mówią nam one o fizjologicznym podłożu doznań i zachowania, problemie najbardziej interesującym nas w tym rozdziale? Fale mózgowe są prawdopodobnie odzwierciedleniem następujących po sobie stanów pobudliwości i refrakcji neuronów. Wiele równolegle biegnących włókien nerwowych jest aktywnych w każdym połączeniu synaptycznym ich drogi wiodącej przez mózg, tworząc fale zmiennego potencjału elektrycznego. W każdej „stacji przekaźnikowej” kory może być aż 100 neuronów; toteż posuwająca się fala może w ciągu sekundy objąć ponad 100 tys. neuronów.  Czoło tej fali może przebiegać różnymi drogami przez mozaikę neuronów i może nawet powrócić do punktu wyjścia, tworząc obwód rewerberacyjny. 
Takie czoła fal mogą być zarówno nosicielami częstotliwościowego kodu czuciowego impulsu nerwowego, jak i środkiem umożliwiającym zorganizowanie częściowych informacji tak, aby utworzyły sensowne doznanie sensoryczne.  Jak już mówiliśmy, informacja czuciowa z receptorów przychodzi do kory jako specyficzny sygnał, który można wykryć nawet w pojedynczych komórkach odpowiednich czuciowych pól projekcyjnych kory. Ponieważ jednak różne komórki kory dekodują informację o różnych cechach obiektu (wielkości kształcie, ruchu, barwie, fakturze powierzchniowej, ciężarze, zapachu, temperaturze itd.), przeto cała ta informacja musi być w jakiś sposób zintegrowana.

Integracja ta może zachodzić między czołami fal generowanych przez impulsy każdego z tych narządów receptorowych. Niektórzy badacze przypuszczają, że te nieustannie napływające czoła fal wiążą ze sobą i integrują wejścia z wszelkich narządów zmysłowych i wyjścia w postaci reakcji.
Cała ta aktywność mózgu wymaga wydatkowania wielkiej ilości energii w formie metabolizmu komórkowego. Gdy człowiek spoczywa bez ruchu, wówczas na metabolizm ten przypada 20% ogólnego zużycia tlenu przez organizm. Gdy aktywność mózg wzrasta w wyniku lęku lub skupienia uwagi, wówczas mózg zużywa więcej tlenu. I przeciwnie, gdy funkcjonowanie mózgu zaczyna słabnąć (jak u ludzi w podeszłym wieku cierpiących na otępienie starcze) lub dochodzi prawie do punktu zerowego (jak w ogólnym znieczuleniu chirurgicznym lub śpiączce alkoholowej) wówczas mózg zużywa znacznie mniej tlenu - czasem mniej niż połowę normalnego zapotrzebowania. Uważa się, że procesy zakłócające przekazywanie synaptyczne zmniejszają zużycie tlenu przez mózg (Kety, 1967b).
Praktyczne zastosowania prowadzonych obecnie badań nad falami mózgowymi przypominają trochę science fiction. Możemy tu przytoczyć parę przykładów.

„W badaniach przeprowadzonych w Stanach Zjednoczonych (U. S Naval Academy) porównywano zapis EEG uzyskany z mózgów 25 „piątkowych” studentów (A students) i tej samej liczby studentów „trójkowych” (C students) w czasie, gdy wykonywali oni szereg zadań. Studenci „piątkowi” wytwarzali istotnie różne fale mózgowe przy rozmaitych zadaniach lub w różnych sytuacjach - w czasie odpoczynku, przy rozwiązywaniu problemów i w czasie stresu; studenci „trójkowi” nie wykazywali takiej odpowiednio zróżnicowanej reakcji. Najlepsi studenci potrafili także wytworzyć większą ilość fal mózgowych o wolniejszym rytmie, znanych jako fale alfa (zostaną one opisane w Rozdziale 7).
Czy mniej uzdolnieni studenci mogą zmienić przebieg swych fal mózgowych, tak aby upodobnić je do przebiegów występujących u kolegów uzyskujących dobre wyniki? W czasie, gdy pisaliśmy te słowa, ćwiczono grupę „trójkowych” studentów w dowolnym wywoływaniu u siebie fal alfa i większości udało się tego dokonać. Czy wpłynie to na ich stopnie - trzeba będzie dopiero ustalić.
Przeprowadzono także analizę zapisów EEG dokonanych wtedy, gdy badani przechodzili od koncentracji uwagi do bezcelowego marzenia na jawie („Gdzie Ty jesteś w tej chwili?”). Badania te doprowadziły do skonstruowania „analizatora poziomu uwagi”, który kontroluje poziom koncentracji i wydaje ostrzegawczy dźwięk, gdy myśli badanego zaczynają gdzieś błądzić. Jeśli badany nadal oddaje się marzeniom, dźwięczy drugi alarm, zawiadamiając o tym fakcie inną osobę.
Urządzenie to funkcjonowało dobrze w odniesieniu do około trzech czwartych ogólnej liczby badanych. Badacz sugeruje, że można by je stosować do alarmowania pilotów lub kierowców ciężarówek, gdy ich czujność osłabnie i będzie mniejsza, niż powinna być; pozwoliłoby ono również pracownikom wież kontrolnych na lotniskach, operatorom urządzeń radarowych i hydrolokacyjnych (sonaru) oraz ich zwierzchnikom zdać sobie sprawę z tego, że wykonywanemu zadaniu nie poświęca się dość uwagi” (Montor, 1973).

Inna nowa, fascynująca dziedzina badań praktycznych polega na stosowaniu stymulacji „ośrodków przyjemności” w celu nauczania mózgu sterowania swą własną aktywnością. Odkrycie, że w mózgu istnieją „ośrodki przyjemności”, które dostarczają motywacji do celowego reagowania o wysokim poziomie intensywności, zapoczątkowało nową erę w badaniach nad mózgiem i sposobami sterowania zachowaniem.

„W jednej serii eksperymentów badano, w jakim stopniu można wyćwiczyć mózg, by kierował wyładowaniem pewnej grupy neuronów w szlaku wzrokowym.  Potencjały wywołane przez błysk światła przed okiem zwierzęcia rejestruje się za pomocą elektrod implantowanych w neuronach czuciowych w mózgu; wyładowują się one z charakterystyczną amplitudą i częstotliwością. Gdy tylko aktywność w formie potencjałów wywołanych zmienia się nieco w określonym z góry kierunku, wówczas mózg jest nagradzany bezpośrednią przyjemną stymulacją. Przez zastosowanie takiej procedury biologicznego sprzężenia zwrotnego (biofeedback procedure) można zwiększyć dwukrotnie amplitudę tych potencjałów wywołanych lub też stłumić je całkowicie.
W ten sposób mózg może nauczyć się nie tylko wywoływania wyładowań pojedynczych neuronów w niespecyficzny sposób, lecz także zmieniania i modulowania ogólnych form aktywności. Na przykład rytm sensoryczno-motoryczny jest to specyficzny rytm fal mózgowych (12-16 cykli na sekundę) generowany przez korę czuciowo-ruchową. Fale mózgowe kota przepuszczano przez specjalne urządzenie filtrujące, które elektrycznie uruchamiało aparat dozujący pokarm, gdy tylko pojawiły się „właściwe” fale.  Mózg głodnego kota miał zatem za zadanie wytworzyć więcej fal o rytmie sensoryczno-motorycznym, tak aby kot dostał jedzenie. To, czy głodny kot będzie jadł czy nie, zostało całkowicie uzależnione od tego, czy jego mózg potrafi zmienić rytm swoich własnych fal.
Po dwudziestu sesjach treningowych właściwe rytmy były wytwarzane częściej niż przedtem. Następnie, gdy kota przestano nagradzać za wytwarzanie tych rytmów, mózg zmniejszał ich „produkcję” (podał Chase, 1973).

Przypuszczalnie niewielu jest uczniów zdolniejszych i pilniejszych od mózgu - co wykazały dalsze badania, w których występowanie rytmu sensoryczno-motorycznego u kotów warunkowano tak, aby pojawił się tylko w jednej półkuli mózgowej. Gdy koty te spały, wówczas tylko ta jedna strona mózgu była nadal pod wpływem tego, co nauczyła się robić w czasie czuwania.
Najbardziej ekscytujące ze wszystkich jest chyba eksperyment M. B.  Stermana (1971), w którym porównywano reakcję na pewną trującą substancję, jakie występowały u kotów ćwiczonych w regulowaniu aktywności elektrycznej swego mózgu i kotów nie poddawanych żadnemu specjalnemu treningowi. Sterman mówi o ćwiczonych kotach co następuje:


„Interesujące było obserwowanie tych zwierząt. Chociaż były one ćwiczone dużo wcześniej, zdawały się opanować wyładowania występujące w ich mózgach przez przyjęcie dziwacznej, nieruchomej postawy, częste gapienie się w przestrzeń lub wpatrywanie się w nieruchomą, podniesioną łapę. Najwyraźniej nauczyły się, jak hamować aktywność ruchową i w ten sposób opóźniać, a nawet zapobiegać wystąpieniu reakcji ruchowych (drgawek) wywoływanych działaniem tego niezwykle toksycznego środka”.

Nasze potencjalne możliwości, jeśli chodzi o programowanie własnego mózgu w taki sposób, by wykorzystać go do podtrzymywania i wzbogacania naszego życia, wydaje się nieograniczone.


Streszczenie rozdziału

Naukowe badania nad mózgiem ludzkim rozpoczęły się na początku XVI wieku.  Zakładając, że ciało i mózg mają charakter mechanistyczny, w odróżnieniu od spirytualistycznej duszy, Rene Descartes przezwyciężył religijne obiekcje wobec badania funkcji mózgu.
Ci psychofizjologowie, którzy poszli w ślady Descartesa, skłonni są przyjmować podejście |redukcjonistyczne - starają się oni zrozumieć złożone procesy zachowania, badając prostsze zjawiska neurologiczne czy biochemiczne. Wielu innych psychologów wybiera podejście |holistyczne, badając organizm jako całość, nie jego funkcjonujące elementy.
Wymagania środowiska kształtują cechy żyjących gatunków, ponieważ zapewniają przetrwanie i reprodukcję tych jednostek, które mają największą zdolność przystosowania się. Przekazywanie cech z pokolenia na pokolenie dokonuje się za pośrednictwem |chromosomów; składają się one z |genów - długich skręconych spirali kwasu dezoksyrybonukleinowego (DNA). |D|N|A kieruje reprodukcją komórek organizmu i wytwarzaniem protein. |Mutacje, czyli zmiany w strukturze DNA, mogą powodować korzystne lub niekorzystne zmiany w organizmie przekazywane przyszłym pokoleniom.
W rozmnażaniu płciowym dwie |komórki |zarodkowe (męski |plemnik i żeńska |komórka |jajowa) łączą się tworząc |zygotę - pojedynczą komórkę, która rozwinie się w nowego osobnika. Ponieważ zarówno plemnik, jak i komórka jajowa, zawierają tylko po połowie chromosomów niezbędnych dla komórek nowego organizmu, zatem geny występujące w danym gatunku nieustannie układają się w nowe kombinacje.
Chociaż organizmy jednokomórkowe zawierają elementy niezbędne dla przetrwania, to jednak ich zdolność przystosowywania się jest ograniczona.  Organizmy wielokomórkowe cechuje znacznie większa elastyczność, wynikająca ze |specjalizacji komórek dostosowanych do pełnienia różnego typu funkcji.  Wyspecjalizowane komórki tworzące |układ |nerwowy umożliwiają organizmowi przetwarzanie informacji z otoczenia i reagowanie na nie.
Podstawowymi elementami układu nerwowego są |komórki |nerwowe, czyli |neurony, które przekazują informację w formie |impulsów |nerwowych.  Neurony różnią się wielkością i kształtem, lecz każdy składa się z |ciała |komórkowego, |dendrytów, które odbierają impulsy nerwowe oraz |aksonu, który przekazuje impulsy do innych neuronów. |Przewodzenie |impulsów |wzdłuż |aksonu przenosi informację w obrębie neuronu; |przekazywanie |synaptyczne przenosi ją przez synapsę do innego neuronu.
W stanie spoczynku akson jest |spolaryzowany, przy czym wewnętrzna powierzchnia błony komórkowej ma ładunek elektryczny ujemny w stosunku do powierzchni zewnętrznej. Impuls nerwowy powstaje wówczas, gdy stymulacja jest dostatecznie silna, by spowodować |depolaryzację błony; ta zmiana |potencjału |błony biegnie następnie wzdłuż włókna nerwowego. Akson przekazuje na zasadzie „|wszystko |albo |nic” - albo pełen impuls, albo nie przekazuje w ogóle żadnego impulsu. Liczba wyładowujących się neuronów oraz częstotliwość tych wyładowań przekazują informację o intensywności stymulacji.
W |przekazywaniu |synaptycznym informacja jest przenoszona przez synapsę (maleńką szczelinę między jednym neuronem a następnym) za pośrednictwem |chemicznych |substancji |przekaźnikowych, które wpływają na polaryzację następnego neuronu. Jeśli polaryzacja |błony |postsynaptycznej zmaleje, to następne neuron wyładowuje się. Dzięki |sumowaniu |przestrzennemu i |czasowemu możliwa jest integracja informacji przychodzącej z kilku neuronów. Dlatego też mówi się, że przekazywanie synaptyczne odbywa się według zasady „|więcej |albo |mniej”. Impulsy biegną tylko w jednym kierunku, stosownie do prawa |przewodzenia |jednokierunkowego: od dendrytu do aksonu i przez synapsę do dendrytów lub ciała komórkowego następnego neuronu.
Układ nerwowy składa się z dwóch głównych części: |ośrodkowego |układu |nerwowego (mózg i rdzeń kręgowy) oraz |obwodowego |układu |nerwowego, który łączy ośrodkowy układ nerwowy z receptorami i efektorami w całym ciele. Część |somatyczna obwodowego układu nerwowego kieruje mięśniami szkieletowymi (poprzecznie prążkowanymi). Część |trzewna (|autonomiczny ukłąd nerwowy) łączy ośrodkowy układ nerwowy z narządami wewnętrznymi.  Autonomiczny ukłąd nerwowy dzieli się z kolei na dwie części - |sympatyczną (współczulną), która reguluje funkcje mobilizacyjne, występując w sytuacji nagłej potrzeby, oraz |parasympatyczną (przywspółczulną), która zawiaduje ciągłymi funkcjami życiowymi.
|Neurony |pośredniczące, czyli |kojarzeniowe, w ośrodkowym układzie nerwowym dostarczają połączeń między impulsami |aferentnymi przechodzącymi z receptorów zmysłowych a impulsami eferentnymi skierowanymi do mięśni i gruczołów. Podstawowym wzorcem każdego aktu  bodziec-reakcja jest |łuk |czuciowo-|ruchowy, składający się z wejście bodźcowego, przetwarzania w ośrodkowym układzie nerwowym i wyjścia w postaci zachowania. W |czynności |odruchowej, najprostszej formie zachowania, przetwarzanie informacji w ośrodkowym układzie nerwowym, może zachodzić wyłącznie w rdzeniu kręgowym, bez angażowania wyższych ośrodków nerwowych. Sieć neuronów w rdzeniu kręgowym umożliwia |dywergencję i |konwergencję impulsów, tworzenie pętli |sprzężenia |zwrotnego oraz |przedłużanie |przepływu informacji do mózgu.
W obecności nowych, konfliktowych lub szczególnie ważnych bodźców występuje w organizmie |reakcja |orientacyjna, w skład której wchodzą: wzrost wrażliwości, wzmożenie aktywności mięśniowej, ogólne wzbudzenie oraz zmiany w narządach wewnętrznych, przygotowujące organizm do działania. Gdy bodźce staną się już znane, wówczas następuje |habituacja, a reakcje słabną lub zanikają. Po wystąpieniu habituacji zmiana bodźca może spowodować |dyshabituację i przywrócić reakcję orientacyjną.
Funkcje mózgu bada się za pomocą lezji (uszkadzania tkanek mózgu), elektronicznego |rejestrowania czynności mózgu oraz elektrycznego lub chemicznego |drażnienia (stymulacji) mózgu. Mózg składa się z dwóch |półkul |mózgowych, które łączy |ciało |modzelowate; każda z półkul ma cztery płaty: |czołowy, |skroniowy, |ciemieniowy i |potyliczny. Zewnętrzna warstwa półkul mózgowych nosi nazwę |kory lub |kory |nowej.
Starsze ewolucyjnie |stare |mózgowie steruje funkcjami pierwotnymi, takimi jak popędy, odczuwanie przyjemności i przykrości. Ważną częścią starego mózgowia jest |pień |mózgu, w skład którego wchodzi |wzgórze, ważna stacja przekaźnikowa dla informacji sensorycznej, |podwzgórze, zawiadujące wieloma istotnymi dla życia funkcjami, oraz |twór |siatkowaty - układ ogólnie pobudzający. |Układ limbiczny (rąbkowy) jest to prymitywna tkanka w korze mózgowej odgrywająca istotną rolę w funkcjach tak różnorodnych, jak uwaga, emocje i pamięć. Do układu limbicznego należy |węchomózgowie, zawiadujące wykrywaniem zapachów, oraz |hipokamp, który ma swój udział zarówno w funkcjach seksualnych, jak i w funkcjach pamięciowych.
Główne pola |czuciowe, odbierające informację sensoryczną, są zlokalizowane w stosunkowo wyspecjalizowanych częściach kory: funkcje słuchowe w płacie |skroniowym, a funkcje wzrokowe w płacie |potylicznym.  Główne pola zawiadujące funkcjami |ruchowymi są zlokalizowane w okolicach kory położonych tuż przed bruzdą Rolanda. Pozostały obszar kory zajmują pola |kojarzeniowe, gdzie dokonuje się integracja funkcji sensorycznych i ruchowych. Uszkodzenie tych pól może spowodować zaburzenia w rozumieniu mowy lub w posługiwaniu się nią. Sposób funkcjonowania mózgu cechuje duża |redundancja, dzięki czemu, jeśli pewne pola są uszkodzone, inne części mózgu mogą przyjąć ich funkcje.
Każda z półkul mózgowych otrzymuje wejście sensoryczne z przeciwnej strony ciała i wysyła do niej polecenia. Jedna z półkul (zwykle lewa) jest |dominującą dla większości funkcji, jednakże istnieje duża specjalizacja funkcji. Istnieją dane świadczące o |eferentnej |regulacji |aferentnego |wejścia, innymi słowy, sygnały z mózgu mogą wpływać na przekazywanie przychodzących impulsów sensorycznych.
|Fale |mózgowe, rejestrowane za pomocą elekrtoencefalogramu (EEG), są odzwierciedleniem spontanicznej aktywności neuronów w mózgu. Na podtrzymanie aktywności mózgu idzie około 20% tlenu zużywanego przez organizm.


Z Frontu Badań.
Fizjologiczna analiza motywowanego zachowania

|Philip |Teitelbaum „Illinois University”


Wielu studentom wydaje się, że psychofizjologia zajmuje się przede wszystkim neuronalnymi mechanizmami stanowiącymi podstawę zachowania, a nie samym zachowaniem: stosując metody anatomiczne, psychofizjologowie często starają się zlokalizować te części mózgu, które wiążą się z interesującymi zjawiskami psychicznymi, takimi jak uczenie się, spostrzeganie, motywacja i procesy poznawcze. Mogą oni badać zapisy czynności bioelektrycznej mózgu lub zmiany w układzie autonomicznym związane z procesami behawioralnymi.  Badania te pozwalają im być może wniknąć głębiej w strukturę i funkcje układu nerwowego, lecz często zdają się mieć niewielki związek z badaniami nad zachowaniem prowadzonymi przez przedstawicieli innych działów psychologii.
Jednakże psychofizjologia może także stanowić bardzo efektywny, bezpośredni sposób podejścia do analizy zachowania. Gdy pewna część mózgu jest uszkodzona, wówczas kontrolowane przez nią zachowanie może całkowicie zaniknąć lub ulec redukcji do bardzo prostej, fragmentarycznej formy.

Fazy Występowania Zaburzeń Spowodowanych Uszkodzeniem Bocznej Części 
Podwzgórza
A - Faza I - Adypsja - Afagia
B - Faza II - Adypsja - Anoreksja
C - Faza III - Adypsja - Afagia przez odwodnieniu
D - Faza IV - Ustąpienie zaburzeń
Je wilgotne, smaczne pokarmy: A-nie B-tak C-tak D-tak
Reguluje ilość pobieranego pokarmu i ciężar ciała jedząc wilgotne smaczne 
pokarmy: A-nie B-nie C-tak D-tak
Je suche pokarmy (gdy nie występuje odwodnienie): A-nie B-nie C-tak D-tak
Pije wodę, utrzymuje się przy życiu jedząc suchy pokarm i pijąc wodę: 
A-nie B-nie C-nie D-tak
Źródło: Teitelbaum i Epstein, 1962.

Następnie, w miarę wyrównywania się defektu, zachodzi stopniowa reintegracja zachowania, co pozwala nam obserwować występujące w nim poziomy organizacji. Krótko mówiąc, możemy posłużyć się |uszkodzeniem |mózgu dla „uproszczenia” zachowania i wykorzystać |ustępowanie |powstałego |zaburzenia do ustalenia, w jaki sposób komponenty behawioralne ponownie zostają zintegrowane, umożliwiając efektywne funkcjonowanie organizmu.
Na przykład, od dawna wiadomo, że struktury mózgowe przechodzące przez podwzgórze odgrywają ważną rolę w zachowaniu motywowanym. Krótkie podrażnienie prądem elektrycznym bocznej części podwzgórza może wywoływać uczucie przyjemności u ludzi, a zwierzęta naciskają dźwignię tysiące razy, aby stymulować tę okolicę swego mózgu, co wskazuje, że im również czynność ta dostarcza wzmocnienia. Dłuższa symulacja bocznej części podwzgórza może wywoływać u nasyconych zwierząt reakcje jedzenia lub picia, a nawet kopulację lub napastowanie.
Jeśli uszkodzimy boczną część podwzgórza po obu stronach, wówczas szczury, koty, psy, małpy, a nawet ludzie przestaną jeść i pić; zwierzęta mogą nie przyjmować jedzenia (|afagia) i nie pić (|adypsja) tak długo, aż zginą. Badania laboratoryjne wykazały jednak, że jeśli zwierzęta takie utrzymuje się przy życiu karmiąc je przymusowo przez odpowiednio długi czas, to w końcu odzyskują one zdolność jedzenia i picia (Teitelbaum i Epstein, 1962).
Behawioralny wzorzec ustępowania zaburzeń u dorosłych szczurów z uszkodzeniami bocznej części podwzgórza przedstawiono schematycznie na zamieszczonej obok tabeli. W odniesieniu do tego zespołu uderzający jest fakt, że u każdego zwierzęcia z takimi uszkodzeniami mózgu |kolejność ustępowania zaburzeń jest taka sama, chociaż tempo przebiegu tego procesu może być różne. Ponieważ zachowanie zawsze odzwierciedla czynności mózgu, zatem taka reorganizacja funkcji mózgowych powinna dostarczyć nam informacji o sposobie, w jaki zorganizowane jest zachowanie.  
Zachowanie szczura z uszkodzeniem bocznej części podwzgórza, w czasie ustępowania zaburzeń, przypomina pod pewnymi względami zachowanie nowo narodzonego szczura. Na przykład w stadium afagii, gdy odmawia przyjmowania suchego pokarmu i wody, ssie odruchowo smoczek założony na butelkę. W późniejszym okresie ustępowania zaburzeń, chociaż je suchy pokarm i pije wodę, nadal nie reaguje w pełni na odwodnienie. U zdrowych zwierząt - osesków - występują podobne braki w zachowaniu związanym z piciem. Jeśli istnieje pewna analogia między procesem ustępowania zaburzeń (recovery) a procesem rozwoju, to wszystkie stadia stwierdzone w przypadku ustępowania zespołu uszkodzenia bocznej części podwzgórza powinny także występować we właściwej kolejności w pierwszym okresie życia zwierząt. W celu zbadania tego zagadnienia zwalnialiśmy przebieg normalnego rozwoju usuwając chirurgicznie nowo narodzonym szczurom tarczycę. Spodziewaliśmy się, że pozwoli to ujawnić powolny rozwój elementów regulacji, podobnie jak powolny przebieg ustępowania zaburzeń ujawnia elementy regulacji w zespole uszkodzenia bocznej części podwzgórza (Teitelbaum, Cheng i Rozin, 1969).
Wpływ usunięcia tarczycy na opóźnienie zarówno przyrostu wagi, jak i powiększania się rozmiarów ciała u szczurów wystąpił bardzo wyraźnie. U szczurów z usuniętą tarczycą, gdy badano je w wieku, w którym zwykle przestają ssać (21 dzień życia), stwierdzono wszystkie stadia rozwoju uszkodzenia bocznej części podwzgórza. U zwierząt najbardziej opóźnionych w rozwoju wystąpiła całkowita afagia i adypsja, niezależnie od tego, czy dawano im wilgotne, smaczne pokarmy, czy zwykły pokarm i wodę. Ssały one odruchowo, lecz, tak samo jak dorosłe szczury z afagią spowodowaną uszkodzeniem bocznej części podwzgórza, nie przyjmowały dobrowolnie pokarmu ani wody, bez względu na to, jak były one smaczne. Inne zwierzęta, lepiej rozwinięte w momencie odłączenia od matki, chętniej przyjmowały wilgotne, smaczne pokarmy, lecz jadły zbyt mało, aby utrzymać prawidłową wagę ciała.  Jeśli stadium to trwało zbyt długo, to zwierzęta ginęły. Inne szczury, jeszcze mniej opóźnione w rozwoju w momencie odłączenia od matki, przybierały na wadze i regulowały pobór kalorii przy płynnej diecie, lecz nadal przejawiały adypsję i zginęłyby, jeśli później dawano by im tylko suchy pokarm i wodę (z niektórymi rzeczywiście tak się stało). I wreszcie najmniej opóźnione w rozwoju zwierzęta przyjmowały suchy pokarm i wodę, lecz piły tylko wtedy, kiedy jadły, a nie reagowały piciem na odwodnienie organizmu. Zależnie zatem od stopnia opóźnienia w rozwoju, można było zaobserwować u tych szczurów każde stadium zespołu uszkodzenia bocznej części podwzgórza u dorosłych zwierząt (przedstawione w tabeli). W odrębnym eksperymencie głodziliśmy szczury w okresie ssania, systematycznie ograniczając im dostęp do matki, od chwili urodzenia do czasu odłączenia od niej (Cheng, Rozin, Teitelbaum, 1971). Oseski z grupy kontrolnej, które miały nieograniczony dostęp do matki, rozwijały się normalnie. Badając zwierzęta słabo rozwinięte w wyniku głodówki, w czasie odłączenia od matki (tzn. w wieku 21 dni), stwierdzono u nich wszystkie stadia zespołu uszkodzenia bocznej części podwzgórza. Te, które przeżyły, podobnie jak szczury z usuniętą tarczycą, przeszły przez różne stadia w procesie rozwoju. Opóźnienie w rozwoju, spowodowane przez którąkolwiek z zastosowanych dwóch metod, wykazuje zatem znaczną analogię do zespołu uszkodzenia w bocznej części podwzgórza.


Analogie w innym systemie


Można by bardziej wierzyć trafności analogii pomiędzy przebiegiem ustępowania zaburzenia u dorosłego zwierzęcia a rozwojem oseska, gdyby można było stwierdzić taką samą analogię w innym systemie struktur mózgowych, nie związanych z jedzeniem i piciem. Analogię taką w istocie zademonstrowano w badaniach nad tym, jak ludzie po udarze mózgu stopniowo odzyskują zdolność dowolnego posługiwania się ręką. Wczesne badania wykazały, że chociaż sparaliżowanej kończyny nie można było użyć do działań dowolnych, to jednak można było wywołać w niej kilka rodzajów odruchów.

Na przykład, zidentyfikowano w tym przypadku trzy typy odruchowego chwytania: 1) reakcję trakcyjną (traction response), gdy pociągnięcie zgiętej ręki powoduje zaciśnięcie pięści; 2) prawdziwy chwyt, gdy dotknięcie palca lub pręcika przesuwanego przez dłoń powoduje zaciśnięcie palców; oraz 3) instynktowną reakcję chwytania, w której dłoń skierowuje się ku bodźcowi i szuka go po omacku, gdy on znika. Twichtell (1951) wykazał, że odruchy chwytania pojawiają się jeden po drugim w odrębnych stadiach odzyskiwania zdolności dowolnego posługiwania się ręką. Później Twitchell (1970) zidentyfikował bardzo podobne stadia w normalnym rozwoju dowolnej kontroli chwytania u noworodków. Możemy zatem wysunąć stąd wniosek, że u ludzi, podobnie jak u szczurów, przebieg ustępowania zaburzeń u dorosłych jest analogiczny do przebiegu rozwoju niemowlęcia.
Nie wiadomo jeszcze, w jaki sposób tkanka nerwowa odnawia się po uszkodzeniu. Być może wchodzi tu w grę wzmożona synteza neuronalnych substancji przekaźnikowych w pozostałym fragmencie częściowo zniszczonego układu, zwiększenie wrażliwości na te substancje, odrastanie neuronów i tworzenie się synaps. Z analogii do rozwoju wynika sugestia, że te połączenia nerwowe, które rozwijają się pierwsze, będą również najpierw odnawiać się po uszkodzeniu.
Z behawioralnego punktu widzenia istnieją ważne implikacje tej analogii pomiędzy przebiegiem ustępowania zaburzeń a przebiegiem rozwoju. Motywowane zachowanie musi być zorganizowane - podobnie jak system nerwowy, którego działanie odzwierciedla - według poziomów inteligencji. To właśnie jest wspólne dla stadiów rozwoju i stadiów ustępowania zaburzeń. Rozpatrzmy raz jeszcze zachowanie związane z pobieraniem pokarmu. Najwcześniejszy typ zachowania, który pojawia się u płodu ludzkiego, polega na ogólnej reakcji cofnięcia głowy i ciała w odpowiedzi na dotknięcie okolicy ust. W miarę postępu rozwoju reakcja na taką stymulację zmienia się: występują ruchy głowy w kierunku, z którego pochodzi stymulacja (podstawowe odruchy - rooting reflexes) i pojawiają się w końcu lokalne odruchy otwierania i zamykania ust, połykania i ssania. Wiemy, że odruchy takie nie wymagają funkcjonowania podwzgórza ani żadnej części mózgu powyżej poziomu śródmózgowia, ponieważ można je zaobserwować u niemowląt, które urodziły się bez części mózgu lub w ogóle bez mózgu oraz u dorosłych zwierząt, którym usunięto mózgowie. Jednakże w takich przypadkach odruchy te nigdy nie rozwiną się w bardziej złożone mechanizmy pobierania pokarmu.  Prawidłowo rozwijające się niemowlę stopniowo włącza i przekształca proste odruchy pokarmowe w bardziej złożone zachowania pokarmowe, a zatem rozwój wyższych części układu nerwowego musi być niezbędny dla przekształcenia prostych odruchów pokarmowych w motywowane zachowanie regulacyjne.  Bezpośrednio po lezji u dorosłych zwierząt z rozległym uszkodzeniem bocznej części podwzgórza występuje jedynie odruch ssania; przebieg ustępowania zaburzenia jest w tym wypadku podobny do zwolnionego rozwoju u niemowląt.  Możemy zatem wyciągnąć stąd wniosek, że w wypadku rozwoju następuje |encefalizacja zachowania, natomiast w wypadku ustępowania zaburzenia - jego |reencefalizacja.
Ten sposób podejścia umożliwia nam efektywną analizę i eksperymentowanie, zarówno w odniesieniu do mózgu, jak i zachowania. W stosunku do organizacji układu nerwowego oznacza to, że musimy myśleć nie tylko w kategoriach zlokalizowanych ośrodków funkcji, lecz także w kategoriach pionowo zorganizowanych struktur mózgowych, przy czym kolejne stacje przekaźnikowe, od rdzenia kręgowego do kory, zwiększają złożoność organizacji. Stosownie do tego, aby zrozumieć jakieś zjawisko z zakresu zachowania, musimy rozpatrywać je tak, jak rozpatrywaliśmy stadium rozwoju czy ustępowania zaburzeń. Ma to sens tylko jako transformacja z poprzedniego stadium integracji (niższego poziomu encefalizacji) do stadium wyższego.  |Zachowanie, |podobnie |jak |układ |nerwowy, |można |określić |jako |hierarchicznie |zorganizowaną |strukturę.
Posłużmy się tym sposobem myślenia, aby inaczej spojrzeć na zespół uszkodzenia bocznej części podwzgórza. Jeśli zlokalizowane uszkodzenie wpływa nie tylko na podwzgórze, lecz na cały pionowo zorganizowany system rozciągający się od rdzenia kręgowego do kory, wówczas anomalie wytworzone przez uszkodzenie ośrodkowego układu nerwowego na każdym z poziomów mogłyby być podobne do defektów wywołanych u zwierząt, u których uszkodzono boczną część podwzgórza. Uczuleni na takie podobieństwa zauważamy, że dorosłe małpy lub ludzie cierpiący na uszkodzenie płata ciemieniowego wykazują pewne cechy, które przypominają objawy występujące u zwierząt z uszkodzeniem bocznej części podwzgórza. Na przykład, odwracają się one od pokarmu i mogą w ogóle odmawiać jedzenia. Szczególnie uderzające jest zachowanie pacjenta z uszkodzeniem płata ciemieniowego; jeśli pacjent ma uszkodzoną jedną, na przykład prawą stronę płata ciemieniowego, to nie zwraca on uwagi na nic, co dzieje się po przeciwnej do uszkodzenia stronie ciała. Zupełnie dobrze orientuje się w tym, co dzieje się po tej samej stronie, co uszkodzenie, lecz zaniedbuje drugą stronę - może ubierać się tylko „po jednej stronie”, czesać się od przedziałka na prawo, lub nawet nie poznawać swej lewej ręki, gdy pojawi się ona w polu widzenia.
Czy podobny defekt uwagi występuje w pierwszym stadium ustępowania zaburzeń po uszkodzeniu bocznej części podwzgórza, gdy zwierzęta w ogóle nie jedzą ani nie piją dowolnie? Marshall, Turner i ja (1971) uszkadzaliśmy szczurom boczną część podwzgórza tylko po jednej stronie. Następnie zastosowaliśmy szereg prostych testów neurologicznych. Zdrowy szczur bada bodziec zwracając ku niemu głowę. Tą naturalną reakcją posłużyliśmy się w celu ustalenia reaktywności szczurów przed uszkodzeniem bocznej części podwzgórza i po nim. Uszkodzenie to, dokonane po jednej stronie, powodowało głębokie upośledzenie reakcji orientacyjnych szczura w stosunku do bodźców pojawiających się po stronie przeciwnej do lezji. Szczury te nie wykazywały reakcji orientacyjnej na bodźce wzrokowe, węchowe czy dotykowe występujące po przeciwnej stronie, podczas gdy reagowały szybko na te same bodźce występujące po tej samej stronie co uszkodzenie. Szczury z lezjami po obu stronach mózgu nie reagowały na żadne bodźce sensoryczne.
To upośledzenie orientacji nie wygląda na paraliż ruchowy, ponieważ zwierzęta nadal były zdolne do wykonywania normalnych ruchów czyszczenia się po obu stronach ciała. Nie jest to też niezdolność do odczuwania bodźców, ponieważ przy prezentacji bodźca często występują ruchy oczu i zmiany w oddychaniu. Defekt ten zdaje się raczej być pewnym rodzajem „ignorowania” (neglect) bodźców. Szczur jest niezdolny do zintegrowania informacji sensorycznej i przystosowawczych reakcji, koniecznych do zwrócenia się w stronę bodźca.
Takie „ignorowanie sensoryczne” może drastycznie wpłynąć na instynktowne wzorce zachowania związane z jedzeniem, piciem i atakowaniem. Na przykład szczury, które normalnie uśmiercały myszy, po jednostronnym uszkodzeniu bocznej części podwzgórza ignorowały mysz, gdy znajdowała się ona po przeciwnej stronie pola wzrokowego. Jednakże, gdy tylko myszka znalazła się w drugiej połowie tego pola, wówczas szczury atakowały ją jak zwykle.
Jest jeszcze jeden wniosek, jaki należy wyciągnąć z obserwacji odruchowego zachowania zwierząt z uszkodzeniami mózgu. Przywykliśmy na przykład myśleć o afagii i |anoreksji (zaburzenia polegające na odmawianiu przyjmowania pokarmu), jakie występują w wyniku uszkodzenia bocznej części podwzgórza, w kategoriach defektu |motywacyjnego - braku pragnienia pokarmu. Było to zwłaszcza dlatego, że smaczne pokarmy mogły spowodować, iż głodujące zwierzę zaczynało jeść wystarczająco dużo, by utrzymać się przy życiu. Zjawisko jednostronnego defektu zmusza nas do zmiany naszej koncepcji. Obecnie myślimy o tych zaburzeniach raczej w kategoriach |ignorowania |sensorycznego - pewnego rodzaju utraty orientacji odruchowej - niż w kategoriach |utraty |motywacji. Regulacji zachowania nie przypisujemy jedynie pewnemu niezależnemu, ośrodkowemu stanowi motywacji, lecz także środowisku. Wiele złożonych motywowanych czynności dowolnych wyjaśnić można w podobny sposób, na podstawie analizy prostych odruchów stanowiących ich podłoże.



Związek przedstawionych badań z funkcjonowaniem człowieka


Należy tu wyjaśnić pewne nieporozumienie dotyczące psychofizjologii.  Ponieważ psychofizjologowie często dokonują uszkodzeń mózgu, aby badać ich wpływ na zachowanie, a więc prace swoje muszą prowadzić na zwierzętach.  Wielu studentów przechodzących wstępny kurs psychologii sądzi, że badania nad zwierzętami w niewielkim stopniu przyczyniają się do zrozumienia ludzkiego zachowania. Nic bardziej błędnego! „Uproszczenia” zachowania, spowodowane uszkodzeniem mózgu zwierząt, często ujawniają takie komponenty zachowania ludzkiego, jakich istnienia nie podejrzewalibyśmy. Pokażę teraz, w jaki sposób się to dzieje.
Kot przejawia bardzo precyzyjne i złożone zachowania sensomotoryczne: gdy więc jego mózg zostanie uszkodzony, możemy zapoznać się bliżej z zaburzeniami zachowania, które trudniej zaobserwować u szczura. Wolgin i ja (1975) stwierdziliśmy, że obustronne uszkodzenie podwzgórza u kotów powoduje te same zaburzenia zachowania związanego z jedzeniem i piciem, które obserwowaliśmy u szczurów; również stadia ustępowania zaburzeń są takie same. U kotów występuje także „ignorowanie sensoryczne”. We wczesnym stadium kompletnej afagii wykazują one zwykłe przejawy katalepsji gdy umieści się je na oparciu krzesła, uczepiają się go odruchowo przednimi łapami i wiszą tak przez długi czas, podpierając się tylnymi łapami i utrzymując prosto głowę. Podobne kataleptyczne uczepienie wywołują środki farmakologiczne, które blokują systemy katecholaminowe (catecholamine systems) w mózgu, Pragnąc sprawdzić, czy to wzrok pozwala kotu trzymać głowę prosto w czasie tej wywołanej farmakologicznie reakcji uczepienia się, Van Harreveid i Bogen (1961) zasłonili kotu oczy, bandażując całą głowę i szyję. Głowa zwierzęcia odchyliła się wówczas powoli ku tyłowi, przednie łapy wyprostowały się i zwolniły stopniowo swój chwyt, co spowodowało, że zwierzę spadło z krzesła na wznak. Jednakże dalsze badania wykazały, że ta „reakcja padania na wznak” nie jest wynikiem wyłączenia zmysły wzroku, ponieważ nie występuje wtedy, gdy nieobandażowane zwierzę bada się w całkowitej ciemności. Jeśli natomiast zabandażuje się kotu głowę i szyję nie zakrywając mu oczu, to reakcja padania na grzbiet również występuje. Wydaje się zatem, że wywołuje ją nacisk na pewne nerwy twarzowe i szyjne.
Gdy koty, nie będące pod wpływem środków farmakologicznych, lecz wykazujące reakcje kataleptyczne w wyniku bocznego uszkodzenia podwzgórza, owinie się bandażem elastycznym (podobnie jak koty bez uszkodzeń mózgu, które otrzymały wspomniane wyżej środki farmakologiczne), to również puszczają one powoli oparcie krzesła, spadając na wznak. Gdy jednak zwierzęta te powracają do zdrowia i zaczynają samodzielnie chodzić, wówczas przestają u nich występować reakcje czepiania się i padania na wznak; zamiast tego, wspinają się na oparcie krzesła lub odwracają się i zeskakują na podłogę.
Jedną z okolic mózgu, naruszonych w przypadku uszkodzenia bocznej części podwzgórza jest droga łącząca istotę czarną z prążkowaną (nigrostiatal pathway); wiadomo, że zmiany w tej okolicy mają związek z chorobą Parkinsona. Wydawało się więc uzasadnione podjęcie próby wykrycia „reakcji padania na wznak po obandażowaniu” (bandage-backfall reaction) u pacjentów ciężko dotkniętych chorobą Parkinsona. Pacjent cierpiący na parkinsonizm zdawał się być świadomy tego, co się dzieje wokół niego, lecz nie potrafił odpowiedzieć więcej niż jednym słowem na skierowane do niego pytanie. W fotelu na kółkach siedział pochylony do przodu, lecz był zdolny trzymać głowę i szyję prosto. Daliśmy mu uchwycić drewniany pręt, trzymany poziomo, a następnie jeden z nas podniósł ten pręt do góry, podnosząc jednocześnie ramiona pacjenta ponad jego głowę. Następnie fotel z pacjentem pochylono do tyłu o około 45 stopni. W tej pozycji pacjent nadal trzymał głowę prosto, mimo że wymagało to aktywnego utrzymywania jej przez mięśnie szyi. Gdy jednak powtórzono ten manewr po obandażowaniu pacjentowi głowy i szyi, wówczas głowa opadła mu do tyłu. Nawet wówczas, gdy ręce pacjenta opuszczono, a jego fotel na kółkach powrócił do zwykłej pozycji, głowa pacjenta pozostawała pochylona do tyłu. Jednak gdy tylko odwinęliśmy bandaż, pacjent podniósł głowę do pozycji wyprostowanej. Wydaje się, że podobnie jak u kotów z uszkodzeniem mózgu, lub będących pod wpływem środka farmakologicznego, efektywną zmienną był tu |nacisk, a nie wzrok. U trzech innych pacjentów z chorobą Parkinsona, jednakże dotkniętych nią w mniejszym stopniu niż ów mężczyzna, „reakcja padania na wznak po obandażowaniu” nie wystąpiła. Ponieważ reakcja ta występuje po uszkodzeniu bocznej części podwzgórza u zwierząt oraz w ciężkim przebiegu choroby Parkinsona u ludzi, a w obu tych przypadkach w grę wchodzi okolica drogi łączącej istotę czarną z prążkiem, przeto dalsze badania powinny mieć dużą wartość z punktu widzenia diagnostyki neurologicznej u ludzi.
Reakcja ta może także rzucić światło na normalne procesy rozwojowe. Jak się już przekonaliśmy, stadia ustępowania zaburzeń reakcji pokarmowych u dorosłego szczura z uszkodzoną boczną częścią podwzgórza ściśle odpowiadają przebiegowi rozwoju tych reakcji w pierwszym okresie życia. Padanie na wznak po obandażowaniu występuje u kota z uszkodzeniem bocznej części podwzgórza jedynie w początkowym, afagicznym stadium tego zespołu. W miarę ustępowania zaburzeń reakcja ta zanika.

Jeśli analogie między przebiegiem ustępowania zaburzeń a przebiegiem rozwoju obowiązują nie tylko dla reakcji pokarmowych, lecz także dla katalepsji; to „reakcje padania na wznak po obandażowaniu” powinny przejawiać zdrowe osobniki w początkowym okresie swego życia. Następnie, w miarę jak encafalizacja postępuje z wiekiem, reakcja ta powinna zanikać - badania przeprowadzone z kociętami, szczeniętami i małymi pawianami wykazują, że tak jest istotnie!
Przeprowadziliśmy także badania nad dziewięcioma niemowlętami w wieku od 4 do 13,5 tygodnia. Przy odchyleniu górnej części tułowia o 10 - 15 stopni do tyłu 8-tygodniowe niemowlę z łatwością trzyma głowę prosto. Gdy jednak obandażowano mu głowę i szyję, wówczas głowa dziecka opadła gwałtownie do tyłu. Gdy usunięto bandaż, wówczas niemowlę znów potrafiło trzymać głowę prosto. U sześciu niemowląt (w wieku od 4 do 11 tygodni) udało się wywołać reakcję padania na wznak po obandażowaniu. Troje niemowląt, w wieku od 10 do 13,5 tygodnia, trzymało podniesioną głowę zupełnie dobrze, niezależnie od tego czy była ona obandażowana, czy nie. Wydaje się zatem, że około trzeciego miesiąca życia u zdrowych niemowląt reakcja na obandażowanie przestaje występować. (Ponieważ nadmierny ucisk na szyję mógłby utrudnić oddychanie i zagrozić życiu dziecka, przy bandażowaniu małych niemowląt pracowaliśmy zawsze w obecności lekarza).
Reakcję padania na wznak po obandażowaniu można zademonstrować u niemowlęcia wkrótce potem, gdy potrafi już ono trzymać podniesioną głowę.  Później reakcja ta zanika. Możliwe jest tu następujące wyjaśnienie: drogi hamujące (od bandażowanych receptorów) u niemowlęcia same ulegają zahamowaniu przez rozwijające się później systemy katecholaminergiczne w mózgu. U dorosłych uszkodzenia bocznej części podwzgórza lub środki farmakologiczne antagonistyczne w stosunku do katecholamin mogą spowodować katalepsję. W tym stanie uaktywnia się pierwotny system hamujący i, podobnie jak u zdrowego niemowlęcia, obandażowanie głowy i szyi znów będzie powodować reakcję padania na wznak.
Reasumując, przekonaliśmy się, że psychofizjologia może być bardzo przydatna do analizy zachowania zwierząt i ludzi. Zlokalizowane uszkodzenie mózgu może „uprościć” pewien system zachowań, a badanie procesu ustępowania zaburzeń może ukazać nam, w jaki sposób system ten zostaje ponownie zintegrowany. Anomalie spowodowane uszkodzeniem mózgu mogą reprezentować prostsze poziomy zachowania, które występują także - chociaż często nie podejrzewa się tego - w trakcie normalnego rozwoju w okresie niemowlęctwa.


Literatura

|Cheng |M. |F., |Rozin |P., |Teitelbaum |P. |Semi-starvation retards develpoment of food and water regulations”. „Journal of Comparative and Physiological Psyhology” 1971, 76, 206-218.
|Marshall |J. |F., |Turner |B. |H., |Teitelbaum |P. „Sensory neglect producet by lateral hypothalamic damage”. „Science” 1971, 174, 523-525.
|Teitelbaum |P., |Cheng |M. |F., |Rozin |P. „Development of feeding parallels its recovery after hypothalamic damage”. „Journal of Comparative and Physiological Psyhology” 1969, 67, 430-441.
|Teitelbaum |P., |Epstein |A. |N. „The lateral hypothalamic syndrome: recovery of feeding and drinking after lateral hypothalamic lesions”.  „Psychological Review” 1962, 69, 74-90. Copyright © 1962, American Psychological Association, Figure 1 (tabela) reprinted by permission.
|Teitelbaum |P., |Wolgin |D. |L. „Neurotransmitters and the regulation of food intake”. In.: W. H. Gispen et al., „Progress in Brain Research” Vol.  42, 235-1249. Amsterdam 1975, Elsevier Scientific Publishing Co.
|Teitelbaum |P., |Wolgin |D. |L., |De |Ryck |M., |Marin |O. |S. |M. 
„Bandage-backfall reaction: Occurs in infacy, brain damage and catalepsy”. 
„Proceedings of the National Academy of Science” 1976.
|Twitchell |T. |E. „The restoration of motor function following hemiplegia in man”. „Brain” 1951, 74, 443-480. 
|Twitchell |T. |E. „Reflex mechanisms and the development of prehension”.  In: K. J. Conally (ed.) „Mechanisms of motor skill development”, New York 1970, Academic Press, 25-45.
|Van |Harreveld, |A. |Bogen |J. |E. „The clinging position of the bulbocapninized cat”. „Experimental Neurology” 1961, 4, 241-246.


Rozdział 3.
Zachowanie przystosowawcze: warunkowanie i uczenie się


Prawdopodobnie śnieg padał w Petersburgu tego dnia, gdy Iwan Piotrowicz Pawłow wsiadł do pociągu, rozpoczynając swą podróż do Sztokholmu. Był rok 1904 i Pawłow udawał się tam, aby przyjąć najwyższą nagrodę przyznawaną za osiągnięcia w podstawowych dziedzinach wiedzy: Nagrodę Nobla. Rosyjski fizjolog opracował technikę pozwalającą badać funkcjonowanie gruczołów trawiennych u żywych i zdrowych zwierząt. Rolę śliny i innych wydzielin biorących udział w trawieniu można było teraz badać wyprowadzając je z organizmu przez rurki implantowane w gruczołach i wnętrznościach psów używanych do eksperymentów.
Dziwna rzecz, Pawłow wyjeżdżając do Sztokholmu był bardziej zakłopotany niż szczęśliwy. Wydawało się, że trudności, jakie napotykał ostatnio podczas pracy w swym własnym laboratorium, postawiły pod znakiem zapytania przydatność jego metody do badania fizjologii trawienia.
We wczesnej fazie eksperymentu jego psy śliniły się wkrótce po umieszczeniu pokarmu w ich pyskach. Tak właśnie powinno być, ponieważ pokarm jest naturalnym bodźcem dla ślinienia się - ślina umożliwia bowiem strawienie pokarmu. Gdy jednak procedurę tę powtórzono wiele razy, to zwierzęta zaczęły wydzielać ślinę |przed spróbowaniem pokarmu. Najpierw widok pożywienia wywoływał ślinienie, później widok eksperymentatora, który przynosił pokarm, a w końcu nawet odgłos jego kroków wystarczył do wywołania ślinienia. Asystenci Pawłowa nie mogli znaleźć sposobu usunięcia tego niepożądanego zjawiska, które mogło być źródłem błędów i komplikowało prosty proces, jaki chcieli zbadać.
Jak to możliwe, że każdy bodziec, który regularnie poprzedzał podanie pokarmu, zaczynał u zwierząt obserwowanych przez eksperymentatorów wywoływać tę samą reakcję, co ów pokarm?
Zakłócający wpływ tego „procesy psychicznego” na podstawowy proces fizjologiczny, będący przedmiotem badania, intrygował Pawłowa. Czołowy fizjolog tego okresu, Sir Charles Sherrington, radził mu, aby nie dał się sprowadzić na manowce przez takie „psychiczne nonsensy”, lecz ciekawość naukowa Pawłowa została pobudzona, a jego otwarty umysł był zdolny ocenić, że oto natknął się na coś ważnego. Wytrwał więc i w końcu potrafił przekształcić to przypadkowe spostrzeżenie w jedno z największych odkryć naszych czasów - odkrycie podstawowych praw warunkowania.
Doniosłość odkrycia dokonanego przez Pawłowa, które znacznie wzbogaciło naszą wiedzę o tym, jak żywe organizmy uczą się przystosowywać do nowych bodźców występujących w ich środowisku, wkrótce stała się oczywista. Tak dalece, że gdy historyka H. G. Wellsa poproszono, aby osądził, czy ważniejszy dla społeczeństwa jest Iwan Piotrowicz Pawłow, czy współczesny mu pisarz George Bernard Shaw, odpowiedział on, że gdyby obaj tonęli, a było tylko jedno koło ratunkowe, to rzuciłby je Pawłowowi.


Czego muszą się nauczyć organizmy?
3 3 75 0 2 108 1 5a 1 74 1

To właśnie dzięki procesowi uczenia się ludzie osiągają najwyższy stopień autonomii i wolności od ograniczeń nakładanych przez ich naturalne środowisko, jak również przez fizjologiczne i autonomiczne dziedzictwo, historię gatunku lub społeczeństwo. Ludzie nauczyli się latać, żyć w stacjach kosmicznych krążąc po zewnętrznej orbicie Ziemi, rozszerzać granice możliwości swych zmysłów za pomocą mikroskopów elektronowych i radioteleskopów, przedłużać życie dzięki odpowiedniej diecie oraz osiągnięciom medycyny i chirurgii, a także zmieniać swe środowisko przez nawadnianie, klimatyzację i ciepłownie jądrowe.
Te i inne osiągnięcia istot ludzkich można w dużym stopniu przypisać temu, że nauczyły się one dokonywać dokładnych, logicznych przewidywań. Są dwa zasadnicze rodzaje przewidywań, które musimy nauczyć się dokonywać tak, aby były one rzetelne i niezawodne: po pierwsze, należy ustalić jakie zdarzenia następują po innych zdarzeniach w nas samych lub w środowisku, i po drugie, jakie zdarzenia następują po naszych własnych działaniach czy reakcjach. Dysponując tą wiedzą możemy następnie przejść od przewidywania do sterowania - interweniować, aby zmieniać zdarzenia zachodzące w środowisku (lub ich wpływ na nas), modyfikować zachowanie innych ludzi i zmieniać nasze własne zachowanie (czyniąc je stosowniejszym i bardziej skutecznym).
Wszystkie żywe organizmy wyposażone są w zdolność uczenia się tych dwóch rodzajów zależności. Organizmy niższe posiadaj ją w mniejszej mierze: ich reakcje są na ogół w większym stopniu z góry zdeterminowane i stereotypowe, a różnice międzyosobnicze nie są wielkie. W ich wypadku historia i biologia całego gatunku odzwierciedla się w reakcjach każdego przedstawiciela tego gatunku na bodźce środowiskowe.
Organizmy znajdujące się wyżej na skali filogenetycznej potrafią uczyć się bardziej złożonych i subtelniejszych zależności niż organizmy niższe.  Mają one także większą zdolność zmieniania swego zachowania tak, aby najlepiej „dopasować” je do określonej informacji środowiskowej, jaką otrzymują.

W wypadku ludzi (znajdujących się na górnym krańcu tej skali) widzimy, w jakim stopniu jednostki wykraczają poza proste przystosowanie się do środowiska i zmuszają środowisko, aby przystosowało się do nich.


Jakie zdarzenia są sygnałami?


Poznając dzięki uczeniu się regularności współwystępowania pewnych zdarzeń, określamy korelacje zachodzące w środowisku. Kompletny zbiór tych korelacji staje się dla nas reprezentacją środowiska oraz podstawą pozwalającą nam przewidywać przyszłe zdarzenia dzięki znajomości zdarzeń obecnych lub przeszłych. Bodziec staje się sygnałem w takiej mierze, w jakiej dostarcza informacji o prawdopodobieństwie, że wystąpi inny bodziec.
Ucząc się, jak wykrywać i rozszyfrowywać sygnałową wartość bodźców, potrafimy lepiej przygotować się do zdarzeń, które one zapowiadają. Dany bodziec może być sygnałem zdarzeń mających bardzo różne znaczenie i różną doniosłość: niebezpieczeństwa, bezpieczeństwa, ulgi, nadziei, rozpaczy lub przyjemności.


Zbliżenie
Mylący sygnał


„Pewien młody psycholog, który miał przedstawić sprawozdanie z badań na swej pierwszej międzynarodowej konferencji, ucieszył się na wiadomość, że jego wystąpienie jest przewidziane do jednoczesnego tłumaczenia z angielskiego na francuski i niemiecki. Jednakże po przedstawieniu dwóch części sprawozdania - wstępu i opisu procedury, które - jak się zdaje - znalazły pozytywny oddźwięk wśród słuchaczy, zauważył, że mała lampka na pulpicie zaczęła zapalać się i gasnąć. Przyszło mu na myśl, że widocznie kończy się czas jego wystąpienia, a ponieważ zapomniał zegarka, nie mógł określić jak długo już mówił, ani też, ile czasu mu jeszcze zostało.
Gdy mówił dalej, lampka zaczęła błyskać w jeszcze szybszym tempie; lęk „świeżo upieczonego” psychologa, że nie zdąży skończyć referatu, stopniowo rósł, mówił więc coraz szybciej. Wkrótce tempo przemawiania dorównało szybkości błyskania lampki. Gdy zbliżał się już do końca swego sprawozdania lampka nagle przestała błyskać, a skonsternowani słuchacze pozdejmowali słuchawki. Tłumacz przestał przekładać, ponieważ jego sygnały czerwoną lampką - które miały poinformować mówcę, że powinien przemawiać |wolniej - zostały zignorowane; mówca z jakichś przewrotnych zapewne powodów, mówił nie wolniej, a coraz szybciej, co w końcu uniemożliwiło tłumaczenie.
A czy ty zrozumiałbyś intuicyjnie znaczenie sygnału w postaci błyskającej lampki? Jaki system sygnalizacji zaprojektowałbyś, aby uniknąć takiej pomyłki, nawet ze strony zbyt lękliwego psychologa?”

Dzwonienie na przejeździe kolejowym sygnalizuje niebezpieczeństwo w postaci zbliżającego się pociągu; umilknięcie dzwonka lub podniesienie pomalowanego w jaskrawe pasy szlabanu (drugi pomocniczy sygnał) jest sygnałem bezpieczeństwa: „można jechać”. Podczas II wojny światowej wycie syren ostrzegało ludność o zbliżającym się nalocie; następnie inny układ dźwiękowy służył jako sygnał odwołania alarmu. Znudzonemu studentowi słowa wykładowcy „I na zakończenie...” sygnalizują, że zbliża się wytchnienie: wykład, który zdawał się trwać bez końca, w rzeczywistości wkrótce się skończy. 
Sygnałem może być również układ czasowy lub przestrzenny. Na przykład na podstawie rozkładu w czasie skurczów macicy u kobiety ciężarnej lekarz położnik potrafi przewidzieć, kiedy nastąpi poród.
Jednakże w naszym otoczeniu zachodzi nieskończona ilość różnych zdarzeń bodźcowych, a tylko niektóre z nich łączy z innymi związek informacyjny, jaki tu opisaliśmy. W jaki więc sposób uczymy się wyodrębniać z tych milionów możliwości te, które są prawdziwymi sygnałami? Arystoteles w swym klasycznym dziele „De Anima”; („O duszy”) wskazywał, że aby idee (czy zdarzenia) skojarzyły się w naszym umyśle, muszą występować łącznie, czyli we wzajemnej „styczności”. Sygnał i rzecz sygnalizowana muszą być spostrzegane wystarczająco blisko w przestrzeni lub w czasie, abyśmy widzieli je jako związane ze sobą; pierwsze z nich będzie później przypominało nam, abyśmy uważali: drugie wkrótce się pojawi. Obecnie psychologowie twierdzą, że styczność wydaje się |konieczna w większości wypadków uczenia się skojarzeń, lecz nie |wystarczy, aby je wyjaśnić. Duża częstość powtarzania się zdarzeń, które mogą być skojarzone, również sprzyja uczeniu się ich związku.
Jeśli drugi bodziec w parze jest przykry, szkodliwy lub potencjalnie niebezpieczny dla życia to jednostki są motywowane do szukania naturalnych, obojętnych sygnałów, które poprzedzają ów niebezpieczny bodziec, i w ten sposób pozwalają im uniknąć poważnych jego konsekwencji. Ponadto, jak w przypadku sygnału alarmu przeciwlotniczego lub świateł sygnalizacyjnych na skrzyżowaniach, ludzie nie ograniczają się jedynie do wykorzystania już istniejących sygnałów - tworzą nowe, aby pomogły im w przewidywaniu innych zdarzeń, a następnie pouczają członków swej społeczności językowej o znaczeniu tych sygnałów.
Ucząc się zatem zależności między zdarzeniami bodźcowymi (związków S-S) poznajemy |naturę |środowiska, w którym działamy. Uczymy się także, które reakcje są ze sobą związane, dzięki czemu możemy później przewidywać ich pojawienie się. Pewne grupy reakcji często występują razem. Na przykład, gdy reakcja dążenia do jakiegoś upragnionego celu zostaje zablokowana (czyli sfrustrowana) występuje wówczas zazwyczaj pewien rodzaj reakcji agresywnych. Gdy reakcje strachu wzmagają się, prawdopodobne stają się reakcje unikania lub ucieczki. Na subtelniejszym poziomie analizy każde zintegrowanie, skoordynowane zachowanie obejmujące sekwencję reakcji, takie jak nauka liczenia od jednego do dziesięciu, gra na skrzypcach, zawiązywanie sznurowadeł lub uczenie się wymowy trudnego słowa, składa się z komponentów, z których każdy jest zarówno reakcją, jak i sygnałem wskazującym, jaka reakcja powinna po nim nastąpić.
Niekiedy brak jest zgodności między reakcjami danej osoby, tak że jedna z nich |nie jest wiarygodnym sygnałem drugiej. Gdy czyjeś słowa i czyny, dotyczące spraw uznawanych przez społeczeństwo za ważne, są niezgodne ze sobą, osobę tę określa się jako „hipokrytę”, a oczekiwana korelacja nie istnieje lub nawet jest ujemna. Przeciwnie, gdy korelacja ta jest stale dodatnia, to daną osobę oceniamy jako godną zaufania. O takich ludziach mówimy: „Na ich słowie można polegać”. Ucząc się takich korelacji między reakcjami (związków R-R) poznajemy |strukturę |zachowania - najpierw własnego, a następnie, przez obserwację i wnioskowanie, zachowania innych ludzi.
Inny rodzaj zależności między zdarzeniami przejawia się w |oddziaływaniu |na |nas |środowiska. Gorąca woda poparzy ci skórę. Jasne światło świecące ci w oczy powoduje zwężenie źrenic, łzawienie, zmęczenie oczu i może doprowadzić do bólu głowy. Ludzie cierpiący na uczulenie muszą nauczyć się, które pokarmy, kwiaty lub inne elementy środowiska wywołują u nich reakcje alergiczne, jeśli chcą uniknąć tych przykrych, a niekiedy niebezpiecznych zdarzeń bodźcowych. Z drugiej strony uczymy się także przewidywać dość dokładnie, które bodźce powodują, że czujemy się szczęśliwi, dumni, zadowoleni czy pobudzeni seksualnie - i następnie staramy się układać swoje życie tak, aby środowisko miało sposobność dostarczenia nam tych przyjemności.


Jakie konsekwencje wiążą się z poszczególnymi działaniami?


Drugi główny rodzaj zależności, jakich musimy się uczyć, to związek między reakcjami, które wykonujemy, a ich konsekwencjami w postaci wpływu na środowisko. Niektóre rzeczy, jakie robimy, mają taki wpływ, podczas gdy inne - nie mają żadnego. Rozpatrzmy na przykład behawioralny akt płaczu.  Nie musisz uczyć się płakać; mechanizmy reakcji związane z płaczem są fizjologicznie zaprogramowane od urodzenia. U każdego niemowlęcia płacz wywołują silne, niepokojące bodźce, takie jak głód, zimno, ból i hałas. W istocie, płacz niemowlęcia jest sygnałem dla dorosłych opiekunów, że coś prawdopodobnie dokucza dziecku. Dziecko jednak wkrótce uczy się, iż po płaczu następuje pojawienie się rodziców, babci lub dziadka i często „używa” płaczu jako środka służącego do zwrócenia ich uwagi, uniknięcia samotności, spowodowania, by wzięto je na ręce i przytulono itd. Dziecko nie uczy się zatem jak płakać, lecz tego, że płacz jest skuteczny. Dzieci wychowane w sierocińcach lub przebywające długo w szpitalu płaczą rzadziej niż dzieci chowane we własnej rodzinie, ponieważ personel tych instytucji rzadziej reaguje na ich płacz.
W wielu społeczeństwach chłopcy uczą się, że konsekwencje następujące po ich płaczu są negatywne - są wyśmiewani lub zawstydzani i obdarzani mianem „maminsynka” lub „beksy”. U chłopców tych czynność płaczu będzie podlegać hamowaniu, gdy nauczą się przewidywać, że prowadzi ona do przykrych konsekwencji. Gdy chłopcy ci dorosną, wówczas nawet takie zdarzenia bodźcowe, jak silny ból czy śmierć kochanej osoby nie skłonią ich do płaczu.
Gdy twoje działania wpływają na otoczenie w sposób możliwy do przewidzenia, wówczas odkrywasz, które elementy otoczenia poddają się sterowaniu, a jednocześnie uczysz się czegoś o sobie samym jako czynniku sterującym. Jeśli podnosisz w klasie rękę do góry, to czy nauczyciel zwróci na ciebie uwagę? Jeśli się uśmiechasz, to czy ludzie też uśmiechają się do ciebie? Jeśli uderzysz kogoś większego od ciebie, to czy dasz sobie z nim radę? Jeśli zalejesz wodą płonącą benzynę, to czy ona zgaśnie? Jeśli krzyczysz „Wilk!” albo „Ratunku!”, to czy ktoś przyjdzie ci z pomocą?  Odkrywając zależności między tymi i innymi parami reakcji i konsekwencji (związki R-S) uczysz się rozumieć, jaki |wpływ |masz - i |możesz |mieć - |na |swoje |środowisko |społeczne |i |fizyczne.

Wadliwe instalacje sanitarne, jakie można spotkać w wielu internatach i domach akademickich, dostarczają nam doskonałego przykładu ilustrującego większość zasadniczych problemów związanych z obydwoma rodzajami tych podstawowych zależności (między zdarzeniami i między konsekwencjami).
Wyobraź sobie, że bierzesz ciepły, kojący prysznic po ciężkim dniu pracy.  Gdy woda spływa ci strumieniami po plecach, odprężasz się rozkosznie i nie dociera już do ciebie nic, prócz tego miłego ciepła. Nagle to błogie odprężenie zostaje brutalnie zniweczone przez świadomość, że woda jest piekielnie gorąca. Ktoś spłukiwał właśnie toaletę, przez co zabrakło zimnej wody nadającej umiarkowaną temperaturę natryskowi. Ukrop parzy ci plecy, wywołując dotkliwy ból. Za chwilę temperatura wody wraca do poprzedniego poziomu i kontynuujesz swą kąpiel, choć nie potrafisz już osiągnąć dawnego stanu błogiego zapomnienia. Wkrótce jednak zauważasz, że ciśnienie wody nagle spadło. Bum! Znów leci strumień wrzątku, któremu towarzyszą twoje przekleństwa - lecz reakcja ta nie obniża temperatury wody. Nie musiałeś się uczyć odczuwania bólu, gdy została uszkodzona tkanka skórna. Te związki są fizjologicznie wbudowane. Musiałeś jednak nauczyć się związku między zdarzeniem a jego wpływem na ciebie, a mianowicie - „bardzo gorąca woda parzy mi skórę”. Musiałeś także odkryć, że spadek ciśnienia wody jest sygnałem pojawienia się ukropu.
To jedno skojarzenie między spadkiem ciśnienia wody a wzrostem jej temperatury może wystarczyć do wytworzenia się „oczekiwania”, w którym pierwsze zdarzenie zapowiada nadciągające niebezpieczeństwo w postaci drugiego. Gdyby obie te zmiany bodźcowe wielokrotnie następowały jedna po drugiej, to z pewnością nauczyłbyś się spostrzegać pierwsze zdarzenie jako sygnał drugiego.
W ten sposób powstało skojarzenie między dwoma bodźcami: istnieje mianowicie wysoki stopień korelacji między spadkiem ciśnienia wody a następującym po nim wzrostem jej temperatury. Jedno jest niezawodnym |sygnałem drugiego. Jeśli jednak nie potrafisz wykorzystać tej wiedzy dla swego dobra, to będziesz mądrzejszy, ale nie mniej obolały.
Początkowo twojej reakcji bólowej może towarzyszyć wiele reakcji behawioralnych, takich jak jęczenie, krzyczenie, przeklinanie, tupanie, kopanie ściany, szarpanie zasłony itd. Niewątpliwe musisz się jeszcze nauczyć, która reakcja z całego twojego repertuaru reakcji będzie przystosowawcza: położy kres bolesnemu doznaniu lub jeszcze lepiej - zapobiegnie mu - gdy będziesz brał prysznic następnym razem. W tym wypadku nauczyłbyś się uciekać spod natrysku natychmiast, gdy zauważysz spadek ciśnienia wody, zanim popłynie strumień wrzątku. Jest to drugi rodzaj skojarzenia, którego musisz się nauczyć - skojarzenie między twoim zachowaniem a jego konsekwencjami. Takie zachowanie polega na |oddziaływaniu na własną relację względem otoczenia lub na samo to otoczenie - tak, aby zmienić je w pożądany sposób.


Zbliżenie
„Rozwiązanie parzącego problemu”


„Pewien żołnierz z dyplomem inżynierskim rozwiązał problem instalacji sanitarnych w koszarach na poligonie Aberdeen, problem, który dla zakwaterowanych tam żołnierzy od lat był problemem naprawdę palącym (a raczej parzącym).
Specjalista czwartego stopnia David Ursin i mieszkający z nim kolega są jedynymi żołnierzami w tym ośrodku wojskowym, którym nie dają się już we znaki strumienie ukropu wypływającego nagle z natrysków koszarowych - za każdym razem, gdy ktoś spłukuje toaletę.
„Gdy kilkakrotnie zostałem poparzony””, mówi Ursin, „musiałem coś z tym zrobić””.
Wynalazł więc „zbiornik zabezpieczający””, metalowy cylinder litrowej pojemności, który zamontował ponad główką natrysku, eliminując w ten sposób niebezpieczeństwo związane z koszarową kąpielą.
W zbiorniku tym gromadzi się wystarczająca ilość wody, aby zapobiec przejściu fali ukropu przez natrysk podczas spłukiwania toalety”.  („Associated Press”, 16 sierpnia 1971).

U ludzi ten rodzaj oddziaływania na otoczenie rozszerzył się ogromnie.  Dzięki niej nie każdy mieszkaniec czy gość domu akademickiego, w którym występuje ten problem instalacji wodnych, musi przejść bolesny proces odkrywania go osobiście. Problem ten staje się częścią zasobu wiedzy, który jedna osoba może przekazywać drugiej za pomocą słów. W kolejnych dwóch rozdziałach przekonamy się, jak znaczny stopień kontroli nad naszym otoczeniem uzyskujemy przez manipulowanie słowami i innymi symbolami.
Badanie procesów uczenia się stanowi podstawę zrozumienia zachowania człowieka. Cechą, która najbardziej odróżnia organizmy wyższe od niższych form zwierzęcego życia jest względna zależność ich zachowania przez uczenie się w kontaktach ze środowiskiem. Uczymy się, jak stawać się ludźmi, jak żyć z innymi, mówić, uważać, spostrzegać, rozumować - a także, jak działać.  Wszystkie nasze podstawy, gusty, przyzwyczajenia, upodobania, niechęci, obawy, uprzedzenia, a nawet symptomy nerwicowe - są wyuczone. Nic więc dziwnego, że uwzględnienie zasad uczenia się będzie mieć podstawowe znaczenie niemal we wszystkich analizach ludzkiego zachowania.
W niniejszym rozdziale skoncentrujemy się głównie na poznaniu dwóch podstawowych form uczenia się, dzięki którym ustalane są związki między faktami (uczenie się sygnałów i uczenie się konsekwencji). W następnych rozdziałach, poświęconych złożonym formom uczenia się ludzi oraz innym zjawiskom psychologicznym, takim jak spostrzeganie, interakcja społeczna i leczenie zaburzeń psychicznych, często będziemy odwoływać się (explicite lub implicite) do tych podstaw, to znaczy zasad uczenia się.

* *
Ryc. 3.1. Fotografia ta przedstawia Iwana Pawłowa i jego zespół przy aparaturze stosowanej w eksperymentach nad warunkowaniem. Pies był przymocowany za pomocą uprzęży do drewnianego stojaka; rurka odprowadzała wydzielaną przez niego ślinę do urządzenia pomiarowego, które rejestrowało jej ilość i tempo wydzielania pod wpływem bodźców.

* * *

Warunkowanie reaktywne (klasyczne) Pawłowa


W swoich licznych eksperymentach nad warunkowaniem psów Pawłow wykrył, w jakich warunkach nieistotne, często nic nie znaczące zdarzenie bodźcowe może stać się zdarzeniem istotnym i wywierającym silny wpływ. Jego badania koncentrowały się na jednej kategorii zachowań - odruchach i reakcjach będących pod kontrolą autonomicznego układu nerwowego, a zwłaszcza tej jego części, która odgrywa istotną rolę w reakcjach emocjonalnych - układu sympatycznego (współczulnego). Każde z tych zachowań - takich jak ślinienie się, zwężenie źrenicy, odruch kolanowy, zgięcie nogi czy mrugnięcie - jest |wywołane przez darzenie bodźcowe określonego rodzaju. Związki między tymi specyficznymi bodźcami a reakcjami, które one wywołują, są u danego gatunku zdeterminowane genetycznie, a u poszczególnych osobników zostają utrwalone w chwili narodzin lub wkrótce potem. Zachowania te są automatyczne, niewyuczone i czasowo zmieniają organizm w taki sposób, aby ułatwić jego przystosowanie się do otoczenia. Wykonując te |mimowolne |reakcje organizm reaguje na bodziec w ten sposób, że zmienia coś w sobie samym, nie w swym otoczeniu. Takie zachowanie określa się jako |zachowanie |reaktywne (respondent bahawior).


Podstawowy paradygmat


|Paradygmat jest to symboliczny model lub schemat, który może dopomóc nam w zrozumieniu zasadniczych cech pewnego procesu. Punktem wyjścia dla paradygmatu warunkowania reaktywnego (zwanego często warunkowaniem klasycznym - przyp. tłum.) jest związek między bodźcem a odruchem wywołanym niezawodnie przez ten bodziec. Bodziec, który normalnie wywołuje te reakcje Pawłow nazwał |bodźcem |bezwarunkowym; reakcję, która niezawodnie po nim następuje, nazwał |reakcją |bezwarunkową.
Pawłow stwierdził, że gdy podawał psu proszek mięsny i obserwował automatyczną, niewyuczoną reakcję ślinienia, to w niedługim czasie inne występujące na krótko przed tym bodźce (widok pokarmu, widok lub odgłos kroków eksperymentatora) również uzyskiwały zdolność wywoływania ślinienia.  Gdy ślinienie wywoływane było przez te właśnie bodźce, wówczas nazywano je |reakcją |warunkową.
W wypadku warunkowania reaktywnego organizm uczy się nowej korelacji między dwoma nie związanymi uprzednio zdarzeniami bodźcowymi - bodziec warunkowy sygnalizuje teraz pojawienie się bodźca bezwarunkowego. Gdy tylko to połączenie S-S zostanie wyuczone, organizm reaguje na sygnał tak, jak by to był pierwotny, silny bodziec (np. pokarm lub wstrząs elektryczny).

W tej procedurze żaden z bodźców nie jest pod kontrolą organizmu; oba występują bez względu na to, co on uczyni. Są one zaprogramowane przez środowisko naturalne (lub sztuczne, jak w wypadku zmiany ciśnienia wody i strumienia ukropu w naszym przykładzie z natryskami) albo też wymyślone przez eksperymentatora, który postanowił wytworzyć reakcję warunkową u badanego człowieka lub zwierzęcia.


Zbliżenie
Wio, Siwy!


„Warunkowanie słów jako symboli zademonstrowano z dobrym skutkiem w humorystycznym „eksperymencie”, jaki przeprowadzili dwaj młodzi dowcipnisie. Ich napuszony stary pastor, który co niedziela jeździł na swym koniu do kościoła, kazał im czyścić tego konia i spełniać inne posługi bez zapłaty ani podziękowania. Aby mu odpłacić, uwarunkowali konia w ten sposób, że jeżdżąc na nim wołali „Wio!”, po czym kłuli go w zad szpilką.  Możesz wyobrazić sobie Rw, która wystąpiła następnej niedzieli, gdy koń kłusował do kościoła, a pastor siedzący dumnie na jego grzbiecie, zawołał dobrze znane koniowi „Wio!”

Poza badaniem warunkowej reakcji ślinienia (tzw. |warunkowanie |apetytywne) Pawłow zajmował się także |awersyjnym |warunkowaniem psów, stosując wstrząs elektryczny w łapę jako Sb oraz różne bodźce dźwiękowe i wzrokowe jako Sw; Rb stanowiło cofnięcie lub zgięcie łapy. Ponieważ uniknięcie bolesnych wstrząsów było niemożliwe, gdyż zwierzę było przytrzymywane uprzężą, reagowało ono na przykry bodziec nie tylko zgięciem nogi, lecz także uogólnioną reakcją strachu. Każdy bodziec warunkowy - dźwięk dzwonka, pojedynczy ton, widok kota, ciemne pomieszczenie eksperymentalne lub nawet uśmiechnięty eksperymentator, który regularnie pojawiał się przed bodźcem bezwarunkowym - zaczynał wywoływać strach.
Przypuśćmy, że znalazłeś się jako obserwator w takim laboratorium, nie znając przeszłości warunkowanego zwierzęcia. Co byś pomyślał, gdybyś zobaczył, że pies kuli się, skomli i ucieka od małego kotka, z ciemnego pokoju do nawet uśmiechniętego eksperymentatora? Że jest on „zwariowany”? A co powiedzieć o ludziach nękanych przez lęki, które są najwyraźniej irracjonalne, „nie mają sensu”, lęk przed nieszkodliwymi owadami, ciasnymi pomieszczeniami, ciemnością, włosami i dosłownie setkami innych przedmiotów i sytuacji?
Na filmie „Dziennik Anny Frank” przybycie hitlerowskich oddziałów SS zawsze poprzedzał zawodzący dźwięk syreny samochodu policyjnego, po czym następowała jakaś przerażająca akcja przeciw Żydom. Pod koniec filmu sam specyficzny, powtarzający się dźwięk syreny (bodziec warunkowy Sw) wywoływał u wielu widzów silne uczucie grozy (reakcja warunkowa, Rw) w przewidywaniu mających nastąpić okropności (bodziec bezwarunkowy, Sb) - jak niewątpliwie wywoływał je także u tych prześladowanych, którzy poznawali z własnego doświadczenia ów sygnał niebezpieczeństwa i przypominali sobie wydarzenia, z którymi się on kojarzył.
Nie tylko bodźce fizyczne, lecz także słowa i inne symbole mogą stać się bodźcami warunkowymi. Takie warunkowanie ogromnie rozszerza zakres bodźców, które mogą wywoływać odruchy, sygnalizować niebezpieczeństwo czy „zastępować” nieobecne bodźce bezwarunkowe. Słowa i symbole skojarzone z ważnymi zdarzeniami stają się substytutami zdarzeń wywołujących tę samą reakcję, co same zdarzenia (ryc. 3.3). Rzeczą godną uwagi jest fakt, że wielu ludzi na całym świecie doświadcza silnych reakcji wewnętrznych, gdy kawałek materiału zostaje wciągnięty na słup, a orkiestra wytwarza pewne dźwięki muzyczne - jeśli ten materiał jest flagą ich państwa, a dźwięki są melodią ich hymnu narodowego.
* * *
Ryc. 3.3. Fotografia ta ilustruje komercjalne zastosowanie bodźca warunkowego. Dla przesyconych słowami Amerykanów „Wow” zaczęło sygnalizować szczyt intensywnego, pozytywnego doznania. Jest to więc potężny bodziec warunkowy, który specjaliści od reklamy mogą wiązać z produktem, w odniesieniu do którego chcieliby wytworzyć u publiczności intensywne i pozytywne uczucia.

* * *

„Każdy bodziec, który dany organizm potrafi spostrzec, może być użyty do wywołania reakcji warunkowej w każdym mięśniu czy gruczole, przez odpowiednie skojarzenie tego bodźca warunkowego z biologicznie ważnym bodźcem bezwarunkowym”.

Jedną z głównych tendencji w psychologii uczenia się, w ostatnich dziesięcioleciach, było poszukiwanie coraz większej liczby zdarzeń środowiskowych, które mogą stać się bodźcami warunkowymi. Istotnie, wydaje się, że jedyne ograniczenia, to granice zdolności percepcyjnych organizmu: może on nauczyć się cenić - lub uważać za groźne czy niebezpieczne - wszystko to, co może on spostrzec.
Z drugiej strony, radziecki badacz Bykow (1957) po dokonaniu przeglądu ogromnej liczby badań nad warunkowaniem reaktywnym, pod kątem możliwości warunkowania funkcji narządów wewnętrznych, doszedł do wniosku, że „Jeśli coś porusza się lub wydziela, to może być uwarunkowane”. Wszystko zatem, co może dotrzeć do naszej świadomości, może też nabrać dla nas znaczenia (pozytywnego lub negatywnego) i właściwie każda reakcja, którą potrafimy wykonać, może stać się zależna od wyuczonych sygnałów.


Anatomia warunkowaniavpawłowskiego


W jaki sposób tworzą się te związki i w jaki sposób się rozpadają, gdy środowisko ulega zmianie i bodziec warunkowy przestaje być znaczącym i wiarygodnym sygnałem? Poniżej przedstawimy w skrócie główne procesy stanowiące podstawę warunkowania reaktywnego.

1. |Ogólna „pobudliwość. Nawet po jednym zestawieniu bodźców - obojętnego z bezwarunkowym - zwierzę będzie reagować na sytuację warunkowania w ten sposób, że będzie bardziej pobudliwe. To może wystarczyć, aby wywołać spontaniczne reakcje ruchowe, jak również wydzielanie w gruczołach. Jeśli warunkuje się reakcję pokarmową, to istnieje „ogólne pobudzenie pokarmowe, ogólne przygotowanie do przyszłej czynności pokarmowej, ogólne oczekiwanie karmienia, które ma nastąpić. Następnie reakcja ta konkretyzuje się, zwierzę oczekuje określonego bodźca warunkowego, po którym następuje karmienie i skupia swą uwagę na tym bodźcu” (Kupałow, 1961, s. 1050).

2. |Układ |bodźców |w |czasie (|odstęp |między |Sw |a |Sb). Zwiększenie liczby zestawień bodźca warunkowanego z bezwarunkowym powoduje zwiększenie siły reakcji warunkowych (do pewnego maksymalnego poziomu), lecz tylko przy zachowaniu pewnych relacji czasowych między tymi dwoma zdarzeniami.  Najkorzystniejszy odstęp między bodźcami to około pół sekundy między początkiem Sw a początkiem Sb. Taki odstęp w czasie wystarczy, aby pierwszy bodziec zasygnalizował i przygotował organizm pod względem fizjologicznym.  Krótsze odstępy zmniejszają użyteczność Sw jako sygnału; dłuższe - dają dość czasu na wystąpienie innych bodźców, aktywację innych reakcji i odwrócenie uwagi od specyficznego Sw.
Sam odstęp czasowy również może stać się bodźcem warunkowym. Jeśli bodziec bezwarunkowy podaje się wielokrotnie, a odstęp w czasie między kolejnymi ekspozycjami jest stały, to badane zwierzę uczy się reagować na ten |odstęp, wykonując reakcję tuż przed momentem, w którym powinien się pojawić Sb. Proces ten nazywa się |warunkowaniem |na |czas.

3. |Generalizacja |bodźca. We współczesnych stadiach wytwarzania reakcji warunkowej wiele bodźców podobnych do właściwego Sw będzie wywoływać tę reakcję. Zjawisko to nosi nazwę |generalizacji |bodźca. Ta skłonność do „mylenia” bodźców we wczesnym okresie warunkowania występuje najłatwiej w odniesieniu do bodźców należących do tej samej modalności zmysłowej, co bodziec warunkowy - tonów różnej wysokości lub bodźców świetlnych różnej jasności. Na przykład, gdy nauczyłeś się, że po dźwięku świdra dentystycznego następuje ból, to podobny dźwięk, niższy lub wyższy, będzie mógł wywołać u ciebie tę samą reakcję. Generalizacja bodźca może jednak występować także wobec bodźców należących do różnych modalności zmysłowych.  Pies, który uczy się wydzielać ślinę na dźwięk dzwonka, może także ślinić się, gdy zapali się jasna lampka.
Jeśli bodźce uporządkuje się (np. od najniższego do najwyższego) według ich relacji do bodźca warunkowanego, to siłę reakcji na każdy z tych bodźców można przedstawić za pomocą krzywej zwanej |gradientem |generalizacji |bodźca. Gdy organizm reaguje podobnie na wiele bodźców, wówczas mówi się, że gradient generalizacji jest „płaski”; gdy różnicuje je i reaguje na każdy bodziec zależnie od jego podobieństwa do pierwotnego bodźca warunkowego, wówczas gradient określa się jako „stromy” (ryc. 3.4).  W miarę postępów warunkowania jednostka reaguje coraz silniej tylko na bodźce zupełnie podobne do właściwego sygnału. Wskutek tego gradient generalizacji zmienia się w krzywej stosunkowo płaskiej w krzywą stromą.

4. |Różnicowanie |i |hamowanie. Chociaż początkowo może być użyteczne dla organizmu reagować na wszystkie bodźce, które potencjalnie mogą mieć wartość sygnałową, musi on nauczyć się rozróżniać, czyli |różnicować bodźce istotne i nieistotne oraz |hamować swoją reakcję na wszystkie bodźce nie związane z bezwarunkowym zdarzeniem bodźcowym. Warunkowanie można uważać za proces, w którym różnicowanie bierze górę nad generalizacją.
Im łatwiejszy do odróżnienia jest |sygnał, tym szybciej zostanie zidentyfikowany i skupi na sobie uwagę kosztem |szumu - nieistotnych bodźców występujących w tym samym czasie. Tak więc duża rozbieżność między bodźcami (np. różnica intensywności) przyspieszy różnicowanie.

* * *
Ryc. 3.4. Gradienty Generalizacji Bodźca. Przy płaskim gradiencie generalizacji (po lewej) reakcje na bodźce o wyższej lub mniejszej intensywności są podobne do reakcji na bodziec warunkowy (Sw). Przy stromym gradiencie generalizacji (po prawej) reakcje na bodźce o wyższej lub niższej intensywności różnią się znacznie od reakcji na bodziec warunkowy.  Opierając się na swym własnym doświadczeniu, spróbuj powiedzieć, czy gradient generalizacji będzie prawdopodobnie stromy czy płaski, jeśli procedura warunkowania wytwarza silne reakcje emocjonalne?

* * *

W przykładzie z natryskiem kąpiący się szybciej nauczy się w związku między spadkiem ciśnienia, a wzrostem temperatury wody, wówczas gdy zmiana ciśnienia jest wyraźna, a wzrost temperatury jest duży, niż wtedy, gdy zmiany te są małe i stopniowe.
|Brak |reakcji również może być reakcją. Chociaż hamowanie reakcji jest aktem biernym w sensie behawioralnym, to jednak wymaga znacznej aktywności na poziomie nerwowym. W trakcie warunkowania widzimy jedynie aktywność zewnętrzną, lecz wielu badaczy sądzi, że najbardziej intrygującym aspektem warunkowania jest koordynująca rola procesów hamowania w tłumieniu niewłaściwych reakcji na wszystkie wejścia sensoryczne z wyjątkiem jednego, krytycznego.
Uwarunkowana już reakcja może oczywiście ulec chwilowemu zakłóceniu przez nieoczekiwany hałas czy światło lub przez stymulację z wewnątrz organizmu, taką jak zmęczenie, pełen pęcherz, pobudzenie seksualne lub inne stany motywacyjne.

5. |Warunkowanie |wyższego |rzędu. Jeden ze współpracowników Pawłowa, Kryłow, stwierdził, że po zastrzyku morfiny wywołującym mdłości i wymioty sam widok strzykawki, którą miano dokonać zastrzyku, też mógł wywołać wymioty - typową reakcję warunkową. Jednakże nie koniec na tym: stwierdził on również, że mdłości zaczynał wywoływać każdy bodziec, który regularnie poprzedzał widok strzykawki: spirytus zwilżający skórę, pudełko zawierające strzykawkę, w końcu nawet pomieszczenie laboratoryjne.
Proces ten, dzięki któremu szereg bodźców warunkowych może kolejno służyć za substytut pierwotnego bodźca warunkowego i wywołać reakcję warunkową, nazywa się |warunkowaniem |wyższego |rzędu. Gdy bodziec warunkowy uzyskał już zdolność wywołania silnej reakcji warunkowej, można go połączyć z każdym innym bodźcem, który organizm jest w stanie spostrzec, i ten drugi bodziec zacznie wywoływać reakcję warunkową pod nieobecność zarówno Sb jak i pierwotnego Sw. W ten sposób zachowanie ludzkie może w końcu w dużym stopniu uzależnić się od bodźców bardzo różniących się jakościowo od tych bodźców, które pierwotnie występowały w czasie warunkowania. Na przykład rolę tę mogą zacząć odgrywać gesty, słowa lub wyobrażenia.

6. |Wygaszanie. Ponieważ rzeczywiste związki między zdarzeniami w środowisku zmieniają się od czasu do czasu, jest rzeczą niezmiernie ważną, aby związki wytworzone przez warunkowanie nie były niezmienne. Inaczej nie bylibyśmy dostatecznie elastyczni, aby móc właściwie reagować na zmieniające się środowisko. Gdy bodziec warunkowy nie sygnalizuje już ani niebezpieczeństwa, ani korzyści, dalsze reagowanie nań byłoby niefunkcjonalne, a nawet szkodliwe.
Na szczęście dla nas, większość takich niefunkcjonalnych reakcji w końcu zanika, gdy po bodźcu warunkowym wielokrotnie |nie następuje bodziec bezwarunkowy: reakcja warunkowa staje się coraz słabsza i w końcu osiąga intensywność równą zeru. Mówi się wówczas, że reakcja ta została |wygaszona, a próby, które doprowadziły do tego (Sw + brak Sb) noszą nazwę |prób |wygaszających.
Gdy reakcja została wygaszona, czy oznacza to, że zanika na zawsze?  Niezupełnie. Wygaszanie jest szczególnym przypadkiem aktywnego hamowania, a nie utratą wyuczonego skojarzenia. Świadczy o tym fakt, że po okresie odpoczynku rzekomo wygaszona reakcja warunkowa znów ożywa - chociaż w nieco słabszej formie - za pierwszym ponownym pojawieniem się bodźca warunkowego.  Zjawisko to nazywa się |spontanicznym |odnowieniem. Jeśli przeprowadzi się dodatkowe próby (Sw + Sb), to reakcja powróci do swej poprzedniej siły.  Jeśli nastąpią dalsze próby wygaszające, to będzie ona słabła i zostanie wygaszona na stałe.
W czasie wygaszania zachodzi proces analogiczny do generalizacji bodźca w trakcie nabywania Rw. Reakcje na bodźce, których nie poddano bezpośrednio wygaszaniu, również zostaną wygaszone - proporcjonalnie do ich podobieństwa do bodźca warunkowego. To szerzenie się hamowania znane jest jako |ubytek (dekrement) |generalizacji.


Czy
Na Dźwięk 
Nazwiska Pawłowa 
Dzwoni w Tobie 
Jakiś Dzwonek?


Dlaczego intensywne, irracjonalne reakcje lękowe, wyuczone w wyniku warunkowania reaktywnego, utrzymując się niekiedy i nie wygasają, chociaż nigdy nie następuje żadna spodziewana krzywda ani niebezpieczeństwo?
Odpowiedź jest następująca: ludzie unikają sytuacji, w których mogliby zetknąć się z tym, czego nauczyli się obawiać (z wężami, ciasnymi pomieszczeniami, otwartą przestrzenią, wysokością) lub uciekają, gdy tylko pojawi się lub zbliża wzbudzający lęk obiekt czy sytuacja. Dlatego też nigdy nie mają sposobności nauczyć się, że w rzeczywistości te obiekty czy sytuacje nie są sygnałami nadciągającego niebezpieczeństwa lub krzywdy. Aby wygasić warunkową reakcję strachu, trzeba stworzyć takie warunki, żeby dany osobnik mógł się sam przekonać, iż po bodźcu warunkowym |nie następuje zło ani niebezpieczeństwo, a nawet, co więcej - że następuje po nim jakieś przyjemne zdarzenie; w tym ostatnim wypadku może występować tak zwane |przeciwwarunkowanie (counterconditioning). Zjawiska te demonstrowano w laboratorium.

„Eksperyment polegał na ćwiczeniu psów w unikaniu bolesnego wstrząsu elektrycznego wymierzanego przez metalową kratę stanowiącą podłogę urządzenia. Urządzenie to składało się z dwóch przyległych pomieszczeń i psy mogły uniknąć wstrząsu skacząc szybko przez barierkę do drugiej „bezpiecznej” przegrody czego uczyły się w ciągu kilku zaledwie prób. Po dziesięciu próbach warunkujących, nigdy już nie wymierzano wstrząsu w „niebezpiecznym” poprzednio pomieszczeniu. Niemniej jednak, gdy tylko umieszczono psy w tym pomieszczeniu, natychmiast przeskakiwały one do sąsiedniej przegrody i robiły to przez 500 prób - bez żadnych oznak wygaszenia! Nigdy nie nauczyły się, że pomieszczenie to jest już bezpieczne, ponieważ nie pozostawały w nim dostatecznie długo, by przekonać się, że związek ten (między sygnałem niebezpieczeństwa a wstrząsem - przyp.  tłum.) przestał istnieć” (Solomon, Kamin i Wynne, 1953).

7. |Siła |warunkowania. Nie możemy mierzyć siły warunkowania bezpośrednio, lecz musimy wnioskować o niej na podstawie pewnego rodzaju zachowania, które daje się zaobserwować i zmierzyć. Pawłow jako miarę siły reakcji stosował |amplitudę reakcji - ilości wydzielanej śliny. Inne stosowanie miary to |latencja (tzn. czas utajenia) reakcji - czas, jaki upływa między pojawieniem się bodźca warunkowego a reakcją - oraz |częstość, czyli tempo wykonywania danej reakcji.
Siłę warunkowania można także mierzyć |odpornością |na |wygaszanie.  Zakłada się, że tym silniejsza jest reakcja warunkowa, im więcej prób potrzeba dla jej wygaszania.
Psychologowie mogą posługiwać się siłą warunkowania nie tylko przy określaniu zdolności uczenia się, lecz także zdolności spostrzegania. W Rozdziale 2 opisano, jak Lipsitt i jego współpracownicy badali, czy niemowlęta potrafią rozróżniać dwa zapachy; ustalili oni, że niemowlęta potrafią nauczyć się reagować na jeden z nich, hamując jednocześnie reakcję na drugi.

8. |Pseudowarunkowanie. W niektórych wypadkach zachowanie podobne do reakcji warunkowej występuje pomimo tego, że w rzeczywistości warunkowanie nie nastąpiło. To zjawisko jest na ogół spowodowane stanem zwiększonej pobudliwości organizmu. W pseudowarunkowaniu zmiana siły reakcji następuje w wyniku doświadczenia, lecz nie jest skutkiem rzeczywistego wyuczenia się specyficznego związku między bodźcem a reakcją.



Zbliżenie
Robak, który się „uczy”, poucza eksperymentatorów.


„Co marny robak ma nam do powiedzenia o zasadach warunkowania? Wypławki (planaria) są najwyższą formą życia zwierzęcego, w której osobniki są zdolne do regeneracji, gdy zostaną przecięte na dwoje. Poruszają się one dzięki skurczom mięśniowym i reagują takimi skurczami na awersyjne bodźce.  W pierwszych eksperymentach nad uczeniem się tych zwierząt (Thompson i McConnell, 1955) wykazano, że na wstrząs elektryczny (Sb) reagują one skurczeniem się (Rb) i że tę reakcję można uwarunkować na światło (Sw).  Następnie McConnell i jego współpracownicy starali się ustalić, czy u uwarunkowanych w ten sposób wypławków, jeśli rozetnie się je na dwoje i pozwoli na regenerację, wyuczona reakcja zostanie zachowana jedynie u zwierząt z uwarunkowaną głową, czy także u osobników odtworzonych z uwarunkowanych ogonów?
Połowę osobników wchodzących w skład grupy uwarunkowanych wypławków przecięto na dwoje, podczas gdy drugą połowę pozostawiono nietkniętą. Gdy rozcięte połówki zregenerowały się, wszystkie zwierzęta zbadano ponownie.  Okazało się, że w obu grupach zregenerowanych zwierząt wyuczona reakcja warunkowa zachowała się w tym samym stopniu, jak u tych uwarunkowanych zwierząt, które pozostały nietknięte (McConnell, Jacobson i Kimble, 1959).
Jak daleko idące wnioski można by wyprowadzić z tego rodzaju danych? Czy uczenie się wywołuje trwałe zmiany w składzie chemicznym organizmu?  Przypuśćmy, że nieuwarunkowane wypławki żywiono by zmielonymi ciałami uwarunkowanych wypławków - czy ci „kanibale” staliby się dobrymi uczniami?  Gdy McConnell zastosował tę procedurę, wyniki zdawały się potwierdzać hipotezę o transferze pamięci z wyćwiczonego pokolenia wypławków na niewyćwiczonych (1962). Możesz sobie wyobrazić, jakie to odkrycie wywołało podniecenie. Oto nareszcie znaleziono sposób spożytkowania starych profesorów psychologii: zemleć ich i karmić nimi studentów I roku!
Niestety, te fascynujące wyniki nie przetrwały krytycznej weryfikacji, przeprowadzonej przez innych badaczy. Hartry, Keith-Lee i Morton (1964) zastosowali rygorystyczne środki kontroli przy ocenie innych możliwych wyjaśnień szybszego uczenia się nieuwarunkowanych wypławków, które karmiono ich uwarunkowanymi poprzednio współplemieńcami. W eksperymencie tym zastosowano siedem różnych sposobów postępowania. Jedną grupę wypławków uwarunkowano, a następnie dano jako pożywienie innym wypławkom; drugą grupę uwarunkowano, lecz pozostawiono nietkniętą. Innych grup nie warunkowano, lecz poddano je działaniu pewnych bodźców, występujących w procedurze warunkowania (wstrząs, światło lub po prostu dotykanie przez eksperymentatorów), a następnie użyto ich jako pokarmu dla „kanibalów”.  Dwie grupy nie otrzymywały żadnych bodźców; jedną z tych grup przeznaczono na pokarm dla „kanibalów”, drugą pozostawiono nietkniętą.
Następnie pięć grup „kanibalów” i dwie grupy, które pozostały nietknięte, przebadano przy użyciu „podwójnie ślepej” procedury (doubleblind technique), aby przekonać się, ile prób każda z nich będzie potrzebować dla osiągnięcia pierwotnego kryterium uczenia się. Jak się okazało, ćwiczenie miało na to wpływ. Najgorsze wyniki osiągnęła grupa nie karmiona innymi wypławkami i nie ćwiczona. Sam proces uwarunkowania ofiar nie zdawały się być jednak krytycznym czynnikiem zwiększającym zdolność warunkowania „kanibalów”. U kanibalów żywionych zwierzętami, które jedynie dotykano lub wystawiano na światło, warunkowanie przebiegało w istocie szybciej niż u tych, które jadły „wykształcone” zwierzęta. Wydaje się, że szybsze uczenie się, tam gdzie ono wystąpiło, nie wynikało z przekazywania uwarunkowanego wcześniej śladu pamięciowego, lecz było po prostu kwestią stymulacji lub odżywiania. Inne badania przyniosły podobne wnioski (Jensen, 1965).
Ogólne zwiększenie zdolności uczenia się wypławków - kanibalów w wyniku uprzedniego „uwrażliwienia” (sensitization) ich ofiar nie zdaje się być zatem niczym innym niż pewną formą |pseudowarunkowania. Obszerne omówienie przez nas sporu, jaki wznieciło banalne na pozór pytanie: „Co sprawia, że robak się skręca?”, wskazuje na doniosłe znaczenie kilku charakterystycznych cech psychologii jako nauki, o których wspomnieliśmy w Rozdziale 1:
1. „Od psychologicznego „odkrycia” daleko jeszcze do jego „udowodnienia”.
2. Najbardziej interesujące idee mają najpoważniejsze implikacje i poddawane są przez sceptyków najsurowszym sprawdzianom.
3. System wzajemnej kontroli i równowagi, nieodłączny od uprawiania metody naukowej, musi być utrzymywany w sprawności przez krytycznych badaczy gotowych poświęcić swój wysiłek i talent, aby w sposób niezależny sprawdzić wniosek przed jego zaakceptowaniem.
4. Nawet jeśli pierwsze wyjaśnienie danego „odkrycia” okaże się niemożliwe do utrzymania, to dalsze sprawdzanie może dostarczyć innych wartościowych wyjaśnień”.


Uczenie się może być czasem niebezpieczne


Jeśli wszystko, co spostrzegamy, może stać się dla nas sygnałem i jeśli każdą reakcję, którą wykonujemy w sposób naturalny, może zacząć wywoływać wyuczony sygnał, to możemy oczekiwać, że w wielu wypadkach będzie zachodzić niewłaściwe warunkowanie, a niektóre reakcje, zamiast zostać wygaszone, będą nadal nas dręczyć. I tak dzieje się rzeczywiście.

„Nadmierne obciążenie” i schizokineza. Przed wieloma laty Liddell (1934), psycholog z Cornell University, badał warunkowanie reaktywne u owiec, stosując wstrząs elektryczny jako bodziec bezwarunkowy. Owce wkrótce nauczyły się zginać nogę, w którą miały otrzymać wstrząs (na dźwięk dzwonka poprzedzającego ten wstrząs). Jednakże zgięciu nogi towarzyszyły także znaczne zmiany w oddychaniu, tempie pracy serca i ogólnej aktywności.  Reakcje te, podobnie jak specyficzna reakcja cofnięcia nogi, również podlegały warunkowaniu: Rw miała kilka komponentów, których nie posiadała prosta Rb.
Znacznie później Zeaman i Smith (1965) stwierdzili, że gdy łączy się światło i wstrząs elektryczny przy warunkowaniu reakcji serca, to zachodzi także warunkowanie reakcji oddechowych. Podobnie Neal Miller (1969) opisał wiele eksperymentów nad warunkowaniem reakcji autonomicznych, w których to eksperymentach zmiany następowały także w reakcjach innych niż warunkowane.  Te „inne” reakcje autonomiczne powracały do swej zwykłej postaci dopiero po dłuższym treningu i odróżnicowaniu wybranej reakcji warunkowej od pozostałych.
Ponieważ warunkowa reakcja mięśniowa może mieć również komponenty autonomiczne i emocjonalne, wygaszenie specyficznej reakcji warunkowej nie gwarantuje, że wszystkie dodatkowe komponenty tego układu reakcji także zostaną wygaszone. Przeciwnie, mogą one utrzymywać się, opierając się wygaszaniu przez czas nieograniczony. Pewien psycholog zauważył:


„Fakt, że raz ukształtowane odruchy warunkowe są tak trudne do wykorzenia sprawia, że jednostka, w miarę upływu lat, staje się muzeum starożytności (...). Jest obciążona wieloma reakcjami, które przestały być użyteczne, a nawet (...) zagrażają życiu. Dotyczy to zwłaszcza funkcji sercowo-naczyniowych, a właśnie te odruchy warunkowe są najtrwalsze. Dana osoba może wciąż reagować na jakąś starą krzywdę lub sytuację, która powoduje przyspieszenie pracy serca lub zwiększenie ciśnienia krwi.  Rezultatem może być chroniczne nadciśnienie. Może to być wyjaśnieniem wielu zgonów z powodu choroby serca”.
(Gantt, 1966, s.62).

Schizokineza jest terminem utworzonym przez Gantta dla określenia tego rodzaju rozdwojenia, w którym komponenty złożonej reakcji warunkowej rozdzielają się, a następnie przez cały czas idą własnymi, oddzielnymi drogami. W wielu przypadkach, w których jednostki nie wykazują już żadnej zewnętrznej reakcji behawioralnej na bodziec warunkowy, nadal wywiera on na nie wpływ na poziomie fizjologicznym.
Taką odporność na wygaszanie reakcji na ważny niegdyś bodziec sygnałowy, który już dawno przestał sygnalizować zbliżanie się realnego niebezpieczeństwa, zademonstrowano w badaniach reakcji związanej z sygnałem „Na stanowiska bojowe!” (Edwards i Acker, 1962).

„Przebywającym w szpitalu weteranom II wojny światowej, którzy odbyli czynną służbę w armii lądowej lub w marynarce, eksponowano serię 20 bodźców dźwiękowych i mierzono reakcję autonomiczne rejestrując zmiany RSG.  Największa różnica między byłymi żołnierzami tych dwóch rodzajów broni wystąpiła wtedy, gdy słuchali oni dźwięku gongu uderzającego raz po raz w tempie około 100 uderzeń na minutę.
Sygnału tego używano podczas wojny na okrętach wojennych Marynarki Stanów Zjednoczonych wzywając marynarzy na stanowiska bojowe i nadal wywoływał on silną reakcję autonomiczną u weteranów marynarki. Chociaż upłynęło więcej niż 15 lat od czasu, gdy bodziec ten sygnalizował niebezpieczeństwo, marynarze odpowiedzieli nań istotnie silniejszą reakcją emocjonalną niż żołnierze armii lądowej. Prawdopodobieństwo przypadkowego uzyskania tak dużej różnicy było mniejsze niż 0,01.

Uwarunkowane nałogi. Spośród wszystkich nałogów najbardziej skraca życie nałóg jedzenia.

Każdy może jeść, kiedy jest głodny; osoba otyła uczy się jeść nawet wtedy, gdy nie jest głodna. Niedawne badania (które przedstawimy w Rozdziale 8) wykazały, że wielu ludzi z dużą nadwagą odznacza się zwiększoną wrażliwością na sygnały skojarzone z pokarmem i jedzeniem - widok lub zapach potraw, obrazy przedstawiające potrawy lub widok innych ludzi jedzących. Ponadto sytuacje, w których ludzie z nadwagą zazwyczaj jedzą, gdy są głodni, stają się bodźcami warunkowymi wywołującymi u nich reakcję jedzenia nawet wtedy, gdy nie odczuwają głodu - na przykład przy oglądaniu telewizji, filmów lub meczów sportowych, czy słuchaniu muzyki, przy przechodzeniu przez kuchnię lub jadalnię itd. Procedura terapeutyczna wypróbowana niedawno z pewnym powodzeniem polega na osłabieniu tych uwarunkowanych skojarzeń przez ograniczenie jedzenia do jednego tylko miejsca, w określonych z góry porach itd.
(Stunkard, 1972).

Nerwica eksperymentalna. Niekiedy u zwierząt, które w trakcie treningu warunkującego poddawane są silnemu stresowi, rozwija się skrajnie anormalny wzorzec reakcji. Jeden z asystentów Pawłowa jako pierwszy zaobserwował tę reakcję u psa, którego uwarunkowano tak, by ślinił się na widok rzutowanego na ekran koła. Następnie uczono go różnicowania między tym kołem a elipsą, przeprowadzając szereg prób, w których po obrazie koła następował pokarm, a po obrazie elipsy - nie.
Później zmieniano stopniowo kształt elipsy, aż wreszcie wyglądała prawie jak koło (z jednym bokiem lekko spłaszczonym). Pies nadal dokonywał właściwych różnicowań, śliniąc się tylko na widok pełnego koła, jednakże w momencie, gdy bodźce były niemal takie same, jego zdolność dokonywania różnicowania załamała się i zaczęła się coraz bardziej pogarszać. W końcu zwierzę nie potrafiło nawet dokonać pierwotnego, prostego różnicowania.  Jeszcze bardziej dramatyczne były towarzyszące temu zmiany w zachowaniu.  Spokojny poprzednio pies szczekał, skowyczał, szarpał aparat, przejawiał oznaki strachu przed pomieszczeniem eksperymentalnym i wykazywał zgeneralizowane hamowanie prowadzące do ospałości i zapadania w sen.  Podobne reakcje stwierdzono w badaniach przeprowadzonych na szczurach, kotach i owcach.
Zjawisko to nazwano |nerwicą |eksperymentalną; jest ono podobne do nerwicy u ludzi w tym, że:
a) jest wynikiem długotrwałego stresu, nieuniknionego konfliktu i niezdolności dokonania wyboru między konkurencyjnymi możliwościami;
b) wiąże się z zachowaniem świadczącym o zgeneralizowanym stanie lękowym;
c) charakteryzuje się występowaniem „symptomów” - reakcji, które są niezwykłe w życiu danego organizmu i zapewniają w najlepszym razie jedynie częściowe rozwiązanie konfliktu;
d) może utrzymać się bez wygaszenia przez całe życie, o ile nie zastosuje się specjalnej, przeciwwarunkującej terapii.
Liddell (1956) opisuje symptomy trwające trzynaście lub więcej lat, a także wzrost liczby przedwczesnych zgonów wśród owiec, u których wywołano nerwicę eksperymentalną. Autor ten relacjonuje też wypadek, jaki zdarzył się eksperymentatorowi, który powrócił po roku innej pracy, a jego 400-funtowa neurotyczna maciora, Tiny, „przyjaznymi demonstracjami zwabiła go w róg ogrodzenia i tam zaatakowała tak złośliwie, że wymagał pomocy lekarskiej” (ss. 982-83).


Gmach wzniesiony przez Pawłowa


„Amerykańscy badacze, reprezentujący nauki behawioralne, z pewnością dobudowali skrzydła do gmachu wzniesionego przez Pawłowa, lecz w istocie są to jedynie skrzydła; główny gmach nadal wznosi się wysoko i stoi mocno, prawie nie naruszony przez wiatr i pogodę”.
G. H.S. Razran „Introductory Remarks to Pavlovian Conference”, 1961, s. 
816.

Z przypadkowego odkrycia warunkowego ślinienia się u psów, jakiego dokonał Pawłow badając fizjologię trawienia, rozwinął się ten sposób badań nad zachowaniem, który do chwili obecnej dominuje w wielu gałęziach psychologii radzieckiej. Również w Ameryce wielu psychologów, badających proces uczenia się, uważa się za neopawłowistów, podobnie jak wielu neurofizjologów, którzy starają się ustalić, co dzieje się w mózgu w czasie procesu uczenia się.
W Stanach Zjednoczonych John B. Watson, twórca psychologii obiektywnej - |behawioryzmu, poszedł nawet jeszcze dalej w kierunku psychologii zjawisk fizjologicznych i związków bodziec-reakcja. Twierdził on, że zachowanie składa się |wyłącznie z wydzielania przez gruczoły oraz ruchów mięśniowych i że reakcje te są zdeterminowane przez efektywne bodźce.
Zdaniem Watsona zadanie psychologii polega zatem na określaniu zależności między bodźcami i zewnętrznymi, możliwymi do zaobserwowania reakcjami, a także na sterowaniu tymi zależnościami. Nie ma sensu badanie procesów świadomych, zjawisk psychicznych czy introspekcyjnych opisów treści umysłu: zachowanie można wyjaśnić i przewidywać bez tego.
Nacisk, jaki Watson kładł na to, że podstawą psychologii są dające się zaobserwować i zmierzyć reakcje, był sprzeczny z dominującą tendencją owego okresu, która polegała na przypisywaniu wszelkiego zachowania wrodzonym tendencjom i „instynktom” oraz ignorowaniu wpływu czynników środowiskowych na kształtowanie zachowania. Badaczom, sceptycznie zapatrującym się na możliwość modyfikowania ludzkiego zachowania za pomocą procesu warunkowania, Watson ogłosił:

„Dajcie mi tuzin zdrowych, normalnych niemowląt i mój własny, specyficzny świat, w którym bym je wychował, a gwarantuję, że wezmę na chybił trafił któreś z nich i wyszkolę je na specjalistę dowolnego typu, jaki tylko mógłbym wybrać - lekarza, prawnika, artystę, kupca, a nawet żebraka czy złodzieja, niezależnie od jego talentów, skłonności, tendencji, powołań oraz bez względu na rasę jego przodków”. (1926, s.10)

Pracę Watsona z jednym takim zdrowym niemowlęciem opisano w poniższym „Zbliżeniu”.


Zbliżenie
Smutna opowieść o małym Albercie i białym szczurze


„Mały Albert z początku był „normalnym”, raczej mało pobudliwym emocjonalnie niemowlęciem. Nigdy nie zareagował strachem na żadną z sytuacji testowych obmyślonych przez eksperymentatora. Jego reakcja na różne podawane mu nagle przedmioty polegała na tym, że wyciągał do nich ręce i bawił się nimi. Były to: biały szczur, królik, pies, futro, kłębek przędzy i różne maski. Jednakże wzdrygał się i zaczynał płakać, gdy nieoczekiwanie tuż za nim rozlegał się głośny dźwięk mocnego uderzenia w stalową sztabę.
Albert miał jedenaście miesięcy i trzy dni, gdy sięgając po przyniesionego mu białego szczura posłyszał dźwięk gongu - |bang! Po dwóch takich doświadczeniach dziecko zaczęło kwilić. Gdy po tygodniu szczur znowu pojawił się na scenie Albert pamiętał tę nauczkę - cofnął rękę zanim dotknęła ona starego towarzysza zabaw. Wówczas rozpoczęto systematyczne warunkowanie reaktywne w celu wytworzenia silnej reakcji emocjonalnej na białego szczura. Przez siedem prób łączono widok białego szczura z przerażającym dźwiękiem. Gdy następnie pokazywano samego białego szczura, Albert zaczynał płakać, odwracał się i uciekał na czworakach ze wszystkich swych niewielkich sił.
Mniej więcej tydzień później reakcja strachu zgeneralizowała się z białego szczura na przyjaznego królika. Pies również go przerażał, futro wywoływało płacz, uciekał od kłębka przędzy. Co najsmutniejsze, reagował „zdecydowanie negatywnie”, gdy pokazano mu maskę Świętego Mikołaja. Nie przejawiał natomiast takiego strachu wobec klocków ani innych przedmiotów, które nie posiadały pewnej wspólnej, najwyraźniej decydującej cechy bodźcowej, a mianowicie nie były „włochate”.
Czy mały Albert wyrósł na Scrooge’a (Bohater „Opowieści wigilijnej” Charlesa Dickensa (przyp. red.)), który nienawidził świąt Bożego Narodzenia wraz z wywołującym straszne wspomnienia Świętym Mikołajem - musi to pozostać w sferze przypuszczeń. Eksperymentatorzy podają, że „Niestety, Albert został zabrany ze szpitala w dniu, w którym przeprowadzono powyższe testy. Wskutek tego zostaliśmy pozbawieni sposobności opracowania techniki eksperymentalnej, za pomocą której moglibyśmy eliminować warunkowe reakcje emocjonalne” (Watson i Rayner, 1920).

Lata, jakie upłynęły od tego czasu, przyniosły przekonywujące dowody, że twierdzenie Watsona jest zbyt skrajne - że trzeba brać pod uwagę zarówno środowisko społeczne, jak i strukturę genetyczną. Ponadto, jak się przekonamy, zgromadzono materiał dowodowy, który wskazuje na potrzebę badania wpływu czynników poznawczych na zachowanie. Lecz nawet przy tych zastrzeżeniach gmach wzniesiony przez Pawłowa nadal jest imponującą i tętniącą życiem budowlą.


Warunkowanie oparte na konsekwencjach: warunkowanie instrumentalne


Nauczenie się, które zdarzenia w otoczeniu są w przewidywalny sposób ze sobą związane, nie wystarczy do adaptacji i przetrwania. Jak już wspominaliśmy, każdy organizm musi także nauczyć się, jakich stałych związków może oczekiwać między swoimi własnymi działaniami a następującymi po nich zdarzeniami w otoczeniu - a zwłaszcza, jakie zmiany może osiągnąć lub jakim zapobiec. Psychologia amerykańska od początku koncentrowała swe zainteresowanie na badaniu uczenia się, a szczególnie uczenia się związków tego drugiego rodzaju - jak przystoi młodemu, nastawionemu na działanie, praktycznemu społeczeństwu, ufnemu w swą zdolność kierowania własnym losem.  Pionierzy amerykańskiej psychologii rozwinęli własne techniki badawcze i koncepcje teoretyczne badanych zjawisk, przy czym prace prowadzone w innych krajach miały na nich początkowo niewielki wpływ.


Koty Thorndike’a w skrzynkach problemowych


W tym samym mniej więcej czasie, gdy rosyjskie psy śliniły się lub zginały łapy pod wpływem różnych bodźców, amerykańskie koty uczyły się wydostać z dziwnych skrzynek. Aby uwolnić się ze swego „miejsca odosobnienia” (i dostać pokarm) głodne koty musiały odkryć, w jaki sposób otwiera się zasuwkę w każdej z siedmiu różnych „skrzynek problemowych”.  Amerykański psycholog E. L. Thorndike z Columbia University już w 1898 roku opisał wyniki tego pionierskiego badania, które dało początek behawioralnemu (w przeciwieństwie do bardziej fizjologicznego pawłowskiego) podejścia do uczenia się:

„Kot, umieszczony w skrzynce, przejawia wyraźne oznaki niezadowolenia i gwałtowną chęć do ucieczki ze swego więzienia. Próbuje przecisnąć się przez każdą szparę, drapie pręty i druty, wtyka łapy w każdy otwór i szarpie wszystko, czego dosięgnie (...). Nie zwraca wiele uwagi na pokarm znajdujący się na zewnątrz (nagroda dla tego głodnego kota), lecz wydaje się, że po prostu instynktownie stara się uciec z więzienia. Energia, z jaką się szamoce, jest niezwykła. Przez osiem czy dziewięć minut będzie drapać, gryźć i przeciskać się nieustannie. „Trzynastka”, stary kot i „jedenastka”, kot niezwykle ospały, zachowywały się odmiennie: nie szamotały się energicznie ani nieustannie, niekiedy w ogóle się nie szamotały. Trzeba więc było wypuścić je parokrotnie ze skrzynki, karmiąc je za każdym razem. Gdy w ten sposób skojarzyły sobie wyłażenie ze skrzynki z otrzymaniem pokarmu, starały się wydostać z niej, gdy tylko je tam umieszczano (...). Niezależnie od tego, czy impuls do szamotania wynika z instynktownej reakcji na uwięzienie, czy ze skojarzenia, zwykle dzięki szamotaniu kot z powodzeniem wydostaje się ze skrzynki. Kot, który podczas swej gwałtownej szamotaniny drapie po całej skrzynce, zaczepi prawdopodobnie pazurem o sznurek, pętelkę czy przycisk tak, że otworzy drzwiczki. Stopniowo wszystkie inne nieskuteczne impulsy zostaną stłumione, a określony impuls prowadzący do skutecznego aktu zostanie utrwalony przez wynikającą z niego przyjemność, aż w końcu, po wielu próbach, kot umieszczony w skrzynce będzie natychmiast naciskał przycisk lub pociągał pętelkę w określony sposób” (s. 13; ryc. 3.5)

Wychodząc od tego rodzaju obserwacji nad „uczeniem się metodą prób i błędów”, Thorndike zaczął badać zjawiska, które z czasem nazwano |warunkowaniem |instrumentalnym. Jego metody i idee stały się kamieniem węgielnym amerykańskich badań nad procesem uczenia się u ludzi i zwierząt.
Przeanalizujemy teraz pokrótce zachowanie kotów oraz zastosowany przez Thorndike’a sposób wyjaśniania go w kategoriach odmiennych niż stosowane przy wyjaśnieniu warunkowania reaktywnego.

Zmienne pośredniczące - popędy, hierarchie reakcji i sygnały. Aby wyjaśnić zachowanie kotów, Thorndike wnioskował o istnieniu niewidocznych, wewnętrznych procesów, które |pośredniczą między obserwowalnymi zdarzeniami. Był na przykład przekonany, że jego koty w skrzynkach problemowych były motywowane przez |stany |popędowe - silne bodźce wewnętrzne, które skłaniały zwierzęta do działania, aktywizując ich zachowanie. Zachowanie to uważał on więc za zachowanie wytwarzane (emitowane; emitted behavior) - spowodowane przez stany wewnętrzne, a nie |wywołane (elicited) przez zewnętrzny bodziec warunkowy (ryc. 3.6).
Thorndike przyjmował, że te wewnętrzne popędy zmuszają osobnika do wykonywania różnych reakcji - niektórych wrodzonych i „zaprogramowanych” w układzie nerwowym danego gatunku (miauczenie i syczenie u kotów, płacz u niemowląt), innych - wyuczonych w uprzednich doświadczeniach.

* * *
Ryc. 3.5. Koty Thorndike’a zamykano w skrzynkach podobnych do tej, a pokarm umieszczano na zewnątrz skrzynki. Aby wydostać się, zwierzę musiało zwolnić zasuwę, dźwignię lub pętlę, w celu odblokowania ciężarka, który pociągał drzwiczki otwierając je.

Ryc. 3.6. Uczenie Się Instrumentalne: Uwalnianie Się Kota Ze Skrzynki. W sytuacji eksperymentalnej Thorndike’a przyjmowano, że dwa motywy pobudzają do działania: strach i głód. Ta sama reakcja prowadzi do uwolnienia się i do pokarmu. Thorndike nigdy nie wiedział, czy oba te stany motywacyjne były niezbędne, czy też koty równie intensywnie starałyby się wydostać, gdyby zostały dobrze nakarmione. Obecnie częściej bada się skutki zastosowania jednej tylko operacji eksperymentalnej na raz.
* * *

Wszystkie te reakcje, zarówno wrodzone, jak i wyuczone, składają się na repertuar reakcji jednostki, przy czym wypróbowanie niektórych z nich jest bardziej prawdopodobne niż innych.
Gdy kot został po raz pierwszy wsadzony do skrzynki problemowej, próbował wielu spośród tych dostępnych reakcji, lecz w ciągu kilku prób większość z nich została wyeliminowana. Chociaż reakcje te były przypuszczalnie wytwarzane w odpowiedzi na bodźce |wewnętrzne (najprawdopodobniej były to głód i strach), to jednak selekcją i eliminacją kierowały sygnały (cues) dostarczane przez bodźce |zewnętrzne. Takie zewnętrzne bodźce mogły pomóc w skupieniu uwagi danego osobnika na istotnych elementach otoczenia (zasuwie lub misce z pokarmem) lub mogły służyć jako sygnały wskazujące, kiedy określona reakcja jest odpowiednia. Na przykład, jeśli światło było zapalone zawsze wtedy, gdy pokarm był dostępny, a zgaszone wtedy, gdy pokarmu nie było, zachowaniem zwierzęcia zaczynała kierować obecność lub brak światła. Chociaż jego „głód” był niezmienny, uczyło się ono zabiegać o pokarm tylko wtedy, gdy zapaliło się światło, ponieważ tylko wtedy po właściwej reakcji następowało karmienie. W warunkowaniu instrumentalnym chodzi o nauczenie się tej reakcji, która jest środkiem („instrumentem”) prowadzącym do otrzymania upragnionej nagrody.

Prawo efektu. Podobnie jak koty Thorndike’a, napotykasz sytuacje, w których wiele zależy od tego, co zrobisz. Jeśli automat z wodą sodową regularnie nie dostarcza tego napoju, chociaż wrzucasz weń monety, to uczysz się, że wrzucenie monety nie ma żadnego wpływu na ten automat; twoje zachowanie nie wywołuje zmiany otoczenia. Jeśli jednak kopniesz automat, po czym popłynie zimna woda sodowa i ugasisz pragnienie, to twoje zachowanie będzie miało wpływ na otoczenie.

Następnym razem, gdy będziesz spragniony, być może podejdziesz do automatu i zaczniesz go kopać (zwłaszcza jeśli nikt nie będzie tego widział). Kopanie automatu stało się więc u ciebie dominującą, wysoce prawdopodobną reakcją. Jeśli w ten sposób nie uzyskasz upragnionego napoju, to możesz nauczyć się, że zachowanie, po którym pojawia się woda sodowa, składa się z dwóch reakcji jednostkowych, najpierw wrzuca się monetę, po czym kopie się solidnie oszukańczą machinę. Przy następnych okazjach będziesz powtarzać tę sekwencję lub poszukasz innego automatu, który dostarczy ci napoju za samą monetę lub za kopniak nieco lżejszy.
Gdyby w eksperymencie Thorndike’a zasuwę otwierał przekaźnik uruchamiany przez dźwięki, jakie wydawał kot miaucząc lub sycząc, albo gdyby przychodziła wówczas jego matka-kocica i otwierała drzwiczki, to w dalszych próbach koty nadal miauczałyby lub syczały. Jednakże miauczenie i syczenie nie prowadziły do wyswobodzenia się ani do pojawienia się pokarmu; w istocie nie miały one w ogóle żadnego wpływu na otoczenie. Wobec tego zachowania te przestawały występować; w terminologii Thorndike’a przesuwały się one na niższe miejsca w hierarchii reakcji.
Thorndike sądził, że to |uczucie |zadowolenia (następna nieobserwalna zmienna pośrednicząca) z osiągniętego rezultatu sprawiało, iż wystąpienie skutecznej reakcji stawało się bardziej prawdopodobne. Uważał on te pomyślne konsekwencje wywołane w otoczeniu za „stany wzmacniające” (reinforcing states) i był przekonany, że związki między tymi następstwami a reakcjami, które do nich doprowadziły, utrwalają się w kolejnych próbach treningowych. Zgodnie ze sformułowanym przez niego |prawem efektu.

„Każdy akt, który w danej sytuacji wywołuje zadowolenie, zostaje skojarzony z tą sytuacją tak, że kiedy sytuacja powtarza się, jest bardziej prawdopodobne niż kiedykolwiek przedtem, iż dany akt także zostanie powtórzony. I na odwrót, każdy akt, który w danej sytuacji wywołuje przykrość, zostaje oddzielony (disassociated) od tej sytuacji - gdy powtórzy się ona, ponowne wystąpienie tego aktu jest mniej prawdopodobne niż przedtem” (1905, s. 202).

Prawo efektu Thorndike’a to w istocie niewiele więcej niż nowoczesne sformułowanie starej doktryny |hedonistycznej, której autorem był filozof Jeremy Bentham; głosi ona, że ludzie skłonni są zachowywać się w taki sposób, który pozwoli im uzyskać przyjemność i uniknąć przykrości. Niemniej jednak przez wiele lat prawo efektu służyło za podstawową zasadę dla rozwijającego się amerykańskiego przedsięwzięcia zwanego „psychologią uczenia się”.




Zintegrowana teoria Hulla


Nieco później Clark Hull (1943, 1952) z Yale University pokusił się o sformułowanie ogólnej teorii uczenia się, która nie tylko zintegrowałaby wyniki badań nad warunkowaniem reaktywnym i instrumentalnym oraz ujęła w sposób obiektywny i ścisły prawo efektu, lecz ponadto stosowałaby się zarówno do społecznego uczenia się ludzi, jak i do uczenia się labiryntów u zwierząt. Główne elementy teorii Hulla są następujące:
1. Przedmiotem uczenia się jest związek między bodźcem a reakcją; jednostka uczenia się nosi nazwę |siły |nawyku.
2. |Wzmocnienie jest niezbędnym warunkiem uczenia się. Aby siła nawyku dla danej reakcji wzrastała, bezpośrednio po niej musi zostać uzyskana pewna „substancja” stanowiąca cel (goal substance). „Substancje” takie, zwane |czynnikami |wzmacniającymi (Czynnikiem wzmacniającym może być także osiągnięcie pewnej szeroko rozumianej wartości lub pewnego stanu rzeczy (np. oddalenie się od awersyjnego bodźca; przyp. nauk.)) (reinfocers), zawdzięczają swą efektywność temu, że redukują poziom istniejącego popędu.  Dlatego też teorię uczenia się Hulla określa się jako teorię |redukcji |popędu.
3. Siła wyuczonego związku między bodźcem a reakcją wzrasta stopniowo, w sposób ciągły, wraz z każdą wzmocnioną próbą w trakcie ćwiczenia; uczenie się stanowi względnie trwałą zmianę w zachowaniu.
Niestety, teoria Hulla pozostała nieukończona z powodu jego śmierci w 1952 roku. Wywarła ona jednak poważny wpływ na amerykańską psychologię, a inni psychologowie udoskonalili ją i rozwinęli („Spence”, 1956).


Celowościowy behawioryzm Tolmana



Na zachodnim wybrzeżu Stanów Zjednoczonych E. C. Tolman (1932, 1950) z University of California w Berkeley odrzucił pogląd, że uczenie się polega na tworzeniu związków S-R - „molekularnych” jednostek zachowania - na rzecz szerszej koncepcji uczenia się. Zdaniem Tolmana uczenie się - to „molarne” zmiany w elementach poznawczych (cognitins), zachodzące w wyniku interakcji z otoczeniem. Zakłada on, że te „elementy poznawcze” składają się ze spostrzeżeń oraz przekonań czy wiadomości dotyczących otoczenia.
Według Tolmana, organizmy uczą się oczekiwać, że otoczenie jest zorganizowane w sensowne struktury czy wzorce. Uczą się, że niektóre bodźce oznaczają, iż nastąpią pewne zdarzenia, czyli są zwykle związane z innymi bodźcami; tak więc bodźce nie tylko wywołują reakcję, lecz także dostarczają informacji, funkcjonując jako sygnały czy znaki. Znaki te są częścią pewnej struktury, w skład której wchodzą wspomnienia ubiegłych doświadczeń, jak również dane z aktualnych spostrzeżeń. Wyuczone zachowanie nie jest zatem tylko automatycznym, ślepym „emitowaniem” reakcji, które w przeszłości zostały skojarzone z określonymi układami bodźców i nagród.  Przeciwnie, w zachowaniu wyuczonym zawsze wchodzą w grę cele - wyraźnie określone lub dające się wywnioskować, a także wytwarzanie hipotez i oczekiwań, dotyczących sposobu osiągnięcia tych celów. Uczenie się jest więc celowe i racjonalnie ukierunkowane. Poglądy te, to herezja dla tradycyjnego behawiorysty - zarówno z powodu uwzględniania doświadczeń wewnętrznych, jak i założeń dotyczących celowości i racjonalności!
Teoria Tolmana, podobnie jak teoria Hulla, przypisuje ważną rolę potrzebom (needs) i celom (goals); wykracza jednak poza to, co byłoby możliwe do przyjęcia dla zwolenników Hulla, jeśli chodzi o wzajemne relacje między tymi dwoma pojęciami. Według Tolmana, potrzeby wytwarzają zapotrzebowania (demands) w odniesieniu do celów, a nagrody prowadzą do powstania |kateksji |przedmiotu (object-cathexis, termin zapożyczony od Freuda), która jest tendencją do poszukiwania pewnych celów, a unikaniu innych.
Stanowisko Tolmana można także określić jako podejście poznawcze, według którego przedmiotem uczenia się są związki S-S, „mapy poznawcze” otoczenia.

Zgodnie z tym sposobem podejścia, ważnym procesem, podczas uczenia się jest raczej nabywanie |informacji (wyłączając tu pojęcia abstrakcyjne i uogólnienia), niż specyficznych |reakcji.


Warunkowanie oparte na konsekwencjach: warunkowanie sprawcze



Jest możliwe, że nazwisko Skinnera, podobnie jak Freuda i Pawłowa, było ci znane, zanim jeszcze zacząłeś studiować psychologię. B. F. Skinner, profesor Harvard Univeristy, jest autorem głośnej powieści „Walden II” (1948), w której opisuje behawiorystycznie zaplanowaną utopijną społeczność, a ostatnio (1971) stał się najbardziej znanym prorokiem „inżynierii behawioralnej”, której wkład dał w swej książce „Beyond and Dignity” („Poza wolnością i godnością”). Pomiędzy tymi pracami literackimi Skinner stworzył tak zwaną |eksperymentalną |analizę |zachowania i rozwinął ją w ścisłą gałąź wiedzy, a także był pionierem w dziedzinie zastosowania swych technik uczenia się do udoskonalenia procesu nauczania i do modyfikacji anormalnego zachowania chorych psychicznie, przestępców i innych ludzi z „zaburzeniami zachowania”.
Skinner od początku kładł nacisk na obserwowanie fizycznych, dających się mierzyć właściwości reakcji oraz na rozwijanie praktycznych technik sterowania obserwowalnymi reakcjami. W takiej analizie zachowania nie ma miejsca dla nieobserwowalnych, wywnioskowanych, psychicznych, motywacyjnych lub nawet fizjologicznych stanów bytów. Na przykład, co naprawdę wiemy o kotach Thorndike’a? Co moglibyśmy |zaobserwować? Miauczenie i drapanie - tak; wewnętrzne popędy - nie. Wyższą częstość występowania skutecznej reakcji - tak: zadowolenie - nie.

* * *
Ryc. 3.8. B. F. Skinner i jego przyjaciele.

* * *

Zaprzestanie nieskutecznych reakcji - tak; „utrwalanie” czy „stłumienie” - nie. W istocie, jeśli ujmiesz uczenie się jako „utrwalanie związków”, to możesz spędzić lata na szukaniu niewłaściwej rzeczy w niewłaściwym miejscu, jeśli w rzeczywistości uczenie się polega na czymś zupełnie innym. Obecnie psychologowie znacznie lepiej zdają sobie sprawę z tego, że stosowane przez nich pojęcia powinny być precyzyjne, jasno określone i ściśle związane z tym, co |można zaobserwować.
Zwolennicy Skinnera uważają, że sytuacje uczenia się można i należy opisać |wyłącznie w takich kategoriach, aby nie trzeba było mówić nic o tym, co zachodzi wewnątrz organizmu. Na przykład definiują oni „głód” nie przez wnioskowanie o popędach, lecz przez eksperymentalną operację pozbawienia pokarmu w ciągu określonej liczby godzin przed próbą lub przez określony procent utraty wagi ciała od chwili, gdy dany organizm poddano deprywacji pokarmowej.
W ramach tego podejścia, zamiast mówić, że głód |motywuje zwierzę do zabiegania o pokarm, mówi się, że deprywacja pokarmowa czyni pokarm skuteczniejszym czynnikiem wzmacniającym, czego miarą jest szybsze tempo reagowania. Deprywacja, ilość i rodzaj pokarmu oraz tempo reagowania - wszystko to są zdarzenia zewnętrzne, dające się obserwować i mierzyć.
Konsekwencje również można zdefiniować empirycznie. |Czynnik |wzmacniający (reinforcer) lub |bodziec |wzmacniający definiuje się jako każdy bodziec, który następuje po reakcji i zwiększa prawdopodobieństwo jej wystąpienia. Jeśli otrzymanie pokarmu w wyniku otwarcia zasuwki czyni reakcję otworzenia zasuwki bardziej prawdopodobną za następnym razem, to otrzymanie pokarmu jest czynnikiem wzmacniającym. Według słów Skinnera:

„Podstawową daną w nauce o zachowaniu jest prawdopodobieństwo, że określony element zachowania wystąpi w określonym czasie. Analiza eksperymentalna ujmuje to prawdopodobieństwo w kategoriach częstości lub tempa reagowania (...). Zadaniem analizy eksperymentalnej jest wykrycie wszystkich zmiennych, których funkcją jest prawdopodobieństwo reakcji” (1966, ss. 213, 214).


Zachowanie sprawcze


Podobnie jak Thorndike, psychologowie będący zwolennikami Skinnera badają zachowanie dowolnie wytwarzane (emitowane) przez organizm, a następnie wzmacniane, nie zaś zachowanie mimowolne, wywoływane automatycznie przez poprzedzający je bodziec. Zamiast jednak posługiwać się terminem |reakcja |instrumentalna, który dla psychologów starających się uniknąć pojęć mentalistycznych, niemile akcentuje celowość, stosują oni termin |reakcja |sprawcza (operant), oznaczający reakcję, która oddziałuje (operates) na otoczenie (w odróżnieniu od ślinienia się i innych zachowań reaktywnych - „respondents - które badają pawłowiści). W rzeczywistości, wielu psychologów stosuje terminy |instrumentalne i |sprawcze zamienne, chociaż |sprawcze pozostaje ulubionym terminem Skinnera i jego licznych uczniów i zwolenników pracujących w dziedzinie modyfikacji zachowania.
Jednakże reakcje „sprawcze” badane przez Skinnera różnią się pod jednym ważnym względem od reakcji „instrumentalnych”, które badał Thorndike.  Podczas gdy koty Thorndike’a musiały nauczyć się nowych reakcji, aby uciec ze skrzynek problemowych, to szczury i gołębie Skinnera zwykle uczą się po prostu zwiększać lub zmniejszać tempo pewnej reakcji, którą już wykonują, takiej jak naciskanie dźwigni lub dziobanie krążka.

Poziom sprawczy. Tempo, w jakim występuje dana reakcja, gdy możność jej wykonania nie jest ograniczona, a jej konsekwencje nie są ani pozytywne ani negatywne, nosi nazwę |poziomu |sprawczego (operant level) tej reakcji.  Każda reakcja ma określony poziom sprawczy u danego osobnika. Psychologowie skinnerowscy badają |zmiany tempa reakcji zachodzące pod wpływem różnych rodzajów wzmocnienia, różnej jego intensywności i różnych rozkładów w czasie. Jąkanie się, gestykulowanie, przełykanie śliny podczas czytania oraz używanie w mowie rzeczowników w liczbie mnogiej - wszystko to są przykłady reakcji, których poziom sprawczy u ludzi można badać lub modyfikować.

Co to jest „reakcja, która może być wzmocniona?” W rzeczywistości to, co arbitralnie określamy jako „reakcję”, jest jedynie pewnym segmentem ciągłego procesu zachowania. Poza poziomem eferentnego impulsu nerwowego nie istnieje coś takiego jak pojedyncza reakcja. Nawet skurcz mięśnia składa się z wielu komponentów. Wielkość jednostki, którą określamy jako reakcję, może być bardzo różna; jeśli jest wzmacniana jako jednostka, to można oczekiwać, że wzrośnie tempo wykonywania całej tej jednostki. Sto naciśnięć dźwigni, które jako jednostka powodują wzmocnienie, mogłoby być reakcją sprawczą, podobnie jak mogłoby nią być uczęszczanie przez cztery lata do college’u za wzmocnienie w postaci dyplomu. Nie ma zatem właściwie granic wyznaczających, jak duża lub jak mała może być „reakcja”, która może być wzmocniona”.
Niektóre jednostki zachowania, takie jak skurcze mięśni, nie mają zwykle bezpośredniego wpływu na otoczenie. Gdy jednak pomysłowy eksperymentator stworzy warunki, w których |mają one taki wpływ, częstość ich występowania odpowiednio się zmienia. Jak przekonaliśmy się w poprzednim rozdziale, można zmieniać w ten sposób nawet częstość występowania poszczególnych rytmów czynności bioelektrycznej mózgu (EEG). Twierdzenie badaczy warunkowania sprawczego, że |każda |reakcja, |która |może |być |szybko |wzmocniona, |może |zostać |uwarunkowana, współzawodniczy zatem niewątpliwie pod względem swej ważności z twierdzeniem badaczy warunkowania reaktywnego, które głosi że |wszystko |co |organizm |może |spostrzec, |może |stać |się |bodźcem |warunkowym i że wszystko, co w sposób naturalny „porusza się lub wydziela”, może zostać uwarunkowane.


Podstawowy paradygmat warunkowania sprawczego


Warunkowanie sprawcze jest procesem, za pomocą którego można modyfikować zachowanie lub - mówiąc bardziej ściśle - za pomocą którego reguluje się tempo wytwarzania reakcji sprawczej przez manipulowanie otoczeniem. Oto proste empiryczne stwierdzenie wyrażające, w jaki sposób to się dzieje:

„Jeśli wytwarzana jest pewna reakcja sprawcza i następuje po niej bodziec wzmacniający, to prawdopodobieństwo ponownego wystąpienia tej reakcji wzrasta”.
                                  
Wystąpienie tych reakcji, które mają korzystne konsekwencje środowiskowe, jest bardziej prawdopodobne, a częstość ich jest większa niż reakcji, które nie mają takich skutków. Jednakże pojęcia wzmocnienia nie wiąże się tu z żadnymi przypuszczalnymi stanami popędowymi ani z „zadowoleniem”. Po prostu |czynnik |wzmacniający definiuje się empirycznie i pragmatycznie jako wszelkie zdarzenie bodźcowe, które zwiększa prawdopodobieństwo wystąpienia danej reakcji. Ta relacja między reakcją a czynnikiem wzmacniającym ma charakter arbitralny, a bodziec określa się jako „czynnik wzmacniający” |dopiero |wtedy, gdy okaże się że wpływa on na tempo reagowania.

Bodziec dyskryminacyjny i kontrola bodźcowa. Ponieważ zachowanie sprawcze nie jest czymś nowym, czego trzeba się nauczyć (dany osobnik już „wie”, jak wydawać dźwięki, poruszać się, naciskać, popychać, dziobać itd.), a więc przedmiotem uczenia się jest to, |kiedy wykonać reakcję, po której nastąpią wzmacniające konsekwencje. Spośród wszystkich dostępnych bodźców w otoczeniu zwierzęta i ludzie uczą się |rozróżniać („dyskryminować”) te szczególne bodźce, które są sygnałami czynników wzmacniających (tzn. są skorelowane z nimi), jakie pojawiają się, gdy zostanie wytworzona reakcja sprawcza. Te sygnały noszą nazwę |bodźców |dyskryminacyjnych (oznaczonych przez Skinnera symbolem S); informują one dany organizm, kiedy po jakimś zachowaniu nastąpi (lub nie nastąpi) nagroda. Bodziec dyskryminacyjny „stwarza warunki” czy „daje sposobność” organizmowi, by wytwarzał on reakcję sprawczą, która jest jednak reakcją dowolną. Bodziec dyskryminacyjny nie wywołuje tej reakcji w takim sensie, w jakim jasne światło wywołuje mrugnięcie powieką, lecz po prostu sygnalizuje: „Jeśli zrobisz to teraz, to możesz otrzymać czynnik wzmacniający”.
Oto rozwinięcie podstawowego paradygmatu warunkowania sprawczego, uwzględniajace bodziec dyskryminacyjny:
„W obecności bodźca dyskryminacyjnego po reakcji sprawczej następuje 
bodziec wzmacniający”

Ściemnianie świateł w sali widowiskowej jest S sygnalizującym, aby zająć swoje miejsca, przestać mówić i oczekiwać na (miejmy nadzieję wzmacniający) rozwój wydarzeń. Wielu profesorów prowadzących wykłady wobec dużego audytorium ma trudności z rozpoczęciem swego występu, ponieważ nie stosują oni wyraźnego, stałego bodźca dyskryminacyjnego, który mógłby być łatwo rozpoznany - takiego jak podejście do katedry i natychmiastowe rozpoczęcie wykładu. Problem, jaki wielu studentów czy uczniów napotyka na swych pierwszych randkach polega na tym, że jest im trudno nauczyć się „odczytywać” bodźce dyskryminacyjne, dostarczane przez ich sympatię - mianowicie muszą się nauczyć, |kiedy jest właściwy moment, by zrobić to, co już wiedzą, jak się robi i otrzymać czynnik wzmacniający, który (jak się spodziewają) będzie tego konsekwencją. Dwa praktyczne zastosowania zasad warunkowania sprawczego przy użyciu bodźców dyskryminacyjnych opisano w „Zbliżeniu” poniżej.


Zbliżenie
Od wyszukiwania i dziobania do kierowania i niszczenia


„Warunkowanie sprawcze złożonych różnicowań za pomocą odpowiedniego wzmacniania ma wiele praktycznych zastosowań (niektóre z nich omówimy w następnych rozdziałach); do najbardziej fascynujących należą te, w których główną rolę odegrały gołębie: w jednym wypadku zastępowały one robotników przy taśmie produkcyjnej, na której trzeba znaleźć i wysortować wadliwe kapsułki z lekarstwami; w drugim, podczas II wojny światowej, nauczono je prowadzić pociski rakietowe ku wybranym celom nieprzyjacielskim.
Wadliwe kapsułki, czyli „braki” wynosiły około 10% wszystkich kapsułek na taśmie linii produkcyjnej w przedsiębiorstwie farmaceutycznym. Pracownicy byli zatrudnieni przy monotonnym zajęciu polegającym na wypatrywaniu braków na przesuwającej się bez końca taśmie. Aby uwolnić ich od tej harówki, Verhave (1966) wyszkolił gołębie na inspektorów kontroli jakości. Podczas treningu kapsułki przesuwały się za małym okienkiem na taśmie w tempie mniej więcej dwóch na sekundę. Gdy pojawił się brak, dziobnięcie krążka dostarczało wzmocnienia; gdy kapsułka była dobra, dziobnięcie innego krążka nie dostarczało wprawdzie pokarmu, lecz powodowało pojawienie się następnej kapsułki. Niewłaściwe dziobnięcie nie przynosiło pokarmu i powodowało 30-sekundowe „zaciemnienie”.


Po tygodniu codziennego treningu dyskryminacyjnego, ptaki nauczyły się kontrolować jakość kapsułek z 99% dokładnością (i wykonywałyby tę pracę, gdyby nie interwencja związku zawodowego).
Podczas II wojny światowej B. F. Skinner doszedł do wniosku, że jeśli gołębie potrafią się nauczyć ciągłego zmieniania swych reakcji stosownie do wymagań zmieniającej się nieustannie sytuacji bodźcowej, to można by je umieszczać w głowicach pocisków rakietowych, aby kierowały nimi, wyszukując i niszcząc wybrane cele. Możliwość tego pomysłu Skinner zademonstrował w ramach projektu „Orcon” (Organic Control - „sterowanie przez organizm”).  Podczas treningu dyskryminacyjnego wzmocnienie uzależniono od dziobania jedynie w środek celu (w postaci okrętu nieprzyjacielskiego), który pojawił się na ekranie. Gdy złota elektroda umieszczona na dziobie gołębia dotknęła ekranu, wówczas obwód elektroniczny dokładnie lokalizował na nim miejsce tego dziobnięcia. Pocisk utrzymywał swój kurs, gdy gołąb dziobnął w środek ekranu, natomiast dziobnięcie w każde inne miejsce powodowało odpowiednią zmianę kierunku lotu. Zdjęcia (ryc. 3.10) przedstawiają widoczny na ekranie, coraz bliższy cel, który ma być zniszczony przez ptaka-patriotę” (Skinner, 1960).

Badaczowi przeprowadzającemu warunkowanie sprawcze chodzi o podanie reakcji pod kontrolę bodźców środowiskowych, którymi można manipulować.  Kontrolując bodziec wzmacniający, może on regulować tempo reakcji lub prawdopodobieństwo jej wystąpienia.

Kontrolując pojawienie się bodźca dyskryminacyjnego, decyduje, kiedy zostanie wykonana dana reakcja. Mówi się, że organizm jest „pod kontrolą bodźca”, gdy reaguje stale w obecności bodźca dyskryminacyjnego, a nie reaguje pod jego nieobecność.
Czujność, jaką przejawia organizm wobec bodźca dyskryminacyjnego, można wykorzystać także do tego, by wyuczyć go rozróżniania bodźców, nawet dość podobnych. Technika ta polega na podawaniu wzmocnienia, gdy reakcje są wykonywane w obecności jednego bodźca, i nie dawaniu wzmocnienia, gdy są one wykonywane w obecności drugiego bodźca. Wówczas pierwszy bodziec staje się |pozytywnym |bodźcem |dyskryminacyjnym (S), a drugi - negatywnym bodźcem dyskryminacyjnym (S lub S, czyta się „es delta”). Po wielokrotnym treningu dyskryminacyjnym, reakcja niemal zawsze występuje wyłącznie w obecności S (zob. „Zbliżenie” poniżej). Psychologowie często posługują się tą techniką, aby ustalić, czy dany osobnik rzeczywiście potrafi odróżnić określone bodźce - na przykład barwę niebieską od zielonej lub linie poziome od pionowych.


Zbliżenie
Błądzić jest rzeczą ludzką, lecz...


„Terrace (1963) opracował technikę treningu dyskryminacyjnego, podczas którego badani nigdy nie robią błędów, nawet w początkowych jego stadiach.  Wytwarzał on mianowicie u gołębi umiejętność różnicowania między czerwienią a zielenią (czego łatwo się uczyły), a następnie nakładał poziome linie na czerwień a pionowe na zieleń (lub odwrotnie). Stopniowo zmniejszano nasycenie barw czerwonej i zielonej, aż wreszcie pozostały jedynie poziome i pionowe linie; w ten sposób gołębie potrafiły nauczyć się różnicowania między poziomymi i pionowymi liniami nie popełniając żadnych błędów.
Odkrycie Terrace’a jest ważne z dwóch powodów: a) umiejętność nabyta w ten sposób - bez popełniania błędów - jest bardziej trwała, a ponadto, co jeszcze ważniejsze, b) technika taka pozwala na wyuczenie różnicowań, które poprzednio uważano za niemożliwe. Na przykład osoby upośledzone umysłowo nauczono takich różnicowań percepcyjnych, które poprzednio zdawały się wykraczać poza ich możliwości (Sildman i Stoddard, 1969).

Warunkowe czynniki wzmacniającego. Każdy bodziec dyskryminacyjny, który regularnie sygnalizuje sposobność do wykonywania wzmacnianej reakcji, może z czasem sam uzyskać zdolność wzmacniania - to znaczy zwiększa częstość reakcji, która po nim następuje. Bodziec taki nazywa się wówczas |warunkowym |czynnikiem |wzmacniającym (conditioned reinforcer) lub |wtórnym |czynnikiem |wzmacniającym (secondary reinforcer). Jeśli więc dziecko po, zbliżeniu się do kogoś uśmiechniętego wielokrotnie otrzymywało smaczny poczęstunek, to uśmiech staje się warunkowym czynnikiem wzmacniającym dla reakcji zbliżenia, nawet pod nieobecność poczęstunku. W rzeczywistości, w bogatych, rozwiniętych technologicznie krajach takie warunkowe wzmocnienia odgrywają znacznie ważniejszą rolę w kierowaniu zachowaniem niż pierwotne czynniki wzmacniające, które mają konsekwencje biologiczne. Wystarczy wziąć pod uwagę liczne reakcje, jakie wytwarzasz, aby uzyskać prostokątny kawałek zielonego papieru z wizerunkiem prezydenta Stanów Zjednoczonych.
Uśmiechy, potakiwania, klepanie po plecach i pieniądze - wszystko to należy do kategorii |zgeneralizowanych |warunkowych |czynników |wzmacniających, za pomocą których można kierować bardzo różnorodnymi reakcjami. Takie czynniki wzmacniające odgrywają zasadniczą rolę w interakcji społecznej ludzi i zapełniają lukę między zachowaniem a ostatecznym wzmocnieniem pierwotnego tego zachowania. W niektórych wypadkach ludzie traktują warunkowe czynniki wzmacniające tak, jakby miały one znaczenie biologiczne, zaczynają cenić je dla nich samych i gromadzą je. Czy znasz takich ludzi?
Chociaż wpływ warunkowych czynników wzmacniających na uczenie się jest bardziej zmienny niż czynników pierwotnych, często nauczyciel lub eksperymentator mogą się nimi posługiwać w sposób skuteczniejszy, ponieważ: a) można je szybciej rozdzielać, b) można je mieć zawsze pod ręką, c) prawie każde dostępne zdarzenie bodźcowe może być użyte jako warunkowy czynnik wzmacniający, d) często nie prowadzą one do nasycenia, e) ich wzmacniające oddziaływanie może być szybsze, gdyż zależy tylko od percepcji, a nie od przetworzenia biologicznego, jak w przypadku pierwotnych czynników wzmacniających. W rozdziale 12 przekonamy się, że wzmacnianie zachowania za pomocą żetonów, które potem można wymieniać na różne konkretne nagrody, stosuje się obecnie na dużą skalę w programach mających na celu modyfikację zachowania ludzi.


Zależności między reakcją a czynnikiem wzmacniającym. W czasie, gdy wykonujesz jakąś reakcję, w otoczeniu zachodzi wiele różnych zdarzeń. W istocie, otoczenie zmienia się stale nawet wtedy, gdy nie |reagujesz. W jaki więc sposób orientujesz się, na które zdarzenia wpływa twoje zachowanie? Przyjmuje się powszechnie, że możesz powiedzieć, iż pewne zdarzenie w otoczeniu jest |zależne (contingent) od twojego zachowania, jeśli następuje po tym zachowaniu z pewnym stopniem regularności (z wysokim, lecz niekoniecznie stuprocentowym prawdopodobieństwem).
Idea |zależności |behawioralnej (behavioral contingency) jest zapewne najważniejszym pojęciem warunkowania sprawczego. Ustanawiając różne zależności - różne związki między reakcjami i czynnikami wzmacniającymi - osoby stosujące metodę warunkowania sprawczego mogą uczynić daną reakcję bardziej lub mniej prawdopodobną. Dokonują tego zmieniając rozkład w czasie i częstość zdarzeń znanych jako czynniki wzmacniające, powodując ich wystąpienie po pożądanej reakcji, a niewystępowanie w innym momencie. Gdy czynnik wzmacniający jest uzależniony od pożądanej reakcji (tzn. dostępny jedynie po jej wykonaniu), to wystąpienie tej reakcji staje się bardziej prawdopodobne.
Badacze zajmujący się warunkowaniem sprawczym zakładają, że każda reakcja, która nie przestaje występować, jest podtrzymywana przez pewnego rodzaju zysk, czyli wypłatę (payoff). Osiągnięcie tej wypłaty jest uzależnione od wykonania danej reakcji, toteż jest ona wykonywana - chociaż obserwatorowi może wydać się niepożądana, irracjonalna lub dziwaczna i chociaż nawet przynosi inne konsekwencje, które powodują cierpienie danego osobnika. Aby zrozumieć tę reakcję trzeba wykryć, na czym polega wypłata.  Badacze warunkowania sprawczego nazywają to |eksperymentalną |analizą |zachowania.
Aby zmienić zachowanie, trzeba ustanowić nowe relacje wypłat, uzależniając wypłatę od zachowania pożądanego i zapobiegając osiągnięciu jej w wyniku zachowania niepożądanego, które zamierza się wyeliminować. Na przykłąd uczy się rodziców, żeby nie zwracali uwagi na płaczące dziecko i nie ustępowali mu (gdyż w ten sposób wzmacniają i podtrzymują reagowanie płaczem), lecz aby wzmacniali zachowanie niepożądane i to tylko wtedy, gdy dziecko nie płacze.
W dalszych rozdziałach omówimy dokładniej różne zastosowania tych technik. Na razie trzeba podkreślić, że w podejściu tym, inaczej niż w wielu innych w psychologii, za przyczynę wszelkich uwarunkowanych zachowań przyjmuje się określone zależności środowiskowe, a nie zjawiska psychiczne, cechy osobowości czy inne stany wewnętrzne.
Istnieje więc pięć możliwych rodzajów zależności między reakcjami a czynnikami wzmacniającymi - trzy rodzaje zależności zwiększających częstość reakcji sprawczej i dwa rodzaje zależności zmniejszających jej częstość.  Częstość reakcji |wzrasta, gdy następuje po niej 1) pozytywny bodziec wzmacniający, 2) ucieczka od bodźca awersyjnego lub 3) uniknięcie bodźca awersyjnego. Częstość reakcji |zmniejsza |się, gdy następuje po niej 4) bodziec awersyjny (kara) lub 5) brak jakiegokolwiek czynnika wzmacniającego (wygaszanie). Pięć wymienionych tu rodzajów zależności przedstawiono w zamieszczonej obok tabeli.

Zależności magiczne. Najbardziej chyba fascynujące powiązanie między reakcjami a następującymi po nich bodźcami zachodzi wtedy, gdy w istocie nie ma między nimi |żadnego |związku, lecz dana osoba sądzi, że związek taki istnieje. Któregoś dnia pewien tenisista, przebierając się przed meczem, włożył najpierw lewą skarpetkę, potem prawą skarpetkę, prawy pantofel, wreszcie lewy pantofel. Mecz ten wygrał. Następnym razem wkładał skarpetki i pantofle w innej kolejności, po czym przegrał spotkanie.

Już po jednej takiej „próbie” niektórzy ludzie (a wśród nich przynajmniej jeden sławny niegdyś mistrz tenisowy) dochodzą do przekonania, że wynik meczu zależy od nakładania skarpetek i pantofli w określonej, nienaruszalnej kolejności.
Rozpatrzymy inny przykład uczenia się tego rodzaju. Pewien człowiek, który nazywa siebie Orfeuszem, mówi ci, że posiada moc, dzięki której śpiewając do Słońca powoduje jego wschód. Będąc z naukowych względów sceptykiem, wymagasz zademonstrowania tej kontroli nad środowiskiem.  Orfeusz zaczyna śpiewać około piątej nad ranem i wkrótce Słońce wschodzi.  Może on powtarzać co dzień tę demonstrację, wykazując, że po jego reakcji zawsze następuje ta zmiana w otoczeniu. Teraz proponujesz więc inny test: niech nie śpiewa i przekona się, czy Słońce jednak nie wzejdzie. Orfeusz musi jednakże odrzucić taki test. Konsekwencją niezaśpiewania byłoby z pewnością niewzejście Słońca, a ze względu na dobro Świata nie ośmieli się zaryzykować tak strasznych następstw.
Przykład ten można uważać za przypadkowe wzmocnienie sprawcze pozornego, wynikłego ze |zbiegu |okoliczności związku między zachowaniem a czynnikami wzmacniającymi. Rytuały, jakie stosują hazardziści, aby „pozbyć się pecha”, świadczą o ich wyuczonym przekonaniu, że coś, co robią, może spowodować, by kostki lub karty układały się w pewien określony sposób. Takie przypadkowe uwarunkowane reakcje nazywa się |przesądami.
Gdy konsekwencje środowiskowe mają bardzo doniosłe znaczenie dla jednostki lub grupy, reakcja przesądna jest niezwykle odporna na wygaszanie. Wynika to z dwóch powodów. Po pierwsze, jak w wypadku Orfeusza, ryzyko towarzyszące niewykonaniu reakcji, |gdyby związek ten |miał charakter przyczynowy, byłoby większe niż korzyść z ustalenia, że dane zachowanie nie pociąga za sobą takich skutków.

Po drugie, jeśli dana osoba wierzy w prawdziwość przesądu, powstrzymanie się od „nieodzownej” czynności mogłoby wywołać inne zmiany w jego czy jej zachowaniu, które |wpłynęłyby bezpośrednio na bieg zdarzeń. Często obserwuje się to wśród studentów - niejeden ma specjalne pióro lub dżinsy, które bierze zawsze, gdy ma zdawać egzamin. Jeśli pióro zginie lub zdenerwowani rodzice wyrzucą brudne dżinsy, student taki może istotnie oblać egzamin, gdyż oczekuje niepowodzenia, a dręczące myśli o tym, że „stracił szczęście”, nie pozwalają mu się skupić.
Tworzenie się takich przesądów łatwo można zademonstrować w laboratorium psychologicznym. Głodnego gołębia zamyka się w skrzynce zaopatrzonej w mechanizm, który automatycznie podaje kulkę pokarmu co 15 sekund, bez względu na to, co robi gołąb. Jakakolwiek reakcja, którą przypadkowo wykonuje gołąb w czasie podawania pokarmu, zostaje wzmocniona i prawdopodobieństwo jej wystąpienia wzrasta.
U różnych osobników mogą się wytworzyć różne stereotypowe wzorce zachowania - obracania się w kierunku przeciwnym do ruchu wskazówek zegara, okręcanie się w koło kilka razy przed podejściem do karmnika, „podrzucanie” głową w jednym kierunku i inne „dziwaczne” ruchy.


Karać trzeba reakcję, nie osobę


Jest napisane w Biblii: „Kto żałuje swojej rózgi, nienawidzi swojego syna”*(*Tłumaczenie Komisji Przekładu, Warszawa 1979)) („Przypowieści „Salomona 13:24). Zaś dobrze znane chińskie przysłowie poucza: „Bij swoje dziecko codziennie. Jeśli ty nie wiesz za co, ono wie”. Wielu uważa więc, że kara „kształtuje charakter”, „uczy odróżniać dobro od zła” i nie pozwala, by dziecko stało się nieopanowanym, upartym, zepsutym tyranem.  Wysuwa się argument, że dzieci trzeba karać dla ich własnego dobra.
Również wśród psychologów są zwolennicy kary jako środka kierowania zmianami zachowania: „Z żadnych danych nie wynika, że którakolwiek z tych procedur (wygaszanie, nasycenie, zmiana bodźca, ograniczenie fizyczne i niezgodność reakcji), daje efekty tak natychmiastowe, trwałe i w ogóle skuteczne, jak te, które przynosi właściwe zastosowanie techniki karania” (Johnson, 1972, s. 1051).
Podnoszą się jednakże głosy sprzeciwiające się stosowaniu kar do rozwiązywania spraw ludzkich. „Każda kara jest krzywdą. Każda kara sama jest złem”, powiedział angielski filozof Jeremy Bentham. Francuski myśliciel Montaigne napisał: „Nie zaobserwowałem nigdy innych skutków chłosty niż te, że czyni ona chłopców tchórzliwymi lub zuchwale upartymi”.  Amerykański pisarz Eric Hoffer wskazał, że kara ma nagradzające „skutki uboczne” dla osoby karzącej a nie karanej: „Nasze poczucie władzy jest żywsze wtedy, gdy łamiemy ducha w człowieku niż wtedy, gdy zdobywamy jego serce”. Czarni psychologowie Grier i Cobbs, utrzymują, że „bicie jako sposób wychowania dzieci, ma swe psychologiczne korzenie w niewolnictwie”.  Inni psychologowie podają, że kara jest stosunkowo nieskutecznym środkiem sterowania zachowaniem, ponieważ rodzi bunt i pociąga za sobą konieczność nadzorowania, a także stwierdzają, że jest ona przyznaniem się do niepowodzenia w stosowaniu technik wzmacniania pozytywnego (Baer, 1970; 
Solomon, 1964).
Zapewne można częściowo rozwiązać ten gorący spór, powołując się na rozróżnienie semantyczne, na które kładą nacisk badacze pracujący w dziedzinie modyfikacji zachowania:

„|Reakcje wzmacnia się, |ludzi się nagradza”.

Rozszerzając to rozróżnienie na efektywne i humanitarne posługiwanie się karami, dodalibyśmy:

„Niepożądane |reakcje można karać; |ludzi karać się nie powinno”.

Wynika stąd bezpośrednio, że byłoby dobrze, gdyby wszyscy - zarówno my sami, jak i wszyscy wymierzający kary - pamiętali iż:

„Chociaż |reakcje mogą być niepożądane, to u |ludzi nigdy nie powinno się wytwarzać poczucia, że to |oni są niepożądani”.

Czy kara skutkuje? Jak wiemy, bodziec nazywa się |pozytywnym |czynnikiem |wzmacniającym, jeśli jest podawany jako konsekwencja pewnej reakcji i zwiększa prawdopodobieństwo wystąpienia tej reakcji. Nazywa się go |negatywnym |czynnikiem |wzmacniającym, jeśli uniknięcie tego bodźca lub ucieczka od niego zwiększa prawdopodobieństwo tej reakcji. Bodziec, który podaje się jako konsekwencję niepożądanej reakcji, aby |zmniejszyć prawdopodobieństwo tej reakcji, nazywa się |karą. Z tego punktu widzenia zasady karania są podobne do zasad wzmacniania pozytywnego, z tym wyjątkiem, że kara |zmniejsza przewidywane prawdopodobieństwo reakcji, podczas gdy pozytywne wzmocnienie |zwiększa je.
Bodźce karzące są normalną częścią naszego środowiska fizycznego. Gdy w ciemnym pokoju uderzymy nogą w krzesło, zaboli nas. Kiedy jednak takie bodźce powinno się stosować w sytuacjach społecznych? Czy w ogóle powinno się je stosować?
Podstawowe cele nawet najbardziej życzliwych rodziców, nauczycieli i innych osób kierujących zachowaniem są następujące: |zapoczątkować pewne zachowania, |utrzymać inne i |zapobiec występowaniu jeszcze innych (zwłaszcza w pewnych miejscach i okolicznościach). Pozytywne wzmacnianie jest bezspornie najskuteczniejszą techniką realizowania dwóch pierwszych celów, zapoczątkowania i utrzymywania pożądanego zachowania - aby coś, co się zdarza rzadko, zdarzało się częściej lub żeby trwało nadal zachowanie, które ci się podoba. Kiedy jednak próbujesz powstrzymać kogoś od wykonania jakiejś utrwalonej czynności, która jest z pewnych względów niepożądana, samo pozytywne wzmacnianie może nie wystarczyć. W takich wypadkach kara, stosowana według podanych niżej zasad, może być skuteczną techniką oddziaływania, lecz wtedy i tylko wtedy, jeśli ogólny kontakt („atmosfera”) jest pozytywny. W przeciwnym razie możesz wygrać bitwę, lecz przegrać wojnę.

1. |Reakcje |alternatywne. W danej sytuacji zawsze powinna być jakaś reakcja, którą jednostka może wykonać i która nie spowoduje wymierzenia karzącego bodźca, lecz zostanie pozytywnie wzmocniona.
2. |Specyficzność |reakcji |i |sytuacji. Powinno się wyraźnie określić, jaka specyficzna reakcja jest karana, dlaczego oraz jakie inne reakcje są możliwe. Ponadto należy sprawić, aby osoba, której reakcje są karane, uświadomiła sobie, że interakcja z osobą karzącą ma przykry charakter tylko w sytuacji, w której występuje karana reakcja.
3. |Synchronizacja. Kara powinna następować bezpośrednio po reakcji, przy każdym jej wystąpieniu.
4. |Ucieczka. Nie powinno być żadnych niedozwolonych sposobów ucieczki przed karą, możliwości jej uniknięcia czy odwrócenia uwagi osoby karzącej.
5. |Intensywność |karzącego |bodźca. Bodziec karzący powinien być silny, na najwyższym rozsądnym poziomie.
6. |Czas |trwania. Należy unikać długotrwałej kary.
7. |Warunkowe |bodźce |karzące. Aby nie krzywdząc danej jednostki jednocześnie zredukować częstość pewnych jej reakcji, można stosować neutralny bodziec, regularnie łączony z przykrym bodźcem karzącym.
8. |Przejawy |współczucia, |miłości itp. Osoby karzące nie powinny dostarczać pozytywnego wzmocnienia w związku z karą. Jeśli postępują w ten sposób, może to wystarczyć do podtrzymania (stać się powodem wytwarzania) reakcji, którą zamierzano ukarać. Kara powinna być początkiem okresu wygaszania karanej reakcji, okresu, w którym nie otrzymuje ona żadnego pozytywnego wzmocnienia.
9. |Okresy „|wykluczenia”. Takie same efekty jak kara daje także zastosowanie „okresów wykluczenia”, w których odmawia się pożądanego pozytywnego wzmocnienia z powodu niepożądanych reakcji (nie będziesz oglądać dziś telewizji, ponieważ wczoraj nie odrobiłeś lekcji).
10. |Motywacja. Należy osłabić motywację do wykonywania karanej reakcji.
11. |Generalizacja |z |czynności |na |dyspozycję. W żadnych okolicznościach karzący nie powinien na podstawie karanej reakcji dokonywać uogólnień dotyczących cech charakteru danej osoby („Jesteś niedobry”, „głupi”, „niepoprawny”). Te wnioski co do cech osobowościowych pozostają w świadomości tej osoby, chociaż karana reakcja dawno już została wygaszona, a kara zapomniana. (Lista zaadaptowana z następujących publikacji: Parke i Walters, 1967; Azrin i Holtz, 1966).


Kiedy kara przynosi więcej szkody niż pożytku? Chociaż istnieje spory materiał dowodowy świadczący o skuteczności rozsądnego, kontrolowanego stosowania kary jako jednej z metod w takim programie kierowania zachowaniem, który kładzie główny nacisk na wzmocnienie pozytywne, to jednak kara zwykle przynosi więcej szkody niż pożytku. Wynika to stąd, że w życiu codziennym nauczyciele, rodzice, policja, personel w domach dziecka, przyjaciele, małżonkowie, zwierzchnicy i inne osoby rzadko stosują kary zgodnie z podanymi wyżej zasadami (które sformułowano na podstawie kontrolowanych badań). Przeciwnie, kary są stosowane bez zastanowienia i zwykle pod wpływem takich motywów osoby karzącej, które mają niewiele wspólnego z zadaniem polegającym na zmniejszeniu prawdopodobieństwa wystąpienia specyficznej karanej reakcji.
Rozpatrzmy teraz niektóre przyczyny, powodujące, że kara w życiu codziennym może wywoływać reakcje bardziej niepożądane od tych, które redukuje:
1. Kara często wzbudza w karzącym i karanym silne reakcje emocjonalne, które generalizują się na sytuacje inne niż sytuacja kary (karzący może czerpać przyjemność z karania; karany może nauczyć się obawiać karzącego, odczuwać do innego urazę, nienawidzić go, a jego samoocena może ulec obniżeniu).
2. Często trudno jest stosować karzący bodziec niezwłocznie i konsekwentnie.
3. Osoba karząca zbyt łatwo może nie docenić surowości czy intensywności kary i z tego powodu może ona wyrządzić krzywdę karanemu.




Zbliżenie
„Jest tylko jeden sposób, aby nauczyć tych małych brzdąców...”


„Do synka swego mów surowo I bij go, jeśli kicha, Chce tylko dręczyć, daję słowo, Więc niech nie budzi licha” (Przekład Macieja Słomczyńskiego, Warszawa 1972))
Lewis Carroll „Allice’s Adventures in Wonderland”, 1865 (wyd. pol. 
„Przygody Alicji w Krainie Czarów”).

„W wielu wypadkach karanie dzieci przybiera skrajne formy, takie, że dzieci są poważnie maltretowane - krzywdzone fizycznie i psychicznie. W istocie tysiące z nich jest zabijanych co roku - rękoma swoich rodziców.
„Syndrom bitego dziecka” analizujemy w Rozdziale 14, lecz tu warto rozpatrzyć pokrótce wyniki szeregu wywiadów z matkami maltretowanych dzieci i matkami z grupy porównawczej, których dzieci nie były maltretowane.  |Maltretowanie w tym badaniu zdefiniowano jako „liczne pęknięcia kości spowodowane pobiciem przez rodziców” (Elmer, 1971).
W rodzinach, w których było maltretowane dziecko, dyscyplinę osiągano różnymi fizycznymi środkami kontroli, włącznie z biciem, łajaniem, zawstydzaniem, potrząsaniem i deprywacją. Przekonywanie lub unikanie konfliktów występowało rzadko. „Rodzice ci skłonni byli uważać, że nawet niemowlęta wymagają dyscypliny; rozmyślnie zachowują się niewłaściwie”.  Wiele z tych matek było przekonanych, że nawet bardzo małe, 6-9 miesięczne dzieci mają „humory”, robią na złość, odróżniają dobro od zła i rozmyślnie robią „złe rzeczy”. Gdy zapytano je, jakby zareagowały, gdyby ich dziecko (6-miesięczne lub starsze) uderzyło je lub opluło, przeważająca większość odpowiedziała, że ukarałyby je fizycznie, „żeby pokazać mu, że |nie |wolno mu robić takich rzeczy”.
„Matki objęte tym badaniem zwykle bardzo słabo odróżniały dyscyplinę od nauczania. Gdy zapytano je, w jaki sposób próbowałyby nauczyć dziecko jakiegoś nowego zachowania, gdyby wymagało to od niego dużego wysiłku, najczęściej odpowiadały, że po udzieleniu słownych wskazówek łajałyby je lub dawały mu klapsy, żeby nakłonić je do uczenia się. Zdaniem badaczy niemowlęta są karane fizycznie częściej niż się sądzi. Skoro powszechnie praktykuje się bicie niemowląt, chociaż lekko, w celu nauczenia ich różnych rzeczy, to prawa prawdopodobieństwa wskazują, że niektóre niemowlęta są bite zbyt mocno, a niektórym dzieje się krzywda”.
Wielu rodziców nie maltretowanych dzieci również jednak karało je fizycznie - różnica polegała na surowości i częstości wymierzania kary.  Osiemdziesiąt siedem procent wszystkich badanych matek dawało klapsy swym dzieciom lub biło je po rękach, zanim skończyły one dwa lata.
Stwierdzono interesujące różnice związane z klasą społeczną i płcią.  Zgodnie z wypowiedziami matek, matki z wyższej klasy społecznej skłonne były bardziej karać za akty agresywne, matki z klasy średniej - za „wybryki”, czynności denerwujące lub niebezpieczne, a matki z klasy niższej za „niewłaściwe zachowanie”, takie jak nadmierne wymagania, nieposłuszeństwo lub płacz. We wszystkich klasach społecznych więcej dziewczynek niż chłopców było karanych w pierwszych latach życia; w wieku 9 miesięcy karanych było 31% dziewcząt, lecz tylko 5% chłopców. W wieku 18 miesięcy było 70% dziewcząt i 50% chłopców”.


4. Karanie staje się główną sytuacją, w której karany uczy się (na konkretnym przykładzie) co oznacza „władza” (social power). Osoba karząca, ze względu na wiek, płeć, siłę fizyczną lub posiadanie pełnomocnictwa, jest spostrzegana jako ktoś mający prawo ustalać, jakie zachowanie jest „pożądane”, a jakie nie, oraz jako ktoś mający prawo podejmować przeciw bezsilnej jednostce akceptowane przez społeczeństwo działania. Ci, którzy są karani, uczą się stosować do tego modelu, również posługując się metodą kary, w celu sterowania zachowaniem innych.
5. Kara stosowana tak, jak się to zwykle czyni, tylko tłumi i hamuje daną reakcję w czasie, gdy sprawowany jest nadzór. Prowadzi to do przyjęcia dwóch „bliźniaczych” przekonań: że nadzór jest konieczny dla zapewnienia właściwego zachowania i że karane jednostki nie są zdolne nauczyć się kierować swoim własnym zachowaniem.
6. Kara często bywa stosowana w sytuacjach społecznych, w których poza karzącym i jednostką karaną obecne są jeszcze inne osoby. Ich obecność może zwiększać odczuwane przez tę jednostkę upokorzenie; może nawet powiększyć karę. Obecność innych osób może także wpływać na zachowanie karzącego. Na przykład karzący może dbać o swój obraz w ich oczach i zastosować karę, ponieważ wszelka pożądana zmiana, jaka nastąpi, będzie wówczas „zapisana na jego korzyść”, a nie na korzyść osoby ukaranej. Karzący może też reagować zbyt silnie, wykorzystując taką okazję jako nauczkę dla grupy.

„W pewnym badaniu, którego tematem było spontaniczne stosowanie kar przez nauczycieli, przez pięć miesięcy obserwowano po dwoje dzieci z każdej z pięciu klas. Dzieci te często zachowywały się w taki sposób, że zakłócały tok lekcji w klasie, za co nauczyciele ganili je publicznie. Prawie wszystkie nagany były głośne, słyszane przez większość klasy. Nagany te nie były szczególnie skutecznym środkiem zmniejszającym częstości zachowań zakłócających.
W II fazie tych badań poproszono nauczycieli by stosowali nagany „łagodne”, słyszalne jedynie dla ganionego dziecka. Prawie we wszystkich wypadkach częstość zachowań zakłócających zmniejszyła się, gdy nauczyciele stosowali łagodne nagany.
W III fazie przywrócono głośne nagany, czemu towarzyszył wzrost częstotliwości zachowań zakłócających. W fazie IV, aby zademonstrować przekonywująco nieskuteczność głośnego, publicznego ganienia i skuteczność łagodnych, osobistych napomnień, nauczyciele znów stosowali ten drugi rodzaj bodźców. 

I znów częstość zachowań zakłócających zmniejszyła się w niemal wszystkich wypadkach, w których nauczyciel uczynił karzący bodziec nie publicznym ogłoszeniem adresowanym do kolegów ucznia, lecz łagodnym, osobistym napomnieniem skierowanym tylko do niego” (O’Leary i in. 1970).

Pojawił się nowy kierunek badań, w którym przedmiotem zainteresowania jest nie karany, a karzący. Prowadzi się prace zmierzające do określenia tych szczególnych zmiennych - społecznych kulturowych i środowiskowych - które wpływają na to, czy osoba postawiona przed zadaniem wymagającym kierowania innymi ludźmi posłuży się karami, wzmacnianiem pozytywnym, czy też przekształceniem otoczenia (Banks, 1973; Banks, Zimbardo i Philips, 1974).


Skrzynka Skindera i zapis kumulatywny



Do badania warunków bodźcowych, które modyfikują tempo reagowania sprawczego, opracowano specjalny aparat: elektroniczne urządzenie programujące oraz odpowiedni sposób rejestrowania zmian częstości reakcji.
Aparat (zwany potocznie skrzynką Skinnera) jest wysoce uproszczony, ograniczony środowiskiem, w którym różne bodźce dyskryminacyjne, będące przedmiotem badań, można prezentować wyraźnie, bez zakłóceń ze strony bodźców rozpraszających uwagę, rywalizujących lub nieistotnych, które działałyby w naturalnym środowisku organizmu.Typowymi bodźcami dyskryminacyjnymi (S) dla gołębi (które zwykle są używane do tych badań) są światła, barwy lub kształty eksponowane na oświetlonych krążkach.  Prawdopodobieństwo wykonania reakcji sprawczej - dziobania krążka lub naciskania dźwigni jest większe dzięki temu, że przedmioty te uczyniono jedynymi elementami środowiska fizycznego, którymi „badany” może łatwo manipulować czy operować.

* * *
Ryc. 3.12. W skrzynce Skinnera przeznaczonej dla gołębi kulkę pokarmu dostarcza się (przez otwór u dołu), gdy ptak dziobie przycisk. Szczur uzyskuje pokarm naciskając dźwignię. Podłoga w postaci kraty w skrzynce może być naelektryzowana dla dostarczenia awersyjnej stymulacji.
* * *

Miska na pokarm lub wodę oraz lampka sygnalizująca, kiedy czynnik wzmacniający jest dostępny, uzupełniają wyposażenie skrzynki Skinnera.
Elektroniczne urządzenie programujące jest niezbędne dla precyzyjnego sterowania ekspozycją bodźców, kontrolowania reakcji i uruchamiania mechanizmu dostarczającego wzmocnienia. Może ono także realizować złożone programy wzmacniania.
Tempo reagowania dogodnie jest mierzyć za pomocą zapisu kumulatywnego.  Polega on na tym, że zapisywana jest każda występująca reakcja, przy czym reakcje są sumowane w każdym przedziale czasowym. Pisak dotyka papieru i albo pisak, albo papier (zwykle ten ostatni) przesuwa się ze stałą prędkością - tyle a tyle cali w jednostce czasu. W trakcie tego przesuwania reakcje są rejestrowane automatycznie: przy każdej reakcji pisak przesuwa się trochę do góry. Im więcej reakcji zostaje wykonanych w danym czasie, tym więcej skoków w górę rejestrującego pisaka nagromadzi się („skumuluje”) na odcinku papieru, który przesunął się w tym czasie pod pisakiem.
Odległość pozioma na takim wykresie pokazuje więc upływ czasu; odległość pionowa - liczbę reakcji. Wysokie tempo reagowania daje stromą krzywą kumulatywną; niskie tempo reagowania daje krzywą mniej stromą.
Na podstawie kształtu (|topografii) krzywej kumulatywnej można także określić, jak tempo reagowania zmieniało się w danym czasie. Na ogół w nowej sytuacji krzywa z początku wznosi się bardzo powoli i nieregularnie, przy czym między reakcjami mogą być długie przerwy; w czasie tych przerw pisak po prostu przesuwa się poziomo po papierze. W miarę jak uczenie się postępuje naprzód, krzywa kumulatywna wykazuje mniejszą zmienność i staje się bardziej stroma. Wprawny badacz potrafi odczytywać krzywą reakcji badanego osobnika, podobnie jak lekarz zdjęcia rentgenowskie, rozpoznając zmiany zachodzące w czasie i ustalając wpływ różnych wzorców wzmocnienia na zachowanie.


Rozkłady wzmacniania


Każde wzmocnienie jest |częścią pewnego planu, czyli |rozkładu (schedule), o charakterze systematycznym lub losowym. Aby zmodyfikować zachowanie, trzeba odkryć, |jaki rozkład wzmocnień steruje w danym czasie zachowaniem jednostki, a następnie - zmienić go.
Przed wielu laty, młody wówczas B. F. Skinner, siedząc samotnie w laboratorium podczas długiego weekendu, dokonał przypadkowo ważnego odkrycia: są mianowicie okoliczności, gdy mniej tego co dobre jest lepsze.

Zdając sobie sprawę, że nie zaopatrzył się w dostateczną ilość kulek pokarmowych dla swych ciężko pracujących zwierząt, postanowił poradzić sobie dając im kulkę jedynie po co drugiej poprawnej reakcji.
Ku swemu zaskoczeniu stwierdził brak jakiejkolwiek różnicy w szybkości uczenia się: |wzmacnianie |częściowe wydawało się równie skuteczne, jak |wzmacnianie ciągłe (kulka pokarmu za każdą poprawną reakcję). Jednakże dopiero wtedy, gdy zwierzęta poddano próbom |wygaszającym, okazało się, że jest to prawdziwe odkrycie. |Nabywanie |reakcji |w |warunkach |wzmacniania częściowego |uczyniło |te |reakcje |bardziej |odpornymi |na |wygaszanie!  Zwierzęta ćwiczone przy zastosowaniu wzmocnienia częściowego dłużej wykonywały wyćwiczoną reakcję, gdy przestawano już podawać wzmocnienie. Ten wpływ częściowego wzmacniania jest faktem dowiedzionym. Stwierdzono go wielokrotnie u wielu różnych gatunków zwierząt, a także u ludzi.
Jeśli więc chcesz, aby ktoś nadal wykonywał pewną reakcję, gdy już nie będzie ciebie w pobliżu, aby ją wzmacniać, to lepiej, abyś zaprogramował od początku udzielane przez ciebie wzmocnienia według rozkładu częściowego, nawet gdy jesteś obecny przez cały czas.
Teraz, gdy znamy już zasadę, że wzmacniając reakcję w stosunku innym niż 1:1 można sterować nimi w przewidywalny sposób, możemy zapytać, jak różne |rozkłady |wzmocnienia |sporadycznego (intermittent reinforcement) wpływają na zachowanie.

Rozkłady stosunkowe (ratio schedules). Jak już wiemy, niekiedy za „reakcję” uważa się pewną klasę reakcji jednostkowych, które wszystkie muszą być wykonane przed podaniem wzmocnienia. Jeśli wzmocnienie podaje się za każdym razem po wykonaniu tej samej liczby jednostek pracy, to rozkład taki nosi nazwę |rozkładu |wzmacniania |według |stałych |proporcji (FR - fixed ratio schedule). W laboratorium gołąb musi dziobać przycisk określoną liczbę razy (od 2 do ponad 100) zanim otrzyma pojedynczą kulkę pokarmu. Na przykład „FR-25” to stosowany w laboratorium skrót, który oznacza „jedno wzmocnienie na każde 25 reakcji”. Rozkład wzmacniania według stałych proporcji stosuje się także przy przyznawaniu niektórych nagród czy odznak, na przykład za wzięcie udziału w określonej liczbie imprez sportowych lub rozwiązanie pewnej liczby zadań szachowych. Te rozkłady wzmacniania dają w laboratorium bardzo wysokie tempo reagowania, o czym świadczy zapis kumulatywny przedstawiony na wykresie. Badane zwierzęta uczą się liczyć na takie rozkłady wzmacniania (ryc. 3.14).
Jednakże świat nie zawsze jest urządzony w sposób tak regularny, jak rozkład wzmacniania według stałych proporcji. Niekiedy świat jest loterią - nie możesz przewidzieć, czy jedna reakcja, czy kilka, czy dopiero wielka ich liczba przyniesie ci w końcu wygraną. Dopóki jednak uzyskujesz niekiedy jakieś „wypłaty”, dopóty ten |rozkład |wzmacniania |według |zmiennych |proporcji (VR- variable ratio schedule) będzie utrzymywać wysokie tempo twych reakcji przez długi czas.

Możliwość, że następna reakcja przyniesie dużą wygraną skłania graczy do kontynuowania gry, wzmacnianej według zmiennych proporcji.


Rozkłady interwałowe. Może być i tak, że uzyskanie wzmocnienia zależy nie od tego, |ile pracy wykonujesz, lecz od tego, |kiedy ją wykonujesz. Aby zapewnić sobie uzyskanie należnych nagród, wystarczy nieraz wyglądać na zapracowanego wtedy, gdy SZEF (kierownik zakładu pracy, asystent prowadzący ćwiczenia w laboratorium itp.) dokonuje obchodu. Gdy wzmacnianie oparte jest na zasadzie czasowej, teoretycznie daje się nagrodę jeden raz za wszystkie reakcje wykonane w poprzedzającym okresie. W rzeczywistości jednak wcześniejsze reakcje nie przynoszą żadnego wzmocnienia i mogą nie mieć żadnego wpływu na to, co nastąpi później. Gołąb w skrzynce Skinnera musi wykonać jedynie |ostatnią reakcję, gdyż to ona uruchamia mechanizm podający pokarm.
Jeśli odstęp czasowy (interwał) między wzmocnieniami jest za każdym razem taki sam, na przykład 10 sekund lub nawet miesiąc (jak w wypadku wypłaty pensji), to rozkład taki nosi nazwę |rozkładu |wzmacniania |o |stałych |odstępach |czasowych (FI - fixed interval schedule). Rozkłady o stałych odstępach czasowych dają typowe, choć szczególne krzywe w kształcie schodków. Po każdej wzmocnionej reakcji badany przestaje reagować w sposób „właściwy” i wykonuje reakcje „odpoczynkowe”. Gdy zbliża się czas następnej wypłaty, znów pojawiają się „właściwe” reakcje i częstość ich szybko wzrasta, aż do momentu wystąpienia wzmocnienia. Wygląda to tak, jak gdyby badany uczył się określać czas. W każdym systemie pracy, w którym stosuje się rozkłady wzmocnienia o długich, stałych odstępach czasowych, konieczny jest nadzór, aby powstrzymać pracowników od „obijania się” w okresie następującym pośrednio po wypłacie - syndrom „poniedziałkowego rozprzężenia”.
Jeśli wzmocnienie podaje się według pewnej zasady czasowej, lecz odstępy czasowe zmieniają się, to rozkład taki nosi nazwę |rozkładu |wzmacniania |o |zmiennych |odstępach |czasowych (VI - variable interval schedule). Czasem musisz długo czekać, zanim uzyskasz pierwszą nagrodę; potem drugą i trzecią, lub jeszcze następne, otrzymujesz po krótkim jedynie oczekiwaniu.  Kiedy jednak myślisz „Już wiem, jak podejść do sprawy!” na następną nagrodę znów trzeba czekać dłuższy czas. Wędkarze, którzy również otrzymują wzmocnienie według rozkładu o zmiennych odstępach czasowych, uczą się prawdopodobnie cierpliwości, która staje się „produktem ubocznym” tego rozkładu.
Rozkłady wzmocnienia mogą występować w postaciach mieszanych i mogą być bardzo złożone; opisano tu jedynie najbardziej podstawowe ich odmiany.  Rozkłady wzmacniania można zaplanować tak, aby pozwalały uzyskać wysokie tempo reagowania lub zapewniały ciągłe, stałe reagowanie przez cały czas (ryc. 3.15).

* * *
Ryc. 3.15. Typowe Krzywe Dla Różnych Rozkładów Wzmocnienia. Są to typowe „wyidealizowane” krzywe, które odpowiadają podstawowym rodzajom rozkładu wzmocnienia. Zapisy te mają określony charakter - niezależnie od tego, czy badany jest szczurem, gołębiem czy dzieckiem.  
Rozkłady o stałych zmiennych proporcjach zwykle utrzymują wysokie tempo reagowania, o czym świadczy strome nachylenie krzywych. Rozkłady o stałych lub zmiennych odstępach czasowych zazwyczaj utrzymują umiarkowane tempo reagowania. Rozkład o stałych odstępach czasowych daje zwykle pokazaną tu krzywą „schodkową”, co odzwierciedla fakt, że zwykle badany niemal przestaje reagować po otrzymaniu wzmocnienia i czeka prawie do następnego zaplanowanego wzmocnienia, zanim zacznie znów aktywnie reagować.
Wzmacniając niskie tempo reagowania można także uzyskać niemal płaskie krzywe reagowania, jak ta, którą tu pokazano. (Rysunek zaczerpnięty z „Teachnig machines B. F. Skinnera”. Copyright © 1961 by Scientific American Inc. All rights reserved).

* * 

Niektóre rozkłady nawet tłumią wykonywane reakcje, wzmacniając czekanie i niereagowanie. W istocie, zwierzęta nauczyły się nawet przebiegać labirynt lub uliczkę z taką szybkością, jaka powodowała otrzymanie większej lub szybciej uzyskiwanej nagrody (Logan, 1960, 1972). Istnieją także dane, że ludzie nie tylko uczą się reagować, z określoną szybkością, lecz nawet uczą się |uczyć z takimi szybkościami, które są dodatnio skorelowane z nagrodami.

Opóźnienie wzmocnienia: nie zawsze prawdziwe jest stwierdzenie, że „lepiej późno niż nigdy”. Niezależnie od rozkładu  wzmacniania czynniki wzmacniające trzeba podawać szybko, aby były skuteczne. Im szybciej, tym lepiej; jeśli upłynie zbyt wiele czasu między ostatnią reakcją w sekwencji zachowania a jej wzmocnieniem, to efekt nagrody zostaje całkowicie zaprzepaszczony.
Można by sądzić, że pedagodzy czynią użytek z tej prostej zasady i dbają o to, by dobre osiągnięcia uczniów były szybko wzmacniane; niestety, jak najprawdopodobniej wiecie z własnego doświadczenia, sprawa przedstawia się inaczej. Zbyt często wzmocnienie w klasie szkolnej następuje po upływie zbyt długiego czasu od wykonania pracy, a kiedy wreszcie nastąpi, jest to często jedynie ogólna ocena, a nie szczegółowe informacyjne sprzężenie zwrotne dla poszczególnych reakcji.
W tych sytuacjach nauczania, w których opóźnienie wzmocnienia jest nieuniknione, nauczyciel może jednak wpłynąć na polepszenie osiągnięć ucznia, a to przez:
1. Upewnienie się, iż poprawny sposób wykonania reakcji został określony tak wyraźnie i jednoznacznie, że zarówno nauczyciel, jak i uczeń rozpoznają poprawną reakcję, gdy zostanie wykonana.
2. Wyraźne określenie zasad wzmacniania (nagradzania), tak aby nigdy nie wydawały się one dowolne lub niekonsekwentne; uczniowie powinni wiedzieć, że nagroda jest w przewidywalny sposób uzależniona od określonego zachowania.
3. Stosowanie „przypomnień” werbalnych i innego rodzaju w celu wytworzenia u ucznia symbolicznego powiązania między dawno minioną reakcją a późno pojawiającą się nagrodą.
4. Stosowanie warunkowych czynników wzmacniających, które zastępowałyby tymczasowo pierwotny czynnik wzmacniający.


Nowe reakcje dzięki warunkowaniu sprawczemu


Ponieważ można wzmocnić tylko tę czynność, która została wykonana, mógłbyś sądzić, że badacz stosujący warunkowanie sprawcze nie może w żaden sposób wpłynąć na zachowanie, które jeszcze się nie wydarzyło lub w każdym razie nie zachodzi obecnie. Jest jednak inaczej. Istnieje kilka sposobów, za pomocą których można wywołać pożądaną reakcję, niezależnie od tego, czy jest to reakcja znana, lecz po prostu nie wykonywana, czy też całkowicie nowa reakcja lub sekwencja zachowania, której dana jednostka nigdy przedtem nie wykonywała.

Uzyskanie pierwszej reakcji. Załóżmy, że jesteś pełnym dobrej woli rodzicem, nauczycielem lub trenerem zwierząt i że masz kieszeń pełną „czynników wzmacniających”, które chcesz rozdawać - jeśli tylko dana jednostka wykona poprawną reakcję. Jakie procedury zastosować dla wywołania pierwszej poprawnej reakcji, abyś mógł ją wzmocnić i w ten sposób spowodować częstsze jej występowanie? Jest to problem, którego nigdy nie miał Pawłow, ponieważ badał on reakcje, jakie zawsze można było wytworzyć przez staranną prezentację właściwego bodźca.
Jest to decydujący i podstawowy problem uczenia się, któremu poświęca się o wiele za mało systematycznych badań. Tutaj naszkicujemy jedynie kilka sposobów podejścia i omówimy pokrótce ich możliwą efektywność. Istnieją sposoby nakłonienia danej jednostki do wykonania pierwszej poprawnej reakcji, tak aby można było ją wzmocnić; oto niektóre z nich: a) zwiększanie motywacji, b) zmniejszenie zahamowań, c) strukturalizacja otoczenia, d) zastosowanie przymusu, e) dostarczenie modelu, f) udzielenie wskazówek oraz g) próby i błędy. Każda z tych technik ma pewne zalety i wady, uzależnione też od tego, czy potrzebne są tylko wyniki natychmiastowe, czy też bardziej trwałe, długoterminowe. Ponieważ stosowanie tych technik może mieć niezamierzone ujemne konsekwencje, zwłaszcza na dalszą metę, przeto musimy zachować ostrożność przy rozstrzyganiu, która z nich najlepiej pasuje do danej sytuacji uczenia się.

Zwiększanie motywacji”. Pobudzenie organizmu do reagowania zwiększa prawdopodobieństwo, że jedna z reakcji będzie poprawna. Naelektryzowanie kraty podłogowej skłoni szczura do biegania, dzięki czemu będzie mógł odkryć drogę ucieczki. Konieczność jest tu matką wynalazku. Zagrożenia oraz obietnice przyszłej nagrody (zwane „motywacją związaną z podnietą”) - jak również stany deprywacji lub przykre bodźce - wszystkiego tego można z powodzeniem użyć do motywowania działania.
Jednakże takie czynniki motywujące mogą mieć różne niekorzystne następstwa. Nie zaleca się podnosić poziomu motywacji, jeśli jednostka nie ma danej reakcji w swym repertuarze lub jeśli nie jest w stanie jej wykonać. Na przykład matka, która „przestanie kochać Jasia, jeśli Jaś zabrudzi swoje pieluszku”, nie wpłynie na sposób jego wypróżnień, jeśli dziecko nie ma jeszcze kontroli nad mięśniem zwieracza. Może natomiast wytworzyć u swego dziecka zarówno poczucie niższości, jak i długotrwałą urazę. Procedura ta może również prowadzić do konfliktu i stresu, jeśli działa silny rywalizujący motyw. Wreszcie, jeśli dana jednostka wykonuje jaką reakcję tylko ze względu na |motywację |zewnętrzną, to znaczy aby uniknąć kary lub uzyskać nagrodę (np. dobry stopień lub deser), to jest mniej prawdopodobne, że nauczy się cenić daną czynność (przyswajanie wiedzy lub jedzenie szpinaku) dla jej własnej, wewnętrznej wartości.

„Zmniejszenie zahamowań”. Jeśli dany organizm nabył już umiejętności potrzebne do wykonywania poprawnej reakcji, lecz nie wykonuje jej mimo istnienia odpowiednich warunków motywacyjnych, to jest możliwe, że reakcja ta jest zahamowana lub stłumiona. Wyuczone poprzednio nawyki mogą być niezgodne z wytwarzaniem pożądanej reakcji. Nieśmiały chłopiec, który zna odpowiedź na pytanie nauczyciela, nigdy nie uzyska wzmocnienia, jeśli nie podniesie ręki i nie wypowie się głośno, lecz nie potrafi tego uczynić, gdyż nauczył się, że zabieranie głosu w klasie jest dlań bardzo przykre.  Wielu mężczyzn nie potrafi przejawiać „czułych” reakcji, takich, jak „serdeczność” czy żal, ponieważ nauczyli się nazywać takie reakcje „niemęskimi”. Aby skłonić żołnierzy do zabijania lub studentów medycyny do krajania zwłok, stosuje się techniki osłabiające wyuczone opory przeciw takiemu „antyspołecznemu” zachowaniu. Odkrycie rywalizujących motywów i osłabienie ich lub ustalenie czynników wzmacniających, które podtrzymują zahamowanie, a następnie usunięcie tych czynników, może dopomóc w wywoływaniu „pożądanej” reakcji. Z drugiej jednak strony, to, co hamuje dane zachowania, może także trzymać na uwięzi inne, niepożądane zachowania, których wcale |nie chciałbyś wyzwolić.

„Strukturalizacja otoczenia”. Przypuśćmy, że chcesz, aby dwoje rywalizujących ze sobą dzieci nauczyło się współdziałać ze sobą. Jeden ze sposobów zachęcania ich do tego typu reagowania polega na umieszczeniu ich w pokoju, gdzie znajdują się zabawki, do manipulowania którymi potrzeba co najmniej dwojga dzieci. Jeśli chcesz, żeby zwierzę nauczyło się naciskać dźwignię, dziobać przycisk, otwierać zasuwę, uciekać przez otwór czy choćby konsumować dostępną nagrodę, to możesz zwiększyć prawdopodobieństwo tych zachowań usuwając rozpraszające, nieistotne bodźce, upraszczając otoczenie, starając się, by przedmioty służące do |manipulowania (dźwignia, przycisk itd.) były bardziej widoczne niż inne elementy otoczenia. Różnica między względnie skomplikowaną skrzynką problemową Thorndike’a a prostą skrzynką Skinnera ilustruje dążenie do zwiększenia prawdopodobieństwa wystąpienia pożądanej reakcji przez strukturalizowanie otoczenia w taki sposób, by usunąć większość innych możliwości. Umiejętność przetrwania jedynie w stosunkowo prostym środowisku może oczywiście pozostawić organizm bezradnym i przytłoczonym przez mnóstwo różnorodnych bodźców, jeśli napotka on złożone środowisko (jak wtedy, gdy polna mysz przeniesie się do miasta).

„Stosowanie przymusu”. Często najskuteczniejszą metodą uzyskania pierwszej poprawnej reakcji jest fizyczna pomoc w jej wykonaniu. Bierzesz rączkę dziecka z łyżeczką pełną nieznanej mu potrawy i kierujesz ją do jego ust. Następnie wzmacniasz „włożenie pokarmu do buzi” (i miejmy nadzieję, połknięcie go) pochwałą lub jakoś inaczej. Aby nauczyć psa przewracać się, trener najpierw podaje sygnał słowny, następnie przewraca psa i chwali go lub karmi za każdym razem, dopóki zwierzę nie „pojmie”, o co chodzi.
Ta technika szybkiego wywoływania reakcji ma prawdopodobnie najgorsze konsekwencje na dalszą metę, gdy uczącymi osobnikami są ludzie, zwłaszcza jeśli uczą się pod przymusem lub niechętnie, lub jeśli osoba stosująca tę technikę jest nierozsądna. Pokierowanie uczącym się tańca może być pomocne, lecz wyobraź sobie, co czułby nasz nieśmiały uczeń wobec nauczyciela, który wymuszałby reakcję zgłaszania się do odpowiedzi, podnosząc siłą jego rękę.  Niezależnie od wielkości późniejszego wzmocnienia dla tej reakcji, brutalny sposób jej wymuszenia spowodowałby prawdopodobnie rozwinięcie się negatywnych reakcji emocjonalnych wobec osoby posługującej się przymusem, pogłębiłby poczucie osobistego niedostosowania lub doprowadziłby do mechanicznego wykonywania poprawnej reakcji, bez zrozumienia wchodzącej w grę zasady.

„Naśladowanie modelu”. Repetez, s’il vous, mówi nauczyciel francuskiego i uczeń stara się naśladować to, co powiedział nauczyciel - zarówno treść, jak i sposób wymawiania. Uczenie się obserwacyjne jest także wartościowe wówczas, gdy nie można łatwo przekazać słowami wszystkich szczegółów złożonej czynności ruchowej - takiej jak na przykład zawiązanie sznurowadeł czy uderzenie piłki tenisowej. Ten rodzaj uczenia się odgrywa niewątpliwie ważną rolę w uczeniu się społecznym, zarówno u zwierząt, jak i u ludzi.
Z drugiej strony, nadmierne poleganie na modelach (którymi zwykle są osoby mające autorytet - authority figures) może ograniczyć własną inicjatywę danej jednostki i nauczyć ją konformizmu. Może także prowadzić do „podchwytywania” mnóstwa innych reakcji wykonywanych przez model. Mogą to być reakcje związane z pożądaną reakcją, takie jak sposób mówienia rodziców, używane przez nich wyrażenia gwarowe itd., których dziecko uczy się razem z językiem. Mogą też to być inne, nie powiązane bezpośrednio reakcje, które po prostu są często prezentowane przez model, na przykład sformułowania wyrażające uprzedzenie wobec grup mniejszościowych.

„Wskazówki słowne”. Powiedzenie „Rób to, co ci mówię, a nie to, co robię” wskazuje na różnicę między tym podejściem a poprzednim. Zdolność posługiwania się mową może niewątpliwie być dużym ułatwieniem w pewnych rodzajach uczenia się i może znacznie przyspieszyć wywołanie pierwszej poprawnej reakcji. W istocie, za pomocą wskazówek słownych można nie tylko opisać, jak należy wykonać daną reakcję, lecz także przedstawić błogie następstwa, jakie przyniesie jej wykonanie. Można przedstawić złożone sekwencje reakcji, jak również abstrakcyjne zasady, informacje dotyczące opóźnienia nagrody, sposoby wykorzystania posiadanych umiejętności oraz wskazówki na przyszłość.
Stosowanie się do wskazówek słownych wymaga oczywiście ich zrozumienia, a to nie zawsze jest łatwe - jak mogą poświadczyć ci rodzice, którzy sfrustrowani i zdesperowani usiłowali bezskutecznie złożyć zabawkę dziecięcą na podstawie „łatwych do zastosowania wskazówek”. Wieloznaczność w sposobie posługiwania się językiem, założone opanowanie szeregu pojęć czy umiejętności, a niekiedy także różnica między tym, co się mówi, a tym, co w rzeczywistości ma się na myśli - wszystko to może zmniejszać efektywność wskazówek słownych dla wielu potencjalnych uczniów. Z drugiej strony, zbyt precyzyjne wskazówki mogą na dalszą metę doprowadzić do ukształtowania się wyuczonej zależności - osobie zależnej trzeba dokładnie powiedzieć, co ma zrobić i w jaki sposób, przy czym wiąże się to u niej z zanikiem ciekawości intelektualnej i obawą przed podejmowaniem ryzyka.

„Próby i błędy”. Ta metoda, którą można by też nazwać metodą „pływaj albo się utop” lub metodą „przetrwania najlepiej przystosowanych”, jest pod wieloma względami szczególna. Jest jedną z najmniej skutecznych technik uzyskiwania pierwszej poprawnej reakcji, lecz może mieć najbardziej pożądane następstwa na dalszą metę, kiedy poskutkuje. Jest to jednak zdecydowanie niedemokratyczny, elitarystyczny sposób podejścia, gdzie wielu jest wezwanych, a tylko niewielu uzyskuje wzmocnienie. Dla tych, którzy starali się i odnieśli sukces, względne subiektywne wzmocnienie jest większe, gdy weźmie się pod uwagę wszystkich tych, którym się nie powiodło.  Ponadto zostaje tu wzmocniona nie tylko poprawna reakcja, lecz cały proces poszukiwania rozwiązania.
Natomiast dla wielu osób, których próby prowadzą jedynie do błędów, wzmocnienie za poprawną reakcję nigdy nie nadchodzi. Należy oczekiwać, że wysiłek i ciekawość, towarzyszące danemu zachowaniu, ulegną wygaszeniu.  Jest to szczególnie prawdopodobne wtedy, gdy oceny przyznaje się według krzywej rozkładu normalnego i połowa uczniów w klasie jest skazana na stopnie „poniżej przeciętnej”. Z drugiej strony nierywalizujące „badawcze” podejście typu prób i błędów, pod czujnym okiem nauczyciela pomagającego tak ukierunkować poszukiwania, by uczniowie stale osiągali więcej niż przedtem (lecz nie za wiele od razu), może pozwolić uczniom uzyskiwać przez cały czas dostateczne wzmocnienia, aby podtrzymać swą aktywność. 

Kształtowanie i wiązanie (chaining) zachowań. Czy wierzysz w to, czy nie wierzysz, przy zastosowaniu warunkowania sprawczego możesz dokonać nawet takich oto niezwykłych rzeczy: nauczyć gołębia gry w ping-ponga, szczura - podnosić ciężar większy od wagi własnego ciała lub delfina - skakać przez obręcz. Sekret polega na tym, abyś zaczął naukę od czegoś, co zwierzę już wykonuje i stopniowo zmieniał wzmacniającą reakcję, „kształtując” ją tak, aby była coraz bardziej podobna do reakcji, którą chcesz otrzymać.
Dla wielu złożonych zachowań, których wystąpienie w doskonałej postaci jest w pierwszej próbie nieprawdopodobne, obniżyłbyś kryterium wzmocnienia.  Na początek postanowiłbyś, że poprawną reakcją będzie każda zewnętrzna reakcja będąca przybliżeniem (czyli w pewnym stopniu podobna) do choćby jednego „kroku” w ostatecznej sekwencji czynności, jaką chcesz uzyskać.  Następnie, w kolejnych próbach, reakcja ta musiałaby być coraz bardziej zbliżona do pożądanej czynności, aby spowodować podanie wzmocnienia.  Wreszcie kilka takich ukształtowanych zachowań można powiązać w całą złożoną sekwencję. Pod koniec treningu wzmocnienie stosuje się jedynie po wykonaniu całej sekwencji.

Zbliżenie
Herkulesowa siła

„Fotografie zamieszczone obok przedstawiają łagodnego laboratoryjnego szczura Herkulesa, który został przekształcony w energicznego ciężarowca zdolnego podnieść ciężar dwa razy większy od wagi własnego ciała. Najpierw po każdej reakcji głodnego szczura skierowanej w stronę miski następował głośny trzask, miska zostawała oświetlona i pojawiała się w niej kulka pokarmu. Gdy szczur zaznajomił się już z mechanizmem karmienia, nagradzano go tylko za ruchy ciała w kierunku dźwigni, później - tylko za dotknięcie dźwigni, a wreszcie - tylko za pociągnięcie do dołu.
Po zakończeniu tego etapu dokładano małe odważniki na szalkę przymocowaną do drugiego końca dźwigni na skutek czego wysiłek potrzebny do jej naciśnięcia stopniowo się zwiększał. Dzięki starannemu rozłożeniu wzmocnień i stopniowemu zwiększaniu ciężaru, już po kilku godzinach ćwiczeń 250-gramowy szczur potrafił podnieść ciężar 515 gramów.
Można zauważyć, że Herkules nauczył się także przybierać odpowiednią postawę w celu dokonania swego wyczynu. Musiał wczepić pazury tylnych łap w ściankę z drucianej siatki, by nie dać unieść się w górę przez obciążoną na drugim końcu dźwignię, gdy już udało mu się ściągnąć ją w dół (wtedy mikroprzełącznik zamykał kontakt, powodując dostarczenie kulki pokarmu).

Niewątpliwie widywałeś w telewizji tresowane zwierzęta dokonujące różnych zadziwiających wyczynów, przy czym dopiero po ostatniej reakcji otrzymywały marchewkę, kostkę cukru lub kawałek ryby. Eksperymentalna demonstracja procedury stosowanej w celu otrzymania takich mądrych zachowań zwierząt wykazałaby, że najważniejsze jej elementy to cierpliwość tresera i jego umiejętność posługiwania się warunkowaniem sprawczym.
Pierrel i Sherman (1963) potrafili przekształcić zwykłego małego szczurka, Barnabę, w artystę cyrkowego, podobnie jak profesor Higgins zmienił uliczną kwiaciarkę w „my fair lady”. Barnaba nauczył się:

a) wspinać na spiralne schody,
b) przechodzić po wąskim moście zwodzonym,
c) wdrapywać się na drabinę,
d) przyciągać za pomocą łańcuszka samochodzik,
e) wskakiwać do tego samochodzika,
f) pedałować w nim do drugiej drabiny,
g) wspinać się na tę drabinę,
h) pełzać przez rurę,
i) wsiadać do windy,
j) ciągnąć łańcuch, który podnosił flagę, a jego samego opuszczał na platformę startową, gdzie mógł
k) nacisnąć dźwignię dostarczającą malutką kulkę pokarmu, a po zjedzeniu tego pokarmu
l) wspinać się na spiralne schody...

Aby nauczyć Barnabę tej godnej podziwu sekwencji czynności, eksperymentatorzy zaczęli nie od jej początku, lecz od końca. Najpierw Barnaba nauczył się naciskać dźwignię, aby otrzymywać kulki pokarmu.  Następnie umieszczali go w windzie, która, gdy zjechała na dół, dawała mu dostęp do dźwigni pokarmowej. Gdy Barnaba nauczył się, że jazda windą przynosi takie korzystne rezultaty - a następnie, że można je osiągnąć ciągnąc za łańcuch - nietrudno było skłonić go, aby pełzał przez tunel do windy. I tak dalej. Poszczególne elementy reakcji, które początkowo nie znajdowały się w repertuarze Barnaby, trzeba było niekiedy wywoływać za pomocą specjalnych technik, opracowanych przez specjalistów z zakresu warunkowania zwierząt, takich jak pokazywanie, umieszczanie szczura tam, gdzie powinien sam wejść, wyraźniejsze wyodrębnienie krytycznych elementów otoczenia itd. Następnie przybliżenia pożądanych reakcji kształtowano tak, by uzyskać dokładnie określoną, pożądaną czynność. W końcu każde ogniwo tego łańcucha czynności stało się |bodźcem |dyskryminacyjnym dla następnego kroku i |warunkowym |czynnikiem |wzmacniającym dla kroku poprzedniego.
Przyjmujemy, że podobny wzorzec występuje wtedy, gdy uczymy się złożonej serii nowych reakcji, takiej jak kierowanie samochodem, granie na fortepianie lub tańczenie. Wytwarzane są najpierw elementy składowe - początkowo niekiedy w postaci surowej, „niewygładzonej” - które następnie są doskonalone przez selektywne wzmacnianie oraz łączone w sekwencję.


Tradycyjne paradygmaty wobec nowych problemów


Wstępne podręczniki ze wszystkich dziedzin są pod pewnym względem podobne do domu przygotowanego na przyjęcie zapowiedzianych w ostatniej chwili gości - śmiecie wmieciono pod dywany, pokoje z niezasłanymi łóżkami zamknięto na klucz, a nieokiełznanego małego Kazia wysłano, by bawił się u sąsiadów. Dla gości dom przedstawia miły wygląd, nacechowany porządkiem i harmonią. Autorzy podręczników psychologii chcieliby przekazać swoim studentom to samo wrażenie prostoty i regularności - przekonanie, że każda rzecz jest na swoim właściwym miejscu. Po pierwsze, w ten sposób najłatwiej jest uczyć się materiału, lecz wydaje się także, iż stawia to psychologię w lepszym świetle, sprawiając wrażenie, że psychologowie zawsze dokładnie wiedzą, co robią.
Ponieważ jednak psychologia jest dyscypliną rozwijającą się - nauką czyniącą postępy - jest wiele rzeczy, których nie można ładnie posegregować ani porządnie skategoryzować. Całkiem niedawno pojawiły się pewne „kłopotliwe” nowe badania w dziedzinie psychologii uczenia się, które „nie mają sensu” z punktu widzenia tradycyjnych, podręcznikowych kategorii i zróżnicowań. Wyniki tych badań podważają, być może, naszą zasadniczą koncepcję; co najmniej zaś zmuszają do uświadomienia sobie, jak wąski jest akceptowany obecnie pogląd na to, co stanowi psychologię uczenia się.
Sądzimy więc, że w tym podrozdziale z przyjemnością zajrzysz do niektórych „nieposprzątanych” pokojów w domu, który wzniósł Pawłow, a rozbudował Skinner. Po krótkim porównaniu warunkowania reaktywnego z warunkowaniem sprawczym, rozpatrzymy badania, które wykazują, jak zachowanie reaktywne można uwarunkować sprawczo, jak zachowanie sprawcze można uwarunkować reaktywnie oraz w jaki sposób czynniki genetyczne, a nawet przeszłe doświadczenia, mogą spowodować, że uczenie się nie będzie przebiegało tak, jak należałoby tego oczekiwać na podstawie naszych „praw uczenia się”.


Porównanie warunkowania reaktywnego i warunkowania sprawczego


Powinno to być dla ciebie oczywiste, że bodziec bezwarunkowy (S) w warunkowaniu reaktywnym jest tym samym, co pozytywny lub negatywny czynnik wzmacniający (S) w warunkowaniu sprawczym, ponieważ oba dostarczają wzmocnienia dla wykonywanej reakcji. Bodziec warunkowy (S), który reprezentuje bodziec bezwarunkowy w warunkowaniu pawłowskim, spełnia tę samą funkcję, co warunkowe, czyli wtórne, czynniki wzmacniające w warunkowaniu skinnerowskim. Jakie są główne różnice między tymi dwoma typami uczenia się? Różnice te podsumowano w zamieszczonej obok tabeli.
Teraz skomplikujemy trochę ten obraz pewnymi wyjątkami, nawet od tych - wydawało by się - podstawowych rozróżnień. Wyobraź sobie, że jesteś niemowlęciem. Podczas karmienia ciebie twoja matka uśmiecha się, następnie daje ci łyżeczkę twojej ulubionej papki, a ty ślinisz się, zjadasz pokarm i też śmiejesz się zadowolony. Wydaje się, że podlegasz warunkowaniu reaktywnemu: uśmiech Mamy (S) - pokarm (S) - ślinienie się ®. W końcu będziesz się ślinić ® na uśmiech Mamy - nawet przed pojawieniem się pokarmu.
Jak jednak wygląda sprawa z twojego punktu widzenia? Czy nie jest możliwe, że nauczyłeś się wierzyć, iż twoje ślinienie się, śmiech, gruchanie itd. powodują pojawienie się pokarmu? Gdy już zostałeś uwarunkowany, sekwencja przedstawia się następująco: uśmiech Mamy - ty reagujesz - pokarm się pojawia. Dla ciebie jest to czynność instrumentalna - paradygmat warunkowania sprawczego - nawet jeśli twoja matka uważa ją za warunkowanie reaktywne. W istocie jesteś podobny do Orfeusza z naszego przykładu magicznego warunkowania sprawczego: postępujesz tak, |jak |gdyby czynnik wzmacniający był uzależniony od twojej reakcji, mimo że nie jest, i traktujesz uśmiech Mamy, jako bodziec dyskryminacyjny stwarzający warunki dla działania mechanizmu R-S, a nie po prostu jako zwykły, słodki S, którym miał być. Przekonałbyś się, że nie miasz racji, gdyby można ci było wytłumaczyć, abyś się nie ślinił i nie śmiał, bo wówczas zobaczyłbyś, że i tak dostaniesz pokarm - wytłumaczenie czegoś głodnemu, dobrze uwarunkowanemu, śmiejącemu się niemowlęciu, jest jednak trudnym zadaniem.  Więc co to jest: warunkowanie reaktywne czy warunkowanie sprawcze?
Przejdźmy do dodatkowych, mniej prozaicznych komplikacji.


Warunkowanie sprawcze zachowań reaktywnych


Reakcje odruchowe (Dla oddania skinnerowskiego terminu respondents (dla którego w języku polskim brak jest dobrego odpowiednika) w tekście używa się zamiennie określeń „zachowania reaktywne” i „reakcje odruchowe” (przyp.  red. nauk.)) (respondents) są to czynności ściśle związane z pierwotnym, biologicznym przetrwaniem organizmu. Trawienie, ślinienie, rozszerzanie się i kurczenie naczyń krwionośnych, pocenie się, zmiany w tempie pracy serca, ciśnieniu krwi i temperaturze ciała, oddychanie, funkcjonowanie wątroby i nerek - oto niektóre z reakcji mimowolnych, które utrzymują nas przy życiu i zwykle zachodzą bez żadnego wysiłku z naszej strony. Rzadko nawet uświadamiamy je sobie, o ile nie cierpimy na astmę, wysokie ciśnienie krwi, nieżyt jelit, wrzody żołądka czy któreś z wielu zaburzeń tych normalnie niezauważalnych, sprawnie przebiegających procesów.
Przed kilku laty można było przeczytać w gazetach o siedemnastoletniej dziewczynie, która nagle zaczęła kichać i nie mogła przestać. Kichała częściej niż co minutę, z wyjątkiem okresów snu, dzień po dniu, całymi miesiącami. Żadne lekarstwo, zmiana klimatu ani też „środki domowe” (straszenie, nakładanie na głowę papierowej torby itd.) nie miały żadnego wpływu na tę przykrą przypadłość. Gdyby kichanie było reakcją sprawczą, to w jaki sposób można by zmniejszyć jej częstość?... Tak, przez zastosowanie kary.

„Psycholog Malcolm Kusher zdecydował się podjąć tę szansę i zastosować procedury warunkowania sprawczego dla wyleczenia reakcji odruchowej w postaci nieopanowanego kichania. Zastosowany przez niego sposób był prosty.  Po każdym kichnięciu natychmiast następowały przykre dla dziewczyny konsekwencje - impuls elektryczny wymierzany w jej przedramię. Po około czterech godzinach takiego łączenia kichnięć z impulsami elektrycznymi kichanie ustało i już nie powróciło, chyba że jako normalna, sporadycznie wywoływana reakcja”.

W innym przypadku, osobiście znanym autorom, u młodego chłopca z Nowego Jorku występowały silne napady astmy za każdym razem, gdy jego rodzice wysyłali go na wieś do krewnych w New Jersey. Dolegliwość tę uznano za alergiczną reakcję na pyłek kwiatowy, którego jest dużo na wsi, a nie ma go w mieście. Jest jednak ciekawe, że chłopiec ten nie miał nigdy żadnych trudności z oddychaniem, gdy obozował w lasach New Jersey ze swą drużyną skautowską. „Wysyłanie do krewnych” było dla niego awersyjną konsekwencją, której przypuszczalnie nauczył się unikać, wytwarzając reakcję astmatyczną - która wymuszała jego radosny powrót do miejskich kolegów i do rodziny.
Jeśli można wykazać, że reakcje narządów wewnętrznych, gruczołów i mięśni gładkich stosują się do tych samych praw uczenia się co zewnętrzne, dowolne reakcje mięśni szkieletowych, to klasa reakcji, które można zmieniać za pomocą wzmocnienia, staje się nieomal nieograniczona. Ponadto, jeśli mięśnie gładkie i gruczoły reagują na warunki środowiskowe, to jesteśmy w stanie wykryć, jak rozwija się choroba psychosomatyczna. Wiemy, że te fizyczne dolegliwości są wywoływane w jakiś sposób przez stres psychologiczny, jak w przypadku astmatycznego chłopca. Być może są one pod kontrolą mechanizmów warunkowania sprawczego. Jeśli tak, to (podobnie jak u kichającej nieustannie dziewczyny) można je modyfikować za pomocą procedur sprawczych. Zazwyczaj jednak większość reakcji autonomicznego układu nerwowego nie ma żadnego wpływu na środowisko. Wobec tego nie są one wzmacniane przez swe konsekwencje i nie znajdują się pod kontrolą środowiska.
Aby wykazać, że reakcje te mogą być |modyfikowane przez wzmocnienie, dzięki czemu powstaje możliwość kierowania nimi, Neal Miller i jego współpracownicy z Rockefeller University (1969, 1970, 1973) opracowali szereg pomysłowych procedur; miały one dać odpowiedź na pytanie, czy ten „tępy” układ nerwowy może nauczyć się zachowywać w sposób „sprytniejszy”, bardziej wrażliwy na środowisko. W zakrojonej na szeroką skalę serii badań, które jeszcze nie zostały ukończone, badaczom tym udało się wykazać, że uczenie się sprawcze reakcji wewnętrznych (visceral operant learning) jest istotnie możliwe, a co więcej, że za pomocą takich technik można osiągnąć zaskakująco duży stopień kontroli nad zachowaniem.
Miller i jego współpracownicy opracowali trzy procedury umożliwiające wzmacnianie reakcji autonomicznego układu nerwowego:
1. Musieli oni wyeliminować reakcje mięśni szkieletowych, takie jak oddychanie i poruszanie się, które mogłyby wpływać na reakcje narządów wewnętrznych. Osiągnięto to aplikując |kurarę, która blokuje wszelkie reakcje ruchowe i zmniejsza zakłócenia powodowane przez nieistotne bodźce, lecz nie eliminuje świadomości. Oddychanie podtrzymywano sztucznie. Badania przeprowadzano na zwierzętach.
2. Konieczne było wykrywanie i rejestrowanie słabych reakcji narządów wewnętrznych, a niewielkie zmiany amplitudy lub częstości trzeba było wzmacniać natychmiast.

Dokonywano tego za pomocą skomplikowanych urządzeń (rejestrujących zmiany fizjologiczne) połączonych z małym komputerem, który mógł wykryć zmianę reakcji i zainicjować podawanie wzmocnienia.

* * *

Ryc. 3.17. Na tej fotografii, przedstawiającej aparat Millera, szczur sparaliżowany przez zastosowanie kurary, oddycha w wymuszony sposób przez lejek nałożony na nos. Za pośrednictwem implantowanych uprzednio elektrod podaje się mu do mózgu stymulację - natychmiast po każdej autonomicznej zmianie w pożądanym kierunku. Na wykresie pokazano krzywą, obejmującą około 90 minut, dotyczącą szczurów nagradzanych za zwiększanie tempa pracy serca oraz analogiczną krzywą (opadającą) dla szczurów nagradzanych za zmniejszenie tego tempa.
* * *

3. Wzmocnienie musiało być dostarczane natychmiast, mieć natychmiastową efektywność i nie wymagać od badanego zwierzęcia wykonywania żadnych reakcji ruchowych (które byłyby niezbędne, gdyby czynnikiem wzmacniającym był pokarm). Osiągnięto to przez drażnienie słabym prądem elektrycznym określonych okolic pnia mózgu, znanych jako „ośrodki przyjemności” (opisano je w Rozdziale 2).
Możliwą do osiągnięcia precyzję sterowania zachowaniem dobrze ilustruje fakt, że można zmieniać eksperymentalnie nawet odstęp czasowy między skurczem komory a skurczem przedsionka w pojedynczym uderzeniu serca.  Oprócz zmian w tempie pracy serca, pokazanych na wykresie, techniki warunkowania sprawczego umożliwiły badaczom regulowanie: ślinienia, ciśnienia krwi, skurczów jelit, szybkości wytwarzania moczu, przepływu krwi w ściankach żołądka oraz innych reakcji (ryc. 3.17).
„Aby wykazać, że wzmacnianie sprawcze może wywierać wysoce specyficzny wpływ na poszczególne części współczulnego układu nerwowego - nauczono szczury „rumienić się” tylko na jednym uchu. Fotokomórki przymocowane do uszu szczura wskazywały chwilowe zmiany w rozszerzaniu się naczyń krwionośnych. Gdy naczynia krwionośne w jednym uchu rozszerzyły się w pewnym określonym stopniu, szczur otrzymywał natychmiastowe wzmocnienie poprzez drażnienie mózgu. Z 12 szczurów 6 nagradzano za większe rozszerzenie się naczyń krwionośnych (rumienienie się) w prawym uchu, podczas gdy 6 nagradzano jedynie za rumienienie się lewego ucha. Wszystkich 12 zwierząt nauczyło się rumienić tylko na nagradzanym uchu (Di Cara i Miller, 1968b).
W wielu laboratoriach uniwersyteckich i medycznych badacze zainspirowani powodzeniem badań nad zwierzętami pracują obecnie nad rozszerzeniem tych zasad tak, by można było uzyskać kontrolę nad objawami psychosomatycznymi u ludzi. Uzyskane dotąd wyniki są obiecujące, lecz nie tak efektowne, jak w lepiej kontrolowanych eksperymentach nad zwierzętami.
Trudność polega po części na tym, że w odniesieniu do ludzi stosuje się czynnik wzmacniający o działaniu mniej bezpośrednim i słabszym niż drażnienie mózgu u zwierząt. W badaniach nad ludźmi rejestruje się na przykład zmiany reakcji, a gdy przekroczą one pewien poziom kryterialny, zapala się lampka lub słychać dźwięk sygnalizujący badanemu o „powodzeniu”.  Czynnikiem wzmacniającym jest sprzężenie zwrotne - to znaczy poczucie „kompetencji”, zadowolenie, że potrafi się włączyć dzwonek czy zapalić lampkę. Jednakże nawet przy stosowaniu wobec ludzi słabszego czynnika wzmacniającego, okazało się możliwe uwarunkowanie pacjentów z niedomogą serca tak, aby zredukowali występujące u nich przedwczesne skurcze przedsionków, przy czym u 4 z 8 badanych ten korzystny stan utrzymywał się nadal, gdy zbadano ich ponownie prawie dwa lata później (Weiss i Engel, 1971).
Wszystkie te fakty dowodzą, że reakcje odruchowe można poddawać warunkowaniu sprawczemu. Chociaż może to początkowo zaciemniać wyraźne niegdyś rozróżnienie między dwoma typami uczenia się, może to jednak prowadzić do opracowania procedur klinicznych przynoszących ulgę w poważnych schorzeniach nie przez aplikowanie leków, lecz drogą uczenia się.


Warunkowanie reaktywne zachowań sprawczych


Jak wiemy, zachowania sprawcze (Dla oddania Skinnerowskiego terminu operants (dla którego w języku polskim brak jest dobrego odpowiednika) w tekście używa się zamiennie „zachowanie sprawcze” i „reakcje sprawcze” (przyp. red. nauk.)) (operants) są wzmacniane przez swe konsekwencje.  Zachowaniem (reakcją) sprawczym, najczęściej stosowanym w badaniach laboratoryjnych, jest dziobanie (przez gołębie). Przypuśćmy, że można by wykazać, iż dziobanie jest wywoływane przez bodziec warunkowy w paradygmacie warunkowania reaktywnego, gdzie dziobanie nie wpływa na dostarczenie pokarmu.
Zjawisko takie stwierdzono w eksperymentach nad tak zwanym |samokształtowaniem (autoshaping), w których reakcji sprawczej nie kształtują następujące po niej konsekwencje, lecz wytwarzane „we własnym zakresie” czynniki wzmacniające, wywodzące się z ewolucji danego organizmu.  Brown i Jenkins (1968) jako pierwsi zaobserwowali następujące ciekawe zachowanie:

„Głodnym gołębiom umieszczonym w skrzynce Skinnera podawano pokarm wkrótce po oświetleniu małego krążka. Pokarm podawano według rozkładu nieregularnego, bez względu na to, co gołąb robił; łączenie bodźców było wyraźnie typu S-S. Wkrótce gołębie zaczęły dziobać oświetlony przycisk, mimo że dziobanie nie było związane z podawaniem pokarmu. Jednakże dziobały one przycisk tylko wtedy, jeśli był to sygnał pokarmu; jeśli był on zawsze oświetlony, to gołębie ignorowały to.
Jeszcze ciekawszy fakt stwierdzono w podobnym badaniu: takie „samokształtowane” dziobanie utrzymało się nawet wtedy, gdy dziobanie przycisku w rzeczywistości zapobiegało podaniu pokarmu (Williams i Williams, 1969). Opisano także zjawisko samokształtowania u przepiórek, małp, ryb i szczurów”.

Badania te sugerują, że chociaż zwierzęta, u których zachodzi samokształtowanie, mają swobodę poruszania się, a reakcja warunkowana jest reakcją sprawczą, to jednak zachodzący proces jest warunkowaniem pawłowskim. Dlaczego możliwe jest takie zjawisko? Racjonalną odpowiedzią jest wskazanie na przystosowawczy charakter uczenia się reakcji, polegającej na zbliżaniu się do bodźców środowiskowych, które sygnalizują pokarm.

„Ten pawłowski mechanizm był wysoce przystosowawczy w większości naturalnych sytuacji. Powodował on, że zwierzę wracało do miejsc, przedmiotów, substancji lub organizmów, w obecności których prawdopodobne było napotkanie tych rodzajów bodźców warunkowych, które wywołują reakcję zbliżenia (...) Uderzająca prostota procesu pawłowskiego oraz ekonomia, z jaką wykorzystuje on mechanizmy przekazywania informacji, występujące już u pierwotnych organizmów, dawały mu od początku znaczną przewagę ewolucyjną” (B. Moore, 1973, s. 183)

Czy jednak zwierzęta rzeczywiście reagują na bodziec warunkowy tak, jak gdyby to był bodziec bezwarunkowy (jak się to dzieje w warunkowaniu pawłowskim)? Czy forma ich reakcji na ten bodziec jest podobna do formy ich reakcji konsumpcyjnej, gdy jedzą lub piją? Odpowiedź zdaje się być twierdząca. Przyspieszone zdjęcia filmowe dziobiących przycisk gołębi, które otrzymywały bądź pokarm, bądź wodę, ujawniły, że samokształtowane reakcje były różne w zależności od czynnika wzmacniającego i dostosowane do niego gołębie, otrzymujące później pokarm, miały dzioby otwarte, a ich dziobnięcia były szybkie i energiczne; gołębie nagradzane wodą miały dzioby zamknięte - ich dziobnięcia były powolniejsze i często towarzyszyły im ruchy połykania.

„W doskonale zaprojektowanych, niedawno przeprowadzonych badaniach warunki zaaranżowano w taki sposób, że dla połowy badanych zwierząt (szczurów) jedna dźwignia w skrzynce Skinnera była skojarzona z podawaniem pokarmu (|S), a druga dźwignia pojawiała się losowo (|S). W drugiej grupie badanych zwierząt jedna dźwignia była skojarzona ze wzmocnieniem w postaci elektrycznego drażnienia mózgu (|S), podczas gdy pojawienie się drugiej dźwigni nie miało żadnego związku z drażnieniem mózgu. Reakcje badanych zwierząt nie miały żadnego wpływu na bodziec wzmacniający.

Reakcje badanych zwierząt nie miały żadnego wpływu na bodziec wzmacniający. Trening nabywania reakcji składał się z 5 posiedzeń, po 40 prób, po czym następowały próby wygaszające (bez pokarmu lub bez drażnienia mózgu), ponowne nabywanie, a następnie odwrócenie warunków eksperymentu - dźwignia S była teraz związana z czynnikiem wzmacniającym, podczas gdy dźwignia będąca poprzednio S nie miała żadnego funkcjonalnego znaczenia.
Podobnie jak w omówionych poprzednio eksperymentach nad samokształtowaniem reakcji, badane zwierzęta kontaktowały się często z dźwignią S. Liczba tych reakcji malała szybko w czasie wygaszania, lecz szybko też wzrastała podczas ponownego nabywania: łatwo również następowała zmiana częstości kontaktów, gdy zmieniano wartość sygnałową obu dźwigni.
Bardzo interesujące jest stwierdzenie, że specyficzna forma kontaktu zależała od rodzaju stosowanego bodźca bezwarunkowego. Gdy był to pokarm, wówczas zdjęcia zarejestrowane na taśmie magnetowidu ujawniły, że badane zwierzęta kontaktowały się z dźwignią niemal wyłącznie oralnie, liżąc ją i gryząc.

Natomiast zwierzęta poddawane drażnieniu mózgu rzadko lizały dźwignię S, lecz badały ją wzrokiem, wąchały i dotykały jej przednimi łapami. Pawłowski bodziec warunkowy wywołał więc specyficzne reakcje szkieletowe, podobne do reakcji wywoływanych bezpośrednio przez bodziec bezwarunkowy, który miał wkrótce wystąpić” (Peterson, Ackil, Frommer i Hearst, 1972).

Badania tego rodzaju uświadomiły nam nieocenioną dotąd rolę warunkowania pawłowskiego w pojawianiu się, podtrzymywaniu i modyfikacji pewnych reakcji sprawczych, ważnych dla przetrwania organizmu i gatunku.


Specyficzne dla danego gatunku ograniczenia warunkowania


Prawa uczenia się przedstawiane w tym rozdziale są stwierdzeniami o funkcjonalnych zależnościach między pewnymi klasami zmiennych niezależnych i zależnych. Badania będące podstawą takich praw oparto na założeniu, że zasadnicze elementy, które kojarzy się ze sobą - bodźce, reakcje i czynniki wzmacniające - są ustalane arbitralnie i najlepiej można je badać w wysoce uproszczonych, sztucznych środowiskach laboratoryjnych, na oswojonych, hodowanych w laboratorium zwierzętach. Wielu psychologów, pozostających w kręgu tradycyjnych badań nad uczeniem się zwierząt, jest przekonanych o uniwersalności stosowanych przez siebie procedur eksperymentalnych - o tym, że wykrywane przez nich „prawa uczenia się” są naprawdę zasadami zachowania dotyczącymi wszelkich organizmów.

„(...) wybieramy arbitralnie jakąkolwiek czynność z repertuaru zwierzęcia i wzmacniamy ją pokarmem, wodą lub jakąkolwiek inną rzeczą, dla uzyskania której zwierzę będzie pracować. Chociaż zazwyczaj uczymy szczura naciskać dźwignię, a gołębia dziobać przycisk dla otrzymania kulki pokarmu, możemy łatwo, jeśli tak zechcemy, wyćwiczyć każde z tych zwierząt, by tańczyło wokół klatki. Zwykle stosujemy światło, aby zasygnalizować podanie pokarmu, lecz możemy posłużyć się jakimś dźwiękiem, brzęczykiem lub innym dowolnym bodźcem, który zwierzę potrafi wykryć (...). Tę samą czynność można poddać dowolnemu wzmacnianiu (...). W rezultacie, w każdej sytuacji sprawczej, bodziec, reakcja i wzmocnienie są całkowicie arbitralne i zamienne. Żadne z nich nie ma żadnego biologicznego, wbudowanego, stałego powiązania z innymi” (Teitelbaum, 1966, s. 566-67).

Pociągająca prostota takiego poglądu nie uchroniła go ostatnio przed atakami ze strony badaczy argumentujących, że zdolność danego zwierzęcia do uczenia się wiąże się ściśle z wymaganiami dotyczącymi uczenia się, wynikającymi z warunków jego środowiska naturalnego i |cech |specyficznych |dla |gatunku - cech, które są swoiste dla danego gatunku i odmienne u różnych gatunków (np. Shettlesworth, 1972; Rozin i Kalat, 1970).  |Etologowie (badacze, którzy studiują zachowanie zwierząt w naturalnym otoczeniu) od dawna podkreślają, że zachowanie każdego osobnika może być tak charakterystyczne dla jego gatunku, jak jego fizjologia czy anatomia.  Laboratoryjne badania nad uczeniem się zwierząt gwałcą zasadę „trafności ekologicznej” w odniesieniu do badanego gatunku - gołębiom nie pozwala się budować gniazd ani latać, szczury nie mogą gryźć ani szperać w poszukiwaniu pokarmu, małpom nie daje się łączyć w pary. W codziennym życiu zwierząt laboratoryjnych rzadko występuje konieczność wykonywania reakcji obronnych, agresywnych, badawczych czy reakcji czujności. Podsystemy zachowania (takie jak unikanie prześladowców, migracje, łączenie się w pary, jedzenie, opieka nad młodymi) w każdym gatunku ewoluowały przystosowawczo przez miliony lat i prawdopodobnie stosują się do odpowiednich dla nich praw uczenia się.  Zwiększa się ilość materiału dowodowego świadczącego o potrzebie zmodyfikowania obecnych praw uczenia się w taki sposób, by uwzględniały takie, oparte na mechanizmach genetycznych, oddziaływania.

Tendencja instynktowna. Breland i Breland (1966), mający długoletnie doświadczenie w tresowaniu zwierząt, takich jak świnie, kury i króliki, do zwierzęcych przedstawień i pokazów, opisali zjawisko, które nazwali „tendencją instynktowną” (instictual drift). U zwierząt nie hodowanych w laboratorium często występowały reakcje, które w danej sytuacji uczenia się były niekorzystne, lecz przypominały reakcje „naturalne”, wykonywane w ich zwykłym środowisku. Na przykład głodne świnie, które uczono wkładać monetę do skarbonki (po czym następował czynnik wzmacniający w postaci pokarmu), przerywały tę czynność ryjąc wokół niej i potrącając ją. Zaobserwowano, że reakcje tego rodzaju, przypominające reakcje występujące w przypadku samokształtowania, opóźniały uzyskanie wzmocnienia pokarmowego także u wielu innych gatunków. Zwierzęta „robiły swoje”, zamiast wykonywać tę reakcję, którą eksperymentator cierpliwie nagradzał pokarmem, czynnikiem wzmacniającym, który - jak się ogólnie przyjmuje - steruje zachowaniem głodnego organizmu.

Ostrożność wobec przynęty. Unikanie trucizny w pokarmach jest oczywiście wyuczoną zdolnością posiadającą znaczną wartość, jeśli chodzi o utrzymanie się przy życiu takiego zwierzęcia jak szczur. Ostatnio, w wielu eksperymentach wykazano, że szczury uczą się unikania pokarmu, który uprzednio zjadły, a który był skażony promieniowaniem lub substancjami wywołującymi wymioty. Nie jest to zbyt zaskakujące. Jednakże dwie rzeczy było nowe: 1. Jedynie smak pokarmu stał się bodźcem warunkowym dla unikania. Szczury nie unikały pokarmów, które wyglądały podobnie do skażonego, pokarmów, które miały podobną konsystencję lub temperaturę, pokarmów, które jadły w tym samym czasie, co zatrutą potrawę - nawet jeśli towarzyszyły temu wstrząsy elektryczne. Nie ma zatem żadnej generalizacji bodźca, takiej, jaka zwykle występuje w warunkowaniu. 2. Po jednej tylko próbie szczury uczyły się kojarzyć smak zatrutego pokarmu (S) z wymiotami (S), mimo że występowały one kilka |godzin po jedzeniu. W laboratorium potrzeba zwykle wielu prób i jest pewnikiem, że S musi nastąpić bardzo szybko po S, aby zaszło warunkowanie. Zgodnie z prawami uczenia się, idealny odstęp czasu między S a S wynosi mniej niż |sekundę, podczas gdy tu mamy przykład efektywnego i wysoce selektywnego uczenia się, które zachodzi pomimo to, że między sygnałem niebezpieczeństwa, a niebezpiecznym zdarzeniem upływają godziny. Badanie to, przeprowadzone przez Garcię i jego współpracowników (1972) stawia pod znakiem zapytania możność wyjaśnienia wszelkich rodzajów uczenia się za pomocą podstawowych praw warunkowania i skupia naszą uwagę na przystosowawczych mechanizmach uczenia się, które dany organizm wnosi w każdą taką sytuację.
Staje się coraz bardziej oczywiste, że istnieją różnice gatunkowe pod względem „predyspozycji” do uczenia się tych a nie innych rzeczy (gołębie łatwiej uczą się odróżniać barwy niż linie kątów), łatwości, z jaką pewne bodźce uzyskują zdolność zróżnicowanego sterowania zachowaniem, skuteczności czynników wzmacniających (śpiew dla ptaków, sposobność „pokazania się” dla pewnych ryb) oraz trudności warunkowania czy modyfikowania pewnych podsystemów zachowania w porównaniu z innymi podsystemami. Uwzględnienie tych ograniczeń uczenia się doprowadzi do szerszego ujęcia procesu uczenia się, choć niekoniecznie tak prostego, jak ujęcie tradycyjne.

Wdrukowanie, czyli „Pójdę za tobą wszędzie”. W 1935 roku słynny etolog Konrad Lorenz zwrócił uwagę na pewne zjawisko ważne zarówno dla rozwoju jednostki, jak i dla zachowania gatunku - tak zwane wdrukowanie (imprinting) reakcji podążania i reakcji seksualnych. Termin |wdrukowanie odnosi się do pewnego wczesnego doświadczenia polegającego na tym, że młode zwierzę podąża za zwierzęciem, które jest obecne w czasie krytycznego okresu jego rozwoju. Później, po osiągnięciu dojrzałości, osobnik ten wybiera zwierzę tego samego gatunku jako partnera seksualnego. Zwykłym obiektem wdrukowania jest oczywiście matka młodego osobnika.
Dla zilustrowania tych zjawisk, które badano głównie u kacząt i kurcząt, przytoczymy dwa zaobserwowane fakty: nowo wyklute kaczątko, umieszczone z przybraną matką należącą do innego gatunku a) będzie podążać za nią, a nie za swoją biologiczną matką, b) gdy osiągnie dojrzałość płciową, wybierze jako partnera seksualnego osobnika należącego do tego samego gatunku, co przybrana matka.
Hess (1959) przeprowadził kontrolowane badania laboratoryjne, w których u kacząt wytwarzano wdrukowanie wobec drewnianego modelu kaczki; model ten dzięki specjalnym urządzeniom poruszał się i wydawał dźwięki podobne do kwakania. Posługując się urządzeniem przedstawionym na rysunku zamieszczonym na następnej stronie, zweryfikował on obserwacje dokonane w warunkach naturalnych przez etologów, zgodnie z którymi krytyczny okres wdrukowania reakcji podążania przypada (u piskląt kaczki krzyżówki) między 5 a 24 godziną życia, ze szczytem między 13 a 16 godziną (ryc. 3.19). Po upływie tego okresu wdrukowanie następuje rzadko, a na nieznane obiekty młode reagują nieufnością i strachem. Analogiczny okres u psów występuje w wieku około 13 tygodni, po czym niełatwo jest uczynić z nich pieszczoszków.  Podobnie kocięta, których nie dotyka się i nie bierze na ręce w pierwszych paru tygodniach życia, zawsze potem okazują strach przed ludźmi.
Oto niektóre godne uwagi cechy wdrukowania, które wiążą się z naszymi obecnymi rozważaniami nad ograniczeniem praw uczenia się: a) reakcja ta może zostać utrwalona („zafiksowana”) w bardzo krótkim czasie - w trakcie podążania trwającego zaledwie jedną minutę (Schultz, 1969); b) reakcja ta jest tym silniejsza, im |więcej |wysiłku wymaga podążanie za modelem; c) awersyjne bodźce, takie jak wstrząsy elektryczne wymierzane młodym osobnikom podążającym za modelem, nie zmniejszają, lecz zwiększają efektywność wdrukowania.
W naturalnych warunkach życia reakcja podążania jest ważna dla przetrwania bezradnego pisklęcia, które musi trzymać się swej matki dla zapewnienia sobie ochrony i opieki. Wdrukowanie w stosunku do matki zapewnia także późniejsze wybranie sobie partnera seksualnego należącego do tego samego gatunku; mechanizm ten zapobiega krzyżowaniu się. Badania nad wdrukowaniem ukazują wyraźnie interakcję między wrodzonymi mechanizmami reagowania, procesami dojrzewania i specyficznymi doświadczeniami środowiskowymi. Chociaż mogłoby się wydawać, że ludzie podlegają temu procesowi w mniejszym stopniu niż zwierzęta, to jednak interesujące jest przypuszczenie, iż trwała nietowarzyskość, obserwowana u pewnych osób, które spędziły wczesne dzieciństwo w zakładach wychowawczych (Goldfarb, 1943), może wynikać z braku normalnych kontaktów z ludźmi (i nie wytworzenia się właściwego „wdrukowania” wobec nich) w krytycznym okresie rozwoju.

* * *
Ryc. 3.19. Podatność Na Wdrukowanie A Wiek Krytyczny. Aparatura stosowana przez Hessa w badaniach nad wdrukowaniem składała się z makiety kaczki, zawieszonej na obracającym się ramieniu, za którą kaczątko podążało po okrągłej bieżni. Na pierwszym planie widoczny jest pulpit sterowniczy i aparatura rejestrująca. Na wykresie pokazano procent pozytywnych reakcji, jakie wystąpiły w poszczególnych grupach kacząt - u których wywoływano wdrukowanie w różnym wieku - w próbach kontrolnych, które przeprowadzano |po „sesjach wdrukowujących”. U niektórych osobników wdrukowanie następowało po wykluciu, u innych - nawet w 32 godziny po wykluciu się, lecz kaczęta, u których wdrukowanie nastąpiło między 13 a 16 godziną życia, z reguły uzyskiwały najwyższe wyniki w próbie kontrolnej polegającej na podążaniu za makietą.
* * *

Uprzednie uczenie się jako ograniczenie warunkowania


Kilka lat temu Martin Seligman i jego współpracownicy, Maier i Overmier (1967) natknęli się na interesujące zjawisko, gdy badali wpływ awersyjnego warunkowania pawłowskiego na późniejsze uczenie się unikania. Psy unieruchomione częściowo w uprzęży tego typu, który stosował Pawłow, warunkowano tak, by reagowały na ton sygnalizujący bolesny wstrząs.  Następnego dnia umieszczono je w „skrzynce wahadłowej” (shuttlebox), urządzeniu składającym się z dwóch pomieszczeń oddzielonych barierą, gdzie miały uczyć się prostej reakcji instrumentalnej polegającej na przeskoczeniu barierki, aby uniknąć wstrząsu wymierzanego w pierwszym pomieszczeniu.
Psy niedoświadczone, którym poprzednio nie wymierzano wstrząsu w aparacie pawłowskim, gdy po raz pierwszy otrzymają wstrząs w „skrzynce wahadłowej”, biegają chaotycznie do okoła przez około 30 sekund, wyjąc oraz wydalając mocz i kał, następnie przeskakują przez barierę, odkrywając, że po drugiej stronie jest bezpiecznie. Po kilku dalszych próbach psy te uczą się całkowicie unikać wstrząsu, przeskakując barierkę, gdy tylko zostaną włożone do pierwszego pomieszczenia.
A jak zachowywały się psy, które doświadczyły poprzednio wstrząsów w aparaturze pawłowskiej? Początkowo reagowały tak samo jak psy niedoświadczone, wyjąc, biegając dookoła itd., lecz następnie przestawały reagować, kładły się i skomlały, cicho, znosząc działanie silnych, traumatycznych impulsów elektrycznych. Nie uczyły się przeskakiwania barierki dla uniknięcia wstrząsu, lecz biernie godziły się doznawać go.  Nawet gdy jeden z tych psów przeskoczył pewnego razu barierkę, co pozwoliło mu uciec od wstrząsu, wzmocnienie to nie zmieniło jego późniejszego zachowania: w następnej próbie po prostu pozostał w pierwszym pomieszczeniu, znosząc przez całe 50 sekund traumatyczne działanie pulsującego prądu. 
Ta |wyuczona |bezradność ma dodatkowe, dość dramatyczne efekty uboczne.  Takie „przystosowanie” nie tylko jest nieprzystosowawcze z tego względu, że uprzednie doświadczenie bezradności hamuje potrzebne reakcje, lecz ponadto cierpi na tym fizjologiczne funkcjonowanie organizmu: zwierzęta tracą apetyt, ubywa im na wadze, wreszcie mogą rozwinąć się wrzody żołądka.  Seligman stwierdził, że gdy psy raz nauczyły się bierności, potrzebowały wielu doświadczeń (aż do 200), polegających na przeciąganiu ich siłą z pomieszczenia „wstrząsowego” do bezpiecznego, aby odkryć ponownie, iż reagowanie może przynieść ulgę i w ten sposób pozbyć się wyuczonego zespołu bezradności.
W Rozdziale 9 omówimy wyuczoną bezradność bardziej szczegółowo, łącznie z wyuczoną bezradnością u ludzi. Przedstawimy także nowsze prace Seligmana poświęcone „terapii prewencyjnej”, w której jednostkę można „zaszczepić” przeciw wyuczonej bezradności przez uprzedni trening panowania nad otoczeniem.


Streszczenie rozdziału

Każdy organizm, aby przetrwać, musi mieć zdolność uczenia się: a) jakie zjawiska w środowisku są ze sobą związane, b) jak jego własne działania wpływają na zdarzenia środowiskowe oraz jaki wpływ mają te zdarzenia na jego zachowanie. Taka wiedza pozwala organizmowi dokonywać przewidywań dotyczących przyszłych zdarzeń oraz wykorzystywać środowisko do zaspokajania swych potrzeb.
Bodziec, który regularnie wywołuje daną reakcję jeszcze przed uczeniem się, nosi nazwę |bodźca |bezwarunkowego (S). Bodziec obojętny, który wielokrotnie występuje tuż przed pojawieniem się bodźca bezwarunkowego, uzyskuje zdolność wywoływania tej reakcji, stając się w ten sposób |bodźcem |warunkowym (S). Proces ten nazywa się |warunkowaniem |reaktywnym lub |warunkowaniem |klasycznym. W tym typie uczenia się jeden bodziec zaczyna zastępować inny, stając się sygnałem, że zbliża się |zdarzenie |przyjemne (np. pokarm) lub |zdarzenie |awersyjne, przykre (np. wstrząs elektryczny).  Reakcja, którą początkowo wywołuje niejako automatycznie bodziec bezwarunkowy, nosi nazwę |reakcji |bezwarunkowej ®. |Reakcja |warunkowa ®, wywoływana przez pierwszy sygnał, może być bardzo podobna do R, lecz też może mieć dodatkowe komponenty. Nie tylko bodźce fizyczne, lecz także słowa i inne symbole mogą stać się bodźcami warunkowymi.
W sytuacji warunkowania występuje zgeneralizowany wzrost |pobudliwości.  Najkorzystniejszy |odstęp |czasowy między pojawieniem się S i pojawieniem się S wynosi pół sekundy. Zwykle zachodzi |generalizacja bodźca, w wyniku której nie tylko sam właściwy bodziec warunkowy, lecz także inne bodźce, nieco do niego podobne, również wywołują tę reakcję. Gdy kontynuuje się próby, w których wzmocnienie następuje tylko po właściwym S, organizm zaczyna reagować tylko na właściwy bodziec i wykonuje tylko poprawną reakcję, w wyniku |różnicowania oraz |hamowania |reakcji |rywalizujących.  Może też zachodzić |warunkowanie |wyższego |rzędu, w którym nie bodziec bezwarunkowy, lecz warunkowy służy jako wzmocnienie przy tworzeniu się związku drugiego rzędu. |Wygaszanie, spowodowane aktywnym hamowaniem dawnej reakcji, zachodzi po okresie warunkowania, w sytuacji, gdy bodziec bezwarunkowy regularnie |nie następuje po bodźcu warunkowym. Gdy po długotrwałym ćwiczeniu wygaszającym nastąpi okres odpoczynku, wówczas może dojść do |samorzutnego |odnowienia się tej reakcji. |Siłę |warunkowania można mierzyć |odpornością |na |wygaszanie, jak również |amplitudą |reakcji, |częstością |reakcji lub |czasem |utajenia (latencją) |reakcji. W |pseudowarunkowaniu zmienia się siła reagowania, lecz nie zachodzi rzeczywiste uczenie się.
Uprzednie warunkowanie może pozostawić niekorzystne i często nieuświadamiane ślady. W wypadku |schizokinezy, części składowe reakcji warunkowej (np. zmiany tempa pracy serca) utrzymują się, chociaż zasadnicza reakcja mięśniowa czy gruczołowa została wygaszona. Przejadanie się może być wynikiem |uwarunkowanego |nałogu jedzenia. Gdy warunkowane zwierzę zmusza się, by dokonywało coraz subtelniejszych różnicowań, różnicowanie warunkowe wytworzone pierwotnie może zaniknąć i mogą się pojawić symptomy „nerwicowe”, zjawisko to znane jest jako |nerwica |eksperymentalna.
Każdym bodźcem, który organizm jest w stanie spostrzec, można się posłużyć do wywołania reakcji warunkowej w każdym mięśniu czy gruczole przy zastosowaniu procedur warunkowania reaktywnego.
Warunkowanie oparte na konsekwencjach danego zachowania badał jako pierwszy E. L. Thorndike na głodnych kotach zamykanych w skrzynkach problemowych. W tym wypadku zachowanie ma charakter |instrumentalny, to znaczy |służy |do |osiągnięcia |celu; jest ono |wytwarzane (emitowane) przez organizm, a nie |wywoływane przez bodziec, a wzmocnienie podaje się tylko wtedy, jeśli zostanie wykonana określona reakcja. Dla wyjaśnienia warunkowania instrumentalnego Thorndike postulował wprowadzenie |zmiennych |pośredniczących, takich jak |stany popędowe, |hierarchie |reakcji i |sygnały, a także zaproponował |prawo efektu, zgodnie z którym poczucie zadowolenia, pojawiające się po skutecznej reakcji, sprawia, iż za następnym razem wykonanie tej reakcji jest bardziej prawdopodobne.
Clark Hull podjął próbę sformułowania ogólnej teorii uczenia się opartej na zasadzie |redukcji |popędu; według tej teorii uczenie się polega na tworzeniu prostych związków bodziec-reakcja. Tolman natomiast opracował teorię o szerszym zakresie, traktującą uczenie się jako |proces |celowy, w którym zachodzą zmiany o charakterze poznawczym.
B. F. Skinner, pionier w dziedzinie |eksperymentalnej |analizy |zachowania, oraz jego zwolennicy utrzymują, że uczenie się można i należy opisywać wyłącznie w kategoriach dającego się obserwować zachowania.  Prowadzą oni badania nad |warunkowaniem |sprawczym, również opartym na konsekwencjach, w którym mierzy się |tempo reagowania, a nie występowanie nowych reakcji. Reakcją w tym kontekście może być pojedynczy akt behawioralny lub określona liczba aktów behawioralnych wzmacnianych jako grupa (np. 100 naciśnieć dźwigni). |Czynnik |wzmacniający definiuje się operacyjnie jako każde zdarzenie bodźcowe, po którym wystąpienie reakcji staje się bardziej prawdopodobne.
|Bodziec |dyskryminacyjny (S) jest to bodziec, który sygnalizuje dostępność czynnika wzmacniającego; w jego obecności tempo reagowania wzrasta. |Negatywny |bodziec |dyskryminacyjny (S) powoduje obniżenie tempa reagowania. Bodziec dyskryminacyjny sam może stać się wzmocnieniem; mówi się wówczas, że |jest |on |warunkowym |lub |wtórnym |czynnikiem |wzmacniającym.
Między reakcją a czynnikiem wzmacniającym może występować pięć rodzajów zależności. Tempo reagowania |wzrasta, gdy po reakcji następuje |pozytywny bodziec wzmacniający, gdy możliwa jest |ucieczka od bodźca awersyjnego lub jego |uniknięcie, tempo to maleje, gdy po reakcji następuje bodziec awersyjny (|kara) lub brak bodźca (wygaszanie). Związki |magiczne występują wtedy, gdy dana jednostka zakłada istnienie związku między bodźcem a reakcją, który w rzeczywistości nie istnieje.
|Kara jest to podanie bodźca awersyjnego, który |zmniejsza prawdopodobieństwo wystąpienia reakcji. Chociaż kara może być skuteczna w pewnych okolicznościach, trzeba ją stosować ostrożnie, jeśli |nie ma pociągnąć za sobą niepożądanych konsekwencji. Powinno się dać wyraźnie do zrozumienia, że karze się reakcję, a nie osobę.
Tempo reagowania rejestruje się na urządzeniu do kumulatywnego rejestrowania: im szybsze tempo, tym bardziej stroma będzie |kumulatywna |krzywa |reakcji. Gdy reakcja została już wyuczona, można ją podtrzymywać za pomocą |wzmocnienia sporadycznego. Cztery główne rodzaje rozkładów wzmacniania sporadycznego to rozkład według |stałych |proporcji, |zmiennych proporcji, rozkłady o |stałych |odstępach |czasowych i |zmiennych |odstępach |czasowych; każdy z nich prowadzi do charakterystycznego wzorca reagowania. Im szybciej podawane i bardziej konkretne jest wzmocnienie, tym skuteczniej zwiększa ono tempo reagowania.
Ponieważ czynniki wzmacniające mogą oddziaływać tylko na te reakcje, które już występują, trzeba było obmyślić specjalne sposoby wywoływania pierwszej reakcji. Do tych sposobów należy zwiększanie motywacji, zmniejszanie zahamowań, strukturalizacja otoczenia, stosowanie przymusu, dostarczanie modelu, udzielanie wskazówek, nakłanianie do prób i błędów i nagradzanie kolejnych przybliżeń (|kształtowanie |reakcji). Dzięki |wiązaniu zachowań można nauczyć badanego osobnika sekwencji reakcji, w której bodziec dyskryminacyjny dla jednego kroku staje się |warukowym |czynnikiem |wzmacniającym dla kroku poprzedniego.

Reasumując, w warunkowaniu reaktywnym występują mimowolne reakcje biologiczne, które są |wywoływane przez prezentację bodźca. Mogą tu wchodzić w grę zależności S-S, R-R lub S-R.
W warunkowaniu sprawczym występują reakcje dowolne, |wytwarzane przez organizm, po których następuje bodziec wzmacniający; tak więc wchodzą tu w grę zależności R-S.
Wielu wyników współczesnych badań nad warunkowaniem nie można zaliczyć jednoznacznie do jednej z tych kategorii; wykazano na przykład, że możliwe jest warunkowanie sprawcze czynności narządów wewnętrznych (reakcji odruchowych), takich jak „czerwienienie się”. Z drugiej strony, w tak zwanym |samokształtowaniu zachodzi warunkowanie reaktywne zachowania sprawczego. Specyficzne dla danego gatunku właściwości mogą wpływać na proces uczenia się w naturalnym środowisku zwierzęcia. Jako przykłady można wymienić |tendencję |instynktowną, |ostrożność |wobec |przynęty oraz |wdrukowanie. Uprzednie uczenie się również może powodować ograniczenia warunkowania, na przykład |wyuczona |bezradność może prowadzić do biernego „poddawania się losowi” w sytuacjach stresowych.


Z Frontu Badań.
Samowzmacnianie: zdolność sprawowania pozytywnej wewnętrznej kontroli nad samym sobą

|Albert |Bandura „Stanford University”


W jaki sposób można wyjaśnić zmienność, spójność i złożoność funkcjonowania człowieka? Od dawna wysuwa się wiele różnych teorii mających wyjaśnić, dlaczego ludzie zachowują się tak, jak się zachowują, i sugerujących, jak można by zmienić ich zachowanie. Poszczególne teorie koncentrują się zwykle na jednej kategorii zjawisk, przy jednoczesnym ignorowaniu innych. Przyjęta przez badacza koncepcja decyduje ponadto o tym, w jaki sposób zbiera on materiał dowodowy, ten materiał zaś kształtuje z kolei jego teorię.
Od pewnego czasu niektórzy teoretycy prezentują pogląd, że głównymi przyczynami zachowań są czynniki |motywacyjne działające „wewnątrz” danej jednostki. Te wewnętrzne determinanty - potrzeby, popędy i impulsy - nie są obserwowalne bezpośrednio, lecz wnioskuje się o nich z zachowań, które rzekomo powodują. Czynność jedzenia uznaje się za dowód występowania popędu głodu, zachowanie zorientowane na osiągnięcia ma świadczyć o istnieniu popędu osiągnięć, eksploracja środowiska ma być motywowana przez popęd ciekawości i tak dalej. W psychodynamicznych teoriach zachowania, zwłaszcza w teorii freudowskiej, przyjmuje się, że siły motywacyjne działają poniżej poziomu świadomości i niekiedy prowadzą do zachowań będących przeciwieństwem tych, których można by oczekiwać. W wyniku działania rzekomych mechanizmów pozorowania reakcji (reaction formation) intensywny popęd agresji może zatem prowadzić do bierności, zamiast do agresywnego działania.
Takie koncepcje motywacji poddano krytyce zarzucając im, że nie umożliwiają przewidywania, że opisują zamiast wyjaśniać, że nie nadają się do weryfikacji eksperymentalnej i że nie uwzględniają ogromnej złożoności ludzkich reakcji. Najważniejszą rywalką tych koncepcji jest |teoria |zachowania, która w poszukiwaniu wyznaczników zachowania odstąpiła od studiowania mglistych stanów wewnętrznych na rzecz szczegółowego badania zewnętrznych czynników oddziałujących na zachowanie człowieka. Każde zachowanie można analizować w kategoriach zewnętrznych warunków bodźcowych, które je wywołują, oraz zewnętrznych warunków wzmacniających, które je podtrzymują. Przeprowadzono wiele badań potwierdzających pogląd, że zachowanie ludzkie jest regulowane zewnętrznie. Empiryczny sukces podejścia opartego na warunkowaniu sprawczym skłonił wielu psychologów do odrzucenia poglądu, że zachowanie człowieka jest determinowane przez czynniki działające wewnątrz danej jednostki. Przeciwnie - kładą one nacisk na władzę, jaką nad zachowaniem człowieka mają czynniki środowiskowe.  Radykalny behawioryzm został jednakże odrzucony przez wielu badaczy, którzy odmawiają uznania ludzi za bierne istoty kontrolowane przez wszechmocne środowisko. Zwolennikom teorii zachowania zarzuca się ponadto, że nie chcą uznać doniosłego wpływu funkcji poznawczych na zachowanie człowieka.
Jeszcze inne podejście, z którym się tutaj zapoznamy, reprezentuje |teoria |uczenia |się |społecznego (zob. Bandura, 1976a, b), według której zachowanie, czynniki osobowe oraz czynniki środowiskowe determinują się nawzajem. Jest prawdą, że środowisko wpływa na zachowanie, lecz środowisko to jest po części tworem ludzi. Nie można również uważać, że sami ludzie są niezależną przyczyną własnego zachowania. Głównie w wyniku swych działań ludzie kształtują warunki środowiskowe, które z kolei wpływają na ich zachowanie. Doświadczenia, które są produktami zachowania, również po części decydują o tym, kim dana osoba się staje i co potrafi zrobić, a to z kolei wpływa na jej późniejsze zachowanie. Względna siła oddziaływań, wywieranych przez te uzależnione od siebie nawzajem czynniki, jest różna dla różnych środowisk i różnych zachowań. Niekiedy czynniki środowiskowe są głównymi determinantami zachowania, bez względu na osobiste postawy, wartości czy uprzednie doświadczenia danej jednostki. Kiedy indziej, czynniki osobowe biorą górę nad wpływami środowiska.

Taka koncepcja funkcjonowania człowieka nie skazuje ludzi na rolę istot bezradnych wobec miotających nimi sił wewnętrznych ani też biernych istot popychanych przez bodźce środowiskowe. Uważa się, że ludzie mogą w pewnym stopniu sprawować kontrolę nad swym własnym zachowaniem. Bodźce środowiskowe często wywierają swój wpływ za pośrednictwem procesów poznawczych, dzięki którym ludzie definiują zdarzenia bodźcowe, interpretują je, porównują, przeciwstawiają sobie, nadają im znaczenie i integrują je. Ludzie zapamiętują okoliczności, w których po ich zachowaniu następowało wzmocnienie, a także to, jak często to wzmocnienie występowało; po pewnym czasie potrafią identyfikować taki układ wzajemnych uwarunkowań.  Ta zdolność integrowania doświadczeń opiera się na umiejętnościach poznawczych.
Orientacja poznawcza skłania zwolenników teorii uczenia się społecznego do badania pomijanych dotąd aspektów uczenia się, takich jak uczenie się obserwacyjne, uczenie się symboliczne oraz procesy samoregulacji. Liczne zachowania, niezbędne dla rozwoju i przetrwania, nabywane są nie w drodze żmudnych prób i błędów, lecz raczej dzięki |obserwacji zachowania modeli, a także konsekwencji tych zachowań dla samych modeli. W swych stosunkach z innymi osobami i w stosunkach ze swym środowiskiem ludzie często posługują się |symbolami. Symbole słowne i wyobrażeniowe są różnego rodzaju reprezentacjami, które pozwalają nam przetwarzać, przechowywać w pamięci i przywoływać doświadczenia mogące służyć nam za wskazówki dla przyszłych działań. Ta poznawcza zdolność posługiwania się symbolami pozwala uczniowi wyobrażać sobie alternatywne konsekwencje różnych działań; sprawdzać rozwiązania problemów w myśli i wcielać w życie abstrakcyjne idee, takie jak „wolność”, „godność”, „patriotyzm” i wiele innych.
Jedną z najbardziej charakterystycznych cech teorii uczenia się społecznego jest ponadto nadawanie dużego znaczenia |zdolnościom |samoregulacyjnym. Ludzie potrafią sami wytwarzać czynniki środowiskowe pobudzające ich do działania, wykorzystywać operacje poznawcze umożliwiające im dokonanie wyboru takiego a nie innego kierunku działania, a następnie dostarczać sobie wzmocnienia za wykonanie takich działań.
|Samowzmacnianie (self-reinforcement) zajmuje ważne miejsce wśród różnych badanych przez nas procesów samokontroli. Jednostki regulują swe zachowania nagradzając się za osiągnięcia wyznaczonych przez siebie standardów wykonania. Wyniki badań nad procesami samoregulacji wywierają znaczny wpływ na programy terapeutyczne mające na celu doprowadzenie do zmian osobowościowych. Tam, gdzie zwykle kładziono nacisk na „kierowanie” zachowaniem przez wytwarzanie zależności od bodźców, obecnie przechodzi się do rozwijania umiejętności w zakresie samoregulacji. Kontrolę nad zachowaniem przekazuje się samym zainteresowanym jednostkom, a nie terapeutom, instruktorom, nauczycielom, badaczom czy też innym „czynnikom dokonującym zmian”. Jednostki, ustanawiając swe własne cele, sprawdzają uzyskiwane przez siebie czynniki, oceniają je w kategoriach ustalonych kryteriów, a następnie decydują o dostarczeniu lub niedostarczeniu sobie bodźców wzmacniających.
Czym jest samowzmacnianie? Polega ono na tym, że dana jednostka sprawuje pełną kontrolę nad dostarczeniem sobie dostępnych czynników wzmacniających, lecz nie korzysta z nich, dopóki nie osiągnie wyznaczonego przez siebie standardu wykonania. Wyniki, które dorównują tym standardom lub przewyższają je, służą jako sygnały dyskryminacyjne do samonagradzania się; wszystkie inne są sygnałami dla niewzamcniania. Te standardy wykonania przyjmują zwykle postać a) pewnego |bezwzględnego |poziomu wykonania (takiego jak 90% poprawnych odpowiedzi w teście lub uzyskania ponad 200 punktów w kręglach), b) własnego |poprzedniego |standardu |osobistego (np.  zmniejszenie liczby wypalanych w ciągu dnia papierosów lub zwiększenie szybkości czytania o określoną wielkość) lub c) |standardu |społecznego, czyli wyników osiąganych przez inne osoby (np. uzyskanie w teście wyniku równie dobrego lub lepszego niż ten, który uzyskał twój najlepszy przyjaciel).
Standardy te decydują o |użyciu samowzmocnienia, co należy odróżnić od |procesu, w którym konsekwencje zewnętrzne wpływają na zachowanie. Główne różnice między wzmocnieniami kontrolowanymi zewnętrznie a tymi, które samemu się reguluje, występują przed przyznaniem nagród. Gdy już dany standard został osiągnięty i nagroda przydzielona, wówczas źródło tej nagrody nie ma znaczenia. Proces wzmacniania przebiega w taki sam sposób.
W celu zbadania, kiedy i jak jednostki decydują się nagradzać siebie i czy te przyznawane przez siebie samego nagrody istotnie wpływają na zachowanie, przeprowadza się dwa rodzaje eksperymentów. W pierwszej kategorii badań |zmiennymi |niezależnymi są wszystkie te czynniki (takie, jak np. zachowanie modeli), które prawdopodobnie wpływają na standardy ustanawiane jako warunek przydzielania sobie nagrody. |Zmiennymi |zależnymi są rzeczywiste wyniki działań, za które dane jednostki same się nagradzają lub karzą. W badaniach drugiego rodzaju stawia się pytanie, czy nagrody i kary wymierzane przez siebie samego istotnie podnoszą poziom wykonania? W tym paradygmacie |zmiennymi |niezależnymi są stosowane wobec siebie samego konsekwencje, a |zmiennymi |zależnymi są poziomy wykonania.
Rozpatrzymy teraz pokrótce, w jaki sposób standardy wykonania są nabywane i generalizowane na różne czynności, a następnie przejdziemy do analizy warunków, w których zasady samowzmacniania ulegają czasowemu zawieszeniu.
Standardy behawioralne, służące do określania, kiedy przyznanie sobie nagrody jest uzasadnione, ustalane są w wyniku dwóch procesów, |modelowania oraz oceniania konsekwencji. Wpływ modeli na przekazywanie standardów samonagradzania zademonstrowano w wielu badaniach. W typowych sytuacjach badane dzieci obserwują modele wykonujące pewne zadania, w których modele te przyjmują albo wysokie, albo niskie standardy wykonania jako warunek dla przyznania sobie nagrody. Gdy standard zostaje osiągnięty lub przekroczony, wówczas modele nagradzają i chwalą siebie; gdy nie udaje się im osiągnąć standardu, wówczas powstrzymują się od wzięcia dostępnych nagród i same się krytykują. Gdy dzieciom, które obserwowały tę sytuację, pozwoli się później wykonywać takie samo zadanie i same siebie nagradzać, to są one skłonne przyjmować standardy przyjmowane uprzednio przez modele, oceniając swe wyniki według tych standardów i stosownie do nich się nagradzać (Bandura i Kupers, 1964). Preferowanymi modelami odniesienia są zwykle te, których możliwości zwykle oceniane są jako podobne do własnych, a nie modele o znacznie wyższych lub niższych możliwościach. Jednakże w specjalnych warunkach obserwatorzy mogą przyjąć surowe standardy samonagradzania (stosowane przez wybitne modele), nawet jeśli oni sami rzadko osiągają te wysokie standardy. Aby ukształtować takie „wzniosłe ideały”, obserwatorowi trzeba prezentować jednolicie wysokie standardy, musi istnieć właściwy stosunek między modelami i obserwatorem, a ponadto model musi być obdarzany publicznym uznaniem za „dążenie do doskonałości” (Bandura, Grusec i Menlove, 1967).
Trzeba wspomnieć na marginesie, że przyswajanie standardów jest w życiu codziennym skomplikowane z powodu niekonsekwencji standardów różnych modeli lub tego samego modelu w różnych okolicznościach, albo też z powodu sprzeczności między standardami głoszonymi a standardami stosowanymi w rzeczywistości. Ta ostatnia przyczyna często występuje w sferze zachowań moralnych i uprzedzeń.
Zależność pomiędzy przenoszeniem standardów wykonania a zróżnicowanymi skutkami działań badano jedynie na zwierzętach (Bandura i Mahoney, 1974).  Po ustaleniu podstawowych standardów dla przyznawania sobie nagrody oraz negatywnych konsekwencji za niewystarczające wykonanie stopniowo podnoszono wymagania. Zwierzęta przyjmowały coraz wyższe standardy wykonania, jako warunek przydzielenia sobie nagrody, a następnie standardy te generalizowały nawet na nieznane sobie zadania.
Generalizacja standardów wykonania jest ważnym aspektem samonagradzania.  Niepowodzenie wielu terapeutycznych i eksperymentalnych programów treningowych, zmierzających do wyeliminowania złych nawyków: przejadania się, narkomanii, alkoholizmu czy palenia papierosów, można w istocie przypisać nieudanej generalizacji abstynencji w sytuacji treningowej na różne codzienne sytuacje, jakie napotyka dana osoba. Sądzę, że zasadniczym celem rozwoju społecznego jest przekazywanie ogólnych standardów postępowania, które mogą służyć jako wskazówki dla samoregulacji zachowania podczas najrozmaitszych czynności. Te generalizowane standardy najlepiej przekazuje się zmieniając charakter określonych czynności oraz warunki środowiskowe, wymagając jednocześnie osiągnięcia podobnego poziomu wykonania przed przyznaniem sobie nagrody.
Gdy ludzie nauczą się już ustanawiać dla samych siebie standardy i oceniać swe własne zachowanie, wówczas mogą wpływać na siebie za pośrednictwem wytwarzanych przez siebie samych konsekwencji. Wyniki licznych badań wskazują, że ludzie potrafią przez długi czas samodzielnie udoskonalać swe zachowania lub też powstrzymywać się od ich podejmowania równie dobrze lub lepiej niż wówczas, gdy inni stosują nagrody w celu nakłonienia ich do zmiany zachowania. Rozwój zdolności do samokontroli daje ludziom możliwość kierowania sobą.
Kontrola wewnętrzna ustanowiona za pośrednictwem wytwarzanych przez siebie samego konsekwencji nie działa w sposób niezmienny i sztywny.  Kontrola wewnętrzna może ulec czasowemu zawieszeniu, a naganne postępowanie można samemu zaakceptować i uczynić je akceptowanym społecznie, przedstawiając je jako służące moralnym celom lub aranżując warunki środowiskowe w taki sposób, aby zaciemnić lub zniekształcić związek między danymi działaniami a ich skutkami (rzucanie bomb napalmowych i nieoglądanie palących się ciał).
Ludzie potrafią angażować się w potępianie działania - niemoralne, bezprawne, złe - nie zmieniając swych standardów moralnych ani systemów samowzmacniania, ponieważ wymierzane przez siebie samego konsekwencje mogą zostać wybiórczo zawieszone w wyniku dehumanizacji osób, przeciwko którym skierowane są dane działania, błędnego spostrzegania lub błędnego przedstawiania związku między działaniami a ich konsekwencjami oraz wynajdywania moralnych usprawiedliwień dla negatywnego postępowania. Gwałty popełniane przez żołnierzy w wojennych starciach z „wrogiem” lub „żółtkami w My Lai”, w zestawieniu z ich postępowaniem w kraju ojczystym w czasie pokoju, są godnym uwagi przykładem tego procesu.
Należy również zdawać sobie sprawę z tego, że wiele tak zwanych systemów nagród zewnętrznych, które zachęcają do zachowania prospołecznego, jest w istocie tworem człowieka: systemy ocen, schematy awansów, uznanie dla osób o szczupłych figurach - nie są zadekretowane przez autonomiczne i bezosobowe środowisko. Istnieje zatem wzajemne oddziaływanie między systemami nagród generowanych przez siebie samego i przez środowisko, w którym to oddziaływaniu człowiek i środowisko przekształcają się nawzajem.  Podczas poszukiwania pierwotnych przyczyn, dla każdej kury, odkrytej przez wyznawcę teorii jednokierunkowego oddziaływania środowiska, zwolennik teorii uczenia się społecznego potrafi znaleźć jajko, które było pierwsze.
I wreszcie w teorii uczenia się społecznego trzeba docenić rolę motywacji. Wzmocnienie regulowane przez siebie samego podnosi poziom wykonania głównie dzięki swej funkcji motywacyjnej. Uzależniając samonagradzanie od osiągnięcia pewnego poziomu wykonania, jednostki same stwarzają dla siebie zachętę, aby wytrwać w swych staraniach, dopóki wyniki nie dorównają ustalonym standardom. Wzmocnienie zewnętrzne również spełnia przede wszystkim funkcję motywacyjną, a nie służy tylko jako mechaniczny czynnik wzmacniający reakcję. Jeśli wykonując pewne czynności jednostka może uzyskać cenione nagrody, to jest ona motywowana przez te nagrody do podejmowania owych czynności. Z perspektywy teorii uczenia się społecznego, lepiej jest zatem mówić o |regulacji zachowania przez jego konsekwencje dla podmiotu niż o „wzmacnianiu”.

Literatura

|Bandura |A. „Social learning theory”. Englewood Cliffs, N. J. 1976a, Prentice-Hall.
|Bandura |A. „Seff-reinforcement: theoretical and medthodological considerations” „Behaviorrism” 1976b.
|Bandura |A., |Grusec |J. |E., |Menlove |F. |L. „Some social determinants of self-monitoring reinforcements systems”. „Journal of Personality and Social Psychology” 1967, 5, 449-455.
|Bandura |A., |Mahoney |M. |J. „Maintenance and transfer of self-reinforcements” „Behaviour Research and Therapy” 1974, 12, 89-97.
|Bandura |A., |Kupers |C. |J. „Transmission of patterns of self-reinforcement through modeling” „Journal of Abnormal and Social Psychology” 1964, 69, 1-9.




II. Przetwarzanie informacji przez człowieka

4. Język, komunikowanie się i pamięć
5. Myślenie, rozumowanie i twórczość


Rozdział 4.
Język, komunikowanie się i pamięć


Zapoznajmy się z następującym zapisem z posiedzenia eksperymentalnego przeprowadzonego w laboratorium badań hipnotycznych. Jakie nasuwa on pytania dotyczące funkcji języka? natury pamięci? (Odłóż na chwilę pytania co do samej hipnozy; temat ten rozpatrzymy dokładnie w jednym z dalszych rozdziałów).

Hipnotyzer: „Dzisiaj są twoje urodziny, Chuck. Cofasz się w czasie, stajesz się coraz młodszy, znów masz tylko pięć lat. Możesz zobaczyć, jak lata na twoim „osobistym” kalendarzyku znikają, w miarę, jak powoli czujesz się coraz młodszy; nie masz już swoich osiemnastu lat. Stajesz się młodszy, szesnaście... czternaście... dwanaście... dziesięć... lat... osiem...  siedem... sześć... a teraz |jesteś małym pięcioletnim chłopcem i to jest twoje przyjęcie urodzinowe! Masz teraz tylko pięć lat i jesteś na swoim własnym przyjęciu urodzinowym”.

„Chuck: „Oooo, Mami! Que linda! Que torta mas grande y tantas velas! Hay uno, dos, tres, cuatro, cinco, y uno mas para darme mi deseo especial.  Quiero, quiero... una hermanita. Pero, como voy a tener mi deseo si no puedo decirselo a nadie? Puedo, puedo Mami? Puedo hacer lo que me prometiste? Puedo meter un dedo en la torta para sacar la crema? Huii (...) („Och, Mamusiu, jaki piękny, jaki wielki tort, i tak dużo świeczek, jest jedna, dwie, trzy, cztery, pięć i jeszcze jedna, aby spełnić moje specjalne życzenie. Ja chcę, chcę... siostrzyczkę. Ale jak spełni się moje życzenie, jeśli nie mogę nikomu powiedzieć? Czy mogę, czy mogę, Mamusiu? Czy mogę zrobić to, co obiecałaś? Czy mogę wsadzić palec w tort i wydłubać krem?  Eee...”))

Hipnotyzer: „Teraz Chuck jeszcze raz będziesz stawał się młodszy.  Będziesz mógł słyszeć mnie i rozumieć, co mówię, lecz wkrótce będziesz miał tylko sześć miesięcy. Będziesz mieć sześć miesięcy, dopóki nie poklepię cię po ramieniu, a wtedy szybko wrócisz do tego wieku, w jakim byłeś, gdy przyszedłeś do laboratorium badań hipnotycznych. Znów będziesz mieć osiemnaście lat i będziesz studentem college’u zdolnym przypomnieć sobie i opisać wszystkie swoje przeżycia związane z cofaniem się w czasie. Teraz te lata zostają usunięte z twojego kalendarza: masz pięć lat, cztery...  trzy... stajesz się coraz młodszy, teraz dwa... teraz rok, a zaraz będziesz tylko małym niemowlęciem, leżącym w swoim łóżeczku i nakrytym miękkim, ciepłym kocykiem. Rozkosznym, miłym sześciomiesięcznym niemowlęciem. Miły dzidziuś. Tatuś kocha swojego dzidziusia. Dobry dzidziuś”.


Zapiski obserwatora: „Badany leży na podłodze laboratorium, zwija się w kłębek, kciuk w ustach, ślina ścieka z kącika ust, uśmiecha się... zaciska pięści, wyraz napięcia na twarzy, klęka, gwałtowny ruch kołysania się, wielokrotnie podrzuca głową ku przodowi, nieco powyżej rąk. Zdaje się płakać bezdźwięcznie. Hipnotyzer mówi badanemu, że jest karmiony. Matka karmi go ciepłym mlekiem. Przestaje się kołysać, wargi ściągnięte, kładzie się, ręce podniesione blisko ust, przestaje ssać, wszystkie ruchy ustają badany wydaje się pogrążony w głębokim śnie!”.

Informacje zebrane po posiedzeniu hipnotycznym ujawniły, iż student ten - chociaż jego rodzina spędziła kilka lat w Meksyku, gdy był dzieckiem - nie zdawał sobie sprawy z tego, że zna choć trochę hiszpański, i rzeczywiście nie potrafił ani mówić tym językiem, ani zrozumieć go, o ile nie był pod hipnozą. Jego matka przypomniała sobie, że przez pewien czas Chuck, gdy był niemowlęciem, kołysał się niekiedy w swym łóżeczku, uderzając głową o jego boki.

Na przykładzie tym możemy się przekonać, że język najwyraźniej ma zdolność do tworzenia wyobrażeń, które mogą zastępować przedstawione przez nie rzeczywiste zdarzenia. Oddziaływanie to może być silniejsze pod hipnozą, lecz to samo zjawisko występuje w pewnym stopniu za każdym razem, gdy dobra powieść zupełnie cię „pochłonie”. Wyobrażenia takie mogą służyć nie tylko do odtwarzania przeszłości, lecz także jako pomost do przyszłości. Marzenia na temat „kim będę”, przewidywane nagrody i przykrości, oczekiwania i stawiane sobie cele nadają naszemu zachowaniu możliwy do przewidzenia kierunek. W niektórych kulturach wiara w słowa przekleństwa, wypowiedziane przez potężnego czarownika, może spowodować chorobę i w końcu nawet śmierć (zob. Rozdział 9).
Chociaż język służy zarówno do strukturalizowania rzeczywistości, jak do pobudzania fantazji, może on także stać się przeszkodą w pełnym przeżywaniu emocji, gdyż pozwala nam zastępować rzeczywiste uczucia słownymi opisami tego, co czujemy (lub powinniśmy czuć). Językiem można się więc posługiwać dla uzyskania analitycznego dystansu w stosunku do kłopotliwych doznań, przez nadanie im jakiejś etykietki, podanie wyjaśnienia i ujęcie w kategoriach czasowych, przez co wpycha się je niejako w swoistą „niszę historyczną”.

Zahipnotyzowana osoba, która „cofa się w latach”, często zaczyna od obserwowania i bezgłośnego komentowania przeszłych wydarzeń, które rozgrywają się tak, jak gdyby oglądała je na swym prywatnym ekranie kinowym. Tylko wtedy, gdy ów widz zrezygnuje z tej korzystnej pozycji „na dystans” i włączy się w akcję, jego doznania zdają się przechodzić z czasu przeszłego do teraźniejszego, jak w przypadku opisanym powyżej. W takich wypadkach mogą wchodzić w grę pewne aspekty pamięci, z których zwykle nie robimy zbyt dużego użytku. Ponieważ ludzie stali się gatunkiem zdominowanym przez język, przeto słowa stanowią znaczną część tego, co przechowujemy w pamięci, a także odgrywają dużą rolę w procesie wydobywania zmagazynowanej informacji. Są jednak i inne sygnały, które mogą wzbudzać wspomnienia dotyczące dawno minionych zdarzeń, sytuacji i ludzi. Wspomnienia emocjonalne mogą być wywoływane przez bodźce wzrokowe, zapachy lub inne niewerbalne sygnały skojarzone z danym przeżyciem. Na przykład u pewnego mężczyzny w średnim wieku zostało nieoczekiwanie wzbudzone silne poczucie winy, gdy poważnie skręcił sobie nogę w kostce i musiał chodzić o lasce, kulejąc. Zaczął on się czuć tak, jak gdyby był swoim młodszym bratem, który jako dziecko cierpiał na chorobę Heinego-Medina. Równocześnie mężczyzna ów znów doświadczał poczucia winy, które mu dokuczało, gdy widział swego brata utykającego, o kulach, podczas gdy on sam mógł biegać swobodnie - wspomnienie to zostało wzbudzone przez bodźce posturalne i sensoryczne sprzężenie zwrotne od własnego utykania.
Dzięki władaniu językiem ludzie mogą przekazywać mądrość jednego pokolenia następnemu, a dzięki pamięci uczymy się na naszych błędach i wyciągamy korzyści z sukcesów. Skąd jednak bierze się nasza zdolność posługiwania się językiem: czy jest ona wyuczona, czy też stanowi wbudowany w nas wytwór niezliczonych lat ewolucji? Co ujawniły badania psychologiczne - jak zapamiętujemy i jak (co zdarza się stanowczo zbyt często) zapominamy?  Oto jedynie nieliczne spośród tych zagadnień, którymi zajmiemy się rozpatrując szczytowe osiągnięcia naszego gatunku: niewiarygodny wręcz system języka i porozumiewania się oraz godny uwagi system przechowywania i odzyskiwania tego, czego doświadczyliśmy i czegośmy się nauczyli.


Uczenie się języka i posługiwanie się nim


„Kotki mają ten bardzo niedogodny zwyczaj (zauważyła pewnego razu Alicja), że cokolwiek im powiesz, one zawsze mruczą. „Gdyby mruczały tylko zamiast „tak””, a miauczały zamiast „nie””, lub według jakiejś podobnej zasady”, powiedziała Alicja, „wtedy można byłoby prowadzić rozmowę. Lecz jak możesz rozmawiać z kimś, kto zawsze mówi to samo?”
Lewis Caroll „Through the Looking Glass”, 1871 (wyd. pol. „O tym, co Alicja odkryła po drugiej stronie lustra”)

„Musimy się lepiej porozumieć”. Wypowiedzi tego rodzaju stały się bardzo częste w ostatnich latach, co po części jest wynikiem rosnącego wpływu „grup spotkaniowych” (encounter groups) i grup treningu wrażliwości, których członkowie uczą się, jak odnosić się do innych ludzi. Co jednak właściwie mamy na myśli, mówiąc o „porozumiewaniu się”? W najszerszym znaczeniu „porozumiewanie się” (czyli „komunikowanie się”) jest procesem, dzięki któremu jednostka przekazuje i otrzymuje informacje. Informacjami, które należy przekazać, mogą być fakty, myśli lub uczucia; można je przekazywać różnymi sposobami, na przykład za pomocą mowy, gestów, symboli obrazkowych lub symboli pisma. Gdy ludzie umieją zrobić dobry użytek z tego procesu, wówczas „porozumiewanie się” nabiera dodatkowego znaczenia - umożliwia zbliżenie poglądów i zaciśnienie wzajemnych związków.
Chociaż jest wiele sposobów porozumiewania się, to najważniejszym z nich jest porozumiewanie się werbalne. Wytworzenie wysoce złożonego systemu lingwistycznego, posługiwanie się nim, jest jednym z najwybitniejszych i najciekawszych osiągnięć istot ludzkich i jako takie stało się przedmiotem wielu badań. Najpierw zajmiemy się więc językiem mówionym, a następnie przejdziemy do innych form (zarówno werbalnych, jak i niewerbalnych) porozumiewania się.
Być może największym wyczynem intelektualnym, jakiego dokonuje każda istota ludzka, jest nauczenie się ojczystego języka. Osiągnięcie to ma miejsce w pierwszych paru latach życia, na długo przed rozpoczęciem jakiejkolwiek formalnej nauki. Obecnie może to oczywiście nie wydawać się szczególnie imponujące, ponieważ i ty, i prawdopodobnie wszyscy ludzie, których znasz, osiągnęliście już ten cel. Jeśli jednak zastanowisz się, w jaki skomplikowany sposób łączy się ze sobą tysiące słów, aby utworzyć sensowne wypowiedzi, to niewątpliwie zgodzisz się, że jest zdumiewające, iż małe dziecko potrafi opanować taki system w tak krótkim czasie. W jaki sposób tego dokonuje? Zarówno psycholodzy, jak i lingwiści od dawna szukają odpowiedzi na to pytanie, a ich połączone usiłowania powołały do istnienia nową gałąź nauki - |psycholingwistykę, której domeną są psychologiczne badania nad językiem i mową. Zanim jednak przejdziemy do rozpatrzenia teorii wyjaśniających, w |jaki |sposób dziecko uczy się języka, musimy najpierw zobaczyć, z czego składa się język i zapoznać się z przebiegiem rozwoju mowy u dzieci.


Struktura języka


Na pozór języki ludzkie wydają się nieskończenie zróżnicowane, jednak stosując psycholingwistykę wkrótce dochodzi się do wniosku, że mają one pewne wspólne właściwości. Chociaż więc specyficzne dźwięki, słowa i reguły, które będziemy rozpatrywać w naszych rozdziałach nad językiem, są zaczerpnięte z języka angielskiego, to jednak te same ogólne zasady stosują się do każdego języka.

Poziom analizy lingwistycznej. Jedną z właściwości wspólnych wszystkim językom ludzkim jest podstawowa struktura lingwistyczna - hierarchiczny system budujący z prostych jednostek dźwiękowych jednostki strukturalne, a z nich z kolei - złożone jednostki znaczeniowe.

„Poziom fonologiczny”. Na poziomie fonologicznym interesują nas podstawowe jednostki dźwiękowe, które tworzą „strumień mowy”. |Fonem, jest to klasa dźwięków, które osoby mówiące danym językiem rozpoznają jako posiadające pewne odrębne cechy, wyróżniające je spośród innych dźwięków, i sygnalizujące różnicę w znaczeniu. Na przykład, chociaż brzmienie litery „p” w słowie „pan” (patelnia) nie jest całkowicie identyczne jak w słowie „plan” (plan), to jednak każdy mówiący po angielsku rozpoznałby je jako przypadki tego samego fonemu: („p”). Ponadto osoba mówiąca po angielsku stwierdziłaby wyraźną różnicę między tym fonemem a początkowym dźwiękiem w słowie „ban” (zakaz, potępienie) - to znaczy fonemem („b”). Oczywiście, aby zrozumieć dany język mówiony, trzeba nauczyć się rozróżniać fonemy i dostrzegać ich identyczność.
„Poziom gramatyczny”. Poziom gramatyczny (czyli strukturalny) ma dwa działy: |morfologię i |składnię. |Morfem jest najmniejszą jednostką mowy, która ma określone znaczenie; może być słowem, lub może nim nie być. Na przykład słowo „tigers” (tygrysy) składa się z dwóch morfemów, nazwy zwierzęcia („tiger” - tygrys) i „s”, które wskazuje liczbę mnogą. Słowa można uważać za jednostki mowy, które przekazują znaczenie i które są symbolami pewnych klas przedmiotów, zdarzeń lub czynności.
Reguły |składni (syntaktyczne) określają dopuszczalny porządek, w jakim mogą być ustawione słowa i zwroty tworzące zdanie. Chomsky (1957) przyjął, że podstawowym elementem języka na poziomie syntaktycznym jest proste zdanie oznajmiające w stronie czynnej, które nazwał |zdaniem |jądrowym („kernel sentence”). Temu podstawowemu zdaniu można nadawać różne znaczenia stosując pewne |reguły |przekształcania. Na przykład zdanie podstawowe, takie jak „John hit the ball” (Jan uderzył piłkę) możemy przekształcić w zdanie w stronie biernej „The ball was hit by John” (Piłka została uderzona przez Jana), w zdanie przeczące John „did not hit the ball” (Jan nie uderzył piłki), w zdanie pytające „Did John hit the ball” (Czy Jan uderzył piłkę?) lub w pewne połączenie tych form, takie jak „Wasn’t the ball hit by John?” (Czy piłka nie została uderzona przez Jana?), co jest zdaniem pytająco-przeczącym w stronie biernej. Szczegółowe reguły w rozmaitych językach są różne, lecz pewne aspekty tych przekształceń są wspólne dla języków reprezentujących nawet bardzo odmienne kultury.

„Poziom semantyczny”. Pewne twory lingwistyczne posiadają znaczenie, inne są bezsensowne. Nauka o znaczeniu zwie się |semantyką. Niektóre słowa lub zestawienia słów mają arbitralnie uzgodnione znaczenie (np. słowo psychologia), inne uzyskują znaczenie przez skojarzenia emocjonalne lub poznawcze. Znaczenie słowa zależy także od bezpośredniego kontekstu i od modulacji głosu, z jaką jest wypowiadane, w porównaniu z sąsiednimi słowami. Na przykład proste słowo „run” (biec, płynąć, obracać się, ścigać itd.) ma ponad 20 znaczeń (Ile z nich potrafiłbyś wymienić?). „A white house cat” (biały, domowy kot; kot z białego domu) oznacza co innego, w zależności od tego, na które słowo położymy nacisk. Zdanie „The King is pregnant” (Król jest w ciąży) można uznać za poprawne na poziomie fonologicznym i gramatycznym, lecz jest ono nie do przyjęcia na poziomie semantycznym.

Realność psychologiczna analizy lingwistycznej. Czy te jednostki, poziomy i reguły, rzeczywiście odznaczają się psychologiczną „realnością” dla osoby mówiącej (lub słuchającej wypowiedzi) w swym ojczystym języku? Jedna ze strategii badawczych, które stosują psycholingwiści w celu znalezienia odpowiedzi na to pytanie, polega na tym, że zmienia się jeden element lingwistyczny, a następnie obserwuje się, czy ma to jakiś wpływ na zdolność postrzegania, uczenia się lub pamiętania danej wypowiedzi przez osobę badaną.

„Badania nad fonemami”. Badaczom zajmującym się poziomem fonologicznym udało się ustalić podstawowe fizyczno-akustyczne właściwości, które są niezbędne, aby posłyszeć i rozpoznać fonem. Wypowiadane dźwięki można rejestrować, a następnie przekształcać w zapisy wizualne zwane |spektrogramami. Na spektogramach tych zapisana jest częstotliwość dźwięku (w cyklach na sekundę) oraz czas potrzebny na jego wydanie. Ruth Day i jej współpracownicy w Haskins Laboratories w New Haven opracowali metodę konstruowania na podstawie tych spektogramów uproszczonych, idealnych wzorców dźwięku. Za pomocą specjalnej aparatury można znów przekształcać te idealne wzorce w dźwięk i odtworzyć go słuchaczom, których prosi się, aby podali, co słyszą.

Badacze stwierdzili, że pewne bardzo podobne wzorce słyszane są jako różne fonemy. Innych, bardzo odmiennych wzorców fizycznych słuchacze często |nie odróżniają jako odrębnych fonemów. Wobec faktu, że nie znaleziono jakiegoś jednego wzorca, który odpowiadałby danemu fonemowi (np. 8d8), jeszcze bardziej zadziwiającym jest to, iż słuchacze tak łatwo wyodrębniają fonemy ze strumienia mowy i rozpoznają je.

„Badania nad morfemami”. W języku angielskim morfem liczby mnogiej może być jednym z trzech różnych dźwięków, zależnie od ostatniego fonemu danego rzeczownika. Bezwdźwięczne „s” dodaje się zatem do takiego słowa jak „trick” (podstęp, sztuczka), dźwięk „z” - do słowa jak „bird” (ptak), a dźwięk „ez” - do słowa takiego jak „glass” (szkło). Psycholingwiści potrafią sformułować ścisłe reguły określające, kiedy stosuje się każdą z tych form. W jaki jednak sposób można ustalić, czy dzieci istotnie nauczyły się tych reguł?

„W pomysłowym eksperymencie Joan Berko starała się ustalić, czy dzieci przedszkolne i pierwszoklasiści znają reguły tworzenia liczby mnogiej. Na przykład pokazywała każdemu dziecku rysunek jakiegoś stworzenia podobnego do ptaka, mówiąc przy tym „To jest wug”. Następnie wskazywała na rysunek z dwoma takimi samymi stworzeniami i polecała dziecku uzupełnić zdanie. „To są dwa...” W tym wypadku poprawną formą liczby mnogiej jest wugz. Podobnie, gdy zwierzęta na rysunku nazwano „niss”, wówczas dziecko odpowiedziałoby poprawnie, gdyby stwierdziło, że dwa takie zwierzęcia to są dwa „niss-ez”.
Dzieci potrafiły odpowiadać na te pytania w sposób konsekwentny; autorka doszła od wniosku, że „nie może być wątpliwości, iż dzieci w tym przedziale wieku operują wyraźnie określonymi regułami morfologicznymi”. Dziewczęta i chłopcy uzyskiwali równie dobre wyniki; w wielu zadaniach wyniki pierwszoklasistów były istotnie lepsze niż przedszkolaków” (Berko, 1958).


Należy zwrócić uwagę, że w badaniu tym zastosowano nazwy bezsensowne; gdyby posłużono się normalnymi słowami angielskimi, takimi jak „bird” (ptak), nie bylibyśmy w stanie ustalić, czy dzieci znają regułę, czy też słyszały przedtem zarówno słowo „bird”, jak i „birds” (ptaki) i po prostu zapamiętały obie formy. „Znajomość reguły lingwistycznej” nie oznacza, że ktoś potrafi podać tę regułę w postaci doskonałej pod względem formalnym, lecz że potrafi stosować ją poprawnie, zwłaszcza w nowych sytuacjach.

„Badanie nad składnią i semantyką”. W serii eksperymentów George Miller i jego współpracownicy z Rockefeller University badali psychologiczne skutki naruszania reguł syntaktycznych i semantycznych. Przyjrzyjmy się pięciu „normalnym zdaniom” w tabeli poniżej. Zwróćmy uwagę, że we wszystkich występuje ten sam porządek syntaktyczny, a mianowicie (Podmiot)+(Orzeczenie)+(Dopełnienie bliższe)+(Przyimek)+(Rodzajnik określony „the”)+(Dopełnienie dalsze).


Zdania Stosowane W badaniach Nad Konsekwencjami Naruszania Reguł Lingwistycznych
Zdania poprawne:
1. Urządzenia ułatwiają pracę w domu.
2. Wypadki grożą motocyklistom na szosach.
3. Pociągi wiozą pasażerów przez kraj.
4. Niedźwiedzie kradną miód z ula.
5. Myśliwi strzelają słoniom między oczy.
Zdania niepoprawne semantycznie:
1. Urządzenia grożą pasażerom z oczu.
2. Wypadki wiozą miód między dom.
3. Pociągi kradną słonie w szosach.
4. Niedźwiedzie strzelają pracę na kraj.
5. Myśliwi ułatwiają motocyklistom przez ul.
Niegramatyczne ciągi słów:
1. W wypadki kraj miód strzelają.
2. Na pociągi ul słoniom ułatwiają.
3. Przez niedźwiedzie oczy pracę grożą.
4. Od myśliwi dom motocykliści wiozą.
5. Między urządzenia szosy pasażerów kradną.


Z tych zdań utworzono nowy zbiór zdań, które naruszały reguły semantyczne, lecz zachowywały porządek syntaktyczny. Każde z tych zdań zbudowano biorąc pierwsze słowo z jednego normalnego zdania, drugie słowo z następnego normalnego zdania, trzecie słowo - z kolejnego normalnego zdania itd.; w ten sposób otrzymano szereg „Gadgets kill passengers from the eyes” (Przyrządy zabijają pasażerów z oczu). Procedurę tę kontynuowano, dopóki nie użyto wszystkich słów, otrzymując w tabeli drugą grupę zdań, które są poprawne pod względem gramatycznym, lecz „nieprawidłowe semantycznie”.  Trzeci zbiór zdań utworzono przez losowe poprzestawianie słów wchodzących w skład normalnych zdań, tak aby zniszczyć ich normalną strukturę syntaktyczną, dzięki czemu otrzymano przedstawione w tabeli „szeregi niegramatyczne”. Zdania te nagrano na taśmę, a badanych poproszono, by powtarzali je głośno, gdy tylko je usłyszą. Badani potrafili powtórzyć poprawnie 89% zdań z pierwszej grupy, 80% zdań z drugiej grupy i tylko 56% z trzeciej „niegramatycznej grupy”. Podobne wyniku otrzymano wtedy, gdy poproszono badanych o zapamiętanie tych typów zdań. Zarówno struktura jak i znaczenie zdają się zatem wpływać na naszą zdolność dokładnego słyszenia oraz zapamiętania tego, co usłyszeliśmy (Miller i Isard, 1963; Marks i Miller, 1964).
Niedawne badania nad niestandardowymi odmianami języka angielskiego (gwarami), jakimi posługują się liczne grupy etniczne (zwłaszcza w gettach miejskich), wskazały, że są to dobrze rozwinięte systemy lingwistyczne, posiadające swoje własne reguły i konstrukcje. Aczkolwiek reguły te różnią się od reguł obowiązujących w standardowym, literackim języku angielskim, to jednak osoby posługujące się niestandardową angielszczyzną stosują je w sposób konsekwentny, dzięki czemu ich wypowiedzi są zrozumiałe dla innych członków danej wspólnoty językowej.


Zbliżenie
„He done did follow the man’s rules”: niestandardowa angielszczyzna


„Jaka jest różnica między następującymi zdaniami: „He workin’ when the boss come in” (dosł. On pracujący, gdy szef wchodzi) oraz „He be workin’ when the boss come in?” (dosł. On być pracujący, gdy szef wchodzi). Według zasad standardowej angielszczyzny oba te zdania są niepoprawne gramatycznie i niejasne. Jeśli jednak wypowiada je Amerykanin będący Murzynem, to między znaczeniem tych zdań występuje istotna różnica, która według psycholingwistów J. L. Dillarda (1967, 1968, 1972) i Williama Labova (1969) jest przekazywana ze znaczną precyzją. Pierwsze zdanie oznacza, że robotnik wykonuje swą pracę |tylko w obecności pracodawcy. Drugie zdanie wskazuje, że robotnik jest sumienny i pracuje nawet bez dozoru.
„I do” (ja robię). „I did” (ja robiłem) i „I have doe” (ja zrobiłem są formami czasownika „to do” (robić) akceptowanymi w standardowej angielszczyźnie, natomiast dziecko murzyńskie mogłoby powiedzieć „I do”, „I done”, „I have did” lub „I done did”. Wielu białych pedagogów uważa, że różnice lingwistyczne tego rodzaju są wynikiem „deprywacji kulturalnej” oraz braku zdolności poznawczych w zakresie uczenia się złożonych pojęć i operowania nimi.
Istotę tego sporu stanowi pytanie, czy niestandardowa angielszczyzna jest błędna i nielogiczna, czy też stanowi system językowy, w którym obowiązują pewne zasady. Rozwiązanie tego problemu oznacza nie tylko zaspokojenie akademickiej ciekawości, a to ze względu na jego implikacje społeczne, kulturalne i polityczne. Dzieci murzyńskie i inne, które opanowały stosowany w ich grupie etnicznej system językowy niestandardowej angielszczyzny, są w gorszej sytuacji, gdyż muszą oduczyć się go i przyswoić sobie „obcy” język, który w szkole jest jedyną akceptowaną i poprawną formą. Ponadto, ponieważ ich język nie jest formalnie uznany za „pełnoprawny” - jak byłoby wtedy, gdyby mówiły po rosyjsku, arabsku albo francusku - dzieci takie są często wyśmiewane z powodu swych „błędnych” nawyków językowych i szkoła staje się dla nich miejscem skojarzonym z poczuciem niższości. (Przypadkowo niektóre reguły dotyczące form czasownikowych w niestandardowej angielszczyźnie są podobne do reguł obowiązujących w języku rosyjskim i arabskim, a odmienne od reguł języka angielskiego).

Oto parę przykładów reguł gramatycznych dialektu murzyńskiego: a) gdy jakieś słowo kończy się dwoma słyszalnymi spółgłoskami, ostatnią się opuszcza - „fist” (pięść) zmienia się w „fis”, a „desk” (biurko) w „des”.  Wobec tego w liczbie mnogiej „fis” zostaje przekształcone w „fisses” (zamiast w „fists” - pięści, przyp. tłum.), a „des” w „desses” (zamiast w „desks” - biurka); b) wszędzie tam, gdzie w standardowej angielszczyźnie można posłużyć się skróconą formą czasownika, dzieci murzyńskie stosują albo formę skróconą, albo też formę polegającą na całkowitym opuszczeniu czasownika (zwaną „łącznikiem zerowym” - „zero copula”), na przykład „they „mine” (zamiast „they are mine” - one są moje), „jou right” (zamiast „jou are right” - masz słuszność); c) w długich zdaniach stosują dodatkowe „znaczniki orzecznikowe” („predicate markers”), aby przypominały mówiącemu i słuchaczowi o przedmiocie rozmowy, jak w następującym zdaniu: „Jou know that girl live on 151 st street, dress real cool, work modeling downtown, got real deep eyes, she go to school with me” (Znasz tę dziewczynę, (która) mieszka na 151 ulicy, ubiera się naprawdę szałowo, pracuje jako modelka w śródmieściu, ma naprawdę fantastyczne oczy, ona chodzi ze mną do szkoły).
Lingwiści argumentują, że charakterystyczne właściwości niestandardowej, murzyńskiej angielszczyzny umożliwiają lepsze określenie momentu w czasie lub czasu trwania toczącej się akcji. Ponadto język ten, jako nadal bliższy swej ustnej, gawędziarskiej tradycji niż formie pisanej, posługuje się środkami gramatycznymi, akcentem i słownictwem, aby utrzymać uwagę słuchacza. Murzyni jako osoby badane, nawet jeśli słuchają zdania wypowiedzianego w formie standardowej, gdy poprosi się ich o powtórzenie tego zdania, tłumaczą je zgodnie z regułami ich dialektu. Na przykład, gdy dzieciom zamieszkałym w gettcie murzyńskim polecono powtarzać zdania zawierające zwrot „nobody ever” (dosł. nikt kiedykolwiek), wypowiadały one niezmiennie słowa „nobody never” (dosł. nikt nigdy), co jest poprawną formą w murzyńskiej angielszczyźnie (Labov i in., 1968).
Stanowisko lingwistów, którzy są przekonani, że murzyńską, niestandardową angielszczyznę powinno się uznać za normalny, pełnoprawny język, przedstawił wymownie Labor:
„Obecnie mówi się nauczycielom, aby ignorowali język dzieci murzyńskich, jako niegodny uwagi i nieprzydatny do uczenia się. Uczy się ich, aby każdą naturalną wypowiedź takiego dziecka traktowali jako dowód jego umysłowej niższości. Jako lingwiści jednomyślnie potępiamy ten pogląd: jest to błędna obserwacja, fałszywa teoria i szkodliwa praktyka. To, że teoria tak fałszywa w świetle wiedzy o języku ma silny wpływ na psychologię wychowawczą, jest niekorzystne - lecz to, że dzieci są ofiarami tej ignorancji, jest niedopuszczalne” (1969, s. 169).


Rozwój mowy

Dotychczas mówiliśmy o języku w taki sposób, jak gdyby był on po prostu sposobem wyrażania myśli. Jednakże język jest czymś więcej niż środkiem porozumiewania się; odgrywa on zasadniczą rolę w podporządkowaniu doświadczeń i stabilizowaniu oszałamiającego świata, jaki ukazuje się oczom małego dziecka. W istocie, bardzo mało jest procesów psychicznych, na które nie oddziałuje język, słowne oznaczenia i symbole. Przez „odpowiednie” poługiwanie się językiem dziecko może zapewnić sobie lepsze zaspokojenie swych biologicznych potrzeb, zwrócić na siebie uwagę i sterować zachowaniem innych.

Język pozwala także dziecku przedstawić wszystko w formie symbolicznej i dzięki temu dokonywać operacji intelektualnych na poziomie abstrakcyjnym, a nie tylko na poziomie konkretnym bezpośredniego doświadczenia. Opanowanie języka jest niezbędne, jeśli mamy przypominać sobie, planować, rozumować, analizować, syntetyzować, wyjaśniać niezgodności, redukować nieokreśloność i kształtować wspólną rzeczywistość społeczną wraz z innymi członkami naszej wspólnoty językowej.


Kolejne stadia rozwoju mowy. Rozwój mowy dziecka można podzielić z grubsza na cztery stadia. Stadia te częściowo zachodzą na siebie i nie są wyraźnie zróżnicowane, lecz pozwalają uporządkować w czasie wczesne przejawy wokalizacji (Kaplan i Kaplan, 1970).

* * *
Ryc. 4.3. Nosacz i Wielki Ptak należą do mieszkańców ulicy Sezamowej pomagających dzieciom przedszkolnym w rozwijaniu zdolności poznawczych.
* * *

|Stadium |1. Badania nad rozwojem mowy u dzieci zaczynają się od momentu wydania pierwszego krzyku przez noworodka. Przez pierwsze trzy tygodnie repertuar wokalny noworodka jest bardzo ograniczony. Podstawowy krzyk może być nieco modyfikowany, dzięki czemu powstają jego odmiany, z których czujni rodzice wnioskują o gniewie lub bólu fizycznym. Krzyk, kaszel i gulgotanie - oto całość produkcji wokalnej noworodka.


Zbliżenie
Płacz niemowlęcia


„Płacz niemowlęcia wykazuje dostatecznie regularne formy, aby badacze mogli posługiwać się analizą „płaczu alarmującego” („distress cry”) dla wykrywania pewnych zaburzeń funkcji mózgu lub defektów genetycznych. Gdy przeanalizowano ponad 300 przypadków płaczu alarmującego u 13 niemowląt, przy zastosowaniu spektogramów dźwiękowych, wówczas stwierdzono różnice pod względem struktury i wysokości dźwięku w płaczu niemowląt „normalnych” i niemowląt uznanych za „anormalne” lub „być może anormalne” (Ostwald i Peltzman, 1974). Nie było różnic w czasie trwania płaczu, wystąpiły natomiast wyraźne różnice w strukturze częstotliwości dźwięku. W płaczu niemowląt „anormalnych” średnia wysokość dźwięku była dużo wyższa niż w płaczu niemowląt „normalnych” i nieco wyższa niż w płaczu niemowląt zaliczonych do grupy „być może anormalnych”.

|Stadium |2. W wieku od trzech tygodni do czterech czy pięciu miesięcy u niemowlęcia zaczyna pojawiać się „pseudopłacz” - płaczliwe wokalizacje, które jednak nie są zwykłym płaczem. Niemowlę urozmaica te dźwięki, zmieniając ich czas trwania, wysokość i artykulację.
|Stadium |3. W drugiej połowie pierwszego roku życia dziecko zaczyna wydawać na tyle zróżnicowane dźwięki mowy, i czyni to wszystko w sposób na tyle ciągły, że okres ten zwany jest „stadium gaworzenia”. Dziecko nie tylko wydaje dźwięki podobne do samogłosek i spółgłosek, lecz także zaczyna naśladować intonację dorosłych. Dźwięki łatwiejsze do wymówienia, takie jak „e” w słowie „bet” (zakład) pojawiają się w tym stadium wokalizacji wcześniej niż dźwięki trudniejsze, takie jak „Íoo” (u) w słowie „noon” (południe).
|Stadium |4. Początki ustrukturalizowanej, „prawdziwej” mowy przypadają gdzieś na koniec pierwszego roku życia. „Prelingwistyczny” okres, obejmujący trzy poprzednie stadia, kończy się z chwilą pojawienia się pierwszych dających się rozpoznać słów dziecka. Jednakże ciągle jeszcze nie jest jasne, czy istnieje jakiś systematyczny związek między stadiami prelingwistycznymi a „produkcją” prawdziwej mowy. Niektórzy badacze utrzymują, że w stadium gaworzenia występuje uporządkowana sekwencja rozwojowa: dziecko jest zaabsorbowane najpierw dźwiękami samogłoskowymi, potem spółgłoskowymi, następnie zestawieniami spółgłoska-samogłoska, a wreszcie jednostkami spółgłoska-samogłoska-spółgłoska-samogłoska, mającymi rytm i intonację prawdziwej mowy. Z poglądem tym nie zgadzają się inni teoretycy, którzy twierdzą, że dźwięki gaworzenia po prostu „tworzą się same” i nie mają wyraźnie określonej funkcji. Zgodnie z tym stanowiskiem rozwój prawdziwej mowy nie jest bynajmniej kontynuacją uprzedniego zachowania lingwistycznego.
Zaczątki słownika przeciętnego, rocznego dziecka składają się z 2 lub 3 słów. Słownik ten wzrasta do około 50 słów w wieku 24 miesięcy i 1000 słów w wieku 3 lat (Lenneberg, 1969). Prawdopodobnie większa stymulacja, jaka jest wynikiem codziennego oglądania programu telewizyjnego, przyspiesza rozwój słownika, a umiejętnie przygotowane programy (jak np. „Sezame Street” - Ulica Sezamowa - nadawany w Stanach Zjednoczonych) mogą wpływać na inne aspekty rozwoju językowego. Jedno z badań (Irwin, 1960) wykazało, że kiedy dzieciom rodziców ze środowiska robotniczego czytano regularnie przez 15 minut dziennie od 13 do 30 miesiąca życia, to pod względem produkowanych dźwięków mowy przewyższały one coraz bardziej (poczynając od 17 miesiąca życia) dzieci z odpowiednio dobranej grupy kontrolnej).

Typowy przebieg rozwoju mowy. Co mówią dzieci, gdy już potrafią wymawiać dające się rozpoznać słowa? Pierwszymi sensownymi wypowiedziami są pojedyncze słowa, takie jak „mama”, które często znaczą tyle, co pełne zdania. Na przykład „mama” oznaczać może „To jest mama”, „Mamo, gdzie jesteś?”, „Mamo, jestem głodny” lub różne inne rzeczy, zależnie od sytuacji. Później dziecko zaczyna zestawiać słowa, tworząc zdania złożone z dwóch słów. Jak wkrótce się przekonamy, te zestawienia słów nie są przypadkowe, lecz mają określoną, regularną strukturę. Struktura ta zmienia się z wiekiem i nie zawsze odpowiada strukturze języka dorosłych.

„Zestawianie słów”. Około osiemnastego miesiąca życia dziecko zaczyna się posługiwać wypowiedziami złożonymi już nie z jednego, lecz z dwóch słów.  Badacze, którzy analizowali te zdania, zidentyfikowali dwie odrębne klasy słów (Braine, 1963; Miller i Ervin, 1964). Jedna z tych klas, o stosunkowo małej liczebności, zawiera tak zwane |słowa |osiowe („pivot words”), podczas gdy druga, liczebniejsza klasa, obejmuje wszystkie inne słowa ze słownika dziecka. |Słowo |osiowe jest to takie słowo, które można połączyć z wieloma innymi słowami, tworząc w ten sposób sensowne zdania. Na przykład słowo „more” (więcej, bardziej) jest słowem osiowym, ponieważ dziecko może powiedzieć wiele rzeczy („more hot” - bardziej gorące, „more milk” - więcej mleka, „more wet” - bardziej mokre) łącząc je z różnymi słowami z klasy „słownikowej”. Pozycja danego słowa osiowego w zdaniu składającym się z dwóch słów jest zawsze stała (por. tabela); znajduje się ono albo zawsze na pierwszej pozycji („Allgone milk” - Nie ma mleko, „Allgone Daddy” - Nie ma tatuś), albo zawsze na drugiej pozycji („Mail come” - Poczta przyjść, „Mommy come” - Mamusia przyjść).

Część „Gramatyki Osiowej” Pewnego Dziecka. Każde ze słów osiowych (z niewieloma wyjątkami) z następującym po nim którymkolwiek ze słów „słownikowych” może tworzyć sensowne zdanie w języku tego dziecka.

Słowa osiowe (występujące na pierwszym miejscu):
„allgone” (wyszedł); „byebye” (pa-pa); „big” (duży); „more” (więcej); 
„pretty” (ładny); „my” (mój); „see” (zobacz); „night-night” (dobranoc); 
„hi” (hej)
Słownik: „boy” (chłopiec); „sock” (skarpetka); „boat” (łódka); „fan” (wentylator); „milk” (mleko); „plane” (samolot); „shoe” (but); „vitamins” (witaminy); „hot” (gorący); „Mammy” (mama); „Daddy” (tatuś)
(Źródło: McNeill, 1966)


Drugi typ zdania złożonego z dwóch słów, którym dziecko zaczyna się posługiwać w tym czasie, to zdanie będące połączeniem dwóch słów „słownikowych”. Zdania takie zdają się wyrażać różne rodzaje relacji między rzeczami. Na przykład zdanie „Cup glass” (Kubek szklanka) może oznaczać |koniunkcję („I see a cup and glass” - Widzę kubek i szklankę). Podobnie |położenie może być wyrażone zdaniem „Hat chair” (Kapelusz krzesło), co oznaczałoby „The hat is on the chair” (Kapelusz jest na krześle), podczas gdy „Party hat” (Przyjęcie kapelusz) mogłoby oznaczać |atrybucję („This is a party hat” - To jest kapelusz na przyjęcie). Zdanie takie jak „Mary Ball” (Marysia piłka) mogłoby oznaczać albo Posiadanie („Here in Mary’s ball” - Tu jest piłka Marysi) albo |relację |między |podmiotem |a |przedmiotem („Mary throws the ball” - Marysia rzuca piłkę). Dwuwyrazowe zdania, takie jak przytoczone powyżej, można oczywiście zrozumieć tylko wtedy, gdy znamy kontekst, w jakim są wypowiadane.
Należy sobie dobrze zdawać sprawę z tego, że język dziecka w tym stadium |nie jest bezpośrednią kopią języka dorosłych. Chociaż słowa są takie same, to dziecko zestawia je ze sobą w odmienny sposób. Gramatyka dziecka ma swoje własne reguły, inne niż reguły języka dorosłych, który dziecko słyszy codziennie i którym musi w końcu się posługiwać, aby mogło skutecznie porozumieć się z innymi.

„Organizowanie słów i zwrotów”. Gdy dziecko ma około dwóch lat, wówczas zaczyna tworzyć zdania składające się z więcej niż dwóch słów. Często te dłuższe zdania są rozwinięciem krótszych; dziecko najpierw tworzy krótkie zdania, a następnie „włącza je” w bardziej złożone. Na przykład dziecko powie: „Want that...” „Andrew want that” (Chcieć to... Andrzej chcieć to) lub „Stand up...” „Cat stand up...” „Cat stand up table” (Wstawać... Kot wstawać... Kot wstawać na stół). Staranne zbadanie tych dłuższych zdań sugeruje, że dziecko aktywnie rozkłada każde zdanie na strukturalne subjednostki, a nie po prostu wypowiada słowa jedno po drugim.
W miarę jak język dziecka staje się coraz bardziej złożony, zaczyna ono wprowadzać weń pewien porządek. Dziecko zaczyna stosować ogólnie przyjęte wzorce, czyli |reguły, a następnie stosuje je tak często, jak to możliwe.  Niekiedy przypisuje ono regule zbyt szerokie zastosowanie, tworząc wskutek tego niepoprawne formy językowe. Na przykład, gdy dziecko nauczy się ogólnej zasady tworzenia liczby mnogiej (dodanie „s” do rzeczownika), wówczas rozszerza tę regułę na |wszystkie rzeczowniki, tworząc takie słowa, jak „foots” lub „mouses” (zamiast poprawnych form „feet” - stopy, oraz „mice” - myszy). Podobnie, gdy nauczy się reguły tworzenia czasu przeszłego, mającej zastosowanie do większości czasowników (dodanie „ed” do czasownika), będzie dodawać „ed” do wszystkich czasowników, tworząc takie słowa jak „doed” i „breaked” (zamiast „did” - zrobiłem i „broke” - złamałem, stłukłem).
Ta nadmierna generalizacja reguły jest szczególnie interesująca, ponieważ zwykle występuje |po tym, gdy dziecko nauczyło się już poprawnych form czasowników i rzeczowników. To znaczy, dziecko najpierw używa poprawnych form czasownikowych „come” (przyszedłem) i „went” (szedłem), najwyraźniej dlatego, że nauczyło się ich jako odrębnych słów. Gdy jednak dziecko później nauczy się ogólnej reguły tworzenia czasu przeszłego, natychmiast rozciąga ją na wszystkie czasowniki i zaczyna mówić „comed” i „goed” (zamiast „came” i „went”), chociaż nigdy nie słyszało, żeby inni ludzie mówili takie słowa. Niekiedy te niepoprawne nadmiernie uogólnienia utrzymują się przez kilka lat, mimo wysiłków dorosłych, którzy starają się je zmienić. Na podstawie analizy takich właśnie błędów możemy wykryć, w jaki sposób uczenie się języka jest uzależnione od przyswajania sobie reguł.
Do tego czasu zdania wypowiadane przez dziecko przybierały na ogół postać prostych stwierdzeń, takich jak „More cookie” (Więcej ciasta) lub „John want that” (Jaś chcieć to). Stopniowo jednak dziecko zaczyna stosować reguły transformacyjne, konstruować zdania pytające i przeczące. Na przykład zdanie oznajmiające „He is doing it” (On robi to) można przekształcić w zdanie pytające dokonując jednej transformacji: „Is he doing it”? (Czy on to robi?). Jeśli doda się także „why” (dlaczego) na początku zdania, aby utworzyć zdanie pytające „Why is he doing it”?  (Dlaczego on to robi?), to pozostaną dokonane dwie transformacje.
Początkowo, gdy dzieci uczą się dokonywać tych transformacji, nie potrafią przeprowadzić w jednym zdaniu więcej niż jednej. Na przykład, dziecko w tym stadium rozwoju, doda do zdania „why”, lecz nie potrafi ponadto zamienić miejscami „he” i „is”. W rezultacie tworzy zdanie pytające „Why he is doing it”? (zamiast poprawnego „Why is he doing it”?). W późniejszym stadium dziecko opanuje umiejętność dokonywania dwóch transformacji naraz i będzie mogło sformułować to pytanie poprawnie.  Dziecko musi jednak osiągnąć jeszcze wyższy poziom rozwoju językowego (Bellugi-Klima, 1968), zanim będzie potrafiło utworzyć zdanie wymagające |trzech transformacji, takie jak „Why is he not doing it”? (Dlaczego on tego |nie robi?).


Teorie uczenia się języka


Teraz, gdy mamy już pewne wyobrażenie o tym, czego dzieci uczą się mówić, możemy zająć się zagadnieniem, |w |jaki |sposób uczą się to mówić. Skąd bierze się zdolność tworzenia złożonych form językowych? Gdybyś wyszedł na ulicę i zadał ludziom to pytanie, wówczas prawdopodobnie odpowiedzieliby: 
„Och, dzieci po prostu naśladują to, co słyszą, a jeśli robią błąd, rodzice poprawiają je”. Ten model „naśladowania i potwierdzania” jest w istocie jedną z głównych teorii przyswajania języka, ogólnie zwaną jako |podejście |oparte |na |teorii |uczenia |się.

Podejście oparte na teorii uczenia się. B. F. Skinner (1957), jeden z najwybitniejszych teoretyków uczenia się, twierdzi, że dzieci uczą się języka w dokładnie taki sam sposób, w jaki uczą się wszystkich innych zachowań, na przykład posługiwania się przy jedzeniu widelcem lub pałeczkami, gry w piłkę lub pasania owiec. Naśladują one zachowanie językowe dorosłych z ich otoczenia i jeśli czynią to poprawnie, dorośli nagradzają je chwaląc i mówiąc, że powiedziały to „dobrze”. Jeśli jednak popełnią błąd i powiedzą coś niegramatycznego, dorośli nie dostarczają im wzmocnienia, a niekiedy karzą słowami: „Nie, to jest źle” lub „Nie możesz mówić w ten sposób”. W wyniku tego selektywnie wzmacnianego naśladowania języka dorosłych dzieci stopniowo uczą się mówić poprawnie.
Istnieją dane przemawiające za tym poglądem: stwierdzono, że można wzmóc wokalizację u 3-miesięcznych niemowląt, dostarczając im wzmocnienia społecznego, gdy występuje u nich wokalizacja (Rheingold, Gewirtz i Ross, 1959). Inne, nowsze badania wykazały, że za pomocą wzmacniania można zwiększyć lub zmniejszyć częstość występowania określonego dźwięku (zob.  Routh, 1969).
Chociaż koncepcja ta, mająca wyjaśnić, jak dzieci uczą się języka, jest dość prosta, to jednak nastręcza ona poważne trudności. Po pierwsze, |różnorodność |warunków środowiskowych i warunków wzmacniania u poszczególnych dzieci powinna powodować ogromne różnice między nimi pod względem rodzaju mowy. Jednakże jest inaczej. Chociaż najrozmaitsze środowiska społeczne, w których zachodzi proces uczenia się języka, różnią się bardzo, jeśli chodzi o sposobność ćwiczenia się i dostarczane wzmocnienia społeczne, to jednak rozwój mowy u dzieci z różnych kultur i klas społecznych zdaje się przebiegać według względnie stałego, uniwersalnego wzorca. Niezwykłe środowisko dla rozwoju mowy u dziecka stwarzają głusi rodzice, którzy nie mogą wzmacniać selektywnie wokalizacji podobnych do zachowania językowego dorosłych, ponieważ ich nie słyszą. Eric Lenneberg (1969) opisuje fascynujące badanie, w którym rejestrował dźwięki z otoczenia oraz wokalizacje dwóch grup niemowląt - sześciorga mających rodziców głuchych i sześciorga, które miały rodziców słyszących. Obserwacje te przeprowadzano dwa razy w tygodniu przez trzy miesiące, zaczynając je, zanim niemowlęta ukończyły dziesiąty dzień życia.

„Dzieci, których oboje rodzice byli głusi, słyszały od nich niewiele normalnych dźwięków mowy, a ponadto w ich domach było istotnie mniej innych dźwięków (z telewizji, radia oraz głosów ludzi) niż w domach pozostałych dzieci. Jednakże te drastyczne różnice środowiskowe nie spowodowały żadnej różnicy między niemowlętami z obu grup, jeśli chodzi o ich wokalizacje (płacz, gruchanie, krzyk). „Tak więc najwsześniejszy rozwój dźwięków ludzkich zdaje się stosunkowo niezależny od ilości, charakteru czy rozkładu w czasie dźwięków wytwarzanych przez rodziców”.

Następnym argumentem przeciwko takiemu analizowaniu procesu przyswajania języka w kategoriach teorii uczenia się jest to, że dzieci często mówią różne rzeczy, które niewątpliwie nie są naśladowaniem mowy dorosłych. Jak już wspominaliśmy poprzednio, dzieci mówią „foots” (zamiast „feet” - stopy) i „goed” (zamiast „went” - poszedłem) albo tworzą dwuwyrazowe zdania typu „Allgone Daddy” (Nie ma Tatuś), chociaż nigdy nie słyszały, aby dorośli mówili w ten sposób. W pewnych stadiach rozwoju nie są zdolne dokonywać paru transformacji gramatycznych na raz, chociaż zawsze słyszały je w wykonaniu dorosłych. Ponadto rodzice w rzeczywistości nie korygują mowy dziecka tak często, jak to przyjmują zwolennicy teorii uczenia się. Jeśli przysłuchamy się uważnie interakcji między którymś z rodziców a dzieckiem, to przekonamy się, że ojciec czy matka bardziej troszczą się o to, by zrozumieć, |co dziecko stara się powiedzieć, niż to, |jak ono to mówi.  Prawdziwe stwierdzenie często otrzymuje pozytywne wzmocnienie od rodziców, nawet jeśli jest niepoprawne gramatycznie. Na przykład, jeśli dziecko mówi „Her curl my hair” (Jej zakręca moje włosy), matka prawdopodobnie odpowie „słusznie”, ponieważ rzeczywiście zakręca włosy dziecka. Jeśli jednak dziecko wypowiada gramatycznie poprawnie zdanie „There’s the animal farmhouse” (Tam jest domek dla zwierząt), lecz wskazuje przy tym latarnię morską, to ojciec czy matka z pewnością powie: „Nie, mylisz się” (Brown, Cazden i Bellugi-Klima, 1969).
Co najważniejsze, gdyby dzieci potrafiły tylko wypowiadać te zdania, które udatnie naśladowały, otrzymując za to wzmocnienie, to jak mogłyby kiedykolwiek tworzyć nowe zdania, których nie słyszały nigdy przedtem?  Oczywiście, zarówno dzieci jak i dorośli nieustannie tworzą zdania, które są całkowicie oryginalne, a ogólna liczba zdań, które mogłaby wypowiedzieć każda istota ludzka, jest teoretycznie nieskończona. Musimy więc poszukać takiej teorii rozwoju mowy, która bierze to pod uwagę.

Podejście psycholingwistyczne. Skinnerowską analizę języka, opartą na teorii uczenia się, poddał ostrej krytyce Noam Chomsky z Massahussets Institute of Technology (1968, 1969), który stał się jednym z czołowych propagatorów psycholingwistycznej teorii przyswajania języka. Teoria ta głosi, że dziecko uczy się złożonego systemu |reguł, a nie po prostu wielu różnych sekwencji słów, i że taki system pozwala mu tworzyć nieskończoną liczbę nowych zdań. Jak już przekonaliśmy się wcześniej, stosowanie przez dzieci „gramatyki osiowej” („pivot grammar”) i nadmierne generalizowanie formy czasu przeszłego są wyraźnym dowodem, że posługują się one systemem reguł. Dzieci nie tylko przyswajają sobie te reguły, chociaż nikt nie uczył ich formalnie „jako reguł”, lecz ponadto dokonują tego w bardzo wczesnym wieku, gdy nie są zdolne do innych złożonych osiągnięć intelektualnych. W jaki sposób potrafią one dokonać takiego niewiarygodnego wyczynu?
Teoretycy, tacy jak Lenneberg (1969), podkreślają doniosłą rolę aspektów biologicznych. Wszelkie dane wskazują, że zdolność rozwijania złożonego, abstrakcyjnego systemu językowego jest |specyficzna |dla |gatunku - to znaczy występuje tylko u ludzi. Niektóre zwierzęta, na przykład pawiany, wytworzyły dość złożony system sygnałów pozwalających informować o niebezpieczeństwie lub obecności pokarmu. Jednakże w systemach takich brak jest istniejących w językach ludzkich ekspresji lub abstrahowanie; jak się przekonamy, zdolność zwierząt do nauczenia się mowy ludzkiej jest ograniczona.
Ta zdolność do wytwarzania języka i posługiwania się nim zdaje się być również |jednakowa |w |obrębie |gatunku - nie jest znany żaden przypadek grupy ludzkiej, która nie posługiwałaby się językiem. Ponadto różnice między rozmaitymi językami ludzkimi, pod względem ich złożoności gramatycznej, są niewielkie. Obserwacje tego rodzaju skłoniły wielu badaczy procesów językowych do wysunięcia tezy, że wiele aspektów naszej zdolności językowej jest prawdopodobnie wrodzonych. Innymi słowy, nasza zdolność mówienia i rozumienia mowy w dużym stopniu jest zdeterminowana raczej przez nasze wyposażenie genetyczne niż przez specyficzne wzmocnienia, jakie na nas oddziaływały. Lenneberg podkreśla, że „Dzieci zaczynają mówić nie wcześniej i nie później niż wtedy, gdy osiągną określone stadium dojrzałości fizycznej (1969, s. 635). Wykazał on, że rozwój językowy jest w systematyczny sposób skorelowany z rozwojem ruchowym i „dojrzałościowym” („maturational”) wskaźnikami rozwoju mózgu.
Jeśli ta teoria wrodzonej zdolności jest poprawna, to wszystkie sprawne intelektualnie dzieci powinny być zdolne do utworzenia systemu reguł, niezależnie od tego, jakim językiem mówią - i rzeczywiście wydaje się, że tak jest istotnie.

Badania porównawcze przeprowadzone nad dziećmi z całego świata wykazują, że uczą się one swego ojczystego języka w tym samym mniej więcej wieku i że posługują się one podobnymi systemami reguł (Slobin, 1971).
W podejściu psycholingwistycznym szczególnie wiele uwagi poświęca się |twórczym aspektom języka - w jaki sposób ludzie potrafią tworzyć całkowicie oryginalne zdania, których nie słyszeli nigdy przedtem.  Przypuszczalnie zdolność ta opiera się na umiejętności stosowania różnych reguł syntaktycznych. Według Chomsky’ego reguły te można podzielić na dwie kategorie, zależnie od tego, czy determinują one powierzchniową czy głęboką strukturę języka. |Struktura |powierzchniowa zdania odnosi się do jego części składowych (takich, jak podmiot, orzeczenie, dopełnienie itd.) oraz sposobu ich powiązania. Ta struktura zdania odgrywa ważną rolę w determinowaniu jego znaczenia. Jeśli weźmiemy takie na przykłąd zdanie: 
„Lecturers like silent, happy audiences” (Wykładowcy lubią spokojnych, pogodnych słuchaczy) i będziemy przestawiać słowa tworząc rozmaite kombinacje, to będą one przybierały bardzo różne znaczenie.
Znaczenie zdania (jego interpretacja semantyczna) jest jednak określone przede wszystkim przez jego |strukturę |głęboką. Nawet jeśli zdania mają bardzo różną strukturę powierzchniową, to ich struktura głęboka może być podobna. Na przykład, zdania: „I asked Chris to come” (Prosiłem Chris, żeby przyszła) i „What I asked of Chris was that she come” (dosł. - To, o co poprosiłem Chris, było, aby przyszła) mają tę samą głęboką strukturę i interpretację semantyczną, mimo że różnią się pod względem swej struktury powierzchniowej. 
To właśnie struktura głęboka jest intuicyjnie i nieświadomie przeksztłacana za pomocą reguł transformacyjnych w strukturę powierzchniową. Weźmy na przykład zdanie „The man who is sitting at the head of the table is my father” (Mężczyzna który siedzi u szczytu stołu jest moim ojcem). Możemy uważać to zdanie za złożone z przekształconej wersji zdania „The man is my father” (Ten mężczyzna jest moim ojcem) i zdania „The man is sitting at the head of the table” (Ten mężczyzna siedzi u szczytu stołu).

W tym wypadku mówiący nieświadomie przekształcił dwa odrębne (na poziomie pojęciowym) „zdania” w pojedyncze zdanie, które wypowiada. Zastosował on pewne reguły transformacyjne, aby |osadzić jedno zdanie w drugim i dokonać zmian morfologicznych i składniowych niezbędnych dla utworzenia poprawnej konstrukcji. Osoba słysząca to zdanie przeprowadza odwrotną procedurę, przekształcając strukturę powierzchniową w struktury głębsze, które ujawniają jego podstawowe znaczenie.
Podejście psycholingwistyczne jest z pewności interesującą alternatywą w stosunku do teorii uczenia się, lecz nie daje ostatecznej odpowiedzi na pytanie, jak dziecko uczy się swego ojczystego języka, ponadto zostały zakwestionowane niektóre z podstawowych założeń tego podejścia. Nie wiemy jeszcze dokładnie, czym są „wrodzone zdolności” umysłu dziecka, ani w jaki sposób one działają, by wytworzyć różne umiejętności językowe. Potrzeba znacznie więcej badań, zanim naprawdę zrozumiemy proces rozwoju języka. Na razie polemika między zwolennikami Chomsky’ego i Skinnera na temat tego, w jakim stopniu nabywanie języka ma charakter wrodzony, a w jakim opiera się na uczeniu się, prawdopodobnie potrwa jeszcze przez pewien czas.


Formy komunikowania się


Wyobraź sobie, że razem z trzema innymi studentami uczestniczycie jako osoby badane w eksperymencie, w którym wchodzi w grę symulacja czynności projektowania miasta. Powiedziano wam, że jeden z was zostanie wybrany projektantem, a pozostali będą pełnić funkcję konsultantów, pracujących wspólnie nad zaplanowaniem wzorowego miasta. Osoba, która zostanie wyróżniona zaszczytnym stanowiskiem projektanta, będzie wybrana na podstawie szeregu testów i po dyskusji „okrągłego stołu” między wszystkimi uczestnikami. Co byś zrobił, aby zakomunikować eksperymentatorowi, że masz ochotę na stanowisko projektanta - przy czym oczywiście, nie jesteś tak niedelikatny, aby wystąpić wprost i poprosić o to?
Lecz poczekaj! Czy jesteś pewny, że chcesz być wybrany? W niektórych sytuacjach kierownik musi przyjąć na siebie wielką odpowiedzialność, znosić stres i lęk, przy czym otrzymuje niewiele pochwał czy nagród. I rzeczywiście, gdy przeprowadzano ten eksperyment, w połowie grup projektantowi miano aplikować wstrząs elektryczny za podjęcie każdej niewłaściwej decyzji - co imitowało nieprzyjazne środowisko pracy. W pozostałych grupach, w sprzyjających warunkach środowiskowych, projektant miał otrzymać nagrodę pieniężną za każdą trafną decyzję.

Teraz musisz zdecydować się, jak się zachować, aby wyróżnić się z tłumu w przychylnym, nagradzającym środowisku lub aby skryć się niepostrzeżenie w tym tłumie, gdy środowisko jest nieprzyjazne i zagrażające.
W eksperymencie tym, przeprowadzonym przez Christinę Maslach (1974) na studentach Stanford University, werbalne i niewerbalne zachowanie badanych rejestrowano na taśmie magnetowidowej, po czym analizowano je klatka po klatce; miało to na celu ustalenie różnic między wzorcami komunikowania się, których używali badani, aby przekazać informację, że chcą być wybrani, chcą się wyróżnić lub pragną pozostać |nie |zauważeni, „bezimienni”.  Istotnie, wystąpiły znaczne różnice między wzorcami stosowanymi w obu tych sytuacjach, a niektóre cechy tych wzorców różniły się także w zależności od tego, czy badani byli mężczyźni czy kobiety.
Aby wyróżnić się w przychylnym środowisku, badani podawali niezwykłe opisy samych siebie, czemu towarzyszyły pełne ekspresji gesty rąk; wypowiadane przez nich uwagi i komentarze były długie, a odpowiedzi na testy oryginalne i niekonformistyczne. Kobiety uśmiechały się częściej niż mężczyźni, natomiast wykonywały mniej ruchów w czasie, gdy mówił ktoś inny z grupy. Kobiety, które mówiły więcej o sobie, wypowiadały mniej ogólnych uwag, chociaż każda z ich uwag była dłuższa od przeciętnej długości uwag czynionych przez pozostałe osoby.
U badanych, którzy spodziewali się, że znajdą się w zagrażającym środowisku, występowały reakcje lęku i podniecenia. Nieoczekiwanie dużo żartowali, uśmiechali się, przerywali mówiącym i wypowiadali wiele krótkich uwag. Aczkolwiek te „obronne” sposoby komunikowania się w rzeczywistości zwracały uwagę na nich samych, świadomie starali się roztopić w grupie, dając wysoce konformistyczne odpowiedzi na testy i unikając stwierdzeń, które miały charakter osobisty lub niezwykły.
Na podstawie tych badań możemy sparafrazować znaną kwestię z „Jak wam się podoba” Szekspira: Cały świat jest sceną, na której ludzie starają się być albo częścią chóru na dalszym planie, albo głównymi aktorami; tragedie cofają nas w głąb sceny, podczas gdy romanse i komedie zachęcaj nas do wystąpienia w pełnym świetle reflektorów.
Nasze pragnienia, aby być zauważonymi lub zignorowanymi, komunikujemy innym nie tylko za pośrednictwem tego, co mówimy, lecz także tego, jak to wypowiadamy - nie tylko językiem słów, lecz także bezgłośnym językiem ciała i naszego stylu ekspresji.


Komunikowanie się bez słów.


Język słowny, ze swą zadziwiającą złożonością struktury i bogactwem słownika, jest oczywiście głównym środkiem, za pomocą którego ludzie wyrażają swoje myśli i uczucia. Przyjęcie założenia, że język słów jest |jedynym środkiem porozumiewania się, byłoby jednak poważnym błędem. Wyraz twarzy, ruchy ciała, gesty oraz charakterystyczne cechy głosu (takie, jak zwieszenie go) - wszystko to są potężne środki komunikowania się. Te same słowa (np. „Kocham cię”) mogą być interpretowane na wiele różnych sposobów, zależnie od tego, czy zostały wypowiedziane szeptem, ironicznym tonem głosu, ze łkaniem, czy towarzyszyły przytuleniu się. Nasza intuicyjna ocena, że czyjaś wypowiedź „nie brzmi szczerze”, często oparta jest raczej na tym, w jaki sposób ten ktoś wypowiada słowa niż na treści samych słów.  Żywym przykładem niejęzykowych sposobów ekspresji jest opisywane nieraz zachowanie jeńców wojennych, którzy na żądanie wroga odczytywali na głos pewne teksty, lecz zmieniali intonację głosu tak, aby ich bliscy oraz inni jeńcy wiedzieli, że nie wierzą naprawdę w to, co mówią.
Chociaż jesteśmy specjalnie ćwiczeni w posługiwaniu się językiem, jakim mówimy, niewielu z nas, z wyjątkiem studentów szkół dramatycznych, uczono kiedykolwiek, jak posługiwać się różnymi formami ekspresji niewerbalnej.  Niektóre z nich, takie jak płacz i śmiech, zdają się być reakcjami wrodzonymi. Innych uczymy się w sposób nieformalny - dotyczy to na przykład wypowiadania pozytywnej oceny („Ach, jakież to wspaniałe!”) „negatywnym” tonem w celu wyrażenia ironii czy sarkazmu. Te niewerbalne komunikaty przekazują zwykle jedynie nieliczne podstawowe wymiary uczuć i postaw (upodobanie - niechęć, dominację oraz przychylność wobec innych), w odróżnieniu od bardziej złożonych aspektów, które można wyrazić za pomocą języka werbalnego (Mehrabian, 1971b). Jedynym ważnym wyjątkiem od tej zasady jest złożony niewerbalny język znaków używany przez głuchoniemych.

Ekspresja niewerbalna. W szerokim ujęciu |ekspresja |niewerbalna oznaczy wszelkie porozumiewanie się, które nie opiera się wyłącznie na słowach lub symbolach słów. Aczkolwiek ten rodzaj ekspresji może być stosowany łącznie z wypowiedziami słownymi (np. gdy ktoś mówiąc uśmiecha się lub gestykuluje), to jednak posługiwanie się nim nie wymaga użycia słów.  Zainteresowanie badaczy skupia się na wykorzystaniu zachowań niewerbalnych jako sposobu porozumiewania się - za pomocą jakich wyrazów twarzy czy ruchów przekazujemy nasze myśli i uczucia, a także wnioskujemy o myślach i uczuciach innych ludzi?
Badania eksperymentalne koncentrują się na czterech głównych typach ekspresji niewerbalnej. Przedmiotem wielu badań jest |mimika |twarzy, ponieważ emocje najwyraźniej ujawniają się na twarzy, przynajmniej u ludzi (badania te omówiono w Rozdziale 9). Drugi obszar badań to |kinezjetyka (kinesisc), która zajmuje się pozycjami ciała, postawą, gestami i innymi ruchami ciała. |Proksemika (proxemics) interesuje się przestrzenną odległością między ludźmi, którzy wchodzą ze sobą w jakąś interakcję, jak również ich stosunkiem do siebie (przejawiającym się w kontakcie dotykowym i wzrokowym). Czwarty obszar badań dotyczy |parajęzyka (paralanguage), który obejmuje głosowe, lecz niewerbalne aspekty porozumiewania się - cechy głosu, takie jak wysokość i natężenie oraz tempo mówienia, wahania, błędy oraz inne zakłócenia płynności mowy i wreszcie dźwięki niejęzykowe, takie jak śmiech i ziewanie.

„Oko potrafi grozić jak nabita i wycelowana strzelba, potrafi znieważyć jak gwizdy lub kopnięcie; lub też, w odmiennym nastroju, promieniując życzliwością potrafi sprawić, iż serce tańczy z radości”.
Ralph Waldo Emerson „Conduct of Life”, 1860.

„Oczy mówią”. Oczy od dawna uważa się za jedną z najbardziej „wymownych” części ciała. „Robi się oko” do kogoś, kto się podoba, podczas gdy przeciwnicy spotykają się „oko w oko”. Osobnicy, którym nie można ufać, „nie patrzą ci prosto w oczy”, natomiast ludzie zakłopotani, nieśmiali lub pełni szacunku „spuszczają oczy ku ziemi”.
Ogólnie biorąc, wydaje się, że kontakt wzrokowy pomaga ustalić charakter wzajemnego stosunku między ludźmi - pozytywny lub negatywny, bliski lub „na dystans”. Ludzie skłonni są spoglądać nawzajem na siebie, jeśli się lubią, lecz starają się nie patrzeć na współtowarzysza, którego nie lubią (Exline i Winters, 1965). Rubin (1970) rozszerzył nieco tę zasadę; obserwował on wzorce kontaktu wzrokowego u par mieszanych pod względem płci, które czekały razem, by wziąć udział w eksperymencie psychologicznym. Te pary, które były w sobie zakochane, częściej patrzyły sobie w oczy niż pary niezakochane.

Chociaż z obu tych badań zdaje się wynikać, że kontakt wzrokowy jest przejawem pozytywnego stosunku do drugiej osoby, nie zawsze jest to prawdą.  Według Ellsworth i Carlsmitha (1968) kontakt wzrokowy służy do intensyfikacji treści werbalnej danego stosunku, bez względu na to, czy jest on pozytywny, czy negatywny. Jeśli więc ktoś prawi mi komplementy, to będę przychylniejszy dla tej osoby, gdy patrzy na mnie, a nie gdzieś w bok.  Jeśli jednak ktoś mnie krytykuje, to będę czuł się lepiej, jeśli osoba ta stara się na mnie nie patrzeć - brak kontaktu wzrokowego sprawia, że to „ujemne sprzężenie zwrotne” zdaje się mieć charakter mniej osobisty.
Wiadomo od dawna, że |wpatrywanie |się u naczelnych sygnalizuje groźbę, a w wielu kulturach w różnych częściach świata silna jest obawa przed destrukcyjną magią „uroku”, czyli „złego oka”, co spowodowało nałożenie „tabu” na wpatrywanie się. Aby ustalić, w jak sposób bardziej „cywilizowani” Amerykanie reagowaliby na intensywne wpatrywanie się kogoś obcego, Ellsworth i jej współpracownicy przeprowadzili bardzo interesujący eksperyment naturalny, tak prosty, że może go powtórzyć każdy student, który miałby chęć to uczynić.

„Eksperymentator czekał na rogu ruchliwego skrzyżowania, dopóki jakiś samochód nie zatrzymał się przy czerwonym świetle. Gdy samochód stanął, wówczas eksperymentator zaczynał się wpatrywać spokojnie i nieustannie, w kierowcę. Gdy zapalało się zielone światło, wtedy inny obserwator uruchamiał ukryty stoper i mierzył czas, jaki był potrzebny kierowcy na przejechanie skrzyżowania. W wypadku kierowców zaliczonych do grupy kontrolnej eksperymentator po prostu stał na rogu - nie patrząc wprost na kierowców - i mierzył czas, jaki im zajęło przejechanie skrzyżowania.
Eksperyment ten powtarzano kilka razy, w różnych wariantach, a za każdym razem wyniki były te same: kierowcy, w których wpatrywał się eksperymentator, przejeżdżali skrzyżowanie znacznie szybciej niż ci, w których się nie wpatrywano” (Ellsworth, Henson i Carlsmith, 1972).

W tym wypadku kontakt wzrokowy był najwyraźniej bodźcem wywołującym zachowanie typu unikania. Interpretując ten wynik, nie musimy wyciągać wniosku, że wpatrywanie się jest dla ludzi wrodzonym sygnałem zagrożenia lub że współcześni Amerykanie nadal potajemnie pielęgnują wiarę w „złe oko”. Eksperymentatorzy sugerują, że w tej sytuacji wpatrywanie się miało dwie zasadnicze właściwości: a) stwarzało bezsensowną sytuację, w której kierowca nie miał możliwości wykonania żadnej oczywistej, właściwej reakcji oraz b) było dostatecznie silnym bodźcem, aby kierowca czuł się zaangażowany i zmuszony do zareagowania.
Sama bezsensowność sytuacji nie wystarczy, aby wyjaśnić „ucieczkowe” zachowanie kierowców. Wykazało to badanie kontrolne, w którym eksperymentator wykonywał bezsensowną czynność (walenie młotkiem w chodnik), która nie była związana z wpatrywaniem się. Ogólnie biorąc, kierowcy w tych warunkach nie przejeżdżali skrzyżowania szybciej niż w sytuacji bez wpatrywania się - widzieli bezsensowne zachowanie, ale nie mieli poczucia, że ich ono dotyczy. Jedynie wtedy, gdy byli osobiście zaangażowani, brak odpowiedniej reakcji najwyraźniej wzbudzał napięcie i powodował ucieczkę, gdy tylko stała się ona możliwa. Kiedy osoba wpatrująca się dostarcza dodatkowych „sugestywnych” sygnałów, lub wpatruje się w takiej sytuacji, w której reakcje zbliżenia są odpowiednie lub mogłyby okazać się nagradzające, wówczas należałoby oczekiwać, że kontakt wzrokowy będzie bodźcem raczej przyciągającym niż odpychającym.

„Ciało i dusza”. Niewątpliwie były przypadki, kiedy wiedziałeś, że ktoś jest tobą zainteresowany, mimo że osoba ta nie wyraziła tego słowami. Z jakich niewerbalnych sygnałów korzystałeś, by dojść do tego przekonania?  Jak wynika z omówionych wyżej badań, kontakt wzrokowy byłby jedną ze wskazówek zainteresowania tej osoby. Zapewne jednak za oznaki zaangażowania uznałbyś także pewne ruchy ciała i gesty - na przykład zwracanie się twarzą do ciebie, pochylanie się ku tobie, gdy mówisz, wyciąganie ręki, jak gdyby w celu dotknięcia cię (gdy np. ktoś podnosi rękę w geście powitania).  Wszystkie te zachowania są sygnałami, że uwaga danej osoby jest skoncentrowana na tobie. Różni „domorośli psychologowie” dobrze wiedzą, jaka ilość informacji zawarta jest w tego rodzaju ruchach i gestach.




Zbliżenie
„Pokerowe ciało” jest równie ważne jak „pokerowa twarz”


„Zawodowi gracze dobrze zdają sobie sprawę z tego, ilu informacji mogą dostarczać ich niewerbalne zachowania. Aby uniemożliwić innym graczom odgadnięcie, jak silnymi kartami dysponują, zawsze przybierają oni „pokerowy wyraz twarzy”, w możliwie największym stopniu pozbawiony wszelkich oznak emocji czy zainteresowania. Jednakże nowicjusze często nie wiedzą, że ich ruchy mogą być równie wymowne jak ich twarz. Bystrooki przeciwnik może ocenić siłę ich kart obserwując, czy siedzą blisko stołu czy też opierają się wygodnie, czy kładą stawkę szybko czy powoli, czy swoje żetony umieszczają w środku puli czy bliżej siebie itd. Aby uchronić się przed tym, doświadczeni pokerzyści utrzymują nie tylko stały wyraz twarzy, lecz także stałą, jednakową ekspresję |ciała. Przez cały czas trwania gry utrzymują tę samą postawę, kładą żetony w tym samym miejscu, takim samym ruchem i z tą sama szybkością”.
Ruchy i postawa ciała są również dobrymi (aczkolwiek subtelnymi) wskaźnikami pozycji (statusu) ludzi. Gdy dwaj ludzie spotykają się ze sobą, wówczas bardziej rozluźnioną postawę przybiera zwykle ten, kto ma wyższy status. Oznacza to, że osoba o wyższej pozycji będzie raczej siedzieć niż stać, rozsiądzie się wygodnie lub podeprze zamiast siedzieć wyprostowana, a także przybierze podstawę bardziej asymetryczną (np. założy nogę na nogę lub weźmie się pod boki). Przyjęcie bardziej rozluźnionej postawy przez osobę o niższym statusie uważa się na ogół za zachowanie świadczące o braku szacunku lub nawet wyzywajce. Dlaczego właściwie rozluźnienie ma świadczyć o wyższym statusie? Jedno z możliwych wyjaśnień wskazuje, że wysoki status był w przeszłości zależny od siły. Silni ludzie są mniej lękliwi i mniej czujni od słabych, a więc mogą pozwolić sobie na to, aby odprężyć się lub odwrócić plecami do innych (Mehrabian, 1969b).
Nie tylko postawa ciała, lecz także sposób chodzenia może wyrażać pewność siebie i status. Ktoś, kto chodzi sztywno lub niezdecydowanie, wywiera zupełnie inne wrażenie niż ten, kto stąpa żwawo i bez wysiłku. W niektórych wypadkach informacje zawarte w sposobie chodzenia danej osoby są znacznie ważniejsze niż fakt, że zdąża ona do określonego miejsca przeznaczenia.  Szczególnie żywym przykładem tego jest tak zwany murzyński chód („black walk”), dość typowy dla młodych czarnych mężczyzn, zwłaszcza w dzielnicach tworzących getto murzyńskie. Chód ten jest właściwie niedbałym i rytmicznym przechadzaniem się. Jedna ręka, z dłonią lekko stuloną, kołysze się wzdłuż boku, podczas gdy druga ręka albo zwisa miękko, albo też palce jej wsunięte są do kieszeni. Głowa bywa lekko podniesiona i przechylona na bok. Do tego podstawowego wzorca każdy mężczyzna dodaje pewne oryginalne komponenty, tworząc swój własny, indywidualny styl. Chodząc w ten sposób, czarnoskórzy mężczyźni komunikują szereg informacji o sobie - o swym szacunku dla samego siebie, męskości, opanowaniu oraz (gdy jest to reakcja na naganę) o odrzuceniu autorytetów (Johnson, 1971).
Inną ekspresyjną formą ruchów ciała są gesty. Potakiwanie czy przeczenie ruchem głowy, uścisk dłoni, rozkładanie rąk, czy wskazywanie - oto przykłady tego rodzaju ekspresji. Podobnie jak wiele innych zachowań niewerbalnych, gesty mogą informować o emocjach, statusie, przychylności lub zainteresowaniu.




Zbliżenie
Ręce, które lubią tańczyć


„Niektórzy pedagodzy utrzymują, że ci nauczyciele, którzy z reguły gestykulują, uzyskują lepsze efekty nauczania. Jeśli to spostrzeżenie jest prawdziwe, to w jaki sposób moglibyśmy je wyjaśnić? Jedna z możliwych odpowiedzi jest następująca: stwierdzono, że częste gestykulowanie stanowi element ogólnego afiliatywnego stylu, który mówi o pozytywnych uczuciach danej osoby wobec otoczenia (Mehrabian, 1971a).

Taki styl wywołuje zwykle wzajemną sympatię i współpracę ze strony innych ludzi. Nauczyciel, który stosuje wiele gestów (jak ten, którego widzimy na zdjęciach), wyraża zatem prawdopodobnie pozytywne uczucia w stosunku do swoich uczniów, co prowadzi do ich większego zaangażowania w naukę. W wypadku nauczyciela, który jest mniej swobodny i bardziej kontroluje swoje gesty, należałoby oczekiwać przeciwnych rezultatów. Ponieważ miałeś sposobność obserwować wielu nauczycieli w akcji, jakie jest twoje zdanie? A może zaczniesz systematycznie zbierać dane do własnych badań na ten temat”?

Terapeuci od dawna zdają sobie sprawę z doniosłego znaczenia gestów (jak również innych zachowań niewerbalnych) w sytuacji terapeutycznej, lecz dopiero w ostatnich latach przeprowadzono nad nimi systematyczne badania.  Ekman i Friesen (1968) filmowali wywiady kliniczne z pacjentami w czasie przyjmowania ich do szpitala psychiatrycznego i tuż przed zwolnieniem.  Analizując gesty pacjentów i towarzyszące im wypowiedzi, badacze zidentyfikowali indywidualne wzorce komunikacji niewerbalnej, które odzwierciedlały stan psychiczny pacjentów. U pewnej pacjentki pocieranie rąk o krzesło zdawało się wskazywać na stan podniecenia i niepokoju. U innej, charakterystyczne wzruszanie ramionami skazywało na gniew wynikający z frustracji.

„Niewidzialne ściany”. Próbując odpowiedzieć na nasze wcześniejsze pytanie: „Skąd wiesz, że ktoś jest zainteresowany tobą?”, pomyślałeś może (poprawnie), że ważny byłby tu czynnik |odległości. Ogólnie biorąc, im bardziej dwie osoby są zainteresowane sobą nawzajem, tym bliżej siebie się trzymają. Jednakże badania z zakresu proksemiki wykazały, że istnieje granica określająca, na jaką odległość ludzie pozwalają się zbliżyć innym do siebie, o ile stosunki między nimi nie mają charakteru intymnego. U Amerykanów ta niewidzialna granica, czyli „bańka prywatności”, rozciąga się na odległość około 45 - 60 cm wokół nich. Każdy kto narusza tę granicę, zbliżając się na zbyt małą odległość, wywołuje zwykle silne napięcie, niepokój i zażenowanie u danej osoby, która stara się przywrócić właściwą odległość cofając się lub odsuwając. Ponieważ w różnych kulturach istnieją różne poglądy na to, jaka jest „właściwa” odległość, łatwo mogą powstać nieporozumienia. Na przykład „niewidzialna granica” u mieszkańców Ameryki Łacińskiej przebiega w mniejszej odległości od ciała niż u mieszkańców Ameryki Północnej. Jeśli Latynos i obywatel Stanów Zjednoczonych zaczną rozmawiać ze sobą, to pierwszy z nich będzie zwykle przysuwał się bliżej, w celu zapewnienia „właściwej” odległości. W odpowiedzi na to Amerykanin z Północy zacznie się odsuwać. Każdy z nich prawdopodobnie wytworzy sobie w końcu ujemną opinię o swym rozmówcy - pierwszy będzie myślał, że drugi jest bardzo oziębły i „na dystans”, gdy drugi uzna pierwszego za wielce natrętnego i agresywnego (Hall, 1966).
Co jednak będzie, jeśli dana osoba nie może odsunąć się od kogoś, kto zbliżył się na zbyt małą odległość - jak upora się z tą przymusową poufałością? Dobrą ilustracją tego problemu może być zatłoczona winda, gdzie ludzie często stoją bardzo blisko kilku nieznajomych osób.  Rozwiązanie stosowane przez większość ludzi polega na odwróceniu się od współpasażerów i unikaniu kontaktu wzrokowego z nimi. W windzie ludzie patrzą zatem zwykle w milczeniu albo na drzwi, albo na wskaźnik pięter, starając się wytworzyć dystans psychiczny tam, gdzie dystans fizyczny nie istnieje.

„Gdy oczy mówią jedno, a usta drugie, wówczas doświadczony człowiek polega na mowie oczu”.
Ralph Waldo Emerson „Conduct of Life”, 1860

„Słyszę to z twoich ust, lecz nie mogę zobaczyć tego w twoich oczach”.  Chociaż istnieje wiele różnych kanałów komunikacji, służących do wyrażania myśli i uczuć (werbalny, wokalny, mimiczny, ruchowy) to jednak zakładamy zwykle, że wszystkie one wyrażają to samo. Jeśli ktoś mówi „Jestem szczęśliwy”, to oczekujemy, że powie to w sposób radosny, że będzie się przy tym uśmiechał, że jego ruchy będą żywe i swobodne. Jeżeli jednak istnieje rozbieżność między różnymi kanałami, to jak wówczas ocenimy tę reakcję? Przypuśćmy, na przykład, że ktoś powiedział „Jestem szczęśliwy” drżącym głosem, z trzęsącymi się rękoma. Czy pomyślałbyś, że rzeczywiście czuje się szczęśliwy? Czy też byłbyś bardziej skłonny określić tę reakcję jako zdenerwowanie lub strach? Jeśli opowiedziałbyś się za tą drugą możliwością, wówczas oznaczałoby to, że polegasz bardziej na sygnałach niewerbalnych niż werbalnych.

* * *

Ryc. 4.6. Unikanie kontaktu wzrokowego jest sposobem zachowania swej odrębności w grupie osób obcych sobie, a zmuszonych przebywać blisko siebie.
Jak wykazują badania, jest to charakterystyczna reakcja na rozbieżne informacje. Na podstawie tych danych Mehrabian (1971a) sformułował prowizoryczny wzór przedstawiający wływ każdego z kanałów na ogólną interpretację przekazanej informacji: |Ogólne |uczucie |= |7|% uczucia |wyrażonego |słowami |+ |38|% uczucia wyrażonego |głosem |+ |55|% |uczucia |wyrażonego |mimiką.

* * *
Równanie to podaje ocenę względnej ważności tych kanałów: wskazuje, że ludzie skłonni są najbardziej ufać twarzy, a - najmniej słowom. Może to wynikać stąd, że kanał werbalny jest najbardziej świadomie sterowany i kontrolowany przez nadawcę. Przypuszczalnie kanały niewerbalne nie są tak dobrze kontrolowane i dlatego odzwierciedlają w sposób bardziej bezpośredni głębsze, prawdziwe uczucia i podstawy danej osoby.
Sarkazm jest dobrym przykładem tego niespójnego komunikatu, o którym tu mówimy. W sarkastycznej wypowiedzi człowiek formułuje werbalnie sąd dodatni (np. „To jest wspaniałe”), lecz mówi to „negatywnym” tonem głosu i (lub) z grymasem na twarzy, który implikuje: „To jest okropne”. Przeciwieństwo sarkazmu (na określenie którego nie istnieje odrębny termin) jest również typowym przykładem niespójnego komunikatu. Dana osoba mówi coś negatywnego (np. „Ty idioto”), lecz w sposób tak pozytywny pod względem niewerbalnym, że cały ten komunikat jest interpretowany jako serdeczna, żartobliwa akceptacja. Takie niespójne komunikaty występują w sytuacji, w której mówiący ma mieszane uczucia w stosunku do danej osoby, czy zdarzenia. Na przykład, jeśli ktoś mówi „Ty idioto” do przyjaciela, który właśnie popełnił głupi błąd, to pozytywny komponent niewerbalny tego komunikatu wskazuje, że osoba ta nadal lubi swego przyjaciela, mimo chwilowego zdenerwowania czy rozczarowania z powodu owego błędu.
Niekiedy takie niespójne komunikaty mogą wywierać bardzo ujemny wpływ na ludzi, a nawet powodować trwałe zaburzenia. Wyobraź sobie rodzinę, w której dzieciom mówi się, że są kochane, lecz jednocześnie stale otrzymują oni niewerbalne komunikaty, że rodzice są wobec nich obojętni lub niechętni.  Jakie, twoim zdaniem, może to mieć konsekwencje? Ten sposób komunikowania się terapeuci zaobserwowali w rodzinach dzieci cierpiących na schizofrenię, co doprowadziło do wysunięcia teorii schizofrenii, zwanej |teorią |blokady („podwójnego wiązania”; „doublebind theory” - Bateson, Jackson, Haley i Weakland, 1956). Według tej teorii, komunikat blokujący jest to taki komunikat, który zawiera dwie (lub więcej) niezgodne informacje, wymagające od danej jednostki niemożliwych do pogodzenia reakcji. Jako przykład Bateson i jego współpracownicy przytaczają przypadek młodego schizofrenika, którego odwiedziła w szpitalu matka. Gdy powitał ją uściskiem - zareagowała na to bardzo sztywno; gdy cofnął ramiona - zapytała: „Czy już wcale mnie nie kochasz?”. Młody człowiek stał więc wobec niemożliwego do rozwiązania dylematu: „Jeśli chcę utrzymać moją więź z matką, to nie mogę okazywać jej, że ją kocham, lecz jeśli nie będę jej okazywać, że ją kocham, to ją utracę”. Zdaniem autorów, u ludzi stale otrzymujących takie „rozdwojone” komunikaty kształtują się nieprzystosowawcze formy funkcjonowania interpersonalnego i często uczą się oni sami reagować „rozdwojonymi” komunikatami. Syn z powyższego przykładu mógłby zatem powiedzieć matce, że nie może jej uściskać, ponieważ ma skaleczoną rękę lub dlatego, że „Jan” go przytrzymuje (w obu przypadkach wymówki te są tworem wyobraźni). Za pomocą takiego „rozdwojonego” komunikatu wyraża on swoje pragnienie okazania uczucia matce, a zarazem zabezpiecza się przed koniecznością zrealizowania tego pragnienia.


Komunikowanie się zwierząt


Czy tylko ludzie są obdarzeni mową? Czy istnieje możliwość, że inne gatunki także mają swoje własne systemy językowe? Chociaż istnieją niewątpliwie sygnały, za pomocą których zwierzęta komunikują się ze sobą (takie jak popisy w czasie zalotów, krzyki ostrzegawcze lub wojownicze postawy), to jednak dotychczas brak naprawdę solidnych dowodów wskazujących, że dysponują one złożonym systemem językowym ze słowami i gramatyką, takim, jaki mają ludzie. Jak dotąd, jedynym uczonym, któremu udało się odkryć mowę zwierząt, był fikcyjny doktór Dolittle, który nie tylko rozumiał różne języki zwierzęce, lecz także potrafił nimi mówić.  Niemniej jednak nadal prowadzi się w tej dziedzinie wiele badań, nie tylko po to, by zrozumieć, jak zwierzęta porozumiewają się ze sobą, lecz także w celu lepszego poznania specyficznych aspektów ludzkiej mowy.



Zbliżenie
Ptaki posługują się tym samym „dialektem” trzymają się razem


„Potrafisz niewątpliwie rozpoznać, z jakich regionów pochodzą niektórzy twoi koledzy, na podstawie pewnych charakterystycznych form językowych występujących w ich mowie - to znaczy na podstawie używanego przez nich dialektu. Czy wiesz jednak, że ptaki też mają swoje „dialekty”? Naukowcy prowadzą badania nad pewną odmianą wróbla („white-crowned sparrow”), małym śpiewającym ptaszkiem zamieszkującym Amerykę Północną, stwierdzili, że w śpiewie tych ptaków występują różnice regionalne i że różnice te wiążą się z ważnymi formami zachowania.
Analiza spektogramów dźwiękowych pieśni godowych 18 samców pochodzących z trzech miejscowości położonych w pobliżu Zatoki San Francisco wykazała, że pewne cechy śpiewu są takie sama u ptaków z tej samej miejscowości, lecz zupełnie inne, niż u samców tego samego gatunku zamieszkujących obszar oddalony zaledwie o 60 mil.
Wspomniane wyżej badania Petera Marlera (1967) i jego współpracowników z Rockefeller University ujawniły pewne interesujące analogie z rozwojem mowy u dzieci i pojęciem „wspólnoty językowej”.
1. Ptak ma predyspozycje do uczenia się określonych układów dźwięków - podobnie pewne aspekty mowy u ludzi zdają się być wrodzone.
2. Młody ptak musi mieć możność słyszenia własnego głosu; słuchowe sprzężenie zwrotne jest potrzebne, aby mógł on „przełożyć” zapamiętany śpiew swych rodziców na aktywność motoryczną i w ten sposób „wytworzyć” własny śpiew.
3. Śpiew u młodych ptaków nie pojawia się nagle, lecz rozwija się z czasem w miarę ćwiczenia: poprzedzają go stadia przejściowe, które można by określić jako „podśpiewy”.
4. Układy dźwięków charakterystyczne dla danego „dialektu” są przekazywane z pokolenia na pokolenie za pośrednictwem procesu uczenia się.
5. Istnienie dialektów powoduje, że lokalne populacje utrzymują się jako odrębne zbiorowości, ponieważ ptaki mają tendencję do łączenia się w pary z osobnikami posługującymi się tym samym „dialektem”.
6. Wzorce zachowania, które tworzą tę „społeczność wspólnego śpiewu”, są wyznaczane raczej przez czynniki środowiskowe niż genetyczne”.

Gwiżdżące delfiny. W ostatnich latach wiele uwagi poświęcono systemom komunikacji u delfinów, po części dlatego, że sądzono, iż dźwięki wydawane przez te zwierzęta pod wodą tworzą prawdziwy język. Jeden rodzaj tych dźwięków to serie „kłapnięć”. Jednakże badania wykazały, że kłapnięcia te służą jedynie jako podwodna sonda dźwiękowa („sonar”) do badania otoczenia.  Emitując dźwięk, który zostaje odbity w postaci echa, delfin (podobnie jak nietoperz) może ustalić położenie przedmiotów.
Innym dźwiękiem wydawanym przez delfiny jest „gwizd”. Wydają go osobniki obojga płci i w każdym wieku - nawet nowo narodzone delfinki. Ten specyficzny dźwięk jest zupełnie nietypowy dla ssaków (z wyjątkiem ludzi) i wielu badaczy przypuszczało, że może on pełnić funkcję prawdziwego języka.  Jednakże najnowsze badania zdają się podważać to przypuszczenie.  Stwierdzono, że gwizdy pojedynczego delfina są bardzo stereotypowe i bardzo powtarzalne. Chociaż istnieją różnice między typami gwizdów wydawanych przez różne delfiny, to jednak poszczególne gwizdy nie są dostatecznie zróżnicowane pod względem swej formy, by uzasadniało to uznanie ich za język. Gwizd zdaje się raczej spełniać cztery funkcje |społeczne: 1) sygnalizuje innym delfinom obecność danego delfina, 2) umożliwia identyfikację oraz 3) lokalizację tego delfina, wreszcie 4) dostarcza ogólnych wskazówek o stanie emocjonalnym gwiżdżącego zwierzęcia (Caldwell i Caldwell, 1972).
Uzyskano dane eksperymentalne stanowiące potwierdzenie pierwszych trzech funkcji, a obecnie zbiera się dane świadczące o istnieniu czwartej.  Caldwellowie wykazali, że delfiny potrafią doskonale rozróżniać gwizdy poszczególnych osobników, zarówno należących do tego samego, jak i do innych gatunków. Potrafią one ponadto ustalić miejsce, gdzie znajduje się inny delfin, na podstawie jego gwizdu. Badacze ci stwierdzili także, że delfiny dużo gwiżdżą wtedy, gdy są w stanie podniecenia emocjonalnego, lecz natychmiast przestają gwizdać, gdy są przestraszone. Najwyraźniej delfiny nie nauczyły się jeszcze ludzkiego „triku” polegającego na tym, że gwiżdżemy wesołą melodię, aby inni nie poznali, że jesteśmy w strachu.
Smutnym, lecz prawdziwym jest fakt, że badacze, którzy uzyskali dowody obalające popularny mit, często stają się bardzo niepopularni i witani są okrzykami: „Powiedzcie, że tak nie jest!” Caldwellowie piszą o tym, co następuje:

„Zdziwienie, jakie odczuliśmy stwierdzając, że gwizdy pojedynczego delfina są bardzo stereotypowe, było niczym w porównaniu z naszym zaskoczeniem na widok nieokiełznanego gniewu, który wywołaliśmy, gdy musieliśmy sformułować ten wniosek. Było to nieprzyjemne doświadczenie, ponieważ my również chcemy być lubiani przez naszych kolegów, wzbudzać uznanie, a nie gniew. Byliśmy zmuszeni wystąpić w roli burzycieli jednego z niewielu mitów, jakie pozostały naszemu nieoświeconemu gatunkowi, chociaż wcale tego nie chcieliśmy. Z początku mieliśmy nadzieję, że gwizdy delfinów okażą się przynajmniej pieśniami podobnymi do ptasich, lecz nie znaleźliśmy na to żadnych dowodów (...). Na podstawie aktualnego materiału dowodowego, w przeciwieństwie do autorów niektórych wcześniejszych prac, nie sądzimy, aby gwizdy bądź serie impulsów dźwiękowych wydawanych przez delfiny były używane do czegokolwiek innego, niż komunikowanie się w bardzo ogólnym sensie” (1972, s. 25-26).

* * *
Ryc. 4.7. Strumienie pęcherzyków wskazują, że delfiny te właśnie gwiżdżą.  Jednakże wydawane przez nie dźwięki zdają się służyć raczej jako środek identyfikacji, niż komunikowania się.
* * *
Badania nad mową małp. Dlaczego ludzie są jedynymi istotami obdarzonymi mową? Czy zawdzięczają to ewolucji i wrodzonym strukturom umysłowym, czy też środowisku, które idealnie sprzyja uczeniu się języka, a do którego inne gatunki nie mają dostępu?
W ciągu ostatnich czterdziestu lat przeprowadzono szereg eksperymentów w celu ustalenia, czy u szympansów wychowywanych w rodzinie ludzkiej uda się rozwinąć umiejętności komunikowania się podobne do tych, jakie wykazują dzieci. Młody szympans szybko przystosowuje się do swego środowiska fizycznego i społecznego, przywiązuje się bardzo do swego opiekuna, naśladuje czynności dorosłych bez żadnego ćwiczenia, a rozwój zachowania ruchowego jest u niego szybszy niż u dziecka w podobnym wieku. Co się jednak tyczy rozwoju mowy, uzyskane wyniki nie są zbyt imponujące. Żaden z szympansów objętych badaniami nigdy nie naśladował ani nie odtwarzał spontanicznie dźwięków słów ludzkich, nie ma też żadnych dowodów na to, że próbowały one to czynić. Nie występował też żaden okres gaworzenia czy przypadkowego emitowania dźwięków (poza szczekaniem, płaczem , „uu-uu” i skrzeczeniem).
Jedno małżeństwo badaczy zdołało nauczyć swą szympansicę Viki wymawiać cztery słowa: „mama”, „papa”, „cup” (kubek) i „up” (do góry). Viki nauczyła się tych słów z wielką trudnością, dopiero po dłuższym ćwiczeniu, a nawet wówczas nie potrafiła wymawiać ich z prawdziwą łatwością ani nie potrafiła utrzymać bez zmiany ich poprawnej formy dźwiękowej (Hayes i Hayes, 1952).  Znacznie lepsze wyniki uzyskiwały szympansy w zakresie zrozumienia mowy - jeden z nich opanował w ciągu 9 miesięcy 58 specyficznych, poprawnych układów reakcji na proste polecenia podawane przez człowieka, podczas gdy wychowywany razem z nim mały chłopczyk opanował w tym czasie 65 takich układów (Kellogg i Kellogg, 1933).

„Washoe mówi Amerykańskim Językiem Znaków...” Jeśli szympansy potrafią zrozumieć, gestykulować i naśladować, to może kluczem do przyswojenia sobie języka jest u tego gatunku komunikacja bezgłośna, za pomocą jakiegoś rodzaju znaków? W czerwcu 1966 roku Allen i Beatrice Gardnerowie, psychologowie z University of Nevada, rozpoczęli intensywne badania nad przyswajaniem sobie języka przez małpy. W tym celu posłużyli się „Amerykańskim Językiem Znaków” (ASL - „American Sing Language”), kodem arbitralnie dobranych symboli, opracowanych dla głuchoniemych, za pomocą którego porozumiewali się z hodowaną przez siebie samicą imieniem Washoe.  Dbając, aby była to jedyna forma komunikowania się między Washoe a jej opiekunami, Gardnerowie (1969) donieśli o osiągniętych znacznych postępach i perspektywach na przyszłość.
W ciągu pierwszych siedmiu miesięcy Washoe przyswoiła sobie cztery znaki, którymi posługiwała się w wiarygodny sposób: „przyjść”, „więcej”, „do góry”, „słodkie”. Ponadto rozumiała ona więcej znaków, niż stosowała. Przez następne siedem miesięcy przyswoiła sobie 9 dalszych znaków, a do jesieni 1970 roku opanowała ponad 160 znaków. Kryterium przyswojenia znaku było surowe: właściwe i nie wynikające z naśladowania stosowanie go w każdym z piętnastu kolejnych dni.
Również i inni psychologowie, na przykład Roger Brown (1970), notowali dokładnie to, co Washoe „mówiła” za pomocą znaków; czynili to jednak nie ze względu na rozmiary jej słownika, lecz dlatego, że spontanicznie stosowała wiele (29) znaków dziennie, zaczynała wiązać swoje słowa - znaki w proste zdania i wykazywała umiejętność zarówno generalizacji, jak i różnicowania.  Na przykład stosowała ten sam znak „więcej”, zarówno gdy chodziło o kontynuowanie zabawy, jak i dodatkową porcję pokarmu; znak „otworzyć” - w odniesieniu do otwarcia drzwi, butelki wody sodowej lub zamka błyskawicznego. Tworzone przez nią sekwencje znaków, takie jak „Dać prosić pokarm”, „Prosić drapać więcej”, „Szybko dać szczoteczkę”, „Ty mnie wejść tam” lub „Roger Washoe łaskotać”, nie są po prostu szeregami słów, lecz konstrukcjami sensownymi semantycznie. Nie są one jednak poprawne pod względem składni i nie wykazują żadnych reguł, jeśli chodzi o kolejność znaków. Jest to poważna różnica w porównaniu z rozwojem mowy u dzieci i w przyszłości trzeba będzie zbadać ją dokładniej.
Roger Fouts, który uprzednio pisał pracę magisterską pod kierunkiem Gardnerów, przeniósł się z Washoe do „Institute for Primate Studies” (Instytut Badań nad Naczelnymi) w Norman w stanie Oklahoma, gdzie prowadzi się badania nad zastosowaniem ASL z coraz większą liczbą szympansów (Fleming, 1974).

„...Sarah pisze na tablicy...” David Premack i jego współpracownicy, posługując się nieco innym sposobem podejścia, z dużym powodzeniem uczyli swoją szympansicę, imieniem Sarah, porozumiewania się przez układanie zdań z kolorowych plastikowych żetonów na tablicy magnetycznej. Sarah najpierw uczyła się, dzięki zastosowaniu prostych procedur warunkowania, kojarzyć żeton określonej barwy i kształtu z określonym owocem - poprawnie zidentyfikowany owoc pozwolono jej zjadać jako nagrodę. Inne żetony stały się „imionami” eksperymentatorów lub reprezentowały pewne czynności, a Sarah wkrótce już rozumiała i konstruowała zdanie takie, jak „Mary dawać jabłko Sarah” czy „Sarah włożyć banan wiadro”.
Następny krok polegał na ustaleniu, czy Sarah potrafi nauczyć się pojęć relacyjnych, takich jak „na” czy „pod”. Posługując się najpierw kolorowymi kartami, a następnie plastikowymi „nazwami” barw, wkrótce nauczyła się wypełniać polecenia i umieszczać „czerwone na zielonym” lub na odwrót. Inny typ relacji, jeszcze bardziej abstrakcyjny, najlepiej można określić jako „jest nazwą”. Gdy pokazywano Sarah jakiś symbol i kawałek owocu, wówczas szybko nauczyła się używać symboli oznaczających relacje: „jest nazwą” i „nie jest nazwą”, do konstruowania takich zdań, jak: „(symbol) nie jest nazwą jabłka”. Jednakże szczytowym punktem kariery „pisarskiej” Sarah był chyba dzień, w którym wyraźnie znudzona udziałem w zajęciach, ułożyła szereg niekomletnych zdań i dała swemu zdumionemu trenerowi test uzupełniania zdań z odpowiedziami do wyboru! (Premack, 1969, 1970).

* * *
Ryc. 4.8. Wszystkie widoczne tu szympansy są bardzo rozmowne, każdy na swój sposób. Washoe (z prawej u góry) poprosi o napój posługując się Amerykańskim Językiem Znaków. Sarah (z prawej poniżej) „pisze” swą prośbę o czekoladę na tablicy magnetycznej. Lana (z lewej poniżej) wypisuje zdania na skomplikowanej klawiaturze komputera. Wszystkie trzy pomagają nam lepiej zrozumieć procesy komunikacji.
* * *

„...a Lana rozmawia z komputerem”. W Yerkes Primate Research Center w stanie Georgia zastosowano trzecią metodę badania możliwości językowych szympansów. Trzyletnia Lana nauczyła się tam „czytać” symbole na tablicy kontrolnej komputera i „wpisywać” na niej za pomocą klawiszy swoje prośby (o pokarm, muzykę itd). Komputer nagradzał tylko „poprawne pod względem gramatycznym zdania” - to znaczy szeregi symboli następujących po sobie we właściwej kolejności - i Lana nauczyła się nie tylko formułować poprawnie swoje prośby, lecz także kasować i poprawiać „niegramatyczne” zdania prezentowane przez komputer (Rumbaugh, Gill i von Glasersfeld, 1973).
Według ostatnich doniesień, Lana posługuje się efektywnie ponad 74 symbolami słów. Jeszcze bardziej uderzające jest to, że teraz nie czeka już biernie na nowe polecenia, lecz prosi swych nauczycieli, by podawali nazwy przedmiotów, które ją interesują.

„A teraz, wszystkie razem...” Washoe i Sarah nauczyły się swoich systemów językowych od ludzi, a Lana w wyniku interakcji z komputerem. Jak dotąd, używały ich tylko do komunikowania się z ludźmi. Przypuśćmy jednak, że są one w towarzystwie innych szympansów, które także znają ten sam system. Czy szympansy używałyby tego języka do porozumiewania się między sobą?Szympansy z Oklahomy, które nauczyły się języka znaków od ludzi ćwiczących je w tej umiejętności, często posługiwały się tymi znakami, gdy porozumiewały się między sobą. Na przykład jeden z szympansów reagował zwykle na znak dany mu przez drugiego, polecający „przyjść, przytulić” lub „przyjść, szybko”.  Niekiedy zwierzęta te korzystały ze znaków przy urządzaniu zabaw - na przykład jeden z szympansów poprosił drugiego: „Przyjść, łaskotać”.  Pierwszy szympans z tej pary gonił wówczas drugiego, aż wreszcie gonitwa kończyła się „sesją” wzajemnego łaskotania.
Szympansy nie tylko potrafią stosować swój język znaków w dialogach z osobnikami innymi niż ćwiczący je ludzie, lecz ponadto są dane, że wynajdują one własne znaki w celu lepszego porozumienia się. W jednym z takich przypadków szympansica Lucy podeszła do badaczy i pokazała zupełnie nowy znak - zgięła palec wskazujący na kształt haczyka i dotknęła nim swej szyi. Psychologom nietrudno było się domyślić, że znak ten odnosi się do szyi Lucy i że zwierzę prosi, by je wiąć na spacer.
Wyniki tych badań nasuwają szeregi interesujących pytań. Czy taki system językowy pozwala szympansom komunikować się w sposób bardziej precyzyjny?  Czy mogłyby one teraz rozwijać samodzielnie ten język przez tworzenie wielu nowych, własnych znaków? Czy byłoby możliwe, żeby nauczyły one inne szympansy posługiwania się swym nowo przyswojonym systemem językowym? (Lucy pewnego razu próbowała uczyć kotka, lecz zrezygnowała, gdy jej wysiłki nie przynosiły żadnych rezultatów).
Osiągnięcia Sarah, Lany oraz szympansów z Oklahomy wyraźnie podważają dotychczasowe poglądy na temat ograniczonych możliwości językowych u gatunków stojących na drabinie ewolucyjnej niżej niż człowiek. Zakres, w jakim szympansy te potrafią komunikować się z ludźmi (jak również ze sobą nawzajem) za pomocą wspólnego systemu językowego, stwarza pewne nadzieję, iż posiadana przez dr. Dolittle’a umiejętność „rozmawiania ze zwierzętami” może nie być mimo wszystko czystą fantazją.



Pamięć


Pomyśl przez chwilę o wszystkich skomplikowanych informacjach, jakie przyswoiłeś sobie w szkole: gramatyka, języki obce, wzory chemiczne, dowody geometryczne, reguły rozumowania sylogistycznego i wiele innych. Następnie zastanów się, o ile więcej musiałeś się nauczyć - poza klasą szkolną - o swym środowisku, a zwłaszcza o ludziach i instytucjach. Część tych wiadomości przyswoiłeś sobie łatwo i w sposób „naturalny”; nauczenie się innych wymagało od ciebie ciężkiej pracy.
Również nie wszystko zapomina się tak samo. Czy nie zdarzyło ci się opanować jakiegoś materiału tak dobrze, że dostałeś „piątkę”, aby po paru miesiącach stwierdzić, iż zapomniałeś większość tego, czego się nauczyłeś?  Lecz z drugiej strony, czyż nie pamiętasz jeszcze wszystkich szczegółów związanych z twoją pierwszą „prawdziwą randką”? Studenci często potrafią przypomnieć sobie nazwiska wszystkich swoich nauczycieli ze szkoły podstawowej, lecz zapominają nazwiska profesora psychologii i tytuł podręcznika następnego dnia po egzaminie końcowym.
Kiedy jednak założysz łyżwy, zaczniesz ćwiczyć ze skakanką lub spróbujesz przypomnieć sobie taniec, którego nie tańczyłeś od lat, to prawdopodobnie stwierdzisz, że po krótkim czasie robisz to prawie równie dobrze, jak niegdyś. Dlaczego niektóre rzeczy przechowujesz w pamięci znacznie dłużej niż inne? Czy różnica ta jest uzależniona od rodzaju przyswajanego materiału, czy jakiś aspekt sposobu uczenia się decyduje o tym, jak dobrze będziesz potrafił przypomnieć sobie później ten materiał? A może to ma coś wspólnego ze sposobem, w jaki twój mózg przechowuje informacje, których się „nauczył”?
W naszych wcześniejszych rozważaniach nad warunkowaniem i procesami nerwowymi mówiliśmy tak, jak gdyby zawsze istniał bezpośredni, wzajemnie jednoznaczny związek między przychodzącymi bodźcami a reprezentacją tych bodźców w układzie nerwowym. W wielu prostych przypadkach możemy założyć, że praktycznie bodziec „na zewnątrz” jest taki sam, jak nasza percepcja tego bodźca, a zatem reakcje, jakie dany bodziec wywołuje w naszym układzie nerwowym, będą zawsze podobne.
Jednakże w większości przypadków interakcji człowieka ze środowiskiem nie jesteśmy tak bezpośrednio uzależnieni od bodźców, które na nas oddziaływują. Możemy przetwarzać przychodzącą informację w różny sposób, a nie tylko reagować na kolejno pojawiające się bodźce. U ludzi, w znacznie większym stopniu niż u innych gatunków, przetwarzanie informacji polega nie tylko na odbieraniu i dokładnym kodowaniu przychodzącej informacji, lecz także na jej selekcji, reorganizacji i transformacji. Główną przyczyną tego selektywnego kodowania jest po prostu fakt, że informacji wejściowej jest zbyt wiele, abyśmy mogli wykryć każdy bodziec, który mieści się w zakresie wrażliwości naszych systemów sensorycznych i nie wykracza poza naszą zdolność różnicowania, aby jednak uchronić od przeciążenia układy przetwarzające i magazynujące informacje, wytworzyliśmy operacje umożliwiające selektywne organizowanie i kodowanie wszelkich przychodzących bodźców. Czy jednak takie przeorganizowanie napływającej informacji ma wpływ na dostęp do niej, gdy później chcemy ją odszukać? Oto następne zagadnienie, którym będziemy się zajmować w tym rozdziale.
Efekty uczenia się u człowieka są w większości przypadków zależne w tym samym stopniu od naszej szczególnej zdolności przetwarzania informacji, co i od naszej zdolności przechowywania nowej wiedzy czy zmiany sposobu reagowania. Przetwarzanie i kodowanie informacji są zatem ważnymi komponentami uczenia się spostrzegania, uczenia się umiejętności motorycznych, uczenia się mowy oraz przyswajania i zapamiętywania materiału słownego i pojęciowego.
Zauważyłeś już może, że dokonaliśmy rozróżnienia między uczeniem się a pamięcią. Psychologowie w swych badaniach przeprowadzają zwykle to rozróżnienie. Psycholog badający uczenie się obserwuje zmiany w wykonaniu zadania zachodzące z próby na próbę lub ustala, jak dobrze badany potrafi w końcu wykonać określone zadanie po różnych rodzajach ćwiczenia - tak więc przedmiotem jego zainteresowania są zmiany w wykonaniu będące wynikiem doświadczenia.

Przy badaniu pamięci interesuje nas to, czy materiał wyuczony w danym czasie w przeszłości jest dostępny dla badanego w wyznaczonym czasie obecnie. Testy pamięci wymagają więc odtwarzania przeszłości w czasie teraźniejszym. Psychologiczne badania procesów pamięciowych ma doprowadzić do zrozumienia a) w jaki sposób magazynowana jest wiedza, b) jak trwale przechowywana jest w pamięci zmagazynowana wiedza oraz c) jak zmagazynowana wiedza jest odszukiwana dla jej wykorzystania. Bodźcami najczęściej stosowanymi w tych badaniach są słowa (w niektórych przypadkach słowa sztucznie utworzone), liczby i obrazki. Z historycznego punktu widzenia jest interesujące, że wielu psychologów, w latach czterdziestych, pięćdziesiątych i sześćdziesiątych badali uczenie się zwierząt oraz podstawowe prawa warunkowania i uczenia się instrumentalnego, obecnie przenosi swe zainteresowania na „przetwarzanie informacji u ludzi”, „psychologię poznawczą” czy też „język i pamięć”. Ludzie zwyciężyli! W istocie nie ma chyba dziedziny psychologii, w której obecnie prowadzono by więcej intensywnych i nowatorskich badań, czy która miałaby większe możliwości, jeśli chodzi o rozwijanie nowych koncepcji dotyczących funkcjonowania ludzkiego umysłu.
A teraz zanim przeczytasz, co wiemy o pamięci ludzkiej, sprawdź najpierw swoje własne zdolności pamięciowe.


Zbliżenie
Test pamięci


„Poniżej podany jest szereg złożony z dwudziestu liczb; poproś kolegę, aby przeczytał ci je powoli na głos albo przebiegnij je wzrokiem sam, patrząc na każdą tylko raz przez parę sekund. Następnie napisz tyle liczb, ile udało ci się zapamiętać; staraj się odtworzyć je w niezmienionej kolejności.

12, 3, 18, 27, 96, 41, 37, 82, 65, 54,
77, 8, 26, 75, 98, 6, 32, 56, 98, 40

Jest prawdopodobne, że potrafiłeś przypomnieć sobie poprawnie nie więcej niż około 12 liczb, a tylko 7 we właściwej kolejności. Jak sądzisz, jakie czynniki - ćwiczenia, praktyka, testy - mogłyby polepszyć twój „wskaźnik pamięci”? Techniki, które omówimy pod koniec tego rozdziału, powinny dopomóc ci w znacznym zwiększeniu tej zdolności.


Klasyczne badania nad pamięcią i zapominaniem


W badaniach laboratoryjnych wyciąga się wnioski na temat pamięci na podstawie porównania ilości materiału pamiętanego po upływie pewnego czasu, z tym, co się wie bezpośrednio po uczeniu się. Zakłada się, że w przypadku pamięci doskonałej obie te wielkości byłyby jednakowe - nie byłoby żadnej straty. W rzeczywistości pamięć ocenia się zwykle w kategoriach ilości zapamiętanego materiału. To wyjaśnia, dlaczego w niniejszym podrozdziale poświęconym pamięci będziemy często mówić o zapominaniu i dlaczego najważniejsze teorie dotyczące pamięci zostały sformułowane w kategoriach procesu zapominania.

Ogólna procedura eksperymentalna. Kolejność działań, stosowana zazwyczaj w badaniach eksperymentalnych nad pamięcią, wynika z tego, co powiedzieliśmy wyżej. Najpierw badanemu daje się pewien materiał do wyuczenia, po czym zwykle mierzy się, ile się nauczył. Następnie badanemu poleca się, aby przez pewien czas zajmował się czynnością określonego rodzaju (np. uczeniem się czegoś innego lub wykonywaniem zadania wypełniającego czas, takiego jak obliczenia arytmetyczne, które po prostu ograniczają możliwość myślenia o pierwotnym zadaniu). Na koniec sprawdza się, co badany zapamiętał z pierwotnego zadania i wynik porównuje się z wynikiem uzyskanym przy końcu posiedzenia poświęconego uczeniu się.
Aby zmierzyć, ile zostało zapamiętane, badacz może posłużyć się techniką |przypominania, |rozpoznawania lub |ponownego |uczenia |się.
1. |Przypominanie. Przypominanie polega na odtwarzaniu wyuczonego materiału. Jeśli pytanie egzaminacyjne wymaga podania przyczyn Wojny Secesyjnej, to musisz wydobyć te przyczyny ze swojej pamięci i sformułować odpowiedź, która przekona egzaminatora, że je znasz.
Badacze rozróżniają dwa rodzaje przypominania. Pierwszy z nich to |przypominanie |mechaniczne, czyli |dosłowne. Zawsze, gdy konieczne jest zapamiętanie czegoś dokładnie (dotyczy to zwłaszcza oznaczeń umownych, takich jak numery telefoniczne), musimy przechowywać całą informację, aby móc odtworzyć ją poprawnie. Jednakże w większości przypadków, gdy w grę wchodzi materiał o większej złożoności, przypominanie wymaga pewnego |rekonstruowania. Magazynujemy wówczas i przypominamy sobie jedynie część informacji, lecz na podstawie tej części jesteśmy w stanie zrekonstruować resztę zdarzenia czy faktu. Na przykład, potrafiłbyś prawdopodobnie rozwinąć teorię przyczyn Wojny Secesyjnej na podstawie zaledwie kilku zapamiętanych faktów.
2. |Rozpoznawanie. Inna technika, umożliwiająca ocenę stopnia zapamiętania, opiera się na zdolności |rozpoznawania tego, z czym miało się uprzednio do czynienia. Pomyśl, jak olbrzymią liczbę przedmiotów i ludzi potrafisz rozpoznać! Ulice i budynki w pobliżu twego miejsca zamieszkania, twarze licznych kolegów i znajomych, słowa - lista ta jest niemal nieograniczona. Ponadto większość rzeczy, które potrafisz rozpoznać, zapewne nie umiałbyś odtworzyć z pamięci. W teście z odpowiedziami do wyboru często rozpoznajesz wiele poprawnych odpowiedzi, których nie potrafiłbyś sformułować samodzielnie.
Rozpoznawanie bada się zwykle prezentując pewien bodziec i pytając, czy należał on do zbioru, którego badany uczył się przedtem, czy też jest to nowy bodziec. Inna metoda polega na tym, że pokazuje się kilka obiektów, i pyta, czy badany rozpoznaje któryś z nich jako ten, z którym miał do czynienia uprzednio.
3. |Ponowne |uczenie |się. Jest to jeszcze bardziej pośrednia miara zapamiętania, która zwiera w sobie zarówno technikę przypomnienia, jak i rozpoznawania. Określa się, ile czasu trzeba się uczyć, aby spełnić pewne kryterium opanowania materiału, na przykład bezbłędnie odtworzyć go dwa razy z rzędu. Następnie, po upływie określonego czasu, badany znowu uczy się równie dobrze wykonać tego samego testu.
Szybsze uczenie się zadania za drugim razem psychologowie nazywają |oszczędnością. Wskaźnik oszczędności („savings score”) uważa się za miarę określającą, w jakim stopniu badany przechowywał w pamięci to, czego nauczył się za pierwszym razem.
Technika ponownego uczenia się jest najczulszym sposobem pomiaru. Nawet wtedy, gdy inne techniki nie ujawniają żadnych oznak zapamiętania, ponowne uczenie się może być szybsze niż pierwotne, co wskazuje, że jego efekty nie zostały całkowicie utracone.
W zależności od zainteresowań eksperymentatora i sprawdzanych hipotez, w konkretnym badaniu można manipulować warunkami w fazie pierwotnego uczenia się, w okresie przejściowym bądź w fazie przypomnienia. Na przykład badacz może chcieć porównać wpływ różnych warunków pierwotnego uczenia się na późniejsze przechowanie materiału w pamięci. W tym wypadku osoby badane w grupie eksperymentalnej i kontrolnej uczą się w różnych warunkach, lecz stopień wyuczenia się, a następnie przechowania materiału, mierzy się w ten sposób; również w okresie przejściowym, między uczeniem się a przypominaniem warunki w obu grupach są jednakowe.
Być może eksperymentator interesuje się wpływem różnych czynności wykonywanych w okresie następującym po pierwotnym uczeniu się. W tym wypadku warunki pierwotnego uczenia się, muszą być takie same dla wszystkich osób badanych, a także w jednakowym stopniu muszą one wyuczyć się materiału; w przeciwnym razie, gdyby później pamiętały materiał w różnym stopniu, to nie można by powiedzieć, czy przyczyną tego było wykonywanie w międzyczasie odmiennych czynności, czy też różnice w poziomie pierwotnego wyuczenia się.

Pamięć odtwórcza. W psychologii można wyróżnić dwa zasadnicze kierunki badań nad pamięcią. Jeden z nich traktuje pamięć jako proces |odtwórczy, który polega na odszukaniu informacji poprzednio wyuczonej i „zmagazynowanej” w mózgu. To ujęcie wywodzi się z klasycznych badań eksperymentalnych Hermanna Ebbinghausa z 1885 roku. Zwolennicy drugiego kierunku, który traktuje pamięć jako proces |wytwórczy („productive”), głoszą, że aktywnie rekonstruujemy to, co przypominamy sobie, a nie wyciągamy po prostu wspomnień z magazynu, gdzie są przechowywane. Ujęcie to zostało po raz pierwszy sformułowane w pracach Sir Fredericka Bartletta, w latach 1914-1916.

„Ebbinghaus i uczenie się szeregów”. Pierwsze doniosłe badania, które dostarczyły prawdziwie ilościowej miary przechowania, zostały przeprowadzone przez Ebbinghausa pod koniec ubiegłego stulecia. Ebbinghaus był wynalazcą „sylaby bezsensownej” - pozbawionej znaczenia trzyliterowej jednostki, składającej się z dwóch spółgłosek i umieszczonej między nimi samogłoski, na przykład „ceg”, „dak” itd. Posługiwał się on sylabami bezsensownymi dlatego, że chciał uzyskać „czystą” miarę pamięci, nieskażoną uprzednim uczeniem się czy skojarzeniem, które inaczej mogłyby wpływać na wykonanie zadania użytego w badaniu. Występując w roli swej jedynej osoby badanej, Ebbinghaus uczył się takich bezsensownych sylab, dopóki nie potrafił powtórzyć ich bezbłędnie dwa razy z rzędu. Ponadto mierzył on czas, jaki zajęło mu wyuczenie się całej listy. Następnie, po upływie określonego czasu - w ciągu którego zazwyczaj uczył się innych list - ponownie uczył się pierwotnej listy i znów mierzył czas uczenia się.  Różnica między tymi czasami - |wskaźnik |oszczędności - stanowiła miarę przechowania.
Rezultaty uzyskiwane przez Ebbinghausa ilustruje zamieszczony obok wykres, gdzie procent czasu zaoszczędzonego przy ponownym uczeniu się przedstawiono jako funkcję liczby dni, kiedy upłynęły od pierwszego uczenia się. Jak łatwo stwierdzić, krzywa początkowo gwałtownie opada, a następnie obniża się wolniej. Tego rodzaju krzywa jest typowa dla wyników uzyskiwanych w badaniach nad zapamiętywaniem mechanicznym.
Metoda |antycypacji, którą wprowadził Ebbinghaus, stała się jedną z klasycznych metod przypominania, stosowanych przy badaniu uczenia się werbalnego i pamięci. W procedurze tej badany przypatruje się najpierw całej liście słów lub sylab bezsensownych, które następnie pokazuje mu się pojedynczo. Badanemu poleca, się aby po ukazaniu się każdego elementu „przewidział” (antycypował), jaki element jest następny na liście, a więc ukaże się za chwilę. W laboratorium typowa procedura polega na prezentowaniu każdego z elementów przez określony czas w okienku aparatu zwanego |mnemometrem. Powtarza się to przez tyle |prób (tzn. prezentacji całej listy), ile potrzeba dla osiągnięcia kryterium ustanowionego przez eksperymentatora. W wypadku badań Ebbinghausa, jak pamiętamy, jako kryterium przyjęto dwie bezbłędne próby. Niezależnie od tego, jakie kryterium zostało przyjęte w uczeniu się pierwotnym, jest ono stosowane również w odniesieniu do ponownego uczenia się.
Jeśli miałeś jakieś praktyczne doświadczenia w zakresie uczenia się szeregów, to mogłeś zauważyć zjawisko, które występuje prawie zawsze. Gdy uczysz się listy elementów - takich jak cyfry w numerze telefonu - to pierwsze i ostatnie elementy tej listy zdają się łatwiejsze do zapamiętania niż środkowe. Zjawisko to określa się jako |wpływ |miejsca |w |szeregu.  Nikt nie potrafi powiedzieć z całą pewnością, dlaczego ono występuje, lecz obserwuje się je regularnie w eksperymentach. Jak dotąd, przyjmowane jest wyjaśnienie, zgodnie z którym pierwszy i ostatni element zajmują szczególne pozycje na liście i dlatego najbardziej rzucają się w oczy, ponieważ służą jako „słupy „graniczne”, wyznaczające początek i koniec listy. Jeśli na przykład nie ma żadnego odstępu między „ostatnim” a „pierwszym” elementem w szeregu - który podano w postaci tak zwanej listy kołowej - to efekt pozycji w szeregu jest znacznie słabszy. Niech dana osoba najwyraźniej wybiera subiektywny „punkt startowy”, a efekt pozycji w szeregu występuje względem tego subiektywnego „punktu zakotwiczenia”.
Pionierska praca Ebbinghausa miała doniosłe znaczenie z kilku powodów.  Jego sposób podejścia oznaczał przejście od filozoficznych spekulacji do naukowego eksperymentowania, a zatem stwarzał warunki dla rozwoju nowoczesnej teorii uczenia się. Ebbinghaus był pod wrażeniem dokonanej przez Fechnera ścisłej analizy wrażeń zmysłowych i jako pierwszy próbował wprowadzić taki sam rygor i precyzję do badania wyższych procesów psychicznych. Realizował to w systematyczny sposób, badając wpływ wszystkich zmiennych, jakie tylko potrafił wymyślić - liczby sylab na liście, czasu uczenia się, liczby prób itd.

W tym celu modyfikował określoną zmienną, utrzymując inne na stałym poziomie. Stosował on miary o charakterze ilościowym oraz specjalne materiały do zapamiętywania o porównywalnej trudności; jako pierwszy mierzył oddzielnie uczenie się i zapamiętywanie i ustalił związek między pierwotnym uczeniem się a przechowaniem.
Jednakże wyniki ostatnich badań podważyły celowość posługiwania się w badaniu pamięci pozbawionymi znaczenia, bezsensownymi sylabami.  Stwierdzono, że badani często wymyślają jakiś sposób przekształcenia każdej bezsensownej sylaby w słowo mające znaczenie (np. sylaby bezsensownej luk w lukrecję), a następnie zapamiętują to słowo oraz jego przekształcenie (Prytulak, 1971). Chociaż współcześni badacze przeprowadzając swoje eksperymenty mają ten sam cel, co Ebbinghaus (zrozumieć istotę pamięci), to jednak sądzą oni, że drogą do osiągnięcia tego celu jest posługiwanie się materiałem |sensownym, nie zaś bezsensownym.
Zapamiętywanie bezsensownych sylab, zamiast stanowić „czystą” formę przechowania (jak zakładał Ebbinghaus), może różnić się jakościowo od zapamiętywania materiału mającego znaczenie. Dlatego też obecnie przeprowadza się wiele badań nad pamiętaniem zdań i innego sensownego materiału, co jest wyraźnym odejściem od ebbinghausowskiej tradycji.

„Uczenie się skojarzeń parami”. Pomyśl o uczeniu się angielskich odpowiedników polskich słów lub o uczeniu się nazw stolic różnych państw. W tym wypadku informacją, którą należy sobie przyswoić, jest zbiór takich par, w których jeden element pary wiąże się lub ma być związany z drugim jej elementem. Przykłady te stanowią ilustrację drugiej klasycznej techniki stosowanej w badaniu pamięci, a znanej jako |uczenie |się |skojarzeń |parami. Zazwyczaj osoba badana przypatruje się przez krótki czas każdej parze i w ten sposób zapoznaje się z całą listą. Następnie badanemu przedstawia się po kolei pierwsze elementy z każdej pary prosząc go, aby przypomniał sobie drugi element zanim zostanie on pokazany parę sekund później. Procedurę tę powtarza się, dopóki badany nie będzie umiał przewidzieć poprawnie drugiego elementu każdej pary wchodzącej w skład listy”.

„Przypominanie swobodne”. Niekiedy, zamiast polecić badanemu odtworzyć szereg elementów we właściwej kolejności lub reagować na pierwszy element każdej pary podaniem drugiego elementu, eksperymentator prosi po prostu o |swobodne |wymienianie wszystkich elementów, które badany potrafi sobie przypomnieć. Nawet w tym wypadku stwierdza się zazwyczaj wpływ miejsca w szeregu: początku listy uczymy się najszybciej, a pozycji znajdujących się tuż poza środkiem listy - najwolniej.

„Zjawisko interferencji”. Zarówno uczenie się szeregów, jak i uczenie się par znalazły szerokie zastosowanie w badaniu różnych aspektów pamięci.  Jeden z głównych kierunków badań polegał na dociekaniu, w jaki sposób pamiętanie czegoś hamuje czy zakłóca pamiętanie czegoś innego. W wypadku |interferencji |proaktywnej (tj. działającej do przodu) pamiętanie wyuczonego wcześniej materiału przeszkadza w pamiętaniu materiału przyswojonego później. W |interferencji |retroaktywnej (działającej wstecz) zachodzi proces odwrotny - pamiętanie materiału przyswojonego później przeszkadza w pamiętaniu materiału wyuczonego wcześniej.
Jedna z technik służących do badania procesów interferencji polega na tym, że polecamy osobom badanym uczyć się kolejno dwóch list skojarzeń parami, przy czym pierwsze elementy par są takie same w obu listach, natomiast elementy kojarzone z nimi zmieniają się. Na przykład, jeśli w pierwszej liście (X-A) jest para bezsensownych sylab „juf-dak”, to druga lista (X-B) będzie zawierać parę taką, jak „juf-geb”. Jeden ze sposobów badania interferencji |proaktywnej polega na tym, że polecamy badanym nauczyć się najpierw listy X-A, a następnie listy X-B. Później, po upływie określonego czasu, bada się stopień zapamiętania listy wyuczonej jako drugiej (X-B). Wyniki uzyskane przez badanych tworzących grupę eksperymentalną porównuje się następnie z wynikami badanych z grupy kontrolnej, którzy uczyli się tylko drugiej listy, a okres poprzedzający uczenie się spędzili na jakiejś innej czynności. W takich warunkach badani z grupy kontrolnej pamiętają więcej par z listy X-B, niż badani z grupy eksperymentalnej, co prowadzi do wniosku, że zapamiętanie pierwszej listy musiało przeszkadzać w pamiętaniu drugiej listy (tabela).
Gdy badanie ma na celu określenie wpływu interferencji |retroaktywnej, wówczas grupy uczą się |pierwszej listy; następnie tylko grupa eksperymentalna uczy się drugiej listy, podczas gdy grupa kontrolna wykonuje jakieś inne zadanie. Na koniec sprawdza się, w jakim stopniu obie grupy pamiętają pierwszą listę. Także i w tym wypadku grupa kontrolna uzyskuje zwykle lepsze wyniki, prawdopodobnie z powodu mniejszej interferencji ze strony czynności wykonywanej po nauczeniu się pierwszej listy.

Pamięć wytwórcza. Wszyscy wiemy, jak w plotce zmieniają się szczegóły opowiadania. Ktoś posłyszał pikantną historyjkę o swym znajomym; nim miał sposobność opowiedzieć ją komuś innemu, historyjka ta w jego (lub jej) pamięci uległa - jak się zdaje - pewnej zmianie. Gdy powtórzona w ten sposób kilkakrotnie plotka wróci do osoby, która pierwsza ją opowiedziała, wówczas ta wysłuchawszy jej może nawet nie poznać, że jest to ta sama historyjka, którą niedawno puściła w obieg!
Angielski psycholog F. C. Bartlett nie interesował się zbytnio plotkami, lecz był zupełnie pewny, że takie systematyczne zniekształcanie stanowi istotną właściwość pamięci.


Jego badania miały na celu ujawnienie i wyjaśnienie tych zniekształceń.  Jest to więc typ badań różny od tradycji werbalnego uczenia się, jaka rozwinęła się w Stanach Zjednoczonych.

„Kolejne odtwarzanie”. Bartlett opracował technikę znaną pod nazwą kolejnego odtwarzania, w której badani odtwarzali kilkakrotnie jakiś materiał mający pewien sens: albo tę samą osobę badaną proszono, aby odtworzyła dany materiał kilkakrotnie w różnych odstępach czasu od chwili nauczenia się go, albo kilku badanych przekazywało sobie kolejno, co zapamiętało z tego materiału. Pokazywano na przykład pewnej osobie obrazek i proszono ją, by starała się go zapamiętać. Po pewnym czasie polecono jej narysować ten obrazek z pamięci. Następnie rysunek ten dawano drugiej osobie jako obrazek do zapamiętania i odtworzenia i tak dalej. Typowy rezultat tej procedury, którą przedstawiał pierwotny obrazek, stopniowo przekształcił się w kotka.
W innych eksperymentach Bartlett czytał osobom badanym bajkę Indian północnoamerykańskich. Po piętnastu minutach (a także później, po upływie dłuższego czasu) badanych proszono o odtworzenie tej bajki. Na ogół badani zdawali się pamiętać dokładnie zasadniczy sens („rdzeń”) opowieści, lecz dodawali także nowy materiał, którego nie było w oryginalnym opowiadaniu.  Często ten nowy materiał zawierał także modyfikację opowieści, dzięki którym stawała się ona bardziej zgodna z normami kulturowymi osób badanych.  Na przykład zdanie „poszli ku rzece, by polować na foki”, jeden z badanych (Anglik) zapamiętał jako „poszli łowić ryby”.
Według interpretacji Bartletta wyniki te wykazują, że pamięć ma nie tylko charakter |odtwórczy, ale i |wytwórczy - wywołuje to pewne dające się przewidywać zmiany w przechowywanym materiale. Jego zdaniem:

„Pamiętanie nie polega na pobudzaniu od nowa nieprzeliczonego mnóstwa utrwalonych, martwych i cząstkowych śladów. Jest to pełne wyobraźni rekonstruowanie czy konstruowanie, będące wytworem naszej postawy wobec całej aktywnej masy zorganizowanych przeszłych reakcji czy doświadczeń (...). Dlatego też prawie nigdy nie jest ono naprawdę dokładne, nawet w najbardziej elementarnych wypadkach streszczania z pamięci” (Bartlett, 1932, s. 213).

Współczesną wersję oryginalnej teorii Barletta sformułował Neisser (1967), który twierdzi, że dobra pamięć to coś więcej niż po prostu sprawny system rejestrowania i przechowywania. Funkcje pamięci są analogiczne do pracy paleontologa, który zaczyna od kilku kawałków kości, a potem rekonstruuje stopniowo dinozaura lub jakieś inne zwierzę. W podobny sposób ludzie rekonstruują to, co pamiętają, na podstawie kilku przypomnianych elementów.

* * *
Ryc. 4.11. Pierwotną figurą jest stylizowany rysunek sowy. Na kolejnych reprodukcjach staje się on coraz bardziej wieloznaczny; wreszcie dziesiąty rysunek jest już figurą wyraźnie przedstawiającą kota.
* * *
„Pamięć znaczenia”. Jedna z różnic między sposobami podejścia Ebbinghausa i Bartletta polegał na tym, że pierwszy z nich stosował sylaby bezsensowne, podczas gdy drugi posługiwał się materiałem mającym znaczenie, takim jak opowiadania.

Ponieważ Ebbinghaus wywarł większy wpływ na badania amerykańskie, przeto w większości wczesnych eksperymentów przeprowadzonych w Stanach Zjednoczonych również używano sylab bezsensownych. Dopiero stosunkowo niedawno, zaznaczyła się wyraźna tendencja do badania pamięci w odniesieniu do materiału mającego znaczenie. W tych ostatnich badaniach stwierdzono między innymi, że ludzie nie pamiętają dokładnie słów, których się uczą, natomiast pamiętają ogólne znaczenie tych słów. Tak więc jutro będziesz pamiętać coś niecoś z tego, co powiedziano w tym rozdziale, natomiast z pewnością nie będziesz pamiętał, jakie właściwie słowa zostały użyte.

„W pewnym eksperymencie badanym czytano krótkie opowiadanie, które zawierało następujące zdanie: „Wysłał o tym list do Galileusza, wielkiego uczonego włoskiego”. Zaraz po tym, albo po dodatkowych 80 lub 160 sylabach opowiadania, dawano im test rozpoznawania tego zdania. W teście tym podawano zdanie, które było albo identyczne z pierwotnym, albo zmienione jedynie pod względem formy, lecz mające takie samo znaczenie („List o tym został wysłany do Galileusza, wielkiego uczonego włoskiego”), albo też zmienione pod względem znaczenia („Galileusz, wielki uczony włoski, wysłał do niego list o tym”), albo też zmienione pod względem znaczenia (Galileusz, wielki uczony włoski, wysłał do niego list o tym”).Jak wynika z podanego niżej wykresu, badani doskonale wykrywali zmiany znaczenia, natomiast uzyskiwali znacznie słabsze wyniki zarówno w rozpoznawaniu identycznego sformułowania, jak i w wykrywaniu zmienionej formy przy zachowanym znaczeniu (Sachs, 1967).

Podczas gdy badania podobne do opisanego powyżej koncentrowały się na zapamiętywaniu pojedynczych zdań czy słów, przedmiotem innych badań było pamiętanie „idei”. Idee takie często są oparte na wielu różnych zdaniach, które wyrażają pewną wspólną treść semantyczną. Zjawisko „przyswajania i przechowywania idei” zademonstrowali w serii eksperymentów Bransford i Franks (1971). Stwierdzili oni, że informacje zawarte w szeregu powiązanych ze sobą zdań badani spontanicznie integrowali w kilka złożonych idei. Zdania wyrażające te złożone idee badani rozpoznawali (czyli „pamiętali”) później znacznie częściej niż proste zdania, które słyszeli na początku. Wyniki tego rodzaju sugerują, że ludzie często konstruują schematy organizujące informacje, których się uczą. To, co pamiętają, jest w rezultacie przejawem tego procesu konstrukcji, a nie mechanicznym, dosłownym odtwarzaniem. Prace te, których wyniki najwyraźniej są zgodne z poglądami Bartletta na temat pamięci, dały początek nowej i pasjonującej dziedzinie badań psychologicznych (zob. Cofer, 1973).


Teorie pamięci i zapominania


Wyjaśnienia zjawisk pamięci i zapomnienia koncentrują się na dwóch związanych ze sobą zagadnieniach: Co się dziej, kiedy zapominamy? Jak wspomnienia są przechowywane w mózgu i w jaki sposób się je wyszukuje?

Dlaczego zapominamy? Przynajmniej jeden fakt dotyczący uczenia się jest znany wszystkim - że nie pamiętamy wszystkiego. Zapominamy nazwiska ludzi, zapominamy o umówionych spotkaniach, zapominamy wiadomości, które wkuliśmy na egzamin, zapominamy numer telefonu zaraz po nakręceniu go i tak dalej.  Chociaż zapominanie jest dla nas wszystkich bardzo pospolitym doświadczeniem, to jednak niełatwo znaleźć wyjaśnienie tego zjawiska.  Przeprowadzono wiele badań poświęconych temu zagadnieniu i wysunięto kilka teorii w celu wyjaśnienia, jak i dlaczego zapominamy to, czegośmy się nauczyli.


„Teoria zanikania śladów”. Według tej teorii wyuczony materiał pozostawia „ślad” w mózgu; ślad ten, jeśli nie czyni się z niego użytku, z czasem zaniknie. Innymi słowy, wiadomości, które sobie przyswoiliśmy, po prostu się ulatniają. Takiemu zanikowi można zapobiec, jeśli ciągle korzystamy z tych wiadomości i w ten sposób utrwalamy ślad.

Aczkolwiek teoria zanikania śladów jest bardzo prostym wyjaśnieniem zjawiska zapominania, to jednak nie znalazła ona potwierdzenia w nowszych badaniach.

„Teoria interferencji”. Podstawowe twierdzenie |teorii |interferencji głosi, że wszystko, czego się nauczyliśmy, pozostanie w pamięci, o ile nie zajdzie coś nowego, co będzie interferowało z przyswojoną wiedzą. Gdyby nic nie interferowało z nabywanymi przez nas wiadomościami czy umiejętnościami, to nigdy nie zapomnielibyśmy niczego. Jednakże interferencja jest w naszym życiu zjawiskiem powszednim, przy czym przyjmuje ona jedną z dwóch form (interferencja proaktywna lub retroaktywna), które już omówiliśmy. W przeciwieństwie do teorii śladów, w której sam |czas jest czynnikiem decydującym o zapominaniu, w teorii interferencji twierdzi się, że decydujące znaczenie ma to, |co |dzieje |się w tym czasie. Jeden z pierwszych eksperymentów, testujących te konkurencyjne hipotezy, przeprowadzili w 1924 roku Jenkins i Dallenbach.

„W eksperymencie tym badani uczyli się list bezsensownych sylab, a następnie odtwarzali te listy po upływie różnego czasu. Okres między uczeniem się a odtwarzaniem był wypełniony albo normalną aktywnością w stanie czuwania, albo snem (zakłada się, że podczas snu interferencji jest mniej). Wyniki wykazały, że po okresie snu zapominanie występowało w mniejszym stopniu, niż po okresie czuwania wypełnionego normalną aktywnością. Potwierdza to główną tezę teorii interferencji, że decydujący wpływ na zapominanie ma nie sam upływ czasu, lecz charakter aktywności zachodzącej w tym czasie.

Na czym polega proces interferencji? Jedna z hipotez głosi, że interferujący materiał „bierze górę” nad wyuczonym wcześniej materiałem i staje się silniejszy, bardziej dominujący w naszej pamięci. Alternatywna koncepcja (która uzyskała większe poparcie eksperymentalne) utrzymuje, że interferujący materiał powoduje |oduczenie |się |przyswojonego |wcześniej |materiału |- |innymi |słowy |zapominamy |materiał |wcześniejszy |po |to, |abyśmy |mogli |łatwiej |nauczyć |się |nowego |materiału.

„Teoria usuwania” („displacement theory”). Teoria ta (Waugh i Norman, 1964) postuluje zasadę zbliżoną do koncepcji interferencji. Zgodnie z tą zasadą „magazyn pamięciowy” ma ograniczoną pojemność i wobec tego kolejne napływające informacje będą niejako „wypychać”, czyli usuwać znajdujące się już w nim informacje. Jeśli w danym czasie nie przybędą żadne nowe informacje, to nic nie zostanie zapomniane. Różnica między teoriami interferencji i usuwania polega na tym, że inaczej przedstawiają one sposób, w jaki nowy materiał powoduje zapominanie innych materiałów; pierwsza z nich postuluje proces oduczania się, podczas gdy druga kładzie nacisk na to, że pojemność magazynu pamięciowego jest ograniczona.

„Zapominanie jako utrata dostępu”. Czwarta hipoteza głosi, że w rzeczywistości nigdy nie zapominamy niczego - że informacje, które na pozór zapomnieliśmy, stały się jedynie czasowo niedostępne - z tego czy innego powodu. Inaczej mówiąc, wszystkie te informacje znajdują się w magazynie pamięciowym, lecz są niedostępne ze względu na brak odpowiednich sygnałów umożliwiających ich odszukanie. Jeśli odpowiednie sygnały są do dyspozycji, wówczas zapominanie nie występuje. Na przykład, gdyby ktoś zapytał cię, czy pamiętasz człowieka nazwiskiem Jan Misiak, to mógłbyś poszukawszy w pamięci odpowiedzieć „nie”. Gdyby jednak ta sama osoba zapytała cię, czy pamiętasz Jana Misiaka, który był właścicielem sklepiku z warzywami na rogu, to mógłbyś odpowiedzieć: „Ach, |tego Jana Misiaka - oczywiście, znam go!” Najwyraźniej nie utraciłeś ani nie „oduczyłeś się” tej informacji; to raczej sygnał w postaci nazwiska nie był wystarczający do odszukania informacji o danym człowieku w twoim magazynie pamięciowym.
Psychologowie wykazywali często, jaką rolę pełnią różne rodzaje „sygnałów odszukujących” („retrieval cues”) w zapominaniu i przypominaniu.  Elementarnym przykładem jest przeczytanie na głos jakiejś dowolnej listy złożonej z dwudziestu czy trzydziestu nie powiązanych ze sobą słów, a następnie polecenie słuchającemu, aby przypomniał sobie różne części listy w odpowiedzi na rozmaite sygnały. Na przykład poleca mu się, aby przypomniał sobie wszystkie słowa zaczynające się na literę „b”, wszystkie słowa odznaczają zwierzęta, wszystkie słowa rymujące się ze słowem „gruszka” itd. Każde słowo, nawet mające jedno tylko znaczenie, można sklasyfikować wieloma sposobami. Toteż istnieje wiele możliwych dróg, którymi można je osiągnąć, i każdą z nich można wypróbować, aby przekonać się, czy doprowadzi ona do przypomnienia określonego „docelowego” słowa.  Badania takie pozwoliły sformułować ogólny wniosek, że bodziec staje się efektywnym sygnałem odszukującym dla określonego elementu tylko wtedy, jeśli w czasie uczenia się tego elementu dana osoba myśli o nim i tym bodźcu jako o powiązanych wzajemnie ze sobą. Jeśli więc ktoś myśli o słowie |Niemen jedynie jako nazwisku znanego piosenkarza, to wówczas sygnały odszukujące: „słowo zaczynające się na literę n” czy „rzeka wpadająca do Bałtyku” byłyby nieskuteczne.
Ostatnio prowadzone są badania nad sygnałami w postaci środowiska czy |kontekstu, w którym dana osoba uczy się jakiegoś materiału i odtwarza go.  Istnieją dane świadczące o tym, że informację przyswojoną w pewnym „kontekście środowiskowym” (takim, jak określony pokój) łatwiej jest przypomnieć sobie w tym samym „kontekście” niż w innym. Nie jest również wykluczone, że |wewnętrzny kontekst środowiskowy danej osoby (taki jak nastrój, stan organizmu itd.) może wpływać na pamięć i zapominanie. Rand i Wapner (1967) sprawdzali tę hipotezę w eksperymencie, w którym polecali badanym przybierać różną postawę. Osoby badane albo stały prosto, albo leżały podczas uczenia się testu słownego, a także później, gdy próbowały przypomnieć go sobie. Ci badani, którzy i uczyli się i przypominali sobie test w tej samej pozycji, pamiętali go lepiej niż ci, którzy zmienili postawę. Materiał taki badani mogą sobie lepiej przypomnieć również wtedy, gdy podobne układy kontekstowe wytwarza się za pomocą sugestii hipnotycznej - czy pamiętasz Chucka i jego przyjęcie urodzinowe?

„Teorie motywacyjne”. We wszystkich teoriach omawianych dotychczas, zapominanie traktuje się jako automatyczne następstwo funkcjonowania systemu pamięciowego (usuwanie, interferencja) lub jako niewydolność tego systemu (zanikanie śladów, nieodpowiednie sygnały). Zupełnie inne podejście przyjął Zygmunt Freud, który twierdził, że zapominanie może być |intencjonalne. Wysunął on tezę, że pamiętanie i zapominanie wiąże się z wartością i znaczeniem, jakie dany materiał ma dla nas. Na przykład rzeczy bardzo dla nas przykre często stają się na jakiś czas „niedostępne” - zostają niejako wypchnięte ze świadomości. Takie |wypieranie (represja) jest środkiem, za pomocą którego chronimy się przed niemożliwymi do zaakceptowania czy przykrymi informacjami. Jak przekonamy się w Rozdziale 10, ten „zapomniany” materiał może przetrwać na poziomie nieświadomości i jeszcze po latach wywoływać konflikty emocjonalne.
W tym samym mniej więcej czasie, gdy Freud mówił o motywacjach, które wypierają przykre informacje, Kurt Lewin i jego uczniowie badali wpływ motywacji zadaniowej na pamięć. Legenda głosi, że zdziwiło ich pewne wydarzenie w berlińskiej piwiarni. Podobno był tam kelner z tak wybitną pamięcią, że mógł przyjmować długie, skomplikowane, szczegółowe zamówienia nie zapisując ich. Jednakże pewnego razu, gdy podał już całemu towarzystwu zamówione dania i napoje i wręczył rachunek, ktoś zadał mu proste pytanie dotyczące zrealizowanego już zamówienia. Okazało się, że skoro tylko wykonał swoje zadanie, to potrafił sobie przypomnieć z niego bardzo niewiele.
Rezultatem tego spostrzeżenia był klasyczny eksperyment, który wykazał, że lepiej pamięta się zadania nie wykonane niż wykonane. Zjawisko to nazwano |efektem |Zeigarnik, od nazwiska Blumy Zeigarnik, młodej kobiety, która przeprowadziła to badanie.

„W eksperymencie tym badani wykonywali proste zadania, które potrafili ukończyć, jeśli mieli dość czasu. Były to takie zadania, jak pisanie z pamięci ulubionych cytatów, rozwiązywanie łamigłówek, rozwiązywanie w pamięci zadań arytmetycznych. W niektórych zadaniach badanym przerywano pracę, zanim mieli możność zrealizować w pełni instrukcję, w innych pozwalano im skończyć.
Mimo że badani spędzali więcej czasu nad zadaniami ukończonymi niż nad przerwanymi, na ogół zadania niedokończone pamiętali lepiej niż ukończone, gdy wypytywano ich o nie po paru godzinach. Ta różnica na korzyść zadań nieukończonych znikała jednak w ciągu 24 godzin. Najwidoczniej była ona spowodowana wpływem krótkotrwałych czynników motywacyjnych, które oddziaływały na proces spontanicznego powtarzania w pamięci (rehearsal process”; Zeigarnik, 1927).

Być może doszedłeś do wniosku, że efekt Zeigarnik jest niezgodny z koncepcją wyparcia, ponieważ można by oczekiwać, że ludzie wypieraliby wspomnienia dotyczące zadań nieukończonych, zwłaszcza gdyby nieukończenie ich uważali za porażkę. Późniejsze badania przyniosły wyjaśnienie tej niezgodności, wykazując, że efekt Zeigarnik występuje tylko w wypadku zadań wykonywanych w warunkach niestresowych. Gdy niewykonanie zadania „angażuje ego” i zagraża samoocenie danej jednostki, wówczas istnieje tendencja do odwrócenia efektu Zeigarnik - to znaczy ukończone zadania pamięta się lepiej niż zadania nieukończone.
Dalsze przykłady hamującego wpływu zagrażających doświadczeń na pamięć zademonstrowano w szeregu badań. Ogólnie biorąc wykazano, że pamięć jest gorsza, gdy stosuje się słowa bodźcowe wywołujące lęk, gdy z danym zadaniem wiąże się groźba niepowodzenia lub gdy między uczeniem się a odtwarzaniem doświadcza się frustracji lub innej przyjemności. To, czy wpływ motywacji na pamięć ma charakter hamujący czy facylitujący, zależy od rodzaju i intensywności wzbudzonej emocji, jak również od charakteru zadania, rodzaju wymaganej reakcji oraz miejsca w sekwencji uczenia się i odtwarzania, w którym wprowadza się czynniki motywacyjne.

„Aktualna ocena teorii zapominania”. Mniej więcej 2300 lat temu Arystoteles zaproponował teorię pamięci i zapominania, która kładła nacisk na rolę takich zmiennych, jak styczność, podobieństwo i kontrast.  Późniejsze badania eksperymentalne potwierdziły niektóre koncepcje Arystotelesa, lecz nie doprowadziły do żadnego przełomu, jeśli chodzi o zrozumienie i poznanie procesu pamięciowego. Każda z teorii zdaje się „wyjaśniać” pewien aspekt zapominania, lecz żadna z nich nie jest w stanie dać nawet ogólnej odpowiedzi na pytanie: dlaczego zapominamy? Miejmy nadzieję, że przyszłe badania albo doprowadzą do scalenia obecnych hipotez w pełniejszą teorię, albo odkryją całkowicie nowy model funkcjonowania ludzkiego umysłu.


Jak zapamiętujemy? Chociaż psychologowie nie są jeszcze pewni, jak wyjaśnić procesy pamięci i zapominania, to jednak stosunkowo dobrze zgadzają się w kwestiach dotyczących niektórych cech procesu pamięciowego.  Zasadniczo wydaje się, że są trzy różne systemy pamięciowe: magazyn informacji sensorycznej, pamięć krótkotrwała i pamięć długotrwała.

„Magazyn informacji sensorycznej”. Jeden z systemów pamięciowych przechowuje informacje sensoryczne dostatecznie długo, aby mogły być wykorzystane w spostrzeganiu, zapamiętywaniu, ocenianiu itd; nosi on nazwę |magazynu |informacji |sensorycznej („sensory-information storage). System ten przechowuje informacje jedynie przez bardzo krótki czas (zwykle mniej niż pół sekundy) i ma bardzo ograniczoną pojemność magazynowania (zob.  Zbliżenie poniżej). Z magazynu informacji sensorycznej materiał może zostać przekazany do pamięci krótkotrwałej.


Zbliżenie
Ulotne odczucia


„Możesz uzyskać pewne wyobrażenie o systemie magazynowania informacji sensorycznej, jeśli wykonasz następujące ćwiczenia: „Postukaj czterema palcami o swoją rękę. Zwróć uwagę na bezpośrednie wrażenia - zauważ, jak one zanikają: tak, że najpierw zachowujesz jeszcze rzeczywiste odczucie stukania, lecz po chwili jedynie wspomnienie o tym stukaniu (...).  Przesuwaj ołówek (lub choćby palec) w lewo i prawo przed oczami, patrząc prosto przed siebie. Zobaczysz niewyraźny obraz, który wędruje za poruszającym się przedmiotem” (Lindsay i Norman, 1972, ss. 287 -288).

„Pamięć krótkotrwała”. Drugim systemem pamięciowym jest |pamięć |krótkotrwała, w której ograniczona ilość informacji, przyswojonych sobie właśnie przez daną osobę, jest przechowywana przez bardzo krótki czas.  Klasycznym przykładem pamięci krótkotrwałej jest zapamiętywanie nieznanego numeru telefonu. Po wyszukaniu numeru w spisie potrafisz nakręcić go natychmiast, a może nawet powtórzyć go komuś innemu, jeśli to konieczne.  Jednakże już po krótkim czasie prawdopodobnie nie będziesz umiał powtórzyć poprawnie tego numeru.
Pamięć krótkotrwała, podobnie jak magazyn informacji sensorycznej, ma ograniczoną pojemność i może przechowywać jedynie małą ilość informacji.  Jednakże informacja w niej zawarta jest bardzo łatwo dostępna i można ją łatwo przywołać. Aby utrzymać informację w pamięci krótkotrwałej, trzeba ją aktywnie powtarzać (tak, jak powtarzamy sobie nowy numer telefoniczny).  Pomimo tego, większość informacji z pamięci krótkotrwałej zostaje wkrótce „utracona”, czyli zapomniana. Badania wykazały, że ten typ zapominania jest wynikiem procesów interferencji, a nie po prostu zanikania, jak niegdyś przypuszczano.
Błędy, które wiążą się z przechowywaniem w pamięci krótkotrwałej, polegają zwykle na myleniu rzeczy, które |brzmią podobnie, nawet jeśli wyglądają inaczej i mają odmienne znaczenie. Na przykład, gdy ludzie próbują odtworzyć natychmiast listę liter, mogą przypomnieć sobie B zamiast D lub S zamiast X. Te akustyczne pomyłki występują nawet wtedy, gdy badani widzieli listę liter zamiast jej wysłuchać (Conrad, 1964). Takie wyniki sugerują, że w pamięci krótkotrwałej zachodzi pewien proces przypominający echo, dzięki któremu pamiętamy raczej dźwięki niż ich znaczenie.

„Pamięć długotrwała”. Pamiętanie |znaczenia informacji zdaje się być cechą charakterystyczną |pamięci |długotrwałej. W tym trzecim systemie pamięciowym informacje przechowywane są przez czas dłuższy, przy czym jego pojemność jest teoretycznie nieograniczona. W tym systemie, inaczej niż w przypadku pamięci krótkotrwałej, nie zawsze jest łatwo wyszukać informację.  Ponieważ zmagazynowany tam materiał nie jest dostępny bezpośrednio, przeto trzeba znaleźć odpowiednie sygnały umożliwiające odszukanie go.
Abyśmy mogli korzystać z naszych doświadczeń - nie popełniać tych samych błędów - informacja musi w jakiś sposób zostać przekazana do pamięci długotrwałej. Pierwszy krok w tym procesie polega na tym, że nowa informacja przechodzi bezpośrednio z magazynu informacji sensorycznej do pamięci krótkotrwałej. Okres pobytu informacji w pamięci krótkotrwałej jest bardzo „niebezpieczny”, gdyż informacja może być wtedy łatwo zapomniana, czyli stracona dla systemu. Wyniki eksperymentów ze zwierzętami, jak również obserwacje kliniczne pacjentów z uszkodzeniami mózgu sugerują, że w tym okresie wspomnienie danego zdarzenia może łatwo zostać „oderwane” i „wytrząśnięte” z systemu. W badaniach nad zwierzętami typowa technika „rozrywania” świeżej pamięci polega na poddawaniu mózgu zwierzęcia elektrowstrząsom powodującym drgawki lub na wywoływaniu stanu nieświadomości i śpiączki („coma”) przez podanie środków farmakologicznych.  Stwierdzono, że zachowania występujące krótko przed drgawkami lub śpiączką zostają prawie zupełnie wymazane z pamięci, tak, że w późniejszym badaniu można wykryć w najlepszym razie małe pozostałości tej informacji. Im dłuższy odstęp czasowy między danym zdarzeniem a traumatycznym oddziaływaniem na mózg, tym mniejsze prawdopodobieństwo, że wspomnienie tego zdarzenia ulegnie destrukcji. Stwierdzenie to jest zgodne z poglądem, że do pamięci długotrwałej przekazywanych jest tym więcej informacji, im dłużej dany materiał może pozostać w pamięci krótkotrwałej bez interferencji. Wynika stąd jednakże intrygujące pytanie, w jaki sposób mózg potrafi zróżnicować i magazynować |znaczenia.
Pacjenci, którym usunięto część hipokampa (jednej ze struktur  podkorowych), nie mogą trwale zapamiętać nowej informacji, lecz potrafią przypomnieć sobie materiał wyuczony przed tą informacją (Milner i Penfield, 1955). Hipokamp może zatem pełnić istotną rolę w przekazywaniu informacji z pamięci krótkotrwałej do pamięci długotrwałej.
Jest kilka czynników, które sprzyjają przeniesieniu informacji z systemu pamięci krótkotrwałej, z której bardzo łatwo one ulatują, do pamięci długotrwałej, gdzie pozostają na dłużej. Prawdopodobieństwo przejścia informacji do pamięci długotrwałej jest tym większe, im mniejsza jest ilość prezentowanego materiału, i im jest on nowszy, im aktywniej jest powtarzany oraz im większe jest jego znaczenie czy doniosłość dla danej jednostki w związku z jej możliwościami orientacji i radzenia sobie z wymaganiami zagrażającego środowiska. Niestety, wiele informacji bezwartościowych dla nas, na przykład teksty reklamowe, zostaje zmagazynowanych w pamięci długotrwałej, ponieważ spełniają te kryteria. Na przykład, informacje w postaci reklam papierosów, które z pewnością mają ujemną wartość dla utrzymania się człowieka przy życiu, zdają się trwać w pamięci bez końca.  Chociaż telewizja amerykańska już od wielu lat zaprzestała reklamowania papierosów, to popularne slogany reklamowe nadal zalegają magazyny pamięci długotrwałej Amerykanów i zapewne będą je oni pamiętali do końca życia.

„Fizjologiczne podłoże pamięci”. Hipotezy wysuwane ostatnio na temat sposobu przechowywania w pamięci dotyczą mechanizmów neuronalnych mogących o tym decydować oraz zagadnienia, czy jeden taki mechanizm może wyjaśnić wszelkie zjawiska z zakresu pamięci. Jak przekonaliśmy się w poprzednim podrozdziale, utrata pamięci krótkotrwałej w wyniku uszkodzenia mózgu lub traumatycznego wstrząsu wskazuje na istnienie związku między pamięcią a specyficznymi procesami fizjologicznymi w mózgu. Niestety, mimo intensywnie prowadzonych badań i analiz, ciągle niewiele wiemy o neurologicznym podłożu pamięci ludzkiej. Mniej więcej przed 50 laty Karol Lashley postanowił ustalić, gdzie ślady pamięciowe, czyli |engramy, mogą być magazynowane w mózgu. „W poszukiwaniu engramu” Lashley usuwał chirurgicznie różne okolice kory zarówno u naczelnych, jak i u szczurów, oraz obserwował wpływ tych zabiegów na pamiętanie wyuczonych uprzednio zadań. Jego poszukiwania zakończyły się niepowodzeniem i wreszcie stwierdził: „Nie jest możliwe zademonstrowanie izolowanej lokalizacji śladu pamięciowego w jakimkolwiek miejscu układu nerwowego” (1950, s. 501). Wyciągnął stąd wniosek, że engram prawdopodobnie jest „ogromnym systemem asocjacji, wymagającym wzajemnych powiązań między setkami tysięcy czy milionami neuronów” (s.  498).

Trzysta lat wcześniej Descartes podał wskazówkę, gdzie można by rozpocząć owocne poszukiwanie podłoża pamięci - mianowicie w zróżnicowanej sprawności przenoszenia czy receptywności synaps. Warto zapoznać się z wczesną doktryną Descartesa dotyczącą neurologicznego podłoża pamięci i porównać ją z obecnym fizjologicznym podejściem do tego problemu. Descartes pisał:

„Kiedy umysł chce sobie coś przypomnieć (ukierunkowana uwaga), wola ta powoduje, że mały gruczoł (szyszynka) nachylając się kolejno w różne strony, wysyła energie życiowe (impulsy nerwowe) ku różnym częściom mózgu, dopóki nie trafią one na tę część, gdzie pozostały ślady rzeczy, którą chce on sobie przypomnieć; ślady te bowiem polegają po prostu na tym, że pory („synapsy”) mózgu, przez które energie życiowe odbyły już swą drogę przy prezentacji danego obiektu, uzyskały dzięki temu większą niż reszta gotowość, by otworzyć się znów w ten sam sposób dla napływających ku nim energiom, tak że energie te napływające ku tym porom wnikną w nie łatwiej niż w inne” (cytowane przez Lashleya, 1950, s. 478 - jego uwagi w nawiasach).

We współczesnych eksperymentach ze szczurami stosuje się środki farmakologiczne zmieniające sprawność przekazywania synaptycznego i obserwuje się wywołane w ten sposób zmiany w sprawności pamięci. W wypadku zastosowania środków, blokujących przyjmowanie substancji przekaźnikowej przez odbierający neuron, pamięć jest gorsza. Kiedy aplikuje się środki, które chronią substancję przekaźnikową przed rozłożeniem, pamięć polepsza się. Dane sugerują, że miany fizyczne będące podłożem uczenia się wiążą się ze wzrostem zdolności synapsy do przekazywania impulsów po zastosowaniu środka farmakologicznego, podczas gdy ubytki pamięci mogą być spowodowane zmniejszeniem sprawności przekazywania synaptycznego, z tego czy innego powodu (Descartes i Deutsch, 1966).
 „Kontrola pamięci: wiedzieć, co się wie”. Przetrząsasz półki biblioteczne w poszukiwaniu określonej książki tylko wtedy, jeśli masz podstawy, by sądzić, że tam się ona znajduje. Mało byłoby pożytku, gdybyś szukał bibliofilskich „białych kruków” czy starych dokumentów rządowych w objazdowej „bibliotece na kółkach”. Ludzka pamięć zdaje się mieć wbudowane urządzenie kontrolne, które informuje cię, czy prawdopodobne jest posiadanie przez ciebie pewnej wiadomości - czy dokładniejsze poszukiwanie w pamięci odpowiedzi na dane zagadnienie okaże się owocne. Na przykład wiesz, że znasz swój obecny adres, i wiesz, że zapewne potrafisz sobie przypomnieć swoje poprzednie adresy (lub że będziesz je miał „na końcu języka”). Jednakże wiesz z pewnością, że nie znasz adresu Indiry Ghandi w New Delhi. Eksperymenty wykazały, że takie oceny dotyczące poczucia wiedzy (lub niewiedzy) mogą być całkiem trafne.

Zbliżenie
Nic nie mów - mam to na końcu języka

„Jak się nazywa woskowata substancja otrzymana z wnętrzności kaszalotów, a znajdująca zastosowanie w przemyśle perfumeryjnym? Jak się nazywają małe łódki używane w portach i na rzekach Chin i Japonii? Czy znasz nazwę protekcji, udzielanej ze względu na powiązania rodzinne, a nie w uznaniu zasług? Gdy zadano te pytania wielkiej liczbie studentów, to uzyskano trzy rodzaje reakcji: natychmiastowe przypomnienie właściwego słowa, niemożność zidentyfikowania słowa na podstawie definicji oraz - co najbardziej interesujące - świadomość, że zna się właściwe słowo, lecz nie potrafi się go sobie przypomnieć (Brown i McNeil, 1966). Tę ostatnią reakcję znamy wszyscy z własnego doświadczenia - występuje ona wtedy, gdy słowo, którego szukamy, mamy „na końcu języka” (NKJ).
Jeśli „słowa NKJ” są rzeczywiście znane i przechowywane w pamięci, chociaż nie są dostępne w słowniku aktywnego przypominania danej osoby, to powinno być możliwe wykazanie, że wiele cech danego słowa można odtworzyć w drodze wypytywania. Gdy badanym polecono wypisać wszystkie słowa, o których myśleli jak o możliwych odpowiedziach, wówczas podawali oni słowa podobne |znaczeniowo do nieuchwytnego słowa NKJ, częściej jednak przytaczali słowa podobne pod względem |dźwiękowym. W wypadku słowa NKJ |sampan podawali oni takie słowa jak „Sjam”, „Cheyenne”, „Sarong” czy „Saipan” częściej niż „dżonka” czy „barka”. Potrafili także przypomnieć sobie inne cechy zdefiniowanego im słowa, takie jak liczba sylab i pierwsza litera, mimo że nie mogli sobie przypomnieć samego słowa.
Sam możesz spróbować zademonstrować to zjawisko, aby przekonać się, co osoby badane przez ciebie (koledzy, znajomi czy krewni) powiedzą, gdy będą szukać w pamięci takich słów, jak |ambra, |sampan, |nepotyzm czy też innych słów, które mogłyby znaleźć się w kategorii NKJ. Z badań takich dowiadujemy się, że przechowywanie i poszukiwanie w pamięci jest procesem złożonym, który nie ma charakteru „wszystko albo nic”.

„W jednym z eksperymentów studentom zadano szereg pytań z zakresu wiedzy ogólnej (np. „Kto wynalazł maszynę parową?”). Jeśli studenci nie mogli przypomnieć sobie odpowiedzi na te pytanie, to proszono ich, by określili swoje „poczucie wiedzy” na 5-punktowej skali. Później dano im testy z odpowiedziami do wyboru, dotyczący tych samych wiadomości, które przedtem badani próbowali sobie przypomnieć. Analiza tylko tych pozycji, dla których badani nie mogli przypomnieć sobie odpowiedzi, wykazała, że ich oceny dotyczące „poczucie wiedzy” pozwalały przewidzieć, czy uda im się rozpoznać i wybrać właściwą odpowiedź w teście z odpowiedziami do wyboru. Ilość poprawnych wyborów wynosiła około 63% w wypadku pytań, w odniesieniu do których badani mieli pewne poczucie, że znają na nie odpowiedź, a 47% dla pytań, co do których sądzili, że odpowiedź jest im nieznana (ponieważ na każde pytanie były cztery odpowiedzi do wyboru, losowo można by oczekiwać jedynie 25% poprawnych odpowiedzi). Innymi słowy, badani potrafili w pewnej mierze ocenić, czy znają informację, których nie mogli sobie przypomnieć w danym czasie (Hart, 1967).

Ta introspekcyjna kontrola, ta wiedza o własnej wiedzy, jest z pewnością jedną z bardziej fascynujących zdolności umysłu. Dzięki niej wiemy, czy warto szukać w pamięci jakiejś nieuchwytnej informacji i nie tracimy czasu na bezowocne i beznadziejne poszukiwania.


Jak można polepszyć pamięć


W tym ostatnim podrozdziale dowiemy się, w jaki sposób możemy rozwinąć nasze zdolności pamięciowe; wskazówek na ten temat dostarczają wyniki licznych badań nad pamięcią.


Strategia uczenia się. Badania nad uczeniem się werbalnym dawno już doprowadziła do poznania trzech technik sprzyjających lepszemu przechowywaniu wyuczonego materiału - przeuczania się, okresowego przeglądania materiału i powtarzania z pamięci.

„Przeuczanie się”. Jeśli masz nauczyć się listy słów, to mógłbyś pomyśleć, że gdy potrafisz odtworzyć bezbłędnie całą listę to uczenie się zostało zakończone i nie miałoby sensu uczyć się dalej. Wprost przeciwnie - dalsze ćwiczenie, zwane |przeuczaniem („overlearning”), ma znaczny wpływ na to, ile materiału przypomnisz sobie później.

„W jednym z eksperymentów badanym polecono nauczyć się na pamięć kilku list słów. Gdy tylko to uczynili, podzielono ich na 3 grupy i każdej z grup dano różną ilość czasu na dodatkowe ćwiczenie. Jedna z grup powtarzała słowa dalej przez tyle samo czasu, ile pierwotnie zajęło ich nauczenie się (100%), druga grupa powtarzała słowa przez połowę czasu poświęconego pierwotnie na wyuczenie się (50%), wreszcie trzecia grupa nie powtarzała w ogóle (0%). W następnym miesiącu we wszystkich trzech grupach sprawdzano co pewien czas odtwarzanie list. Jak widzimy na rycinie 4.14 „grupa 100%” przypominała sobie w każdym z sześciu testów mniej więcej dwa razy więcej słów niż „grupa 0”, aczkolwiek 28 dnia poziom przypominania był bardzo niski we wszystkich grupach”.

3 3 75 0 2 108 1 5a 1 74 0
„Okresowe przeglądanie”. Gdy czytasz jakąś książkę na początku semestru i spodziewasz się, że będziesz musiał referować jej treść po upływie pewnego czasu, to prawdopodobnie wypadniesz lepiej, jeśli co pewien czas będziesz przeglądać materiał. Przyjmuje się, że przeglądanie takie jest pomocne między innymi dlatego, iż pozwala zwrócić uwagę na te części, których nie nauczyłeś się porządnie za pierwszym razem. Przy okresowym przeglądaniu stopniowo coraz mniej czasu trzeba poświęcać na tę czynność, aby zachować materiał w pamięci”.
3 3 75 0 2 108 1 5a 1 74 1

„Aktywne powtarzanie z pamięci”. W trakcie pierwszego uczenia się zapisywanie i (lub) wypowiadanie na głos przyswajanego materiału (jak również odczytywanie go) prowadzi do lepszego przechowania tego materiału.

Takie |aktywne |powtarzanie umożliwia utrzymanie czynnej uwagi, zamiast biernej recepcji, a ponadto sprawia, że opanowujesz materiał w stopniu umożliwiającym odtworzenie go, a nie tylko rozpoznanie. Użyteczne jest nawet „egzaminowanie” siebie samego z zamkniętą książką - innymi słowy powtarzanie na głos materiału bez zaglądania do niego. Psychologowie sugerują, że skuteczność takiego recytowania, nawet bez kontrolowania jego poprawności, może polegać na tym, iż dostarcza ono sposobności do ćwiczenia się w |odszukiwaniu w pamięci potrzebnych informacji - być może w opracowaniu strategii, która będzie najskuteczniejsza później, gdy nadejdzie czas egzaminu.

Porcjowanie a pamięć. Przeczytaj jeden raz następujący szereg liter, a następnie zamknij oczy i spróbuj powtórzyć je z pamięci.

PIE - SPO - GON - IŁK - OTA

Jest bardzo prawdopodobne, że szereg liter zbliża się do granicy pojemności twojej pamięci krótkotrwałej. Litery te są połączone w grupy w sposób przypuszczalnie pozbawiony sensu - toteż litery trzeba zapamiętywać pojedynczo. Jeśli jednak zauważyłeś, że ten szereg liter po odmiennym pogrupowaniu tworzy zdanie „Pies pogonił kota”, to zapamiętanie i odtworzenie tego szeregu nie sprawiło ci żadnych trudności.
Nasza zdolność odtworzenia raz eksponowanego materiału zależy od liczby jednostek organizacyjnych czy |porcji, jakie w nim dostrzegamy. W wielu badaniach wykazano, że w krótkim czasie możemy przyswoić sobie jedynie od 5 do 9 porcji - jak ujął to George Miller (1956). |7 |2 |bity |informacji.  Reguła ta zdaje się obowiązywać niezależnie od tego, czy jednostki te są duże czy małe, złożone czy proste (Czy próbowałeś zapamiętywać ten szereg liter jako 15 odrębnych jednostek?).

„Pewien psycholog nauczył się przekodowywać szeregi złożone z dwóch cyfr następujących po sobie w przypadkowej kolejności - na przykład 101100111010 - posługując się kodem, który przekształcał każdą grupę trzech cyfr w jedną cyfrę - od 0 do 7. Na przykład powyższy szereg - podzielony na następujące grupy: 101, 100, 111, 010 - zostałby zakodowany jako 5472.
Najpierw ustalił on, jak długi szereg pierwotnych cyfr może zapamiętać bez przekodowania. Następnie uczył się przekodowanych szeregów. Zgodnie z oczekiwaniami mógł teraz zapamiętać prawie trzy razy tyle, co poprzednio. 
Najwyraźniej to, co w pierwotnym szeregu było zapamiętane jako trzy porcje, 
w szeregu przekodowanym zapamiętywał jako jedną porcję, czemu towarzyszyło 
odpowiednie zwiększenie liczby cyfr, jakie można było zapamiętać”
(S. Smith, cytowany w pracy G. A. Millera, 1967).

W wielu badaniach weryfikowano tę tendencję do zapamiętywania stałej liczby porcji, bez względu na ich wielkość czy złożoność. Gdy więc litery pogrupuje się w słowa, liczba liter, które można zapamiętać, wzrasta mniej więcej siedmiokrotnie, mimo że słowa są bardziej złożonymi jednostkami informacyjnymi. Gdy słowa organizuje się w zdania, a zdania w większe jednostki myślowe, ilość materiału, jaką można sobie przyswoić, odpowiednio wzrasta.
Dane tego rodzaju przemawiają zdecydowanie za koncepcją porcjowania i stałą pojemnością pamięci krótkotrwałej (określonej w kategoriach porcji).  Być może fakt, że lepiej pamiętamy materiał sensowny niż pozbawiony sensu (o czym była mowa na początku tego rozdziału) wynika stąd, iż materiał bezsensowny, taki jak listy sylab, składa się z wielu małych porcji, których nie można zgrupować w większe jednostki i dlatego każdą z nich trzeba przetwarzać oddzielnie. W każdym razie jest całkiem oczywiste, że istotnie organizujemy materiał, którego mamy się nauczyć, w jednostki „zakodowane znaczeniowo”.

Strategie mnemoniczne. Jeszcze do niedawna osoby, które starały się stosować zasady psychologiczne w klasie szkolnej, zwracały zbyt mało uwagi na „problemy organizacyjne”, przed jakimi staje uczeń, gdy zabiera się do zadania polegającego na uczeniu się. Po odkryciu znaczenia „porcjowania” oraz doniosłości organizacji hierarchicznej i kodowania, psychologowie zaczęli badać procesy psychiczne umożliwiające kodowanie materiału oraz techniki zapewniające większą efektywność kodowania. Techniki takie są zwane |strategiami |mnemonicznymi. Podstawową ideą stanowiącą podłoże większości strategii mnemonicznych jest wykorzystanie posiadanej już wiedzy jako punktu oparcia czy kontekstu dla wiedzy nowo nabywanej.

„Wykorzystanie istniejącej struktury”. Osoba ucząca się może wykorzystać sposób zorganizowania jakiejś już dobrze znanej struktury, jako „schemat” umożliwiający uporządkowanie nowych informacji. Na przykład właściwą kolejność jakichś informacji można zapamiętać łatwiej, jeśli przypisze się im kolejne liczby. Wielu początkujących muzyków uczy się nazw linii w zapisie nutowym, recytując „_Every _Good _Boy _Does _Fine”. Można tu ułożyć poszczególne pozycje w listę w taki sposób, aby początkowe litery utworzyły znane słowo. Na przykład nazwy Wielkich Jezior (Huron, Ontario, Michigan, Erie, Superior) tworzą słowo „homes” (domy).

„Zwiększanie sensowności”. Ponieważ materiał sensowny jest znacznie łatwiejszy do nauczenia się i zapamiętania, zatem inna skuteczna strategia mnemoniczna polega na nadawaniu jakiegoś określonego znaczenia względnie bezsensownemu materiałowi.
Jednym z najskuteczniejszych sposobów mnemonicznych, umożliwiającym zwiększanie sensowności listy słów, jest włączenie ich do jakiegoś opowiadania lub zdania. Bower i Clark (1969) zademonstrowali skuteczność tej strategii przy zapamiętywaniu listy rzeczowników.

„Badani otrzymywali listę 10 zupełnie nie związanych ze sobą rzeczowników, których musieli się nauczyć w kolejności, w jakiej były one prezentowane. Badanym w grupie eksperymentalnej powiedziano, aby ułożyli opowiadanie, w którym rzeczowniki te pojawiałyby się we właściwej kolejności. Dla przykładu podajemy historyjkę opracowaną przez pewnego badacza, a osnutą wokół rzeczowników (wyróżnionych poniżej dużymi literami), które tworzyły jedną z list:
„JARZYNA (vegetable) może być użytecznym NARZĘDZIEM (instrument) dla studenta COLLEGE’U. Marchew może być GWOŹDZIEM (nail) dla twojego PŁOTU (fence) lub MISKI (basin). Natomiast KUPIEC (merchant) KRÓLOWEJ (queen) wszedłby po DRABINIE (scale) na ten płot i dałby marchew do zjedzenia KOZIE (goat)”.
Każdy badany nauczył się w ten sposób dwunastu list. Do każdego badanego z grupy układającej opowiadania dobrano jednego badanego z grupy kontrolnej, odpowiadającego mu pod pewnymi istotnymi względami, któremu dano te same listy rzeczowników i tę samą ilość czasu do nauczenia się ich, jaką zużył badany z grupy układającej opowiadania. Badanym w grupie kontrolnej nie dano żadnych instrukcji dotyczących układania opowiadań.
Ponieważ listy zawierały tylko po 10 słów, obie grupy badanych odtwarzały każdą z nich niemal bezbłędnie po okresie uczenia się. Gdy jednak badani nauczyli się po kolei wszystkich list, wówczas każdemu z nich podawano pierwsze słowo każdej listy i proszono, aby odtworzył resztę listy we właściwym porządku. Różnice były ogromne: badani, którzy układali opowiadania, potrafili odtworzyć poprawnie 94% słów ze wszystkich list, podczas gdy w grupie kontrolnej otrzymano jedynie 14% poprawnych odtworzeń.  Strategia mnemoniczna zwiększyła liczbę odtworzonych słów prawie siedmiokrotnie.

„Wykorzystanie wyobraźni wzrokowej”. Wyobraźnia wzrokowa stanowi jeszcze jeden przykład strategii mnemonicznej. Technika ta jest szczególnie efektywna wtedy, gdy trzeba skojarzyć ze sobą niewielkie grupy sensownych elementów, takich jak słowa. W technice tej należy wyobrazić sobie kojarzone przedmioty jako biorące udział w jakiejś żywej scenie. Jeśli na przykład w zadaniu polegającym na kojarzeniu parami jedną z par na liście jest |pies-|rower, to prawdopodobnie najszybciej możesz się nauczyć tej pary i najlepiej ją zapamiętać, jeśli wyobrazisz sobie wielkiego, nakrapianego psa pedałującego na pięknie przyozdobionym dziecięcym rowerku.  Również nazwiska ludzi często można łatwiej zapamiętać posługując się wyobraźnią wzrokową. Im żywsze i bardziej osobliwe jest takie wyobrażenie, tym lepiej.
To, jaka strategia mnemoniczna będzie najwłaściwsza w danej sytuacji, zależy w pewnym stopniu od rodzaju zapamiętywanego materiału, jak również od wymaganego typu zapamiętywania. Strategie takie od dawna były propagowane w popularnych książkach, lecz dopiero niedawno stały się przedmiotem poważnych badań ze strony psychologów, takich jak Gordon Bower, oraz pedagogów pragnących rozwijać pamięć swych uczniów, by mogła przechować ogromną ilość wiedzy potrzebnej im w życiu.


Streszczenie rozdziału

Język odgrywa u ludzi ważną rolę w uczeniu się, komunikowaniu i zapamiętywaniu. Służy on zarówno do strukturalizowania rzeczywistości, jak i pobudzania fantazji, a także umożliwia przekazywanie wiedzy z pokolenia na pokolenie.
|Psycholingwistyka, nauka o psychologicznych aspektach języka i uczenia się mowy, zajmuje się przede wszystkim badaniem treści i struktury języka.  Analizę lingwistyczną przeprowadza się na trzech poziomach: a) na |poziomie |fonologicznym, dotyczącym |fonemów, podstawowych jednostek dźwiękowych języka; b) na |poziomie |gramatycznym, obejmuje |morfologię, czyli naukę o |morfemach (słowach i mających określone znaczenie częściach słów) oraz |składnię (reguły łączenia słów i zwrotów w zdania) i wreszcie c) na |poziomie |semantycznym, gdzie przedmiotem zainteresowania jest znaczenie.  W badaniu akustycznych właściwości morfemów przydatne okazały się |spektogramy |dźwiękowe. Zarówno struktura syntaktyczna, jak i znaczenie wpływają na naszą zdolność dokładnego słyszenia i zapamiętywania.
Osiągnięcia językowe w ciągu pierwszego roku życia ograniczają się do różnych form krzyku i gaworzenia. Pod koniec tego roku pojawiają się rozpoznawalne słowa i zaczyna się rozwijać prawdziwa mowa. Od tej chwili dzieci nieustannie powiększają swój zasób słów i coraz lepiej posługują się gramatyką. Zaczynają od pojedynczych słów, a następnie przechodzą do zdań dwuwyrazowych, złożonych z tak zwanego |słowa |osiowego i ze słowa „|słownikowego” (lub z dwóch słów „słownikowych”). W wieku dwóch lat dzieci potrafią tworzyć dłuższe zdania, a wkrótce po tym zaczynają opanowywać reguły gramatyczne stosowane w mowie ludzi dorosłych.
Zwolennicy teorii uczenia się głoszą, że języka, jak i wszelkich innych zachowań, ludzie uczą się przez |wzmacnianie poprawnych reakcji, które małe dziecko wykonuje spontanicznie lub przez naśladowanie dorosłych. Natomiast psycholingwiści utrzymują, ze zdolność tworzenia języka jest |wrodzoną zdolnością ludzką, zarówno |specyficzną |dla |gatunku, jak i |jednakową |w |obrębie |gatunku. Sądzą oni, że proces rozwoju mowy nie opiera się na naśladowaniu, lecz raczej na konstruowaniu ogólnej teorii języka zawierającej |reguły |transformacyjne, za pomocą których |struktura |głęboka, czyli znaczenie, zostaje przekształcona w |strukturę |powierzchniową. 
Komunikowanie się nie zawsze jednak wymaga słów. Badania nad |komunikacją |niewerbalną obejmuje mimikę twarzy, |kinezjetykę (ruchy ciała), |proksemikę (odległość w przestrzeni, kontakt dotykowy i wzrokowy) oraz |parajęzyk (niewerbalne aspekty komunikacji głosowej). Kontakt wzrokowy jest ważnym czynnikiem w ekspresji niewerbalnej. Skłonni jesteśmy patrzeć prosto w oczy ludzi, których lubimy, i unikać kontaktu wzrokowego z tymi, których nie lubimy; niepożądany kontakt wzrokowy może być źródłem przykrości. Postawa ciała, jak również nawykowe gesty, mogą przekazywać sygnały na temat stopnia zainteresowania, własnego statusu czy pełnionej roli. Odległość, jaką ludzie zachowują od innych ludzi, także sygnalizuje stopień pożądanej poufałości. Gdy sygnały głosowe i inne sygnały niewerbalne przekazują informacje niezgodne z treścią wypowiedzi słownej, to wówczas sygnały niewerbalne zwykle są bardziej wiarygodne.
Psychologów od dawna intryguje pytanie, czy zdolność posługiwania się językiem występuje jedynie u ludzi. Badania nad gwizdami wydawanymi przez delfiny wykazały, że spełniają one funkcję raczej społeczną niż komunikacyjną. Badania nad szympansami przeszły ewolucję od prób nauczenia tych zwierząt wymawiania słów do studiowania ich zdolności posługiwania się różnymi symbolami. Kilku badaczy osiągnęło już w tej dziedzinie interesujące rezultaty.
Badania nad pamięci zmierzają do znalezienia odpowiedzi na pytanie, w jaki sposób informacje są magazynowane, przechowywane i odszukiwane. W tym celu porównuje się ilość materiału pamiętaną bezpośrednio po uczeniu się, z ilością pamiętaną po pewnym czasie. W badaniach nad uczeniem się werbalnym stosuje się metodę |przypominania (odtwarzania) - dosłownego albo rekonstruującego), |rozpoznawania oraz |ponownego |uczenia |się (w tej ostatniej) metodzie eksperymentatora interesuje oszczędność czasu uczenia się). Tradycja badań nad uczeniem się werbalnym bierze początek od Ebbinghausa, który uczył się sylab bezsensownych |metodą |antycypacji. 
Ebbinghaus ustalił typową krzywą przechowywania dla pamięci mechanicznej: 
po początkowym okresie szybkiego zapominania krzywa obniża się coraz wolniej. Stwierdził on także wpływ |miejsca |w |szeregu na zapamiętywanie (zwykle łatwiej jest przypomnieć sobie pierwsze i ostatnie pozycje).
W badaniu pamięci stosuje się także |metodę |skojarzeń |parami, w której badany uczy się par słów i musi przypomnieć sobie jedno słowo z pary, gdy podawane jest drugie. Bada się także |przypominanie |swobodne. Metodę skojarzeń parami stosuje się powszechnie przy badaniu interferencji |proaktywnej (tzn. działającej „do przodu” i |retroaktywnej (tzn.  działającej wstecz). Pamięć może mieć charakter |wytwórczy, co wiąże się zarówno z rekonstruowaniem, jak i zniekształcaniem szczegółów. Przy badaniu tego zjawiska stosuje się technikę |kolejnego |odtwarzania |materiału.
W celu wyjaśnienia zjawisk zapominania stworzono liczne teorie, wśród nich |teorię |zanikania |śladów, |teorię |interferencji, |teorię usuwania, |teorię |utraty |dostępu oraz |teorie |motywacyjne odwołujące się do |mechanizmu |wyparcia (represji).

Niedokończone zadania pamięta się lepiej niż ukończone (|efekt |Zeigarnik), z wyjątkiem sytuacji, gdy w grę wchodzi lęk. Różne teorie wyjaśniają rożne aspekty zapominania, lecz żadna z nich nie daje ogólnego wyjaśnienia tego zjawiska.
Przyjmuje się powszechnie, że istnieją trzy różne systemy pamięci.  |Magazyn |informacji |sensorycznej przechowuje informacje sensoryczne tylko tyle czasu, by mogły być natychmiast wykorzystane w procesie percepcji. W |pamięci |krótkotrwałej ograniczone ilości informacji są przechowywane przez krótki czas. Treści, które mają być przechowywane przez czas dłuższy, muszą być przekazane do |pamięci |długotrwałej. Wydaje się, że pamięć wiąże się raczej z procesami przekazywania synaptycznego niż z przechowywaniem specyficznych śladów pamięciowych, czyli |engramów.
Można rozwinąć własne zdolności uczenia się i zapamiętywania, stosując zasady oparte na wynikach badań nad uczeniem się, a mianowicie |przeuczanie |się, |okresowe |przeglądanie i |aktywne |powtarzanie |z |pamięci.  |Porcjowanie redukuje liczbę jednostek, które trzeba zapamiętać. Inne |strategie |mnemoniczne to wykorzystywanie istniejącej struktury, zwiększanie sensowności materiału oraz posługiwanie się wyobraźnią wzrokową.


Z Frontu Badań.
Próba wniknięcia w milczący świat autystycznego dziecka

|John |D. |Bonvillian
„Vassar College”

Jakie mogą być przyczyny, że dziecko nie zaczyna mówić, mimo że ukończyło już trzy lata? W wielu przypadkach zdolności językowe dziecka okazują się nienaruszone, a główną różnicą w stosunku do normalnego rozwoju jest wolniejsze tempo opanowywania języka. W niektórych przypadkach badania lekarskie ujawniają upośledzenie słuchu, jednakże pewna niewielka liczba niemówiących dzieci nie wykazuje żadnego wykrywalnego upośledzenia słuchu ani uszkodzenia mózgu, a jednak nie opanowują one mowy. Takim dzieckiem był Ted. Chciałbym opowiedzieć historię trwającego nadal przedsięwzięcia, zmierzającego do nawiązania kontaktu z tym izolowanym dzieckiem.
Od wczesnego niemowlęctwa Ted zachowywał się zupełnie inaczej niż jego starsi bracia i siostra. Podczas gdy oni często domagali się brania na ręce, Ted nie przytulał się do swych rodziców. Jego rodzeństwo podobnie jak inne normalne dzieci, reagowało na ból płaczem, natomiast Ted często zdawał się niewrażliwy na ból. Gdy mając trzy lata nie zaczął jeszcze mówić, wówczas zaniepokojeni rodzice Teda zwrócili się o pomoc do specjalistów w dziedzinie zaburzeń językowych i problemów emocjonalnych dzieci. Po kilku latach uczestniczenia w wielu zajęciach terapeutycznych, Ted pozostał nadal dzieckiem niemówiącym i izolowanym. Uzgodniono jednak diagnozę tego rzadkiego zespołu zachowań: autyzm dziecięcy.
Zespół wczesnego autyzmu dziecięcego wzbudza znaczne zainteresowanie od czasu, gdy go opisano przed przeszło trzydziestu laty. Tę jednostkę chorobową rozpoznaje się jednak u bardzo nielicznych dzieci (około 4 na 10 tysięcy). Początkowo opisy autystycznych dzieci koncentrowały się na kilku cechach ich zachowania, którymi wyraźnie różnią się one od dzieci normalnych. Dzieci autystyczne charakteryzuje się jako wykonujące dziwaczne, powtarzane wielokrotnie ruchy, pragnące samotności, często także nie opanowujące zrozumiałej mowy. Niekiedy wykazują one również silne zainteresowanie urządzeniami mechanicznymi. Wczesne analizy autyzmu sugerowały także, że anormalny rozwój dziecka jest wynikiem znacznego braku rodzicielskiego ciepła oraz interakcji między rodzicami a dzieckiem. Gdy jednak zebrano więcej materiałów dowodowych, wówczas pogląd ten, uznający rodziców za czynniki przyczynowe, został w dużej mierze odrzucony.  Natomiast w nowszych pracach przeglądowych argumentuje się, że zakłócenia funkcji językowych i operowania symbolami są w przypadku autyzmu pierwotnymi formami zaburzenia, z których wynikają późniejsze poważne anomalie w zakresie rozwoju społecznego i zachowania. Ponadto wykazano, że brak funkcjonalnej mowy u autystycznego dziecka w wieku pięciu lat jest w wysokim stopniu skorelowany z niedomyślną prognozą co do późniejszego przystosowania danego dziecka - jest nieprawdopodobne, aby dziecko takie kiedykolwiek osiągnęło normalne przystosowanie do środowiska.
Drogi Teda i moje przecięły się po raz pierwszy przed kilku laty. Kilka dni wcześniej miałem wykład, wobec małej grupy studentów Stanford University, poświęcony strukturze języka gestów czy znaków używanego przez głuchych. Wśród słuchaczy był pewien student, którego brat był niemówiącym 15-letnim autystycznym chłopcem. Po dyskusji doszliśmy z tym studentem do wniosku, że może warto by spróbować zastosować jakiś inny niż mowa wokalna kanał komunikacji, a mianowicie język znaków. Dr Gloria F. Leiderman, kierowniczka ośrodka terapeutycznego, do którego uczęszczał ten chłopiec, zasugerowała, że moglibyśmy wypróbować najpierw nasz pomysł na 9-letnim Tedzie, który nie zareagował na żadne poprzednio stosowane oddziaływania zmierzające do ukształtowania czynności mowy.
Rozumowaliśmy, że w sytuacji, w której nie mogła rozwinąć się mowa, posłużenie się jakimś językiem o charakterze wzrokowo-ruchowym mogłoby ułatwić Tedowi opanowanie umiejętności porozumiewania się. Uprzednie badania wykazały, że reakcje wzrokowe dzieci autystycznych bardziej upodabniały się do reakcji dzieci normalnych niż ich umiejętności słuchowe i artykulacyjne. Wzrokowo-ruchowe środki porozumiewania się mogły zatem znaleźć oparcie w podstawowych umiejętnościach, które - w przeciwieństwie do mowy - były stosunkowo nieupośledzone. Ponadto oprócz tej widocznej korzyści w postaci wykorzystania sprawności wzrokowej Teda, język znaków w porównaniu z mową miał tę zaletę, że łatwo go było „kształtować” - nauczyciele mogli łatwo układać ręce Teda w odpowiednie gesty.
Znaki w Amerykańskim Języku Znaków (ASL - „American Sign Language”), w języku znaków używanych przez głuchych w Stanach Zjednoczonych do potocznych rozmów, odpowiadają w dużym stopniu słowom języka mówionego.  Każdy znak, podobnie jak słowa, reprezentuje jakieś podstawowe pojęcie, czy znaczenie. Podobnie szereg znaków łączy się tak, aby wyrażały jakąś kompletną myśl, w taki sam niemal sposób, w jaki grupuje się słowa tworzące zdanie. Przeprowadzone niedawno analizy składni i semantyki ASL wskazują na wysoki stopień spójności strukturalnej, co sugeruje, że jest to system syntaktyczny, oparty na pewnych regułach. Każdy znak w ASL składa się z określonej konfiguracji ręki lub rąk, ich ruchu oraz miejsca na ciele lub w jego pobliżu, w którym zaczyna się lub kończy wykonywanie tego ruchu.  Dalszych danych, świadczących o podobieństwie między językiem znaków a mową dostarczają badania, w których porównywano przyswajanie sobie języka znaków przez dzieci głuche oraz mowy przez dzieci normalnie słyszące.

* * *
Ryc. 4.15. Zdjęcie przedstawia Teda w trakcie jednego z codziennych posiedzeń z nauczycielem-terapeutą, wkrótce po tym, gdy zaczął przyswajać sobie język znaków i posługiwać się nim.

* * *
Wiele stadiów opanowywania języka znaków odpowiada ściśle stadiom opanowywania mowy przez dzieci słyszące. W miarę postępu naszych badań przeszliśmy od stosowania ASL do SEE („Spigning Exact English”, forma języka znaków ściśle dostosowana do gramatyki języka angielskiego).
W czasie, kiedy zaczynaliśmy uczyć Teda języka znaków, miał on dziewięć lat i jeden miesiąc i |nigdy nie posługiwał się zrozumiałą mową. Jednakże zdawał się być wrażliwy na dźwięki, często odwracał się i pokazywał palcem kogoś kto wszedł do pokoju, w którym odbywał on terapię. Gdy był znacznie młodszy, wówczas stwierdzono, że jego słuch, podobnie jak zapis EEG, są w granicach normy. Poczynając od trzeciego roku życia, Ted przez osiemnaście miesięcy brał udział w zajęciach terapeutycznych w formie wspomaganej przez komputer interakcji językowej i był dzieckiem najsłabiej reagującym na ten rodzaj terapii. Oprócz udziału w tych zajęciach, poddano go indywidualnemu treningowi językowemu oraz grupowej terapii zabawowej; obie te formy terapii były zupełnie nieskuteczne, jeśli chodzi o pobudzenie rozwoju mowy czy reaktywności społecznej. Poziom inteligencji Teda w wieku pięciu lat został oceniony jako niezwykle niski (I.I.=46, podczas gdy 100 uważa się za „normę”). Mając siedem i pół roku Ted rozpoczął leczenie ambulatoryjne w ośrodku rehabilitacyjnym Peninsula Children’s Center w Palo Alto w stanie Kalifornia. Tu zastosowano program nauki mowy oparty na procedurach warunkowania sprawczego, lecz i tym razem nie udało mu się opanować języka ani nawet pojedynczych słów. Gdy zaczęliśmy uczyć Teda języka znaków, to było oczywiste, że gdyby potrafił go opanować, to po raz pierwszy użyłby generatywnego języka, a byłyby to zapewne również pierwsze kroki na drodze do bardziej normalnego życia społecznego.
Ted przechodził specjalny trening w posługiwaniu się językiem znaków na codziennych półgodzinnych sesjach w ośrodku terapeutycznym. Aby zapoznać go z nowym znakiem, jego nauczycielka-terapeutka Rachel Vasiliev pokazywała mu zwykle obrazek, który przedstawiał przedmiot lub czynność odpowiadające znakowi, jakiego miał się nauczyć, a następnie układała jego ręce w odpowiedni gest. Następny krok polegał na tym, że Rachel pokazywała Tedowi poprawny znak dla danego obrazka i polecała mu naśladować go. Na koniec Ted uczył się wykonywać poprawny znak w odpowiedzi na sam obrazek. W ciągu pierwszych miesięcy przyswajania sobie słownika znaków, Ted otrzymywał pozytywne wzmocnienie za właściwe reakcje. Wprowadzono system nagród w postaci żetonów - otrzymywał on specjalną kartę za każdym razem, gdy poprawnie wykonał jakiś znak. Pod koniec sesji treningowej Tedowi pozwalano zamienić zebrane przez niego karty na upragnioną zabawkę lub możliwość zabawy poza pomieszczeniem. Przez cały czas sesji treningowej Rachel chwaliła go po poprawnym wykonaniu każdego znaku i udzielała mu zachęty.  Codzienne sesje językowe uzupełniały nieformalne ćwiczenia i interakcje przy zastosowaniu języka znaków z matką w domu. Zarówno matka Teda, jak i nauczycielka-terapeutka przechodziły szkolenie i praktykę w posługiwaniu się językiem znaków przez co najmniej jedną godzinę tygodniowo.  Zamieszczona obok tabela przedstawia powolne, lecz stałe postępy Teda w przyswajaniu sobie słownika znaków w ciągu pierwszych sześciu miesięcy realizacji programu. W tym okresie przyswajał on sobie nowe znaki w tempie równym przeciętnie dwom nowym znakom na tydzień. Jest interesujące, że jeśli Ted użył raz jakiegoś znaku poprawnie (bez bezpośrednio poprzedzającego ten fakt formowania gestu czy demonstrowania go), to było bardzo prawdopodobne (w 96 procentach), że zastosuje go we właściwy sposób w przynajmniej dwóch innych sytuacjach. W ciągu dwóch lat słownik znaków Teda nadal się rozszerzał, oceny zasobu jego słownictwa wskazywały, że znał on i stosował prawie 400 pojedynczych znaków.
Aczkolwiek poprawne stosowanie pojedynczych znaków stanowiło ważny pierwszy krok w uczeniu się języka przez Teda, to jednak niezbędnym warunkiem efektywnego porozumiewania się z rodziną i personelem ośrodka było nauczenie się łączenia znaków, tak aby móc wyrażać treści bardziej złożone. Można wyobrazić sobie naszą radość, gdy po nieco więcej niż trzech miesiącach ćwiczenia pojedynczych znaków zaobserwowaliśmy po raz pierwszy, że Ted samorzutnie łączy znaki w celu zakomunikowania swych myśli.  Porównanie pierwszych kombinacji znaków stosowanych przez Teda ze sposobem zestawiania słów przez dzieci uczące się dopiero mówić ujawniało szereg podobieństw. Analiza podstawowych relacji semantycznych, wyrażanych w spontanicznych zestawieniach dwóch znaków stosowanych przez Teda, wykazała, że pod względem strukturalnego znaczenia przypominają one bardzo dwuwyrazowe zdania występujące u normalnych dzieci. Oto przykłądy używanych przez Teda kombinacji dwóch znaków oraz ich strukturalne interpretacje: 
„chłopiec pić” (działająca osoba i czasownik), „pływać szkoła” (czasownik i miejsce) oraz „chłopiec piłka” (posiadanie i przedmiot). Dalsze podobieństwa, to stosowanie przez Teda znaku „więcej” dla wyrażenia żądania lub ponownego pojawiania się sygnału (na przykład „więcej mleko”, „więcej ciastko”) oraz posługiwanie się przez niego znakiem przeczenia przed innym znakiem lub kombinacją znaków (na przykład „nie jedzenie”, „nie iść”) dla wyrażenia nieistnienia lub odmowy. Ponadto jego matka zaobserwowała, że niekiedy pokazywał on znaki sobie samemu w lustrze - zachowanie to przypomina pierwsze zabawy słowne normalnych dzieci.
Mimo wielu analogii w procesie przyswajania sobie języka, pierwsze kombinacje znaków dokonywane przez Teda różniły się pod przynajmniej dwoma względami od wczesnych wypowiedzi normalnego dziecka. Po pierwsze, zaledwie po dwóch miesiącach łączenia znaków Ted „wyprodukował” kilka pełnych wypowiedzi złożonych nawet z pięciu znaków (na przykład „nie matka samochód bawić się szkoła” - matka Teda nie przyszła zabrać go do samochodu, ponieważ miał bawić się w szkole) i po drugie często stosował on poprawnie okoliczniki czasu w swych zdaniach (na przykład „jeść indyk jutro”).
Należy zwrócić uwagę, że wypowiedzi tej długości oraz poprawne zastosowanie okoliczników czasu są czymś wysoce niezwykłym we wczesnych stadiach przyswajania sobie języka.
W ostatnich dwóch latach liczba i złożoność „wypowiedzi” Teda stopniowo wzrastały, aczkolwiek temat jego konwersacji ograniczał się głównie do bezpośrednich doświadczeń. Jeśli jednak słuchacz znał sposób patrzenia Teda na świat, to mógł prowadzić z nim spójną konwersację nawet przez kilka minut. Oto przykład osiągniętego przez niego poziomu rozumienia i poziomu złożoności języka, którym się posługiwał. Gdy jego nauczycielka-terapeutka zapytała go, co zamierza robić, gdy dorośnie, wówczas Ted odpowiedział: 
„Ted, duży tatuś, mieć wąsy - zamiatacz ulic, doktór” („Gdy będę duży jak tatuś i będę miał wąsy, to będę zamiataczem ulic albo doktorem”).
W ubiegłym roku podjęliśmy próbę rozbudowania umiejętności komunikacyjnych Teda tak, aby objęły one czytanie i mówienie. Jego nauczycielka-terapeutka zaczęła uczyć Teda czytania drukowanych słów, zestawiając je z odpowiadającymi im znakami. Po wielu miesiącach ćwiczenia Ted zaczął opanowywać ideę właściwego porządku słów i obecnie potrafi czytać i odtwarzać proste zdania złożone z podmiotu, orzeczenia i dopełnienia. Na koniec Deborah Bresler, prowadząca z Tedem zajęcia z zakresu przyswajania sobie języka i mowy, zaczęła pracować z nim nad przyswajaniem sobie języka mówionego. Jego postępy w tej dziedzinie były bardzo powolne, gdyż Ted nie potrafił wysuwać języka ani otwierać ust na polecenie. Ćwiczenia koncentrowały się na pomaganiu Tedowi w uzyskaniu kontroli nad celowymi ruchami oralnymi. Ćwiczył on ruchliwość języka, zlizując lodu umieszczane regularnie na jego wargach. Jego pierwszym, umiarkowanie zrozumiałym słowem było „ice-cream” (lody).

Rozwojowi umiejętności komunikowania się towarzyszyła poprawa indywidualnego i społecznego zachowania Teda. W ciągu pierwszych sześciu miesięcy realizacji tego programu znacznie spadła częstość zanieczyszczania się - od przeciętnej do ponad dwóch razy dziennie do około jednego razu w tygodniu. Obecnie, po raz pierwszy zdaje się on mieć całkowitą kontrolę zarówno nad funkcjami swego pęcherza, jaj i nad wypróżnianiem się. Częstość występujących u niego poprzednio wybuchów złości, zarówno w domu, jak i w szkole zbliżyła się do zera, a jego rodzice zlikwidowali specjalnie wybudowane „pomieszczenie wypoczynkowe” (mały pusty pokój), gdzie poprzednio umieszczano go, aby ochłonął po napadzie złości lub destrukcyjnym zachowaniu. Wydaje się także, że poprawie uległy zarówno zdolności Teda do koncentrowania się, jak i jego zdolność do zwracania uwagi na różnych ludzi oraz wydarzenia zachodzące w jego otoczeniu; nastąpiła także stopniowa redukcja dziwacznych, stereotypowych gestów i ruchów.
Reasumując, Ted w ciągu dwóch i pół roku uczestniczenia w tym zindywidualizowanym programie badawczo-terapeutycznym poczynił wielkie postępy w przyswajaniu sobie umiejętności komunikowania się. Pozostaje on nadal znacznie upośledzonym dzieckiem, które prawdopodobnie będzie potrzebowało troskliwego nadzoru i opieki przez całe życie. Sukcesy Teda w opanowywaniu języka znaków świadczą o tym, że jego zdolności poznawcze i językowe nie zostały zaktywizowane we właściwy sposób przez środowiska terapeutyczne nastawione na kształtowanie mowy. Sugerują one w dodatku, że wiele innych autystycznych i niemówiących dzieci może posiadać zdolności poznawcze niezbędne do tego, by nauczyły się porozumiewać za pomocą języka znaków lub innej niewokalnej mowy. Istotnie, sprawozdania napływające z ośrodków badawczych i rehabilitacyjnych w całym kraju wskazują, że wiele autystycznych dzieci czyni postępy w przyswajaniu sobie umiejętności porozumiewania się za pomocą języka znaków.


Rozdział 5.
Myślenie, rozumowanie i twórczość



„Co chodzi na czterech nogach rano, na dwóch w południe, a na trzech nogach o zmierzchu?”


Odpowiadając |Człowiek, Edyp rozwiązał zagadkę zdaną mu przez Sfinksa i uwolnił lud Teb spod jego tyranii. Nasz gatunek zwany jest „homo sapiens” - człowiek rozumny. Ćwicząc swobodnie naszą szczególną zdolność myślenia, rozumowania i rozwiązywania problemów, uwalniamy sami siebie spod tyranii życia zdominowanego przez siły środowiskowe i wewnętrzne potrzeby. Aby przezwyciężyć liczne przeszkody spotykane na drodze naszego pełnego ludzkiego rozwoju, musimy nauczyć się jak analizować charakter różnych problemów, jak obmyślać dla nich twórcze rozwiązania i jak te rozwiązania wcielać w życie.
Nasza zdolność poznawania obejmuje zdolność myślenia, to znaczy manipulowania elementami otoczenia lub organizowania ich za pomocą symboli, a nie aktów fizycznych. Do symboli tych zalicza się słowa, liczby, gesty, obrazy, schematy i wyobrażenia wzrokowe. Myślenie może przyjmować wiele postaci, od rozwiązywania konkretnych problemów do marzeń na jawie i wzlotów fantazji. Posiadając zdolność rozwiązywania codziennych, praktycznych problemów, każdy z nas jest jednak również „homo ludens” - człowiekiem bawiącym się. Bawimy się ze swym środowiskiem i ze sobą nawzajem. Nauczyliśmy się, jak znajdować przyjemność w rozumowaniu dla niego samego, jak rozkoszować się grami wymagającymi pewnych umiejętności czy też opartymi na przypadku bądź ryzyku. Gdy nieskrępowane, nacechowane wyobraźnią myślenie zostaje wykorzystane w służbie rzeczywistości, wówczas mówimy o |twórczości.
W niniejszym rozdziale będziemy zajmować się tymi wysoce złożonymi procesami umysłowymi, starając się zrozumieć, w jaki sposób one przebiegają. Jako przedstawiciele z gatunku „homo sapiens”, sami stanowimy dla siebie najtrudniejszą zagadkę.
W roku 1639 wygłaszając swe słynne dziś słowa: „Cogito, ergo sum” - Myślę, więc jestem, Descartes powiedział nam, że egzystencja ludzka opiera się na świadomości myśli ludzkiej. Czy organizm, który pod względem fizycznym wyglądałby zupełnie tak samo jak ty, lecz który nie potrafiłby myśleć, byłby jeszcze istotą ludzką? W jaki sposób mógłby on wiedzieć, czy istnieje, czy nie istnieje, nie będąc zdolnym do myślenia ani do obserwowania swych własnych procesów myślowych? Zadziwiającą cechą myśli ludzkiej jest to, że nie tylko myślimy, lecz także jesteśmy świadomi tego, że myślimy, a nawet potrafimy myśleć o naszym istnieniu.

„Myślenie jest próbą uchwycenia rzeczywistości za pomocą idei.
Jose Ortega y Gasset „La deshumanizacion del arte”, 1925 (wyd. pol. „O dehumanizacji w sztuce”)

Myślenie jest najbardziej złożoną czynnością, jaką wykonują istoty ludzkie. Polega ono na operowaniu |symbolami reprezentującymi materialne elementy środowiska. Jest ono przekształcaniem tego, co istnieje poza nami, w doświadczanej przez nas rzeczywistości, na to, czym było niegdyś (historia i geneza), z czym może się wiązać (skojarzenia, kategorie, tożsamość) i czym może się stać (przyszłość, potencjalne możliwości, fantazja). Myślenie pozwala więc wykroczyć poza percepcję; dzięki niemu możemy tworzyć pojęcia abstrakcyjne, takie jak „wolność”, które mogą nawet nie mieć konkretnego desygnatu. W ten sposób myśl uwalnia działanie ludzkie od ograniczeń nakładanych przez środowisko materialne.
Gdy nasze myśli odpowiadają ściśle cechom i wymaganiom obiektywnej, zewnętrznej sytuacji, wówczas myślenie takie określa się jako |realistyczne. Gdy realistyczne myślenie jest ukierunkowane na działanie, na rozwiązanie jakiegoś problemu, na określenie środków niezbędnych do osiągnięcia pożądanego celu, wówczas nazywa się |rozumowaniem.
Na przeciwległym krańcu kontinuum wyrażającego związek między myślą a wymaganiami rzeczywistości znajduje się |myślenie |autystyczne. Bodźcem dla myślenia autystycznego jest raczej rzeczywistość wewnętrzna niż zewnętrzna.  Nie musi ono być dostosowane do jakichś elementów świata „realnego”, lecz może składać się wyłącznie z pragnień, marzeń, fantazji, reakcji związanych z potrzebą autogratyfikacji. Jednakże osobie, która myślałaby przede wszystkim w sposób autystyczny, trudno byłoby przetrwać w naszym fizycznym i społecznym środowisku. Takie myślenie prawdopodobnie doprowadziłoby do niemożności uporania się z wymaganiami, stresami i zagrożeniami ze strony rzeczywistości zewnętrznej, jak również do braku więzi z innymi ludźmi, jaką stwarza podobny sposób myślenia. Grupa ludzi, których myślenie miałoby charakter autystyczny, nie mogłaby stworzyć żadnej społeczności - byłyby to tylko izolowane jednostki myślące o swych własnych sprawach.
Rozpatrując w Rozdziale 11 zachowania odbiegające od normy, przekonamy się, że ludzi, u których rozpoznano schizofrenię, określa się jako |tracących kontakt z rzeczywistością, podczas gdy bardziej prawdopodobne jest to, iż wykorzystują oni swą rzeczywistość wewnętrzną jako kryterium, czy sprawdzian, dla rzeczywistości zewnętrznej. Gdy nasze idee pozostają w konflikcie z rzeczywistością, wówczas zwykle zmieniamy je. Można jednak wierzyć w słuszność swych idei „bez względu na wszystko” i starać się zmienić rzeczywistość zewnętrzną, dokonać jej restrukturalizacji, lekceważyć ją lub w skrajnym przypadku odrzucić ją zupełnie na rzecz własnej rzeczywistości wewnętrznej.
Twórczość niewątliwie wymaga wyjścia poza to, co jest oczywiste dla każdego, tak, aby uzyskać nowe rozwiązania, albo nowe sposoby ujmowania starych problemów.

Akt twórczy, wymaga więc w dużym stopniu myślenia autystycznego, które nie jest ograniczone do zwykłego, stereotypowego czy tradycyjnego sposobu reagowania. Twórcze rozwiązywanie problemów, które doprowadza do wynalazków, jest połączeniem myślenia autystycznego i realistycznego. 

* * *
Ryc. 5.1. Różne twórcze sposoby podejścia do tego samego przedmiotu, wszystkie autorstwa Pabla Picassa. Od lewej: „Visage” (Oblicze) Kolekcja „The Detroit Institute of Arts” (Instytutu Sztuki w Detroid), dar „The Friends Of Modern Art” (Przyjaciół Sztuki Nowoczesnej); „Woman Weeping” (Kobieta płacząca) Kolekcja Rolanda Penrose’a, Londyn; „Girl Before Mirror” (dziewczyna przed zwierciadłem) 14 marca 1932, olej na płótnie, 160x129, Kolekcja „The Museum of Modern Art” (Muzeum Sztuki Nowoczesnej) w Nowym Jorku, dar Simon Guggenheim.

* * *
Twórczość znajdująca wyraz w ekspresji artystycznej tego rodzaju jak u Pabla Picassa, wiąże się z nadawaniem autystycznym wyobrażeniom artysty takiej formy, aby inni mogli ją przyjąć i zaakceptować. W nauce twórczość na ogół opiera się na myśleniu realistycznym, które uwzględnia najlepsze, dostępne źródła danych, a następnie kombinuje te dane w nowy sposób, wyciąga z nich nowe wnioski, znajduje brakujące ogniwo lub odkrywa podstawową unifikującą zasadę.
Warto wspomnieć mimochodem, że w odróżnieniu od Amerykanów i Europejczyków, którzy na ogół cenią w twórczości oryginalność, odkrywczość i nowe formy, charakterystyczną cechą twórczości ludzi Wschodu jest kształtowanie elementów w nowy sposób, ale w ramach pewnej starej formy. Na przykład, twórczy poeta japoński, piszący epigramy zwane „haikai” (zwykle na temat przyrody), ograniczony jest sztywną formą wersyfikacyjną - 17 sylab w trzech nierymowanych wierszach, złożonych z 5, 7 i 5 sylab.  Jednakże ilość wariacji, utrzymanych w ramach przepisanej formuły, jest nieskończona i pozostawia dosyć swobody dla myśli twórczej.


Psychologia procesów poznawczych


Nie ulega wątpliwości, że w centrum zainteresowania psychologii eksperymentalnej są obecnie |procesy |poznawcze. Poprzednio kładziono nacisk na „warunkowanie i uczenie się” izolowanych, zewnętrznych reakcji na bodźce fizyczne, często u niższych zwierząt. Podręczniki i wstępne kursy psychologii do niedawna zajmowały się głównie „psychologią szczura”, a stosunkowo niewiele miejsca poświęcono w nich zagadnieniu myśli ludzkiej.  Szczury i gołębie były godne uwagi, ludzie nie - co najwyżej jako opiekunowie owych cennych „osób badanych”.
Nowe podejście koncentruje się na tym, w jaki sposób ludzie manipulują symbolami w swym umyśle. Termin „poznanie” („cognition”) oznacza |proces |poznawania w najszerszym sensie, obejmującym percepcję, pamięć, ocenianie, mowę itd. Lecz odnosi się on również do |wyniku |czy |wytworu |aktu |poznawania (myśl, bit informacji, element pamięciowy itd). To właśnie nasze jedyne w swoim rodzaju zdolności poznawcze pozwalają nam wyjść poza troskę o przetrwanie i zaabsorbowanie adaptacją do środowiska. Gdy wykorzystujemy w pełni nasz aparat poznawczy, wówczas stajemy się aktywnymi twórcami nowych rzeczywistości. My, ludzie, przekształcamy zewnętrzną, empiryczną, konkretną, ograniczoną do „tu i teraz” rzeczywistość w coś całkowicie odmiennego, a to dzięki naszej zdolności do tworzenia symbolicznej jej reprezentacji.


„Wiesz, to nie deszcz pada, to padają fiołki”.
„Każda ciemna chmura ma srebrną podszewkę”.
„Pragnienie może przekształcić rzeczywistość”.

W rozwiniętych technicznie społeczeństwach rzadko wpływ na nasze działanie wywierają naglące potrzeby biologiczne czy rozpaczliwa ucieczka przed prześladowaniami i klęskami żywiołowymi, częściej zaś działamy pod wpływem mitów, jakie stworzyliśmy swoimi słowami, pod wpływem naszych marzeń i idei. Zazwyczaj reagujemy raczej na naszą osobistą ocenę czy interpretację sytuacji niż na samą „obiektywną” sytuację. Operujemy nazwami zamiast rzeczami nazywanymi, pojęciami i uogólnieniami zamiast zdarzeniami czy specyficznymi bodźcami fizycznymi.


„Nasze życie jest tym, czym czynią je nasze myśli”.
Marek Aureliusz „Eis heauton II w.n.e”.
(wyd. pol. „Rozmyślania”)

W poprzednim rozdziale omówiliśmy już niektóre aspekty psychologii procesów poznawczych; w tym rozdziale rozpatrzymy inne aspekty tego sposobu podejścia. Oto jeden z poglądów na psychologię procesów poznawczych, który przedstawił brytyjski psycholog D. E. Broadbent (1971):


„W ostatnich latach przyjęła się moda, aby o każdym zdarzeniu sensorycznym myśleć tak, jakby wpływało ono na kompleks oddziaływujących na siebie nawzajem procesów, z których wiele przebiegało już przed pojawieniem się |S (bodźca). Procesy te mogą przekształcać informację o |S w inną postać; odkładającą chwilowo tę informację, a później powracają do niej, wyodrębniają z niej pewne cechy i pomijają inne, wykorzystują ją do zmodyfikowania wewnętrznej reprezentacji całego środowiska zewnętrznego, manipulują tym symbolicznym modelem świata tak, by reprezentował zdarzenia zachodzące w czasie czy przestrzeni, zapoczątkowują pewien ruch albo sterują nim, gdy już został zapoczątkowany, i w ogóle dokonują na |S różnych operacji, a nie tylko reagują nań przez wytwarzanie |R (reakcji)”.
Zanim przejdziemy do szczegółowego omówienia tego, co wiemy o naszym poznawaniu, przedstawimy pokrótce przedstawione tematy, które powtarzają się wciąż w badaniach i teoriach dotyczących procesów poznawczych.
1. Koniecznym warunkiem wszechstronnego rozwoju intelektualnego jest uwolnienie się procesu konceptualizacji od jej bezpośredniej zależności względem spostrzeganej rzeczywistości zewnętrznej. Badając, jak u dzieci rozwija się logiczne zrozumienie świata, możemy odkrywać, w jaki sposób fakty przyrodnicze stają się zasadami rozumowania, jaki dane stają się informacją i jak założenia, reguły i kategorie zaczynają zastępować doświadczenie. Te symbole  świata zewnętrznego mogą ulegać transformacji pod wpływem każdego z procesów (lub ich kombinacji) generowanych przez całą rodzinę wewnętrznych operacji umysłowych.
2. Nadal toczy się ożywiony spór, co do względnego znaczenia natury i wychowania, jeśli chodzi o ich wpływ na rozwój poznawczy. Nietrudno wyciągnąć wniosek o istnieniu silnego podłoża o charakterze wrodzonym, ponieważ struktura poznawcza jest bardzo złożona, dzieci wykonują skomplikowane funkcje po małej liczbie ćwiczeń, a stadia rozwoju poznawczego następują po sobie w stałej kolejności. Z drugiej strony, indywidualne i kulturowe różnice pod względem stopnia wyrafinowania funkcji poznawczych skłaniają innych badaczy do podkreślania głębokiego, subtelnego wpływu czynników środowiskowych, takich jak uczenie się, własne doświadczenia podmiotu i kształcenie.
3. Procesy poznawcze mają charakter ciągły, aczkolwiek dla celów analizy można je dzielić na następujące po sobie kolejno fazy, które pośredniczą między wejściem bodźcowym i wyjściem w postaci reakcji. Fazy te arbitralnie wyodrębnione przez badaczy z przebiegającego procesu, obejmują: wykrywanie cech bodźca, wybór cech, na które należy zwracać uwagę, uznanie bodźca za nowy lub znany, przekształcenie czy zakodowanie wybranych cech, zmagazynowanych elementów poznawczych i wyszukiwanie ich, sprecyzowanie możliwych planów działania i ich konsekwencji, wreszcie porównywanie uzyskanych wyników z oczekiwaniami.
4. Badanie procesów poznawczych polega na analizowaniu wzorców zachowania występujących w różnych punktach kontinuum czasu. Jest to zarówno badanie wzorców rozwojowych, które kształtują się przez lata, jak i badanie wzorców reakcji występujących w ciągu minut lub nawet mikrosekund, gdy element poznawczy jest przesyłany przez system przetwarzania informacji u człowieka.
5.  Procesy poznawcze nie zawsze przebiegają w sposób uporządkowany, liniowy, lecz mogą polegać na równoległym, równoczesnym przetwarzaniu różnych rodzajów informacji w różnym tempie. Na przykład, możesz rozwiązywać zadanie matematyczne, planować obiad, usiłować przypomnieć sobie nazwisko, które „masz na końcu języka”, być roztargnionym pod wpływem uświadamianego sobie głodu lub impulsów seksualnych, zauważyć dziurę w swojej skarpetce, przypomnieć sobie głupi sen oraz zastanawiać się, co w ogóle robisz na uczelni - i to wszystko w ciągu kilku chwil.
Ulric Neisser, jeden z najbardziej wpływowych myślicieli w dziedzinie psychologii procesów poznawczych, podaje szeroką definicję tego, co mamy na myśli, gdy mówimy o tych procesach:
„(...) poznanie oznacza wszystkie procesy, dzięki którym wejście sensoryczne jest przekształcane, redukowane, przetwarzane, magazynowane, odtwarzane i wykorzystywane. Odnosi się ono do tych procesów nawet wtedy, gdy przebiegają one pod nieobecność właściwych (odbieranych z zewnątrz) bodźców, jak w wypadku wyobrażeń i halucynacji” (1967, s. 4).

Różne podejścia do badania rozwoju poznawczego


Gdy Menon zapytał Sokratesa, czy cnoty można kogoś nauczyć w drodze racjonalnych rozważań, czy wymaga ona ćwiczenia, czy też jest naturalnym, przyrodzonym stanem, wówczas został postawiony podstawowy problem rozwoju dziecka. Nie odnosi się on jedynie do pojęcia „cnoty”, lecz do każdego aspektu zachowania człowieka. Co by się stało, gdyby nie robić nic, gdyby nie było żadnego nauczania, żadnej sposobności obserwowania innych ludzi, krótko mówiąc - żadnego środowiska społecznego? Czy dziecko rozwijałoby się tak samo?
Psychologowie od dawna zajmują się problematyką procesów stanowiących podłoże rozwoju poznawczego, dzięki któremu nieme, nierozumne niemowlę staje się spostrzegawczym, rozmownym dzieckiem, a wreszcie - gdy dorośnie - filozofem, poetą czy uczonym. Toczą również spory na temat czynników |determinujących ten rozwój, jego |granic oraz tego, czy |kolejność, |tempo i |cechy |jakościowe rozwoju są niezmienne, czy też mogą ulegać modyfikacji.



Dzieło Piageta


Nikt nie wzbogacił bardziej naszej wiedzy o tym, jak dzieci myślą, rozumieją i rozwiązują problemy niż szwajcarski psycholog Jean Piaget.  Blisko pięćdziesiąt lat swej naukowej kariery poświęcił na obserwowanie, czego dzieci potrafią dokonać i jak wyjaśniają one to, co umieją (i czego nie umieją) zrobić w kolejnych stadiach swego intelektualnego rozwoju.  Piaget zaczął od dokładnego obserwowania zachowania swoich własnych dzieci.  Stawiał im zadania, zmieniał nieco sytuację, a następnie obserwował, jak zareagują. Fakt, że Piaget studiował zoologię, tłumaczy przypuszczalnie jego podejście badawcze: intensywne obserwacje zachowania i rozwoju zdrowych organizmów w naturalnym środowisku.
W przeciwieństwie do wielu psychologów eksperymentalnych, którzy badając w warunkach laboratoryjnych procesy przetwarzania informacji, obmyślają złożone eksperymenty prowadzące do prostych wniosków. Piager posługiwał się prostymi eksprymentami, na podstawie których można wyprowadzać złożone uogólnienia.

Od pozorów do reguł. Małe dzieci rozpoczynają swą podróż przez życie jako |naiwni |realiści - to znaczy wierzą w to, co widzą, ufając, że pozór jest jedyną rzeczywistością. W wypadku wielu problemów, przed jakimi staje dziecko, takie oparcie się na |percepcji jako środku poznawania otoczenia jest wystarczające - ale pozory mogą być złudne, jak wtedy, gdy mówimy naszym dzieciom, że „nie wszystko złoto, co się świeci”.


„W ułud i marzeń kwiat stroi się życie, Czas jednak ściera zeń świetne kolory, W życiowej walce nieszczęście zwycięża Złudy zrzucają skórę na kształt węża”.
(Przekład Edwarda Porębowicza. Warszawa 1955.)
Lord Byron „Don Juan”, 1824 (wyd. pol. „Don Juan”)

Centralnym problemem rozwoju poznawczego jest zagadnienie, w jaki sposób dzieciom udaje się nauczyć |reguł, które rządzą abstrakcyjnymi zależnościami w ich świecie, oraz właściwego posługiwania się tymi regułami. Do reguł tych należą zasady niezbędne do logicznego zrozumienia świata. Według Piageta (1970), wiedzę tę dzieci uzyskują dopiero wtedy, gdy uwolnią się od dominującego wpływu, jaki wywiera na nie percepcyjna bezpośredniość rzeczywistości zewnętrznej. Właśnie w procesie odkrywania, stosowania i sprawdzania reguł, stanowiących podstawę relacji logicznych i matematycznych, dzieci uczą się, jakie właściwości ich świata są stałe i niezmienne, a w dodatku poznają relacje, jakie zachodzą między nimi a światem oraz między nimi a innymi ludźmi, którzy także go zamieszkują.

Podstawowe idee Piageta. Jeśli spróbujemy podsumować charakterystyczne aspekty podejścia poznawczego Piageta, to za najważniejsze należałoby uznać następujące idee:
1. Badanie procesów poznawczych wymaga analizy |rozwoju zachowania w czasie; w tym celu niezbędne jest intensywne badanie pozwalające ustalić, jak to samo dziecko myśli i rozumuje w kolejnych stadiach rozwoju intelektualnego.
2. Między procesami poznawczymi dziecka i dorosłego występuje pewien |brak |ciągłości. Przyjmuje się, że dzieci przedstawiają sobie świat, rozumieją go i reagują nań inaczej niż dorośli - w sposób jakościowo odmienny. Procesy te trzeba badać dla nich samych, a nie jako niższe czy gorsze wersje zachowania dojrzałego.
3. Ten brak ciągłości między dziecięcym a dojrzałym modelem myślenia występuje dlatego, że istnieją odrębne stadia rozwoju intelektualnego, występujące w różnych okresach życia każdej jednostki. Chociaż nie można precyzyjnie określić granic między tymi stadiami, to jednak każde stadium reprezentuje zmiany o charakterze raczej nagłym, skokowym niż ciągłym czy stopniowym. Szczytowe osiągnięcia realizowane w każdym stadium różnią się od siebie |jakością, a nie tylko wyższym poziomem trudności. Struktury i zdolności ukształtowane w danym stadium zostają włączone w stadium następne - którego nie można by bez nich osiągnąć.
4. Istnieją cztery główne stadia rozwoju poznawczego (opiszemy je później), które u różnych dzieci występują w różnym wieku. Jednakże te cztery stadia następują po sobie w tej samej kolejności u wszystkich dzieci we wszystkich kulturach; to znaczy stadium trzecie następuje dopiero po osiągnięciu pierwszego i drugiego stadium, a przedtem, zanim możliwe będzie osiągnięcie czwartego stadium.

* * *
Ryc. 5.2. Jean Piaget, szwajcarski psycholog, którego prace stanowią podstawę naszej wiedzy o rozwoju poznawczym dzieci.
* * *
|Tempo, w jakim dziecko przechodzi tę ustaloną sekwencję, zależy natomiast od indywidualnych czynników biologicznych i motywacyjnych, jak również od doświadczeń z zakresu uczenia się.
5. Rozumienie, wnioskowanie, abstrahowanie, stosowanie reguł logicznych oraz zdolność rozwiązywania problemów rozwijają się wyłącznie pod wpływem przypadków niezadowalającej |interakcji dziecka ze środowiskiem (|stany |niepełnej |równowagi). Wiedza jest ustrukturalizowana, podobnie jak zachowanie, a struktury intelektualne zmieniają się tylko wtedy, gdy spostrzegana jest |rozbieżność między nimi (czy ich poziomem złożoności) a złożonością środowiska. Z tych „starć” między dzieckiem a problemami stawianymi przez środowisko |fizyczne wyłania się niezmienna sekwencja poznawczych stadiów rozwojowych.
6. Ogólny proces rozwoju jest a) funkcją pobudzenia intelektualnego będącego wynikiem konfrontacji istniejących struktur poznawczych dziecka z nową, prowokującą informacją ze środowiska oraz b) nieustannym procesem wewnętrznego, samorzutnego reorganizowania i integrowania treści i struktur intelektu ludzkiego.
7. Głównymi wyznacznikami kształtującymi rozwój intelektualny są pewne |niezmienniki |funkcjonalne („functional invariants”), które pozwalają dziecku przystosować się skutecznie do jego środowiska. Piaget sugeruje tu pewne podobieństwo między funkcjonowaniem intelektualnym a funkcjonowaniem biologicznym. Dziecko rozpoczyna życie dysponując wrodzonymi biologicznie sposobami interakcji ze środowiskiem, określanymi jako |funkcje. Funkcje te umożliwiają dziecku wykonywanie czynności niezbędnych dla utrzymania się przy życiu, takich jak na przykład pobieranie pokarmu.
W miarę upływu czasu czynności te zostają zorganizowane w |struktury, które przekształcają się, przystosowując się do zmieniających się wymagań środowiska. Dziecko rozwija więc struktury poznawcze, które wiążą środki (takie, jak patrzenie, sięganie, manipulowanie) z celami (takimi, jak otrzymywanie określonych rodzajów bodźców). Dwoma najważniejszymi niezmiennikami funkcjonalnymi są asymilacja i akomodacja. |Asymilacja jest procesem, dzięki któremu nowe elementy percepcyjne czy poznawcze są modyfikowane tak, by stały się bardziej podobne do znanych już z doświadczenia elementów. W ten sposób nowość jest włączona w istniejące struktury poznawcze. Jednakże nie zawsze należy przekształcać nowe w stare, ponieważ niekiedy nowe jest bardziej wartościowe i musi zmienić to, co stare. |Akomodacja jest procesem, dzięki któremu wytworzone uprzednio struktury poznawcze zostają zmodyfikowane na podstawie nowych doświadczeń.  Struktury poznawcze ukształtowane w wyniku akomodacji noszą nazwę |schematów. Schematy są to charakterystyczne wzorce specyficznych związków między środkami a celami. Rozwój poznawczy, według Piageta, polega na kolejnych zmianach w tych strukturach. To właśnie te schematy, poprzez swój regulujący czy sterujący wpływ, decydują o tym, co dziecko potrafi zrozumieć i zrobić w danym czasie.

Cztery stadia rozwoju poznawczego. Na podstawie obserwacji swych małych dzieci Piaget wyodrębnił cztery kolejne stadia rozwoju poznawczego: sensomotoryczne, myślenia przedoperacyjne, operacji konkretnych i operacji formalnych.

Stadium 1: „Okres sensomotoryczny” (0 - 2 lata). Najpierw pojawiają się proste, automatyczne odruchy i reakcje. Mają one ograniczony czas trwania i wydaje się, że ich konsekwencje nie mają na nie wpływu. W miarę jak niemowlę staje się starsze, reakcje te zostają zorganizowane i skonsolidowane we wzorce, które wyraźniej oddziałują na otoczenie - są one powtarzane, ponieważ mają konsekwencje, które są dostrzegalne i przypuszczalnie pożądane (to zaś, jak wiemy, stanowi podstawę warunkowania sprawczego). Piaget podaje na przykład, że jego córeczka Lucienne mając trzy miesiące trzęsła raz po raz swym łóżeczkiem, najwidoczniej dlatego, że ruch ten powodował chwianie się wiszących lalek. Pomiędzy 12 a 18 miesiącem życia wyłączne powtarzanie wzorców reakcji przekształca się w ich |zmienianie. Bierne, skoncentrowane na sobie niemowlę staje się aktywnym poszukiwaczem wiedzy, badaczem-odkrywcą. W tym okresie wytwarzanych jest wiele nowych schematów, przy czym koordynowane są schematy dla różnych zmysłów, stanowiące reakcje na różne nowe sytuacje.
W tym pierwszym stadium rozwoju poznawczego najważniejszymi i najgłębszymi zmianami są te, które łącznie generują poczucie własnej tożsamości, skuteczności działań i przyczynowości zjawisk.
Oddzielanie pojęcia własnego ja od obiektów zewnętrznych wymaga wytworzenia pojęcia rzeczywistości zewnętrznej, składającej się z istniejących w przestrzeni przedmiotów - innych niż ja. Początkowo dziecko uważa przedmioty za stałe części pola percepcyjnego, w którym po raz pierwszy zostały spostrzeżone. Oddzielenie figury od tła jest ważną strukturą poznawczą, która stanowi podstawę ukształtowania poczucia własnego ja (jako czegoś odrębnego od wszystkiego, co mną nie jest). Córka Piageta, Jacqueline, mając dziesięć miesięcy obserwowała, jak ojciec dwukrotnie ukrywał pajacyka po jej lewej stronie i z łatwością odnajdywała go. Jednakże po zaobserwowaniu, jak schował go po jej prawej stronie, próbowała znaleźć go znowu w starym miejscu po lewej stronie. Później nauczyła się rozróżniać także kontekstowe odmiany.
Dzieci poznają swoje możliwości, uczą się, jak wpływać na ludzi i przedmioty, jak ich zamiary i potrzeby realizują się dzięki ich reakcjom powodującym określone konsekwencje. To niejasne poczucie |skuteczności swych działań (osobistej kompetencji, zdolności, własnej wartości) jest może najważniejszym rodzajem wiedzy, jaki kiedykolwiek uzyskujemy. To właśnie dzięki niemu, mimo wielu niepowodzeń, frustracji i rozczarowań, możemy nadal funkcjonować i od nowa podejmować działanie.
Wielkie znaczenie w tym pierwszym stadium poznawczym ma początek myślenia przyczynowego. Dla utrzymania się przy życiu niezbędne jest nauczenie się, że zdarzenia są związane ze sobą tak, iż jedne z nich wpływają na występowanie bądź niewystępowanie innych. Dzieci muszą nauczyć się wnioskować o prawdopodobnych przyczynach na podstawie obserwowanych skutków i przewidywać skutki, gdy znają przypuszczalne przyczyny. Wymaga to przyjęcia założenia |przyczynowości |fizycznej, zdarzenia poprzedzające mogą być przyczynami innych zdarzeń tylko wtedy, jeśli istnieje między nimi jakiś bezpośredni związek. Idea ta musi zająć miejsce bardziej „prymitywnego” przekonania, zwanego |fenomenalizmem, zgodnie z którym następujące po sobie zdarzenia mogą być związane przyczynowo nawet wtedy, jeśli zachodzą w różnych miejscach, bez żadnego bezpośredniego kontaktu.  Dzieci muszą nauczyć się, że istnieje psychologiczny związek przyczynowy między ich zamiarami a działaniami - muszą jednak odrzucić przekonanie, że ich pragnienia spowodują wystąpienie zdarzeń zewnętrznych, bez konieczności działań z ich strony.


Zbliżenie
Pociąg wjeżdża, pociąg wyjeżdża


„Jeśli niemowlę obserwuje poruszający się przedmiot, który znika na krótko z pola widzenia, a następnie pojawia się stale w innym miejscu, to czy będzie ono śledzić wzrokiem przedłużenie obserwowanego toru ruchu przedmiotu? Keith Nelson (1970) szukał odpowiedzi na to pytanie w badaniach, które miały pokazać, jak niemowlęta uzupełniają swój wrodzony repertuar percepyjny nową wiedzą - umożliwiającą uchwycenie i zrozumienie nowych aspektów napotykanych zjawisk.
Nelson zaczął od zarejestrowania ruchów oczu 80 niemowląt (w wieku od 99 do 264 dni), które obserwowały zabawkę - pociąg elektryczny jeżdżący w kółko po torze. Gdy tylko niemolwęta zauważyły pociąg, wówczas natychmiast zaprzestawały wszelkich dotychczasowych, przypadkowych czynności. Zastygłe w bezruchu obserwowały z przejęciem poruszający się pociąg. W pierwszej próbie 73 badanych niemowląt nieustannie śledziło pociąg, dopóki nie zniknął w tunelu, wtedy nadal wpatrywały się we wlot tunelu („jak koty w wejście mysiej nory”) i zwykle zdawały się nie widzieć, że z drugiej strony jest wylot.

Jednakże w każdej z następnych trzech prób niemowlęta coraz częściej patrzyły ku wylotowi tunelu i coraz wcześniej spostrzegały wyjeżdżający z niego pociąg - widzimy siedmiomiesięczne niemowlę, które oczekuje z przejęciem wyłonienia się pociągu z tunelu.

W tej złożonej, nowej sytuacji niemowlęta w ciągu zaledwie paru prób nauczyły się śledzenia wzrokiem i przewidywania, przy czym niemowlęta siedmiomiesięczne uczyły się szybciej niż pięciomiesięczne.”

Stadium 2. „Myślenie przedoperacyjne” (2 - 7 lat). Głównym osiągnięciem w tym okresie jest rozwój zdolności |wewnętrznego przedstawiania świata zewnętrznego za pomocą symboli, które zaczynają reprezentować przedmioty.  Ta funkcja symbolizacyjna umożliwia dziecku przedstawianie sobie nie tylko zdarzeń zachodzących w otoczeniu obecnie, lecz także zdarzeń przeszłych i przyszłych. Użycie symboli pomaga dziecku uwolnić się od sztywnych ram operacji konkretnych, ograniczonych do „tu i teraz”, ułatwia mu manipulowanie oraz rozwijanie najbardziej różnorodnych strategii prowadzących do osiągnięcia tego samego celu.
Na rozwój poznawczy dziecka w stadium przedoperacyjnym oddziałują dwa ograniczenia, a mianowicie:
1. |Rozumowanie |transdukcyjne: ten typ rozumowania polega na tym, że dziecko „rozumie przez podobieństwo” - porównując poszczególne przypadki, podobne pod pewnym względem, dochodzi do wniosku, że są one podobne pod wszelkimi względami. Myślenie transdukcyjne przebiega |od |szczegółu |do |szczegółu, w odróżnieniu od myślenia |dedukcyjnego, kiedy to z ogólnych twierdzeń wynikają w konieczny sposób szczegółowe wnioski, jak też myślenia |indukcyjnego - gdy od obserwacji poszczególnych, pojedynczych przypadków przechodzi się do uogólnień.
3. |Egocentryzm: niemożność wyobrażenia sobie świata z perspektywy innej niż własna oraz niezdolność do uświadomienia sobie, że własna perspektywa jest tylko jedną z wielu możliwych, nosi nazwę |egocentryzmu. Brak ten prowadzi do wielu nieporozumień w komunikowaniu się i w znacznym stopniu ogranicza zakres wiedzy, jaką może uzyskać dziecko.
Pomysłowe badania, przeprowadzone niedawno przez Johna Flavella i jego studentów (1974) z Univeristy of Minnesota, pokazują w jaki sposób egocentryzm wpływa na wnioski dziecka dotyczące tego, co postrzegają inni ludzie.
W zadaniu, jakie dawano dzieciom, posłużono się białym nieprzezroczystym kartonem o wymiarach około 20 cmx25 cm, na jednej stronie tego kartonu znajdował się obrazek przedstawiający psa, a na drugiej - kota. Gdy dziecko obejrzało już karton z obu stron, eksperymentator ustawiał go pionowo między sobą a dzieckiem i zadawał dziecku dwa pytania: „Co ty widzisz?” i „Co ja widzę?”. Wszystkie trzylatki potrafiły przyjąć czyjś punkt widzenia, wywnioskować, na co patrzy druga osoba - na coś innego niż to, co one widzą. Jednakże tylko mniej więcej połowa dwulatków potrafiła przełamać swoje egocentryczne nastawienie, które powodowało wytworzenie się u nich przekonania, że inni muszą widzieć to samo, co i one. Jest to tak, jak gdyby egocentryczne dziecko modyfikowało słynne stwierdzenie Descartesa na: 
„Widzę i myślę, więc |ty widzisz i jesteś”.
Rozwój zdolności nieegocentrycznego wnioskowania wyraźnie wykazano w innych badaniach (Strayer, Bigelow i Ames, 1973), w których małym dzieciom w pięciu grupach wieku dawano podobne zadanie obrazkowe. Im starsze były dzieci, tym więcej wyprowadzały poprawnych wniosków (w 8 próbach):

Wiek - Poprawne wnioski:
19 miesięcy - 0
22 miesiące - 0
25 miesięcy - 1
28 miesięcy - 2
31 miesięcy - 6

Badania te potwierdzają piagetowską koncepcję egocentryzmu, lecz wykazują, że zdolność wyprowadzenia poprawnych wniosków, co do spostrzeżeń wzrokowych innych ludzi, rozwija się wcześniej niż to postulował Piaget (Flavel, 1973).

Stadium 3: „Operacje konkretne” (7 - 11 lat). W tym stadium dziecko rozwija system poznawczy dla organizowania zdarzeń zachodzących w świecie zewnętrznym za pomocą struktur logiczno-matematycznych. Dziecko znajdujące się w trzeci stadium opanowuje działania arytmetyczne, mierzenie, klasy logiczne, relacje między klasami i zbiorami oraz pojęcia przestrzenne.  Ponadto przyswaja ono |zasadę zachowania ilości („conservation” (Termin „conservation” w znaczeniu ogólnym odnosi się do tworzenia niezmienników umożliwiających operacje intelektualne na pojedynczych wymiarach przedmiotów i zdarzeń (przyp. red. nauk.) - oznacza ona wiedzę, że ilość substancji pozostaje nie zmieniona (zachowana), nawet jeśli jej wygląd ulegnie zmianie, na przykład po umieszczeniu w naczyniu innej wielkości lub innego kształtu albo wskutek połączenia jej części, lub przeciwnie, podzielenie całości na części. Aby rozwiązywać problemy z zakresu zachowania ilości, stawiane przez Piageta (i przez środowisko naturalne), dziecko musi nauczyć się reagować na dwa lub więcej wymiarów bodźca równocześnie.
Rozpatrzmy jedno z badań Piageta: do dwóch identycznych szklanek nalewa się równe ilości lemoniady. Kto ma więcej, dziecko czy eksperymentator?  Szwajcarskie pięcio- sześcio- i siedmiolatki mówią bez wyjątku, że oboje mają tyle samo. Teraz jednak lemoniadę z jednej szklanki przelewa się do szklanki węższej i wyższej i podaje się ją dziecku. Kto teraz ma więcej?  Pięciolatki są przekonane, że mają więcej w swych wysokich szklankach; sześciolatki są tego mniej pewne, lecz także mówią, że mają więcej; siedmiolatki „wiedzą”, że nie ma żadnej różnicy. Gdy lemoniada zostanie z powrotem przelana do identycznych szklanek, wówczas pięciolatki mówią, że więcej jest w tej szklance, do której przelano napój z wyższego naczynia, natomiast sześciolatki wiedzą, że lemoniada znów jest rozdzielona równo.  Dla pięciolatka wyrazisty sygnał w postaci wysokości jest zwykle wiarygodnym sygnałem w odniesieniu do wymiaru „więcej niż”. Gdy jednak wymiarem jest objętość, a wysokość i szerokość zmieniają się równocześnie, wówczas sygnały co do wysokości są mylące. „Przeciętny” sześciolatek zdaje sobie sprawę, że ważne jest również coś poza wysokością, lecz nie potrafi jeszcze zintegrować pojęciowo dwóch wymiarów naraz. Siedmiolatek zrozumiał już, że pojęcie ilości zależy zarówno od wysokości, jak i szerokości. Jeśli zmiany w jednym wymiarze są skompensowane przez odpowiednie zmiany w drugim wymiarze, wówczas poddana tym zmianom rzeczywistość („reality”) zostaje |zachowana (tzn. dana rzeczywistość pozostaje niezmieniona, mimo, że jej wygląd się zmienia).
Dzieciom trudno jest zrezygnować ze swego zaufania do bodźców percepcyjnych i nauczyć się analizować na poziomie symbolicznym operacje przerowadzane na tych bodźcach.


Według Jerome Brunera (1973) z Harvard University wynika to po części stąd, że percepcyjne reprezentacje bodźców są magazynowane w postaci jednostek |ikonicznych (tzn. „obrazowych”). Istnieje konflikt, czyli interferencja, między symbolicznymi operacjami a symbolicznymi reprezentacjami bodźców fizycznych. Bruner wywnioskował, że więcej dzieci potrafiłoby rozwiązać problemy związane z zachowaniem objętości, gdyby szklanki były zasłonięte, a dziecko mogło oglądać operacje przelewania.  Gdyby w ten sposób zaaranżował sytuację, wówczas liczba poprawnych odpowiedzi (tzn. wskazujących na zachowanie ilości) skoczyła u czterolatków z 0 do 50%, u pięciolatków z 20% do 90%, a u sześciolatków z 50% do 100%.  Gdy dzieci dokonały już oceny na podstawie samych tych operacji, wówczas przesłonę usunięto i dzieci otrzymały dane percepcyjne. Jak, twoim zdaniem, dzieci zareagowały na to dodatkowe źródło informacji?
Wszystkie czterolatki, które poprzednio odpowiedziały poprawnie, zmieniły zdanie. Dane percepcyjne miały na nie przemożny wpływ - dzieci zdecydowały, że w szerszej szklance jest mniej wody. Natomiast prawie wszystkie pięciolatki pozostały przy swej ocenie, często powołując się na różnicę między pozornym wyglądem a rzeczywistością - „To wygląda, jakby tu było więcej do picia, a jest tyle samo”, bo to jest ta sama woda i tylko była przelana stamtąd tutaj” (typowa wypowiedź pięciolatka). Wszystkie sześcio- i siedmiolatki pozostały przy swej ocenie (Bruner, 1973, s. 336).

Stadium 4: „Operacje formalne” (11 lat i więcej). W trzecim stadium rozumowanie i wnioskowanie są jeszcze uzależnione od danych wzrokowych, konkretnych przedmiotów i istnienia pola percepcyjnego. W czwartym, ostatnim stadium rozwoju poznawczego rozumowania może opierać się wyłącznie na opisach słownych: dziecko potrafi odróżnić formę twierdzenia od jego treści oraz kształtuje hipotetyczne czy wyobrażone konsekwencje i związki między środkami i celami, które współistnieją z rzeczywistymi konsekwencjami i związkami. Zrozumienie przez dziecko świata fizycznego i królestwa logiki pozwala mu teraz operować pojęciami negacji, odwrotności i innymi przekształceniami.

Amerykańska krytyka szwajcarskiego scenariusza. Do niedawna piagetowski sposób podejścia do rozwoju poznawczego nie znajdował uznania wśród amerykańskich psychologów, którzy nie doceniali także jego wpływu. Takie krytyczne stanowisko (zob. Manis, 1971) wynikało z szeregu przyczyn: a) strukturalizm Piageta był trudny do pogodzenia z amerykańskim funkcjonalizmem; b) behawiorystom trudno było przyjąć teorię, w której jednostka reakcji - schemat - jest tak ogólna i niesprecyzowana, a bodziec i reakcja wchodzą ze sobą w interakcje i nie dają się od siebie oddzielić; c) eksperymentalne sytuacje zadaniowe stosowane przez Piageta były swobodne, nieustrukturalizowane i słabo kontrolowane, przez co trudno było wykluczyć wpływ Piageta-teoretyka na Piageta-zbieracza danych. Obserwacje Piageta były przeprowadzane przeważnie na jego własnych trojgu dzieciach.  Jak dalece na podstawie tej ograniczonej próbki możemy wyciągać wnioski dotyczące ogólnej teorii rozwoju, zwłaszcza gdy weźmiemy pod uwagę fakt, że badani ci mieli bardzo inteligentnego ojca i wychowywali się raczej w niezwykłym środowisku domowym? d) Piaget zbytnio polegał na podawanych przez dziecko słownych opisach wewnętrznych procesów myślowych. Związek między tymi opisami i procesami nie nie jest doskonały: dziecko może coś zrozumieć, nie umiejąc jednocześnie tego wyjaśnić. Potrzebne są więc procedury sprawdzające, oparte na technikach niewerbalnych; e) Piaget zdaje się sądzić, że procesy poznawcze rozwijają się najlepiej bez formalnego kształcenia i bez stosowania podniet (zob. Kessen, 1964). W jednym z nielicznych publicznych wykładów, jakie miał na kontynencie amerykańskim, zaszokował pedagogów stwierdzeniem: „Za każdym razem, gdy uczycie dziecko czegoś, uniemożliwiacie mu odkrycie tego od nowa”.
Według Piageta, wysiłki amerykańskich pedagogów zmierzające do przyspieszenia tempa rozwoju poznawczego są jałowymi wprawkami technicznymi, uważa on, iż należy pozwolić, aby „naturalny” rozwój przebiegał we własnym tempie. Sądzi on, że częścią idealnej sytuacji uczenia się powinny być zaprogramowane, rosnąco stopniowo trudności oraz wymagania ze strony środowiska zbliżone do granic wyznaczonych przez aktualne stadium rozwojowe dziecka.
Pomimo tych i innych zarzutów prace Piageta stanowią kamień milowy w psychologii. Nie tylko wzbogaciły one naszą wiedzę o rozwoju procesów poznawczych u niemowląt i dzieci, lecz także dostarczyły szerszych informacji o tym, w jaki sposób dochodzimy do zrozumienia otaczającego świata i rzeczywistości wewnętrznej, jak odnosimy się do nich i jak w końcu zaczynamy panować nad nimi.


Wpływ kultury na rozwój poznawczy


W badaniach Piageta nad rozwojem poznawczym wiek dzieci jest jedyną uwzględnianą zmienną niezależną (tzn. bada on, jak dobrze wykonują pewne zadanie dzieci w różnym wieku). Jest to zrozumiałe, gdy weźmiemy pod uwagę nacisk, jaki kładzie on na dojrzewanie biologiczne. Jednakże przy takim podejściu nie można zbadać, jaką rolę w rozwoju myślenia i rozumowania, a zatem w pojawieniu się inteligencji, odgrywają wpływy środowiskowe.
W jakim stopniu na inteligencję wpływa technika, system wartości czy struktura językowa danej kultury? Pytanie to stawiają ci badacze, którzy są przekonani, że „inteligencja jest w dużej mierze internalizacją narzędzi dostarczonych przez daną kulturę” (Greenfield i Bruner, 1973).


Zbliżenie
Doniosłe znaczenie psychologicznych badań międzykulturowych


„Aczkolwiek głosi się, że psychologia ma umożliwić zrozumienie ludzkiego zachowania, to jednak warto zwrócić uwagę, jak bardzo ograniczony jest zakres badanych zachowań i krąg badanych ludzi. Zaznacza się „leniwa zaściankowość”, skłaniająca badaczy do studiowania tego, co jest pod ręką: członków ich własnego społeczeństwa, łatwo przy tym dostępnych. Badane populacje to zazwyczaj grupy „wzięte do niewoli”, które zebrały się w danym miejscu dla jakiegoś celu i które można nakłonić, by zostały |osobami |badanymi, takie jak studenci szkół wyższych i dzieci przedszkolne, pacjenci szpitali psychiatrycznych, wojskowi, robotnicy fabryczni, więźniowie itd. Ograniczając nasze badania do takich populacji poważnie redukujemy ogólność wniosków, jakie można wyciągnąć, oraz zmniejszamy zakres teorii, na których mogą być oparte takie badania.
Badania międzykulturowe są niezbędne, by uchronić się przed tendencyjnym, wąskim określeniem wyznaczników ludzkiego zachowania. W badaniach takich analizuje się zachowanie jednostek żyjących w kulturach o różnych tradycjach, w których jednostki te stykają się z warunkami środowiskowymi innymi niż nasze. Dobrą definicję |psychologii |międzykulturowej znajdujemy w pracy Brislina Lonnera i Thorndike’a (1973), zawierającej doskonałe podsumowanie metod oraz dotychczasowych osiągnięć tego sposobu podejścia:


„Psychologia międzykulturowa polega na empirycznym badaniu członków różnych grup kulturowych, którzy mieli różne doświadczenia prowadzące do przewidywalnych i istotnych różnic w zachowaniu. W większości takich badań grupy badane mówią różnymi językami i podlegają władzy różnych struktur państwowych” (s. 5).

Badania międzykulturowe są wartościowe, gdyż umożliwiają zweryfikowanie twierdzeń o „uniwersalnej” czy wrodzonej naturze pewnej cechy, pewnego zachowania czy procesu psychologicznego, zapewniają zmienność czynników eksperymentalnych nieosiągalną w żadnej kulturze, uwypuklają wzorce zachowania, które nie istnieją we własnym kraju badacza i wreszcie pozwalają badać, jak członkowie różnych grup kulturowych określają swoje własne subiektywne doświadczenia kulturowe. Istnienie międzykulturowych kartotek w kilku większych uniwersytetach Stanów Zjednoczonych umożliwia badaczom sprawdzanie hipotez za pomocą wielkich zasobów danych - zawczasu zebranych i skatalogowanych przez antropologów, psychologów i reprezentantów innych nauk, którzy gromadzili raporty o badanych przez siebie kulturach. Przykładowe zastosowanie tej metodologii zaprezentujemy w Rozdziale 14, w którym pokazano, jak poziom agresywności w czasie bitwy zależy od tego, czy wojownicy - w różnych kulturach - zapewniają sobie anonimowość przed bitwą, czy też nie (Watson, 1973).
Przekonywującym przykładem tego, jak badania międzykulturowe mogą wzbogacić wiedzę psychologiczną, jest klasyczne studium Margaret Mead „Coming of Age in Samoa” („Dorastanie na Samoa”; 1938); autorka wykazała w nim, że fizyczne i psychiczne zaburzenia, jakie u młodzieży amerykańskiej powszechnie wiązano z dojrzewaniem płciowym, nie występują u młodzieży samoańskiej dzięki temu, że na Samoa postawy kulturowe wobec seksu mają charakter mniej represyjny.
W innych badaniach sprawdzono, jak dzieci meksykańskie z rodzin garncarzy wykonują piagetowskie zadania z zakresu niezmienności masy w porównaniu z dziećmi z rodzin niegarncarskich. Wczesne doświadczenia dzieci garncarzy, które pomagały rodzicom ugniatać i formować glinę, doprowadziły je do przyswojenia sobie zasady niezmienności masy w młodszym wieku, niż zdarzało się to u innych dzieci meksykańskich, czy też u dzieci wychowywanych w kulturach industrialnych (Price-Williams, Gordon i Ramirez, 1969).  Wykazano zatem, iż doświadczenie kulturowe modyfikuje proces, który teoretycznie jest zdeterminowany wyłącznie przez dojrzewanie”.

Chociaż amerykańscy pedagodzy na ogół nie chcą się dowiedzieć, czy piagetowskie stadia można przyspieszyć przez zastosowanie specjalnych technik, to jednak mogą oni przeoczyć o wiele bardziej fundamentalne zagadnienia - w jaki sposób na strukturę i treści rozwoju poznawczego wpływają takie zmienne, jak wykształcenie, upośledzenie danej grupy społecznej, ekonomiczna obfitość lub niedostatek oraz to, czy jednostki należące do danej kultury zachęca się, by rozwijały świadomie swego ja, indywidualistyczne nastawienie, czy też jedynie tożsamość kolektywną, w której własne ja jest stosunkowo mało ważne (jak w Związku Radzieckim lub Chinach Ludowych).
Gdy dzieciom w Senegalu (plemię Wolof) dano piagetowskie zadania dotyczące zachowania ilości, to ich osiągnięcia w wykonaniu tych zadań, jak również sposób wyjaśnienia tego, co obserwowały, zależały nie tylko od ich wieku, lecz także od tego, czy chodziły one do szkoły i czy wychowywały się w mieście. Wiejskie dzieci nie uczęszczające do szkoły (w wieku od 6 do 11 lat) porównywano z innymi dziećmi z buszu, które chodziły do szkoły, a także z miejskimi dziećmi szkolnymi (Greenfield, 1966).
Miejskie dzieci uczęszczające do szkoły nie tylko lepiej wykonywały zadanie, lecz także wykazywały większe jego zrozumienie. Gdy dzieci nie uczęszczające do szkoły poproszono o podanie, dlaczego druga szklanka po przelaniu wody zawiera więcej, tyle samo lub mniej płynu - milczały. Nie potrafiły one odpowiedzieć na pytanie sformułowane następująco: „Dlaczego mówisz (lub myślisz), że jest tak a tak?” Potrafiły jednak odpowiedzieć na to pytanie, gdy przeformułowano je w ten oto sposób: „Dlaczego jest tak a tak?” Możliwe było dla nich wyjaśnienie zjawiska zewnętrznego, lecz nie |twierdzenia o zjawisku zewnętrznym. Dalsza analiza sposobu, w jaki dzieci te tworzyły pojęcia i rozwiązywały zadania, ujawniła iż nie odróżniają one swych własnych reakcji psychicznych od zjawisk zewnętrznych; jest im więc trudno kategoryzować te same bodźce według kilku różnych kryteriów czy alternatywnych punktów widzenia.
Efektem nauki szkolnej, na który kładzie się szczególny nacisk w kulturach typu miejskiego i w społeczeństwach zachodnich jest ukształtowanie orientacji |indywidualistycznej. Przy takiej orientacji przywiązuje się dużą wagę do inicjatywy, celów i pragnień jednostki, jako niezbędnych warunków działania i zmian - kładzie się także przesadny nacisk na poczucie osobistej ważności i odpowiedzialności jednostki oraz na jej świadomość własnego ja. Kultury, które rozwijają samoświadomość jednostek, rozwijają także ich poczucie władzy nad światem fizycznym oraz poczucie odrębności swego ja od środowiska zewnętrznego. Natomiast kultury, w których występuje niedobór środków, gdzie gospodarka ma na celu jedynie utrzymanie się przy życiu i gdzie technika nie panuje nad przyrodą lub gdzie ważną jednostką funkcjonalną nie jest pojedynczy człowiek, lecz grupa czy plemię, rozwijają sposoby myślenia, które można nazwać |kolektywnymi.  Przy orientacji kolektywnej pragnienia jednostki są podporządkowane potrzebom i wymaganiom grupy. W ten sposób jednostka przez kolektywne działanie przezwycięża poczucie bezradności i przyjmuje taki pogląd na świat, w którym podstawy, działania i zdarzenia fizyczne |nie są kategoryzowane oddzielnie.
Dzieci eskimoskie w Anchorage na Alasce są ćwiczone w tłumieniu postaw indywidualistycznych, ponieważ utrzymanie się tej społeczności przy życiu wymaga grupowego działania w najważniejszych dla niej formach działalności, takich jak polowanie czy rybołóstwo. Dzieci te nie przechodzą przez stadium |egocentryzmu, które Piaget zaobserwował u dzieci europejskich, ponieważ egocentryzm jest sprzeczny z wartościami dominującymi w ich kulturze (Reich, cytowany przez Brunera, Olvera, Greenfield i in., 1966).
Wpływ nauki szkolnej na rozwój poznawczych polega również na wytwarzaniu struktur poznawczych, które powodują, iż „myślenie magiczne” staje się mało prawdopodobne. Dzieci, które nie chodziły do szkoły, były skłonne wyjaśniać różnicę między pozornie niejednakowymi ilościami wody w szklankach odmiennego kształtu, przypisując dorosłemu eksperymentatorowi magiczne zdolności: „Teraz nie jest w nich tyle samo, bo |ty przelewałeś tę wodę”.  Myślenie magiczne tego rodzaju nie występuje w innych grupach dzieci senegalskich, które uczęszczały do szkoły choćby przez pół roku.
Jednym ze sposobów skłonienia dzieci, by przestały przypisywać eksperymentatorowi zdolności magiczne, jest polecenie im, aby same dokonały operacji przelewania. W takim wypadku dzieci częściej odpowiadają zgodnie z zasadą zachowania ilości, natomiast liczba wyjaśnień „magicznych” spada.  Gdy dziecko samo przelewa płyn, wówczas podstawą wyjaśnienia staje się to, że „Na początku ilości te były równe i muszą być równe nadal, ponieważ |nie |zrobiłem nic, żeby je zmienić”.
W kulturze zamieszkującego Nigerię plemienia Tiv dzieci zachęca się, aby wobec fizycznego świata stosowały aktywną manipulację; gdy więc otrzymały do rozwiązania zadanie związane z zachowaniem ilości, wówczas same |spontanicznie wykonywały operacje przelewania i odwracały kolejność tych operacji, wykazując, że nic się nie zmieniło - uzyskiwały w ten sposób wysokie oceny (Price-Williams, 1961).




Podstawowe wyznaczniki rozwoju poznawczego


Większość naszych rozważań nad rozwojem poznawczym można by ująć z innego punktu widzenia, zadając pytanie „W jaki sposób mózg staje się umysłem?”.  Na czym polega proces, dzięki któremu protoplazma i biochemiczno-elektryczna aktywność w komórkach stają się systemem umożliwiającym spostrzeganie, organizowanie, integrowanie, zapamiętywanie, planowanie i kierowanie działaniem?
Ta „humanizacja materii” intrygowała filozofów przez stulecia, lecz dopiero niedawno podstawowe filozoficzne pytanie „W jaki sposób poznajemy?” zmodyfikowano tak, by nadawało się do analizy psychologicznej. Dla psychologów pytanie to przybrało postać: „Jaki jest względny udział dziedziczności i środowiska w rozwoju inteligencji ludzkiej?”
Filozofowie, tacy jak Immanuel Kant, utrzymywali, że w chwili urodzenia istnieją już w organizmie liczne idee i relacje, które rozwijają się w naturalny sposób, w miarę jak dziecko dojrzewa. Podstawy wiedzy ludzkiej należy więc szukać w ideach wrodzonych (aksjomatach „a priori”) istniejących przed jakimkolwiek doświadczeniem środowiskowym. Gdyby zwolennicy tego stanowiska, zwanego |natywizmem, posługiwali się terminologią XX wieku, to mogliby określić mózg jako skonstruowany zawczasu system, który dziedziczy się jako część wrodzonego wyposażenia i który musi być tylko „dostrojony” przez doświadczenie.

Jako pierwszy przeciwko natywizmowi Thomas Hobbes w XVII wieku, argumentuje, że wrażenia i doświadczenia są źródłem wszelkiej wiedzy i że pamięć oraz wyobraźnia są to zanikające wrażenia zmysłowe, wiązane ze sobą przez kojarzenie. Powinno się więc poszukiwać początków intelektu we wrażeniach i badać jej rozwój dokonujący się na zasadzie kojarzenia.  Stanowisko to, upatrujące podstawę ludzkiej wiedzy w doświadczeniu, zwane jest |empiryzmem; znalazło ono swego orędownika w Johnie Locke’u. Wysunął on tezę, że mózg niemowlęcia podobny jest do czystej tablicy (po łacinie „tabula rasa”), na której doświadczenie pisze wrażeniami zmysłowymi, przekazując w ten sposób sens życia.
Również w psychologii oba te skrajne stanowiska znalazły gorących zwolenników gotowych staczać potyczki intelektualne w obronie natury („nature”) bądź wychowania („nurture”) jako ważniejszego z wyznaczników inteligencji.
Omówimy teraz pokrótce niektóre dowody przytaczane przez obie strony, a następnie zastanowimy się, o co właściwie cała ta wrzawa. Czy zmieniłoby to w jakikolwiek sposób twoje poglądy na ludzki potencjał intelektualny, gdyby się okazało, że jedna bądź druga strona ma słuszność?


Argumenty natywistów


Kto twierdzi, że natura jest podstawowym wyznacznikiem inteligencji? Skąd pochodzą dowody, które skłoniły uczonych do wyciągnięcia wniosku, że nasze genetyczne wyposażenie wyznacza i określa granice rozwoju poznawczego czy intelektualnego? W dawniejszych latach byli to: Galton, Dugdale, Goddard i Terman; obecnie sztandar natywizmu dzierżą: psycholog Arthur Jensen i fizyk William Shockley. Dowody nagromadzone na poparcie ich twierdzenia, że przeważająca część zmienności indywidualnej w zakresie inteligencji jest wynikiem różnic genetycznych, pochodzą z badań, w których porównywano wyniki testów inteligencji uzyskane przez osobników o różnym stopniu podobieństwa genetycznego.
Główne wnioski z tych badań, które omówimy niżej, są następujące: 
inteligencja jest przede wszystkim cechą dziedziczną (czyli „rodzinną”); inteligencja jest dodatnio skorelowana z pożądanymi społecznie zachowaniami: wyższa inteligencja jest dobrym predyktorem osiągnięcia wyższej jakości życia, a niższa inteligencja wiąże się z najrozmaitszymi niepożądanymi cechami społecznymi. Byłoby dobrze, gdybyś przed dokonaniem oceny słuszności tych wniosków przypomniał sobie naszą analizę „pułapek psychologicznych” z Rozdziału 1, aby sprawdzić, czy któryś z podanych tam „morałów” nie znajduje tu zastosowania.

Badania Galtona nad wybitnymi rodzinami. Sir Francis Galton opublikował w 1869 roku monumentalną pracę zatytułowaną „Hereditary-Genius: An Enquiry into Its Laws and Consequences” („Dziedziczenie genialności: badanie jego praw i następstw”). Wykazał w niej, że talent i geniusz pojawiają się często w pewnych rodzinach i wyciągnął stąd wniosek, że są one cechami dziedzicznymi. Dane Galtona, zaczerpnięte z biografii „wielkich ludzi”, ujawniły, że osiągnięcie sławy przez ich dzieci, jak również przez ich rodziców i przodków, było w pewnych rodzinach znacznie bardziej prawdopodobne, niż gdyby to wynikało z przypadku. Po kilkunastu latach Galton stwierdził, że uzyskane przez niego wyniki znalazły potwierdzenie w dalszych badaniach: „W ciągu 14 lat, jakie upłynęły od czasu opublikowania poprzedniej książki, członkowie utalentowanych rodzin, które przedstawiłem jako przykłady roli dziedziczności, uzyskali w wielu wypadkach nowe, wybitne osiągnięcia, wzmacniając w ten sposób moje argumenty” (Galton, 1907, s. 57).
Galton, który był kuzynem Darwina, wziął zupełnie dosłownie podtytuł klasycznego dzieła „O powstawaniu gatunków drogą doboru naturalnego, czyli o utrzymaniu się doskonalszych ras w walce o byt” i stał się założycielem ruchu eugenicznego. (|Eugenika jest nauką, która zajmuje się ulepszaniem gatunku przez kontrolowanie czynników dziedzicznych przy dobieraniu par).  Uczniem Galtona był znany brytyjski statystyk Karl Pearson, który opracował wzór na obliczanie korelacji (współczynnik korelacji Pearsona wg momentu iloczynowego). Pearson wykorzystywał swoje wybitne zdolności matematyczne dla rzekomego „udowodnienia” wrodzonej niższości intelektualnej pewnych grup etnicznych - zwłaszcza Żydów, którzy w tym czasie napływali do Wielkiej Brytanii.

Juke’owie i Kallikakowie; teoria „złej krwi”. Zwolennicy dziedziczności zastosowali podczas poszukiwania argumentów pomysłową taktykę - starając się również z „odwrotnej strony” wykazać słuszność teorii Galtona. Podczas gdy w Anglii dziedziczność ogłoszono czynnikiem przyczynowym genialności wielkich ludzi, to w Ameryce „udowodniono”, że jest ona podłożem wad dwóch osławionych rodów, a mianowicie Juke’ów i Kallikaków.
Wyniki badań Richarda Dugdale’a nad dziedzicznym podłożem „zbrodni, żebractwa, chorób i obłędu”, opublikowane w 1875 roku przyjęto na całym świecie jako najlepiej udokumentowany dowód słuszności teorii „złej krwi”.  W swojej drobiazgowej analizie klanu Juke’ów Dugdale zidentyfikował ponad 700 osób „należących do rodu Juke’ów”, spośród których ponad 500 było degeneratami społecznymi. Były wśród nich osoby „niemoralne”, „ladacznice”, „rozpustnicy”, „nędzarze”, „pijacy”, „próżniaki”, „cudzołożnicy”, jak również mordercy, gwałciciele i złodzieje. Ta linia rodzinna była tak zła i zepsuta, że w ciągu 73 lat swego analizowanego istnienia kosztowała podatników stanu Nowy Jork ponad milion dolarów.
W roku 1912 badacz Henry Goddard, znalazł jeszcze jeden argument na rzecz stanowiska natywistycznego, natrafiwszy na naturalny eksperyment z zakresu prokreacji. Pewien żołnierz wojny o niepodległość Stanów Zjednoczonych, którego Goddard nazwał „Kallikakiem” (z greckiego „kalos”-dobry i „kakos”-zły), założył dwie rodziny: jedną z „nieprawego łoża” a drugą - z „łoża prawego”. Najpierw związał się z dziewczyną z tawerny, podobno upośledzoną umysłowo; później ożenił się  z młodą panną „z dobrego domu”.  Jakie były konsekwencje tych różnych związków? Tylko paru spośród blisko 500 potomków pochodzących z legalnego małżeństwa Martina Kallikaka można by uznać za „nieudanych”. Natomiast syn zrodzony z romansu Martina z dziewczyną z tawerny zapoczątkował długi szereg obarczonych różnymi wadami potomków. Spośród 480 jego zidentyfikowanych potomków, 143 określono jako upośledzonych umysłowo, 33 było niemoralnych pod względem seksualnym, 24 było alkoholikami, wielu zmarło w okresie niemowlęcym, inni zaś byli przestępcami, portierami w domach publicznych itp.
Badania te skłoniły niektórych kryminologów do przyjęcia teorii, że „socjopatia”, podobnie jak obłęd i upośledzenie umysłowe, może być dziedziczna. Ponieważ wydawało się nieuniknione, że zepsuta jednostka przekaże „złą krew” następnym pokoleniom, dostarczyło to potężnego bodźca dla rozwoju ruchu eugenistycznego w Stanach Zjednoczonych. Dwadzieścia siedem stanów uchwaliło ustawy przewidujące przymusową sterylizację, aby zapobiec przekazywaniu takich „nieusuwalnych” defektów.
W wyniku tych słynnych badań wzrósł osobisty prestiż Goddarda i Public Health Service U. S. (Społeczna Służba Zdrowia Stanów Zjednoczonych) zaprosiła go, by badał inteligencję europejskich imigrantów przybywających na Ellis Island. W swym sprawozdaniu z 1913 roku, dotyczącym wyników badania „wielkiej masy przeciętnych imigrantów”, Goddard podał, że stwierdził wśród nich następujące procenty „niedorozwiniętych umysłowo” osobników:
Rosjanie - 87%; Węgrzy - 80%; Żydzi - 83%; Włosi - 79%

W roku 1917 Goddard mógł donieść o znacznym wzroście deportacji imigrantów, u których wykryto niedorozwój umysłowy za pomocą testów zdolności umysłowych.

Terman i zagrożenie ze strony niedorozwiniętych umysłowo. Lewis Terman jest dobrze znany wśród psychologów dzięki swym dwom dokonaniom: wprowadzeniu w 1916 roku w Stanach Zjednoczonych pewnej odmiany testu inteligencji, opracowanego przez francuskiego psychologa Alfreda Bineta (test ten omówimy w Rozdziale 10) oraz badaniom podłużnym nad rozwojem grupy dzieci uznanych za geniuszy na podstawie tego testu, zwanego „stanfordzką wersją testu Bineta” (Terman był wówczas profesorem na uniwersytecie w Stanford). Mniej znany jest fakt, iż Terman był przekonany, że niedorozwój umysłowy (wykrywany za pomocą testów inteligencji) stanowi poważne zagrożenie dla społeczeństwa. W roku 1917 pisał: 
„(...) dopiero ostatnio zaczęliśmy sobie zdawać sprawę, jak poważne jest to zagrożenie dla społecznej, ekonomicznej i moralnej pomyślności państwa (...). Jeśli mamy zachować nasze państwo dla klasy ludzi, która jest go godna, to musimy zapobiegać, w miarę możliwości, rozmnażaniu się degeneratów umysłowych” (ss. 161, 165). Po stwierdzeniu zaś niskich ilorazów inteligencji u |dwojga przebadanych dzieci - meksykańskiego i indiańskiego - Terman uogólniał:

„Ich tępota zdaje się być związana z ich rasą lub przynajmniej jest nieodłączną cechą rodzin, z których pochodzą. Fakt, że ten typ umysłu spotyka się tak niezwykle często wśród Indian, Meksykanów i Murzynów, sugeruje dość silnie, iż całe zagadnienie różnic rasowych pod względem cech inteligencji trzeba będzie podjąć od nowa (...). Dzieci tej grupy powinno się uczyć oddzielnie, w klasach specjalnych (...). Nie potrafią one opanować pojęć abstrakcyjnych, lecz często można z nich uczynić wydajniejszych robotników ...” (1916, s. 91-92).


Zanim przejdziemy do mniej efektownych danych liczbowych, przytaczanych dla poparcia stanowiska natywistów, rozpatrzmy pokrótce źródła tendencyjności w tym materiale dowodowym. Nikt oczywiście nie podważałby faktu, że „wybitność”, rozumianą jako wysoki status społeczny, spotyka się często w pewnych rodzinach - lecz czy to świadczy o dziedziczności, czy też o towarzyskich, politycznych i ekonomicznych |kontaktach, które wybitni rodzice mogą zapewnić swemu potomstwu? Czy można nie uwzględniać korzystnych wpływów społecznych sprzyjającego środowiska rodzinnego, właściwych wzorów ról oraz możliwości kształcenia (które dawniej było dostępne tylko dla bogatych)? A w jaki sposób było możliwe zrekonstruowanie drzew genealogicznych rodzin Juke’ów i Kalikaków dla tego okresu historii, kiedy rejestry stanu cywilnego należały do rzadkości lub były niekompletne - i |nie |były prowadzone dla nieprawych potomków? Jak dalece obiektywne są piętnujące określenia stosowane przez badaczy dla potomstwa o „złej krwi”: 
„niemoralni”, „leniwi”, „zboczeni”? Czy złe „prowadzenie się” jest oznaką patologii? Muszą wzbudzać zdziwienie obiektywne kryteria, który pozwoliły przypisać kategoryczne określenie „niedorozwinięci” w taki sposób, że objęło ono ogromną większość emigrantów z wschodniej i południowej Europy.  Niemniej student psychologii musi się zastanowić nad wielkością przeskoku indukcyjnego, jaki wchodzi w grę przy generalizowaniu wyników, uzyskanych z próbki, którą stanowiło dwoje dzieci, na wiele różnych populacji etnicznych i rasowych. I wreszcie, po naszych długich rozważaniach na temat obiektywizmu metody naukowej zamieszczonych w Rozdziale 1, możesz być zaskoczony widocznym brakiem tego obiektywizmu w omawianych badaniach. Być może, jest to dziedzina badań, w której wartości uznawane przez badaczy przeszkodziły we właściwym wykorzystaniu metody naukowej: zebraniu bezstronnych danych i wyciągnięciu trafnych wniosków na podstawie rzetelnych materiałów dowodowych.

Współczesne badania nad bliźniętami. Jeśli inteligencja jest cechą wrodzoną, to powinna istnieć możliwość wykazania, że podobieństwo dwu osób pod względem uzyskiwanych przez nie wyników w teście inteligencji jest funkcją ich podobieństwa biologicznego - zakładając, że środowisko pozostaje bez zmiany. Powszechnie stosowane podejście polega na porównywaniu korelacji pomiędzy wynikami testu inteligencji, uzyskiwanymi przez bliźnięta identyczne, zwykłe rodzeństwa, rodziców i dzieci oraz jednostki nie spokrewnione ze sobą. Metoda ta jest oparta na następującym rozumowaniu: jeśli dziedziczność wpływa na inteligencję, to bliźnięta |jednojajowe, czyli identyczne (pochodzące z tego samego zapłodnionego jaja, a zatem mające identyczne wyposażenie genetyczne), powinny różnić się mniej pod względem inteligencji niż bliźnięta |dwujajowe, czyli zwykłe, które rozwijają się z odrębnych komórek jajowych i których wyposażenie genetyczne nie jest bardziej podobne niż w przypadku jakiegokolwiek rodzeństwa. Powinniśmy zatem częściej stwierdzać podobną inteligencję wśród bliźniąt identycznych - czy to wysoką czy niską - niż wśród bliźniąt dwujajowych. Istotnie, jak wykazują współczynniki korelacji przedstawione w tabeli, stwierdzono takie zależności.

Korelacja Pod Względem Inteligencji
Typy par - Liczba par - Współczynnik korelacji ®
Zwykłe rodzeństwo - 384 - 0,53
Bliźnięta dwujajowe - 482 - 0,63
Bliźnięta jednojajowe - 687 - 0,87
(Źródła: McNemar, 1942; Nichols, 1965)


Wyższe korelacje ilorazów inteligencji dla bliźniąt identycznych (0,87) niż dla innych par nie ulegają wątpliwości, lecz wyższe korelacje dla bliźniąt dwujajowych (0,63), niż dla rodzeństwa (0,53) mogą wynikać z faktu, że w przypadku bliźniąt środowisko jest bardziej podobne niż w przypadku rodzeństwa, które urodziło się w odstępie kilku lat. Aby odziedziczyć te czynniki środowiskowe od czynników dziedzicznych, zebrano dane z czterech badań, w których bliźnięta identyczne było wychowywane osobno, a niespokrewnione z sobą dzieci były wychowywane wspólnie.

„Rozdzielone bliźnięta identyczne”. Analiza wyników testu inteligencji identycznych bliźniąt, które były rozdzielone wkrótce po urodzeniu się i wychowywane w różnych środowiskach, powinna umożliwić wykazanie, że korelacje między ich ilorazami inteligencji są mimo to wyższe niż korelacje bliźniąt dwujajowych wychowywanych wspólnie w tym samym środowisku. Dane pochodzące z czterech badań (w Anglii, Danii i Stanach Zjednoczonych), które w sumie objęły próbkę złożoną ze 122 par bliźniąt (wszystkie one były białe), stanowią materiał dowodowy użyty ostatnio przez Jensena (1969, 1972) i Shockleya (1972) dla poparcia ich wniosku, że dziedziczne wyposażenie genetyczne jest głównym czynnikiem wpływającym na inteligencję środowisko zaś odgrywa stosunkowo mniejszą korelację.
Korelacje między ilorazami inteligencji rozdzielonych bliźniąt identycznych (oceniane w tych czterech badaniach) były dość wysokie: 0,62, 0,67, 0,77, 0,86. Wspomniene bliźnięta identyczne, wychowywane oddzielenie, różniły się pod względem średniego ilorazu inteligencji o około 5 punktów, podczas gdy bliźnięta wychowywane razem różniły się średnio o 2 lub 3 punkty, a rodzeństwa i bliźnięta dwujajowe wychowywane razem różniły się średnio aż o 12 punktów. Toteż Jensen konkluduje:

„Badania nad bliźniętami identycznymi wykazują wyraźnie, że jednostki genetycznie identyczne są prawie tak samo podobne do siebie pod względem zdolności intelektualnych, jak pod względem cech fizycznych, przy czym dzieje się tak nawet wtedy, gdy były one wychowywane w różnych środowiskach” (1972, s. 149).

„Niespokrewnione dzieci wychowywane razem”. Według wyników badań Shieldsa (1962) i Burta (1957, 1966), gdy niespokrewnione dzieci wkrótce po urodzeniu się są adoptowane przez przybranych rodziców i wychowywane w tym samym środowisku, wówczas różnią się one nadal pod względem wyników testu inteligencji. Różnice punktowe między takimi dziećmi są prawie takie same, jak między niespokrewnionymi ze sobą dziećmi z różnych rodzin należących do tej samej klasy społeczno-ekonomicznej. Twierdzi się zatem, że środowiskowe warunki wychowania mają mały wpływ na korelację ilorazów inteligencji.  Twierdzenie to podtrzymują ponadto wyniki badań, zgodnie z którymi, ilorazy inteligencji dzieci adoptowanych nie są skorelowane z ilorazami inteligencji ich przybranych rodziców, lecz są prawie tak samo zbieżne z ilorazami inteligencji ich rodziców biologicznych, jak ilorazy inteligencji dzieci wychowywanych przez swych biologicznych rodziców.
Analiza danych dotyczących 122 par bliźniąt skłoniła Shockleya (1972) do wyprowadzenia wniosku, że genetyczne czynniki mają cztery razy większy wpływ na inteligencję - taką, jaką mierzą testy inteligencji - niż czynniki środowiskowe. Innym słowy, jest on przekonany, że dziedziczne wyposażenie genetyczne wyjaśnia 80% obserwowanej wariancji inteligencji, podczas gdy środowisko wyjaśnia jedynie 20% tej wariancji. Wcześniejsze badania Burksa (1928) i Leahy’ego (1935) przemawiają za tym samym wnioskiem.




Replika badaczy podkreślających rolę środowiska


Stanowisko, jakiego broni większość tych badaczy, których można by nazwać „środowiskowcami”, jest znacznie mniej precyzyjne niż natywistów, jeśli chodzi o ocenę względnego znaczenia przypisywanego czynnikom dziedzicznym i środowiskowym. Zgadzają się oni, że ponieważ jesteśmy stworzeniami biologicznymi, których ewolucją kierowały czynniki genetyczne, przeto inteligencja musi istotnie pozostawać w pewnym stopniu pod wpływem dziedziczności. Polemizują oni jednak z każdym stanowiskiem, które nie uwzględnia w dostatecznym stopniu modyfikującego wpływu różnorodnych, potężnych wpływów środowiskowych na zmienne intelektualne czy fizyczne. Ich argumentacja opiera się na dwu ogólnych liniach rozumowania: a) materiał dowodowy tego rodzaju, jaki prezentują wszelkie podstawowe prace psychologiczne, świadczy o doniosłym wpływie czynników środowiskowych na funkcje fizjologiczne, zdolności percepcyjne, uczenie się i zachowanie adaptacyjne w ogóle; b) przeprowadzane dotychczas badania nad bliźniętami pozostawiają wiele do życzenia pod względem metodologicznym.
Jak wiemy, środowisko najmniej wpływa na proste odruchy, nieco więcej na instynkty, w największym zaś stopniu na zachowanie adaptacyjne, które jest najbardziej uzależnione od uczenia się. Zachowanie inteligentne jest zachowaniem adaptacyjnym, wymaga elastyczności, identyfikowania istotnych wymogów stawianych przez dany problem oraz dobierania odpowiednich środków rozwiązania go. Spostrzeganie, integrowanie, zapamiętywanie, planowanie oraz kierowanie działaniem - wszystko to są elementy zachowania inteligentnego, a środowisko odgrywa ważną rolę w ich rozwoju i kształtowaniu. „Środowiskowcy” twierdzą zatem, że potencjalne możliwości zachowania inteligentnego nie rozwijają się po prostu same, lecz wymagają szczególnego rodzaju doświadczeń.
Badania przeprowadzone na University of California w Berkeley przez zespół fizjologów i psychologów (Rosenzweig i in., 1969) wykazały, że szczury przydzielone losowo do grupy wychowywanej w środowisku „wzbogaconym”, w porównaniu ze szczurami przydzielonymi  do grupy wychowywanej w środowisku „zubożonym”, nie tylko lepiej uczyły się w wieku dojrzałym, lecz ponadto w ich mózgach nastąpiły trwałe zmiany. Zwierzęta hodowane w sprzyjającym środowisku miały większe mózgi, o grubszej korze, występowało w nich więcej substancji przekaźnikowych oraz więcej pewnego określonego enzymu w komórkach odżywiających komórki nerwowe. Te biochemiczne konsekwencje wczesnych wpływów środowiskowych występowały najwyraźniej w korze potylicznej, która jest ośrodkiem otrzymującym wiele rodzajów wejść sensorycznych oraz środkiem integracji czuciowo-ruchowej.  Inne współczesne badania nad percepcją, które zostaną omówione w następnym rozdziale, wskazują, że działanie pojedynczych neuronów czuciowych może być w dużym stopniu modyfikowane przez jakość wczesnych doświadczeń życiowych (Hirsch, 1972; Barlow, 1972). Badania nad wdrukowaniem („imprinting”; 
Hess, 1972) wyraźnie sugerują, że ta ważna reakcja społeczna u nowo wyklutych ptaków zależy zarówno od warunków środowiskowych i czynników dojrzewania, jak i od zmiennych specyficznych dla poszczególnych gatunków.  Zapoznamy się również później z klasycznymi badaniami Harlowa, które wykazują, ż u zdrowych, nowo narodzonych małpek, hodowanych ze „sztucznymi matkami” sporządzonymi z włochatego materiału, nigdy nie rozwija się normalne zachowanie społeczne ani też zachowanie heteroseksualne i występują u nich poważne zaburzenia pod wieloma względami. Imponująca jest lista badań, które świadczą o doniosłym znaczeniu czynników środowiskowych, o ich wpływie na szeroki zakres zachowań, między innymi na rozwój poznawczy. Niemniej jednak w żadnym z tych badań nie próbowano wyodrębnić względnego wpływu środowiska w porównaniu z dziedzicznością, nie koncentrowały się one na inteligencji ludzkiej ani na możliwości jej modyfikowania przez oddziaływanie środowiskowe.
Niektórzy krytycy genetyczno-natywistycznych poglądów na rozwój intelektualny (zwłaszcza Jerry Hirsch, 1970; David McClelland, 1972; N.  L. Gage, 1972; Leon Kamin, 1974) zebrali przekonujące argumenty wykazujące błędność wniosków opartych na wspomnieniach czterech głównych badaniach nad bliźniętami. Ponadto krytykuje się polityczne i społeczne wnioski wyciągane przez niektórych zwolenników stanowiska natywistycznego.  Omówienie ich poglądów na pewne sposoby wykorzystywania wyników uzyskiwanych w testach inteligencji można znaleźć poniżej.


Zbliżenie
Tyrania testów inteligencji: osobiste oświadczenie Phila Zimbardo


„Kiedy byłem studentem, spór „dziedziczność czy środowisko” był abstrakcyjną kwestią intelektualną, która zdawała się nie mieć żadnego powiązania z problemami realnego życia. Takie terminy, jak „tabula rasa”, „dziedziczność”, „współczynnik korelacji” itp. należały do żargonu filozoficznego i psychologicznego, który nie miał nic wspólnego ze sprawami bardziej praktycznymi, a we wczesnym okresie mojej działalności dydaktycznej nie potrafiłem sprawić, aby moi studenci poważnie zainteresowali się tym zagadnieniem.
Wszystko to się zmieniło. W ostatnich kilku latach ukazywały się doniesienia, że programy kształcenia wyrównawczego („Head Start” i inne) dla „upośledzonych mniejszości” miały małą wartość, ponieważ kształcenie nie mogło w sposób istotny podnieść genetycznie zdeterminowanej inteligencji. Ten wniosek Artura Jensena, opublikowany w „Harvard Educational Review” (1969), oparty był na jego interpretacji danych uzyskanych w omówionych tu badaniach nad bliźniętami. Jensen dokonał zatem uogólnienia danych dotyczących dziedziczności ilorazu inteligencji u 122 par białych bliźniąt, aby wyjaśnić przytoczone różnice pomiędzy wynikami testu inteligencji (około 15 punktów) uzyskanych przez białych i czarnych Amerykanów.
Wiliamowi Shockleyowi (laureat nagrody Nobla i współwynalazca tranzystora) pozostało tylko wyprowadzić z tego rozumowania jedyny, oczywisty wniosek. Shockley opowiedział się za wprowadzeniem narodowego programu kontroli genetycznej w celu przeciwdziałania temu, co określił jako |”dysgenikę - wsteczną ewolucję zachodzącą w wyniku nieproporcjonalnej reprodukcji upośledzonych genetycznie”. Jego interpretacja danych (dotyczących tych samych 122 par bliźniąt) „prowadzi w nieuchronny sposób do poglądu, że ilorazy inteligencji Murzynów amerykańskich i ich nieprzystosowanie społeczne („social deficits”) są uwarunkowane przede wszystkim dziedzicznie i genetycznie” (1973, s. 3).

Shocley zaleca drastyczne działanie społeczne: finansową rekonpensatę dla Murzynów, którzy dobrowolnie poddadzą się sterylizacji. Takim pomysłem można by się w ogóle nie zajmować, gdyby nie to, że: a) głoszą go osoby posiadające naukowe i akademickie „listy uwierzytelniające”, co sprawia, że takie enuncjacje są publikowane, b) jest on poparty argumentami Jensena oraz c) zaaprobowany już przez pewną część populacji.
Umieśćmy teraz poglądy Jensena-Shockleya w ich właściwym kontekście historycznym, zanim wykażemy ich błędy. Kontekst ten wiąże się z histerią antyimigracyjną, która doprowadziła Pearsona i Moula do „udowodnienia”, że Żydzi są „nieco gorsi fizjologicznie i umysłowo, w w porównaniu z rodzimą ludzkością” Wielkiej Brytanii (1925, s. 126). W Ameryce na przełomie ubiegłego i bieżącego stulecia, w związku z dążeniami do utrzymania „czystości” narodu amerykańskiego, również domagano się od twórców testów inteligencji, aby dostarczyli oni podstaw naukowych - zarówno dla programów eugenicznych, jak i ograniczeń emigracyjnych. Nie czyniono przy tym istotnych rozróżnień pomiędzy różnymi typami „degeneratów” - kryminalistami, obłąkanymi, ubogimi i „niedorozwiniętymi umysłowo”.  Umieszczano ich w „charytatywnych i korekcyjnych instytucjach publicznych”, w których często wymagano sterylizacji podopiecznych przed ich zwolnieniem.
Głośna książka Carla Binghama „A Study of American Intelligence” („Badania nad inteligencją Amerykanów”) dostarczyła niezbędnego uzasadnienia dla uchwalonej w 1924 roku przez Kongres pierwszej ustawy imigracyjnej, ograniczającej imigrację z różnych krajów - stosownie do „systemu kontyngentów”. Bingham doszedł do wniosku, na podstawie wysoce nieadekwatnego zbioru korelacji, że nordyckie i alpejskie kraje Europy wysyłały do Ameryki swój lepszy materiał rasowy, podczas gdy emigranci z krajów śródziemnomorskich stanowili materiał rasowy biologicznie gorszy.  Uogólnienie to zostało oparte na danych wskazujących, że imigranci, którzy przebywali w Stanach Zjednoczonych dłużej niż 16 lat, uzyskiwali wyższe wyniki w testach inteligencji niż imigranci późniejsi. Ci późniejsi imigranci pochodzili częściej z południowej Europy, podczas gdy imigranci osiedleni od dawna pochodzili z północnej Europy. W korelacjach tych miejsce i czas plączą się zatem ze sobą. Interesujące, że najwyższe wyniki testów inteligencji stwierdzono u białych, anglosaskich imigrantów płci męskiej - grupy, która tradycyjnie sprawuje w Stanach Zjednoczonych władzę polityczną, ekonomiczną i społeczną (i stanowi ogólną kategorię, do której należy większość współczesnych natywistów).
3 3 75 0 2 108 1 5a 1 74 0
Wyższy iloraz inteligencji |jest predyktorem lepszej jakości |życia |w |środowisku, które nagradza umiejętności werbalne i osiągnięcia intelektualne możliwością kształcenia się, lepszymi posadami oraz zaszczytnymi stanowiskami. Ogólny iloraz inteligencji pozwala dobrze przewidywać osiągnięcia szkolne, lecz nie jest dobrym predyktorem wielu innych umiejętności, koniecznych, aby radzić sobie ze środowiskiem pozaszkolnym i przystosowywać się do niego - a jest to środowisko, z którym większość ludzi styka się każdego dnia. |Nie |ma żadnych dostępnych danych uzasadniających słuszność twierdzenia Shockleya - że o inteligencji jednostki w 80% decyduje dziedziczność - w odniesieniu do jakiejkolwiek grupy innej niż grupa kaukaska (tzn. białej rasy - przyp. tłum.). Fałszem logicznym i empirycznym jest również utrzymywanie, że ze względu na dziedziczność ilorazu inteligencji oddziaływanie środowiskowe, takie jak kształcenie wyrównawcze, będzie miało nieistotny wpływ na inteligencję.  Wykazano, że wysokość ciała, która jest oczywiście cechą wrodzoną, zmienia się z pokolenia na pokolenie w wyniku zmian środowiskowych (Cavalli-Sforza i Bodner, 1971). Współczynniki dziedziczności nie mówią nam nic o potencjalnej skuteczności zmian środowiskowych. Jeśli programy wyrównawcze typu „Head Start” są nieefektywne, to może jest to spowodowane nie tym, że |dzieci zawiodły, lecz tym, że |programy te zostały źle opracowane. W dalszym ciągu tej książki przekonamy się wielokrotnie, że zawsze, kiedy występują „problemy społeczne”, reakcja ze strony polityków polega raczej na obwinianiu ludzi niż sytuacji społecznych. Argumenty natywistyczne wywarły spory wpływ na operacje typu „wyszukaj i zniszcz” zmierzające do wyeliminowania „kłopotliwych ludzi”.
3 3 75 0 2 108 1 5a 1 74 1
Ja sam mógłbym wyciskać dziś winogrona na Sycylii, zamiast wykładać na tym uniwersytecie, gdzie stworzyli swoje dzieła Terman i Shockley, gdyby wszystkim tym „niższym” typom śródziemnomorskim nie pozwolono za czasów moich dziadków przybyć do tego kraju wszelkich możliwości. Cieszę się, że natywiści nie zwyciężyli”.


Aby udowodnić w pełni twierdzenie, że inteligencja jest zdeterminowana genetycznie, należałoby zapewnić następujące warunki: a) obiektywny pomiar inteligencji rodziców bliźniąt oraz rodzeństw przy zastosowaniu tych samych wystandaryzowanych testów inteligencji; b) znormalizowane warunki badania testowego; c) losowe przydzielanie dzieci do rodziców z różnych środowisk; d) ocena „jakości intelektualnej”, czyli pozytywnego wpływu na inteligencję każdego z tych środowisk, w których dzieci te są umieszczane.
|Żaden z tych warunków nie został spełniony w badaniach przeprowadzonych dotychczas. Przeciwnie, staranna analiza każdego z tych badań ujawnia szereg wątpliwych procedur, które powodują, że uzyskiwane wyniki są niejednoznaczne. Przekonaliśmy się w Rozdziale 1, że statystyką można się posługiwać w celu udowodnienia każdego twierdzenia - lecz słuszność tych twierdzeń jest taka, jak jakość pomiarów, które doprowadziły do ich wysunięcia. W każdym z omawianych badań nad bliźniętami stosowano różne rodzaje testów inteligencji: testy grupowe oraz testy indywidualne. Ponadto niektóre wyniki korygowano stosownie do „ocen nauczycieli”. W niektórych wypadkach nie dysponowano wynikami uzyskanymi przez rodziców w testach inteligencji i wobec tego określono tylko ich poziom wykształcenia. Kilka z testów nie było wystandaryzowanych dla populacji, z której pobrano próbkę badawczą. Nie przeprowadzono standaryzacji wyników testowych stosownie do wieku i płci bliźniąt - a korelacja między ilorazem inteligencji a wiekiem jest różna u chłopców i dziewcząt. Analiza badań Shieldsa (1962) wykazuje, że kiedy Shields badał bliźnięta sam, wówczas różnica między ich ilorazem inteligencji wynosiła tylko 8,5 punkta, natomiast różnica między bliźniętami w parach |nie badanych przez niego była duża i wynosiła 22,4 punkta - jest to różnica istotna statystycznie.
Nie jest wykluczone, że nastawienie badacza mogło mieć wpływ na wyniki uzyskiwane w testach inteligencji przez ludzi, o których było wiadomo, że są bliźniętami, jeżeli badacz miał nadzieję stwierdzić, że ludzie ci uzyskują te same wyniki. Dlatego też badacze nie powinni wiedzieć, czy dana osoba badana jest bliźniakiem jednojajowym czy bliźniakiem dwujajowym, lub też nie jest w ogóle bliźniakiem (nie ma żadnych danych, że tego rodzaju procedurę stosowano w badaniach przeprowadzonych do tej pory).
Domniemanych różnic pod względem środowiska bliźniąt wychowywanych osobno nigdy nie oceniano pod względem psychologicznych właściwości tych środowisk - co najwyżej rejestrowano zmienne społeczno-ekonomiczne oraz dane dotyczące wykształcenia rodziców. Ponieważ badania te nie są „prawdziwymi eksperymentami” (losowe przydzielanie dzieci do środowisk byłoby nieetyczne) działały przeto czynniki selektywne, które decydowały o tym, gdzie umieszczano adoptowane bliźnięta. W wielu przypadkach, zgodnie z tym, czego można by oczekiwać, bliźnięta przeznaczone do adopcji umieszczano w rodzinach przyjaciół lub krewnych rodziców. Gdy bliźnięta były kierowane do adopcji przez placówki opiekuńcze, wówczas wykorzystywano iloraz inteligencji lub poziom wykształcenia prawdziwych, biologicznych matek, w celu wybrania dla adoptowanego dziecka rodziny o odpowiednich cechach, czego wynikiem są „nieautentyczne” korelacje pomiędzy ilorazem inteligencji naturalnych matek, a ilorazami inteligencji dzieci; wynikało to z podobieństwa ich środowisk - odrębnych, lecz podobnych. Wykazano, że przybrani rodzice w tych badaniach różnili się od rodziców naturalnych pod względem kilku cech, które mogą mieć wpływ na jakość środowiska: byli oni starsi, zamożniejsi, bardziej wykształceni i mieli mniej dzieci - tak więc idealne „dobieranie” o którym pisał Jensen (1969) nie było możliwe.
Natywiści rzadko wspominają o stwierdzonym w trzech badaniach fakcie, że korelacje między ilorazami inteligencji rodziców naturalnych i ich własnych dzieci są podobne do korelacji między ilorazami inteligencji przybranych rodziców i dzieci zaadoptowanych przez nie. Korelacja między ilorazami inteligencji 48 przybranych rodziców a ilorazem inteligencji ich naturalnego dziecka wynosiła 0,35 podczas gdy korelacja między ilorazami inteligencji przybranych rodziców a I.I. dzieci adoptowanych (w próbie liczącej 520 dzieci) wynosiła 0,26 - różnica ta |nie jest istotna statystycznie. (Wspomniane tu badania - to badania Leahy’ego, 1935; 
Burksa, 1928; Freemana i in., 1928). Następna wątpliwa sprawa polega na tym, że z niewieloma wyjątkami większość danych przytaczanych przez natywistów dla poparcia ich stanowiska pochodzi z badań przeprowadzonych w tym okresie (lata dwudzieste i trzydzieste naszego wieku), kiedy w ogóle badania były prowadzone mniej rygorystycznie pod względem metodologicznym.  Nieco późniejsze, klasyczne badanie przeprowadzone przez Burta (1955), budzi, zgodnie z twierdzeniem Kamina (1974), zastrzeżenia natury metodologicznej, co skłania do przeprowadzenia reanalizy jego oryginalnych danych. Niestety, dane Burta zostały zagubione po jego śmierci.
Podczas gdy w przeszłości badacze kładący nadmierny nacisk na aspekt genetyczny rozwoju poznawczego przyjmowali fatalistyczny pogląd na możliwości człowieka i wykorzystywali swoje wnioski do uzasadniania prostackich rozwiązań problemów społecznych, to badacze wyznający poglądy empirystyczne często błądzili w przeciwnym kierunku. Zgodnie z amerykańską tradycją behawiorystyczną, prawie wszelkie zachowania dają się modyfikować przez doświadczenie i ćwiczenie. Nie uwzględniając ograniczeń genetycznych, „środowiskowcy” wzbudzali niekiedy nieuzasadniony optymizm, co do możliwości przesuwania górnych granic zdolności jednostki.
Obecnie różnice między tymi stanowiskami zmniejszają się, ponieważ staje się coraz bardziej oczywiste, że oba czynniki: dziedziczność i środowisko, pozostają w stałej |interakcji - od momentu poczęcia danej jednostki.  Obecnie niewielu badaczy zajmuje stanowisko czysto natywistyczne i czysto „środowiskowe”. Przyjmuje się powszechnie, że to, co dziedziczymy od swoich rodziców - umożliwia występowanie pewnego zakresu zachowań i być może wyznacza pewien maksymalny poziom funkcjonowania w odniesieniu do każdego z tych zachowań. Grupa 50 naukowców zainteresowanych tą sprawą i domagających się uznania wpływu dziedziczności na inteligencję, opublikowała niedawno rezolucję dotyczącą tego zagadnienia w poważnym czasopiśmie Amerykańskiego Towarzystwa Psychologicznego.


Zbliżenie
Rezolucja w sprawie badań nad dziedzicznością


„(...) My, niżej podpisani naukowcy, reprezentujący różne dziedziny, deklarujemy następujące poglądy i uznawane przez nas zasady:
1. Przeanalizowaliśmy wiele materiałów dowodowych dotyczących możliwego wpływu dziedziczności na ludzkie zdolności i zachowanie i jesteśmy przekonani, że wpływy dziedziczne są bardzo silne.

2. Pragniemy mocno zachęcić do badań nad biologicznymi, dziedzicznymi podstawami zachowania jako poważnym uzupełnieniem prób jego wyjaśniania odwołujących się do wpływów środowiskowych.

3. Zdecydowanie bronimy prawa wykładowcy do omawiania wpływów dziedziczności na zachowanie i kładziemy nacisk na jego naukowy obowiązek przedstawiania ich (w odpowiednich kontekstach i z odpowiednią erudycją).

4. Ubolewamy nad unikaniem we współczesnych podręcznikach rozumowania uwzględniającego rolę dziedziczności i nad pomniejszaniem wagi dziedziczności w takich dyscyplinach, jak socjologia, psychologia społeczna, antropologia społeczna, psychologia wychowawcza, pomiar psychologiczny i wielu, wielu innych.

5. Wzywamy liberalnych akademików - senaty wydziałów, stowarzyszenia zawodowe i naukowe, Amerykańskie Stowarzyszenie Profesorów Uniwersytetów, Amerykański Związek Wolności Obywatelskich, Uniwersyteckie Ośrodki Racjonalnych Alternatyw, przewodniczących i członków zarządów różnych instytucji, wydziały nauki oraz wydawców naukowych czasopism - aby nalegali na otwarcie wiedzy społecznej dla dobrze uzasadnionych twierdzeń wynikających z rozumowania biobehawioralnego i aby chronili czynnie wszystkich przedstawicieli nauki, którzy w odpowiedzialny sposób wykładają, publikują czy badają zagadnienia związane z takim rozumowaniem.

Nalegamy na to, ponieważ jako naukowcy jesteśmy przekonani, że ludzkie problemy najlepiej możemy rozwiązać powiększając zasoby wiedzy, co przyniesie najprawdopodobniej zwiększenie szczęścia ludzkości, nie zaś skutki przeciwne”. (APA - „Amerykańskie Towarzystwo Psychologiczne”, 1972, s. 600).

Wydaje się oczywiste, że możliwości genetyczne mogą być zrealizowane jedynie w sprzyjającym środowisku, lecz żadne środowisko nie może stworzyć możliwości, które nie istnieją. Nie możemy obecnie powiedzieć, jak bardzo korzystny wpływ mogłoby mieć środowisko idealne, ponieważ nie dysponujemy jeszcze dostateczną wiedzą, aby zaprojektować takie idealne środowisko.


Czy rozwój poznawczy jest stały i przewidywalny?


Przeprowadzono bardzo wiele badań, aby ustalić, czy wyniki testów inteligencji, wykorzystywane jako wskaźniki rozwoju poznawczego, pozostają bez zmiany w ciągu lat. Z reguły dochodzi się do wniosku, że zazwyczaj pozostają one w zasadzie stałe wtedy, kiedy warunki pozostają bez zmiany - to znaczy wtedy, gdy zdrowie, wykształcenie i sytuacja domowa nie ulegają znacznym zmianom. Jedynym godnym uwagi wyjątkiem są bardzo małe dzieci, których możliwości być może są bardzo zmienne; ponadto opracowanie dla nich testów i stosowanie ich nastręcza szczególne trudności: na przykład, uwaga małych dzieci może być chwiejna, albo też ich słaba jeszcze koordynacja ruchowa może utrudniać dokładną ocenę. Inny poważny problem polega na tym, że testy stosowane w różnym wieku opierają się na różnych komponentach inteligencji: testy dla małych dzieci badają głównie zdolności sensoryczne i motoryczne, podczas gdy testy dla starszych dzieci są bardziej uzależnione od zdolności słownych i pojęciowych. Niewątpliwie jest to przyczyna, dla której wyniki otrzymane po ukończeniu przez dziecko 6 lat korelują zwykle wyżej z inteligencją w wieku dojrzałym niż wyniki otrzymane przez nie w latach przedszkolnych. Wyniki uzyskane w wieku poniżej 2 lat nie są zbyt stabilne i w każdym razie testy te w większym stopniu badają ogólny poziom rozwojowy niż zdolności intelektualne.


Zbliżenie
Wzbogacone środowisko rozwija niedożywione umysły i ciała


„Wyniki przeprowadzonych niedawno badań (Winick, Meyer i Harris, 1975) wykazują, że wzbogacenie środowiska niedożywionych uprzednio dzieci powoduje nie tylko lepszy ich rozwój fizyczny, lecz i psychiczny. Sześć lat przebywania w przybranych rodzinach, należących do amerykańskiej klasy średniej, wpłynęło znacznie na wysokość i ciężar ciała, I.I. oraz wskaźniki osiągnięć szkolnych u sierot koreańskich, adoptowanych przed ukończeniem drugiego roku życia. Próbkę złożoną ze 141 dzieci podzielono na trzy podgrupy według stopnia ich niedożywienia w momencie adopcji - „niedożywionych”, „średnio odżywionych” i „dobrze odżywionych”.
We wszystkich trzech grupach wysokość i ciężar ciała dzieci przekroczyły oczekiwaną średnią dla dzieci koreańskich, znajdującą się jednak poniżej 50 centyla norm amerykańskich. Początkowe różnice pod względem rozwoju fizycznego na ogół utrzymywały się - te dzieci, które były dobrze odżywione w wieku 18 miesięcy, były też większe w czasie, gdy uczęszczały do szkoły podstawowej. Najbardziej jednak uderzające były ilorazy inteligencji, jakie osiągnęły te dzieci. Dzieci wychowywane w sprzyjającym środowisku, jakie zapewniły im rodziny należące do amerykańskiej klasy średniej, uzyskały I.I. wyższe o około 40 punktów od ilorazów inteligencji podobnych dzieci, które powróciły do swego poprzedniego (niekorzystnego) środowiska domowego.
Piętno niedożywienia we wczesnym okresie życia utrzymywało się jednak w pewnym stopniu, ponieważ średni I.I adoptowanych dzieci koreańskich z grupy „dobrze odżywionej” jest o blisko 10 punktów wyższy niż u ich rówieśników z grupy „niedożywionej”. Wyniki dotyczące osiągnięć szkolnych przypominają zależności występujące w przypadku I.I. - są wyższe u dzieci początkowo lepiej odżywionych, we wszystkich zaś grupach są co najmniej równe średniej dla amerykańskich dzieci szkolnych. Co więcej, średni I.I. w grupie „dobrze odżywionych” dzieci, równy 112, jest istotnie wyższy niż I.I. dzieci amerykańskich z klasy średniej. Autorzy przypuszczają, że „osiągnięcia” (tych dzieci) mogą być odbiciem szczególnie korzystnego wpływu cech przybranych rodziców oraz środowiska, jakie stworzyli oni swym adoptowanym dzieciom”.

Wykazano, że drastyczne zmiany w środowisku powodują duże zmiany w |wynikach testów inteligencji - punkt na korzyść „środowiskowców”. Jest tak zwłaszcza w przypadkach, w których dziecko podlegało w przeszłości poważnej deprywacji i kiedy zmiana środowiska następuje wtedy, gdy dziecko jest jeszcze zupełnie małe. Zdaje się nie ulegać wątpliwości, że w takich przypadkach pierwotny wynik testów inteligencji nie był miarą pełnych możliwości dziecka. Niestety, nie wiemy, w jakim stopniu dotyczy to wyników testowych w ogóle, czyli jak często - i w jakim wieku - wyniki innych dzieci wzrosłyby wskutek lepszego zaprogramowania ich środowiska.
Dwa badania podłużne pomogły nam ustalić czynniki odpowiedzialne za stałość lub zmiany w poszczególnych przypadkach. Jedno z badań przeprowadzonych w „Fels Research Institute of Human Development” („Instytucie Badań nad Rozwojem Człowieka im. Felsa”) w Ohio (Sontag, Baker i Nelson, 1958); kompletowano w nim przez 20 lat dokumentację dotyczącą 200 badanych nie przebywających w instytucjach opiekuńczych. W drugim badaniu, którym kierowała Nancy Bayel (1968) i Marjorie Honzik (1973) oraz ich współpracownicy z University of California w Berkeley, badano 56 „zdrowych” ludzi - od urodzenia do wieku 36 lat. Godne uwagi poświęcenie uczonych, którzy zaangażowali się w długoterminowe, złożone badania tego rodzaju, przyniosło wiele korzyści w postaci nowej wiedzy i wskazówek do dalszych badań. Jednym z najbardziej uderzających wyników było stwierdzenie wielkiego zróżnicowania przebiegu rozwoju poznawczego u różnych jednostek. 
Na przykład:
1. W obu badaniach stwierdzono, że u wielu obserwowanych dzieci zmiany w wynikach testów zdolności intelektualnych zachodziły nie tylko w okresie przedszkolnym, lecz w ciągu całego dzieciństwa.
2. |Tempo rozwoju umysłowego u poszczególnych dzieci w ciągu pierwszych lat ich życia było zmienne: rozwój zdawał się wykazywać okresy nagłego przyspieszenia i okresu zastoju (plateau).
3. U poszczególnych o.b. występowały różne wzorce zmian ilorazu inteligencji: u niektórych I.I. nie zmienił się, u innych występował jego stopniowy wzrost lub spadek, u jeszcze innych wzorzec ten był różny w różnych okresach ich rozwoju.
4. Największy zaobserwowany przyrost wynosił 73 punkty (od 107 w wieku 2,5 lat do 180 w dziesiątym roku życia); największy zaobserwowany spadek wynosił 40 punktów (od 142 w wieku 3 lat do 102 w wieku 8 lat).
W badaniach Bayley uzyskano wiele danych świadczących o różnym przebiegu rozwoju poznawczego u chłopców i dziewcząt, jak również o relacjach pomiędzy rozwojem poznawczym a różnymi zmiennymi osobowościowymi.  Stwierdzono u chłopców kilka stałych korelacji pomiędzy zachowaniami w ciągu pierwszych trzech lat życia, a wskaźnikami inteligencji werbalnej w ciągu 36 lat życia. Natomiast u dziewcząt nie było żadnych wyraźnych korelacji między zachowaniem w okresie dziecięcym, a inteligencją w tym właśnie czy późniejszym okresie. W gruncie rzeczy, w pewnych przypadkach korelacje stwierdzane u dziewcząt w wieku 16 lat ulegały odwróceniu w wieku 36 lat. U chłopców również występowały pewne przypadki odwrócenia: na przykład chłopcy, którzy byli bardzo aktywni pomiędzy 10 a 15 miesiącem życia, mieli później na ogół niskie wskaźniki werbalne, podczas gdy wysoka aktywność u chłopców pomiędzy 18 a 36 miesiącem życia była predyktorem późniejszych wysokich wskaźników werbalnych, jeśli chłopcy ci byli ponadto weseli. Nieśmiałość i smutek u uroczych dziewczynek była predyktorem późniejszych wysokich wskaźników werbalnych, natomiast u chłopców w tym samym wieku ich predyktorem była wesołość. Nieśmiałość w wieku 4 lat nie była skorelowana z późniejszymi wskaźnikami werbalnymi zarówno u chłopców, jak i u dziewczynek. Nie ulega wątpliwości, że jeśli traktuje się dane w sposób bardziej analityczny, to można ujawnić wiele zależności, które są ukryte w ogólnych wynikach reprezentujących przeciętne dla wielu jednostek.
Jaki wpływ ma rodzaj i jakość zachowania matek na rozwój inteligencji i osobowości dziecka? Korelowanie zachowań matek z inteligencją dzieci ujawniło bardzo interesujące zależności. Sposób reagowania matek na zachowanie chłopców w ciągu pierwszych 3 lat życia najwyraźniej miał trwały wpływ na ich inteligencję mierzoną w 18, a nawet w 36 roku życia. Wrogość matek była skorelowana z niską inteligencją ich synów w wieku dojrzałym (korelacje około 0,60), podczas gdy miłość i zrozumienie ze strony matki były dodatnio skorelowane z ich inteligencją w wieku dojrzałym. Natomiast wskaźniki inteligencji u dziewcząt nie były zależne od sposobu, w jaki były one |traktowane przez matki, lecz były skorelowane ze wskaźnikami |zdolności rodziców. Bayley wyciąga następujący wniosek:

„To związane z płcią zróżnicowanie korelacji skłoniło nas do sformułowania sugestii, że między płciami istnieją genetycznie zdeterminowane różnice pod względem trwałości skutków wczesnych doświadczeń (takich, jak miłość i wrogość ze strony matki). Dziewczęta zdawały się bardziej elastycznie powracać do swych własnych, charakterystycznych sposobów reagowania. Natomiast na chłopców w sposób bardziej trwały oddziaływał klimat emocjonalny okresy niemowlęctwa, czy to klimat ciepła i zrozumienia czy też karzącego odrzucenia” (ss. 14 - 15).


Potrzeba więc badań, aby uzyskać dane, które pozwoliłyby zrozumieć specyficzne sposoby współdziałania dziedziczności i środowiska w kształtowaniu inteligencji. Przytoczone powyżej wyniki wskazywałyby, że czynniki dziedziczne mogą mieć większy wpływ na inteligencję dziewcząt niż chłopców. Chłopcy i mężczyźni zdają się być bardziej podatni na wpływy środowiskowe niż dziewczęta i kobiety. Wiele danych wykazuje, że to dość zaskakujące twierdzenie jest prawdziwe w odniesieniu do bardzo wielu różnorodnych zachowań. Na przykład chłopcy częściej niż dziewczęta umierają w niemowlęctwie, częściej mają trudności z czytaniem, częściej rozwija się u nich schizofrenia dziecięca, częściej popełniają samobójstwa, częściej dopuszczają się aktów przemocy, częściej umieszczani są w szpitalach z powodu chorób fizycznych i psychicznych. Co więcej, podaje się, że po wybuchu bomby atomowej nad Hiroszimą płody płci męskiej częściej rodziły się tam martwe lub z uszkodzeniami niż płody żeńskie (Maccoby, 1966).
Rozwoju zdolności poznawczych nie można oddzielać od ogólnego rozwoju jednostki, ponieważ funkcjonowanie w sferze poznawczej decyduje o tym, czego dana jednostka może dokonać w środowisku i dla środowiska. Z drugiej strony, zdolności poznawcze są tylko jednym z aspektów osobowości danej jednostki. Nasze dotychczasowe rozważania wskazują, że inteligencji nie powinno się uważać za jakiś statyczny, trwały byt - za coś, co ludzie „posiadają”. Miary inteligencji są zawsze miarami przystosowawczego zachowania jednostki, próbującej uporać się z określonymi wymaganiami ze strony środowiska.

Aby jednostka była zdolna do złożonego |zachowania |przystosowawczego, potrzebny jest jej zarówno dziedziczny potencjał umożliwiający radzenie sobie ze złożonością zadań, jak i pewne rodzaje kontaktów ze środowiskiem, które umożliwiają nabywanie niezbędnych umiejętności - percepcyjnych, pojęciowych, motorycznych, a być może także językowych i społecznych.
Honzik formułuje następujące wnioski, które odnoszą się do całego zagadnienia „dziedziczność czy środowisko” oraz problemu długoterminowego prognozowania rozwoju inteligencji. Pisze ona:

„Dziedziczność określa granice i ma istotne znaczenie dla inteligencji dziecka, której miarą są jego wyniki w testach inteligencji, lecz otrzymane korelacje są niskie i wskazują na wpływ, jaki czynniki związane z doświadczeniem mogą wywierać na przebieg rozwoju umysłowego. Czynniki środowiskowe nie zaczynają działać w chwili urodzenia się dziecka, lecz w momencie jego poczęcia lub przedtem (...). Zapewniając jednostkom, od urodzenia do starości, więcej wzbogacających je programów, możemy mierzyć wynikające stąd układy zdolności - umożliwia to nam poznanie rozmiarów plastyczności ludzkiego organizmu w rozwijaniu jego zdolności” (1973, ss.  649, 653).


Procesy myślowe


Ktoś powiedział, że chociaż mózg znajduje się w głowie, to jednak myślimy całym naszym ciałem. Wydaje się, że myślenie to coś więcej niż tylko „myśli” i stany psychiczne; w procesie tym odgrywa rolę mowa subwokalna i stan organizmu. W pewnym stopniu na myślenie wpływają nasze wyobrażenia o bodźcach, sprzężenie zwrotne, jakie otrzymujemy słysząc komunikowane przez nas myśli oraz rodzaj języka, jakim posługujemy się, aby wyrazić to, co „mamy w głowie”.


Obrazy w naszych głowach


Ludzie myślą czasami za pomocą |wyobrażeń, które są obrazami psychicznymi rzeczywistych doznań zmysłowych. Najmocniejszą stroną większości ludzi zdaje się być wyobraźnia wzrokowa, chociaż u niektórych jest nią wyobraźnia słuchowa, a niewielka mniejszość podaje, że dominuje u nich wyobraźnia dotyku, ruchów mięśniowych, smaku czy zapachu.
Aczkolwiek niektórzy dawniejsi psychologowie byli przekonani, że myślenie |wymaga posługiwania się wyobraźnią, różne badania przeprowadzone do tej pory wykazały, że myślenie może także przebiegać pod nieobecność wyobrażeń.  W jednym z pionierskich badań stwierdzono na przykład, że wielu naukowców i matematyków-praktyków, chociaż zajmują się oni najwyższym i najbardziej skomplikowanym typem myślenia w rzeczywistości wykazywało zupełny brak wyobraźni wzrokowej (Galton, 1883). Poincare, wielki matematyk francuski zajmujący się również geometrią, mówił o sobie samym, że brak mu zdolności wzrokowego wyobrażenia sobie przestrzeni. Fakty te podajemy nie po to, aby twierdzić, że wyobraźnia jest niepotrzebna w wielu rodzajach myślenia, lecz by wykazać, że nie zawsze jest ona niezbędna.

Wyobraźnia ejdetyczna. Niektóre osoby posiadają wyobraźnię, która odznacza się prawie taką wyrazistością i dokładnością, jak rzeczywista percepcja. Takie wyraziste wyobrażenia, zwykle wzrokowe, zwane są |wyobrażeniami |ejdetycznymi. Ludzie z wyobraźnią ejdetyczną potrafią często określić dokładnie położenie jakiegoś wzoru czy opisu na zadrukowanej stronicy podręcznika. Potrafią oni nawet, spojrzawszy przez ułamek sekundy na pewien przedmiot, na przykład grzebień, przywołać następnie tak żywe jego wyobrażenie, że mogą podać jego kompletny opis, z liczbą zębów włącznie. Na egzaminach mogą oni „przepisywać” ze swojego wyobrażenia zadrukowanej stronicy, czyniąc to tak dokładnie, jak gdyby mieli przed sobą otwartą książkę (Haber, 1968).
Uderzające przykłady wyobraźni ejdetycznej zostały udokumentowane w pracy „The Mind of a Mnemonist” (Umysł mnemonika), stanowiącej stadium przypadku mężczyzny z „fotograficznym” umysłem, której autorem jest radziecki psycholog Łuria.

„Badany ten miał takie zdolności wyobrażeniowe, że potrafił dokonywać zdumiewających wyczynów pamięciowych. Poniżej podano opis jednego z wielu eksperymentów przeprowadzonych z tym człowiekiem (możesz spróbować przeprowadzić to na sobie samym); zapoznanie się z tabelą liczb, przedrukowaną poniżej, zajęło mu 3 minuty.

6  6  8  0
5  4  3  2
1  6  8  4
7  9  3  5
4  2  3  7
3  8  9  1
1  0  0  2
3  4  5  1
2  7  6  8
1  9  2  6
2  9  6  7
5  5  2  0
X  0  1  X

Potrafił on odtworzyć tę tablicę bezbłędnie wymieniając wszystkie liczby w ciągu 40 sekund. Potrafił wymienić liczby zarówno w kolumnach, jak i w poziomych wierszach, po kolei lub w odwrotnej kolejności. Potrafił także odtworzyć w ciągu 35 sek. liczby, które tworzą przekątne (6, 4, 8, 5; 5, 6, 3, 7). Na koniec, 1,5 min zajęło mu przekształcenie wszystkich 50 cyfr w jedną liczbę pięćdziesięciocyfrową” (Łuria, 1968).

W tym momencie zapragnąłeś może posiadać dar ejdetycznej wyobraźni (czyli „pamięci fotograficznej”). Mogłeś pomyśleć, że cała twoja praca na uczelni byłaby dla ciebie czymś bardzo prostym do wykonania, gdybyś potrafił wszystko tak dobrze zapamiętać. W rzeczywistości wyobraźnia ejdetyczna jest bardzo wątpliwym błogosławieństwem i często zamiast być pomocna - przeszkadza w myśleniu. Materiały przechowywane ejdetycznie niełatwo jest rozłożyć i złożyć ponownie w nowe układy. Jednostki posiadające wyobraźnię ejdetyczną potrafią odtworzyć to, co widziały, lecz sprawia im trudność zastosowanie tej informacji w nowy sposób.

Wyobraźnia ejdetyczna nie odgrywa zatem zapewne żadnej roli w myśleniu abstrakcyjnym czy wyobraźni twórczej, która wymaga giętkości myślenia.  Badany Łurii nie mógł na przykład zrozumieć prostych abstrakcyjnych idei, ponieważ nie mógł „zobaczyć” ich w postaci konkretnych wyobrażeń wzrokowych. Być może wyjaśnia to, dlaczego wyobraźnię ejdetyczną spotyka się najczęściej u dzieci, a stosunkowo rzadko u dorosłych.


Zbliżenie
On potrafiłby cię pokonać z zawiązanymi oczyma


„Zdolność tworzenia wzrokowej reprezentacji sytuacji, użyteczna w złożonym myśleniu, nie musi być tym samym, co wyobraźnia wzrokowa. Fakt ten podkreślił w opisie introspekcyjnym pewien psycholog, a zarazem mistrz szachowy, który potrafił równocześnie rozgrywać „w ciemno” 12 partii szachów. W rzeczywistości gracz taki nie ma zawiązanych oczu, lecz siedzi tyłem do szachownicy czy szachownic; jego pomocnik podaje mu ruchy przeciwnika. Zdolność wzrokowego przedstawienia sobie tego, co zachodzi na szachownicy, jest oczywiście głównym warunkiem zwycięstwa. Jednakże zdolność ta polega w większym stopniu na procesie abstrahowania, niż dosłownego wyobrażenia sobie wszystkich szczegółów.

Ów psycholog-mistrz reasumuje to w sposób następujący:
1. W wyniku długiego doświadczenia w grze w szachy zarówno szachownica, jak i figury są powiązane licznymi skojarzeniami. Myślenie oddzielne o szachownicy i figurach staje się niemożliwe.
2. Jest także niemożliwe, aby myśleć o ruchach bez specjalnej notacji, czyli języka symbolicznego, którym posługują się szachiści dla opisania swych partii. Rozgrywane równocześnie partie są utrzymywane w izolacji w umyśle gracza przede wszystkim za pomocą tych symboli. Partie różnią się znacznie swym charakterem, w zależności od zastosowanego otwarcia, a w miarę jak rozwijają się one i różnice między nimi stają się większe, nie jest trudniej, lecz łatwiej utrzymać ich odrębność.
3. Cała szachownica zostaje ukształtowana w przestrzenno-czasową „postać” („Gestalt”), czyli wzorzec. Inaczej mówiąc, pozycja figur zmienia się w przestrzeni i czasie, lecz liczba prawdopodobnych zmian jest ograniczona.
4. Główną umiejętnością w szachach jest zdolność zreasumowania każdej pozycji w sposób dynamiczny, w kategoriach najważniejszych jej elementów, bez względu na ich ważność.
5. Powyższe 4 fazy zachodzą przeważnie poniżej poziomu aktywnej świadomości. Dopiero gdy zostaną zreasumowane istotne elementy, obraz wzrokowy dochodzi do świadomości. „Obraz”, który gracze wyobrażają sobie świadomie, jest spójny dzięki ich zdolności organizowania abstrakcyjnych i symbolicznych danych (Fine, 1965).

Jeden z problemów metodologicznych w badaniu wyobraźni ejdetycznej polega na ustaleniu czy jest to proces |pamięciowy, czy też |wzrokowy. Innymi słowy, czy opisany powyżej mnemonik opanował jakiś specyficzny sposób werbalnego |zakodowania 50 liczb - tak że może później wyliczyć, jakie to były liczby? Czy też istotnie ma on dokładne wyobrażenie tej tabeli, na którą może „patrzeć” i odczytywać z niej te liczby?
Aby wykazać w przekonywający sposób, że ktoś posiada wyobraźnię ejdetyczną, a nie „tylko” doskonałą pamięć, trzeba posłużyć się specjalną metodą - trzeba również znaleźć chętną osobę badaną stwierdzającą, że posiada wyobraźnię ejdetyczną. Dwóch młodych badaczy (doktorantów z Harvard University), Charles Stromeyer i Joseph Psotka (1970), opracowało niedawno odpowiedni test, a jednocześnie znalazło nauczycielkę, która najwyraźniej posiadała tę rzadko spotykaną umiejętność. Osobą badaną z ejdetyczną wyobraźnią była 23-letnia plastyczka, która zdolność tę posiadała w wybitnym stopniu. Potrafiła ona na przykład przeczytać stronicę poezji w jakimś znanym jej obcym języku, rzutować jej „obraz” na czystą stronę, a następnie przepisywać ją od najniższego wiersza do najwyższego - tak szybko, jak tylko jej ręka mogła pisać.
Test polegał na tym, że osobie badanej polecono patrzeć na 2 stereogramy.  Były to układy czarnych punktów rozmieszczonych w przypadkowy sposób na macierzy 100x100, co dawało w sumie 10 000 czarnych lub białych pól. Oba te układy były identyczne: z wyjątkiem małego obszaru jednej z figur, w którym niektóre czarne punkty były przesunięte w bok. Gdy na jeden układ patrzy się w stereoskopie lewym okiem, a na drugi prawym, wówczas pojawia się trójwymiarowa figura w tym miejscu, gdzie punkty zostały przesunięte.  Figury te opracował Bela Julesz (1971) z Bell Telephone Laboratories. W zależności od stereogramu trójwymiarowa figura może wydawać się cofnięta lub wystająca, może być dowolnego kształtu - ze spiralą włącznie, wówczas nie można zobaczyć, zgadnąć ani wydedukować, co powinno się zobaczyć, gdy układy te zostaną połączone w stereoskopie.
Osobę badaną poproszono, aby popatrzyła na jeden układ prawym okiem (lewe było zasłonięte). Układ ten usuwano, a po trzech minutach patrzyła na drugi układ lewym okiem (teraz prawe oko było zasłonięte). Co zobaczyła? „To jest śmiesznie łatwe!” zawołała i zaczęła opisywać z dokładnymi szczegółami trójwymiarową figurę wystającą z powierzchni, którą |zobaczyła. Mogła ona przechowywać takie układy w swojej ejdetycznej wyobraźni nawet przez trzy miesiące; potrafiła nawet złożyć ejdetyczny obraz w wypadku układów steregoramowych składających się z miliona kwadracików. Zdaje się, że podstawą takiego zjawiska może być tylko przechowywanie w pamięci „fotograficznego” wyobrażenia obrazu - jest on rzutowany w tej samej postaci w momencie składania. Nie wiadomo, jak to jest możliwe z neurologicznego punktu widzenia.

Wewnętrzna reprezentacja przedmiotów. Pewna hipoteza dotycząca rozwoju pojęć u dzieci przyjmuje za punkt wyjścia przesłankę, że skuteczna interakcja z przedmiotami w środowisku wymaga skonstruowania wewnętrznej reprezentacji tych przedmiotów zewnętrznych i relacji między nimi.  Przypuszcza się, że w trakcie rozwoju poznawczego budowane są kolejno trzy, coraz bardziej efektywne typy reprezentacji. Pierwszy z nich to reprezentacja |mięśniowa i motoryczna. Potrafisz wchodzić po schodach we własnym domu w ciemności nie potykając się, ponieważ nauczyłeś się dokładnie przystosowywać swoje ruchy do wysokości stopni i do zakrętów czy nierówności schodów. Nawet bez sygnałów wzrokowych potrafisz dokładnie wykonać potrzebne ruchy.
Następny typ reprezentacji opiera się na |wyobrażeniach. W przeciwieństwie do reprezentacji ruchowej, wyobraźnia może służyć nam pod nieobecność samych przedmiotów. Jednakże wyobrażenia są zapisami dosłownymi; pozostają one podobne - pod względem formy i swych wzajemnych relacji - do przedmiotów, jakie uprzednio zostały spostrzeżone. Dopiero, gdy uzyskamy zdolność konstruowania |symboli, takich jak symbole językowe, to dysponujemy systemem reprezentacji, który może wykraczać poza szczegółowe właściwości tego, co spostrzegamy. Wyobrażenia opierają się na konkretnych szczegółach percepcyjnych, podczas gdy symbole mogą być efektem procesów wnioskowania, abstrahowania lub przekształcania (transformacji) według pewnej reguły (Bruner, 1964).
Do niedawna stwierdzenia takie jak powyższe, że ludzie posługują się podczas myślenia wyobrażeniami, opierały się po prostu na ich sprawozdaniach. Aby niejasne pojęcie „wyobrażenia umysłowego” było użyteczne naukowo, trzeba je przeformułować w kategoriach, które umożliwiają jego eksperymentalną analizę. W jakiej mierze rzeczywiście tworzymy wewnętrzne reprezentacje przedmiotów z naszego środowiska zewnętrznego? Czy możemy |mierzyć zgodność pomiędzy takimi zdarzeniami wewnętrznymi a ich zewnętrznymi odpowiednikami, nie opierając się na sprawozdaniach słownych? Czy istnieje jakiś systematyczny związek między zmianami w zewnętrznych układach bodźcowych a ich reprezentancjami wewnętrznymi? Tego rodzaju pytania stawiali sobie Roger Shepard i jego współpracownicy (Shepard i Metzler, 1971, 1974; Shepard i Feng 1972; 
Cooper i Shepard 1973). Ich badania miały na celu ustalenie, czy reprezentacja zewnętrzna jest procesem |analogowym, to znaczy takim, w którym proces |psychiczny odpowiada bezpośrednio jakiemuś procesowi fizycznemu (w tym wypadku procesowi zmian bodźca zewnętrznego).

„W każdej próbie badanemu prezentowano parę rysunków przedmiotów trójwymiarowych ujętych z perspektywy. Zadanie polegało na ustaleniu, tak szybko, jak tylko było to możliwe, czy przedstawione dwa przedmioty są różne, czy też mają ten sam kształt trójwymiarowy, lecz różne ustawienie.  Badany wskazywał, czy przedmioty te były „takie same” czy „różne” przez naciskanie jednej z dwóch dźwigni. Zmienną zależną była ilość czasu, jaki upływał między prezentacją tych rysunków a naciśnięciem dźwigni.

„Przez sporządzenie wykresu zależności tych czasów reakcji od kąta, o który obrócono identyczne figury, można było ustalić związek między reprezentacją wewnętrzną a zmianami zewnętrznymi. Czasy reakcji wzrastały w miarę jak wzrastał kąt, o który obrócono figurę. Dane wykazują, że czas potrzebny do dokonania w myśli rotacji figury był taki sam dla rotacji dwuwymiarowej i trójwymiarowej. Badani podawali, że obracali w myśli jeden z tych przedmiotów, to takiego samego położenia jak drugi, spostrzegając dwuwymiarowe figury tak, jak gdyby były one przedmiotami w przestrzeni trójwymiarowej. Mówili oni, że czynność rotacji myślowej zdawała się wymagać pewnej ilości czasu - zależnie od tego, jak duża rotacja była potrzebna - lecz rotacje obu rodzajów można było przeprowadzać z równą łatwością”.

Shepard sądzi, że reprezentacja wewnętrzna, w tym i w wielu innych podobnych badaniach, rzeczywiście stanowi proces analogowy, w którym stadia pośrednie procesu odpowiadają ściśle („one-to-one”) sytuacjom pośrednim w świecie zewnętrznym. Jest to proces molarny w przeciwieństwie do innych procesów percepcyjnych i procesów myślenia polegających na wyszukiwaniu charakterystycznych cech, operowaniu symbolami, analizie werbalnej czy obliczeniach cyfrowych na poziomie molekularnym.




Zbliżenie
Trzeba czasu, aby pomyśleć: czas reakcji


„Psychologowie, którzy zdecydowali się badać procesy myślowe, przekonają się wkrótce, iż większość interesujących ich zjawisk jest tego rodzaju, że nie można ich mierzyć. Jedną z rzeczy, którą można mierzyć, jest |czas |reakcji: czas upływający między podaniem bodźca a reakcją na ten bodziec.  Badanie czasu reakcji miało ważne znaczenie dla badań psychologicznych nie tylko ze względu na to, co czas reakcji mówi nam o prostych reakcjach ruchowych, lecz także dlatego, że służy on jako wskaźnik ilości informacji, jaka może zostać przetworzona w czasie między zadziałaniem bodźca a reakcją.
Związek między czasem reakcji a myśleniem najlepiej można ustalić, jeśli rozpatrzymy go z perspektywy historycznej. Badania nad czasem reakcji można podzielić z grubsza na 4 chronologicznie po sobie następujące okresy: 1) badania astronomów nad „równaniem osobistym”, 2) eksperymenty Helmholtza nad przewodzeniem nerwowym; 3) okres „chronometrii psychicznej” oraz 4) nowoczesne badania nad głęboką strukturą języka oraz nad złożonością procesów myślowych.
1. W roku 1796 asystent Królewskiego Astronoma został zwolniony ze swej posady w obserwatorium w Greenwich, ponieważ stale rejestrował moment przejścia gwiazdy przez południk o około 1 sekundę później niż sam Astronom Królewski. Nie przywiązywano dużej uwagi do tej rozbieżności aż do roku 1819, kiedy to niemiecki astronom Bessel zainteresował się takimi „błędami” w obserwacji. Porównał on starannie swoje własne sprawozdania o tranzytach gwiazd ze sprawozdaniami innych astronomów i wykazał, że istnieją stałe różnice pomiędzy ludźmi pod względem czasu, w jakim według nich zachodzą te zjawiska. Bessel wyraził te różnice w postaci równania. Na przykład różnica między obserwacjami Walbecka (innego astronoma) a jego własnymi była następująca:

W (Walbeck) - B (Bessel) = 1,041 s

W rezultacie zjawisko stałych zależności między obserwacjami nazwano |równaniem |osobistym („personal equation”). Pojęcie to, będąc jednym z pierwszych efektów systematycznych badań nad |różnicami |indywidualnymi w zachowaniu, jest prekursorem pojęcia cech osobowości stosowanego dla wyjaśnienia różnic w reakcjach ludzi znajdujących się w tej samej sytuacji.
2. Przed rokiem 1850 uczeni byli przekonani, że impulsy błyskawicznie przebiegają wzdłuż nerwów. Jednakże w tym właśnie roku Helmholtz wykazał: a) że przewodzenie nerwowe wymaga pewnego czasu oraz b) że czas ten można zmierzyć. W swych eksperymentach nad nerwami czuciowymi (omówionymi w Rozdziale 2) Helmholtz wymierzał słaby wstrząs elektryczny najpierw w duży palec stopy człowieka, a później w jego udo. Różnica między czasem reakcji tego człowieka na te dwa bodźce stanowiła miarę szybkości przewodzenia w nerwach czuciowych. Eksperymenty te były pierwszymi prawdziwymi badaniami nad czasem reakcji, jakie kiedykolwiek wykonano.
3. Gdy Helmholtz wykazał już, że upływa pewien czas pomiędzy zadziałaniem bodźca fizycznego a fizjologiczną reakcją danej osoby na ten bodziec naukowcy zaczęli myśleć o tym, że mogłoby to stanowić dobrą miarę procesów psychicznych człowieka. Od połowy ubiegłego stulecia do mniej więcej trzydziestych lat naszego wieku badano czas reakcji w różnych warunkach, posługując się różnymi odmianami aparatu pomiarowego zwanego |chronoskopem.  Jednym z głównych eksperymentatorów w tym okresie był holenderski fizjolog Donders. Wyróżnił on trzy typy czasu reakcji: a) |czas |reakcji |prostej, to znaczy pojedynczej reakcji na pojedynczy bodziec; b) |czas |reakcji |różnicowania, w sytuacji, gdy jest kilka różnych bodźców, lecz możliwa jest tylko jedna reakcja, którą wykonuje się dopiero po odróżnieniu określonego bodźca; wreszcie c) |czas |reakcji |z |wyborem, kiedy to występuje kilka różnych bodźców i możliwa jest różna reakcja na każdy z nich. Jak można by oczekiwać, trzeci z tych czasów reakcji jest dłuższy niż drugi, który z kolei jest dłuższy od pierwszego.
4. Donders wykazał, że czas reakcji zdaje się odzwierciedlać psychologiczną |złożoność danej reakcji, to znaczy określa - jak wiele procesów psychicznych musi zajść, zanim dana osoba zareaguje na bodziec.  Współcześni badacze czynią użytek z tej zasady badając charakter i złożoność procesów poznawczych. Badania takie są opisane w tym rozdziale i w innych miejscach w całej tej książce.


Myślenie za pomocą słów


Chociaż słowa prawdopodobnie nie są niezbędne w procesie myślenia i nawet czasami mogą w nim przeszkadzać, to jednak język zdaje się być pomocny w rozwiązywaniu problemów. Istotnie, niewielu z nas chciałoby spróbować myśleć bez niego. Słowa i inne symbole mogą znacznie ułatwić rozwiązywanie problemów, z którymi byłoby znacznie trudniej poradzić sobie, gdybyśmy musieli posługiwać się wyłącznie bezpośrednim manipulowaniem przedmiotami i wyobrażeniami. Opracowanie ścisłych systemów symbolicznych - na przykład algebry i rachunku różniczkowego - ogromnie zwiększyło naszą zdolność sterowania naszym środowiskiem.


W badaniach przeprowadzonych przed kilkudziesięciu laty zademonstrowano potężny wpływ, jaki język ma na nasze spostrzeganie i przypominanie. Dwom grupom badanych pokazywano te same rysunki, lecz podawano im inne nazwy przedmiotów przedstawionych na tych rysunkach. Później wszystkich badanych poproszono, aby narysowali te figury tak, jak je zapamiętali. Narysowane figury były zawsze bardziej podobne do nazywanego przedmiotu niż figury oryginalne (Carmichael, Hogan i Walter, 1932).
Język może z pewnością wpływać na nasze myślenie (jak wykazano w badaniach Carmichaela), lecz w jakim stopniu w rzeczywistości |determinuje on to, co myślimy? Problem, czy myślenie determinuje język, czy też język determinuje myślenie wzbudził duże zainteresowanie i spory wśród badaczy zajmujących się lingwistyką (Brown 1956). Czy język jest „osłonką przylegającą do konturów myśli”, czy też „formą, w którą wlewane są niemowlęce umysły”?
Głównym propagatorem koncepcji „formy” jest Benjamin Whorf, który twierdzi że wzorce językowe grupy kulturowej formują wzorce myślenia, a nawet spostrzegania dzieci wychowywanych w danej kulturze (Whorf, 1956).  Na przykład Eskimosi mają 7 nazw dla różnych rodzajów i stanów śniegu, podczas gdy ludzie mówiący po angielsku mają tylko jedną nazwę. Indianie Hopi mają jedno słowo na określenie ptaków i jedno słowo na określenie wszystkich innych rzeczy, które latają (samolot, pszczoła itd.). Whorf dowodzi, że takie różnice w rzeczownikach opisowych wpływają na różne sposoby ujmowania danego środowiska. Innymi słowy, u Eskimosa spostrzeżenia śniegu i myśli o nim są różne niż u ludzi mówiących po angielsku. Indianie Hopi myślą inaczej niż my o przedmiotach latających.
Z hipotezy Whorfa wynika kilka ważnych problemów, które niestety trudno jest rozwiązać na podstawie danych eksperymentalnych. Jednym z nich jest stare pytanie o przyczynę i skutek. Być może, przyjęty w danej kulturze sposób myślenia o jakimś zjawisku prowadzi do ukształtowania się dla niego różnych oznaczeń językowych, nie zaś odwrotnie. Ponieważ stan śniegu ma poważny wpływ na codzienne życie Eskimosów, potrzebują oni kilku terminów, aby zróżnicować go językowo, natomiast dla ludzi mieszkających w Nowym Jorku rodzaj śniegu może nie mieć żadnego istotnego znaczenia i dlatego dla nich wszelki śnieg (a nawet breja) jest po prostu „śniegiem”.
Krytycy Whorfa zakwestionowali także ideę, że istnieją rzeczywiste różnice w spostrzeganiu i myśleniu pomiędzy kulturami posługującymi się różnymi językami. Fakt, że niektórzy ludzie mają tylko jeden termin na określenie jakiegoś zjawiska nie musi oznaczać, że nie potrafią oni dostrzec różnic w obrębie tego zjawiska. Dzieci w Nowym Jorku mają tylko jeden termin na określenie śniegu, lecz z łatwością potrafią powiedzieć, jaki rodzaj śniegu jest dobry do lepienia śnieżek, a jaki się do tego nie nadaje. Podobnie narciarze są bardzo wrażliwi na warunki śniegowe i potrafią rozróżniać pomiędzy mokrym śniegiem, śniegiem puszystym, śniegiem zlodowaciałym itd., nawet jeśli nie dysponują całkowicie różnymi słowami dla określenia każdego z tych rodzajów śniegu.


Znaczenie jakiejś formy językowej w określonej kulturze może wpływać na przyjęty w niej sposób kategoryzowania zjawisk, lecz nie na sposób, w jaki zjawiska te są rzeczywiście spostrzegane.


„Osoby badane, mówiące językiem Navaho i mówiące po angielsku, poproszono, aby dzieliły osiem kolorowych żetonów na grupy, na podstawie nazw, jakie eksperymentator nadawał każdemu z żetonów. Następnie eksperymentator zaczynał nazywać cztery z tych żetonów „ma”, a pozostałe cztery „mo”. Jednakże w wypadku dwóch żetonów „ma” i dwóch żetonów „mo” nazwy były wymawiane z długimi samogłoskami, podczas gdy w pozostałych samogłoski te były krótkie. Taka zmiana w długości samogłosek nie stanowi zmiany fonemu w języku angielskim, lecz w języku Navaho długie i krótkie samogłoski są dwoma różnymi fonemami. W rezultacie badani mówiący językiem Navaho dzielili żetony na cztery grupy (maa, ma, moo, mo), podczas gdy badani mówiący po angielsku dzielili je tylko na dwie grupy (ma, mo). Wielu badanych mówiący po angielsku podało, że zauważyli oni niewielkie różnice w długości samogłosek, lecz uważali je za nieistotne dla tego zadania” (Brown, 1956).


Spór „osłonka czy forma” nie został rozwiązany w ten ani inny sposób, lecz wydaje się, że bez wielkiego ryzyka można powiedzieć iż język i myśl wpływają na siebie nawzajem. Myśli są niewątpliwie „kształtowane” przez język, lecz z pewnością nie w takim stopniu, jaki postuluje Whorf.




Myślenie za pomocą
„bezgłośnej mowy”




Myślimy obrazami, myślimy symbolami, myślimy słowami, lecz czy myślimy również za pomocą niewerbalnych reakcji mięśniowych? Takie pytanie wydaje się śmieszne, dopóki nie przeformujemy go następująco: „Czy istnieją dane świadczące o tym, że myśleniu towarzyszy |utajone („covert”) |zachowanie |oralne - aktywność elektryczna w mięśniach używanych przy mówieniu?”
Materiał dowodowy z wielu badań przeprowadzonych w tej dziedzinie (które podsumował McGuigan, 1973) prowadzi do wniosku, że utajone reakcje oralne istotnie występują w sposób regularny w różnych sytuacjach związanych z językiem. Zjawiska wewnętrzne, które uważa się za wskaźniki „procesów myślowych” wywoływanych przez zewnętrzne bodźce językowe, mierzy się przy użyciu elektroencefalografu (EEG) w wypadku zjawisk zachodzących w ośrodkowym układzie nerwowym, przy użyciu elektromiografu (EMG) w wypadku reakcji mięśniowych, takich jak ruchy warg, języka i podbródka oraz przy użyciu takich miar aktywności autonomicznego układu nerwowego, jak zwężanie się źrenic i funkcjonowanie serca.
Wyniki uzyskane w czasie badania dzieci, wskazują, że gdy dzieci czytają po cichu, to poruszają wargami, ich tempo oddychania wzrasta, a ponadto wydają one dźwięki subwokalne (które można mierzyć jedynie po silnym ich wzmocnieniu). Takie same wyniki stwierdzono później u studentów wyższych uczelni, którzy czytali po cichu, starając się zapamiętać fragmenty prozy.  Aktywność taka zdaje się być związana z mechanizmem mowy. McGuigan dochodzi do wniosku, że „zjawiska te są zupełnie powszechne u ludzi biegle władających danym językiem” (1973, s. 351).


Jeszcze bardziej interesujące są niedawno uzyskane dane potwierdzające, że gdy ludzie mają sny o treści konwersacyjnej (w przeciwieństwie do snów wizualnych, niejęzykowych), to nasilają się u nich znacznie reakcji mięśni w okolicy warg i podbródka (McGuigan i Tanner, 1971). Także wtedy, gdy u osób badanych wywoływano hipnotyczne sny różnego rodzaju, wówczas w wypadku snów o treści oralnej następował znaczny wzrost utajonej aktywności oralnej, którego nie stwierdzono w wypadku snów o „odprężeniu” i aktywności fizycznej”.


Na podstawie wyników badań, w których zmieniano charakter zadań z zakresu przetwarzania informacji przez badanych i mierzono ich utajnione zachowanie oralne, wyciągnięto wniosek, że taka bezgłośna mowa ułatwia proces myślenia. Gdy John Watson powiedział, że „myślimy całym naszym ciałem” to mógł on mieć słuszność o tyle, że na pobudzające do myślenia bodźce językowe reagujemy uogólnionymi reakcjami autonomicznymi i mięśniowymi.




Sprzężenie zwrotne
i serwomechanizmy




Znaczna liczba danych eksperymentalnych wskazuje, że we wszelkiego rodzaju zadaniach, osoby które znają swoje postępy, będą uczyć się szybciej niż równie motywowane osoby o podobnych zdolnościach, które pracują na „ślepo” (Ammons, 1956). Psychologowie zwykli zastępować termin |znajomość |wyników bardziej ogólnym wyrażeniem |psychologiczne |sprzężenie |zwrotne (Brown, 1949). Psychologiczne sprzężenie zwrotne jest procesem, dzięki któremu jednostki uzyskują informacje dotyczące poprawności ich poprzednich reakcji, po to, by mogły zmieniając swoje zachowanie, skompensować uprzednio popełnione błędy. Sprzężenie zwrotne jest zatem niezbędne nie tylko w wypadku motorycznego uczenia się nowych ruchów lecz także przy wykonywaniu każdej zintegrowanej sekwencji czynności ruchowych.


Funkcje i rodzaje sprzężenia zwrotnego. Sprzężenie zwrotne spełnia trzy dające się wyodrębnić funkcje: a) dostarcza |informacji zarówno o wynikach danej reakcji, jak i o jej właściwościach (czasowych, przestrzennych, o jej kierunku, poziomie intensywności i tak dalej) b) dostarcza dodatniego lub ujemnego |wzmocnienia w zależności od poprawności reakcji, c) dostarcza |motywacji do kontynuowania zadania, pomagając uczynić świat i własne zachowanie przewidywalnym i potencjalnie podatnym na sterowanie.
Sprzężenie zwrotne może należeć do dwóch ogólnych kategorii: 
|wewnętrznych |sprzężeń |zwrotnych lub |zewnętrznych |sprzężeń |zwrotnych.  Gdy cię poproszę, abyś dość szybko liczył głośno od jednego do stu, to na podstawie dźwięku własnego głosu (który wraca do twych uszu) wiesz, w którym momencie tego szeregu znajdujesz się w danym momencie. Wewnetrzne są również sygnały kinestetyczne dostarczające informacji, która kieruje szybkością ruchu i położeniem naszych członków. Jeśli jednak zamkniesz oczy i spróbujesz dotknąć czubka nosa innej osoby, która będzie ci mówić „zimno, zimno, ciepło, ciepło”, to wtedy będziesz się posługiwać zewnętrznym sprzężeniem zwrotnym; innymi słowy, twoje własne wewnętrzne wrażenia mięśniowe będą wspomagane przez sygnały z zewnątrz.
Ponieważ wewnętrzne sprzężenie zwrotne tak dobrze funkcjonuje w zwykłych warunkach, przeto zupełnie nie zdajemy sobie sprawy z tego, że w ogóle go używamy. Aby badać nasze uzależnienie od sprzężenia zwrotnego oraz wpływ różnych zmiennych na jego funkcjonowanie, badacz musi znaleźć jakiś sposób jego |zakłócenia. Informacja przychodząca przez kanały wzrokowe lub słuchowe okazała się łatwa do zakłócenia w kontrolowanych warunkach laboratoryjnych, przy zastosowaniu specjalnie skonstruowanych aparatów, które opóźniają dopływ sygnałów wzrokowych lub słuchowych.
„Jeśli nie mogę słyszeć tego, co mówię, to nie potrafię normalnie myśleć” - tego rodzaju odpowiedź daje wielu badanych, gdy starają się wyjaśnić niektóre swe myśli w czasie eksperymentu, w którym wywołuje się opóźnienie słuchowego sprzężenia zwrotnego. Wydaje się to dziwne, ponieważ zwykliśmy uważać myśl za przyczynę mowy, a nie na odwrót. W jaki sposób skutek może wpływać na swą przyczynę? Może to czynić wtedy, gdy przyczyna i skutek nie są związane ze sobą jednokierunkowo, lecz są częścią bardziej złożonego układu zwanego serwomechanizmem.
Wpływ słuchowego sprzężenia zwrotnego bada się wydłużając odstęp czasu między wypowiedzeniem jakiegoś dźwięku a usłyszeniem go. Badani zamiast słyszeć słowa, dopiero co wypowiedziane przez siebie, za pośrednictwem przewodzenia dźwięków przez powietrze (jak to się dzieje normalnie), słyszą je poprzez słuchawki z pewnym opóźnieniem.
Skutki takiego opóźnienia mierzy się w postaci zmian występujących w mowie osób badanych - w jej natężeniu, czasie trwania zdania, podstawowej częstotliwości dźwięków mowy („fundamental speech frequency”), zrozumiałości, artykulacji oraz napięciu emocjonalnym (Smith, 1962; Yates, 1963). W warunkach, w których opóźnienie trwa około 1/5 s mowa jest zaburzona najbardziej - niektórzy ludzie w ogóle nie potrafią mówić.
Opóźnienie ma najbardziej zakłócający wpływ wówczas, gdy sprzężenie 
zwrotne jest głośne i gdy materiał jest ściśle zorganizowany w części 
nawzajem od siebie zależne, jak w przypadku śpiewania, gwizdania jakiejś 
melodii czy też deklamowania limeryku, który wymaga „łamania sobie języka”




* * *



Ryc. 5.11. Śledzenie Ruchowe (Odwzorowywanie) Z Opóźnionym Wzrokowym Sprzężeniem Zwrotnym. Rysunek u dołu przedstawia aparaturę magnetowidową stosowaną dla wprowadzenia opóźnienia czasowego w zachowaniach polegających na odwzorowaniu gwiazdy i pisaniu listy słów. W górnej części rysunku pokazano efekty pracy jednego z badanych. Rysunki w pierwszej kolumnie wykonywał on w warunkach normalnych, w kolumnie drugiej - przy zastosowaniu monitora TV, lecz bez opóźnienia, w kolumnie trzeciej przy użyciu monitora TV przekazującego obraz z opóźnieniem. Opóźnienie takie stwarza dla koordynacji wzrokowo-ruchowej przeszkodę nie do pokonania.


* * *





Opóźnienia, które są krótsze lub dłuższe niż 1/5 s działają mniej zakłócająco. Adaptacja czy poprawa w miarę trwania ćwiczenia jest bardzo niewielka, chociaż nie przeprowadzono badań nad wpływem długotrwałego ćwiczenia.


Model serwomechanizmu. Jak już przekonaliśmy się, zachowanie to nie tylko sekwencja zdarzeń - dla płynnego rozwijania się tej sekwencji potrzebne jest sprzężenie zwrotne od zdarzeń zakończonych i zachodzących aktualnie - dlatego też |serwomechanizm (będący ukierunkowaną na cel wrażliwą na błędy, samokorygującą się maszyną) stał się użytecznym modelem sekwencji „myśl-działanie”, charakterystycznych dla żywych organizmów. W serwomechaniźmie występują cztery podstawowe procesy: wejście, przetwarzanie, wyjście i sprzężenie zwrotne.
„Obróbka” wejścia, integrowanie i organizowanie przetwarzania ukierunkowanie wyjścia oraz wykorzystywanie sprzężenia zwrotnego od uprzedniego i aktualnego wyjścia - wszystko to są części procesu psychicznego zwanego „myśleniem”.


Wyobraź sobie na przykład, że właśnie grasz w szachy. Twoje procesy myślowe można opisać w kategoriach następujących operacji:
1. |Obróbka |wejściowa - zauważasz ruch, który właśnie zrobił twój przeciwnik, oraz bezpośrednie zagrożenia, jakie stwarza on dla twoich pionków i figur.
2. |Integrowanie |i |organizowanie |przetwarzania - ustalasz, co powstała obecnie pozycja oznacza z punktu widzenia sytuacji na całej szachownicy i oceniasz możliwe ruchy.
3. |Ukierunkowanie |wyjścia - decydujesz się na swój następny ruch i wykonujesz go.
4. |Wykorzystywanie |sprzężenia |zwrotnego - obserwujesz nową sytuację na szachownicy oraz reakcję twojego przeciwnika na nią.


Powyższe elementy myślenia pokrywają się w pewnym stopniu i nie można ich całkowicie od siebie oddzielić. Można jednak wykazać, że wszystkie one wymagają czasu. Czas reakcji nie jest zatem, jak niegdyś uważano, czasem niezbędnym do zrealizowania jednego tylko pojedynczego procesu. Nie możemy też posługiwać się modelem myślenia nie uwzględniającym wielorakich kanałów sprzężenia zwrotnego, jak również złożonych serwomechanizmów, za pomocą których wyjście nieustannie kieruje wejściem, które z kolei steruje wyjściem, dając w ten sposób początek procesom myślowym.




Rozumowanie




Wspomnieliśmy poprzednio, że myślenie zawiera się między dwiema skrajnościami - myśleniem autystycznym i myśleniem realistycznym. Myślenie autystyczne - fantazje, marzenia i myślenie życzeniowe - stosuje się głównie dla celów autogratyfikacji i spełnienia w wyobraźni swych pragnień.  Myślenie autystyczne jest charakterystyczne dla „marzycieli” - osób, które spędzają wiele czasu w świecie fantazji i marzeń na jawie. Jeszcze bardziej skrajna postać myślenia autystycznego występuje w wielu typach zaburzeń umysłowych.


Myślenie realistyczne, czyli |rozumowanie, w przeciwieństwie do myślenia autystycznego pomaga nam przystosować się do otaczającej rzeczywistości.  Myślenie takie motywowane jest często przez potrzebę znalezienia rozwiązań dla problemów dotyczących środków egzystencji czy wręcz utrzymania się przy życiu. Można je także uprawiać dla czystej przyjemności, jak to czyni na przykład gracz w szachy czy miłośnik krzyżówek.




Typy rozumowania




Ogólnie biorąc w rozumowaniu występują trzy różne procesy: |dedukcyjny, |indukcyjny i |oceniający (ewaluacyjny). |Rozumowanie |dedukcyjne polega w zasadzie na zestawianiu ze sobą faktów. Dana osoba łączy fragmenty wiedzy uzyskane uprzednio w różnych  okolicznościach lub wyciąga wnioski, które wynikają z dostępnych danych. W zasadzie myślenie to zmierza ku poprawnej odpowiedzi, która jest zawarta w danych.
Przykładami rozumowania dedukcyjnego są sylogizmy, które stosuje się do reguł logiki arystotelesowskiej. Gdy dane są przesłanki P1 i P2 wówczas wynika z nich jeden i tylko jeden |poprawny wniosek. Niewątpliwie posługiwałeś się takim rozumowaniem ucząc się geometrii. Jeśli wniosek nie został wyprowadzony zgodnie z zasadami logiki, wówczas sylogizm jest |niepoprawny, na przykład:


Sylogizm poprawny
P1: Wszystkie „A” są „B”,
P2: Wszystkie „B” są „C”,
A zatem, wszystkie „A” są „C”.


Sylogizm niepoprawny
P1: Wszystkie „A” są „B”,
P2: Wszystkie „C” są „B”,
A zatem, wszystkie „A” są „C”.


|Poprawności sylogizmu nie należy mylić z |prawdziwością jego wniosku.  Sylogizm może być poprawny, lecz wynikający zeń wniosek - fałszywy (jeśli opiera się na fałszywych przesłankach) lub też wniosek może być prawdziwy, lecz nie wynikający logicznie z przesłanek - w tym wypadku sylogizm jest niepoprawny.
Jednakże dla wielu problemów nie ma jednej poprawnej odpowiedzi, a rozwiązania wymaganego przez sytuację nie można uzyskać zestawiając po prostu ze sobą dostępne dane. Rozwiązujący musi dodać coś nowego, a właściwe może być przecież więcej niż jedno rozwiązanie. Taka sytuacja wymaga |rozumowania |indukcyjnego, w którym rozwiązujący przechodzi od znanego do nieznanego. Wymaga to dokonywania intuicyjnego przeskoku w celu sformułowania nowej hipotezy dotyczącej tego, co mogą ujawnić przyszłe obserwacje lub w celu zasugerowania kilku nowych kierunków badania. Jest to sama istota myślenia twórczego, zarówno w nauce jak i w sztuce. W przeciwieństwie do rozumowania dedukcyjnego, w którym zawsze przechodzi się z ogólnych przesłanek do szczegółowych wniosków, rozumowanie indukcyjne może potencjalnie prowadzić w każdym z kilku możliwych kierunków, chociaż zawsze przechodzi się od szczegółowych przypadków do bardziej ogólnego wniosku. Wniosek nie jest zatem całkowicie przewidywalny na podstawie dostępnego materiału dowodowego.
Trzecim rodzajem rozumowania jest |rozumowanie |oceniające, czyli |ewaluacyjne - oceniające słuszność lub poprawność jakiejś idei czy wytworu. Myślenie krytyczne ma charakter ewaluacyjny - polega ono na ocenianiu przydatności, wartości czy efektywności jakiejś idei, w odróżnieniu od prób jej stworzenia czy rozwinięcia. Poprawność rezultatu zależy nie tylko od samego procesu rozumowania - to jest oceniania - lecz także od zastosowanego wzorca czy kryterium. Jeśli wzorzec jest niepoprawny, wówczas rozwiązanie uznane za „właściwe” może nie pasować do rzeczywistych wymagań sytuacji.




Rozwiązywanie problemów




Gdy znajdziesz się w nowej sytuacji, w której jesteś motywowany do osiągnięcia pewnego celu, lecz droga do niego jest zablokowana przez pewną przeszkodę, z którą nie potrafisz sobie od razu poradzić, wówczas stajesz wobec |problemu (i wobec sytuacji potencjalnie frustrującej). Rozwiązanie tego problemu wymaga opracowania pewnego sposobu postępowania, który wyeliminuje przeszkodę. Ponieważ frustracja jest w życiu nieunikniona, w twoim zachowaniu (w wielu wypadkach) musi występować aktywność określona jako rozwiązywanie problemów.


Uczenie się i wgląd. Jak pamiętamy z Rozdziału 3, u kotów Thorndike’a występowało zachowanie typu prób i błędów, zanim w końcu udało im się uciec ze skrzynek problemowych. Wyniki tego badania sugerowały, że rozwiązywanie problemów polega bardziej na uczeniu się niż myśleniu - inaczej mówiąc zwierzę nie rozpoznaje nagle poprawnej reakcji, lecz stopniowo uczy się właściwego zachowania. Wolfgang Kohler, jeden z wybitnych reprezentantów psychologii postaci, nie zgodził się z tym poglądem, argumentując, że eksperyment Thorndike’a nie nadawał się do badania rozwiązywania problemów, ponieważ kot nie mógł posłużyć się przewidywaniem i planowaniem w rozwiązywaniu problemu. Mechanizm otwierający drzwiczki był umieszczony poza polem widzenia zwierzęcia, tak, że nie mogło ono „wyobrazić sobie”, w jaki sposób drzwiczki działają. Ponadto poprawna reakcja (manipulowanie klamką drzwiczek) była tak mało podobna do zwykłych ruchów zwierzęcia, że prawdopodobnie mogło ono odkryć ją tylko przypadkowo, a nie przez „rozumowanie”.



Kohler podjął próbę przezwyciężenia tych trudności umieszczając zwierzę w sytuacjach problemowych, w których wszystkie „materiały” niezbędne do rozwiązywania problemu były wyraźnie widoczne. W słynnej serii jego eksperymentów z małpami problem stawiany przed zwierzęciem polegał na uzyskaniu pokarmu umieszczonego poza jego zasięgiem. Na przykład, kosz z owocami zwisał z pułapu klatki w taki sposób, ze można było wprawić go w ruch wahadłowy, pociągając za sznurek. W pewnym punkcie łuku zakreślanego przez kołyszący się kosz znajdowała się platforma. Chociaż zwierzę nie mogło dosięgnąć kosza z podłogi, mogło złapać go, gdy kołysał się na sznurze, skacząc w górę z tej platformy.
W przeciwieństwie do kotów Thorndike’a, małpy Kohlera zdawały się odkrywać rozwiązanie nagle, zamiast wpadać na nie przypadkiem, podczas wykonywania przypadkowych reakcji. Ponadto, gdy już raz znalazły rozwiązanie, reagowały bezbłędnie we wszystkich następnych próbach, zamiast uzyskiwać w miarę upływu czasu coraz lepsze wyniki - co było charakterystyczne dla zwierząt Thorndike’a. Innymi słowy, małpy Kohlera zachowywały się zgodnie z hipotezą |nieciągłości, podczas gdy wyniki Thorndike’a przemawiały za koncepcją |ciągłości. Kohler (1926) utrzymywał, że rozwiązywanie problemów polega przede wszystkim na wglądzie i reorganizacji percepcyjnej a nie na metodzie prób i błędów.
Późniejsze badania doprowadziły do zmodyfikowania stanowiska Kohlera wykazując, że wgląd nie jest zupełnie nagłym procesem, lecz opiera się na uprzednich próbach i błędach.


„Pewien badacz umieścił pokarm poza zasięgiem szympansów tak, że mogły go one uzyskać jedynie wtedy, gdy posłużyły się motyką, aby go ku sobie przyciągnąć. Zwierzęta, które uprzednio bawiły się krótkimi kijami i stopniowo nauczyły się używać ich do kopania, popychania itp., potrafiły rozwiązać dość łatwy problem zdobycia pokarmu. Problem ten jednak okazał się zbyt trudny dla zwierząt, które nie miały tych wcześniejszych doświadczeń” (Birch, 1945).


Rozwiązywanie problemów przez ludzi jest zwykle połączeniem wglądu oraz prób i błędów. Zazwyczaj od początku mamy większy wgląd w problem niż na przykład koty w skrzynce problemowej. Większość problemów nie jest dla nas całkowicie nieznana, a ponadto między elementami naszej sytuacji problemowej istnieją zwykle pewne „naturalne” związki, podczas gdy klamka, którą trzeba było nacisnąć w skrzynce problemowej, nie pozostawała w żadnym naturalnym związku z pokarmem. Wobec tego wysuwamy prawdopodobne hipotezy na podstawie tego, co już wiemy z doświadczenia, a następnie sprawdzamy je: czy to przez działanie, czy też poprzez przemyślenie proponowanego rozwiązania (|ukryte próby i błędy). Gdy widzimy rezultaty tych prowizorycznych rozwiązań, wówczas nasz wgląd staje się coraz lepszy i nasze późniejsze hipotezy coraz lepiej odpowiadają wymaganiom, jakie musi spełniać rozwiązanie - aż wreszcie znajdujemy je. Rzadko rozwiązujemy problem nie wypróbowując pewnych alternatywnych możliwości; a ostateczne znalezienie rozwiązania świadczy samo przez się o uzyskaniu pewnego wglądu w ważne związki. Nawet zachowanie kotów w skrzynce problemowej świadczyło o tym, gdyż w końcu szły one prosto do klamki. Ponadto ich wcześniejsze próby przegryzienia prętów lub przeciśnięcia się między nimi nie były całkowicie przypadkowymi ruchami.


Pułapki napotykane przy rozwiązywaniu problemów. Rozwiązywanie problemów polega zwykle na poszukiwaniu pewnej zasady, która będzie służyć jako ogólna reguła umożliwiająca organizowanie poszczególnych przypadków.  Poszukiwanie takie jest procesem indukcyjnym, w którym generuje się dane, formułuje i sprawdza hipotezy i w końcu odkrywa się zasadę (Wason, 1971).  Możemy nauczyć się wiele o rozwiązywaniu problemów, a także o pewnych ograniczeniach, jakie nakładamy sami na naszą własną zdolność rozwiązywania problemów, jeśli spróbujemy rozwiązać pewien pozornie prosty problem. Opis badania Wasona podajemy niżej:




Zbliżenie


Odkrywanie zasady za pomocą rozumowania


„Trzy liczby: 2, 4, 6 stosują się do pewnej prostej zasady określającej relacje między nimi. Zadanie polega na odkryciu tej zasady przez generowanie innych zbiorów złożonych z trzech liczb. Badanym mówiono, czy zbiory generowane przez nich są poprawne (+), czy niepoprawne (-). Poniżej podano fragmenty |protokołów dotyczących dwóch badanych w eksperymencie Wasona (1971, ss. 207 - 208). Przekonaj się, czy potrafisz odkryć tę zasadę na podstawie podawanego im sprzężenia zwrotnego.


|Protokół |I


Badany: 8, 10, 12 (+); 7, 9, 11 (+); 7, 5, 3 (-); 13, 26, 28 (+); 8, 16, 18 (+); 49, 58, 100 (+); 8, 13, 15 (+); 1, 2031, 2033 (+).
Zasada jest następująca: pierwsza i druga liczba są przypadkowe, a trzecia jest równa drugiej plus dwa.
Eksperymentator: To nie jest zasada, o którą mi chodzi. Proszę kontynuować zadanie.
Badany: 7, 5, 7 (-); 1, 5, 7 (+); 5, 5, 7 (-); 4, 5, 7 (+); 9, 5, 7 (-); 
263, 364, 366 (+). Zasada jest następująca: pierwsza i druga liczba są przypadkowe, lecz pierwsza jest mniejsza od drugiej, a trzecia jest równa drugiej plus dwa.
Eksperymentator: To nie jest zasada, o którą mi chodzi. Proszę kontynuować zadanie.
Badany: 261, 263, 101 (-); 3, 17, 17 (-); 51, 53, 161 (+); 671, 671, 3 (-); 671, 673, 900 (+); 42, 43, 45 (+); 41, 43, 42, (-); 41, 43, 67,(+); 
67, 43, 45 (-). Zasada jest następująca: druga liczba jest przypadkowa, i albo pierwsza liczba równa się drugiej minus dwa, a trzecia jest przypadkowa, lecz większa od drugiej, albo też trzecia liczba równa się drugiej plus dwa a pierwsza jest przypadkowa, lecz mniejsza od drugiej.
Eksperymentator: To nie jest zasada, o którą mi chodzi. 
(Badany zrezygnował po 50 minutach).


|Protokół |2


Badany: 4, 6, 8 (+); 6, 8, 10 (+). Zasada jest następująca: dodaje się dwa do pierwszej liczby i dwa do drugiej.
Eksperymentator: To nie jest zasada, o którą mi chodzi. Proszę kontynuować zadanie.
Badany: 8, 10, 12 (+). Zasada jest następująca: jest to postęp arytmetyczny parzystych liczb całkowitych.
Eksperymentator: To nie jest zasada, o którą mi chodzi. Proszę kontynuować zadanie.
Badany: 13, 15, 17 (+). Zasada jest następująca: jakiekolwiek trzy dodatnie liczby całkowite.
Eksperymentator: To nie jest zasada, o którą mi chodzi. Proszę kontynuować zadanie.
Badany: 3, 5, 7 (+). Zasada jest następująca: są to jakiekolwiek trzy liczby.
Eksperymentator: To nie jest zasada, o którą mi chodzi. Proszę kontynuować zadanie.
Badany: - 11, 0,999, 2287 (+). Zasada jest następująca: są to jakiekolwiek trzy liczby z modyfikującymi je znakami lub bez nich.
Eksperymentator: To nie jest zasada, o którą mi chodzi. Proszę kontynuować zadanie.
Badany: 8, 6, 4 (-)...
W tym miejscu Badany 2 zdołał sformułować poprawną zasadę. Czy |ty potrafisz ją sformułować? Napisz ją tutaj:


Tylko 21% badanych w eksperymencie Wasona odkryło tę zasadę, nie podając przedtem niepoprawnych sformułowań. Jak sądzisz, dlaczego pozostałe 79% badanych miało tyle trudności z rozwiązaniem tego problemu? Dlaczego formułowałeś niepoprawne zasady (jeśli oczywiście to czyniłeś)?
Przeanalizowanie |procesu, w wyniku którego odkrywano tę zasadę, wyjaśnia niektóre pułapki i przeszkody utrudniające skuteczne rozumowanie. Protokoły wykazały, że „wyjątek potwierdza (to jest pozwala sprawdzić) regułę”. Same potwierdzające przypadki nie wystarczą; przypadki negatywne są również potrzebne. Możemy także przekonać się, jak łatwo przeoczyć proste rozwiązanie, gdy usiłujemy sformułować zbyt złożone hipotezy lub niepotrzebne precyzyjne stwierdzenia.
Wason stwierdził także, że badani byli skłonni pokładać zbyt wiele wiary w swe hipotezy, starając się weryfikować je, zamiast oceniać. W niektórych wypadkach to dogmatyczne podejście prowadziło do samooszukiwania się; badani błędnie odbierali lub racjonalizowali sprzężenie zwrotne, które było sprzeczne z proponowanym przez nich rozwiązaniem.
Problemy stosowane w badaniach tego typu nie wiążą się z emocjami, wartościami i poważnymi konsekwencjami osobistymi, które wchodzą w grę przy rozwiązywaniu problemów w życiu realnym. Oddziaływania takie mogą tylko powiększyć trudności, jakie napotykamy przy wyszukiwaniu obiektywnych rozwiązań naszych problemów. Możemy zatem zbliżyć się niebezpiecznie do opisanego przez Craika (1943) typu myślenia patologicznego, w którym „pewną formę adaptacji (...) osiąga się przez ograniczanie i zniekształcanie środowiska, dopóki własne postępowanie nie będzie się wydawało dostosowane do niego, zamiast przez zmienianie własnego postępowania i wzbogacanie wiedzy, dopóki sami nie będziemy w stanie uporać się z realnym środowiskiem” (s. 91).




Wykorzystywanie komputerów
w badaniach nad myśleniem




Dotychczas omówiliśmy wiele czynników, które wpływają na myślenie. Lecz cóż z rzeczywistym |przetwarzaniem informacji? W jaki właściwie sposób mózg syntetyzuje i przekształca informacje w trakcie myślenia i rozwiązywania problemów? Ostatnio wprowadzono modele służące do wyjaśnienia tego procesu, opisują one przepływ informacji w układzie nerwowym nie w kategoriach struktury neurofizjologicznej, lecz w kategoriach programów komputerowych.
Ta koncepcja przetwarzania informacji jest jednym z najbardziej fascynujących osiągnięć w badaniu procesów poznawczych i stwarza pomyślne perspektywy na przyszłość. Zastosowanie programów komputerowych wymaga definiowania poszczególnych kroków sekwencji przetwarzania informacji w kategoriach wyraźnych, ścisłych i precyzyjnych, wykluczając posługiwanie się niejasnymi ogólnikami. Taką sekwencję można przedstawić w postaci |schematu |działań, czyli |algorytmu (ryc. 5.15). Bloki prostokątne oznaczające kroki czynnościowe - komputer otrzymuje polecenie aby coś wykonał. Blok owalny oznacza |krok |decyzyjny - komputer musi odpowiedzieć „tak” lub „nie”. W tym przypadku, za każdym razem, gdy odpowiedź brzmi „nie”, komputer musi wykonać |pętlę, powtarzając tę samą sekwencję kroków tak długo, dopóki napływają dane do przetwarzania. Schematy działań są jedynie reprezentacjami wizualnymi; rzeczywisty |program jest to zbiór zakodowanych krok po kroku instrukcji które wprowadza się do komputera.




* * *



Ryc. 5.15. Schemat działań obrazujący kolejne kroki w hipotetycznym programie komputerowym służącym do obliczania średniej („average”) szeregu liczb. Każdą liczbę, która ma być przetworzona, wprowadza się na karcie perforowanej. SUM reprezentuje komórkę pamięciową komputera, która służy jako tymczasowa przestrzeń robocza („working space”). IND oznacza liczbę wskaźnikową („index number”), która określa, ile liczb umieszczonych na kartach zostało już dodanych. Komputer zgodnie z programem odczytuje liczbę (x) z każdej karty w zbiorze, powiększając IND o 1 za każdym razem, kiedy to czyni. Gdy informacja zawarta na ostatniej karcie w zbiorze została przetworzona, komputer oblicza średnią liczbę (dzieląc SUM przez IND) i drukuje wynik (AVE).


* * *







Czy komputery
są inteligentne?




Dlaczego psychologowie interesujący się procesami myślenia u ludzi zaczęli korzystać z komputerów? Wydaje się, że inspiracją był tu artykuł angielskiego matematyka Turinga (1950), w którym postawił on pytanie „Czy maszyny mogą myśleć?”. Argumentował on, że nasza odpowiedź musiałaby brzmieć „tak”, gdyby sędzia-człowiek nie potrafił odróżnić reakcji wyjściowych komputera od reakcji człowieka. Turing zaproponował grę, w której sędzia mógłby się komunikować z komputerem i z człowiekiem tylko za pośrednictwem dalekopisu. Zadawałby im takie pytania, jakie by chciał, a następnie starałby się ustalić, który dalekopis był obsługiwany przez człowieka, a który przez komputer. Nievergelt i Farrar (1973) wykazali, że komputer zdolny do „wygrania” tej gry musiałby łączyć odrębne zdolności konwersacyjne: musiałby on rozumieć znaczenie twierdzenia czy pytania niezależnie od sposobu sformułowania i musiałby umieć formułować możliwe do przyjęcia twierdzenia, nawet gdyby nie miał dostatecznych danych do udzielenia kompletnej odpowiedzi. Większość dotychczas opracowanych programów koncentrowała się na pierwszej lub drugiej z tych zdolności, lecz nie na obu jednocześnie.
Pierwszym poważnym systemem komputerowym, któremu można było przypisywać „inteligencję”, był „Logik-teoretyk”, opracowany w celu znajdowania dowodów twierdzeń logicznych (Newell, Shaw i Simon, 1958). W jednej z prób „Logik-teoretyk” potrafił dowieść 38 spośród pierwszych 52 twierdzeń zawartych w pracy Whiteheada i Russella - „Principia Mathematica”. Oprócz pewnych procedur rozwiązywania problemów, program „Logika-teoretyka” obejmował kilka zasad praktycznych czyli |heurystyk, którymi posługują się ludzie. Jedną z takich heurystyk jest na przykład „posuwanie się wstecz” od twierdzenia, którego należało dowieść. „Logik-teoretyk” opracował kilka twierdzeń, z których każde implikowało twierdzenie dowodzone, a następnie sprawdzał, czy któreś z tych twierdzeń można było wydedukować z początkowych „danych”. „Logik-teoretyk” w swym zachowaniu wykazywał wiele cech „ludzkich”, takich jak przykłady nagłego „wglądu” w rozwiązywanie problemu. Z tej przyczyny jego twórcy argumentowali, że taki system można rzeczywiście uważać za |model ludzkiego myślenia, ponieważ zdawał się on symulować ludzkie procesy poznawcze.
Implikacje symulacji komputerowej dla badań nad rozumowaniem zafascynowały wielu psychologów, którzy dysponowali umiejętnościami programowania komputerowego i interesowali się nim. Po pojawieniu się „Logika-teoretyka” opracowano bardzo wiele programów starając się, by rozwiązywały one problemy w taki sam sposób, jak czynią to ludzie. Na przykład Gelernter (1960) napisał program, który posługiwał się wykresami przy rozwiązywaniu zadań geometrycznych. Programowano także komputery tak, aby grały w różne gry z przeciwnikiem. Program grający w warcaby Samuela (1967) uzyskał doskonałe wyniki pokonując mistrzów gry w warcaby.  Natomiast program grający w szachy znajduje się jeszcze w stadium rozwojowym. Najlepszy program, który istniał w końcu lat sześćdziesiątych (Greenblatt, Eastlake i Crocker, 1967) potrafił grać nieźle w szachy, lecz przegrywał z dobrymi zawodnikami. Badacze z University of Southern California opracowali ostatnio program gry w szachy „korzystający z rad”, który potrafi uczyć się na swoich błędach; jego nauczycielem jest mistrz Charles Kalme (Zobrist i Charlson, 1973). Gra w szachy stanowi idealną sytuację dla symulowania i badania ludzkich procesów myślowych. Zarówno możliwe operacje (ruchy), jak i ostateczny cel (mat) są ściśle określone, natomiast strategie niezbędne dla osiągnięcia tego celu wymagają wysokiego poziomu analizy i abstrakcji.




Czy komputery mogą być
tak uniwersalne
jak ludzki mózg?




Psychologowie szybko zdali sobie sprawę z tego, że program komputerowy, który potrafi rozwiązywać zadania geometryczne, lecz nie potrafi grać w szachy, nie jest w rzeczywistości właściwym modelem ludzkiego mózgu, który potrafi wykonywać obydwie te czynności. Przypuszczalnie ludzie posługują się tymi samymi procesami intelektualnymi dla rozwiązywania wszelkich problemów - a nie innymi w wypadku szachów, a innymi w wypadku problemów logicznych. Czy można by opracować uniwersalny model komputera, który potrafiłby się uporać z szerokim zakresem różnych problemów - bez względu na charakter ich treści? Najbardziej ambitną próbą zmierzającą w tym kierunku jest „Uniwersalny Rozwiązywacz Problemów” („General Problem Solver” - GPS) opracowany przez Nevela, Shawa i Simona (1960). Jest to wysoce skomplikowany system, który obejmuje wielką liczbę pojęć, strategii i heurystyk uważanych za podstawę rozwiązywania problemów przez ludzi.  Można mu podać pewne wstępne przesłanki, pewien cel i pewne reguły przekształcania, a następnie program ten przekształci przesłanki w cel stosując się do tych reguł. Jednakże do pewnych typów problemów GPS okazał się nieodpowiedni i ciągle brak jeszcze uniwersalnego supersystemu wymarzonego przez Turinga.
Idee i techniki przetwarzania informacji stosuje się także w badaniu procesów psychologicznych innych niż rozwiązywanie problemów takich na przykład, jak uczenie się werbalne i rozpoznawanie form. „Maszyna Ideologiczna” („Ideological Machine”) Abelsona i Carrola (1965) próbuje symulować stabilne struktury przekonań społecznych czy politycznych jednostki. Programuje się komputery symulujące osobę neurotyczną (Colby, 1965), a także spełniające rolę psychoterapeuty (Colby, Watt i Gilbert, 1966). Rozmowę jednego z autorów niniejszej książki z komputerowym „terapeutą” reprodukujemy poniżej, jego rozmowę z paraidonalnym „pacjentem” komputerowym przytaczamy w Rozdziale 11.




Zbliżenie


„Doktor od wariatów”


„Czy komputer może pomóc ci w rozwiązywaniu twoich kłopotów osobistych?  Przykłade jego zdolności terapeutycznych jest przedstawiona poniżej prawdziwa rozmowa pomiędzy „pacjentem” (jeden z autorów tej książki) a „doktorem od wariatów”, komputerem, który pracuje w laboratorium sztucznej inteligencji w Stanford Univeristy. Pacjent pisze odpowiedzi na dalekopisie, a w chwilę później komputer-terapeuta odpowiada za pomocą dalekopisu lub ekranu wideoskopu.


Pacjent (P. G. Z): Hallo.
Terapeuta (Doktor od wiariatów): Jak się masz? Sformułuj, proszę swój problem.
PGZ: Przez cały czas czuje się przygnębiony.
DW: Powiedz mi coś więcej o tych odczuciach.
PGZ: Jestem po prostu nieszczęśliwy i potrzebuję twojej pomocy.
DW: Czy sądzisz, że potrafię ci pomóc?
PGZ: Nie jestem pewny.
DW: Czy dlatego do mnie przyszedłeś, że nie jesteś pewny?
PGZ: Myślę, że cię nienawidzę.
DW: Być może wyobrażasz sobie, że nie lubimy się nawzajem.
PGZ: Ty jesteś tylko głupią maszyną.
DW: Czy komputery cię drażnią?
PGZ: Komputery i terapeuci drażnią mnie.
DW: Dlaczego wspominasz o komputerach?
PGZ: Ty wspomniałeś je pierwszy.
DW: My dyskutujemy o tobie - nie o mnie.
PGZ: Czy ty jesteś terapeutą czy komputerem?
DW: Jak sądzisz, co maszyny mają wspólnego z twoim problemem?
PGZ: One są jego przyczyną.
DW: Czy ty kiedykolwiek pomyślałeś, że one być może nie są jego przyczyną?
PGZ: Nie.
DW: Czy mówisz „nie” tylko po to, aby zaprzeczać?
PGZ: Nie.
DW: Wydaje się, że nie jesteś dzisiaj zbyt rozmowny.
PGZ: Nie mam ochoty mówić nic więcej.
DW: Czy naprawdę nie chcesz mówić więcej?
PGZ: Nie.
DW: Jesteś trochę negatywistyczny.
PGZ: Pewno, że jestem. Odchodzę.
DW: Czy sądzisz, że to jest normalne, że odchodzisz?
Źródło: Dr Kenneth Colby




Przydatność komputerów
i jej ograniczenia




W ostatnich latach nastąpiła dosłownie eksplozja w dziedzinie opracowywania i stosowania modeli przetwarzania informacji oraz „sztucznej inteligencji”. Podjęto olbrzymią liczbę problemów badawczych, a programy komputerowe stają się coraz bardziej wyrafinowane i skomplikowane. Jednakże ten szybki postęp wzbudzał także pewne zastrzeżenia. Najczęściej spotyka się zarzut, że komputery, które są prostoduszne i nie podlegają emocjom, nie mogą w pełni symulować ludzkiego myślenia. 
Chociaż zarzuty takie są celne, to jednak z pewnością nie są one miażdżące. W nowsze modele przetwarzania informacji zaczęto wbudowywać pewne ludzkie „słabości”, których im poprzednio brakowało. Na przykład Simon (1967) opracował model mający takie cechy, jak „niecierpliwość” (wybieranie najlepszego rozwiązania znalezionego w danym okresie), „zniechęcenie” (zaprzestanie przetwarzania po określonej liczbie niepowodzeń). Jeśli działalność w tej dziedzinie będzie się rozwijać to nie powinniśmy być zaskoczeni, gdy zetkniemy się z programem komputerowym, który potrafi być znudzony, doświadczać konfliktowych motywów, czasami bywa głupi itd. Chociaż takie programy będą, być może, bardziej przypominały myślenie człowieka, to jednak nie chcielibyśmy stosować ich do sterowania mechanizmami. Modele opracowywane w celu sterowania skomplikowaną maszynerią lub operacjami handlowymi mogą zatem różnić się znacznie od modeli służących do badania ludzkiego myślenia.
Ogólnie biorąc, możemy rozpatrywać znaczenie badań nad przetwarzaniem informacji w taki sam prawie sposób, jak znaczenie badań nad zwierzętami (Reitman, 1965). Istnieje wiele |podobieństw między zachowaniem ludzi i zachowaniem zwierząt (i ludzie, i zwierzęta jedzą, piją, rozmnażają się uczą się itd); możemy zatem starać się zrozumieć ludzkie popędy, nawyki i uczenie się, badając te procesy u szczurów, ponieważ zakładamy, że wyjaśnienia tych zachowań są w dużej mierze podobne i odnoszą się zarówno do szczurów, jak i do istot ludzkich. Ograniczenia takiego porównawczego podejścia są uzależnione od podstawowych |różnic pomiędzy człowiekiem a innymi gatunkami (człowiek na przykład posługuje się językiem mówionym i pisanym a zwierzęta nie). Różnice te mają zatem decydujące znaczenie dla rozstrzygnięcia, jakie dane dotyczące zwierząt można odnieść do ludzi; niestety, nasza wiedza o szczegółowych specyficznych cechach każdego gatunku jest obecnie jeszcze zbyt uboga.
Modele przetwarzania informacji, podobnie jak zwierzęta, posiadają pewne cechy wspólne z istotami ludzkimi (i jedne i drugie odbierają informację, rozpopznają ważne obiekty, rozwiązują problemy itd.). A zatem, stosowanie takich modeli jako podstawy do badania ludzkich procesów poznawczych może być uzasadnione, lecz należy posługiwać się nimi z pewnymi ograniczeniami i z taką samą ostrożnością, jaka ma miejsce przy wyciąganiu wniosków na podstawie zachowania się zwierząt.


Obecnie przyszłość podejścia związanego z przetwarzaniem informacji rysuje się w świetle nieograniczonych oczekiwań co do jego możliwości.  Stworzono wiele ośrodków komputerowo-naukowych i obecnie projektuje się w nich i przeprowadza mnóstwo pomysłowych badań. Takie prace będą niewątpliwie kontynuowane, aby odkrywać godne uwagi sposoby, za pomocą których człowiek analizuje problem i znajduje rozwiązanie. Pewnego dnia może nawet powstać program komputerowy, który będzie rozwiązywał problemy w sposób |twórczy - którą to cechę obecnie uważa się za specyficznie ludzką.




Twórczość




Gdyby ktoś poprosił cię, abyś wymienił ludzi, którzy byli wysoce twórczy, jakie nazwiska przyszły by ci na myśl? Niewątpliwie podałbyś takie osoby, jak Michał Anioł, Beethoven, Szekspir czy Einstein. Lecz jaka właściwie byłaby podstawa twojej oceny? Jakie cechy tych ludzi skłaniają cię do określenia ich jako twórczych? Można by odpowiedzieć na to, że wszyscy oni stworzyli coś nowego, co zostało uznane za wielkie dzieło sztuki lub wspaniałą teorię naukową. Jednakże takie kryterium pozwoliłoby nam jedynie zidentyfikować twórczość ludzi genialnych i o ustalonej sławie. A co z ogromną większością ludzi, którzy nie są geniuszami i nie są dobrze znani ze swych osiągnięć?
Spójrz na przykład na poniższe odpowiedzi, których dziesięcioletni chłopiec, o przeciętnym ilorazie inteligencji, zamieszkały w ubogiej dzielnicy (getto), udzielał na proste pytanie: „Ile potrafisz wymyśleć zastosowań dla gazety?”:


„Możesz ją czytać, pisać na niej, położyć ją i namalować na niej obrazek.  Jeśli nie masz okrycia, to możesz się nią okręcić. Możesz ją spalić, zanieść do garażu i umieścić pod samochodem, gdy go myjesz, rozścielić ją i położyć na niej swoje dziecko, zalepić nią wybite okno, umieścić ją na swoich drzwiach dla dekoracji, włożyć ją do kubła ze śmieciami, położyć na krześle, jeśli krzesło jest brudne. Jeśli ktoś ma szczeniaka, to może wyłożyć gazetą jego pudełko lub rzucić mu ją na podwórko dla zabawy. Kiedy buduje się coś i nie chce się, żeby ktoś inny to widział można zasłonić to ze wszystkich stron gazetą. Gdy nie ma się materaca, kładzie się gazetę na podłodze, używa się jej też, gdy trzeba wziąć coś gorącego, można nią zatamować krew, a także  podkłada się ją pod suszące się ubranie, żeby woda nie kapała na podłogę. Można użyć gazety zamiast zasłony w oknie, włożyć ją do buta, jeśli coś rani ci stopę, zrobić z niej latawiec, osłonić lampę, która świeci zbyt jasno. Można zawinąć w nią rybę, wytrzeć szyby lub zawinąć w nią monetę, gdy trzeba ją rzucić tak, żeby nie narobiła hałasu.  Na gazecie stawia się wyczyszczone buty, gazetą wyciera się okulary, gazetę podkłada się pod kapiący zlew, zawija się w nią sadzonkę; można z niej zrobić torebkę, używać jej jako kapelusza, gdy pada deszcz, owinąć nią stopy gdy się nie ma pantofli. Można rozłożyć ją na piasku zamiast ręcznika, zrobić z niej bramki przy grze w piłkę nożną, sporządzić z niej papierowe samoloty, użyć jej jako śmietniczki przy zamiataniu, zrobić dla kota piłkę do zabawy, owinąć w nią ręce, jeśli marzną” (Ward i Kogen, 1970).


Oceniając odpowiedzi tego chłopca mógłbyś powiedzieć, że jest on bardzo twórczy, ponieważ podał wiele niezwykłych odpowiedzi, o których nigdy byś nie pomyślał. Co więcej, gdybyś porównał jego odpowiedzi z odpowiedziami innych dziesięcioletnich dzieci o przeciętnym ilorazie inteligencji, to jego wynik mógłby się wydać jeszcze bardziej imponujący. Lecz skąd się bierze takie uzdolnienie? Czy jest to cecha ogólna, z którą się urodził, czy też coś, czego się nauczył? Jeśli przyjrzymy się jeszcze raz odpowiedziom tego chłopca, to przypuszczalnie uznamy, że ważnym czynnikiem jest |doświadczenie. Niewątpliwie, im częściej ktoś musi używać czegoś na różne sposoby, tym łatwiej mu wymyśleć dla tej rzeczy jeszcze inne zastosowanie. Zapewne odpowiedzi tego dziecka zostałyby uznane za mniej twórcze przez ludzi pochodzących z tego samego środowiska społeczno-ekonomicznego. Jeśli tak, to wynikałoby stąd, że twórczość jest cechą względną, która występuje tylko wtedy, gdy ktoś myśli, że ona występuje. Wielu psychologów jednak odrzuca taki pogląd i utrzymuje, że twórczość jest cechą, którą można w sposób rzetelny mierzyć i oceniać.




Zbliżenie


Chcesz tworzyć: przerzuć się na prawą stronę


„W ostatecznym rozrachunku proces tworzenia zachodzi w mózgu, a przybiera kształt realny za pośrednictwem naszych mięśni - gdy mówimy, piszemy, tańczymy, malujemy, rzeźbimy itd. W którym wszakże miejscu mózgu zachodzi ten proces?
Wiemy już, że każda z dwóch półkul mózgu spełnia odrębne, wyspecjalizowane funkcje. W lewej półkuli dokonują się operacje logiczne i analityczne; decyduje ona o zdolnościach matematycznych i językowych. Prawa „spokojna” półkula mózgowa zawiaduje działaniami wymagającymi uzdolnień artystycznych - muzycznych lub plastycznych. W zależności od rodzaju działania przewagę uzyskuje jedna z półkul, synchronizując własne działania z aktywnością drugiej półkuli.
U większości osób praworęcznych dominuje lewa półkula. Umiejscowienie wszakże dominacji zależy od rodzaju działania, cech danej jednostki, a być może nawet uwarunkowań kulturowych. Aktywność prawej półkuli łączy się z medytacją, hipnozą, zażywaniem narkotyków, intuicją i emocjami. Czy jest także źródłem procesów twórczych?
Niezwykle interesujące badania prowadzone wśród Eskimosów z Wyspy Baffina w północnowschodniej Kanadzie wskazują na to, że kultura tego ludu sprzyja aktywności prawej półkuli. Jak podano w „Science News” z 3 kwietnia 1976 r., antropolog Solomon Katz prowadzi badania nad związkami między sztuką Eskimosów a ich językiem i zachowaniami społecznymi. Eskimosi słyną ze swych rzeźb w piaskowcu i fiszbinie i z dokładności wykonywanych przez siebie map. Ich język jest raczej syntetyczny niż analityczny, a ucząc, w większym stopniu posługują się przykładami niż opisem słownym. Obserwacja ruchów oczu i rąk podczas rzeźbienia doprowadziła badacza do wniosku, iż rzeźbiący umieszczają zazwyczaj wykonywany przedmiot w lewej części pola widzenia (prawa półkula). Prawą ręką wykonują drobne, precyzyjne czynności, lewą zaś manipulują rzeźbionym przedmiotem w przestrzeni.
W naszej kulturze nacisk kładziony jest na funkcjonowanie analityczne (właściwe lewej półkuli), w kulturze Eskimosów zaś - na funkcjonowanie właściwe dla półkuli prawej. Być może i my możemy nauczyć się posługiwać w większym stopniu tą „inną” półkulą i powiększyć nasze twórcze możliwości częściej „przerzucając” się na prawą stronę”.




Co to jest twórczość?




Zgodnie z najbardziej rozpowszechnioną definicją twórczości, polega ona na występowaniu |niepospolitych czy |zniezwykłych, |lecz |stosownych |reakcji. To założenie stanowi podstawę większości testów, które opracowano w celu mierzenia dolności twórczych.




* * *



Ryc. 5.16. Testy Zdolności Twórczych. Do testów projekcyjnych, stosowanych w celu odróżnienia jednostek twórczych od nietwórczych, należą: test plam atramentowych i test uzupełniania rysunków. Aby opisać pokazane wyżej plamy atramentowe, jednostka musi przypisać określonej konfiguracji pewien porządek i sens. Jednostka przeciętna skłonna jest opisywać plamę atramentową w kategoriach jej prostych, oczywistych cech. Jednostka twórcza ma większą skłonność do narzucenia tej figurze nowego, „eleganckiego” porządku. Gdy zadanie polega na uzupełnieniu rysunku (u dołu, po lewej), wówczas jednostka przeciętna zadowala się rysunkiem, który „ma sens” (w środku), podczas gdy jednostka twórcza wykonuje rysunek, który ma bogatsze znaczenie i8lub treść emocjonalną (po prawej).


* * *





Chociaż oryginalność uznaje się zwykle za główny czynnik twórczości, to jednak nie zawsze zdajemy sobie sprawę z doniosłego znaczenia stosowności, tymczasem jest to kryterium, które odróżnia działania twórcze od bezsensownych. Rozwiązania problemu, które są jedyne w swoim rodzaju, lecz całkowicie bezwartościowe, czyli niestosowne, nie mogą być uważane za reakcje twórcze. Przypuśćmy na przykład, że polecono ci wyobrazić sobie wszystko to, co mogłoby się zdarzyć, gdyby nagle zostały zniesione wszystkie prawa państwowe i lokalne. Odpowiedź „padałoby przez 40 dni i 40 nocy” mogłaby być oryginalna, lecz nie uznalibyśmy jej za twórczą, ponieważ nie ma ona żadnego związku z postawionym problemem. Podobnie wypowiedzi pacjentów psychotycznych mogą być oryginalne i ekscentryczne, lecz nie uważa się ich za dowód talentu twórczego.


Odpowiedzi zwykłe
1. Plamy
2. Ciemne chmury


Odpowiedzi niezwykłe
1. Namagnetyzowane opiłki żelaza
2. Mały chłopczyk i jego matka biegną w pochmurny, wietrzny dzień, 
usiłując dotrzeć do domu przed deszczem


Odpowiedzi zwykłe
1. Małpa
2. Nowoczesny obraz przedstawiający goryla


Odpowiedzi niezwykłe
1. Pawian przeglądający się w lusterku
2. „Myśliciel” Rodina krzyczący „Eureka!”


Odpowiedzi zwykłe
1. Afrykański tancerz voodoo
2. Kaktus


Odpowiedzi niezwykłe
1. Meksykanin w sombrero wbiegający na wysoki pagórek, aby uciec przed 
chmurami deszczowymi
2. Słowo napisane po chińsku


Pisząc o pewnym rzeźbiarzu włoskim Burnham (1968) stwierdził: „(Jego Geniusz) był tego rodzaju, że wykazywał on prawie patologiczną niezdolność rozwiązania jakiegokolwiek problemu z zakresu rzeźby w sposób oczekiwany”.  Spojrzenie na problem w nowy sposób często stanowi klucz do ważnego odkrycia czy przełomu w nauce; zademonstrował to Descartes, który postulując istnienie dwóch rodzajów procesów, umożliwił naukowe badanie funkcji fizjologicznych (por. Rozdział 2). Ten proces wybierania i kształtowania właściwego sposobu przedstawienia (reprezentacja) danego problemu stanowi najważniejszy element programów komputerowych, które starają się symulować twórcze zachowanie człowieka (Amarel, 1966). Cecha oryginalności oznacza w zasadzie, że reakcji twórczej nie da się przewidzieć, dopóki nie zostanie wykonana - a wówczas staje się ona standardem, na podstawie którego można oceniać twórczy charakter przyszłych reakcji.




Kogo można uznać
za twórczą jednostkę?




W badaniach nad twórczością można wyróżnić kilka kierunków. Niektóre badania koncentrują się na |procesie twórczości, niektóre na |wytworze, a inne na czynnikach |sytuacyjnych, które wpływają na twórczość. Jednakże podstawowym podejściem badawczym w tej dziedzinie jest badanie |twórczej |jednostki. W jaki sposób można rozpoznać ludzi twórczych? Jakie cechy odróżniają ich od ludzi mniej twórczych? W jaki sposób stali się oni tym, czym są? (Czy ty mógłbyś także stać się takim?) Wielu psychologów poszukuje odpowiedzi na te pytania.
Ogólnie biorąc, badania wykazały, że istnieje pewien szczególny układ cech psychicznych, który charakteryzuje jednostki twórcze, niezależnie od ich wieku, środowiska kulturowego czy dziedziny działalności. Osoby twórcze zdają się wyróżniać bardziej swymi zainteresowaniami (Dellas i Gaier, 1970). Brak silnej korelacji między twórczością a inteligencją może wydawać się zaskakujący, lecz badania wyraźnie potwierdziły ten wniosek (Wallach i Kogan, 1965).
Istnieją jednak inne cechy poznawcze, które wydają się charakterystyczne dla ludzi twórczych. Jedną z najbardziej wyróżniających się cech tego rodzaju jest preferencja poznawcza |złożoności (w przeciwieństwie do prostoty). Ujawnia się to w wyborze figur, które są asymetryczne, dynamiczne, a nawet chaotyczne, nie zaś regularne, nieskomplikowane i proste.
Wiele badań nad twórczością dotyczyło cech osobowości twórczych jednostek. Wyniki tych badań pozwoliły wyodrębnić pewną grupę cech, które obejmują impulsywność, niezależność, introwersję, intuicyjność oraz samoakceptację.


Twórczy architekci (MacKinnon, 1961) oraz twórczy naukowcy - badacze (Gough, 1961) wykazywali znaczne podobieństwo pod względem tych cech osobowości, mimo że treść ich pracy zawodowej była różna. Także u twórczych pisarzy stwierdzono podobny zbiór cech, aczkolwiek wykazywali oni większą oryginalność oraz fantazję (Barron, 1963).
|Niezależność, zarówno w postawach jak i zachowaniu, jest chyba najbardziej uderzającą cechą osobowości twórczej. We wszystkich niemal badaniach stwierdzono, że jednostki twórcze nie bardzo dbają o opinie innych ludzi o nich. W rezultacie jednostki takie mogą swobodniej być sobą  wyrażać nowe idee niż inni, mniej twórczy ludzie. Taka niezależność jest wręcz niezbędna, ponieważ twórcze działanie często spotyka się z krytyką, ośmieszaniem i całkowitym brakiem wzmocnienia (i musi być pomimo tego kontynuowane).
Inna zmienna osobowościowa, która wyróżnia jednostki twórcze, polega na tym, że ich układ zainteresowań odzwierciedla zarówno męską, jak i żeńską stronę ich natury - typ |androgyniczny. Twórczy mężczyźni są zdolni zaakceptować żeńskie aspekty swej osobowości nie odczuwając jakiegoś konfliktu płci, dzięki czemu są bardziej otwarci na emocje i uczucia, a także cechuje ich większa wrażliwość estetyczna (Hammer, 1964). Można by oczekiwać, że twórcze kobiety akceptowałyby męskie cechy swej osobowości, lecz nieliczne dostępne badania nie w pełni potwierdzają ten pogląd.  Zgodnie z wynikami badań, Ravenny Helson (1967) nad twórczymi matematyczkami, kobiety te różniły się mniej od twórczych tym, że akceptując męskie cechy zachowały swą kobiecość i były często |mniej, a nie więcej „męskie”. Być może, pewne cechy tradycyjnie uważane za „męskie” raczej hamują twórczość niż jej sprzyja. Dopiero dalsze badania mogą wyjaśnić, w jakiej mierze występują w procesie twórczym rzeczywiste różnice związane z płcią.
Istnieje popularny pogląd na temat wyjątkowo twórczych ludzi, zgodnie z którym, chociaż są oni geniuszami, to poza ty są oni również zupełnie zwariowani. Obłąkanie takich artystów, jak Van Gogh czy Niżyński, często przytacza się jako „typowy przykład”. Czy są jakieś dane psychologiczne dotyczące związku między twórczością a psychopatologią? Odpowiedź (zaskakująca dla wielu) brzmi: prawie żadne. Przeciwnie, ludzie twórczy zdają się odznaczać większą siłą ego i zdolnością rozwiązywania problemów w sposób konstruktywny (Cross, Cattell i Butcher, 1967). Być może, takie cechy, jak niezależność i oryginalność, które prowadzą do tego, że twórcze jednostki myślą często w sposób zakazany (tabu) lub uważany za „dziwny”, powodują, iż inni ludzie uważają ich (błędnie) za niezrównoważonych psychicznie.




Czy każdy (na przykład ty)
może być twórczy?




Chociaż ludzie często krytykują jednostki wysoce twórcze lub określają je w sposób niepochlebny, to jednak paradoksalnie sami chcą być bardziej twórczy. Twórczość jest cechą, która dla większości ludzi ma wysoce pozytywną wartość - w tym znaczeniu, że chcieliby sami posiadać ją w większym stopniu, a także chcieliby, aby szkoły pomogły ich dzieciom stać się bardziej twórczymi. Gdyby twórczość była czymś, z czym się rodzimy, wówczas uzyskanie takiej poprawy byłoby niemożliwe. Albo byłbyś twórczy, albo byś nie był. Na szczęście nie ma żadnych danych, które potwierdzałyby pogląd, że twórczość jest wrodzona; wydaje się raczej, że jest ona zachowaniem |wyuczonym.
W jaki sposób możemy sprawić, aby ludzie byli bardziej twórczy?
Opierając się na podstawowych zasadach uczenia się, Maltzman (1960) założył, że jeśli ludziom będzie się podawać wzmocnienie za twórcze reakcje na wstępnym posiedzeniu treningowym, to w wyniku generalizacji reakcji będą oni wykazywać bardziej twórcze zachowanie w późniejszej sytuacji testowej.


„Aby sprawdzić tę koncepcję, Maltzman dawał badanym sześć razy z rzędu test kojarzenia słów, polecając im, aby za każdym razem podawali inne odpowiedzi. W ten sposób zmuszał badanych, aby nie ograniczali się do pospolitych skojarzeń słownych i produkowali bardziej twórcze reakcje. Gdy badanym tym dano później test twórczości, to uzyskiwali oni wyższe wyniki niż grupa kontrolna, które nie przeszła takiego treningu”.


Twórczość jest często tłumiona przez obawę, że jakaś nowa idea zostanie uznana przez innych ludzi za głupią i bezwartościową. Osoba, która nie chce ujawniać swoich pomysłów (lub nie uzyskuje za nie żadnego wzmocnienia) może w końcu nauczyć się nie myśleć nigdy w sposób prawdziwie twórczy. W jaki sposób moglibyśmy temu zapobiec?
Jedną z propozycji jest stosowanie tak zwanej burzy mózgów („brainstorming”; Osborn, 1957). W początkowym stadium takiego „szukania pomysłów” członkom grupy przedstawia się problem i prosi się ich, aby wymyślali wszelkie możliwe jego rozwiązania - niezależnie od tego, czy wydają się one praktyczne, czy też nie. Uczestników zachęca się także, aby uwolnili się od wszelkich zahamowań z jednym wyjątkiem: nie pozwala się krytykować pomysłów innych. W drugim stadium - „oceniania” - grupa rozpatruje bardzo dokładnie każdy pomysł, zachowując wszystkie te pomysły, w wypadku których istnieje choćby niewielkie prawdopodobieństwo, że mogą być użyteczne. Całą tę procedurę, zwaną metodą |odroczonej |oceny, mogą stosować zarówno indywidualni pomysłodawcy, jak i grupy.
Jak skutecznie technika burzy mózgów ułatwia twórczość?
Niestety, istnieje bardzo mało danych potwierdzających jej efektywność, jakkolwiek metoda ta wydaje się rozsądna. Na przykład, w jednym z badań stwierdzono, że w trakcie burzy mózgów nie wytworzono więcej oryginalnych idei, niż wytworzyła ta sama liczba jednostek pracujących samotnie (Taylor, Berry i Block, 1958). Sugerowałoby to, że obecność innych ludzi, nawet w idealnych warunkach, może wywierać pewien hamujący wpływ na twórczość.  Istnieją jednak dane, że można podnieść efektywność „indywidualnych posiedzeń burzy mózgów”, jeśli poprzedzi się ją grupową „rozgrzewką” (Dunnette, Campbelli i Jaastad, 1963).


Chociaż prawdziwie efektywną technikę sprzyjąjącą twórczości trzeba będzie dopiero wynaleźć, to jednak nie ulega wątpliwości, że zdolności twórcze |można rozwijać. Fakt ten ma ważne implikacje dla kształcenia, ponieważ sugeruje, że dziecko może uczyć się twórczości podobnie, jak uczy się czytania, pisania czy arytmetyki. Należy mieć nadzieję, że będą przeprowadzane dalsze badania nad możliwymi metodami pobudzania twórczości.  Ciekawe, że technika wzmacniania oryginalnych reakcji u danej osoby na dłuższą może nie być najbardziej skuteczna, ponieważ wielu twórców opracowuje swe najbardziej oryginalne dzieła wtedy, gdy są niezależni od tradycyjnych nagród rozdzielanych przez społeczeństwo.
George Bernard Shaw w swej książce „Maxims for Revolutionists” („Maksymy dla rewolucjonistów”) przeprowadza rozróżnienie pomiędzy ludźmi rozsądnymi i nierozsądnymi, które zdaje się być równie przydatne do odróżnienia osób twórczych od pozostałych. „Rozsądny człowiek przystosowuje się do świata, człowiek nierozsądny ciągle stara się przystosować świat do siebie. Zatem wszelki postęp zależy od człowieka nierozsądnego” (i twórczego).




Streszczenie rozdziału




Nasza ludzka zdolność posługiwania się umysłem do rozwiązywania problemów wykraczających poza zwykłe problemy utrzymania się przy życiu sprawia, że nie jesteśmy niewolnikami naszego środowiska. Potrafimy operować symbolami reprezentującymi elementy środowiska (|myśleć), wykorzystywać te symbole w rozwiązywaniu problemów (|rozumować) oraz wymyślać nowe i oryginalne idee (|tworzyć). Myślenie może być albo |realistyczne, jak w wypadku rozumowania zmierzającego do rozwiązania określonego problemu, lub |autystyczne, jak w marzeniach na jawie, albo też może stanowić kombinację obu tych rodzajów.
W ostatnich latach pojawił się nowy sposób podejścia do badania |procesów |poznawczych. Procesy te rozpatruje się jako złożone, długotrwałe zjawiska zachodzące w czasie i oddziaływujące na siebie. Termin |poznanie oznacza zarówno |proces poznawania, jak i |wytwór tego procesu.
Psychologowie od dawna interesują się badaniem rozwoju procesów poznawczych. Istnieje pewien brak ciągłości pomiędzy procesami poznawczymi u dzieci i dorosłych. Dzieci zaczynają życie jako naiwni realiści przyjmujący pozory za dobrą monetę. Według Piageta, rozwój poznawczy zachodzi wtedy, gdy dzieci odkrywają i uczą się stosować zasady, które rządzą interakcją ze środowiskiem. Gdy dzieci dostrzegają rozbieżność pomiędzy prostymi pojęciami a zjawiskami środowiskowymi, wówczas tworzą one nowe pojęcia, które je wyjaśniają. Dzięki procesom |asymilacji i |akomodacji dzieci stopniowo doskonalą struktury poznawcze (|schematy), które utworzyły dla powiązania procesów i wyników. Różne dzieci przechodzą cztery stadia rozwoju poznawczego w różnym tepmie, lecz w tej samej kolejności. Stadia te to: |okres |sensoryczno-motoryczny, |stadium |myślenia |przedoperacyjnego, |stadium |operacji |konkretnych oraz |stadium |operacji |formalnych. Wymagania i potrzeby danej kultury mogą wpływać na rozwój poznawczy.
Od stuleci toczy się spór o to, czy umysł dziecka jest czystą tablicą zapisywaną przez środowisko, czy też magazynem wrodzonych zdolności.  Współcześni psychologowie zgadzają się, że odpowiedź leży gdzieś pośrodku i starają się zidentyfikować warunki środowiskowe umożliwiające jak najlepszy rozwój istniejącego potencjału.
Wiele współczesnych badań, przeprowadzonych w wysoce nienaukowy sposób, miało „udowodnić”, że dziedziczy się zarówno określony poziom zdolności intelektualnych, jak i takie „cechy”, jak obłęd, żebractwo, rozpustę czy alkoholizm.


Późniejsze dane przemawiające za doniosłym znaczeniem dziedziczności pochodziły z badań wykazujących wyższe korelacje pomiędzy inteligencją identycznych genetycznie bliźniąt niż pomiędzy inteligencją innych braci i sióstr. Badacze podkreślający rolę środowiska poddają w wątpliwość rzetelność tych badań i ich interpretację oraz domagają się ponownej oceny wyników uprzednich badań, jak również bardziej rygorystycznej kontroli na przyszłość.
Dane pochodzące z różnych źródeł, między innymi badania nad dziećmi wychowywanymi w przybranych rodzinach lub przeniesionymi do bardziej pobudzających środowisk, wskazują, że środowisko odgrywa decydującą rolę w rozwoju funkcji intelektualnych. Istniejący obecnie materiał dowodowy sugeruje, że zdolności intelektualne są wynikiem wzajemnego |oddziaływania czynników dziedzicznych i środowiskowych, przy czym dziedziczność określa granice tych zdolności, środowisko zaś wyznacza osiągnięty w rzeczywistości poziom.
Myślenie obejmuje wyobrażenia, słowa oraz utajone procesy mięśniowe.  |Wyobrażenia są to „obrazy umysłowe” rzeczywistych doznań sensorycznych. U większości ludzi największą rolę odgrywa wyobraźnia wzrokowa, aczkolwiek wyobraźnia nie jest niezbędnym warunkiem procesu myślenia. |Wyobraźnia |ejdetyczna jest to zdolność tworzenia wyobrażeń tak wyraźnych i dokładnych, jak oryginalne spostrzeżenie.
Sugeruje się, że rozwój poznawczy obejmuje trzy stadia tworzenia wewnętrznych reprezentacji obiektów. Najpierw uczymy się posługiwać |reprezentacjami |mięśniowymi, następnie |wyobrażeniami, a w końcu |symbolami.
W eksperymentach nad |czasem |reakcji bada się, ile czasu zajmuje proces myślenia. Słowa, podobnie jak wyobrażenia, zdają się nie być niezbędne dla procesu myślenia, lecz znacznie ten proces ułatwiają. Na nasz sposób spostrzegania przedmiotów wyraźnie wpływają słowa, które z nimi kojarzymy.
Psychologowie od dawna spierają się, czy myśl determinuje język, czy na odwrót. |Hipoteza |Whorfa głosi, że wzorce językowe danej grupy kulturowej kształtują jej formy myślenia i spostrzegania. Krytycy Whorfa argumentują, że z powodzeniem mogą istnieć różne wzorce myślowe, które prowadzą do różnic w języku.
Nie myślimy samym tylko mózgiem; procesy myślenia zdaje się również ułatwiać |utajone |zachowanie |oralne (niewidoczne reakcje mięśniowe).  |Sprzężenie |zwrotne, czyli znajomość wyników, jest niezbędnym czynnikiem w myśleniu i uczeniu się. W ostatnich latach psychologowie zaczęli rozpatrywać zachowanie ludzkie jako szereg zdarzeń, a myślący organizm traktować tak, jakby był podobny do |serwomechanizmu: ukierunkowanego na cel, wrażliwego na błędy, samokorygującego się urządzenia, w którym wyróżnia się: - |wejście, |wyjście, |przetwarzanie i |sprzężenie |zwrotne.
Istnieją trzy typy rozumowania: |rozumowanie |dedukcyjne, w którym zestawia się dane i wyciąga nieuniknione wnioski; |rozumowanie |indukcyjne, w którym formułuje się hipotezy, o czymś nieznanym na podstawie wniosków z tego, co już wiadomo; oraz |rozumowanie |oceniające - ocenianie trafności czy stosowności pewnej nowej idei lub wytworu.
Jednostka znajdująca się w nowej sytuacji, starająca się osiągnąć pewien cel, staje wobec |problemu, gdy uniemożliwia jej to jakaś przeszkoda.  Rozwiązywanie problemów przez ludzi polega na połączeniu |wglądu oraz uczenia się metodą |prób i |błędów. Z początku mamy pewne pomysły, jak rozwiązać dany problem;  wypróbowujemy kilka z nich, (być może tylko w myśli) i w końcu dochodzimy do poprawnego rozwiązania. Badania nad procesami, za pośrednictwem których poszukujemy pewnej reguły czy zasady organizującej, ujawniają pułapki i trudności nieodłącznie związane z procesem rozwiązywania problemów.
Ostatnio w badaniach nad przetwarzaniem informacji stosuje się komputery, które |symulują myślenie człowieka. Komputery naśladują ludzi w procesach tak różnych, jak rozwiązywanie zadań geometrycznych, gra w szachy i udawanie neurotyków. Chociaż daleko jeszcze do zbudowania komputera, który oddałby całą złożoność ludzkiego umysłu, możemy wiele się nauczyć badając podobieństwa i różnice między umysłem ludzkim i mechanicznym.
Jednostka |twórcza to taka, która wykazuje niezwykłe, lecz stosowne reakcje. Twórczość jest cechą dającą się mierzyć, polegającą na zdolności łączenia elementów w nowe i odmienne sposoby. Osoby twórcze różnią się od innych bardziej swymi zainteresowaniami, postawami i cechami osobowości niż swymi zdolnościami intelektualnymi. Wydaje się, że twórczość jest zdolnością wyuczoną, aczkolwiek badacze nie ustalili jeszcze, w jaki sposób najlepiej można by ją rozwijać.




Z Frontu Badań.
Występowanie stałych
różnic indywidualnych
w przetwarzaniu informacji




|Ruth |S. |Day „Yale University”


Gdy przed kilku laty przeprowadzałam eksperymenty nad pewnym dość prostym problemem, wówczas niektóre z uzyskanych wyników były dość zaskakujące. W eksperymentach tych zastosowałam technikę rozdzielnego słuchania („dichotic listening”), w której do każdego ucha podaje się równocześnie przez słuchawki inny bodziec. W poprzednich badaniach otrzymywano wyniki świadczące o |rywalizacji bodźców; na przykład osoby badane, którym podawano równocześnie parę bodźców: SEVEN (siedem) i NINE (dziewięć), stwierdziły, że słyszą albo jedno z tych słów, albo obydwa, nie słyszały natomiast |połączeń („fusions”), takich jak SNEVEN. Ponieważ w analogicznych badaniach nad widzeniem uzyskiwano wyniki świadczące zarówno o łączeniu, jak i o rywalizacji bodźców, wydawało się zatem niezwykłe, że w wypadku słuchania otrzymano wyniki świadczące jedynie o rywalizacji.
Analiza bodźców stosowanych w poprzednich eksperymentach nad rozdzielnym słuchaniem sugerowała, że łączenie bodźców mogłoby wystąpić, gdyby wzięło się pod uwagę pewne zmienne psycholingwistyczne. Konstruowałam zatem różne bodźce, takie jak BANKIET I LANKET (słowa pozbawione sensu - przyp. tłum.) i pytałam badanych, co słyszeli. Pierwszych kilku badanych stwierdziło, że słyszeli połączenia, takie jak BLANKET (koc). W tym momencie wydawało się, że w rozdzielnym słuchaniu istotnie zachodzi łączenie bodźców. Następnie jednak pojawiła się osoba badana, która nie dokonywała takich połączeń, lecz stwierdzała, że słyszy zarówno BLANKET, jak i LANKET. Zapewne moje „odkrycie” nie było mimo wszystko prawdziwe.
Zamiast zrezygnować w tym momencie z realizacji projektu badawczego, postanowiłam zbadać dużą liczbę osób i rejestrować przeciętny procent połączeń dokonywanych przez wszystkich badanych. Decyzja ta wynikała z dobrze ugruntowanej w psychologii tradycji, zwanej podejściem |nomotetycznym. W podejściu tym zakłada się, że jednostki mogą różnić się w pewnym stopniu sposobem wykonywania tych samych zadań, lecz różnice te są raczej nieinteresującymi, mało ważnymi fluktuacjami. Powinniśmy zatem zbadać wiele jednostek, aby zminimalizować te różnice i uzyskać w ten sposób „uśrednione” wyniki, które prawdopodobnie odzwierciedlają podstawowe zasady zachowania, wspólne dla wszystkich jednostek.




Dwa wzorce percepcji




Podejście nomotetyczne charakteryzowało kilka następnych eksperymentów nad łączeniem bodźców słuchowych; w eksperymentach tych chodziło o zbadanie sprzyjąjącego lub hamującego wpływu różnych czynników bodźcowych i zadaniowych na zjawisko łączenia bodźców. Za każdym razem wystąpiła dość duża liczba połączeń. Nadal jednak zaznaczały się także duże różnice indywidualne. W końcu wydało się konieczne dokładne zbadanie charakteru tych różnic.
W różnych eksperymentach, przy zastosowaniu dających się łączyć rozdzielnych bodźców, takich jak BANKET i LANKET, przebadano ponad 800 osób. We wszystkich parach bodźce zachodziły na siebie w czasie tak, że jeden bodziec wyprzedzał nieco drugi (przedstawiono to na ryc. 5.18). Jako pierwsze mogło zatem zaczynać się słowo BANKET, poprzedzając słowo LANKET o 50, 75, 100 lub 125 milisekund, lub też słowo LANKET mogło poprzedzać słowo BANKET o takie same okresy. Ponieważ przeciętny fonem (podstawowy dźwięk mowy) trwa około 70 milisekund, dlatego też przesunięcia te są dość duże.  Wykonywano kilka zadań przy użyciu tych samych bodźców i przy udziale tych samych osób badanych. W badaniu wymagającym |identyfikacji osoby badane proszono po prostu o podanie „co słyszały”, czy „jedno słowo, czy dwa: 
(...), słowa normalne, czy słowa bezsensowne”. W zadaniu wymagającym oceny kolejności w czasie (OKC; ang. TOY - „Temporal Order Judgment Task”) te same osoby proszono o podanie „pierwszego dźwięku, jaki usłyszały”, na przykład („b”) czy („I”).
W badaniach tych nieodmiennie występowały dwa zasadnicze układy danych, które przedstawiono na rycinie 5.18 dla reprezentatywnych bodźców BANKET i LANKET. Niektóre osoby podają, że w zadaniu wymagającym identyfikacji słyszą BLANKET, a zarazem w zadaniu oceny kolejności w większości wypadków stwierdzają, że („b”) występuje jako pierwsze, nawet wtedy, gdy („I”) poprzedzało („b”) o okres dość znaczny. Zgodnie z fonologicznymi zasadami języka angielskiego spółgłoski zwarte, takie jak („b”), mogą poprzedzać na początku słowa spółgłoski półotwarte, takie jak („I”), lecz nie na odwrót; inaczej mówiąc nie mogą występować słowa o ogólnej postaci LBANKET. Wydaje się, że osoby te są „uzależnione od języka” („language-bound”), ponieważ podają one to, na co pozwala język, a nie rzeczywiste bodźce. Inne osoby rzadko podają, że w zadaniu wymagającym identyfikacji słyszą połączone bodźce (takie jak BLANKET) i potrafią poprawnie określić, który dźwięk pojawia się jako pierwszy w teście oceny kolejności. Osoby te zdają się być „niezależne od języka” („language-optional”), ponieważ potrafią one stosować zasady językowe lub odrzucić je, zależnie od wymogów zadania.
Aby w rzetelny sposób sklasyfikować jednostki jako uzależnione lub niezależne od języka, potrzebne jest dość długie posiedzenie badawcze.  Najwłaściwsze podejście polega na analizowaniu ogólnego układu danych w zadaniu oceny kolejności, co przedstawiono na rycinie 5.19. Osoby określane jako „zależne od języka” stwierdzają na ogół, że słyszą spółgłoskę zwartą jako pierwszą, nawet gdy spółgłoska półotwarta poprzedza ją o czas dość znaczny; toteż uzyskują one dobre wyniki wtedy, gdy spółgłoska zwarta rzeczywiście jest pierwsza, lecz wyniki ich są słabe, gdy pierwsza jest spółgłoska półotwarta. Osoby niezależne od języka z reguły podają, że słyszą ten fonem, który rzeczywiście był pierwszy, bez względu na jego charakter. Aczkolwiek krzywe są wykreślone na podstawie przeciętnych wyników w grupach osób uzależnionych od języka, to jednak podobny kształt przybierają krzywe wykreślone dla poszczególnych badanych.


U większości ludzi występuje albo ogólny wzorzec uzależnienia, albo niezależności od języka, chociaż niektórzy nie spełniają surowych kryteriów statystycznych przyjętych w procedurze klasyfikacyjnej. Nieliczne z pozostałych osób po prostu nie potrafią wykonać tego zadania; punkty odpowiadające uzyskanym przez nie wynikom są rozrzucone losowo wokół linii wyników przypadkowych (50% poprawnych odpowiedzi).




Natura zjawiska




Początkowo wydawało się, że osoby zależne od języka mogą po prostu słabo oceniać kolejność w czasie. Jednakże kilka eksperymentów wykazało, że nie jest to prawdą. Po pierwsze, te same rozdzielne, dające się łączyć w pary bodźce zastosowano w innym zadaniu oceny kolejności. Tym razem osoby badane poproszono o podanie, którym uchem odebrały pierwszy dźwięk, nie zwracając uwagi na to, jaki to był w rzeczywistości dźwięk. Osoby uzależnione od języka wykonywały to zadanie bardzo poprawnie. W sytuacji, gdy nie wymagano w ogóle przetwarzania informacji językowej, zostały one zatem w pewnym sensie „uwolnione” od zależności od języka. W drugim eksperymencie badanych proszono o podanie, który dźwięk (fonem) był pierwszy, gdy stosowano rozdzielne, nie dające się połączyć bodźce, takie jak BAE i GAE. Osoby uzależnione od języka znów z powodzeniem oceniały kolejność w czasie tych bodźców. Ponieważ język angielski nie pozwala na takie zestawienia spółgłosek jak BGAE lub GBAE, przeto nie było żadnych określonych reguł fonologicznych, które by uwarunkowały percepcję osób uzależnionych od języka w określonym kierunku. W ostatnim eksperymencie zastosowano takie bodźce, jak GAS i GAP, które można łączyć w obu kierunkach, GASP (dyszeć) lub GAPS (przerwy). I tu także osoby uzależnione od języka potrafiły określić porządek tych bodźców w czasie. Eksperymenty te wykazały, że osoby uzależnione od języka mają trudności przy ocenianiu kolejności w czasie tylko wtedy, gdy muszą podejmować decyzję „językową”, a bodźce są skonstruowane w taki sposób, że zasady fonologiczne umożliwiają łączenie fonemów w takiej a nie innej kolejności. Ujmując to w sposób bardziej ogólny możemy powiedzieć, że osoby uzależnione od języka nie potrafią odrzucić reguł językowych wyższego poziomu, aby dokonywać ocen na niższym poziomie analizy, nawet wtedy, gdy poleganie na tych regułach prowadzi do niepoprawnej percepcji. Natomiast osoby niezależne od języka potrafią przyjmować lub odrzucić reguły z danego poziomu, zależnie od wymogów zadania.
Inną podstawą różnic między osobami uzależnionymi i niezależnymi od języka mogłoby być różnice pod względem ich inteligencji ogólnej: osoby uzależnione językowo mogłyby być mniej inteligentne niż osoby niezależne od języka. Ponieważ okazało się, że jestem uzależniona od języka, miałam więc nadzieję, że nie jest to prawdą. Materiał dowodowy był przekonywujący: wykazał on, że nie ma żadnych różnic między tymi grupami ani w standardowym teście inteligencji, ani też w podtestach uzdolnień słownych i liczbowych „Scholastic Aptitude Test” („Testu Uzdolnień Szkolnych”). Biorąc pod uwagę tę homogeniczność inteligencji ogólnej, tym bardziej zaskakujące są różnice w wynikach zadań, w których wchodzi w grę łączenie oddzielnych bodźców słuchowych.
Termin „styl poznawczy” nie nadaje się do określenia różnicy między osobami uzależnionymi i niezależnymi od języka, ponieważ słowo „styl” implikuje, że dana jednostka może dowolnie zadecydować o tym, czy zachowywać się zgodnie z jednym czy drugim wzorcem. Gdy osobom uzależnionym i niezależnym od języka opowie się o dzielących je zasadniczych różnicach i poprosi się, aby „były inne”, to dzieje się coś dziwnego. Osoby uzależnione od języka często stwierdzają, że naprawdę słyszały BLANKET, niekiedy zaś nawet twierdzą, że to my popełniliśmy błąd i w rzeczywistości nagraliśmy na taśmie BLANKET. Gdy wykonują one zadanie oceny kolejności bodźców wielokrotnie, przez wiele dni i mówi się im, jakiego rodzaju bodźce są na taśmie, to ich wyniki w tym zadaniu ulegają poprawie, lecz układy ich odpowiedzi nie upodabniają się do układu odpowiedzi osób niezależnych od języka. Gdy osoby niezależne od języka poprosi się , aby były „uzależnione” od języka, to zwykle śmieją się; właściwie rozróżniają one bodźce (niepotrzebne są im wyjaśnienia) usiłowania zaś, by „słyszeć” połączone bodźce, uważają za śmieszne. Krótko mówiąc fenomenologiczne doświadczenia osób należących do tych dwóch grup są bardzo trudne (jeśli nie niemożliwe) „przestawianie się” na inny wzorzec. Obecnie wydaje się, że najtrafniejszym rozwiązaniem byłoby uznanie, iż różnice między osobami uzależnionymi językowo i niezależnymi od języka wynikają z mających trwały charakter różnic poznawczych.




Inne aspekty
procesów poznawczych




Aczkolwiek między osobami uzależnionymi i niezależnymi od języka w eksperymentach nad łączeniem oddzielnych bodźców słuchowych są bardzo wyraźne, to jednak, gdyby była to jedyna sytuacja, w której obie te grupy różnią się między sobą, to zjawisko owo miałoby stosunkowo ograniczone znaczenie. Ostatecznie, ludziom, zajmującym się swymi codziennymi sprawami, nie dostarcza się często takich bodźców, jak BANKET i LANKET. Obie te grupy wykazują jednak różnice w rozmaitych sytuacjach percepcyjnych i pamięciowych. Na przykład, osoby niezależne od języka potrafią lepiej zapamiętywać listę cyfr, taką jak 8 - 5 - 4 - 3 - 2 - 6 - 1 - 9 - 7, wypowiadanych szybko jedna po drugiej. Wydają się one lepiej przystosowane do przechowywania takiej informacji w systemie pamięci krótkotrwałej i odtwarzania jej w tej samej kolejności, w jakiej została zaprezentowana.  Jednakże w sytuacjach wymagających zdolności z zakresu pamięci długotrwałej właśnie osoby uzależnione od języka wykazują pamięć lepiej zorganizowaną.  Na przykład, odczytuje się długą listę złożoną z 22 nie związanych ze sobą słów, a następnie osoby badane zapisują w dowolnej kolejności wszystkie słowa, które zdążyły zapamiętać. Tę samą listę słów układa się następnie w innej kolejności, przedstawia się ją ponownie, a osoby badane muszą znów zapisać to, co zapamiętały. W ciągu wielu kolejnych prób tego rodzaju osoby zależne od języka nadają swą organizację semantyczną chaotycznej skądinąd liście słów: konsekwentnie podają one razem pewne grupy słów, chociaż miejsca tych słów na liście zmieniają się z próby na próbę. Osoby niezależne od języka dokonują w tym zadaniu stosunkowo niewielkiej organizacji semantycznej. Przeciwnie, w ich sposobie wykonywania zadania nie można zaobserwować jakiejkolwiek organizacji, z wyjątkiem tendencji do podawania słów w takiej kolejności, w jakiej zostały one zaprezentowane w danej próbie.
Jednym ze sposobów spojrzenia na rezultaty tych eksperymentów nad pamięcią jest przyjęcie założenia, że dla osób uzależnionych od języka charakterystyczne jest stosowanie większej liczby operacji kodowania niż dla osób niezależnych od języka. W eksperymencie z cyframi mało jest czasu na takie operacje; gdyby osobom uzależnionym od języka dano więcej czasu, to mogłyby one łączyć cyfry w takie grupy, jak „854 - 326 - 197”; i w ten sposób uzyskać wyższe wskaźniki zapamiętywania. W eksperymencie ze słowami badany ma wiele czasu na zestawienie poszczególnych pozycji z grupy, a może nawet na obmyślenie „historyjek” dla nich - na przykład, INSPEKTOR - OGRÓD - TRĄBKA, można zapamiętać jako: „INSPEKTOR siedzi w OGRODZIE, grając na TRĄBCE”. Tymczasem osoby niezależne od języka zdają się mniej skłonne do wykonywania takich „głębokich” operacji kodowania i niekiedy opierają się na mniej stałych zasadach, takich jak kolejność prezentacji. Eksperymenty te wykazują, że rozróżnienie między osobami uzależnionymi i niezależnymi od języka odnosi się także do sytuacji pamięciowych i nie ogranicza się do tych sytuacji, w których główną rolę odgrywa percepcja. Obejmuje ono zatem sytuacje podobne do spotykanych w życiu codziennym, takich na przykład, jak zapamiętywanie numerów telefonów lub list zakupów.
Przeprowadzono wiele innych eksperymentów w celu porównania operacji przetwarzania informacji przez osoby uzależnione od języka i niezależne od niego. Starano się analizować sytuacje, w których nie występują różnice między tymi dwoma grupami, jak również sytuacje, w których któraś z grup ma w pewnym sensie „przewagę”.




Implikacje dla badań




Byłoby zbytnim uproszczeniem twierdzenie, że wszelkie procesy poznawcze dzielą się tylko na te dwa podstawowe „typy”. Jednakże rozróżnienie między osobami uzależnionymi i niezależnymi od języka jest wystarczająco kontrastowe, trwałe i obejmujące rozmaite sytuacje poznawcze, aby rewizja nomotetycznego podejścia do badań wydawała się uzasadniona. Przypuśćmy, że przekształcamy numery telefoniczne i umieszczamy grupę cyfr określających centralę telefoniczną na końcu numeru (na przykład 2300-321), zamiast na początku (321-2300), tak aby ludzie mogli natychmiast powtórzyć sobie wyróżniającą informację, a następnie dodać do niej dobrze znane im oznaczenie centrali. Osoby niezależne od języka mogą zapamiętywać obie te formy numerów telefonicznych równie dobrze, ponieważ potrafią one doskonale zapamiętywać niepogrupowane szeregi cyfr. Forma numerów może nie być obojętna dla osób uzależnionych od języka, ponieważ mają one trudności z zapamiętywaniem wypowiadanych cyfr i ponieważ w innych eksperymentach pamięciowych organizują one elementy w sensowne grupy. Jeśli przeprowadzamy eksperyment i stwierdzamy, że obie formy grupowania cyfr są zapamiętywane równie dobrze, to moglibyśmy dojść do wniosku, że forma nie ma żadnego wpływu na zapamiętywanie. Jednakże jest prawdopodobne, że większość osób badanych była niezależna od języka; gdyby zbadano więcej osób uzależnionych od języka to mogłaby wystąpić różnica między zapamiętywaniem obu tych form.  Względna proporcja osób uzależnionych i osób niezależnych od języka w danych warunkach eksperymentalnych może mieć zatem większy wpływ na wyniki niż jakieś zmienne bodźcowe lub zadaniowe.
Stosunek liczby osób uzależnionych od języka do liczby osób niezależnych od języka mógłby także być przyczyną zmienności, jaka niekiedy występuje przy powtarzaniu tego samego typy eksperymentu. Gdy w pewnych warunkach eksperymentalnych uzyskuje się lepsze wyniki niż w innych warunkach, lecz zdarza się to jedynie w niektórych eksperymentach, to jest możliwe, że różnica między warunkami nie ma istotnego wpływu, lecz jest też możliwe, że stosunek liczby osób uzależnionych od języka do liczby osób niezależnych od języka w badanej próbie zmieniał się znacznie w różnych eksperymentach i że różnice między warunkami wpływają tylko na jedną z tych grup osób.
Na koniec, niektóre bardzo dobrze znane i często powtarzające się wyniki badań mogą być oparte na „uśrednianiu” różnych układów danych. Możliwe jest zatem, że pewne ogólnie akceptowane modele procesów poznawczych są oparte na „uśrednionych danych”, które nie odzwierciedlają prawidłowości występujących u poszczególnych osób badanych.




Implikacje praktyczne




Osoby uzależnione od języka zdają się być tak doskonale „dostrojone” do struktury ich języka, że mają trudności, gdy trzeba zmieniać jego zasady.  Na przykład, w eksperymencie z „tajnym językiem” osoby badane musiały zmieniać w wymawianych słowach wszystkie („r”) na („I”) i na odwrót. W ten sposób ROCKET zmienia się w LOCKET, zaś NELSON ROCKEFELLER staje się NERSONEM LOCKEFELLEREM. Osoby uzależnione od języka popełniają w tym zadaniu znacznie więcej błędów niż osoby niezależne od języka. Podobnie osoby uzależnione od języka mają trudności przy powtarzaniu pewnych słów w obcych językach; na przykład, wymawiają one litewskie słowo TSNOTA jako SNOTA, podczas gdy osoba niezależna od języka powtarzają to słowo dokładnie. Podczas prywatnych rozmów dowiedziałam się, iż osobom uzależnionym od języka trudno jest nauczyć się rozmawiać w obcym języku (aczkolwiek mogą one bez trudności czytać), podczas gdy osoby niezależne od języka osiągają biegłość w mówieniu (aczkolwiek mogą popełniać błędy gramatyczne). Te eksperymenty i opinie prywatne sugerują, że w stosunku do osób uzależnionych i niezależnych od języka skuteczne mogą być odmienne metody nauczania języków obcych.
Jeśli u małych dzieci występuje wzorzec uzależnienia i wzorzec niezależności od języka, to użyteczne mogłoby być stosowanie różnych metod przy uczeniu czytania.


Jednostki niezależne od języka mogłyby odnieść więcej korzyści z metody fonetycznej, w której kładzie się nacisk na związku między dźwiękami, a literami, jednostki zaś uzależnione od języka - z tradycyjnej metody „patrz i mów”.
Jeśli chodzi o ogólne techniki nauczania rozmaitych przedmiotów na wszelkich poziomach kształcenia, to jest kwestią otwartą, czy specyficzne metody mogą lub powinny być opracowane dla nauczania różnych typów ludzi.  Niemniej jednak uświadomienie sobie dużych różnic, jakie mogą występować w procesach poznawczych (nawet w populacji o dość różnorodnym poziomie inteligencji), powinno mieć pewien wpływ na sposób nauczania.




Kilka słów ostrzeżenia




Uzyskawszy w pewnej dziedzinie zbiór uderzających różnic indywidualnych, odczuwa się pokusę, by uznać owo zróżnicowanie za panaceum umożliwiające usystematyzowanie obserwacji dokonanych w innych sytuacjach i by próbować „korelować je” ze wszystkim, z czym tylko można. Chociaż nawet moglibyśmy mieć nadzieję, że nadamy jakiś sens masie zebranych w ten sposób danych (być może przez zastosowanie różnych technik analizy czynnikowej), to takie podejście zdaje się jednak prowadzić w fałszywym kierunku - ponieważ jest ono |nieukierunkowane. Musi istnieć jakaś podstawa teoretyczna dla analizowania zachowań, które osoby uzależnione od języka i niezależne od języka przejawiają w różnych sytuacjach.
Każda osoba jest oczywiście jedyna w swoim rodzaju, unikatowa pod różnymi względami. Jednakże nie o to chodzi w tej pracy. Chociaż występowałam przeciw skrajnemu |nomotetycznemu podejściu w badaniu procesów poznawczych, to jednak chce się także wypowiedzieć przeciwko podejściu skrajnie |idiograficznemu, w którym doktryna unikatowości jest tak dominująca, iż dla różnych jednostek nie próbuje się szukać wspólnych „zasad”. Tymczasem podejście nomotetyczne i idiograficzne mogą tworzyć pewne kontinuum, gdzie różne problemy lepiej jest badać bliżej jednego lub drugiego z jego krańców. W niniejszej pracy stwierdziłam, że użyteczne jest zajęcie pozycji bliższej nomotetycznego krańca tego kontinuum, lecz nie na samym jego krańcu; wydaje się, że istnieją ogólne zasady rządzące procesami poznawczymi, jednakże zasady takie nie dotyczą „wszystkich” ludzi, lecz jedynie osób wchodzących w skład danej „grupy”, przy czym liczba takich grup jest niewielka. Grupy te różnią się wyraźnie między sobą, lecz operacje poznawcze dokonywane przez ludzi należących do danej grupy wykazują znaczne podobieństwa.




III. Bodźce: zewnętrzne
i wewnętrzne




6. Spostrzeganie
7. Zmienione stany świadomości




Rozdział 6.
Spostrzeganie




Każdy z nas, zamknięty w „doczesnej powłoce” swego ciała, przez całe życie stara się odkryć, jaki naprawdę jest świat zewnętrzny i jacy naprawdę są inni ludzie. W jaki sposób dochodzimy do poznania natury tej niewiarygodnie złożonej rzeczywistości zewnętrznej? Jak to jest możliwe, że nasze oczy chwytają wzory, kształty i wszelki ruch wokół nas, a nasze uszy dostrajają się do dźwięków mowy, rytmów muzyki i głosów dzikiej przyrody?  Percepcja stanowi klucz, który otwiera drzwi do wszystkich tych aspektów otaczającego nas świata.
To właśnie nasze procesy percepcyjne pozwalają nam odnaleźć stałość i ciągłość w nieustannie zmieniającym się świecie. Percepcja jest porządkującą zasadą, która nadaje spójność kalejdoskopowemu wejściu sensorycznemu i sensowną jedność odrębnym elementom, umożliwiając zorganizowanie i ukierunkowanie naszego zachowania. Bez tych organizujących procesów percepcyjnych nie widzielibyśmy przedmiotów, przestrzeni, zdarzeń, ruchu, ludzi czy relacji, lecz dryfowalibyśmy przez świat bezsensownych, przypadkowych wrażeń.
Nasz układ nerwowy jest niezwykle czułym urządzeniem wykrywającym i reagującym, które pozwala nam odpowiadać w sposób wielce zróżnicowany na fizyczne właściwości naszego środowiska. W jednej chwili około |stu |milionów impulsów wejściowych, pochodzących ze źródeł światła w otoczeniu, jest przekazywanych do przetwarzających ośrodków w siatkówce oka i mózgu.  Prawdopodobnie w tym samym czasie przetwarzamy wejścia dotyczące dźwięków, temperatury, smaków, zapachów, naszej pozycji ciała i aktywności mięśniowej, jak również informacje generowane przez potrzeby fizjologiczne, oczekiwania, odpowiednie minione doświadczenia itd. Te odrębne bity informacji są analizowane, organizowane i integrowane, po czym zostaje podjęta decyzja, aby zareagować w pewien sposób. Ocenia się, że wytwarzane w ten sposób „polecenia”, płynące z naszych mózgów do naszych poszczególnych mięśni, są wydawane nieustannie - w tempie przynajmniej pięciu na sekundę!
Nasze systemy percepcyjne, umożliwiające widzenie, słyszenie, smakowanie, wąchanie, odczuwanie dotyky i temperatury ewoluowały przez niezliczone pokolenia tak, że każdy z nas zaczyna życie wyposażony w skomplikowany zbiór mechanizmów zaprogramowanych przez nasze geny, a fizjologicznie „uruchomionych” w momencie urodzenia. Jednakże mechanizmy te, chociaż tak skomplikowane, są nadal plastyczne, zdolne przystosowywać się do nowych sytuacji i doświadczeń życiowych, a zatem mogą ulegać modyfikacji w wyniku uczenia się.
W dodatku spostrzeganie jest czymś znacznie więcej, niż jedynie przetwarzaniem fizycznej energii bodźców w energię impulsów nerwowych, a następnie z powrotem w fizyczną energię, która może oddziaływać na otoczenie. Pierwsze stadium tego procesu możemy rozpatrywać jako stadium polegające na podstawowej recepcji bodźców (co określa się jako |wrażenie), a późniejsze stadia jako wymagające znacznie większej aktywności z naszej strony przy odrzucaniu większości napływającej informacji, selektywnym organizowaniu odbieranej informacji, interpretowaniu jej i kierowaniu naszej uwagi tak, aby przyjąć jeszcze więcej danych wejściowych lub też zwrócić się gdzie indziej w poszukiwaniu nowych bodźców.
Dość uogólnień. Teraz zaprezentujemy „sztukę magiczną” dla zilustrowania znaczenia określenia „funkcjonalne piękno procesu percepcyjnego”. Jest to bardzo prosta sztuka, a więc patrz uważnie, bo w przeciwnym razie nic nie zauważysz.
|Faza |pierwsza - zaciśnij swoją lewą dłoń w pięść, podnieś kciuk do góry i wyciągnij tę rękę na całą długość w tym kierunku, w którym patrzysz.
|Faza |druga - skoncentruj wzrok na twoim kciuku. Teraz sprawisz, że trzykrotnie zniknie on sprzed twoich oczu!
|Faza |trzecia - patrz nadal w kierunku swego kciuka. Teraz zamknij powieki na kilka sekund... Twój kciuk zniknął („numero uno”)!
|Faza |czwarta - spójrz znów w kierunku swego wyciągniętego kciuka, lecz po przeczytaniu następnego polecenia, ponownie zamknij oczy. Teraz „ukryj” lewą dłoń za swymi plecami. O. K., otwórz oczy - nie ma przed nimi żadnego kciuka!
|Faza |piąta - przygotuj się do wielkiego numeru! Przenieś znów swoją lewą rękę w pierwotne położenie (wyciągnij ją przed siebie) i niech tam pozostanie. Nie poruszając głową obracaj oczyma, dopóki nie spojrzysz w sufit. Czy widzisz swój lewy kciuk, czy też zniknął on znowu? Teraz zamknij powieki i powoli obracaj głowę tak daleko w prawo, jak możesz. Otwórz teraz oczy. „Presto”, twój kciuk zniknął zupełnie, po raz trzeci! (Po pewnym ćwiczeniu będziesz umiał sprawić, że pojawi się on ponownie - równie szybko jak zniknął).
Co? Mówisz, że nie wywarło to na tobie specjalnego wrażenia? Mówisz, że twoja dłoń nigdy |naprawdę nie zniknęła? Mówisz, że nie było w tym nic magicznego, ponieważ wiedziałeś, gdzie ona była za każdym razem? Lecz, czy naprawdę? |Skąd wiedziałeś, że twoja ręka nie znikła, gdy nie patrzyłeś na nią, że twoje powieki poruszały się, a nie twoje ręce czy oczy, i że twoje gałki oczne poruszały się, a nie twoje powieki, ręka czy głowa, i że twoja głowa poruszała się, lecz twoja ręka pozostała dokładnie tam, gdzie była? W jaki sposób mógłbyś określić różnicę pomiędzy tym, co |naprawdę |widziałeś, a tym, co |naprawdę |było? Odpowiedz, proszę, na te pytania, zarówno na molarnym, jak i na molekularnym poziomie analizy. I jeszcze jedno pytanie.  W jaki sposób czarne znaczki na tej stronie zostały przełożone na milczący, niemy kod, który przekazał nasze polecenia do twego mózgu, co z kolei mamy nadzieję, doprowadziło do wydania poleceń wykonawczych dla określonych układów mięśni w twoim ciele? To naprawdę jest „magiczne”.
Zanim przejdziemy do omawiania części tej wiedzy, którą przyniosły badania nad percepcją i która zaczyna dostarczać odpowiedzi na niektóre z tych złudnie prostych pytań, chcemy opowiedzieć ci historyjkę o trzech sposobach widzenia świata. Niektórzy ludzie sądzą, że percepcja pozwala widzieć świat realny, taki, jakim on jest. Inni utrzymują, że tym, o czym możemy coś wiedzieć, jest wyłącznie nasz własny proces percepcji - innymi słowy to, co dzieje się w naszej głowie. Może to doskonale odpowiadać temu, co zachodzi w świecie zewnętrznym, lecz może także temu nie odpowiadać. I wreszcie istnieje trzecia grupa, która twierdzi, że ważnym aspektem percpecji nie jest ani to, co jest rzeczywiste, ani to, co zdajemy się widzieć, lecz raczej to, w jaki sposób ustalamy nazwy i określenia tego, co spostrzegamy.
Poniższa historyjka, o tym, jak trzech sławnych sędziów baseballowych identyfikuje „strzał”, dobrze ilustruje to zróżnicowanie poglądów na to, czego dotyczy percepcja. Ponieważ wynik całego meczu może zależeć od jednego zawołania sędziego („strzał” lub „piłka”), jest więc oczywiście rzeczą ważną, aby decyzja była tak obiektywna i „ścisła”, jak to tylko jestmożliwe.
„No, cóż” - powiedział pierwszy sędzia - „ja kucam tuż za bramkarzem i wpatruję się w rękę zawodnika rzucającego piłkę, następnie w piłkę i jej trajektorię, gdy przechodzi ona przez bramkę. Wtedy po prostu |mówię |to, |co |jest”.
„Moje podejście jest nieco inne” odpowiedział drugi sędzia. „Ja także staję tak blisko bramki, jak mogę, wpatruję się w piłkę, w bramkę i zawodnika, lecz następnie po prostu |mówię |to, |co |widzę”.
„Dla mnie, powiedział trzeci sędzia, „nie ma naprawdę znaczenia, czy stoję blisko czy daleko, czy patrzę na jednego czy na drugiego zawodnika, ponieważ gdy zawodnik atakujący rzuci piłkę w moim kierunku, to |jest |ona |niczym, |dopóki |jakoś |jej |nie |nazwę”.




Problem i paradoks
percepcji




Naiwni obserwatorzy przyjmują bezkrytyczne świadectwo swych zmysłów.  Sądzą oni, że po prostu spostrzegają to, co jest. Przyjmują oni za pewnik, że mają bezpośredni kontakt z zewnętrznym światem i bezpośrednią jego znajomość. Mają oni „wyraźne poczucie pewności” w odniesieniu do poprawności swych spostrzeżeń i zakładają, że inni obserwatorzy będą spostrzegać tę sytuację w ten sam sposób - o ile nie są „świadomie przewrotni”. Stanowisko to znane jest pod nazwą |absolutyzmu |fenomenalistycznego.
Podobnie jak student, którego zostawiliśmy pod prysznicem w trzecim rozdziale, potrafisz powiedzieć, jaka jest różnica między zimną a gorącą wodą. Z pewnością cecha „gorącości” jest zlokalizowana w wodzie! Naprawdę?  Jeśli tak sądzisz, to możesz spróbować wykonać eksperyment, który John Locke zaproponował w 1960 roku. Włóż jedną rękę do garnka z gorącą wodą, drugą rękę - do garnka z zimną wodą i trzymaj je tam przez kilka minut.  Następnie włóż je obie do trzeciego naczynia napełnionego letnią wodą. Wodę tę jedna ręka będzie odczuwać jako zimną, a druga - jako ciepłą, chociaż, jak wskazał Locke prawie trzysta lat temu, „jest niemożliwe, aby ta sama woda, gdyby naprawdę zawierała te idee, była jednocześnie zarówno gorąca, jak i zimna”.
Nowsze eksperymenty również wykazują, że to, co spostrzegasz, może nie być tym, czym jest, mimo twojej pewności. Wiesz na przykład, kiedy coś jest wyżej lub niżej (względem ciebie), ponieważ to |jest wyżej lub niżej, prawda? Podobnie wiesz, kiedy coś porusza się w stosunku do innych nieruchomych przedmiotów, ponieważ to |się |porusza!


„W pewnej serii eksperymentów badanych sadzano w krzesłach w pomieszczeniu, które było normalne - z wyjątkiem jednej cechy - można je było przechylać (ryc. 6.1). Kiedy badani w tych krzesłach byli nieruchomi, a pomieszczenie przechylało się, wówczas ich percepcja góry i dołu była zaburzona, ponieważ zakładali oni, że to oni sami i przedmioty w pomieszczeniu mogą przechylać się, lecz ściany zawsze pozostają pionowe.  Spostrzegali oni zatem przechylone ściany jako nie zmienione i pionowe, a samych siebie i inne pionowe przedmioty w pokoju jako przechylone” (Witkin, 1954).


Podobne zjawisko opisują niektórzy pasażerowie olbrzymich odrzutowców, którzy mówią, że przy starcie samolotu wydaje im się, że to ziemia opada w dół, a nie, że oni się unoszą.




* * *



Ryc. 6.1. W przedstawionym tu pomieszczeniu można przechylać albo fotel osoby badanej (na pierwszym planie), albo „ramę bodźcową”, albo jedno i drugie. W ciemności, w której widoczna jest tylko rama bodźcowa, badany musi wskazać, kiedy jest ona ustawiona pionowo. 


* * *





Za każdym razem, gdy idziesz do kina, widzisz ruch, którego nie ma.  Płynny ruch aktorów składa się z serii pojedynczych klatek, które pojawiają się w tempie 24 na sekundę. W obrębie klatek nie ma żadnego ruchu, a jednak widzisz ruch. Taki sam pozorny ruch jest podstawą reklam neonowych, w których kolorowe figurki bez końca wykonują jakąś prostą czynność, a także gazet świetlnych, w których słowa zdają się przebiegać z jednej strony na drugą. W rzeczywistości na ekranie po prostu zapalają się i gasną poszczególne żarówki, lecz jeśli te „nieruchome zdarzenia” są właściwie zsynchronizowane, a bodźce są dostatecznie blisko siebie w przestrzeni, to widzisz ruch. Takie spostrzeganie jednego poruszającego się światła, zamiast dwóch lub więcej nieruchomych świateł zapalających się i gasnących, nosi nazwę |zjawiska |f (zjawiska fi; phi phenomenon).
Zadaniem percepcji jest dekodowanie napływającej informacji w taki sposób, aby identyfikować stałe cechy i relacje w otaczającym nas świecie i w ten sposób czynić go przewidywalnym, tak abyśmy mogli odpowiednio z nim postępować. W niniejszej dyskusji skoncentrujemy się głównie na wzroku - ze względu na jego dominującą rolę w sterowaniu zachowaniem człowieka.




Oszustwa percepcji




Dżungle tropikalne, w których żyją Pigmeje ze szczepu BaMbuti są tak gęste, że krajowcy rzadko mogą widzieć dalej niż na odległość kilku jardów w jakimkolwiek kierunku. W takich warunkach podczas polowania muszą oni polegać głównie na sygnałach dźwiękowych. Rzadko stają wobec konieczności dokonywania ocen percepcyjnych opartych na sygnałach wzrokowych dotyczących odległości czy różnicowania głębi. Jedną z godnych uwagi konsekwencji tego „naturalnego” eksperymentu opisuje antropolog Colin Turnbull (1961). Gdy pewien Pigmej, którego nazywano Kenge, udał się z Turnbullem na otwartą równinę, gdzie wzrok mógł wędrować bez przeszkód, wówczas natura (czy wychowanie?) nagle zaczęła płatać mu figle. Turnbull opisuje:


„Kenge patrzył na równinę, tam, gdzie w odległości kilu mil pasło się stado złożone ze 100 mniej więcej bawołów. Zapytał mnie, co to jest za rodzaj |owadów, a ja powiedziałem mu, że to są bawoły - dwa razy większe od znanych mu bawołów zamieszkujących dżunglę. Zaśmiał się głośno i powiedział mi, żebym nie opowiadał takich głupich historyjek i zapytał mnie znowu, co to za rodzaj owadów. Następnie mówił sam do siebie, poszukując widocznie bardziej inteligentnego towarzystwa i próbował porównywać bawoły do różnych znanych mu żuków i mrówek.
Nadal robił to samo, gdy wsiedliśmy do samochodu i pojechaliśmy tam, gdzie pasły się zwierzęta. Obserwował je, jak stawały się coraz większe i chociaż był on równie odważny, jak każdy Pigmej, przesiadł się bliżej mnie i mruczał, że to są czary (...). W końcu, gdy uświadomił sobie, że to są prawdziwe bawoły, przestał się bać, lecz nadal zastanawiał się, dlaczego były takie małe i czy one naprawdę były małe i nagle urosły większe, czy też był to jakiś rodzaj oszustwa” (s. 305).


Kenge starając się zachować racjonalne wyjaśnienie swego świata, przypisywał takie kapryśne zmiany w percepcji czarom lub oszustwu. Gdy my staramy się wyjaśnić takie złudzenie (i utrzymać założenie o „racjonalności” świata) wówczas zakładamy, że można znaleźć przyczyny naturalne. Szukamy wyjaśnienia albo w niezwykłych warunkach bodźcowych, albo w specyficznej historii doświadczeń osoby spostrzegającej.
Z ten anegdoty wynika kilka wniosków. Zakładamy, podobnie jak ów Pigmej, że przedmioty takie jak bawoły nie zmieniają drastycznie swej wielkości w krótkim czasie. W znanym nam otoczeniu spostrzegamy przedmioty jako zachowujące swą wielkość, bez względu na naszą odległość od nich (spostrzeżenia Turnbulla). W nieznanym środowisku percepcyjnym może wydawać się, że wielkość przedmiotów zmienia się w zależności od odległości (spostrzeżenia Kenge’a), lecz staramy się dopasować nowe spostrzeżenia do znanych kontekstów czy układów odniesienia. (Kenge porównywał te „owady” do żuków). Wreszcie w niezwykłych warunkach bodźcowych nasze normalne spostrzeganie może zmienić się tak, że ulegamy złudzeniom. To właśnie zdarzyło się, gdy Kenge zbliżając się do bawołów w szybko jadącym samochodzie widział, jak zwierzęta te rosną.
Doświadczenie percepcyjne - to, jak dana rzecz przedstawia się obserwatorowi - zwane jest |spostrzeżeniem (lub bardziej formalnie |doświadczeniem |fenomenologicznym). Spostrzeganie ocenia się jako |prawdziwe, gdy dane spostrzeżenie jest zgodne z innymi wskaźnikami tych cech danego obiektu, które można mierzyć i weryfikować niezależnie. Z analogicznych danych, które omówimy później, wiemy, że Kenge prawdopodobnie zaczął spostrzegać świat we właściwy sposób, nawet z odległego punktu widzenia (tak, jak to czynił Turnbull), gdy przekonał się, że przedmioty, które widział, były w rzeczywistości bawołami.


Percepcja złudzeń. Czy byłoby możliwe, abyś ty - doświadczony „spostrzegacz” - miał tak wypaczony obraz rzeczywistości, jak ów „prymitywny człowiek”? Spójrz na zamieszczone obok trzy fotografie. Czy widziesz, że człowiek ten staje się dwa razy wyższy - w miarę jak przechodzi przez pokój? Gdybyś zwinął kartkę papieru w rurkę i spojrzał przez nią na tego człowieka na kolejnych fotografiach, to zjawisko to byłoby jeszcze bardziej uderzające (ryc. 6.2). Ty |wiesz, że to nie jest możliwe. Jak to się stało?
Figura zamieszczona na następnej stronie (ryc. 6.3) znana jest dobrze jako złudzenie Mullera-Lyera. W górnej części dwa odcinki linii poziomej wydają się mniej więcej równe pod względem długości, choć nie są równe; na dole wydają się one różne, lecz są takie same. Zmierz je i sam się przekonaj.




* * *



Ryc. 6.2. Tę serię fotografii wykonywano wtedy, gdy widoczny na nich człowiek przechodził przez pokój. Pokój nie zmienił się ani człowiek nie urósł. Jak wyjaśnisz to, co widzisz?


* * *





Psychologowie interesują się złudzeniami, ponieważ mogą one stanowić klucz do zrozumienia całego spostrzegania.


Oszukująca siatkówka i wędrujące oko. Jeśli złudzenia te przekonały cię, że twoje oczy i mechanizmy interpretacyjne są nierzetelne i nie można im wierzyć, to zastanówmy się nad podstawowym aparatem percepcyjnym, jaki posiadasz, i nad pracą, jaką musi on wykonywać. Na dnie oka znajduje się siatkówka mająca mniej więcej dwa i pół centymetra średnicy, która otrzymuje wszelką informację sensoryczną przechodzącą przez soczewki i musi przekazać ją do mózgu, gdzie zachodzi złożony proces jej przetwarzania.  Lecz jakiego rodzaju informacje w rzeczywistości ona przesyła? Ponieważ siatkówka jest powierzchnią dwuwymiarową, musi ona zatem przesyłać układy dwuwymiarowe reprezentujące świat trójwymiarowy. A ponieważ siatkówka jest tak mała, soczewki muszą znacznie zredukować wielkość tego, co jest na zewnątrz. Ponadto, ponieważ obrazy zostają odwrócone, gdy światło przechodzi przez soczewki, siatkówka „widzi” świat do góry nogami.
Jeszcze bardziej komplikuje sprawę fakt, że oko nieustannie porusza się we wszystkie strony. To nieustannie poruszające się oko podlega słabym, lecz ciągłym |drganiom o wysokiej częstotliwości. Ponadto, wykonuje ono |ruchy |skokowe („saccadic movements”), czyli nieregularne poruszenia tam i z powrotem. Jednakże przedmioty, które widzisz, nie drgają ani nie skaczą tam i z powrotem. (A choćbyś, patrząc w lustro, starał się jak najbardziej, nie udałoby ci się dostrzec, że twoje oczy zmieniają punkt, na którym się koncentrują).
Spójrz po kolei na rogi tej stronicy. Gdy czynisz to, obraz na siatkówce porusza się i zmienia, jednakże ty spostrzegasz siebie samego i kartkę jako niezmiennych i nieruchomych, w zgodzie z „faktami”. A teraz poruszaj stronicą, utrzymując oczy wpatrzone w jeden punkt. W jaki sposób siatkówka odróżnia te dwie sytuacje?
W jakiś sposób widzimy świat jako ciągły, z dołem i górą na właściwych miejscach, „naturalnej wielkości” i pełny trójwymiarowych przedmiotów, a także zwykle potrafimy odróżnić ruch w świecie od ruchu w nas. Gdyby percepcja ograniczała się do przekazywania z siatkówki, to istotnie mielibyśmy dziwny obraz tego, jaki świat „jest naprawdę” (ryc. 6.4).




Wiarygodność percepcji




Oszustwa percepcji, które wykrywamy w złudzeniach, zaskakują nas właśnie dlatego, że nasz system percepcyjny jest zwykle bardzo rzetelny. Nasz system wzrokowy zasłużył sobie na zaufanie, ponieważ w normalnych warunkach wizualnych informacja, jakiej dostarcza, jest dokładna i użyteczna, pomagając nam przystosowywać się do naszego środowiska i zmieniać je.  Ponieważ spostrzeganie przebiega zazwyczaj tak dobrze, tak prosto, tak bez wysiłku i „nieświadomie”, dlatego musimy zakłócić ten system (jak w przypadku złudzeń), aby uświadomić sobie ogromną złożoność wchodzących w grę procesów fizjologicznych i psychologicznych.
W jaki sposób akt percepcyjny dostarcza stałego, zorganizowanego, spójnego i sensownego obrazu rzeczywistości, pomimo wszystkich przyczyn zawodności, które już poznaliśmy? Gdy poszukujemy wyjaśnienia złudzeń lub staramy się zrozumieć, w jaki sposób system percepcyjny ustanawia stały związek pomiędzy |obiektywną |rzeczywistością a |rzeczywistością |spostrzeganą - naszym doznawaniem tego, co istnieje - wówczas ujawnia się sieć wzajemnie powiązanych procesów.


System percepcyjny działa podobnie jak komputer, pobierając informację z różnych źródeł, selekcjonując ją, integrując, abstrahując, porównując, sprawdzając, sortując, wyprowadzając na wyjście, a następnie powtarzając te wszystkie operacje od nowa. Każdy akt percepcyjny jest konstruowaniem czy tworzeniem rzeczywistości na podstawie wszystkich istotnych informacji - przeszłych i aktualnych - które są dostępne dla organizmu.
Percepcja nie jest zatem bynajmniej bezpośrednim doświadczeniem rzeczy „takimi, jakimi są”, lecz |pośrednim procesem zorganizowanego wyciągania wniosków o „rzeczywistym” świecie czasu, przestrzeni, przedmiotów i zdarzeń, który to proces opiera się na znacznie bogatszych danych niż samo tylko wejście bodźcowe. Aby więc wyodrębnić „percepcje” czy „spostrzeganie” jako dziedzinę badań, psychologowie muszą ustanawiać |arbitralne granice pomiędzy różnymi procesami odbierania wrażeń, uwagi, pamięci, uczenia się itd., które w rzeczywistości nie są w ogóle odrębne, lecz ściśle i dynamicznie powiązane między sobą.
Co takiego |zapewnia ci twój system percepcyjny, na co możesz liczyć i w jaki sposób dokonuje on tego?


Dokładność i precyzja spostrzegania. Miarą ostrości wzroku jest łuk na obwodzie wyimaginowanego koła, którego środkiem jest oko. W sprzyjających warunkach nasza ostrość wzroku jest tak wielka, że możemy dostrzec oddzielnie linie, kiedy odległość między nimi wynosi mniej niż jedną minutę łuku - mniej niż 1/60 stopnia (a pamiętamy, że koło ma 360 stopni). Każde oko, chociaż tak małe, ma 125 milionów podstawowych elementów receptorowych. Nasz wzrokowy system rozpoznawania wzroców jest najbardziej skomplikowanym i dokładnym systemem, jaki znamy - o wiele lepszym niż jakikolwiek zbudowany dotychczas komputer.
Oko może wykryć zwierzę znajdujące się na odległej górze lub linie papilarne na odcisku palca - i może błyskawicznie zmieniać swoja ogniskową wydłużając ją lub skracając. Sprawnie kieruje ono subtelną koordynacją wzrokowo-ruchową zegarmistrza i neurochirurgia. W jakiś sposób potrafi dokonać tego wszystkiego, chociaż cały czas samo się porusza; a kiedy obraz na siatkówce zmienia się, oko potrafi stwierdzić (jak już wiemy), czy jest to spowodowane ruchem w świecie zewnętrznym czy też ruchem głowy lub oczu.


Stałość spostrzegania. Weź do ręki małe pudełeczko i poruszaj nim powoli w jedną i drugą stronę, najpierw na długość wyciągniętej ręki, a następnie blisko twarzy, w świetle słonecznym, a następnie w cieniu. Nie wydaje się, aby pudełko to zmieniało swój kształt, wielkość czy jasność, chociaż jego obraz na siatkówce zmienia się drastycznie przy każdym z tych ruchów.
Stałość naszego spostrzegania wzrokowo świata zależy od |stałości |spostrzegania |przedmiotów - spostrzegania ich jako istniejących w sposób ciągły (jako tych samych przedmiotów), pomimo zmian pod względem wielkości, kształtu i położenia obrazu na siatkówce. W rywalizacji o to, które źródło bodźców będzie dominować w ostatecznej ocenie percepcyjnej, stymulacja, jaką otrzymujemy od rzeczywistego przedmiotu (|bodźce |dystalne, |odległe - „distal”) musi wziąć górę nad stymulacją ze wzorca na siatkówce (|bodźce proksymalne, |bliskie - „proximal”), jeśli spostrzeżenie nasze ma być dokładne. Paradoks percepcji polega na tym, że tak właśnie się dzieje; to czego doświadczamy subiektywnie, w istocie ścisłej odpowiada obiektywnemu układowi bodźców z zewnątrz niż obrazowi na naszej siatkówce. |Stałość |wielkości w spostrzeganiu uzyskujemy na przykład integrując przychodzące dane o wielkości obrazu na siatkówce z ocenami odległości. Informacja zmagazynowana w pamięci o zwykłych odległościach i wielkościach znajomych przedmiotów również może brać udział w tym procesie. Ludzie widziani ze szczytu drapacza chmur wyglądają jak mrówki, podobnie jak wyglądały bawoły Kenge’a z odległości kilku mil.


Gdy znajdujesz się w nowej sytuacji i sygnały, na których musisz opierać się przy ocenie odległości, są niewystarczające lub niejednoznaczne, wówczas stałość wielkości przestaje być zachowywana i twój system percepcyjny ucieka się do dostępnej mu informacji - a mianowicie starej, poczciwej, nierzetelnej stymulacji bliskiej.
Regularność w złudzeniach. Złudzenia nie są bynajmniej anormalnymi przykładami naszej dziwacznej percepcji, lecz dostarczają mnóstwo informacji o tym, co jest niezbędne dla normalnego, dokładnego spostrzegania. Nie są one przejawami defektów w naszym systemie percepcyjnym, lecz raczej ukazują jego mocne strony. Wykazują one, w jakim stopniu percepcja nie jest całkowicie uzależniona od każdego bitu informacji bodźcowej w naszym aktualnym środowisku. Dzięki temu nie jesteśmy zależni od bodźców („stimulus-bound”) i możemy posługiwać się naszymi spostrzeżeniami w procesie myślenia - przekonaliśmy się o tym w naszych rozważaniach nad koncepcją Piageta.
Wyjaśnieniem dla niektórych złudzeń percepcyjnych, rozpatrywanych przez nas poprzednio, jest po części nowy układ sygnałów lub połączenie tych sygnałów w taki sposób, który zmienia ich użyteczność. Zamiast spostrzegać dosłownie to, co jest na zewnątrz, odbieramy wrażenie, które wskazuje wyraźnie na istnienie dodatkowego wejścia informacyjnego z naszych własnych oczu, mózgu lub jednego i drugiego.
Czy zauważyłeś kiedyś, że Księżyc wydaje się o wiele większy wtedy, gdy jest nad horyzontem, niż wtedy, gdy jest wysoko na niebie? Ponieważ wiemy, że jego wielkość naprawdę nie zmienia się każdej nocy, gdy wędruje on po niebie, a więc spostrzegana przez nas zmiana jego wielkości jest złudzeniem. Złudzenie to omawiał już w II wieku naszej ery grecki astronom Ptolomeusz. Tłumaczy się je niekiedy tym, że zwraca się wówczas oczy ku górze lub też, że przy patrzeniu w górę ulegają napięciu mięśnie szyi.
Jedno z wyjaśnień tego szczególnego złudzenia odwołuje się do kombinacji dwóch zasad: zasady stałości wielkości oraz zasady stanowiącej podstawę „złudzenia torów kolejowych”. Przedmioty znajdujące się blisko horyzontu spostrzega się jako większe, ponieważ ocenia się, że znajdują się dalej. Ta błędna ocena sygnałów odległości prowadzi do przełamywania zachowanej zwykle zasady stałości wielkości (Kaufmann i Rock, 1962).
W jaki sposób człowiek stał się olbrzymem, gdy szedł przez pokój? Uległeś temu złudzeniu, ponieważ zakładałeś, że pokój jest prostokątny, podczas gdy w rzeczywistości był on trapezoidalny. Prawy róg w rzeczywistości znajdował się znacznie bliżej kamery. Ponieważ zakładałeś, że pokój jest normalny i nie dysponowałeś rzetelnymi sygnałami co do odległości, przeto przyjąłeś większy obraz na siatkówce za dobrą monetę i wydawało ci się, że człowiek rzeczywiście rośnie.




* * *



Ryc. 6.6. Rysunki te przedstawiają widok z przodu i góry na pokój. Gdy widoczny na nich człowiek przechodził z punktu 1 przez punkt 2 do punktu 3, to w rzeczywistości zbliżał się do kamery, ustawionej w punkcie A; dlatego też wydaje się coraz większy na każdej kolejnej fotografii. Zdjęcia „zniekształconego pokoju” zamieszczono za zezwoleniem Exploratorium, San Francisco.


* * *





Inne złudzenia zdają się być skutkiem przesadnych lub niekontrolowanych tendencji organizujących, które występują w związku z wszelkim spostrzeganiem (zostaną one omówione w dalszej części niniejszego rozdziału).




Jak odbieramy informację?




Informację o naturze środowiska zewnętrznego wykrywają różne narządy, złożone z wysoce wyspecjalizowanych |komórek |receptorowych. Na ogół każdy narząd receptorowy jest wrażliwy na jeden tylko typ fizycznych lub chemicznych właściwości środowiska - na przykład na fale dźwiękowe lub fale świetlne. Jednakże te różnice nie są absolutne. Oko, na przykład chociaż „nastrojone” na wykrywanie fal świetlnych, będzie także reagować na nacisk palca dotykającego powieki - co możesz sprawdzić empirycznie (lecz ostrożnie, proszę!) na samym sobie.
Organizm potrafi wykrywać trzy właściwości bodźców środowiskowych: a) ich ogólną kategorię, czyli reprezentowany przez nie typ energii - na przykład świetlnej, termicznej, mechanicznej, b) ich lokalizację w przestrzeni, c) ich natężenie w poszczególnych momentach.
Informacje o pierwszej z tych właściwości - kategorii bodźca - przekazuje do organizmu typ receptora, który został pobudzony. Na przykład komórki receptorowe oka są wrażliwe na stymulację falami świetlnymi w pewnym paśmie częstotliwości promieniowania elektromagnetycznego. Wskazówek co do drugiej właściwości - lokalizacji bodźca - dostarcza lokalizacja pobudzanych receptorów, ponieważ receptory dla każdej klasy wejścia bodźcowego są zwielokrotnione.
Wykrywanie trzeciej właściwości, to znaczy natężenia bodźca, dokonuje się w wyniku procesu zwanego |transdukcją. Jest to proces dwufazowy, w którym natężenie bodźca przekładane jest na |potencjał |generatorowy (depolaryzację błony receptorowej), który z kolei przekłada się na częstotliwość impulsów nerwowych. Przy silniejszej stymulacji komórka reaguje większą częstotliwością, a ponadto reaguje więcej komórek. Gdy informacja przyjmie formę impulsów nerwowych, wówczas może być przekazywana zgodnie z podstawowymi zasadami przekazywania nerwowego, które opisaliśmy w Rozdziale 2.
Bodziec musi mieć pewną siłę, zanim receptory czuciowe będą mogły w ogóle go wykryć. Tę wielkość bodźca, który jest dostatecznie silny, aby był wykrywany poprawnie w 50% przypadków, nazywamy |progiem |absolutnym.  Wartości poniżej tego progu określa się jako |podprogowe.




Skalowanie psychofizyczne




Związek między stymulacją a wrażeniem można mierzyć albo w kategoriach fizycznej reakcji organizmu (potencjał generatorowy oraz impuls nerwowy), albo w kategoriach reakcji psychologicznej (jaka zmiana bodźca jest niezbędna, aby organizm wykrył go jako różny od poprzedniego). Techniki mierzenia reakcji psychologicznej na bodźce fizyczne nazywa się trafnie metodami |skalowania |psychofizycznego.
Jest oczywiste, że zmiany wrażenia nie są wprost proporcjonalne do zmian siły bodźca. Zapalenie jednej świeczki w jednym pokoju zauważymy od razu, podczas gdy w jasno oświetlonym pokoju dodanie tej samej świeczki nie będzie miało żadnego wpływu na nasze wrażenie jasności.
Dawniej badacze zajmujący się tą dziedziną psychologii zakładali, że ponieważ wrażenia są doznaniami subiektywnymi, przeto ich zmian nie można mierzyć w sposób obiektywny. W roku 1834 E. H. Weber wynalazł jednostkę pomiaru zwaną |ledwo |dostrzegalną |różnicą (Idr). Określa się ją podając bodziec standardowy i ustalając, o ile silniejszy musi być inny bodziec, aby był spostrzegany jako „ledwie dostrzegalnie różny” w 75% przypadków.  Potrzebny do tego przyrost bodźca (Idr) stanowi zawsze |tę |samą część wielkości pierwotnego bodźca. To znaczy, że jeśli natężenie pierwotnego bodźca wynosi 10 jednostek i dla uzyskania jednej Idr konieczny jest przyrost bodźca o 5 jednostek, to w przypadku bodźca o natężeniu 15 jednostek potrzebny będzie także przyrost o połowę jego wielkości, to jest o 7,5 jednostek itd. (Tą jednostką pomiaru można się posługiwać nie tylko w odniesieniu do natężenia, lecz także dla takich cech, jak ciężar czy wielkość).
Nieco później D. T. Fechner wysunął hipotezę, że musi istnieć pewien regularny związek pomiędzy przyrostem bodźca a przyrostem wrażenia. Był on przekonany, że za każdym razem, gdy bodziec wzrasta o jedną Idr, to wrażenie wzrasta o pewną stałą wielkość i wrażenie można by zatem zmierzyć licząc takie przyrosty. (W przypadku dźwięku jednostka przyrostu zwana jest |decybelem). Eksperymenty Fechnera doprowadziły go do sformułowania prawa Webera-Fechnera: |wrażenie |wzrasta |o |stałą |wielkość |za |każdym |razem, |gdy |natężenie |bodźca |podwaja |się. Jest to funkcja logarytmiczna. 
Niezbyt skromny Fechner przewidywał w 1877 roku:


„Wieża Babel nie została nigdy ukończona, ponieważ robotnicy nie mogli porozumieć się do co tego, w jaki sposób należy ją budować; moja budowla psychofizyczna będzie stać, ponieważ przeciwnicy nigdy nie pogodzą się co do tego, w jaki sposób ją zniszczyć”.


Ostatnio S. S. Stevens z Harvard University (1972) wykazał, że nie trzeba niszczyć budowli Fechnera: po prostu można ją zastąpić prostszą.  Stevens zaczął od zakwestionowania pierwotnego założenia, że przyrostu wrażenia nie można mierzyć bezpośrednio. Polecał on badanym, aby zaznaczali różne natężenia najrozmaitszych bodźców na skali liczbowej i stwierdził, że przeciętne wyniki dla grupy obserwatorów były stałe i powtarzalne.


Przy zastosowaniu tej nowej techniki odkrył on, że |równe |stosunki |bodźców |dają |w |wyniku |równe |stosunki |wrażeń |subiektywnych.  Określona procentowa zmiana w sile bodźca powoduje zatem stałą zmianę procentową w odczuwalnym jego efekcie. Taka zależność odpowiada |funkcji |potęgowej, a nie logarytmicznej.
Zasada ta obowiązuje dla wielu różnych rodzajów wrażeń. Stały procent dla wielu różnych rodzajów wrażeń. Stały procent wzrostu natężenia bodźca zawsze powoduje stały procent wzrostu wrażenia - chociaż procentowa zmiana wrażenia może być większa lub mniejsza niż procentowa zmiana siły bodźca.




Odmiany informacji
sensorycznej




Obecnie skoncentrujemy się jedynie na wzroku i słuchu, zmysłach, o których wiadomo najwięcej. Oprócz tych dwóch „długodystansowych” zmysłów, które dostarczają dokładnych informacji o środowisku pochodzących z dużej odległości, uzyskujemy także informacje o środowisku za pośrednictwem różnych zmysłów somatycznych (cielesnych), które są znacznie mniej dokładne i zależne od bezpośredniego kontaktu. W skórze znajdują się komórki receptorowe czterech zmysłów somatycznych: (Proponowany tu podział receptorów jest jednym z wielu możliwych - porównaj go na przykład z klasyfikacją receptorów przedstawioną w „Psychologii” pod red. T.  Tomaszewskiego. Warszawa 1979, ss. 214-226 (przyp. red.)) nacisku (dotyku) bólu, zimna i ciepła. Zmysły te są czasem nazywane |zmysłami |skórnymi.  Każdy z nich informuje organizm o innej właściwości świata zewnętrznego.
Dwa dalsze zmysły somatyczne są zlokalizowane wewnątrz organizmu. Są one ściśle związane ze sobą nawzajem i współdziałają ze sobą pomagając utrzymać równowagę ciała i informując nas o położeniu naszych rąk, nóg, głowy i innych częściach ciała. Są to zmysły: |kinestatyczny i |błędnikowy. Ponadto istnieją zmysły |chemiczne: smak i powonienie. Zmysłów somatycznych i chemicznych nie będziemy tu omawiać bardziej szczegółowo.




* * *



Ryc. 6.7. Przekrój Lewego Oka (widok z góry). Gałka oczna składa się z trzech warstw: 1) zewnętrznej warstwy ochronnej zwanej |twardówką, której część stanowi przezroczysta rogówka załamująca promienie świetlne; 2) pigmentowej warstwy środkowej, |naczyniówki; 3) wrażliwej na światło warstwy wewnętrznej zwanej |siatkówką. Światło wpadające do oka przenika najpierw przez rogówkę, a następnie przez |źrenicę, będącej otworem w pigmentowej |tęczówce. Wielkość źrenicy zmienia się, regulując ilość światła wnikającego do oka, co ma wpływ zarówno na jasność, jak i na wyrazistość obrazu. Promienie światła przechodzą następnie przez |soczewkę, która skupia je na światłoczułej powierzchni siatkówki; zanim jednak dojdą do siatkówki, muszą najpierw przejść przez galaretowate |ciało |szkliste, które wypełnia gałkę oczną. Promienie świetlne z centralnej części |pola |widzenia (tzn. tego, na co się patrzy) skupiają się na |plamce |żółtej, która znajduje się w centrum siatkówki i jest najbardziej wrażliwą częścią oka przy normalnym świetle dziennym. Siatkówka zawiera receptory wzrokowe, które pobudzone przez światło wysyłają impulsy nerwowe; przez |nerw |wzrokowy docierają one do |płatów |politycznych, znajdujących się w tylnej części mózgu, po jednym w każdej półkuli.


* * *







Wzrok




Zmysł wzroku, tak ważny dla przetrwania, rozwijał się w sposób fascynujący. Skomplikowane oko ludzkie najprawdopodobniej rozwinęło się z nielicznych komórek wrażliwych na światło, takich, jakie spotykamy u prymitywnych form istot żywych. Stopniowo, w miarę jak rozwijały się formy bardziej skomplikowane, coraz większa liczba elementów wzrokowych przypadała na jednostkę powierzchni, pojawiła się specjalnie wrażliwa plamka centralna oraz rozwinęły się bardziej złożone drogi: nerwowe i związane z nimi okolice mózgu, co umożliwiło dokładniejsze rozpoznawanie kształtów. W oku rozwinęły się mechanizmy umożliwiające wykorzystanie małych ilości światła dostępnych w nocy, co ogromnie zwiększyło czułość narządów wzroku, a u małp i u ludzi oczy stopniowo przesuwały się ku przodowi głowy, dzięki czemu stało się możliwe widzenie dwuoczne. Na koniec, wraz z rozwojem doskonalszych połączeń między mózgiem a oczami, stało się możliwe o wiele bardziej inteligentne wykorzystanie odbieranych bodźców wzrokowych.




* * *



Ryc. 6.8. Połączenia Nerwowe W Siatkówce. Jest to stylizowany i wielce uproszczony schemat, pokazujący przykładowo niektóre drogi nerwowe, łączące trzy warstwy komórek nerwowych w siatkówce. Światło przechodzi przez wszystkie trzy warstwy, zanim dojdzie do receptorów, które znajdują się na tylnej ściance gałki ocznej, dalej od źródła światła. W wyniku konwergencji kilka komórek receptorowych wysyła impulsy do każdej komórki zwojowej, podczas gdy wskutek dywergencji jedna komórka receptorowa może wysyłać impulsy do więcej niż jednej komórki zwojowej. Impulsy nerwowe z komórek zwojowych wychodzą z oka nerwem wzrokowym i biegną do następnego punktu przekaźnikowego.


Ryc. 6.9. Mechanizm Widzenia. W normalnym procesie widzenia światło z jednego punktu w prawej połowie pola widzenia stymuluje punkty po lewej stronie siatkówki obu gałek ocznych, które wysyłają impulsy drogami nerwowymi biegnącymi po lewej stronie mózgu i na koniec aktywują pewien punkt w korze mózgowej lewej półkuli - jak to pokazano na rysunku poniżej.  Jednocześnie punkty w lewej połowie pola widzenia aktywują punkty w prawej połowie kory wzrokowej. Pomimo tego, że tylko połowa pola wzrokowego jest reprezentowana po każdej stronie mózgu, wejście z obu oczu zostaje w jakiś sposób zintegrowane, ukazując nam pojedynczy, jednolity świat.


* * *





Struktury wzrokowe. Oko zawiera dwa systemy wzrokowe - połączone w jeden, lecz wyspecjalizowane w wypełnianiu odmiennych funkcji. Każdy system posiada swoje własne, odmiennie ukształtowane komórki receptorowe; w jednym systemie są to tak zwane |czopki, w drugim - |pręciki. Czopki funkcjonują jedynie w świetle - zawdzięczamy im widzenie barw i dużą ostrość wzroku.  Przy słabym świetle czopki nie reagują i wtedy pręciki funkcjonują same.  Pręciki są niezwykle wrażliwe na bardzo słabe bodźce świetlne (widzenie nocne), lecz nie rozróżniają barw. Gdy funkcjonują tylko nasze pręciki, wówczas wszystko zdaje się być w kolorze białym, czarnym i w różnych odcieniach szarości.
Pręciki i czopki są zlokalizowane w spodniej warstwie siatkówki, co oznacza, że światło musi przejść przez kilka warstw włókien nerwowych oraz naczynia krwionośne zanim dojdzie do tych komórek receptorowych. W siatkówce znajduje się ponad 7 milionów czopków. Najbardziej skupione są one w plamce żółtej, a liczba ich zmniejsza się od centrum siatkówki do jej obwodu. Pręciki znajdują się we wszystkich częściach siatkówki z |wyjątkiem plamki żółtej.
Jak pokazano na rysunku 6.8, receptory łączą się przez synapsy z |komórkami |dwubiegunowymi, które z kolei tworzą połączenia synaptyczne z |komórkami |zwojowymi. (W siatkówce znajduje się także wiele dodatkowych komórek łączących, które nie są pokazane na rysunku). Komórki te pozwalają siatkówce rozpocząć przetwarzanie informacji przed przekazaniem jej do mózgu. Aksony komórek zwojowych tworzą nerw wzrokowy; łączą się one przez synapsy z komórkami w punkcie przekaźnikowym znajdującym się w mózgu, a mianowicie w |ciele |kolankowatym |bocznym we wzgórzu. Z kolei aksony tych ostatnich komórek biegną do |kory |potylicznej w tylnej części mózgu (ryc.  6.9). W tym miejscu, gdzie nerw wzrokowy wychodzi z siatkówki znajduje się |plamka |ślepa, która nie jest wrażliwa na światło.




Zbliżenie


Zlokalizuj swoją ślepa plamkę


„Zwykle nie zdajemy sobie sprawy z istnienia ślepych plamek w naszych oczach, gdy bowiem posługujemy się obydwoma oczami, wówczas obraz nigdy nie pada jednocześnie na obie ślepe plamki - każda z nich znajduje się na przeciw nieco innej części pola widzenia. Możesz ustalić położenie twoich ślepych plamek za pomocą bardzo prostego eksperymentu. Zamknij prawe oko, trzymaj książkę na odległość wyciągniętej ręki i wpatruj się w kółko zamieszczone poniżej. Stale wpatrując się w te kółko, przesuwaj książkę ku sobie, dopóki krzyżyk nie zniknie.


W tym momencie krzyżyk znajduje się w tej części twego pola widzenia, któremu odpowiada ślepa plamka twego lewego oka. Aby ustalić położenie ślepej plamki w prawym oku, zastosuj tę samą procedurę, lecz tym razem zamknij lewe oko i wpatruj się w krzyżyk prawym okiem, teraz zniknie kółko”.


Ocenia się, że siatkówka zawiera około 125 milionów receptorów, kilka milionów komórek dwubiegunowych i milion komórek zwojowych. Zachodzi oczywiście ogromna |konwergencja informacji z wielu receptorów do jednej komórki zwojowej. Jednakże dzięki wielu połączeniom pomiędzy komórkami w siatkówce, istnieje także |dywergencyjny system przepływu informacji. Jeden receptor łączy się zatem z kilkoma komórkami dwubiegunowymi, które z kolei łączą się z jeszcze większą liczbą komórek zwojowych.
W jaki jednak sposób receptory te „przekładają” światło na impulsy nerwowe? W tym procesie transdukcji główną rolę odgrywają fotopigmenty zawarte w receptorach. W pręcikach znajduje się jeden rodzaj fotopigmentu zwany |rodopsyną, podczas gdy w każdym z czopków znajduje się jeden z trzech typów |jodopsyny, wrażliwych na długość fali światła niebieskiego zielonego lub czerwonego. Światło padające na receptor jest pochłaniane przez fotopigment; powoduje ono, że pigment ten rozkłada się na swoje części składowe (na przykład rodopsyna rozkłada się na |retyninę i |opsynę).



‘nv
Proces ten zmienia polaryzację błony komórki receptorowej, wytwarzając potencjał generatorowy, który aktywizuje komórki dwubiegunowe. Podobnie, jak w wypadku innych systemów sensorycznych, proces transdukcji wizualnej nie jest jeszcze całkowicie poznany; wiele ważnych zagadnień trzeba będzie jeszcze rozwiązać.
Gdy już miliony receptorów zareagowały na pewien bodziec wzrokowy, wówczas tę ogromną liczbę informacji system nerwowy musi jakoś przetworzyć i zinterpretować. Zestawiając w różny sposób przychodzące bodźce wzrokowe, system nerwowy dostarcza nam informacji o różnych aspektach obrazu wzrokowego, takich jak jasność, barwa, kształt i ruch. Aby to osiągnąć, informacja odbierana z receptora musi być analizowana równocześnie, na tym samym poziomie, lecz pod różnymi względami. Wspomniany wcześniej system anatomicznej dywergencji umożliwiany wcześniej system anatomicznej dywergencji umożliwia takie równoczesne wielorakie przetwarzanie informacji.


W jaki więc sposób widzimy jasność? Absorpcja światła przez pręciki aktywizuje je, a za ich pośrednictwem łańcuchy neonów, wywołując „percepcję” światła. Im większe jest natężenie światła, tym większa będzie aktywność wzbudzana w siatkówce i przekazana do mózgu, i tym silniejsze będzie wrażenie jasności. Proces, który przygotowuje oczy do widzenia w warunkach słabego oświetlenia, znany jest pod nazwą |adaptacji |do |ciemności. Niewątpliwie zdarzyło ci się wejść do zaciemnionej sali kinowej - nie mogłeś wówczas bez pomocy znaleźć drogi do swego pustego krzesła.  Dopiero po kilku minutach widziałeś zupełnie dobrze. U większości ludzi całkowita adaptacja do ciemności wymaga przebywania przez około pół godziny w pomieszczeniu pozbawionym światła.
Możesz przeprowadzić prosty, lecz interesujący eksperyment nad adaptacją do ciemności, pozostając przez 10 minut w ciemnym pokoju. Pod koniec tego okresu, zamknij jedno oko i trzymając rękę na nim zapal na parę sekund światło. Następnie zaś zgaś światło ponownie. Obserwuj teraz pokój najpierw tym okiem, które było zamknięte przez cały czas, a przekonasz się, że widzisz przedmioty dość dobrze. Następnie zamknij to oko i obserwuj pokój okiem, które przez krótki czas było wystawione na światło; dla tego oka pokój wyda się zupełnie ciemny. Ten eksperyment wskazuje, że proces adaptacji do ciemności zachodzi w siatkówce każdego oka, a nie w mózgu.


W jaki sposób widzimy barwy? Widzenie barw polega na zdolności różnicowania różnych długości fal świetlnych (różnych barw) niezależnie od ich względnego natężenia, czyli jasności. Przyjmuje się, że funkcję tę spełniają czopki w połączeniu ze specjalnymi komórkami w ciele kolankowatym bocznym, zwanym komórkami |przeciwstawnymi („opponent cells”). Każda z tych komórek reaguje pobudzeniem na impulsy wywołane pewną długością fal świetlnych i hamowaniem na impulsy wywołane przez inną długość fali.
Istnieją cztery podstawowe typy komórek przeciwstawnych: pobudzana przez czerwień, hamowana przez zieleń (Czerwony - ang. „red” ®, zielony - ang.  „green” (G), żółty - ang. „yellow” (Y), niebieski - ang. „blue” (B) (przyp.  tłum.)) (+R, -G), hamowana przez czerwień, pobudzana przez zieleń (-R, +G), pobudzana przez żółty, hamowana przez niebieski (+Y, -B) i wreszcie hamowana przez żółty, pobudzana przez niebieski (-Y, -B). Gdy światło jest absorbowane przez czopki (każdy z nich, jak pamiętamy, zawiera jeden z trzech typów fotopigmentowych), informacja ta jest przekazywana do komórek przeciwstawnych, które niejako |odejmują impulsy otrzymywane z jednej kategorii receptorów od impulsów otrzymywanych z innej kategorii receptorów. Na przykład komórka przeciwstawna +R, -G odejmuje impulsy otrzymywane z czopków „zielonych” od impulsów otrzymywanych z czopków „czerwonych”, tak więc tempo wyładowywania się pojedynczej komórki przeciwstawnej zależy od różnicy pomiędzy pobudzeniem dwóch zbiorów komórek receptorowych połączonych z nią. Różne układy pobudzenia i hamowania komórek przeciwstawnych wytwarzają wrażenia różnych barw.


W jaki sposób widzimy formy. Wyniki ostatnich badań nad mechanizmami percepcji form zburzyły wiele uznawanych od dawna poglądów. Przyjmowano niegdyś, że wszelkie procesy percepcyjne zachodzą w mózgu. Sądzono, że impulsy przychodzące z receptorów są przekazywane do mózgu i rzutowane tam na pewną powierzchnię, gdzie relacje są analizowane i interpretowane, w wyniku czego powstają nasze subiektywne doznania związane z widzeniem kształtów. Następnie, w latach pięćdziesiątych naszego wieku, odkryto, że poszczególne komórki, znajdujące się na kolejnych odcinkach drogi przebiegającej od siatkówki do kory, reagują tylko na poszczególne cechy bodźca wzrokowego. Od tego momentu odkrycia potoczyły się szybko.
Obecnie wiemy, że sekwencja przetwarzania informacji wzrokowej przebiega na kilku poziomach komórek i że zarówno analiza, jak i wykrywanie kształtów zachodzi w pewnej mierze na każdym z tych poziomów. Wiemy także, że reakcja pośrednich poziomów nie jest automatyczna, lecz zależy od tego, jaki wzorzec reakcji i hamowania wystąpi na poprzednich poziomach. Ponadto dowiedzieliśmy się, że te genetycznie zdeterminowane, potencjalne zdolności wykrywania kształtów mogą się ujawnić tylko wtedy, jeśli dany organizm uzyskał pewne doświadczenia we wczesnych stadiach swego rozwoju.
H. B. Barlow z University of California był pierwszym badaczem, który odkrył (1953), że aktywizacja pojedynczych komórek w siatkówce oka żaby następowała po ukazaniu jej bodźca podobnego do żuka. Nie tylko występowały intensywne wyładowania w tych neuronach, lecz ponadto żaba wielokrotnie wykonywała reakcje pokarmowe ukierunkowane na ten bodziec. Odkrycie to było ważne z dwóch powodów: po pierwsze, wykazało ono, że mechanizmy umożliwiające rozpoznawanie, związane z ważnymi dla życia funkcjami behawioralnymi, mogą być zlokalizowane poza mózgiem, po drugie, wykazało, że jak się już przekonaliśmy, niektóre komórki są wrażliwe na wysoce specyficzne cechy bodźców.
Układy (wzorce) bodźców sensorycznych, które wywołują reakcje w określonych neuronach czuciowych, zwane są |cechami |wyzwalającymi („trigger features”). Neurony, które reagują selektywnie na te układy bodźców, zwane są |analizatorami |cech („feature analyzers”). O procesach przetwarzania informacji, które zachodzą wtedy, gdy siatkówka otrzymuje pewne wejście wzrokowe i przekazuje je do kory wzrokowej, można wnioskować badając cechy bodźców, które są niezbędne dla zaktywizowania różnych neuronów. Niektóre neurony są pobudzane jedynie przez bodźce umieszczone pod pewnym kątem, inne przez linie pionowe lub linie poziome, przez obraz krawędzi, ruch itd. Stwierdzono, że siatkówkowe analizatory cech u różnych gatunków reagują na zupełnie odmienne cechy i że u gatunków, u których występuje widzenie steroskopowe (trójwymiarowe), większa część przetwarzania informacji wzrokowej odbywa się w mózgu.
Stwierdzono, że pewne komórki zwojowe reagują jedynie na bodziec, który porusza się w określonym kierunku. Ruch w przeciwnym kierunku hamuje reagowanie takiej komórki, podczas gdy ruch w innych kierunkach wywołuje pośrednie wielkości pobudzenia i hamowania. Każda z tych komórek reaguje najsilniej na inny kierunek ruchu. Nie wiadomo jeszcze, w jaki właściwie sposób komórki te są zdolne wykrywać ruch, lecz sądzi się, że w korze mózgowej następuje analiza wyższego rzędu, której przedmiotem są reakcje tych wrażliwych na ruch komórek.
Polem recepcyjnym danego neuronu jest ten obszar siatkówki, z którego otrzymuje on impulsy. Przeprowadzając swe badania na kotach, Hubel i Wiesel (1959) stwierdzili, że komórki zwojowe w siatkówce, z których każda otrzymuje wejście od wielu receptorów, mają koliste, koncentryczne pola recepcyjne; każde z nich ma albo środek reagujący pobudzeniem na bodziec i otoczkę reagującą hamowaniem, lub na odwrót. Te komórki zwojowe są bardzo wrażliwe na |małe |punkciki światła, które dokładnie wypełniają środek ich pola recepcyjnego. W przeciwieństwie do tych komórek zwojowych, komórki w korze wzrokowej kota często zamiast kolistych mają podłużne pola recepcyjne. W tym wypadku bodźcem, który wywołuje największą aktywność danej komórki, jest |linia o pewnej szerokości, zlokalizowana w określonym miejscu pola wzrokowego. Wydaje się, że komórki „liniowe” w mózgu reagują na wejście z grupy tych komórek „koncentrycznych” siatkówki, których pola recepcyjne tworzą linię prostą.


Hierarchiczne przetwarzanie informacji. W latach następujących po pierwszym odkryciu, Hubel i Wiesel (1959) zidentyfikowali sześć kolejnych etapów czy poziomów przetwarzania informacji wzrokowej u kotów: jeden w siatkówce, jeden w |ciele |kolankowatym |bocznym (w punkcie przekaźnikowym w połowie drogi do kory wzrokowej), a ostatnie cztery - w samej korze wzrokowej. Zidentyfikowali oni zarówno cechy wyzwalające komórek na każdym poziomie, jak też i kształt pól recepcyjnych tych neuronów. Przetwarzanie ma tu charakter wyraźnie hierarchiczny, przy czym wejście z prostych komórek jest przekazywane do coraz bardziej złożonych, a każda z nich wykonuje inną część zadania polegającego na wykrywaniu kształtów.
Wydaje się, że komórki na wyższych poziomach stały się selektywne w odniesieniu do bardziej złożonych cech wyzwalających bodźca. Na przykład określone położenie bodźca świetlnego jest niezbędne dla aktywizacji komórki w siatkówce lub nawet prostej komórki korowej, natomiast dla złożonych komórek korowych wyższego rzędu kierunek i długość linii są ważniejsze niż położenie.


Pola recepcyjne dwóch komórek zwojowych
Każda komórka zwojowa w oku otrzymuje wejście z kolistego obszaru siatkówki zawierającego wiele komórek receptorowych. W niektórych wypadkach centrum tego obszaru ma wpływ pobudzający, zewnętrzna zaś obwódka - hamujący; w innych wypadkach jest na odwrót. Komórka zwojowa jest najbardziej wrażliwa na impulsy przychodzące z centrum jej pola recepcyjnego.


Centrum pobudzające:
Stymulacja komórek w centrum pola recepcyjnego pobudza komórkę zwojową;
stymulacja komórek na obwodzie hamuje tę samą komórkę zwojową.


Centrum hamujące:
Stymulacja komórek w centrum pola recepcyjnego hamuje komórkę zwojową;
stymulacja komórek na obwodzie pobudza tę samą komórkę zwojową.


Pola recepcyjne komórek korowych
Dla odmiany obszar siatkówki pobudzający pojedynczą komórkę kory ma kształt wydłużony; zawiera on także zarówno elementy pobudzające, jak i hamujące. Impulsy do takiej komórki przychodzą z wielu komórek zwojowych, których pola recepcyjne pokrywają się tworząc linię.


Jednym z najważniejszych procesów, które występują na poziomach o większej złożoności, jest proces hamowania. Określona komórka nie tylko jest pobudzana przez pewne cechy wyzwalające, a nie pobudzana przez inne cechy, lecz ponadto często hamuje ona (czy też blokuje) reakcje na bodźce, które nie mają wymaganych cech wyzwalających.


Zadanie percepcji. Głównym zadaniem systemów percepcyjnych jest wykrywanie istotnych sygnałów w morzu „szumu”, czyli sygnałów nieistotnych.  Innymi słowy, zadanie percepcji polega na wyszukiwaniu |niezmiennych („invariant”) właściwości w polu bodźcowym: nasze mechanizmy percepcyjne muszą jakoś wykryć niezmienną, „prawdziwą” figurę, pomijając wszystkie zakłócenia, które ją maskują.
We wszystkich systemach przetwarzających informacje główną zasadą jest zasada ekonomii. Biorąc pod uwagę fakt, że możliwa jest nieskończona ilość informacji, przekazywana musi być jedynie informacja istotna; informacja nieistotna musi zostać odrzucona. Systemy takie muszą wytwarzać programy mające na celu |redukowanie |redundancji - to jest minimalizowanie wejść, które „mówią” to samo. Pewna ilość redundacji jest niezbędna, aby uzyskać pewność, że sygnał zostanie przekazany, lecz nadmierna redundacja przeciąża system zmniejszając jego skuteczność w przetwarzaniu innej informacji.
Drogi czuciowe dysponują wieloma sposobami zmniejszania redundacji w informacji, którą przekazują one o środowisku wzrokowym; należy do nich |adaptacja do ciągłego, nie ulegającego zmianom wejścia (w wypadku której komórki receptorowe przestają reagować na nie zmieniający się bodziec), |hamowanie |oboczne (w którym komórki oddziaływują hamująco na komórki sąsiednie) oraz |selektywna |wrażliwość na kierunek ruchu. Na wyższych poziomach regularność bodźców, uchwycona na poziomach niższych, staje się mniej ważna, dzięki czemu większego znaczenia nabiera nieciągłość bodźców, ich nowość i wyjątkowość.
Ten krótki opis mechanizmów pozwalających widzieć jasność, kolor oraz zróżnicowane kształty wystarczy, aby pokazać, jak skomplikowane jest wyposażenie umożliwiające organizmom reagowanie na bodźce wzrokowe. Jest to obecnie niemizernie ożywiona dziedzina badań, do czego przyczyniło się ostatnio dążenie do łączenia pojęć i sposobów podejścia wziętych z psychologii, fizjologii i informatyki.




Słuch




Zmysł słuchu dysponuje jednym z najbardziej złożonych narządów organizmu ludzkiego - uchem. Wrażliwość ucha jest tak wielka, że potrafi ono reagować na niezmiernie słabe dźwięki. (W istocie potrafi ono prawie - choć nie zupełnie - wykryć dźwięk drobin powietrza przypadkowo uderzających o błonę bębenkową!). Z drugiej strony, ucho jest także dostatecznie odporne, aby wytrzymać uderzenia bardzo silnych fal dźwiękowych, takich jak silnie wzmocnione dźwięki muzyki na koncercie rockowym. Ponadto ucho może być bardzo selektywne, jak wówczas, gdy wybiera ono jeden głos spośród wielu głosów w tłumie lub w chórze.
Wytrzymałość ucha ma pewne granice i trzeba zdawać sobie z tego sprawę, zwłaszcza, jeśli lubisz głośną muzykę lub mieszkasz w hałaśliwym otoczeniu.  Wrażliwe struktury ucha chronione są przed silnymi bodźcami przez dwa zespoły mięśni, które kurczą się odruchowo w odpowiedzi na głośne dźwięki.  Zwykle zmniejsza to nacisk na płyn wypełniający ucho wewnętrzne. Gdy jednak poziom natężenia dźwięku (mierzony w decybelach) jest bardzo wysoki, wówczas czas efektywnego funkcjonowania tego mechanizmu ochronnego jest ograniczony. W jednym z badań stwierdzono uszkodzenie ślimaka u świnek morskich poddanych przez 88 godzin oddziaływaniu muzyki rockowej o natężeniu 122 decybeli. W rezultacie rozeszła się pogłoska, że świnkom morskim ma być zabroniony wstęp do pewnych dyskotek w Nowym Jorku. Jednakże ubytki słuchu, stwierdzone ostatnio wśród muzyków rockowych, są wystarczająco poważne, aby skłonić nas do zastanowienia się, jakie trwałe uszkodzenia swego narządu słuchu możemy spowodować słuchając zbyt długo zbyt głośnej muzyki.
Inne hałasy wytwarzane przez ludzi, jak na przykład huk wystrzału, występują tak nagle, że opisany wyżej mechanizm działa zbyt wolno (około 10 milisekund od wystąpienia bodźca), aby uchronić ucho - zostało już ono uszkodzone.


Odbiór dźwięków. Gdy jakiś obiekt wydaje dźwięk, wówczas wytwarza on różnice ciśnienia rozchodzące się w postaci fal w otaczającym powietrzu. Te następujące po sobie fale zagęszczonego i rozrzedzonego powietrza są bodźcami dla zmysłu słuchu, lecz zanim impulsy nerwowe będą mogły być przekazane do ośrodka słuchowego w mózgu, fale dźwiękowe muszą najpierw przejść przez trzy zasadnicze części ucha: ucho zewnętrzne, ucho środkowe, oraz ucho wewnętrzne (|ślimak), gdzie są one ostatecznie przekształcane w impulsy nerwowe (ryc. 6.11).
Ucho jest skonstruowane w taki sposób, aby zmaksymalizować ilość energii, która jest pochłaniana z fal dźwiękowych uderzających o błonę bębenkową.  Kiedy fale dźwiękowe uderzają o twardą powierzchnię, większość ich energii zostaje zwykle odbita. Różne struktury zawarte w uchu służą do zachowania tej energii przez przetworzenie dużej amplitudy fal dźwiękowych w silniejsze drgania o mniejszej amplitudzie (von Bekesy, 1957).


Kodowanie dźwięków. Dźwięki, jakie słyszymy, charakteryzują się wysokością i głośnością - związanymi odpowiednio z częstotliwością i amplitudą fal dźwiękowych. Lecz w jaki sposób ucho wewnętrzne przekazuje informacje zarówno o częstotliwości, jak i amplitudzie bodźca słuchowego do mózgu, tak, że można rozpoznać zarówno wysokość, jak i natężenie dźwięku?  Jedną z prób wyjaśnienia tego jest |teoria |miejsca sformułowana przez Helmholtza pod koniec ubiegłego wieku. Sądził on, że różne włókna błony podstawowej reagują na różne częstotliwości, podobnie jak różne struny fortepianu, i że wskutek tego dany ton powoduje drganie określonych włókien błony podstawowej i pobudzenie komórek receptorowych w tym punkcie. To z kolei dawałoby początek impulsom w poszczególnych włóknach nerwowych biegnących do określonego miejsca w korze słuchowej. Ta teoria miejsca jest często nazywana teorią „pitch is which” - wysokość dźwięku („pitch”), który słyszymy, uważa się w niej za zdeterminowaną przez to, które („which”) włókno zostało pobudzone. Intensywność bodźca, według Helmholtza, jest określona przez częstotliwość, z której reaguje dane włókno nerwowe.
Za pomocą teorii miejsca trudno wyjaśnić (z różnych przyczyn), w jaki sposób dokonujemy rozróżnienia tonów o niskiej częstotliwości. Lepiej radzą sobie z tym problemem teorie częstotliwości („frequency theories”). Typowym ich przykładem jest |teoria |telefoniczna („telephone theory”), sformułowana przez fizyka Rutheforda. Utrzymywał on, że częstotliwość impulsów nerwowych jest bezpośrednio skorelowana z częstotliwością fali dźwiękowej. Uważał więc, ze błona podstawowa działa podobnie jak mikrofon telefonu, wysyłając do mózgu impulsy o różnych częstotliwościach.  Przyjmowano, że o głośności bodźca słuchowego decyduje liczba pobudzonych włókien nerwowych. Kłopot z tą teorią polegał na tym, że nie potrafiła ona wyjaśnić, w jaki sposób słyszymy |wysokie tony: ponieważ pojedyncze włókno nerwowe nie może reagować częściej niż 600 razy na sekundę, to nie może ono oczywiście przekazywać całego zakresu słyszalnych częstotliwości, który dochodzi aż do 20000 cykli na sekundę.
Uzupełnieniem teorii telefonicznej jest |teoria |salw („volley theory”; 
Wever i Bray, 1930). Ponieważ słyszymy dźwięki o częstotliwościach znacznie wyższych niż maksymalna częstotliwość wyładowania włókna nerwowego, wysunięto zatem sugestię, ze włókna nerwowe działają w grupach, przy czym różne grupy reagują (tzn. wyładowują się wysyłając salwy impulsów) w różnych momentach. Na przykład, jeśli przekazywany jest ton o częstotliwości 4000 cykli na sekundę, to powinien wystąpić nagły wzrost aktywności w nerwie słuchowym co 1/4000 części sekundy, to jest dla każdego szczytu fali dźwiękowej - lecz za każdym razem reagowałyby |inne grupy włókien nerwowych. Niektóre włókna mogłyby reagować na każdy czwarty cykl fali dźwiękowej, niektóre na każdy piąty cykl itd.
Uzyskane ostatnio dane zdają się wskazywać, że potrzebne jest pewne połączenie teorii salw i teorii miejsca, aby wyjaśnić zjawisko słyszenia całego zakresu tonów, na jakie wrażliwe jest ludzkie ucho. Zasada, na której opiera się teoria salw, zdaje się przede wszystkim stosować do częstotliwości sięgających 4000 czy 5000 cykli, lecz nawet włókna działające grupowo nie mogą przenosić impulsów w szybszym tempie. Odbiór dźwięków o częstotliwości wyższej niż 5000 cykli na sekundę można zatem wyjaśnić jedynie za pomocą teorii miejsca (Wever, 1949).




* * *



Ryc. 6.11. Budowa Ucha Ludzkiego. Górny rysunek przedstawia przekrój ludzkiego ucha. Poniżej zamieszczono schematyczny przekrój ślimaka - tak, by wyglądał, gdyby go rozwinąć i wyprostować. Fale dźwiękowe przechodzą najpierw przez ucho zewnętrzne oraz zewnętrzny przewód słuchowy i natrafiają na cienką |błonę |bębenkową, która zaczyna drgać. Drgania te wprawiają w ruch trzy małe |kosteczki |słuchowe znajdujące się w uchu środkowym, które przekazują je za pośrednictwem innej błony - |okienka |owalnego - płynowi wypełniającemu |ślimaka. Jedna z tych kosteczek (zwana |strzemiączkiem) działa jak tłok, przemieszczając ten płyn tam i z powrotem w rytm fal dźwiękowych. Ruchy płynu wywołują drgania cienkiej błony znajdującej się w ślimaku (|błony |podstawowej). Z kolei drgania te powodują uginanie się |komórek |włoskowych |narządu |Cortiego, który spoczywa na błonie podstawowej. Komórki włoskowe są rzeczywistymi receptorami słuchowymi; poruszanie ich „pobudza” je i wytwarza potencjał generatorowy, który powoduje powstawanie impulsów nerwowych we włóknach |nerwu |słuchowego. Następnie nerw słuchowy przekazuje te impulsy do mózgu.


* * *





Intensywność, czyli natężenie bodźca słuchowego, może być kodowana zarówno przez całkowitą liczbe impulsów przekazywanych w ciągu każdej sekundy (liczba włókien razy częstotliwość wyładowywania), jak i przez aktywizację włókien o „wysokim progu” (tzn. włókien nerwowych, w których pobudzenie wymaga silnego ugięcia komórek włoskowych). Należy podkreślić, że żadna z tych teorii nie jest w stanie wyjaśnić najważniejszego procesu transformacji słuchowej - to znaczy tego, w jaki właściwie sposób stymulacja receptorów , powodowana uginaniem komórek włoskowych, jest przekładana na impulsy nerwowe.
Zakres ciśnień, na jakie jest wrażliwe nasze ucho, jest ogromny: stosunek najmniejszego do największego ciśnienia wynosi około 1:5 000 000. Ze względu na ten wielki zakres, do mierzenia intensywności dźwięków używa się zwykle jednostki logarytmicznej zwanej decybelem (dB). Miara ta pozwala określić, ile razy intensywność danego dźwięku jest większa od intensywności dźwięku odpowiadającego dolnemu progowi słyszenia. W rzeczywistości ten dolny próg jest w pewnym stopniu zależny nie tylko od tej amplitudy fali dźwiękowej, ale i od jej częstotliwości; toteż jako zero na skali decybelowej można arbitralnie przyjąć dowolny bodziec, stanowiący poziom odniesienia, jeżeli tylko jest on wyraźnie określony.
Chociaż ucho ludzkie potrafi reagować na tak szeroki zakres częstotliwości, są pewne częstotliwości, na które jest ono raczej niewrażliwe. Odnosi się to zwłaszcza do bardzo niskich częstotliwości, dzięki czemu nie słyszymy wszystkich wibracji naszego własnego ciała.  Możesz jednak posłyszeć te dźwięki, jeśli zatkasz palcami oba uszy, zamykając w ten sposób dostęp do nich dla dźwięków z powietrza. Niski, nieregularny dźwięk, który wtedy usłyszysz, są to skurcze mięśni twoich ramion i palców. Możesz również posłyszeć bicie swego serca. Oczywiście, gdybyś zawsze słyszał wibrację swego ciała, jak również inne dźwięki o niskiej częstotliwości, wówczas ważne dźwięki byłyby maskowane przez ten „szum” i słyszane mniej wyraźnie.




Rozwój percepcyjny




Kiedy niemowlęta zaczynają dostrzegać? W jaki sposób zmienia się ich percepcja, gdy rosną i rozwijają się? Jakie zmiany następują i czy zachodzą one w wyniku rozwijania potencjału genetycznego, czy w wyniku określonych doświadczeń, czy też pewnego połączenia lub interakcji obu tych czynników?


Pytania powyższe intrygują zarówno młodych rodziców, jak i psychologów prowadzących badania w tej dziedzinie.




Z czym zaczynamy?




Struktura anatomiczna większości narządów zmysłowych jest dobrze rozwinięta już przed urodzeniem. To, czy i kiedy zaczynają one rzeczywiście funkcjonować u płodu lub noworodka, jest zagadnieniem, na które można odpowiedzieć jedynie w wyniku stosowania dokładnych procedur badawczych.  Jednakże badanie wrażliwości zmysłowej we wczesnym okresie życia jest trudne, ponieważ trzeba o niej wnioskować na podstawie pewnego rodzaju reakcji, a reakcja może nie wystąpić nie dlatego, że mechanizmy sensoryczne są nie rozwinięte, lecz dlatego, że niewystarczająco rozwinięte są systemy motoryczne.
Zamknięty w macicy płód jest wystawiony na niewiele bodźców. Noworodek wchodzi w znacznie bardziej złożone środowisko bodźców i wykazuje wrażliwość na wiele rodzajów stymulacji. Lecz w jakim stopniu niemowlę organizuje to bogactwo wrażeń, to inne pytanie; zapewne, zgodnie z klasycznym sformułowaniem Williama Jamesa, „(...) niemowlę, atakowane jednocześnie przez oczy, uszy, nos, skórę i wnętrzności, odczuwa to wszystko jako jeden wielki, szalony, dźwięczny chaos” (James, 1890, s.  488). Badając rozwój mamy nadzieję ustalić, co jest, a co nie jest chaosem, i w jaki sposób chaos ten staje się niechaotyczny, uporządkowany i stabilny.
Jeśli istotnie natura jest zorganizowana zgodnie z zasadami regularności, to zadaniem wszystkich żyjących stworzeń, które mają nadzieję utrzymać się przy życiu, jest poznanie pewnych sekretów tego systemu. Zanim organizmy przystosują się skutecznie do środowiska lub zaczną próbować zmieniać je, muszą najpierw spostrzegać dokładnie ważne obiekty oraz relacje między nimi.


Dotyk, temperatura i ból. Płód ludzki potrafi reagować na bodźce dotykowe mniej więcej po 8 tygodniach od chwili poczęcia. Przez ten czas rozwinęła się zatem pewna podstawowa zdolność sensoryczna. Wrażliwość na dotyk rozwija się od głowy ku dołowi. W ósmym tygodniu życia prenatalnego płód staje się wrażliwy na bodźce dotykowe oddziałujące na jego nos, wargi i podbródek, a z upływem czasu obszar wrażliwy na stymulację stopniowo powiększa się. W trzynastym lub czternastym tygodniu całe ciało jest wrażliwe na dotyk - z wyjątkiem szczytu głowy i tyłu głowy, które do chwili urodzenia nie reagują na bodźce. Nawet w momencie urodzenia twarz jest bardziej wrażliwa na dotyk i nacisk niż inne części ciała.
Wrażliwość na temperaturę występuje już przed urodzeniem; wiemy o tym stąd, że niemowlęta urodzone przedwcześnie, podobnie jak donoszone, mogą odmówić przyjmowania mleka o niewłaściwej temperaturze. Mogą one także reagować na temperatury zewnętrzne, przy czym zwykle reagują silniej na zimno niż na gorąco.
W okresie płodowym i pierwszych dniach życia po urodzeniu wrażliwość na ból jest mała. Jest ona większa na twarzy niż gdzie indziej, a w ogóle jest ona rozwinięta tak słabo, że w ciągu pierwszych dwóch tygodni można dokonywać obrzezania bez znieczulenia. To opóźnienie w rozwoju zmysłu bólu interpretuje się jako biologiczny mechanizm obronny, chroniący dziecko w trakcie procesu rodzenia się (Carmichael, 1951).


Smak i powonienie. Zmysł smaku jest dobrze rozwinięty w momencie urodzenia. Noworodki zwykle reagują ruchami ssania na słodkie lub słone bodźce kwaśne i gorzkie. Zmysł smaku zdaje się rozwijać na pewien czas przed urodzeniem, ponieważ nawet niemowlęta urodzone przedwcześnie reagują na bodźce smakowe.
Również powonienie jest zmysłem dobrze rozwiniętym u noworodka.  Zaobserwowano określone zmiany w aktywności ciała i w tempie oddychania po podaniu bodźców węchowych. Badania wykazały, że noworodki potrafią rozróżniać takie zapachy, jak kwas octowy, asafetyda, alkohol fenyloetylowy oraz olejek anyżowy, chociaż nie zaobserwowano wyraźnych różnic w reakcji na zapachy, które są przyjemne i nieprzyjemne dla osób dorosłych (Engen, Lipsitt i Kaye, 1963). Procedurę badawczą stosowaną w badaniach tego typu opisaliśmy w Rozdziale 2, w związku z reakcją orientacyjną.


Słuch. Istnieją pewne wątpliwości, czy płód może słyszeć pomimo płynu w uszach. Stwierdzono, że tempo bicia serca płodu wzrasta gwałtownie w reakcji na dźwięk rozbrzmiewający blisko brzucha matki (Bernard i Sontag, 1947). Inny zespół badaczek studiował reakcję płodu na tony o różnej częstotliwości.


„W badaniach tych, które objęły 32 kobiety w ostatnim miesiącu ciąży, obserwowano reakcje serca płodu na tony o częstotliwości 1000 i 2000 cykli na sekundę, o natężeniu wynoszącym 100 decybeli i w czasie trwania równym 5 sekund. Szybkość pulsu u matki i płodu rejestrowano przed, w trakcie i po podaniu tych tonów. W grupie badanej przy zastosowaniu tonu o częstotliwości 1000 cykli na sekundę przeciętny wzrost częstotliwości bicia serca wyniósł 7 uderzeń na minutę. W grupie badanej przy użyciu tonu o częstotliwości 2000 cykli na sekundę przyspieszenie wyniosło 11 uderzeń na minutę. Puls matki nie wykazał żadnego przyspieszenia” (Dwornicka, Jasieńska, Smolarz i Wawryk, 1964).


Specjalnie interesującym punktem w tych badaniach był fakt, że wyższe tony wywoływały silniejszą reakcję. Badania nad niemowlętami, przeprowadzone wkrótce po ich urodzeniu się, wykazały, że - wnosząc z ich zachowania - niskie tony są dla nich przyjemniejsze niż wysokie.
Tuż po urodzeniu słuch wydaje się gorzej rozwinięty niż inne zmysły, chociaż istnieje tu duże zróżnicowanie wyników u poszczególnych dzieci.  Słuch jest najpierw przytępiony przez płyn amniotyczny (wody płodowe), który często pozostaje w uchu środkowym przez kilka dni po urodzeniu.  Zwykle gdzieś między trzecim a siódmym dniem życia niemowlę reaguje na zwykłe hałasy, przy czym żywiej reaguje na szelest papieru lub dźwięk talerzy niż na głos. Jednakże po ukończeniu czwartego tygodnia życia częściej reaguje ono na głosy niż na głośne hałasy. W wieku 2 miesięcy niemowlęta nie tylko reagują już na bodźce słuchowe, lecz także potrafią rozróżniać dźwięki.


Wzrok. Ponieważ siatkówka w momencie urodzenia nie osiąga jeszcze swego pełnego rozwoju, przeto zakładano niegdyś, ze noworodki nie mogą widzieć wyraźnie. Eksperymenty wykazały jednak, że małe niemowlęta mogą rozróżniać  kształty; są nawet oznaki wskazujące na to, że występuje u nich percepcja głębi oraz zjawisko zachowania w spostrzeganiu stałości kształtów.


„Percepcja kształtów i barw”. Wydaje się, że istnieje wrodzona zdolność do wzrokowego spostrzegania kształtów. W jednym z badań stwierdzono, że pięciodniowe niemowlęta patrzyły dłużej na wzory czarno-białe niż na powierzchnie jednobarwne. Niemowlęta o kilka dni starsze dokonywały wzrokowego różnicowania w jeszcze większym stopniu (Frantz, 1963). W innym badaniu eksperymentatorzy pokazywali noworodkom szereg par kształtów różniących się pod względem liczby kątów, jakie zawierały. Kształty o 10 kątach, czyli zmianach w kierunku linii, były preferowane w porównaniu z kształtami o pięciu lub dwudziestu kątach. Wnioskowano o tym na podstawie fotograficznych zapisów fiksacji oka, które wykazywały, że niemowlęta spędzały więcej czasu patrząc na figury o dziesięciu kątach (Hershenson, Munsinger i Kessen, 1965). Około 10 dnia po urodzeniu niemowlęta potrafią śledzić oczami poruszające się wolno przedmioty. Ponieważ mięśnie oczu nie są początkowo dobrze skoordynowane, niekiedy zdają się one spoglądać w dwóch kierunkach na raz.
Istnieje pewna niezgodność zdań co do tego, czy małe niemowlęta spostrzegają barwy, lecz wyniki eksperymentów sugerują, że potrafią je one rozróżniać.


„Czteromiesięcznym niemowlętom prezentowano parami bodźce różniące się pod względem kształtu, barwy lub obu tych cech. Tu także o preferencjach (a więc o zdolności różnicowania), wnioskowano na podstawie czasu fiksacji wzrokowej. Stwierdzono, że barwy czerwona i niebieska były znacznie częściej „wybierane” niż szara; czynnikiem decydującym o preferencjach był jednak kształt a nie barwa. Kształt pawiego oka był przedkładany ponad inne kształty” (Spears, 1964).


„Stałość wielkości”. Aby stwierdzić, czy w spostrzeganiu małych niemowląt występuje stałość wielkości, jeden z badaczy ćwiczył dwumiesięczne niemowlę w reagowaniu na trzydziestocentymetrowy sześcian. Za każdym razem, gdy niemowlę zwróciło głowę ku temu bodźcowi dyskryminacyjnemu, występował silny czynnik wzmacniający - eksperymentator cmokał i gwizdał.


„Gdy ta reakcja sprawcza została dobrze ustalona, wówczas przeprowadzono test generalizacji, w celu ustalenia, czy niemowlę reaguje na podstawie wielkości obrazu na siatkówce, odległości, czy też wielkości rzeczywistej.  Rozumowano następująco: jeśli stałość wielkości w postrzeganiu są wrodzone (lub wyuczone bardzo wcześnie), wówczas dziecko powinno reagować na prawdziwą wielkość bodźca (30 cm), a nie na stałą wielkość obrazu na siatkówce, ani na stałą odległość, gdy te trzy czynniki będą zmieniane niezależnie od siebie, tak aby niemowlę musiało wybrać jeden z nich, a ignorować inne. Przypuszczenia okazały się słuszne: większość reakcji występowała wtedy, gdy wielkość obrazu na siatkówce i odległość były inne niż w warunkach pierwotnych, lecz prawdziwa wielkość bodźca była taka sama (T. G. R. Bower, 1966a).
W innym badaniu różnicowaną cechą bodźca była nie jego wielkość, lecz kształt (kąt nachylenia). I tu także niemowlę wykrywało „poprawny” bodziec na podstawie jego obiektywnego kształtu, a nie na podstawie kształtu jego obrazu na siatkówce” (T. G. R. Bower, 1966b).


„Spostrzeganie głębi”. Dalsze dane świadczące o istnieniu wrodzonych zdolności do spostrzegania kształtu i znaczenia wzrokowych bodźców uzyskano w serii interesujących eksperymentów z młodymi osobnikami różnych gatunków, w których to eksperymentach stosowano urządzenie zwane „urwiskiem wzrokowym” („visual cliff”).


„Urządzenie to składa się z wielkiej płyty grubego szkła, podpartej w ten sposób, że znajduje się na pewnej wysokości ponad podłogą; przez środek tej płyty przebiega deska. Po jednej stronie tej deski, materiał pokryty wzorem - czarnobiałą szachownicą - umieszczono tuż pod powierzchnią szklanej płyty, tak, że szkło wydaje się tak mocne, jak jest w rzeczywistości. Po drugiej stronie deski ten sam materiał leży kilka stóp poniżej szklanej płyty. Wygląda to jak nagłe obniżenie terenu, czyli „urwisko”, pomimo tego, że znajduje się nad nim mocna płyta szklana. W eksperymentach, w których wzięło udział 36 niemowląt w wieku od 6 do 14 miesięcy, niemowlęta te umieszczano pojedynczo na środkowej desce, a ich matki wołały je najpierw od strony „głębokiej”, a następnie od strony „płytkiej” (ryc. 6.12).
27 spośród badanych niemowląt zeszło z deski; wszystkie one przepełzły przynajmniej raz „płytką” stroną, lecz tylko troje wpełzło na szkło ponad „urwiskiem”. Wiele z nich płakało, gdy matka wołała je do siebie od strony urwiska, lecz nie chciały pełznąć do niej nad pozorną przepaścia; inne nawet odpełzały od niej w przeciwną stronę. Niektóre klepały i głaskały szkło po głębokiej stronie upewniając się, że jest ono mocne, lecz mimo to cofały się. Najwyraźniej bardziej polegały na swych wrażeniach wzrokowych niż na świadectwie zmysłu dotyku.
Aczkolwiek eksperyment ten nie dowodzi, że u niemowląt spostrzeganie i unikanie przepaści są wrodzone, to jednak podobne eksperymenty przeprowadzone ze zwierzętami potwierdzają raczej hipotezę, że takie spostrzeganie jest wrodzone. Prawie wszystkie badane zwierzęta były zdolne do spostrzegania i unikania optycznego urwiska, gdy tylko potrafiły stać lub chodzić. Dotyczyło to kurcząt, które nie ukończyły jeszcze 24 godzin życia, a także koźląt, jagniąt i kociąt. Szczury odważały się zapuścić na „głęboką” stronę, o ile mogły dotknąć szkła swymi wąsami, lecz stale wybierały stronę „płytką”, gdy środkową deskę podniesiono tak, aby uniemożliwić im dotykanie wąsami szklanej płyty” (Gibson i Walk, 1960).


Dokonano też zaskakującego odkrycia, mianowicie, że badani reagują nie na sygnały głębi, lecz na |paralaksę |ruchu („motion parallax”): spostrzeganą zmianę swego własnego położenia w stosunku do innych przedmiotów. Gdy „podłoga” była blisko, wówczas własny ruch względem niej wydawał się szybszy, a zmiany własnego położenia były wyraźnie uzależnione od zmian wyglądu podłogi, z chwili na chwilę. Najwidoczniej uczenie się nie było konieczne dla spostrzegania tej różnicy i wyboru warunków, w których ruch względem podłogi spostrzegano jako szybszy.


Genetyczny potencjał nie tylko „rozwija się”. Chociaż jakość spostrzegania niemowlęcia jest godna podziwu, to jednak nie jest ono u niego tak adekwatne, jak u osoby dorosłej. Nawet tam, gdzie programowanie genetyczne dostarcza młodemu organizmowi dokładnego sensorycznego wyposażenia potrzebnego danemu gatunkowi - jak to widzieliśmy w wypadku neuronów „wykrywających robaki” w siatkówce żaby - wyposażenie to nie może zacząć funkcjonować bez określonych doświadczeń we wczesnym wieku. Wykazano to u wielu gatunków.




* * *



Ryc. 6.12. Zdjęcia przedstawiają urządzenie zwane „urwiskiem wzrokowym” („visual cliff”) oraz reakcje dwóch badanych na tę pozorną „przepaść”.  Chociaż dziecko klepało szybę ręką, a więc miało dotykowe dane świadczące, ze jest tam mocna powierzchnia, to jednak nie chciało wpełznąć na nią, gdy matka wołała je do siebie. Jednodniowa kózka spacerowała swobodnie po płytkiej stronie, lecz nie odważyła się wejść na stronę głęboką”. Gdy postawiono ją na odległym krańcu strony „głębokiej”, to tkwiła bez ruchu na wąskim brzeżku deski i wkrótce potem przeskoczyła z powrotem na stronę „płytką”.


* * *





Najwidoczniej środowisko musi dostarczać młodemu organizmowi doświadczeń w postaci wrażeń dotykowych i wrażeń bólu, jeśli zmysły te mają rozwijać się normalnie. Bez tego „środowiskowego treningu” normalny rozwój może być poważnie zakłócony. Interesujące skutki deprywacji dotykowej badano u szympansów.


„Jedno z badanych zwierząt, Rob, od czwartego tygodnia do trzydziestego pierwszego miesiąca życia miało kończyny zamknięte w kartonowych tubach - od łokci i kolan do czubków palców.


Rob nigdy nie nauczył się zwracać głowy ku tej ręce, którą stymulował eksperymentator, To jest, jeśli eksperymentator ściskał jego prawą rękę, Rob powinien zwrócić głowę w prawo, aby uzyskać nagrodę. Nie potrafił on tego zrobić po 2000 prób, chociaż normalny szympans uczył się tego zadania w ciągu około 200 prób” (Nissen, Chow i Semmes, 1951).


Stwierdzono także, że psy pozbawione we wczesnym okresie życia normalnej stymulacji są później w zasadzie niezdolne do wyuczenia się unikania bodźców bólowych i nie uczą się obawiać obiektów skojarzonych z takimi bodźcami (Melzack i Scott, 1957).
Również wzrok może być trwale upośledzony w wyniku braku wczesnych doświadczeń. Jeden z badaczy stwierdził, że wychowywanie szympansa w całkowitej ciemności spowodowało degenerację siatkówki i trwałe upośledzenie wzroku. Gdy jednak innemu szympansowi uniemożliwiono oglądanie przedmiotów, lecz pozwolono spostrzegać światło, to jego siatkówka nie została uszkodzona (Riensen, 1950).
Późniejsze badania przeprowadzone zarówno na kociętach, jak i szympansach, wykazały, że wtedy, gdy deprywacja wzrokowa prowadzi do zmian chemicznych w siatkówce (na przykład, gdy zwierze jest hodowane w całkowitej ciemności), to takie zmiany stają się nieodwracalne, o ile deprywacja ta przeciąga się poza wczesny okres życia („infancy”); powoduje to, że zwierzęta te cierpią na trwałą niezdolność do wyuczenia się pewnych nawyków percepcyjnych (Riensen, 1961).
Wydaje się, że aktywność ruchowa jest niezbędna dla normalnego rozwoju percepcji.


„W jednym z eksperymentów kocięta krępowano w ten sposób, że nie mogły one chodzić po pomieszczeniu od czasu, gdy po raz pierwszy zostały wystawione na światło. W porównaniu ze zwierzętami hodowanymi normalnie, ich zachowanie w sytuacjach wymagających orientacji wzrokowej było upośledzone. Pierwotnie wyniki te przypisywano skutkom deprywacji bodźcowej. Ponieważ skrępowane kocięta nie mogły zmieniać swego środowiska bodźcowego, chodząc po pomieszczeniu, były one zatem pozbawione dużej części zmian w stymulacji wzrokowej; przyjęto, że jest to przyczyną występującego u nich upośledzenia różnicowania wzrokowego.
Dalsze badania wykazały, że wyjaśnienie to jest niewystarczające. Pary kociąt zyskiwały doświadczenie dzięki urządzeniu, które powodowało ich jednakowe przemieszczanie się w środowisku, lecz uniemożliwiało jednemu zwierzęciu z tej pary aktywny ruch (ryc. 6.13). Ruchy aktywnego kotka były przekazywane za pośrednictwem umieszczonej na osi dźwigni oraz przekładni łańcuchowej do małej gondoli, w której umieszczony był drugi kotek. Gdy aktywny kotek chodził dookoła, wówczas bierny kotek w gondoli poruszał się w identyczny sposób; tak więc oba zwierzęta doświadczały tych samych zmian stymulacji wzrokowej.




* * *



Ryc. 6.13. Kociak po prawej może poruszać się po pomieszczeniu, odbierając różne bodźce wzrokowe. Kociak po lewej umieszczony jest w małej gondoli zawieszonej na drążku, który obraca się na osi i jest połączony z uprzężą drugiego kotka; pozwala to zwierzęciu pozbawionemu doświadczeń ruchowych mieć identyczne doświadczenia wzrokowe.


* * *





W tej sytuacji aktywne kocięta rozwijały się normalnie: na przykład mrużyły oczy, gdy zbliżały się do nich jakieś przedmioty, wyciągały łapy, gdy przenoszono je na jakąś powierzchnię. Natomiast bierne kocięta nie wykazywały tych zachowań, chociaż nauczyły się ich szybko po paru dniach, gdy pozwolono im poruszać się po pomieszczeniu samodzielnie” (Held, 1965).


O praktycznym znaczeniu stwierdzeń tego rodzaju świadczą wyniki innego eksperymentu. Grupie dzieci wychowywanych w zakładach opiekuńczych zapewniono wyjątkowe możliwości aktywnego zajmowania się wzbogaconym środowiskiem wzrokowym. Tempo rozwoju pewnych zdolności wzrokowo-słuchowych uległo u nich znacznemu przyspieszeniu. Uzyskano także dane świadczące o występowaniu okresu krytycznego; oddziaływanie to było mniej skuteczne, jeśli zastosowano je zbyt wcześnie lub zbyt późno (White i Held, 1966).  Wynika z tego, że normalny rozwój pewnych aspektów spostrzegania oraz koordynacji percepcyjno-ruchowej wymaga zatem nie tylko określonych rodzajów stymulacji, lecz także aktywności ruchowej.
Wszelkie efektywne przetwarzanie bodźców i zachowanie percepcyjne ma za zadanie przygotować organizm do właściwego reagowania na wymagania środowiska. Jeśli percepcja ma być niezawodnym ogniwem w tej sekwencji, to musimy wytworzyć czuciowo-ruchowy system sprzężenia zwrotnego, który dostarcza nam pewnej informacji o następstwach naszych ruchów. Może to nastąpić jedynie w wyniku aktywnego nabywania przez nas doświadczeń.
Jedno z najbardziej fascynujących odkryć, dokonanych w ostatnich latach w dziedzinie percepcji, pozwoliło w przekonywujący sposób wykazać, że doświadczenie może zmieniać właściwości reakcji poszczególnych neuronów czuciowych.


„Kocięta hodowano w specjalnie zaprojektowanych „środowiskach wzrokowych”, w których widziały one jedynie prążki pionowe lub jedynie prążki poziome. Gdy osiągnęły one wiek dojrzały, wówczas dokonano pomiarów, aby przekonać się, czy w wyniku tych wczesnych doświadczeń nastąpiły zmiany w polach recepcyjnych neuronów ich systemów wzrokowych.
Stwierdzono, ze dorosłe koty miały neurony wrażliwe tylko na bodźce ukierunkowane w ten sam sposób jak bodźce, z którymi stykały się one w okresie swych wczesnych doświadczeń; żadne z nich nie miały neuronów, które reagowałyby na bodźce ukierunkowane poziomo i na odwrót” (Blakemore i Cooper, 1970).


Jeszcze bardziej efektowne wyniki uzyskano w wielu badaniach przeprowadzonych przez Helmuta Hirscha i jego współpracowników (Hirsch i Spinelli, 1970, 1971; Hirsch, 1972). Kocięta hodowano do wieku trzech miesięcy w maskach, które sprawiały, że pole wzrokowe jednego oka składało się z poziomych prążków czarnych i białych, a pole wzrokowe drugiego oka z prążków pionowych. Rejestrując aktywność komórek kory wzrokowej u kociąt w wieku 10 i 12 tygodni, a następnie w wieku dwóch lat, stwierdzono, że komórki kory połączone z okiem odbierającym linie poziome mogły być aktywowane jedynie przez bodźce poziome, podczas gdy komórki połączone z drugim okiem, reagowały na bodźce pionowe. Zdolność spostrzegania takich właściwości świata wizualnego, jak głębia i kontury, zdaje się zatem zależeć od stykania się z nimi w określonym „okresie krytycznym” we wczesnej fazie rozwoju. Specyficzny charakter neuronów korowych, stwierdzany zwykle u osobników dorosłych, jest niewątpliwie wynikiem kształtującego i modyfikującego wpływu doświadczeń wzrokowych.
Wysunięto przypuszczenie, że większe neurony w mózgu mogą pozostawać względnie stałe, pod kontrolą genetyczną, podczas gdy małe „mikroneurony”, o krótkich aksonach, zmieniają się pod wpływem doświadczenia, modyfikując z kolei wzorce aktywności większych neuronów (Hirsch i Jacobson, 1974).  Natura i wychowanie współdziałają zatem ze sobą doskonaląc nasz mózg i umożliwiając nam korzystanie z dawnych przystosowań naszych przodków, jak również z aktualnej informacji, której potrzebujemy, aby przystosować się do warunków panujących tu i teraz. Nie wiemy jeszcze, w jakim stopniu zachowania, które określamy jako „inteligentne” i badamy za pomocą naszych „testów inteligencji”, rozwijają się dzięki temu współdziałaniu i interakcji.




Teorie rozwoju
percepcyjnego




Chociaż filozofowie, fizjologowie i psychologowie reprezentujący wiele różnych szkół i kierunków zgadzają się, że percepcja stanowi klucz do ludzkiego poznania, to jednak podawane przez nich różne wyjaśnienia tego procesu były źródłem gorących sporów. Obecnie naszkicujemy pokrótce główne stanowiska. Będziesz mógł więc ocenić ich przydatność, gdy zapoznamy się ze sposobami zbierania materiałów dowodowych i z uzyskanymi odpowiedziami.


Brytyjski asocjacjonizm i analityczna introspekcja. Pytanie, w jaki sposób dochodzimy do poznania rzeczywistości, interesowało filozofów na długo przedtem, zanim psychologowie zaczęli badać percepcję.


Poczynając od XVII wieku brytyjscy asocjacjoniści (Locke, Berkeley i Hume) wysunęli ogólną teorię wiedzy i percepcji, która oddziałuje na uczonych nawet obecnie. Twierdzili oni, że wiedza o rzeczywistości może pochodzić jedynie z wrażeń przetwarzanych przez aparat zmysłowy. Proste idee uważano za nie podlegające redukcji elementy doświadczenia zmysłowego.  Złożone idee miały ukształtować się z tych prostych elementów w wyniku wyuczonych skojarzeń. Treści umysłu można by zatem rozkładać na te podstawowe jednostki, które są elementami składowymi wrażeń. Filozofowie ci, ze względu na to, iż kładli nacisk na doświadczenie zmysłowe jako podstawę wiedzy, zwani są także brytyjskimi |empirystami. Interesowali się oni nie tym, w jaki sposób zachodzi percepcja, lecz rolą percepcji w naszej wiedzy o rzeczywistości.
Pierwsi psychologowie, tacy jak Wundt i Titchener w Niemczech zaakceptowali te założenia. W końcu XIX wieku skupili oni swe wysiłki na próbach wyćwiczenia obserwatorów w doświadczaniu i opisywaniu „czystych wrażeń”, nie skażonych uczeniem się. Przyjmowano, że „percepcja” stanowi bardziej zaawansowane stadium, w którym „pierwotne” doświadczenia zmysłowe są zmieniane i zniekształcane w różny sposób. Byli oni pewni, że dzięki |wyćwiczonej |introspekcji potrafią dotrzeć do tych pierwotnych elementów doświadczenia psychologicznego i że elementy te powinny być punktem wyjścia dla problematyki psychologicznej.


Rewolucja psychologów postaci. Na początku bieżącego stulecia grupa niemieckich psychologów z Uniwersytetu Berlińskiego (Kohler, Koffka, Wertheimer) zaatakowała zarówno koncepcję |kojarzenia |elementów jako podstawę percepcji, jak też |analizę |introspekcyjną jako klucz do pierwotnego, podstawowego doświadczenia. Położyli oni natomiast nacisk na wrodzone procesy organizujące, które sprawiają, że |struktury („patterns”) są pierwotną właściwością doświadczenia. Według postaciowców, nasza percepcja kontekstu i relacji jest równie podstawową „daną” jak „błękitność” czy jakikolwiek inny z prostych elementów, których poszukiwali introspekcjoniści.
Niemieckie słowo „Gestalt” (dosł. postać) trudno jest dokładnie przetłumaczyć; najbardziej zbliżona pod względem znaczenia jest |konfiguracja (układ). Konfigurację uważa się za podstawową jednostkę percepcji i innych doświadczeń. Według postaciowców „całość jest czymś więcej niż sumą swych części” i na wiele sposobów determinuje charakter i zachowanie się tych części, a nie na odwrót. Melodia jest taka sama w jednej tonacji, jak i w innej, chociaż zmieniają się wszystkie poszczególne nuty. Również cechy całości - takie jak skoczność czy rzewność melodii - nie tkwią w poszczególnych nutach. Właściwości relacyjne, takie jak wymienione powyżej, są częścią pierwotnego spostrzeżenia (percepcji), nie zaś dodanie później wskutek nieświadomego wnioskowania. Na przykład: żadna introspekcyjna analiza pozornego ruchu w przypadku zjawiska f (zjawiska fi), nie może spowodować, że ten ruch zniknie.
Badania Barlowa nad neuronami potwierdzają tezę postaciowców, że cechy strukturalne („pattern characteristics”) są wytworem sił organizacyjnych, które działają w układzie nerwowym. Natomiast mechanizm fizjologiczny jest odmienny, ponieważ postaciowcy zakładają, że organizowanie zachodzi w mózgu, zgodnie z modelem pola sił, podczas gdy odkrycie analizatorów cech („feature analyzers”) ujawniło, że pojedyncze neurony reagują na określone cechy strukturalne w polu wzrokowym (Barlow, 1972).


Podejście transakcyjne. Według Amesa (1951), który prowadził badania przy zastosowaniu przechylonego pomieszczenia, każdy z nas wytwarza - w wyniku swoich transakcji („transactions”) ze swym specyficznym środowiskiem - pewien ograniczony zbiór spostrzeżeń („perceptions”), którym posługuje się w odniesieniu do nieskończonej różnorodności możliwych obrazów na siatkówce, jaki nieustannie odbiera. Na podstawie naszego doświadczenia czynimy przypuszczenia, w jaki sposób skonstruowana jest rzeczywistość, i te właśnie przypuszczenia decydują o tym, co spostrzeżemy. Spostrzeganie staje się wyuczonym aktem konstruowania rzeczywistości, tak aby pasowała do naszych przypuszczeń, które jej dotyczą.
Możemy pomyśleć o tym jako o kasynie gry, w którym gracz uczy się z doświadczenia, jakie są szanse różnych kombinacji zdarzeń. Zwykle gracz ma więcej informacji niż mu potrzeba i wygrywa. Jednakże stale wygrywając nie uczy się on niczego nowego. Jeśli nagle zacznie tracić swoje stawki i zdarzenia, na których polegał, zdają się ulegać zmianom, to wówczas musi poszukiwać nowej informacji.


Spostrzeganie jako identyfikacja sygnałów. Jeszcze inne podejście reprezentuje Eleanor Gibson (1969, 1970), która uważa percepcję za proces polegający nie na |dodawaniu czegoś do wejścia sensorycznego, lecz na |redukowaniu go, w którym to procesie nieistotne elementy - „szum” - ulegają odfiltrowaniu, a istotne elementy sygnału zostają zidentyfikowane.  Proces ten pozwala organizmowi nauczyć się, co w środowisku jest przewidywalne, tak aby mógł on radzić sobie z tym środowiskiem.
Według Gibson, „percepcja polega na wydobywaniu informacji z bodźców”.  Mając do czynienia z nieograniczonym, zmiennym potokiem stymulacji, musimy odkrywać (lub stwarzać) porządek w tym pozornym chaosie i w ten sposób czynić nasze percepcyjne uniwersum zrozumiałym i przewidywalnym. „Redukcja niepewności” stwierdza Gibson, jest sama w sobie wzacniająca, a zatem stanowi pożądany produkt końcowy w naszym poszukiwaniu znaczących, niezmiennych cech naszego środowiska. Musimy wyodrębniać kluczowe elementy, wydobywać ważne szczegóły z kontekstu, odfiltrowując nieistotne, przypadkowe, nieinformacyjne aspekty stymulacji.
Gibson sugeruje, że aby percepcja w wieku dojrzałym była efektywna, dzieci muszą nauczyć się: a)rozróżniać bodźce, które wydają się podobne, b) zdawać sobie sprawę, że zmiany w wyglądzie zewnętrznym nie zawsze oznaczają zmiany w tożsamości oraz c) rozpoznawać relacje, reguły i struktury, które organizują oddzielne części w całość lub umożliwiają rozkładanie całości na elementy.
Na przykład, dla większości młodych ludzi różnice pomiędzy różnymi grupami rockowymi, pod względem rodzaju uprawianej przez nie muzyki, są bardzo wyraźne. Nastolatkowi z lat siedemdziesiątych trudno byłoby pomylić płytę z nagraniem „Rollingstonsów” z płytą zespołu „The Who”, lecz dla rodziców tego nastolatka różnica ta jest zwykle zupełnie nieuchwytna; obie płyty to po prostu „jakaś głośna muzyka rockowa”.
Bez względu na to, do jakiego pokolenia należymy, wydaje się, że są pewne rzeczy na tym świecie, na które nasi rodzice są „ślepi”! Lecz jak często nastolatki i ich rodzice słuchają uważnie muzyki tego samego rodzaju? Z pewnością niezbyt często. Gdy więc młodzi ludzie słuchają takiej grupy, jak „The Who”, to ich minione doświadczenia sprawiają, że lepiej od swych rodziców potrafią rozróżnić specyficzne cechy pozwalajace zidentyfikować ten zespół. Z drugiej strony, rodzice potrafiliby zapewne spostrzec różnicę pomiędzy muzyką Artiego Shawa i Glenna Millera - podczas gdy dla nastolatków muzyka obu tych zespołów mogłaby brzmieć nierozróżnialnie mdło.
Tych właśnie wypadków dotyczy teoria różnicowania opracowana przez Eleanor Gibson. Według tej autorki, wraz z nabywaniem doświadczenia podobne bodźce zaczynają wyglądać lub brzmieć różnie, w miarę, jak zaczynasz zauważać w jednym zbiorze charakterystyczne cechy, które nie występują w drugim zbiorze. Stopniowo identyfikujesz ważne cechy stałe („constancies”) i stałe relacje, za pomocą których możesz rozpoznać te bodźce i wyodrębnić je.
Wielokrotny kontakt nie wystarczy jednak, aby nastąpiło takie zróżnicowanie. Na przykład jest całkiem możliwe, że twoi rodzice mieli dość |kontaktów z lubianą przez ciebie muzyką, aby móc zidentyfikować różne grupy muzyczne, lecz nie zwracali uwagi na to, czego słuchali.
Istnieje wiele innych ogólnych teorii i „mini-teorii” percepcji, lecz przytoczone tu przykłady dadzą ci pewne pojęcie o tym, jak podstawowe znaczenie ma przyjmowana przez kogoś teoria percepcji dla sposobu pojmowania przez niego zadań psychologii. Psychologowie, którzy uważają percepcję za łączenie elementów, będą badać inne problemy niż psychologowie, którzy uważają, że percepcja polega na dokonywaniu nowych różnicowań i identyfikowaniu zintegrowanych struktur. Prawidłowość ta występuje niezależnie od tego, czy psychologowie ci prowadzą badania nad uczeniem się, myśleniem, motywacją, zachowaniem społecznym czy też pomiarem różnic indywidualnych.




Uczenie się nawyków
percepcyjnych




Rozwój percepcyjny u ludzi przebiega równolegle do rozwoju innych systemów - języka, poznania, pamięci i innych. Jak pamiętamy z ostatniego rozdziału, zgodnie z poglądami Jeana Piageta, rozwój percepcyjny i poznawczy nie zawsze uzupełniają się, a w niektórych stadiach są nawet antagonistyczne. Na przykład, zrozumienie zasad, takich, jak zasada zachowania ilości, może wymagać od dziecka posługiwania się pojęciami, które są niezgodne z otrzymywanym w danej chwili wejściem sensorycznym.  Ponieważ jednak spostrzeżenia te są tak bezpośrednie, konkretne i pozornie „rzeczywiste”, trudno jest małemu dziecku nauczyć się nieuwzględniania ich.


Rozwój poznawczy zmienia percepcję. W pierwszych latach życia dzieci są empirystami, biorącymi za dobrą monetę to, co widzą i zajmującymi się tylko realiami. W sztuce „The King and I” (Król i ja) młody książę Syjamu nie chce uwierzyć w istnienie |śniegu, ponieważ nigdy nie widział czegoś takiego. Jego ojciec odpowiada na to, że nauka szkolna byłaby niepotrzebna, gdybyśmy wierzyli tylko w to, co widzimy.
Zarówno nasza nauka w szkole, jak i nasze codzienne kontakty z naszymśrodowiskiem wkrótce przekonują nas, że świat nie ogranicza się do tego, co widzimy. Nasz rozwój poznawczy przekształca nas zatem z empiryków w teoretyków operujących symbolami, abstrakcjami, analizami, możliwościami, a nawet fantazjami. Aby jednak dziecko mogło dokonać tego przekształcenia, musi być wolne od ograniczeń nakładanych przez konieczność stałej czujności percepcyjnej, takiej jaka jest potrzebna w zagrażającym środowisku. Nie ma poetów wśród maltretowanych dzieci ani filozofów wśród głodujących.
W trakcie normalnego rozwoju percepcyjnego uczymy się (w wyniku różnych oddziaływań) ignorować pewne aktualne cechy percepcyjne sytuacji, aby dokonać takich transformacji tej sytuacji, które są potrzebne dla wytworzenia wyobrażeń przedstawiających, w jaki sposób sytuacja ta mogłaby wyglądać w innych warunkach (z innego punktu widzenia lub jak wyglądała ona w przeszłości, lub jak będzie wyglądała w przyszłości, lub jaką mogłaby być w jakiejś innej konfiguracji). Jest to istotnie trudne zadanie percepcyjno-poznawcze: nauczyć się patrzeć na dany obiekt czy sytuację i „widzieć” ją taką, jaka „mogłaby” lub „powinna” być, a nie taką, jaka jest w danym momencie. Umiejętność ta jest doskonale rozwinięta u architektów i projektantów, których zawód polega na wychodzeniu poza aktualną informację bodźcową i wyobrażeniu sobie, jak dany obraz będzie wyglądał, kiedy zostanie przekształcony zgodnie z ich projektem. Taka zdolność rozwija się z wiekiem i doświadczeniem.


„W pewnym badaniu dzieciom w różnym wieku pokazywano cztery zestawy bodźcowe, składające się z dwóch pojedynczych obiektów (okularów i latarki) oraz dwóch złożonych obiektów (scen wiejskich). Po obejrzeniu przez nie zestawu bodźcowego pokazywano im osiem barwnych fotografii tego zestawu, zrobionych z różnych punktów widzenia. Następnie umieszczano w różnych miejscach lalkę i proszono dzieci, aby wybrały fotografię przedstawiającą widok, jaki lalka ma z każdego z tych miejsc. Dzieci wykonywały to zadanie w dwóch sytuacjach: patrząc na pierwotny obiekt bodźcowy i przy obiekcie bodźcowym zasłoniętym.
Sześcioletnie dzieci nie potrafiły wybierać poprawnych fotografii w żadnej z tych sytuacji; nie były one zdolne ignorować tego, jak „naprawdę” wyglądała dla nich dana sytuacja, gdy patrzyły na nią, ani też wyobrazić sobie, jak wyglądałaby ona z innej perspektywy. Ośmiolatki i dziesięciolatki miały trudności, gdy pierwotne bodźce były nadal widoczne, lecz uzyskiwały lepsze wyniki, gdy były one zasłonięte i można się było posługiwać jedynie sygnałami pojęciowymi” („conceptual cues”; Brodzinsky, Jackson i Overton, 1972).


|jewarp |od |jewel |do |zsatyzc |ogezcald, |ęis |śełaiwanatsaz |yzC
Ważnym przykładem nawyków percepcyjnych, jakie wytwarzamy w wyniku uczenia się, jest nasz nawyk czytania od lewej do prawej.
Hebb (1949) wysunął hipotezę, że wielokrotna stymulacja pewnego układu receptorów utrzymuje aktywizację określonego zbioru komórek nerwowych i powoduje nierówne wyćwiczenie pewnych części siatkówki. Jeśli hipoteza ta jest prawdziwa, to ludzie czytający teksty angielskie, przyzwyczajeni do tego, że aby odczytać następne słowo muszą spoglądać w prawo, powinni ukształtować większą wrażliwość na bodźce znajdujące się tuż na prawo od punktu fiksacji. Istotnie, eksperymenty wykazały, że Amerykanie (powyżej VI klasy) rozpoznawali lepiej słowa prezentowane tuż na prawo od punktu fiksacji, niż słowa prezentowane po lewej stronie tego punktu. Natomiast badani, których ojczystym językiem jest hebrajski (w którym teksty czyta się od prawej strony do lewej) - rozpoznawali więcej słów znajdujących się po lewej stronie od punktu fiksacji (Mashkin i Forgays, 1952).
Kiedy jednak czytasz tekst angielski, czytasz cały wiersz liter, a nie tylko pojedyncze litery. Jakich oczekiwałbyś wyników w eksperymencie, w którym zamieszczone poniżej karty są przez ułamek sekundy rzutowane (pojedynczo) na ekran, a badanym powiedziano, aby skupili wzrok na kropce znajdującej się w środku? Które litery będą rozpoznawane najczęściej?


Chociaż |K znajduje się blisko punktu fiksacji tylko na jednej karcie, jest ona rozpoznawana znacznie częściej niż jakakolwiek inna litera na wszystkich tych kartach. Najrzadziej rozpoznawaną literą jest |E, a |U i |P zajmują miejsce pośrednie. Tego rodzaju wyników należałoby oczekiwać na podstawie znajomości wyuczonej struktury uwagi u osób  czytających płynnie, które zwykły zaczynać czytać od lewej strony górnego wiersza i posuwać się ku prawej (Heron, 1957).


„W nowszych badaniach Sekuler, Tynan oraz Levinson (1973) z North Western University stwierdzili, że kiedy równocześnie rzutowano na ekran dwa małe kwadraciki lub dwie litery, to badani podawali na ogół, iż element z lewej strony pojawiał się jako pierwszy. Następnie bodźce te rzutowano w odstępie kilku milisekund; badani podawali właściwą kolejność w 60% przypadków, jeśli bodziec po lewej stronie był rzutowany jako pierwszy, lecz tylko w 30% przypadków, jeśli pierwszy pojawiał się bodziec po prawej stronie. Zjawisko to występowało niezależnie od płci 140 przebadanych studentów, jak również niezależnie od tego, czy badany był praworęczny czy leworęczny”.


Powyższe stwierdzenia wykazują wpływ naszego nawyku czytania od lewej do prawej na wykrywanie i interpretację nowych bodźców. Stwarzają one również pewną nadzieję, jeśli chodzi o identyfikowanie i rehabilitację dzieci mających trudności w czytaniu, znane pod nazwą |dysleksji. Wiele z tych dzieci widzi literę |d jako „b”, słowo „kot” jako „tok” oraz odwraca środkowe cyfry w takich szeregach, jak 4 - 3 - 2 - 1.




Niewidomi uczą się
widzieć




Więcej materiału dowodowego świadczącego, iż dla normalnego rozwoju zdolności spostrzegania konieczne jest doświadczenie w odbieraniu i organizowaniu wejścia sensorycznego, dostarczyły badania nad osobami dorosłymi, które przez całe życie były niewidome, a nagle odzyskały wzrok.
Ludzie urodzeni z kataraktą (zamglenie soczewek) na obu oczach są całkowicie niewidomi. Operacja pozwalająca usunąć tę wadę jest zupełnie prosta. Jednakże z tych czy innych przyczyn niektóre z tych osób pozostają nie leczone, aż do osiągnięcia wieku dojrzałego. Ludzie tacy są oczywiście pozbawieni doświadczeń wzrokowych, lecz większość innych zdolności mają równie dobrze rozwiniętych, jak każda inna osoba dorosła. Badani bezpośrednio po usunięciu katarakty są osobami, które znajdują się na najwcześniejszym stadium rozwoju wzrokowego, a z drugiej strony będąc dorosłymi są zdolni do przekazywania swych doświadczeń.


Von Senden (1932) zestawił dane dotyczące pewnej liczby takich przypadków. Po operacji pacjenci ci byli niezdolni do rozpoznawania nawet najprostszych przedmiotów. Każdy pacjent potrzebował wielu ekspozycji danego przedmiotu w określonym otoczeniu, aby mógł go nazwać. Nawet wówczas pacjent często nie potrafił rozpoznać tego samego przedmiotu w odmiennym otoczeniu. Pacjenci ci mieli równie duże trudności przy rozpoznawaniu twarzy przyjaciół, krewnych oraz innych osób mających duże znaczenie w ich życiu, jak i przy rozpoznawaniu figur geometrycznych. Jeden wyjątkowo inteligentny pacjent dwa lata po operacji potrafił zidentyfikować jedynie cztery czy pięć twarzy.


Dostrzeganie wielu różnic, które uważamy za oczywiste i łatwo są spostrzegane przez każdego człowieka, pacjenci ci musieli się dopiero uczyć. Na przykład potrafili oni szybko nauczyć się rozróżniać koła i trójkąty, lecz nadal mogli być niezdolni do odróżnienia trójkątów od kwadratów. Najwyraźniej zdali sobie tylko sprawę, że trójkąty mają pewne cechy, których nie posiadają koła - zapewne kąty. Jeszcze raz zaznacza się zatem wyraźnie doniosłe znaczenie doświadczeń percepcyjnych we wczesnych stadiach rozwoju.
Dostępny materiał dowodowy sugeruje, że przywrócenie wzroku dorosłym, którzy nauczyli się żyć w świecie niewidomych, nie zawsze jest takim błogosławieństwem, jak moglibyśmy oczekiwać. Wielu pacjentów początkowo niewiele widziało i mieli oni trudności w rozróżnianiu prostych kształtów i przedmiotów; co więcej, niektórzy z nich nigdy nie nauczyli się posługiwać dobrze wzrokiem. W wielu z tych przypadków powtarzało się zjawisko polegające na niechęci do polegania na nowo uzyskanym zmyśle wzroku.  Gregory (1966) opisał przypadek 52-letniego Anglika, który stracił wzrok w 10 miesiącu życia.


„Obserwowaliśmy przybierajace dramatyczną formę trudności, jakie napotykał S. B. (pacjent), gdy miał zaufać swemu wzrokowi i wykorzystać go przy przechodzeniu przez jezdnię. Przed operacją ruch uliczny nie sprawiał mu kłopotu. Przechodził przez jezdnię sam, trzymając rękę lub kij sztywno wyciągnięte przed sobą, wówczas ruch uliczny uspakajał się jak wzburzone wody przed Chrystusem. Natomiast po operacji musieliśmy we dwójkę towarzyszyć mu po obu stronach, aby zmusić go do przejścia przez jezdnię: był przerażony jak nigdy przedtem w życiu” (Gregory, 1966, s. 197)


W końcu S. B. nie zadawał sobie trudu, aby zapalić wieczorem światło, lecz siadywał sam w (przyjemnej) ciemności.




* * *



Ryc. 6.15. Powyższe rysunki angielskich autobusów wykonał S. B. pacjent Gregory’ego. Górny rysunek, wykonany 48 dni po operacji, zawiera tylko te szczegóły, które pacjent jeżdżąc autobusem poznał prawdopodobnie dotykiem.  Drugi rysunek, wykonany sześć miesięcy później, jest bardziej szczegółowy, lecz nadal brak przedniej części autobusu, której pasażer nie poznaje dotykiem. Na ostatnim rysunku, sporządzonym przed upływem roku, widoczne są dalsze szczegóły, a ponadto zostały użyte litery pisane, jednakże przód autobusu jest ciągle jeszcze niekompletny.


* * *





Jednakże w innych przypadkach aktywni, inteligentni, wykształceni pacjenci odzyskali zdolność skutecznego posługiwania się przywróconym im zmysłem wzroku.




Uczenie się
przystosowywania do
sprzecznych danych
spostrzeżeniowych




Wyobraź sobie, że pewnego dnia, kiedy obudziłeś się, wszystko jest odwrócone, tak, że kiedy sięgasz w lewo, aby wyłączyć budzik, nie możesz tego uczynić, ponieważ znajduje się on w rzeczywistości po prawej stronie.  Lub gdy schodzisz na prawą stronę chodnika, aby zejść z drogi rozbrykanym wyrostkom, których widzisz po lewej stronie, wpadasz prosto na nich, chociaż znajdowali się oni wyraźnie po lewej stronie twego pola wzrokowego.  Czy potrafiłbyś przystosować się do takiego zniekształcenia twego pola wzrokowego? Gdybyś był żabą, odpowiedź brzmiałaby „nie”, ponieważ jednak jesteś człowiekiem wyposażonym w elastyczny, dający się modyfikować układ nerwowy, potrafiłbyś tego dokonać.
Podobne zniekształcenie pola wzrokowego wywołano u żab odwracając chirurgicznie bieg ich nerwów wzrokowych (Sperry, 1945). Po tej operacji żaby nie były zdolne zmodyfikować swego zachowania ruchowego tak, aby dostosowało się ono skutecznie do zmienionej w ten sposób percepcji. Raz za razem rzucały się one na owada, który zdawał się być po prawej stronie, lecz nigdy nie udawało się im złapać go, ponieważ w rzeczywistości znajdował się on po stronie lewej.
W końcu ubiegłego stulecia psycholog G. M. Stratton posłużył się samym sobą jako badanym w podobnym eksperymencie, odwracając swoje pole wzrokowe w ten sposób, że to co było po lewej stronie wydawało się po prawej, a to co u góry - u dołu i na odwrót; w tym celu zastosował okulary pryzmatyczne, które nosił bez przerwy przez kilka dni. Chociaż początkowo cierpiał na bóle głowy, lęk oraz popełniał wiele błędów, w końcu udało mu się skoordynować ruchy ciała, pomimo że świat wydawał mu się odwrócony do góry nogami. Również w lepiej kontrolowanych badaniach przeprowadzonych później przez Ivo Kohlera (1962) stwierdzono skuteczną adaptację wzrokowo-ruchową.  Co więcej, niektórzy ludzie wykazują zdumiewającą zdolność szybkiego przystosowania się do zmienionego wzrokowego sprzężenia zwrotnego.




Zbliżenie


Opowieść o Jimie Plunketcie


„Aby zademonstrować, w jakim stopniu funkcjonowanie ruchowe jest uzależnione od sygnałów wzrokowych, jeden z autorów niniejszej książki poprosił studenta pierwszego roku psychologii ze Stanford University, Jima Plunketta (uznanego później przez NFL - Narodową Ligę Futbolową - za debiutanta roku), aby wziął udział jako osoba badana w teście dokładności rzucania piłką futbolową.
Najpierw Plunkett rzucał piłkę ze swą zwykłą zegarmistrzowską dokładnością do poruszającego się pojemnika na końcu 15 metrowego podium.  Następnie założono mu okulary, na które naklejono pryzmaty przemieszczające pole widzenia o 20 stopni w prawo. Przy następnym rzucie chybił on celu - a tłum kolegów przyjął to pomrukiem zdumienia. Lecz po zaledwie jednym rzucie próbnym potrafił on skorygować błędną informację dostarczaną przez zniekształcone wzrokowe sprzężenie zwrotne i trafiał do celu bezbłędnie - ku radości kolegów i pognębieniu pokonanego pozornie profesora.
Po dziesięciu jeszcze bezbłędnych próbach profesor zdjął mu okulary, przywracając gwiazdę futbolu do jej „normalnego” stanu. „Czy zechciałbyś rzucić jeszcze raz do pojemnika, po prostu, aby się upewnić, że potrafisz?” zapytał profesor. Z pogardliwym uśmieszkiem Plunkett podniósł swe potężne ramię i rzucił piłkę - która jednak minęła cel o 20 stopni z lewej strony!
Czy ta przekonująca lekcja psychologii zwiększyła u Plunketta zdolność przystosowywania się do zniekształceń pola widzenia, przyczyniając się w ten sposób do zdobycia w tym roku Różowego Pucharu Stanfordu? Profesor chciałby tak myśleć.


W eksperymentach nad odwróceniem pola wzrokowego mieszano trzy różne procesy, które w nowszych badaniach studiuje się odrębnie. Są to procesy następujące: a) zakłócanie orientacji pola wzrokowego prawa-lewa oraz góra-dół, b) stwarzanie niezgodności pomiędzy wzrokiem a innymi zmysłami, c) zaburzenie koordynacji wzrokowo-ruchowej.
Stwierdzono, że kiedy otrzymana przez nas informacja wzrokowa o położeniu jakiegoś przedmiotu jest różna od informacji słuchowej (słyszymy, że ptak śpiewa w pewnym miejscu, lecz widzimy go w innym miejscu), wówczas nie następuje kompromis, lecz rozwiązanie jednostronne. Jedna z modalności zmysłowych bierze górę nad drugą jako „materiał dowodowy” świadczący o tym, gdzie dany bodziec znajduje się rzeczywiście. Na przykład, gdy wzrokowe sprzężenie zwrotne i słuchowe sprzężenie zwrotne są rozbieżne o mniej niż 30%, wówczas kierunek położenia przedmiotu ustala się na podstawie informacji wzrokowej, a informacja słuchowa dostosowuje się do niej.  Zjawisko to znane jest pod nazwą |dominacji |wzrokowej lub |owładnięcia |wzrokowego („visual capture” Pick, Warren i Hai, 1969).
W nowszych badaniach nad adaptacją percepcyjną do zniekształceń zajęto się problemem adaptacji do rozbieżności wzrokowo-ruchowej, u biernych osób badanych, które nosząc okulary pryzmatyczne, przemieszczając pole wzrokowe na jedną stronę (o około 15 st.), starając się trafić w cele wzrokowe znajdujące się w odległości wyciągniętej ręki (Held, 1965). Chociaż pozornie jest to proste zadanie, to jednak koordynacja wzrokowo-ruchowa obejmuje wiele komponentów: cel bodźcowy, jego obraz na siatkówce, położenie oczu, położenie głowy względem ciała, położenie ręki względem ciała oraz położenie palca w stosunku do celu. Komponenty te tworzą złożony system wzajemnych interakcji, wymagających kodowania wielorakich źródeł informacji, integracji ich, a następnie koordynacji (Howard, 1971). W zadaniu tym adaptacja do okularów pryzmatycznych następuje wówczas, gdy badani aktywnie poruszają ręką, natomiast nie następuje wtedy, gdy ktoś porusza ich ręką zamiast nich samych. Sądzi się zatem, że doświadczenie w zakresie ruchu wytwarzanego przez samego siebie ma decydujące znaczenie dla zaadaptowania się do rozbieżności wzrokowo-ruchowej. Potwierdził to eksperyment, w którym zahipnotyzowanym osobom badanym powiedziano, że nie odbierają oni żadnych wrażeń w swej ręce wskazującej cel; osoby te nie były w stanie zaadaptować się do przemieszczenia wytworzonego przez okulary pryzmatyczne. Badani w grupie kontrolnej, którzy zostali zahipnotyzowani, lecz nie otrzymali żadnych instrukcji dotyczących odbioru wrażeń w ręce, zaadaptowali się łatwo do przemieszczenia wytworzonego przez okulary pryzmatyczne (Wallace i Garret, 1973). Wyniki te są zgodne z wynikami uzyskanymi w badaniach Helda nad kociętami.
Chociaż przemieszczenie wytwarzane przez pryzmaty jest sztucznym sposobem badania rozbieżności wzrokowo-ruchowej, to jednak badania takie dotyczą niezmiernie ważnego zagadnienia: w jaki sposób, na podstawie doświadczeń, których dostarczają nam nasze oczy i nasze mechanizmy mózgowe, uczymy się sięgać, dotykać i manipulować tym, co znajduje się na zewnątrz nas, w naszym środowisku fizycznym.




Czynniki decydujące
o tym, co spostrzegamy




Wydaje się oczywiste, że akt spostrzegania wymaga zarówno złożonego fizjologicznego przetwarzania energii sygnałowej bodźca, jak i psychologicznego przetwarzania otrzymanej informacji. Toteż badania nad percepcją można podzielić na trzy obszerne kategorie, zgodnie z zasadniczym przedmiotem zainteresowania badaczy: a) nacisk na |bodźcowe wyznaczniki percepcji, takie jak konfiguracja, złożoność, siła sygnału, stosunek sygnału do szumu itd., b) nacisk na |aparat |fizyczny służący do wykrywania sygnałów, zarówno na poziomie receptorowym, jak i neuronowym, c) nacisk na |inne |związane |z |daną |osobą |czynniki wpływające na percepcję, takie jak historia uprzedniego ćwiczenia, przynależność do określonej kultury oraz czynniki motywacyjne czy osobowościowe. Rozpatrywaliśmy już badania należące do pierwszej i drugiej kategorii. W niniejszym podrozdziale rozpatrzymy badania należące do kategorii trzeciej.




* * *



Ryc. 6.16. Dlaczego Widzimy Figury Tak, Jak Je Widzimy?


1. Podobieństwo. Podobne elementy widzimy jako należące do siebie nawzajem bardziej niż do innych elementów, równie bliskich, lecz mniej podobnych. Czy w tej figurze widzisz kolumny liter Z i R, czy też rzędy złożone z następujących po sobie na zmianę liter Z i R?
Z R Z R Z R
Z R Z R Z R
Z R Z R Z R
Z R Z R Z R
Z R Z R Z R
Z R Z R Z R


2. Bliskość. Elementy, które są fizycznie bliskie, widzimy jako należące do siebie nawzajem bardziej, niż do podobnych elementów, które znajdują się dalej. Poniżej widzisz pary ZR, a nie RZ.
ZR  ZR  ZR  ZR
Bliskość może także sprawić, że obiekty wydają się podobniejsze, niż są w rzeczywistości. Ta sama figura, która wśród antylop wydaje się podobna do antylopy, wygląda jak ptak w towarzystwie innych ptaków.


3. Zamykanie. Jesteśmy skłonni spostrzegać figury niekompletne tak, jak gdyby były one kompletne. Tę linię krzywą widzimy jako kółko, w którym brakuje kawałka, a rozmieszczone poniżej nieregularne elementy spostrzegamy jako zwierzę.


4. Kontynuacja (ciągłości) Widzimy elementy jako należące do siebie nawzajem, jeśli zdają się być kontynuacją kierunku poprzednich elementów.  Linię falistą widzimy jako jedną figurę, linię łamaną o prostych kątach - jako drugą figurę.


5. Wspólny los. Elementy, które poruszają się w tym samym kierunku, spostrzegamy jako należące do siebie nawzajem. Gdy co druga tancerka wystąpi z szeregu i uczyni ten sam ruch, wówczas spostrzegamy je jako pewną całość.


6. Odwracalność figury i tła. Niekiedy wzorzec bodźcowy jest tak zorganizowany, że można spostrzegać więcej niż jedną relację figura-tło.  Gdy są one w konflikcie, wówczas występują w świadomości na zmianę. W pokazanym tu przykładzie, gdy kielich staje się „figurą”, czarne tło zdaje się rozciągać z tyłu za nim, a gdy jako figury widzimy dwie twarze, w głębi jest białe tło.


7. Tak zwana dobroć figury. Układ nerwowy zdaje się preferować regularne, proste formy. Widzimy tu dwa zachodzące na siebie kwadraty, nie zaś trójkąt i dwie nieregularne figury, chociaż byłoby to równie możliwe ze względu na odbierane bodźce sensoryczne.


* * *







Strukturalizowanie
spostrzeżeń




Podstawowe twierdzenie psychologów postaci, że organizacja stanowi część każdego spostrzeżenia, a nie jest czymś dodanym po odebraniu poszczególnych elementów - zostało ogólnie zaakceptowane. Określono różne aspekty tej organizacji.


Relacje między figurą a tłem. Jesteśmy skłonni organizować postrzegany „potok bodźców” w taki sposób, aby zminimalizować zmiany i różnice, jednocześnie utrzymując jedność i integralność. Najbardziej podstawowe znaczenie w tym procesie ma nasza skłonność do spostrzegania figury w odróżnieniu od tła. Wydaje się, że następuje to automatycznie, niezależnie od tego, czy patrzymy na przedmioty znajdujące się wokół nas, na chmury czy też na listki herbaty.
W porównaniu z tłem figura zdaje się: a) mieć kształt, b) być bliżej, c) być podobna do jakiegoś przedmiotu, d) być wyraźniejsza, e) mieć bardziej nasyconą barwę, f) posiadać oddzielający ją od tła kontur, g) mieć wokół siebie tło. Niektóre z czynników, które decydują o tym, co będzie „figurą”, zostało przedstawione na rycinie 6.16.
Znanym przykładem zastosowania tych zasad, w celu zmiany spostrzeganej figury, jest maskowanie. Niezależnie od tego, czy stosuje je przyroda dla ukrycia ofiary przed prześladowcami czy też wojsko (dla tych samych celów), maskowanie jest skuteczne wtedy, gdy zmniejsza wydatność sygnałów określających „figurę”, przez co pozwala figurze „roztopić się” w tle.
Nie tylko stwarzamy najlepszą figurę, jaką możemy, na podstawie uzyskanej informacji sensorycznej; często ponadto jesteśmy skłonni uzupełniać brakujące części lub widzieć figurę prawie kolistą jako bardziej kolistą niż jest w rzeczywistości, lub też w inny sposób czynimy figurę bardziej stabilną, regularną czy kompletną, niż zapewnia nam to informacja sensoryczna.
Jesteśmy skłonni spostrzegać konfiguracje nawet wtedy, gdy elementy rozpatrywane pojedynczo nie mają w ogóle żadnego związku z kompozycją, która się z nich „wyłania”. Łatwo możemy przekonać się o tym na przykładzie pomysłowej, generowanej przez komputer fotografii chimery, znajdującej się na paryskiej katedrze Notre Dame (Ryc. 6.17).


Łączenie sygnałów przy spostrzeganiu głębi. Wśród sygnałów, za pomocą których spostrzegamy głębię, znajdują się sygnały oparte na wyrazistości, perspektywie liniowej, fakturze, światłach i cieniach, względnym położeniu oraz innych standardach. Wszystkie te sygnały składają się na „bank informacji”, które w spostrzeganiu organizowane są w sensowną całość.
1. |Perspektywa |powietrzna. Ze względu na pył i dym znajdujący się w atmosferze, zarysy oddalonych przedmiotów mogą wydawać się zamglone i niewyraźne. Szczegóły, o których istnieniu wiemy, mogą być niedostrzegalne. 




* * *



Ryc. 6.17. Za pomocą komputera poziom jasności każdego z pól, na które podzielono zwykłą fotografię, został „przetłumaczony” na określone mikrofigury. Powstał w ten sposób obraz, który oglądany z bliska przyprawia o zawrót głowy mnóstwem szczegółów - lecz odsuń książkę na długość ręki, a zobaczysz chimerę, w tle zaś pojawią się budowle Paryża.


* * *





Stopień tego zamglenia zależy od odległości i trzeba sporo czasu, zanim nauczymy się na tej podstawie określać odległość. W istocie, gdy charakterystyczny stan atmosfery zmienia się, wówczas często oceniamy odległość niepoprawnie. Na przykład, osoba wychowana w zadymionym mieście przemysłowym, będzie w znacznym stopniu nie doceniać odległości przedmiotów, które spostrzega przez czyste powietrze górskie. Nowicjusz na górskiej farmie będzie wywoływał zdumienie u domowników oznajmiając, że zamierza „przejść się do tego pagórka i z powrotem przed śniadaniem”; tymczasem „pagórek” ów jest w rzeczywistości górą odległą o jakieś 50 mil.
2. |Perspektywa |liniowa. W miarę jak przedmioty oddalają się, wydają się one mniejsze i bliższe siebie. Szyny kolejowe czy krawężniki szosy zdają się spotykać ze sobą na horyzoncie. Odstępy miedzy przedmiotami rozmieszczonymi w jednakowych odległościach od siebie, takimi jak słupy telefoniczne, zdają się zmniejszać w miarę ich oddalania się. Te zjawiska perspektywy liniowej wykorzystują artyści malarze w celu przedstawienia odległości na obrazach.
3. |Faktura. Ściśle związany z perspektywą liniową jest czynnik faktury.  Na każdej powierzchni nie prostopadłej do linii wzroku, elementy faktury zdają się być rozmieszczone gęściej w miarę oddalania się tej powierzchni.  Faktura wspomaga zatem perspektywę liniową w sytuacjach, w których brak zbiegających się linii równoległych, dostarczających nam sygnałów pozwalających określić odległość.
4. |Światła i |cienie. Gdy światło pada na nieregularną powierzchnię, na przykład na twarz ludzką, wówczas pewne części są jasno oświetlone, a inne pogrążone w cieniu. Wygląd tych cieni mówi nam wiele o głębokości tych części. Malarze używają światłocienia dla przekazania wrażenia głębi na dwuwymiarowym płótnie.
5. |Względne |położenie. Gdy dwa przedmioty znajdują się na tej samej lini widzenia, wówczas bliższy zasłania dalszy lub jego część. Bliższe przedmioty zwykle zdają się znajdować w dolnej części dwuwymiarowego pola widzenia, odległe przedmioty - w jego górnej części.
6. |Znane |standardy. Ponieważ znamy wielkość lub kształt danego przedmiotu, możemy więc posługiwać się nimi jak standardami przy określeniu wysokości innych przedmiotów. Ten sygnał ma oczywiście decydujące znaczenie przy kształtowaniu stałości w spostrzeganiu przedmiotów (|object constancy”).
Przy spostrzeganiu głębi wykorzystuje się także sygnały, jakich dostarczają zmiany zachodzące w soczewkach oczu; soczewki te wybrzuszają się lekko, gdy patrzymy na przedmioty bliskie i spłaszczają się, gdy patrzymy na przedmioty odległe. Widzenie dwuoczne również w dużym stopniu pomaga spostrzeganiu głębi, ze względu na dodatkową informację dostarczaną przez |zbieżność (konwergencję) oczu, gdy ogniskują się one na przedmiocie bliskim względem obserwatora. Ponadto różniące się nieco obrazy, jakie otrzymujemy z dwojga oczu (nosi to nazwę |różnicy |siatkówkowej - „retinal disparity”), pomagają nam także spostrzegać głębię i odległość. Odległość określamy automatycznie, porównując i integrując oba te obrazy, co jest możliwe dzięki badaniu konturów przedmiotu.


Wykorzystanie sygnałów w percepcji dźwięku. Ludzie potrafią określać położenie (odległość i kierunek) przedmiotów wydających dźwięk. Ta zdolność lokalizowania dźwięków ma we współczesnym życiu znaczną wartość adaptacyjną. Na przykład, gdy przechodzisz ruchliwą ulicą, twoje życie może zależeć od tego, jak dokładnie określisz położenie nadjeżdżającego samochodu.
Naszą zdolność zlokalizowania dźwięków zawdzięczamy prawie wyłącznie posiadaniu uszu, umieszczonych w różnych punktach w przestrzeni.
1. Dźwięk przychodzący z przedmiotu znajdującego się po lewej stronie głowy dochodzi najpierw do lewego ucha, a dopiero później do prawego. Ta różnica w czasie może być bardzo mała, lecz mówi nam, z której strony przychodzi dźwięk.
2. Fale dźwiękowe przychodzące z lewej strony pobudzają lewe ucho silniej niż prawe.
3. Fale dźwiękowe, jak dowiedzieliśmy się już w tym rozdziale, składają się z następujących po sobie na przemian obszarów podwyższonego i obniżonego ciśnienia. Ponieważ uszy znajdują się w innych miejscach w przestrzeni, przeto fala dźwiękowa oddziałując na każde z nich będzie w innej fazie. Fale dźwiękowe w porównaniu z falami świetlnymi rozchodzą się bardzo powoli, co powoduje, iż różnice fazy w wypadku fal dźwiękowych są dość znaczne.
Możemy posługiwać się wymienionymi wyżej sygnałami dotyczącymi kierunku tylko wtedy, gdy dźwięki przychodzą z jednej lub drugiej strony. Dźwięków dochodzących prosto z przodu nie można łatwo odróżnić od dźwięków dochodzących z góry czy z tyłu, ponieważ stymulacja odbierana przez oba uszy jest prawie identyczna.




Kultura, doświadczenie
i motywy osobiste




„Percepcja jest niewątpliwie uzależniona od minionego doświadczenia” - powiesz. Lecz od |jakiej właściwie |części tego niejasno określonego „minionego doświadczenia” i w jaki sposób można tego dowieść? W wielu badaniach, zmierzających do uzyskania takiego dowodu, studiowano wpływ szeroko pojętych doświadczeń kulturowych, ogólnych nawyków percepcyjnych, różnic w ćwiczeniu, nastawienia wywołanego instrukcją oraz manipulowano czynnikami wpływającymi na psychofizyczne wykrywanie bodźców.


Doświadczenie kulturowe. Przypadek Kenge’a, który spostrzegał odległe bawoły jako owady, stanowi efektowny przykład wpływu naszych doświadczeń kulturowych na to, co spostrzegamy. Jeśli percepcja jest uzależniona od założeń opartych na minionym doświadczeniu z danym środowiskiem, to powinno być wiele różnic między spostrzeżeniami ludzi pochodzących z różnych środowisk kulturowych. Różnice takie powinny ujawnić się w sposobie spostrzegania przez nich złudzeń.


„Materiał dowodowy dotyczący różnic w spostrzeganiu złudzeń pochodzi z międzykulturowych badań, w których wzięło udział 1878 osób z czternastu kultur pozaeuropejskich plus grupa Amerykanów. Badacze wysunęli hipotezę, że powinny istnieć różnice kulturowe pod względem podatności na dwa różne typy złudzeń - „złudzenie poziomo-pionowe” (nos Pinokia) oraz złudzenie Mullera-Lyera (s. 227-228). Rozumowali oni następująco: doświadczenie z rozległymi równinami i otwartymi widokami powinno zwiększać podatność na „złudzenie poziomo-pionowe”, podczas gdy brak takich doświadczeń (jak w wypadku mieszkańców puszcz) powinno zmniejszać ją. Natomiast osoby żyjące w świecie przedmiotów wyciosanych z drewna, gdzie kąty są ważne i wyraźnie widoczne, powinny być bardziej podatne na złudzenie Mullera-Lyera, niż osoby żyjące w takim środowisku, jak środowisko Zulusów, gdzie chaty są okrągłe i regularne kąty są rzadkością. Uzyskane wyniki potwierdziły powyższe przewidywania (Segall, Campbell, Herskovits, 1966).


Różnice w ćwiczeniu. Aby przekonać się, w jaki sposób nawet krótkie ćwiczenie może wpłynąć na twoje spostrzeganie, przeprowadź następujący eksperyment. Przypatruj się uważnie przez minutę kobiecej twarzy na ilustracji zamieszczonej poniżej. W tym samym czasie poproś kolegę, aby przyglądał się uważnie twarzy (ryc. 6.18b), której |ty |nie |powinieneś |widzieć. Następnie znajdźcie stronę (tę z twarzą) i obaj powiedzcie, najszybciej jak umiecie, czyją twarz tam widzicie.
Gdy przed wieloma laty po raz pierwszy przeprowadzono w laboratorium podobny eksperyment, to eksperymentator stwierdził, że przygotowanie percepcyjne, przy zastosowaniu jednego z dwóch pierwszych obrazków, bardzo skutecznie determinowało reakcje na niejednoznaczną figurę, podczas gdy przygotowanie słowne nie miało żadnego wpływu. Stwierdził on także, że gdy badani widzieli tylko obrazek niejednoznaczny, dwukrotnie większa ich liczba podawała, że widzą młodą kobietę. Chociaż minione doświadczenia były przypuszczalnie podobne, to jednak inne cechy - być może cechy samego układu bodźcowego - zniweczyły równowagę pomiędzy alternatywnymi możliwościami (Leeper, 1935).


Wytworzone nastawienie. Jak wskazuje sam termin, |nastawienie jest to gotowość do spostrzegania czy reagowania w pewien sposób. Nastawienie może opierać się na oczekiwaniach wynikających z minionego doświadczenia lub też może być wytworzone przez instrukcję otrzymaną od eksperymentatora (lub innej osoby, której wypowiedzi bierzesz poważnie). Dane nastawienie może być zatem stanem chwilowym, lub też stałym elementem twojego podstawowego sposobu podejścia do różnych sytuacji.
Wpływ nastawień na spostrzeganie badano intensywnie w laboratorium. Jak napisał przed laty Floyd Allport (1955): „Gdy inne czynniki pozostają bez zmiany, wówczas nastawienia zwykle decydują o tym, które przedmioty zostaną spostrzeżone, jak również o szybkości czy łatwości tych spostrzeżeń oraz - w pewnych granicach - o ich treści i żywości” (s. 241).
Różnicowanie percepcyjne można zwiększyć przez zastosowanie instrukcji przygotowujących osoby badane na pewne kategorie przedmiotów czy cech, z których będą one musiały później zdawać sprawę. Ponadto instrukcje takie mogą być skuteczne, jeśli chodzi o „torowanie” kanałów reakcji - powodowanie, że pewna reakcja będzie bardziej prawdopodobna niż inne, zwłaszcza w odniesieniu do niejednoznacznego układu bodźcowego. Chociaż badania wykazały wyraźnie, że nastawienie rzeczywiście wpływa na oceny percepcyjne, to jednak jest mniej jasne, na jakim poziomie zachodzi to zjawisko - czy zmianie ulega rzeczywista wrażliwość percepcyjna czy też uwaga, pamięć lub motywacja do reagowania.


Zainteresowanie, motywy i samoobrona. Wykazano w sposób niewątpliwy, szczególnie w odniesieniu do ludzi, że nie ma ścisłej odpowiedniości między bodźcem a spostrzeżeniem, ponieważ miedzy nimi jest organizm - ze swymi motywami, potrzebami, wartościami, postawami, oczekiwaniami i emocjami, a wszystkie te czynniki mogą w istotny sposób oddziaływać na percepcję.
Eksperyment, który zapoczątkował kontrolowane badania laboratoryjne nad rolą czynników emocjonalnych w percepcji, miał poważną metodologiczną usterkę. Czy potrafisz ją wykryć?


„Grupę 30 dziesięcioletnich dzieci badano za pomocą przyrządu składającego się z drewnianej skrzynki mającej z jednej strony ekran, a w prawym dolnym rogu gałkę. Obracając tę gałkę dzieci mogły zmieniać średnicę świetlnego koła rzutowanego na ekran. Dwie grupy dzieci, jedną składającą się z dzieci zamożnych, a drugą - z ubogich, proszono o dopasowanie wielkości koła świetlnego do wielkości monet o różnych wartościach; grupa kontrolna dopasowywała wielkość koła świetlnego do wielkości krążków z tektury. 
Monety, które są przedmiotami cenionymi społecznie, były oceniane przez dzieci jako większe krążki. Ponadto grupa dzieci ubogich przeceniała wielkość monet bardziej niż grupa dzieci zamożnych” (Bruner i Goodman, 1947).


Eksperyment ten zapoczątkował ożywioną polemikę, ponieważ krytycy szybko wykazali, że nic nie dowodzi, iż czynnikami determinującymi były tu wartości i potrzeby, ponieważ nie kontrolowano innych zmiennych - takich, jak inteligencja i doświadczenie w posługiwaniu się monetami. Jednakże inna grupa badaczy uporała się, jak się zdaje, z tymi zastrzeżeniami, czyniąc ludzi „ubogimi” lub „bogatymi” za pomocą hipnozy.


„Przed zahipnotyzowaniem osoby badane z klasy średniej dopasowywały wielkość krążka świetlnego, dopóki nie wydał się on równy rzeczywistej wielkości każdej z trzech monet: 5-centowej, 10-centowej i 25-centowej. Gdy te same osoby zapomniały pod hipnozą swych prawdziwych historii życiowych i otrzymały „ubogie” historie życia, wówczas systematycznie oceniały monety jako większe, niż czyniły to w stanie normalnym.


Gdy pod hipnozą przydzielono im „bogate” historie życia, wówczas konsekwentnie oceniały monety jako mniejsze niż poprzednio.
Badacze doszli do wniosku, że na spostrzeżenia osób badanych istotnie oddziaływały ich potrzeby i wartości, ponieważ ich uprzednie doświadczenia z monetami były identyczne. O wpływie „ubogich” i „bogatych” historii życia na kształtowanie się różnych potrzeb i wartości świadczy również fakt, że gdy badani byli „ubodzy”, wówczas siedzieli wyprostowani i pracowali starannie, natomiast gdy byli „bogaci”, wówczas rozsiadali się wygodnie w swych krzesłach i pracowali szybko, lecz niedbale” (Ashley, Harper i Runyan, 1951).


O uwydatnianiu w percepcji cenionych właściwości świadczą także wyniki badań nad właścicielami samochodów marki Volkswagen. Ci badani, którzy cenili fakt posiadania Volkswagena, skłonni byli spostrzegać go jako mniejszy niż ci, którzy byli w stosunku do niego obojętni (Stayton i Weiner, 1961).
Stosując pewien rodzaj analizy treści rysunków dziecięcych, wykonanych w różnych okresach roku, badacze wykryli, że rysunki Świętego Mikołaja wykonane przed Bożym Narodzeniem były większe niż rysunki wykonane po świętach. Nie był to skutek ogólnej przedświątecznej euforii, lecz zjawisko „charakterystyczne dla Świętego Mikołaja”, ponieważ jedynie rysunki tego świętego stawały się większe, w miarę jak zbliżało się jego przyjście (Solley, Haigh, 1959; Sechrest i Wallace, 1964). W innych starannie kontrolowanych badaniach uzyskano wynik, który zdaje się świadczyć o unikaniu motywowanym strachem; stwierdzono mianowicie, że przeciętna wielkość rysunków czarownic |zmniejszała się w okresie Wszystkich Świętych (Craddick, 1967).
O aktywnej roli czynników emocjonalnych i motywacyjnych w percepcji świadczy fakt, że bodźce, które stanowią społeczne „tabu” i są zagrażające, często są spostrzegane błędnie, a ich rozpoznanie wymaga dłuższego czasu niż rozpoznanie bodźców obojętnych.


„W pierwszym badaniu, które przyniosło wyniki potwierdzające tę hipotezę, eksperymentatorzy eksponowali studentom college’u siedem słów „krytycznych” (takich, jak „brzuch”, „gwałt”, „suka”), poprzedzielanych jedenastoma innymi, bardziej niewinnymi słowami. Czas trwania ekspozycji regulowano za pomocą tachistoskopu, urządzenia, które rzutuje słowa na ekran przez ułamek sekundy. Rozpoznanie słów krytycznych wymagało dłuższej ekspozycji niż rozpoznanie słów neutralnych. Ponadto stwierdzono, że słowa „tabu” wywołały silniejszą reakcje skórnogalwaniczną (zmiany w elektrycznej oporności skóry) w okresie przed ich odczytaniem, co przyjęto jako dowód istnienia nieświadomego mechanizmu obrony percepcyjnej” (McGinnies, 1949).


To intrygujące wyjaśnienie dokonane w kategoriach obrony percepcyjnej poddano krytyce, ponieważ metodologia tego eksperymentu umożliwia wysunięcie trzech równie prawdopodobnych wyjaśnień. Różnice w progach rozpoznawania mogły wynikać albo z odmiennej wrażliwości na słowa „tabu”, powodowanej, jak utrzymywano, ich antyspołecznym znaczeniem, lub też z faktu, że w normalnych warunkach słowa te znajduje się rzadziej. Zjawisko to mogło też w ogóle nie mieć charakteru percepcyjnego, lecz polegać na zahamowaniu reakcji: być może badani rozpoznawali „brzydkie” słowa równie szybko jak słowa „ładne”, lecz odczuwali pewne zahamowanie przed odczytywaniem ich na głos wobec innych osób.
W kilku późniejszych badaniach uzyskano jednak rezultaty potwierdzające hipotezę obrony percepcyjnej. W jednym z tych badań słowa zagrażające i niezagrażające drukowano w zeszytach, gdzie na pierwszej stronie słowa te były całkowicie zamazane, lecz na każdej kolejnej stronie stawały się coraz wyraźniejsze (silniejszy sygnał w stosunku do szumu). Słowa zagrażające wymagały odwrócenia większej liczby stronic, zanim zostały rozpoznane.  Zjawisko to wystąpiło mimo to, że kontrolowano częstość występowania użytych słów i nie było konieczne odczytywanie ich publicznie. Ten sam wynik uzyskano wtedy, gdy badanych ostrzegano o zbliżaniu się zagrażających słów i gdy płeć osoby badanej i eksperymentatora była taka sama (Cowen i Beier, 1954).


„W innym eksperymencie częstość występowania użytych słów była również kontrolowana, lecz tym razem słowa te prezentowano parami. Mianowicie, najpierw eksponowano przez dwie sekundy słowo „przedzadaniowe” („pretaskword”), które czasami było słowem „tabu”, a czasami obojętnym; następnie przez 1/100 sekundy eksponowano słowo „zadaniowe” („task word”), które zawsze było słowem neutralnym. Jeśli słowo zadaniowe nie zostało rozpoznane, wówczas znowu eksponowano przez dwie sekundy słowo przedzadaniowe, po czym następowało słowo zadaniowe eksponowane przez 2/100 sekundy. Postępowano w ten sposób dopóty, dopóki słowo zadaniowe nie zostało w końcu rozpoznane. Gdy słowo przedzadaniowe było słowem „tabu”, wówczas próg dla rozpoznania związanego z nim neutralnego słowa zadaniowego był na ogół wyższy niż wtedy, gdy słowo przedzadaniowe było neutralne” (McGinnies i Sherman, 1952).


Nawet gdy warunki wizualne są dobre i wzorce bodźcowe są wyraźne, nasze spostrzeżenia mogą być zniekształcane przez nasze pragnienia, obawy, nawyki, uprzedzenia i inne czynniki wewnętrzne. Gdy warunki wizualne są złe, a bodziec jest niejednoznaczny, wówczas czas spostrzegania jest podznacznie silniejszym wpływem procesów wewnętrznych. Psychologowie kliniczni wykorzystują tę tendencję wówczas, gdy polecają pacjentom reagować na niejednoznaczne obrazki czy nawet pozbawione znaczenia plamy atramentowe. Reakcje pacjentów w tych warunkach mogą dostarczyć wartościowych wskazówek dotyczących motywów i problemów pacjenta.




Spostrzeganie
pozazmysłowe




Podczas lotu kosmicznego statku Apollo 14, kapitan Edgar Mitchell porozumiewał się z ośrodkiem kontroli lotu przez radio, lecz twierdzi on również, że poza tym potajemnie porozumiewał się z innymi ludźmi na ziemi za pomocą ESP - |spostrzegania |pozazmysłowego („extrasensory „perception).  Ze swego statku kosmicznego wysłał on serię fal myślowych do czterech odbiorców na ziemi. Podaje on, że w ogólnej liczbie 200 dokonanych przez nich odgadnięć tego, co nadał, 51 odgadnięć było zgodnych z jego notatkami dotyczącymi treści, jakie starał się przekazać.
Czy wierzysz w istnienie ESP? Czy sądzisz, że ludzie mogą porozumiewać się bez pomocy żadnego ze znanych zmysłów, czy też podlegających pomiarom kanałów komunikacji? Ostatnie badania wskazują, że większość ludzi istotnie w to wierzy, natomiast poglądy psychologów i naukowców w odniesieniu do tego zagadnienia są ostro podzielone. Niektórzy sądzą, „że dostępne materiały dowodowe przemawiające za istnieniem ESP są wystarczające, aby stwierdzić jego rzeczywistość, jego realność w sposób nie pozostawiający żadnych rozsądnych wątpliwości” (R. A. McConnell, 1971), inni utrzymują, że „ogromna liczba badań eksperymentalnych nie dostarczyła wyraźnych dowodów przemawiających za istnieniem ESP” (Hansel, 1966).
W jaki sposób mogą istnieć tak skrajne różnice w opiniach naukowców w odniesieniu do ESP? Nie wynika to stąd, że niedowiarki nie biorą tej sprawy poważnie. Wprost przeciwnie; zdają oni sobie sprawę z tego, że przekazywanie informacji bez użycia znanych kanałów komunikacyjnych pociągnęłoby za sobą rewolucyjne zmiany w myśleniu o komunikacji, przyczynowości oraz zdolnościach ludzkiego umysłu.
Pewien fizyk stwierdził:


„Jeśli ESP jest istotnie faktem, to jest najbardziej doniosły fakt we współczesnej fizyce, ponieważ wyjaśnienie go wymaga przyjęcia nowego rodzaju siły - siły obecnie nieznanej fizykom. Jedyną alternatywą jest całkowite odrzucenie przyczynowości, co spowodowałoby jeszcze większą rewolucję w nauce” (Rothman, 1970, s. 280).


Lecz te właśnie rewolucyjne implikacje pobudzają wyobraźnię zwolenników ESP. Naszkicujemy więc pewne charakterystyczne cechy ESP i podobnych zjawisk, przedstawimy pewne typowe eksperymenty mające udowodnić ich istnienie oraz powiemy, na jakiej zasadzie krytykuje się te eksperymenty.




Dziedzina
parapsychologii




|Parapsychologia jest to współczesny termin, który obejmuje zorganizowane naukowe badania zjawisk pozazmysłowych. Termin ten obejmuje różne zupełnie odrębne typy zjawisk.
|E|S|P odnosi się aktów spostrzegania czy poznania, które są niezależne od (znanej) fizjologicznej aktywności w narządach zmysłowych. Istnieją trzy rodzaje ESP:
1. |Telepatia („czytanie w myślach”) polega na poznawaniu przez daną osobę utajonego zdarzenia („private event”) zachodzącego w danej chwili w myślach kogoś innego, bez żadnych obserwowalnych środków porozumiewania się między nimi.
2. |Jasnowidzenie jest to wiedza o właściwościach danego obiektu, osoby lub zdarzenia uzyskana bez pomocy zmysłów.
3. |Przepowiadanie |przyszłości („wróżenie” lub „przeczucie”) jest to znajomość przyszłości: albo przyszłych myśli innej osoby (|przepowiadanie |telepatyczne), albo też charakteru przyszłych zdarzeń (|przepowiadanie |jasnowidzące).
Czwarta kategoria zjawisk o podobnym charakterze wymaga czegoś więcej, niż po prostu nabywania informacji. Jest to |psychokineza (|P|K, czasami określana jako „lewitacja”). PK jest to sterowanie przedmiotami i zdarzeniami (takimi, jak rzut kostką lub odkrycie karty) za pomocą aktu myśli czy woli.
Uznanym autorytetem w tej dyscyplinie jest J. B. Rhine z Duke University, obecnie prezes Foundation for Research on the Nature of Man (Fundacji do Badań nad Naturą Człowieka). Rhine był botanikiem, który zajął się badaniem zjawisk pozazmysłowych przed wieloma laty, po wysłuchaniu odczytu o spirytyzmie wygłoszonego przez Sir Arthura Conan Doyle’a (twórcę Sherlocka Holmesa). Rhine najpierw podjął studia nad ESP w Harvardzie, gdzie w latach dwudziestych pod wpływem Williama McDougalla oraz Gardnera Murphy’ego kwitły badania nad zjawiskami pozazmysłowymi. W ciągu ostatnich dwudziestu lat, głównie dzięki jego edytorskim staraniom, czasopismo „Journal of Parapsychology” opublikowało ponad 4 tysiące stron o badaniach w tej dziedzinie. Wiele dziedzin psychologii jest powszechnie akceptowanych, mimo posiadania znacznie skromniejszych podstaw badawczych, dlaczego więc dostępny materiał dowodowy nie jest przekonujący dla sceptyków?




* * *



Ryc. 6.20. Dwa zawodowe media i dwóch niewyszkolonych obserwatorów stara się wywołać zjawisko PK - lewitację małego stolika. Chociaż stolik nigdy nie oderwał się całkowicie od podłogi, obserwator podaje, że kołysał się on gwałtownie i „wędrował” przez pokój (Gatland, 1973).


* * *







Typowe schematy
badawcze




W typowym eksperymencie dotyczącym telepatii |nadawca („agent”) patrzy na jeden z pieciu symboli znajdujących się na specjalnych kartach ESP, a |odbiorca („percipient) „zgaduje”, na który z symboli patrzy on w każdej z dwunastu prób. Gdyby odgadywanie to było całkowicie przypadkowe, to poprawne odgadnięcie, czyli „trafienie”, zdarzałoby się w jednej piątej prób. Tak więc w ogólnej liczbie 200 prób odbiorca na zasadzie przypadku powinien mieć 40 trafień. ESP wykazuje się przeprowadzając statystyczne testy istotności odchyleń od tego przypadkowego wyniku.
W eksperymencie nad jasnowidzeniem nie ma nadawcy; odbiorca odgaduje symbol na każdej karcie w wielokrotnie tasowanych zestawach składających się z pięciu kart. W eksperymentach nad przepowiadaniem przyszłości („precognition”) odbiorca odgaduje symbole na kartach, zanim zostaną one potasowane i wyłożone. W typowym badaniu PK osoba badana stara się wpłynąć na to, po której stronie linii upadnie wyrzucana mechanicznie kostka.
Rezultaty wielu z tych eksperymentach wykazują, że niektóre osoby badane uzyskują wyniki istotnie wyższe od oczekiwań losowych. Ponadto w większości tych badań stosuje się starannie opracowane procedury kontrolne. Dlaczego więc ciągle nie uważa się istnienia ESP za „dowiedzione”?
Aby odpowiedzieć na to pytanie, musimy przypomnieć sobie pewne podstawowe zasady metody naukowej, przedstawione w zarysie w pierwszym rozdziale niniejszej książki. Badania nigdy nie |udowadniają niczego. Jeśli są właściwie przeprowadzone, pozwalają nam odrzucić inne wyjaśnienia danego zjawiska, zwiększając jednocześnie ufność w prawdopodobieństwo określonego wyjaśnienia. Po drugie, samo zastosowanie w eksperymencie grup kontrolnych i procedur kontrolnych nie gwarantuje, że najważniejsze, powodujące zakłócenia zjawisko jest w istocie kontrolowane. I wreszcie, prawdziwego naukowca fascynują nieznane nie wyjaśnione zjawiska w życiu, lecz jego ciekawość mityguje sceptyzm: „Jestem przekonany, że wszystko jest możliwe, lecz nic nie jest pewne, o ile nie zmierzyłem tego w takich warunkach, które mogliby odtworzyć inni, jeszcze bardziej sceptyczni niż ja”.




Kryteria akceptacji
materiału dowodowego




Jeśli istnieje rzeczywiście spostrzeżenie pozazmysłowe (ESP), to należałoby poważnie zrewidować zasadnicze poglądy w psychologii, fizyce i biologii. Jednakże ani zaakceptowanie, ani odrzucenie ESP nie może być kwestią wiary, poglądów filozoficznych czy osobistej opinii - musi opierać się po prostu na rzetelności |metody zastosowanej dla oceny jego przejawów.  Zasada ta dotyczy wszelkich zjawisk, lecz spostrzeganie jej staje się jeszcze bardziej nieodzowne, gdy konsewkencje zaakceptowania jakiegoś poglądu są poważniejsze.
Poniższe uwagi metodologiczne wskazują, w jakich warunkach naukowiec nie przekonany o istnieniu ESP byłby zmuszony zaakceptować materiał dowodowy przemawiający za nim, a także pozwalają określić niektóre problemy, jakie nastręczają badania przeprowadzone dotychczas.


1. Jeśli uzyskane wyniki można racjonalnie przypisać |czemuś innemu niż ESP, wówczas dane te nie stanowią wystarczającego dowodu. Badacz spostrzegania pozazmysłowego musi nie tylko eliminować zwykle źródła błędu, takie jak minimalne sygnały sensoryczne, nawyki umysłowe, preferencje w sposobie reagowania nadawcy i odbiorcy oraz błędy w rejestrowaniu, lecz musi także wyeliminować |możliwość świadomego oszukiwania przez osobę badaną czy też oszustwa lub sztuczek ze strony eksperymentatora. Plan badania musi |uniemożliwiać przypisanie wyników działaniu takich zniekształcajacych czynników.
Na przykład, przeprowadzono pewien klasyczny, eksperyment nad ESP (eksperyment Pratta-Woodruffa), o którym Rhine wyraził się w sposób raczej mało skromny: „W całej historii psychologii nie przeprowadzono jeszcze nigdy eksperymentu z tak starannie opracowanymi środkami kontroli przeciw wszelkim możliwym błędom” (1954, s. 55). Jednakże pewien krytyk (Hansel, 1966) potrafił wykryć kilka możliwych źródeł błędu i oszustwa, będących wynikiem przyjęcia takiego właśnie planu eksperymentu.
2. Badani uzyskujący wysokie wyniki muszą uzyskiwać podobne rezultaty także wtedy, gdy są badani w innych laboratoriach przez niezależnych eksperymentatorów.
3. Ten sam paradygmat badawczy musi umożliwiać uzyskanie podobnych rezultatów, gdy zostanie zastosowany do tych samych osób badanych w innym czasie lub przez innych badaczy.
4. Powinno być możliwe opracowanie procedur badawczych, które zapewniłyby coś więcej, niż wnioskowanie o istnieniu ESP na podstawie praw prawdopodobieństwa (Gardner, 1957). Jeśli ESP istnieje, to musi być zmienną funkcją, występującą u różnych osób w różnym stopniu, którą można by ocenić i jednocześnie określić jej związek z innymi zmiennymi, od których jest zależna.
Na przykład, obecność psychokinezy (PK) można by sprowadzać za pomocą |radiometru, to znaczy miernika promieniowania. Wygląda on jak miniaturowy wiatromierz - składa się z czterech ramion, delikatnie zrównoważonych w bańce szklanej, przy czym jedna strona każdego ramienia jest czarna, a druga odblaskowa. Ramiona te obracają się wtedy, gdy pochłaniają i odbijają ciepło. Przyrządowi temu można nadać taka czułość, że potrafi wykryć ciepło wytwarzane przez promień świecy znajdującej się w odległości pół mili.  Można go także skonstruować w ten sposób, aby mierzył wielkość przyłożonej doń siły czy energii, a zatem powinien ujawnić rzekomą zdolność psychokinezy.
Podczas gdy sceptyczni naukowcy oczekują na bardziej przekonywujący materiał dowodowy świadczący o istnieniu ESP, wielu studentów wyższych uczelni, jak również „szarych ludzi”, wierzy już nie tylko w tradycyjne spostrzeganie pozazmysłowe, lecz także w „energię astralną”, pochodzącą z kosmosu i inne najnowsze zjawiska parapsychologiczne. Łatwo jest zrozumieć, dlaczego ludzie |chcą wierzyć w parapsychologię. Po pierwsze, zjawiska te rozszerzają zakres możliwości każdej jednostki: telepatia i jasnowidzenie oznaczałyby lepsze poznanie rzeczywistości; przepowiadanie przyszłości umożliwiłoby lepsze przewidywanie; psychokineza byłaby formą panowania nad otoczeniem. Poza tym ludzie często pragną być czymś więcej niż tym, czym zdają się być - tym, co można zmierzyć za pomocą przyrządów, wydestylować w probówkach i „wyjaśnić za pomocą waszej filozofii”. Z drugiej strony, bardziej konserwatywni naukowcy obawiają się, ze jeśli raz otworzy się drzwi sankcjonując niewidzialne, niemierzalne siły ESP, to wówczas nie byłoby żadnych granic dla zjawisk nadprzyrodzonych; dla wyjaśnienia zjawisk przyrodniczych i zachowania ludzkiego można by się powoływać na „siły tajemne”, a nawet czary. Jako przykład uzasadniający takie obawy możemy przytoczyć przypadek pewnego lekarza z Michigan, którego nową specjalnością są „wampiry psychiczne” - ludzie, którzy „wysysają” pola energii psychicznej innych jednostek. Zacytowano jego stwierdzenie: „Widziałem pacjentów, którzy umierali po 30 minutach od chwili odwiedzenia ich przez wampirów w szpitalu” („San Francisco Chronicle”, 15 grudnia 1973 r.).
ESP jest ciekawym zjawiskiem, zasługującym na więcej ścisłych badań prowadzonych przez sceptycznych badaczy. Mało jest jednak prawdopodobne, aby tacy badacze zostali szybko przekonani.




Streszczenie rozdziału




To właśnie za pośrednictwem naszych procesów percepcyjnych nadajemy stałość i ciągłość przedmiotom i wydarzeniom w naszym środowisku.  Spostrzeganie (percepcja) obejmuje analizowanie, organizowanie i integrację sygnałów wejściowych z otoczenia, dostarczanych zarówno przez zdarzenia środowiskowe, jak i stany wewnętrzne. Teoretycy różnią się w swych poglądach na to, czy najważniejszym aspektem spostrzegania jest taka rzeczywistość, jaka istnieje w świecie zewnętrznym, czy też taka, jaka istnieje w naszych umysłach. Niektórzy twierdzą, że najważniejsza jest nasza interpretacja tego, co spostrzegamy.
|Absolutyzm |fenomenologiczny głosi, że spostrzeżenia są bezpośrednim i dokładnym odtworzeniem cech, które występują w środowisku. Jednakże nie zawsze łatwo określić, kiedy |rzeczywistość |fenomologiczna (nasze doświadczenie percepcyjne) jest |prawdziwą reprezentacją rzeczywistości obiektywnej (tego, co naprawdę istnieje). |Złudzenia są efektownym przykładem tego, w jakim stopniu percepcja może wprowadzić nas w błąd; wywołują one jednak nasze zdziwienie, ponieważ na ogół nasz system percepcyjny funkcjonuje niezawodnie, pozwalając nam mieć do czynienia ze stałym, przewidywalnym środowiskiem pomimo ciągle zmieniających się obrazów na siatkówce. Jest to możliwe właśnie dlatego, że spostrzeganie jest raczej |pośrednim procesem wyciągania wniosków o wejściu bodźcowym; nie chodzi tu o ścisłą odpowiedniość pomiędzy bodźcem a spostrzeżeniem. W zwykłych okolicznościach możemy polegać zarówno na dokładności, jak i na stałości spostrzegania. Na przykład, jeżeli dysponujemy sygnałami dotyczącymi odległości, to spostrzegana wielkość przedmiotu jest zgodna raczej ze stymulacją |dystalną (odległą), czyli rzeczywistą jego wielkością, niż ze stymulacją |proksymalną (bliską), czyli wielkością obrazu na siatkówce.
Energia bodźcowa ze środowiska jest wykrywana przez narządy złożone z |komórek |receptorowych, które mogą rozróżniać rodzaj, położenie i intensywność bodźców. Proces, który przekształca energię bodźcową w impuls nerwowy i wykrywa intensywność bodźca, nosi nazwę |transdukcji. Jako |próg |absolutny przyjmuje się powszechnie siłę takiego bodźca, który z trudem można wykryć w połowie przypadków. |Psychofizyczne |metody |skalowania określają relację pomiędzy danymi intensywnościami bodźca a odpowiadającymi im wrażeniami. |Ledwo |dostrzegalna |różnica (|Idr) jest to przyrost bodźca potrzebny do wywołania w 75% badanych przypadków ledwie dostrzegalnej różnicy we wrażeniu. Według |prawa |Webera-|Fechnera, w większej części zakresu intensywności istnieje stały stosunek pomiędzy bodźcem standardowym a bodźcem wywołującym wrażenie różniące się o ledwo dostrzegalną różnicę.  Stevens wykazał, że równe stosunki bodźców dają w wyniku równe stosunki wrażeń subiektywnych.
Odrębne receptory mamy dla wielu różnych zmysłów, takich, jak wzrok, słuch, nacisk (dotyk), ból, zimno, ciepło, równowaga, położenie, smak i węch. U ludzi najważniejszymi i najbardziej dokładnymi zmysłami są wzrok i słuch.
Oko wyposażone jest w dwa odrębne systemy receptorów: |pręciki, wrażliwe na bardzo nawet słabe światło, lecz nie reagujące na barwę oraz |czopki, funkcjonujące przy świetle dziennym i umożliwiające widzenie barw. Czopki występują najliczniej w |plamce |żółtej, która stanowi obszar najostrzejszego widzenia; w plamce żółtej pręciki nie występują. Światło przechodzi przez kilka warstw włókien nerwowych, zanim dojdzie do komórek receptorowych, które przetwarzają je w informacje przekazywane przez |komórki |dwubiegunowe i |komórki |zwojowe do |nerwu |wzrokowego, a następnie do obszaru wzrokowego w mózgu - |kory |potylicznej. W tym miejscu, gdzie nerw wzrokowy wychodzi z siatkówki, znajduje się |plamka |ślepa.
Trzy rodzaje |fotopigmentów w czopkach absorbują odpowiednio światło niebieskie, zielone i czerwone. Cztery rodzaje |komórek |przetwarzania |przeciwstawnego w |ciele |kolankowatym |bocznym integrują dochodzące doń informacje i przekazują je do |kory |wzrokowej; proces ten daje w wyniku widzenia barw. Spostrzeganie kształtów, struktur i ruchu zależy od wyspecjalizowanych komórek zwanych |analizatorami |cech, które są aktywizowane jedynie przez pewne |cechy |wyzwalające - bodźce o pewnym ukierunkowaniu lub położeniu w przestrzeni.



Komórki znajdujące się na wyższych poziomach w reagowaniu na bardziej złożene cechy wyzwalające.
Głównym zadaniem systemu wzrokowego oraz innych systemów percepcyjnych jest wyszukiwanie |niezmiennych |właściwości w polu bodźcowym. Ze względu na zasadę ekonomii systemy percepcyjne muszą posiadać sposoby redukowania |redundacji. Również ten cel jest realizowany dzięki hierarchicznemu przetwarzaniu informacji.
Gdy odbieramy bodźce dźwiękowe, wówczas następujące po sobie różnice ciśnienia (|fale |dźwiękowe) wnikają do |ucha |zewnętrznego, są przekazywane przez |ucho |środkowe do |ślimaka w |uchu |wewnętrznym, a tam zostaje przetworzone w impulsy nerwowe. Wydaje się, że dla wyjaśnienia procesu kodowania dźwięków niezbędna jest zarówno |teoria |salw, jak i |teoria |miejsca.
Anatomiczne struktury większości narządów zmysłowych są dobrze rozwinięte już przed urodzeniem, lecz trudno jest określić, w jakim stopniu są one w rzeczywistości zdolne do funkcjonowania. Wydaje się, że pewna wrażliwość na dotyk i na zmiany temperatury występuje już przed urodzeniem, natomiast wrażliwość na ból jest słaba. Po urodzeniu stymulacja środowiskowa wydaje się niezbędna dla normalnego rozwoju zmysły dotyku i zmysłu bólu. Zarówno smak, jak i węch są dobrze rozwinięte w momencie urodzenia.
Wydaje się, że słuch u noworodka jest gorzej rozwinięty niż inne zmysły, lecz istnieją pewne dane, że może on funkcjonować przed urodzeniem. Pewna zdolność do spostrzegania kształtów, a być może i barw, występuje od chwili urodzenia, lecz niezbędny jest dalszy rozwój struktur wzrokowych.  Istniejący materiał dowodowy sugeruje, że pewne czynniki w percepcji wzrokowej mają charakter wrodzony, podczas gdy inne są wyuczone. Możliwość ćwiczenia koordynacji funkcji percepcyjnych i ruchowych jest niezbędna dla właściwego rozwoju sensoryczno-motorycznego.
Teorie percepcji obejmują: a) teorie głoszące, że uczymy się złożonych spostrzeżeń przez |kojarzenie spostrzeżeń prostych i że potrzebna jest wyćwiczona introspekcja, aby wyeliminować „dodatki” wynikające z uczenia się i zidentyfikować „pierwotne” doświadczenia zmysłowe; b) teorię postaci, według której nawet przed uczeniem się percepcja dostarcza nam |struktur i relacji; c) teorię utrzymują, że percepcja opiera się na naszych założeniach co do rzeczywistości i naszych |transakcjach ze środowiskiem; i wreszcie d) teorię, zgodnie z którą uczenie się spostrzegania nie jest w istocie procesem dodawania czegoś, lecz procesem |redukcji, w trakcie którego dokonujemy nowych zróżnicowań i identyfikujemy trwałe struktury.
Uczenie się odgrywa ważną rolę w percepcji. W trakcie rozwoju poznawczego przestajemy być empirykami, którzy biorą wszystko co widzą za dobrą monetę, uczymy się natomiast operować symbolami i abstrakcjami oraz wyobrażać sobie wyniki. Na przykład, ucząc się czytać, wytwarzamy nawyki percepcyjne analizowania tekstu od lewej strony do prawej. O doniosłym znaczeniu, jakie dla spostrzegania ma doświadczenie, świadczą badania nad niewidomymi, którzy odzyskali wzrok w wieku dojrzałym. Osoby takie w najlepszym razie przyswajają sobie z wielkim trudem wiele umiejętności percepcyjnych (takich, jak rozpoznawanie przedmiotów), które my przyjmujemy za coś oczywistego. Jest zaskakujące, że nie sprawia dużych trudności przystosowanie się do sztucznie zniekształconego pola percepcyjnego, jeśli sensoryczno-motoryczne sprzężenie zwrotne nie uległo ograniczeniu.
Czynniki decydujące o tym, jaką figurę widzimy, to |bliskość, „podobieństwo, |zamknięcie, „|wspólny |los” oraz |kontekst. Mamy skłonność do spostrzegania tak zwanych dobrych figur, to znaczy prostych i regularnych; ta figura jest „lepsza, którą łatwiej odgadnąć na podstawie znajomości którejś z jej części.
Przy spostrzeganiu głębi posługujemy się następującymi sygnałami: 
|perspektywą |powietrzną, |perspektywą |liniową, |fakturą, |światłem i |cieniem, |względnym |położeniem, |znanymi |standardami, |konwergencją (zbieżnością) |oczu oraz |różnicą |siatkówkową. Różnice w |czasie |odbioru, |intensywności i |fazie fal dźwiękowych pozwalają nam zlokalizować kierunek dźwięków, jeśli nie przychodzą one z jakiegoś punktu zarówno oddalonego od obu uszu; nie potrafimy zlokalizować dźwięków, których źródło znajduje się na wprost przed nami, powyżej nas lub za nami.
Na spostrzeganie oddziaływują zarówno |doświadczenia |kulturowe, jak i |doświadczenia |osobiste. |Nastawienie, |zainteresowania, |motywy i |oczekiwania również wpływają na percepcję, często w sposób drastyczny.  Wewnętrzne, specyficzne dla danego organizmu czynniki mają większy wpływ na percepcje wtedy, gdy bodźce stają się bardziej jednoznaczne i mogą być rozmaicie interpretowane.
|Parapsychologia to naukowe badanie zjawisk pozazmysłowych, takich jak |spostrzeganie |pozazmysłowe (|ESP). ESP obejmuje |telepatie, |jasnowidzenie, |przepowiadanie |przyszłości oraz |psychokinezę. Właśnie dlatego, że zaakceptowanie ESP miałoby dramatyczny wpływ na nasz sposób rozumienia świata, rygorystyczne kontrolowanie badań w tej dziedzinie jest koniecznością.




Z Frontu Badań.
Psychologia naocznego
świadka




|Robert |Buckhout „Brooklyn College, C. U. N. Y”.


Jeśli widziałeś wypadek samochodowy lub byłeś świadkiem morderstwa, a następnie poproszono cię, abyś opisał to, co widziałeś, to nie znajdziesz nikogo, kto mógłby odtworzyć w zwolnionym tempie zapis wypadków. Jesteś zależny od twojej pamięci, ze wszystkimi jej ograniczeniami - fakt ten może nie mieć dużego znaczenia w zwykłych, codziennych czynnościach. Jeśli wtedy nie możesz polegać na swej pamięci, jeśli wtedy mijasz się z prawdą opisując to, co widziałeś, to fakt ten może nie mieć istotnych następstw.  Gdy jednak zastajesz wezwany jako świadek przestępstwa, wówczas sytuacja staje się o wiele poważniejsza: w grę może wchodzić życie człowieka lub reputacja instytucji. Prawdopodobnie poproszą cię o opisanie w najdrobniejszych szczegółach tego, co widziałeś, jak gdybyś był urządzeniem rejestrującym obraz na taśmie magnetycznej.
W sądzie odtworzony przez ciebie przebieg zdarzeń zostaje zapisany w protokole. Oskarżyciel będzie starał się wykazać, iż masz doskonałą pamięć, natomiast obrońca, biorąc cię w krzyżowy ogień pytań, będzie usiłował dowieść, że twoje „urządzenie rejestrujące” jest w złym stanie. Gra idzie o wysoką stawkę, ponieważ we współczesnych sądach zeznania naocznych świadków są cenione wyżej niż świadectwa dotyczące alibi czy też materiały „poszlakowe”. Bezkrytyczna akceptacja zeznań naocznych świadków zdaje się być oparta na fałszywym poglądzie, że człowiek-obserwator jest doskonałym urządzeniem rejestrującym, że wszystko, co się dzieje przed jego oczyma, zostaje zarejestrowane i może być „wyciągnięte” przez zadawanie dociekliwych pytań czy „odświeżanie” czyjejś pamięci. Stwierdzam kategorycznie - co psychologowie czynią rzadko - że jest to |niemożliwe: percepcja i pamięć człowieka funkcjonują efektywnie dzięki temu, że są selektywne. Człowiekowi nie jest specjalnie potrzebna absolutna pamięć; percepcja i pamięć są procesami decyzyjnymi, na które wpływa ogół zdolności danej osoby, jej przeszłość, środowisko, postawy, motywy i przekonania, a także metody stosowane przy badaniu zapamiętywania ludzi i zdarzeń.
Ponieważ pracuję w sądach kryminalnych, przeto zdaję sobie sprawę z zasadniczych rozbieżności między dwoma koncepcjami - dziewiętnastowiecznym poglądem na człowieka i poglądem, jaki ukształtował się w dwudziestym wieku. Koncepcja dziewiętnastowieczna - która znalazła swój wyraz w psychofizyce - przyjmowała założenie o istnieniu ścisłej paraleli między mechanizmami świata fizycznego a mechanizmami mózgu. Sądy w Stanach Zjednoczonych są skłonne przyjmować ten dziewiętnastowieczny sposób myślenia - podobnie jak większość społeczeństwa. Natomiast psychologowie współcześni stworzyli całościową koncepcję istoty ludzkiej wyposażonej w mechanizm przetwarzania informacji, który jest o wiele bardziej złożony niż mechanizm zakładany w modelu dziewiętnastowiecznym. Niestety, psychologowie-badacze, którzy początkowo zajmowali się problemami praktycznymi (funkcjonalizm), stopniowo stawali się w swych badaniach coraz bardziej ezoteryczni i tracili kontakt z rzeczywistym światem.
Uważam człowieka za aktywnego, a nie biernego obserwatora otoczenia; jest on motywowany przez: a) pragnienie, aby precyzyjnie wydobywać sens z nadmiaru informacji oddziałujących na jego zmysły oraz b) pragnienie, aby dostosować się do oczekiwań innych ludzi i cieszyć się nadal ich względami (czynnik, który sprawia, że oko, ucho i inne zmysły są narządami o charakterze nie tylko fizjologicznym, lecz i społecznym).
W naszych eksperymentach laboratoryjnych, dotyczących fizycznych zdolności oka i ucha, mówimy o „idealnym obserwatorze”, przez którego rozumiemy osobę badaną, która sprawnie i bezstronnie reagowałaby na bodźce świetlne i dźwięki, podobnie jak maszyna. Jednakże taki idealny obserwator w rzeczywistości nie istnieje. Innymi słowy „idealny obserwator” jest dogodną fikcją. Podczas projektowania laboratoriów wkłada się wiele wysiłków i kosztów, aby uzyskać „idealne środowisko fizyczne”, wolne od bodźców zakłócających, które pozwoliłoby obserwatorowi skupić się. Warunki takiego idealnego środowiska można próbować stworzyć jedynie w laboratorium; w świecie rzeczywistym spotyka się je rzadko lub nigdy.  Niepodobny do maszyny człowiek-obserwator radzi sobie dość skutecznie w naturalnych środowiskach, będąc wyposażony w zdolności percepcyjne, które są dostosowane do jego natury społecznej. W przypadku świadka przestępstwa zachodzi coś, co można określić jako „percepcję typu zdjęcia migawkowego”.
W przypadku maszyny oczekiwalibyśmy, że to, co otrzymujemy na wyjściu (sprawozdanie), będzie bezpośrednią funkcją tego, co wchodzi („wejścia”, czyli bodźców). Jednakże proces spostrzegania u człowieka można scharakteryzować za pomocą stwierdzenia: „Całość to coś więcej niż suma jej części”. Charakterystyka ta odzwierciedla zdolność człowieka-obserwatora do pobierania fragmentów informacji, na które zdąży on zwrócić uwagę (to znaczy aktywnie zredukować informacje), oraz dochodzenia do wniosków na podstawie swego uprzedniego doświadczenia, wiedzy, nastawień i uprzedzeń, oczekiwań, wiary, pragnienia, aby wydać się pewnymi siebie itd. Na przykład, większość ludzi patrząc na Księżyc widzi kulę - pomimo niemożności sprawdzenia kształtu niewidocznej strony. Wniosek ten z psychologicznego punktu widzenia jest efektywną decyzją podjętą niezależnie od fizycznego materiału dowodowego, który jest niekompletny.
Jako świadek przestępstwa, domyślny człowiek-obserwator znajduje się zwykle w środowisku nie sprzyjającym obserwacjom. Podlega on działaniu czynników, które moim zdaniem w sposób nieunikniony ograniczają zdolność człowieka do podania konkretnego opisu zdarzeń lub do zupełnie dokładnego zidentyfikowania osób biorących w nich udział.
Celem moich badań było poznanie i opisanie (w postaci użytecznej dla systemu sądownictwa kryminalnego) tych czynników, które wpływają zarówno na |przypominanie sobie zdarzeń przez świadka, jak i na jego późniejszą zdolność |rozpoznania winnego. Występowałem w sądzie w około trzydziestu procesach kryminalnych, omawiając następujące czynniki, które wpływają na sprawozdania naocznych świadków:
1. Stres. „Nigdy nie zapomnę jego wyglądu”. To często spotykane stwierdzenie wyraża zaufanie, jakie ludzie mają do swej pamięci - - nawet gdy znajdują się pod wpływem stresu. Gdy życie lub dobro danej osoby są zagrożone, to można oczekiwać, że w jakimś stopniu wystąpi u niej reakcja na stres znana jako ogólny zespół adaptacyjny (GAS - |General Adaptation Syndrome”). Wystąpienie tego zespołu reakcji jest spowodowane wzrostem poziomu adrenaliny we krwi i obejmuje zwiększenie tempa pracy serca, tempa oddychania oraz podniesienie się ciśnienia krwi. Prowadzi to do ogromnego wzrostu będącej do dyspozycji energii, dzięki czemu dana osoba może szybko biec, walczyć, podnieść wielki ciężar - to jest podejmować działania niezbędne dla zapewnienia sobie bezpieczeństwa lub dla utrzymania się przy życiu.
Gdy jednak jesteś pod wpływem silnego stresu, to będziesz wówczas mniej wiarygodnym świadkiem, niż byłbyś normalnie. Badania wykazują, że gdy obserwatorzy znajdują się pod wpływem stresu, to gorzej zapamiętują szczegóły, mniej dokładnie odczytują wskazania przyrządu, popełniają więcej błędów przy wykrywaniu sygnałów. Zwracają oni więcej uwagi na swoje własne dobro i bezpieczeństwo niż na „nieistotne” elementy w otoczeniu. Moje badania, które objęły wyszkolonych członków załóg latających lotnictwa wojskowego, potwierdzają, ze nawet dobrze wyszkoleni ludzie stają się gorszymi obserwatorami, gdy znajdują się pod wpływem stresu. Nie potrafią oni nigdy zapomnieć stresu ani tego, co ich dotknęło, mogą więc zapamiętać zdarzenia, które są bardzo ważne w danym czasie. Natomiast nie zapamiętują tak dobrze szczegółów, ubrań, barw itd. Znajdując się pod działaniem stresu przecenia się zwłaszcza długość czasu, jaki upłynął.
Mógłbyś sprawdzić słuszność tego twierdzenia, pytając paru ludzi, gdzie byli w 1963 roku, gdy po raz pierwszy usłyszeli wiadomość o zabójstwie prezydenta Johna F. Kennedy’ego. Są duże szanse, że dokładnie przypomną sobie, gdzie się znajdowali i kto z nimi był. Czy jednak potrafisz opisać, jak byli ubrani oni sami lub towarzyszące im osoby? Czy ci, którzy oglądali w telewizji zamordowanie Oswalda, potrafią opisać ludzi znajdujących się obok mordercy? Są to logiczne pytania - pozornie banalne, lecz gdyby zadano ci je w sądzie, czy nie zgodziłbyś się, że świadkowie mogą być zbyt zajęci ważniejszymi rzeczami, aby zwracać uwagę na takie szczegóły?
2. Uprzednie warunkowanie i doświadczenie. Psychologowie przeprowadzili wiele badań nad tym, w jaki sposób nastawienie czy oczekiwanie jest wykorzystywane przez ludzi-obserwatorów dla bardziej efektywnego dokonywania ocen. W klasycznym eksperymencie, przeprowadzonym w latach dwudziestych bieżącego stulecia, obserwatorom pokazywano przez parę sekund zbiór kart do gry i proszono ich, aby podali liczbę asów pikowych w tym zbiorze (Bruner i Postman, 1949). Większość obserwatorów powiedziała, że są tylko trzy, podczas gdy w rzeczywistości asów tych było pięć. Dwa asy pikowe były jednak czerwone, a nie jak zwykle czarne. Zgodnie z podaną interpretacją, ludzie nie tracili czasu na dokładne przyglądanie się zestawowi kart, ponieważ byli przyzwyczajeni, że asy pikowe są czarne. W tym więc wypadku efektywność działania prowadziła do nierzetelnych obserwacji. W wielu przypadkach kryminalnych uprzednie doświadczenia świadka mogą skłaniać go do podawania faktów i zdarzeń, których nie było, lecz które powinny być. Nasze badania wskazują także, że biali obserwatorzy lepiej rozpoznają białych ludzi wśród podejrzanych niż Murzynów. Nasze badania potwierdzają tezę, że obserwatorzy lepiej rozpoznają ludzi należących do własnej rasy.


3. Osobiste uprzedzenia i stereotypy. Przekonania (w najmniej przyjemnej postaci) mogą ujawnić się w wypadku nastawień czy uprzedzeń żywionych przez świadka. Ofiara napadu rabunkowego może początkowo podawać, ze została napadnięta przez „czarnuchów” i ze względu na ograniczone doświadczenie, jak również z powodu swych przesądów, może nie być zdolna do odróżnienia jednego Murzyna od drugiego („Oni wszyscy wydają mi się podobni”). W klasycznym badaniu poświęconym temu zjawisku obserwatorom polecono popatrzeć przez krótki czas na obrazek, przedstawiający kilku ludzi w pociągu kolei podziemnej (Allport i Postman, 1945). Na obrazku tym Murzyn siedział, a biały człowiek stał z nożem w ręku. Wytypowani później obserwatorzy skłonni byli podawać, że widzieli nóż w ręku Murzyna.
Uprzedzenia mogą być rasowe lub religijne, mogą być oparte na cechach fizycznych, takich, jak długie włosy i brudne ubranie, a mogą też wynikać z oceny czyjejś pozycji społecznej itd. Wszyscy ludzie posługują się pewnymi stereotypami, na których oparte są ich oceny percepcyjne; stereotypy te nie tylko prowadzą do uprzedzeń, lecz także służą bardziej efektywnemu podejmowaniu decyzji. Świadek wypadku samochodowego może zaoszczędzić sobie czasu na myślenie, przytaczając (mocno u siebie ugruntowany) stereotyp dotyczący kobiet za kierownicą; te skróty myślowe mogą jednak nie odpowiadać rzeczywistej sytuacji, a naoczny świadek nie zdaje sobie sprawy z tego, że opisuje stereotyp, a nie prawdziwe zdarzenie.
Jeśli uprzedzenia świadka podziela osoba prowadząca śledztwo, to protokół w większym stopniu może odzwierciedlać ich wspólne uprzedzenia niż to, co rzeczywiście zostało zaobserwowane.
4. Tendencyjna konstrukcja testu. Takie techniki, jak „rząd podejrzanych” oraz zestaw fotografii stosowany w badaniu zdolności naocznego świadka do rozpoznania osoby podejrzanej można analizować jako tendencyjne lub bezstronne na podstawie kryteriów, na które mogłaby się zgodzić większość psychologów. Bezstronny test powinno się opracować starannie, tak aby po pierwsze, wybranie każdej z pozycji przez osobę, która nie widziała podejrzanego, było równie prawdopodobne; po drugie, pozycje te powinny być tak podobne do siebie nawzajem i do pierwotnego opisu podejrzanego, aby były mylące dla osoby, która jedynie zgaduje; i wreszcie, test należy przeprowadzać bez stosowania naprowadzających pytań czy sugestii.
Aż nazbyt często stwierdzałem, że „rzędy podejrzanych” lub zbiory fotografii są zestawiane niestarannie, czy nawet nierzetelnie, w taki sposób, że test identyfikacji staje się całkowicie niewiarygodny. Jeśli na przykład prezentujesz pięć fotografii, to powinna istnieć tylko jedna szansa na pięć (20%), że każda z tych fotografii będzie wybrana na zasadzie zgadywania; często jednak fotografia podejrzanego w jakiś sposób rzuca się w oczy. W przypadku Angeli Davis zestaw dziewięciu fotografii użyty do tej identyfikacji zawierał trzy zdjęcia oskarżonej wykonane podczas wiecu, dwa zdjęcia innych kobiet z uwidocznionymi ich nazwiskami, jedno zdjęcie kobiety 55-letniej itd. Świadkowi łatwo było wyeliminować pięć zdjęć jako wręcz śmiesznych, tak że test został zredukowany od czterech fotografii, w tym trzech Angeli Davis. Oznacza to, że świadkowie mieli 75% szans wybrania jej zdjęcia, niezależnie od tego, czy widzieli ją, czy nie. Taki test jest bezsensowny dla psychologa i prawdopodobnie zmarnowany jako element materiału dowodowego w sądzie.
Badania nad pamięcią wykazały także, że jeśli jedno zdjęcie w zbiorze fotografii jest odmienne (pod względem ubioru, rasy, wzrostu, płci przedstawionej osoby, jakości fotografii itd.), jest to bardziej prawdopodobne, że zwróci ono na siebie uwagę i zostanie wybrane. Nauczyciel opracowujący test z wieloma odpowiedziami do wyboru obmyśla kilka odpowiedzi, które brzmią lub wyglądają podobnie, tak aby utrudnić uzyskanie dobrego wyniku osobie, która nie zna właściwej odpowiedzi. Stosowane przez policję „rzędy podejrzanych” i zestawy fotografii również nie są testami z odpowiedziami do wyboru. Jeśli zasady opracowywania bezstronnych testów są ignorowane przez władze, to testy te stają się nierzetelne.
Przedstawiłem powyżej podstawy empiryczne, na których oparłem swą ekspertyzę w sądzie. Podstawy te są wynikiem dawnych prac, z których wiele jest znanych psychologowi pracującemu zawodowo, lecz nie są one tematem codziennej konwersacji dorosłych Amerykanów, którzy zostają sędziami przysięgłymi. Istota tej analizy została zawarta w dziełach niektórych psychologów, zwłaszcza Munsterberga, już na początku bieżącego stulecia.  Istnieje jednak nadal dokuczliwa luka między kontrolowanymi sytuacjami badawczymi, które dostarczają danych dotyczących podstawowych procesów percepcyjnych, oraz niektórymi bardzo ważnymi pytaniami dotyczącymi percepcji w gorzej kontrolowanym, lecz za to rzeczywistym świecie. Nasze badania laboratoryjne i terenowe mają zatem na celu ocene wiarygodności zeznań naocznych świadków, którzy obserwowali symulowane przestępstwa - w tym przypadku dysponujemy wiernym zapisem rzeczywistego przebiegu wydarzeń i możemy go użyć do porównania. Swoje badania zacząłem od bardziej szczegółowej wersji eksperymentu, który Munsterberg i jego współpracownicy przeprowadzili ponad sześćdziesiąt pięć lat temu.




Eksperymentalne badanie
naocznych świadków




Aby badać właściwości zeznań naocznych świadków w warunkach zbliżonych do naturalnych, zainscenizowaliśmy napad na terenie California State Univeristy - oszalały student „zaatakował” profesora wobec 141 świadków.  Zarejestrowaliśmy cały ten incydent na taśmie magnetowidu, tak żeby można było porównywać rzeczywisty przebieg zdarzeń ze sprawozdaniami naocznych świadków. Po tym napadzie zebraliśmy zaprzysiężone zeznania od wszystkich jego świadków, przy czym prosiliśmy ich, aby opisali napastnika, napad oraz ubranie obecnych osób (w zasadzie proces swobodnego przypominania).  Prosiliśmy także o podanie ocen pewności (0-100%) dotyczących trafności sporządzonego przez siebie opisu. Na miejscu tych wydarzeń była między innymi osoba postronna, w tym samym wieku co napastnik.


Porównanie „Przeciętnych Opisów Podanych Przez 141 Naocznych Świadków, Z 
Rzeczywistymi Cechami Podejrzanego i Zdarzeń
a) Rzeczywiste właściwości; b) „Przeciętny” opis
Czas trwania incydentu: a) 34 sekundy; b) 81,1 sekundy
Wysokość podejrzanego: a) 69,5 cala; b) 70,4 cala
Waga: a) 115 funtów; b) 180 funtów
Wiek: a) 25 lat; b) 22,7 roku
Ogólny wskaźnik dokładności: a) 28 punktów; b) 7,4 punktu


W tabeli podano porównanie rzeczywistych cech napastnika z „przeciętnymi” opisami cech sporządzonymi na podstawie ocen podanych przez świadków. Jest oczywiste, że świadkowie podawali bardzo niedokładnie oceny - fakt stwierdzano w tego rodzaju eksperymentach tak często, że profesorowie psychologii stosują je dla zademonstrowania nierzetelności naocznych świadków. Ludzie skłonni są przeceniać czas trwania incydentu, w tym przypadku prawie 2,5-krotnie. Ciężar ciała napastnika oceniano jako wyższy o 14%, wiek oceniano zbyt nisko, a wskaźnik dokładności - na który składały się punkty za wierny opis wyglądu zewnętrznego i ubioru - wynosił przeciętnie jedynie 25% maksymalnego możliwego wskaźnika. Jedynie ocena wzrostu była bliska wartości rzeczywistej, lecz mogło to wynikać z tego, że napastnik był przeciętnego wzrostu. Ludzie, jeśli są niepewni swych ocen, to często podają dane dotyczące „przeciętnego” człowieka - niedokładne oszacowania wagi sprawcy napadu, podawane przez świadków, wykazywały istotne korelacje z ich własnym ciężarem ciała.
Odczekaliśmy następnie siedem tygodni i każdemu świadkowi indywidualnie zaprezentowaliśmy zestaw sześciu fotografii, stwarzając cztery rodzaje warunków eksperymentalnych w celu zbadania wpływu tendencyjnych instrukcji i stronniczego testowania na identyfikację podejrzanych przez naocznych świadków. Były dwa rodzaje instrukcji: o niskiej tendencyjności, w których jedynie pytano świadków, czy rozpoznają kogoś na fotografiach, oraz o wysokiej tendencyjności, w których świadkom mówiono, że mamy już pewien pogląd na to, kim jest napastnik i że apelujemy do nich, aby znaleźli go na zdjęciu. Były dwa typy zestawów fotografii, w których zastosowano dobrze naświetlone zdjęcia młodych ludzi, w tym samym wieku co napastnik. W przypadku nie sugerującego zestawu fotografii, wszystkie zdjęcia (sześć) były równo rozmieszczone, a wszyscy przedstawieni na nich mężczyźni mięli ten sam wyraz twarzy i byli podobnie ubrani. W przypadku tendencyjnego zestawu zdjęć, fotografia rzeczywistego napastnika była nieco przekrzywiona, a on sam był inaczej ubrany i miał inny wyraz twarzy niż mężczyźni na pozostałych zdjęciach. Aby móc dokonać porównania, naruszyliśmy tu zatem zasady właściwego konstruowania testu.
Wyniki wykazały, że jedynie 40% świadków poprawnie identyfikowało napastnika; 25% świadków zidentyfikowało niewłaściwą osobę - |niewinnego widza, który był obecny na miejscu przestępstwa. Nawet profesor, który został zaatakowany, wybrał spośród zdjęć fotografię niewinnego człowieka jako napastnika!


Wśród osób poprawnie identyfikujących napastnika najwyższy procent poprawnych rozpoznań mieli członkowie grupy, w której zastosowano połączenie tendencyjnego zestawu zdjęć z tendencyjną instrukcją. W niektórych z naszych nowszych badań posłużyliśmy się tymi samymi zestawami zdjęć wobec osób nie będących świadkami tego zajścia; również i one wybierały zdjęcia numer 5. Wykazaliśmy zatem, ze pogwałcenie właściwych zasad konstruowania testu może prowadzić do nierzetelnego poznawania osoby podejrzanej przez naocznych świadków (w sytuacji zaaranżowanej w sposób dość realistyczny).


Nasze wnioski z tego badania były następujące: po pierwsze, zeznania ponad 100 naocznych świadków przestępstwa były tak mało wiarygodne, że gdyby osoba prowadząca śledztwo zaczęła poszukiwać człowieka opisanego przez większość świadków, to prawdopodobnie skupiłaby swą uwagę na niewłaściwej osobie. Po drugie, przy stosowaniu przez policje metod rozpoznawania podejrzanego na fotografii, tendencyjne instrukcje i sugerujące zestawy zdjęć mogą zwiększyć procent świadków wybierających zdjęcie tej osoby, w stosunku do której władze są już uprzedzone. Po trzecie, jeśli policja jest nastawiona przeciw osobie niewinnej, to tendencyjne instrukcje i sugerujące zestawy zdjęć mogą zwiększyć prawdopodobieństwo, że zostanie zidentyfikowana niewłaściwa osoba.
W naszych nowszych badaniach posłużyliśmy się paradygmatem „wykrywania sygnałów”. Wybraliśmy ten sposób podejścia, ponieważ teoria wykrywania sygnałów rozwinęła się w obrębie psychofizyki jako próba uporania się ze stwierdzonym empirycznie faktem, że postawa obserwatora „zakłóca” dokładne wykrywanie, przetwarzanie i opisywanie bodźców sensorycznych. Idealny obserwator odróżnia wyraźnie to, co jest sygnałem (bodźcem) od tego, co nim nie jest. Zadanie polega zwykle na określeniu, czy sygnał (na przykład ton o danej częstotliwości) jest obecny, czy nie. Eksperymentator zawsze podaje osobie badanej szum stanowiący tło dla sygnału, lecz jedynie w połowie prób obecny jest także słaby sygnał (ton). Przy podejmowaniu decyzji, czy w danej próbie występuje sam tylko szum, czy też sygnał na tle szumu, osoba badana stosuje pewne kryterium, na które wpływ mają czynniki indywidualne, takie jak osobowość, doświadczenie, przewidywane koszty lub nagrody, czy też motywację, by zadowolić kogoś lub sprawić mu zawód. Eksperymentator rejestruje zarówno trafienia (poprawne odpowiedzi „tak”), jak i fałszywe alarmy (niepoprawne odpowiedzi „tak”), uzyskując w ten sposób ilościową ocene kryterium stosowanego przez obserwatora. Osobie bardzo ostrożnej mogłoby zdarzać się bardzo niewiele fałszywych alarmów i duża liczba trafień, co wskazywałoby że „tak” jest stosowane oszczędnie. Obserwator mniej ostrożny mógłby mówić „tak” w większości wypadków, powiększając w ten sposób stosunek fałszywych alarmów do trafień.
W naszym eksperymencie przedstawiliśmy 20 - 25 prawdziwych stwierdzeń dotyczących przestępstwa oraz taką samą liczbę stwierdzeń fałszywych.  Świadkowie zaznaczali odpowiedzi „tak” lub „nie”, a także podawali oceny pewności. W efekcie otrzymywaliśmy zapis trafień i fałszywych alarmów wynikających z zapamiętanego przez świadka przebiegu przestępstwa. Dane te przetworzono statystycznie tak, aby uzyskać krzywe obrazujące sposób, w jaki odpowiadał badany (tzw. krzywa ROC: „Receiver Operating Charakteristic” - Charakterystyka Funkcjonowania Odbiorcy). Linię prostą otrzymalibyśmy dla osoby lub grupy w wypadku której liczba trafień i prawdziwych alarmów jest równa - co wskazuje, że reakcje nie mają żadnego związku z faktami. Im bardziej stroma krzywa, tym bardziej ostrożny obserwator. Im większa powierzchnia pod krzywą, tym bardziej wrażliwy był dany świadek na różnicę między stwierdzeniem prawdziwym a fałszywym.


Z późniejszych naszych badań wynika, że świadkowie uzyskujący w laboratorium „lepsze” krzywe ROC trafniej rozpoznają „przestępcę” w rzędzie podejrzanych. Tego rodzaju funkcja wrażliwości obserwatora pozwala nam sprawdzać różne hipotezy dotyczące wpływu warunków środowiskowych, stresu, tendencyjności wypytywania, płci i środowiska społecznego na dokładność i wiarygodność naocznych świadków. Jesteśmy zatem na drodze do opracowania standaryzowanego testu oceniającego dokładność i wiarygodność naocznych świadków.
W naszej strategii badawczej nastąpiła jedna zasadnicza zmiana. Zamiast inscenizować przestępstwa „na żywo” w salach wykładowych, stosujemy barwne i dźwiękowe filmy przedstawiające starannie zainscenizowane przestęstwa. Po części uczyniliśmy to dla zapewnienia lepszej kontroli - ważniejszym jednak powodem jest to, że czasy apatycznych świadków przestępstwa zdają się mijać. Zainscenizowanie nawet niewinnego wyrwania torebki staje się niebezpieczne dla naszych „przestępców”, ponieważ wielu (mocno zbudowanych) świadków, podejmowało zawzięty pościg za rabusiem. Żadne badanie nie jest warte aż tak dużego realizmu (przynajmniej zdaniem moich poszkodowanych asystentów).
Dysponując krzywą ROC jako miarą wrażliwości świadków możemy badać, w jakej mierze czynniki powodujące tendencyjność, a powszechnie występujące w wypadku spraw sądowych, wpływają na identyfikowanie podejrzanych. W naszych wcześniejszych badaniach stwierdziliśmy, że ci świadkowie, którzy na koniec z powodzeniem rozpoznawali przestępcę w poprawnie zestawionym rzędzie podejrzanych, uzyskiwali wysokie „wskaźniki wrażliwości obserwatora”, podczas odtwarzania z pamięci przebiegu zdarzeń. Ludzie o niskich „wskaźnikach wrażliwości obserwatora” skłonni byli do podejmowania ocen wzrostu i wagi „przestępcy” korelujących z ich własnym ciężarem i wysokością ciała - co potwierdza nasz pogląd, że świadkowie nakłaniani do podawania opisu „fabrykują” swe odpowiedzi tak, by miały one „sens” (jest to zgodne z wynikami badań nad percepcją).
Zamierzamy udoskonalić ten test, umożliwiając świadkom obejrzenie kilku przestępstw. W ten sposób możemy sprawdzić ogólną wiarygodność świadka i zweryfikować szereg hipotez wysuwanych przez funkcjonariuszy policji w odniesieniu do świadków w starszym wieku, kobiet jako świadków, członków różnych grup rasowych i ekonomicznych itd. W pewnym sensie zatem dopiero rozpoczynamy wielki program badawczy, który biorąc początek z realnych zdarzeń, został wprowadzony do laboratorium i zmienił stosowane w nim metody. Spodziewamy się, że wkrótce opuści on laboratorium i jego rezultaty znajdą zastosowanie w rzeczywistym świecie, do którego się odnoszą - mamy również nadzieję, że wiedza psychologiczna pozwoli uczynić identyfikację przez naocznych świadków bardziej wiarygodnym i znacznie bardziej rzetelnym elementem procesu sądowego.




Literatura




|Allport |G. |W., |Postman |L. |J. In „Transactions of the New York Academy of Sciences” 1945, 8, 66.
|Bruner |J. |S., |Postman |L. |J. „On the Perception of Incongruity: A paradigm”. „Journal of Personality” 1949, 18, 206-223.




Rozdział 7.
Zmienione stany
świadomości




(...) Można to odczuć, lecz nie można tego opisać, (...) zatracenie się w morzu barw, „czucie”, „bycie”, całkowite zatopienie się w nim bez zachowania jakiejkolwiek własnej tożsamości, ty wiesz, (...) powiadam ci, że jest to zupełnie zdumiewający, fascynujący stan spostrzegania siebie jako harmonijnej części nieskończonej perspektywy barwy, która jest delikatna, łagodna, poddająca się i wszystko pochłaniająca; zupełnie niezwykłe, najbardziej niezwykłe”.
Aldous Huxley, cytowany przez Ericksona, 1965


Powyższy cytat jest fragmentem podanego przez Aldousa Huxleya opisu jednego z eksperymentów nad doświadczeniem barwy przy zastosowaniu tego, co nazwał on „głęboką refleksją”. Był to stan, który wywoływał on u siebie samego w sposób dowolny, w ciągu niewielu minut, bez żadnego specjalnego ćwiczenia, środków farmakologicznych czy też interwencji jakiejś innej osoby. Według jego własnych słów, „po prostu odrzucał wszelkie kotwice” zwykłej świadomości i dzięki intensywności koncentracji na tym, co zachodziło w nim samym, potrafił oddzielić swą świadomość od tego, co zachodziło w rzeczywistości świata zewnętrznego. Po wprowadzeniu się w ten stan nie tylko mógł doświadczać niezwykłych |wrażeń, lecz także potrafił posługiwac się nimi dla znajdowania nowych pomysłów, rozwijania idei oraz dostrzegania nowych relacji pojęciowych, które następnie mógł włączyć w swą świadomą aktywność, gdy znów zaczął posługiwać się swą zwykłą świadomością.




Normalna świadomość
i jej zmiany




Czym |jest „świadomość” i co oznaczają jej |zmiany? Formułując pytanie w sposób bardziej osobisty mógłbyś się zapytać: „A jaki to ma związek ze mną?  Czy ja mogę doświadczać zmienionych stanów świadomości?” W niniejszym rozdziale zajmiemy się takimi właśnie pytaniami, które jeszcze przed kilkunastu laty wykraczały poza granice „tradycyjnej psychologii”. Po ogólnym omówieniu natury ludzkiej świadomości i jej zmian, rozpatrzymy bardziej szczegółowo kilka dziedzin badań, które dostarczają intrygujących informacji o tym, w jaki sposób psychika może oddziaływać na siebie samą; dziedziny te obejmują sen i marzenia senne, środki farmakologiczne wpływające na psychikę, medytację, biologiczne sprzężenie zwrotne, hipnozę oraz zmiany perspektywy czasowej.
Przy badaniu niezwykłych stanów świadomości występują specyficzne problemy związane z przestrzeganiem wymagań obiektywnej nauki. Badane zjawiska mają tu charakter subiektywny i często bardzo trudno jest uzyskać obiektywne ich wskaźniki, a co dopiero wskaźniki dające się mierzyć.  Występuje tu ponadto pewna istotna wewnętrzna sprzeczność: narzędzia opracowane do mierzenia i oceny regularnie występujących zjawisk fizycznych próbuje się stosować do badania zjawisk niefizycznych, a często pozornie irracjonalnych i nieprzewidywalnych. Być może, powinniśmy rozważyć koncepcję, że nie całą rzeczywistość można zredukować do formuły „wejście-wyjście”. W każdym razie, jeżeli decydujemy się odrzucić (lub zastąpić innymi) reguły, którymi zwykle posługujemy się przy gromadzeniu materiału dowodowego, to jest rzeczą ważną, abyśmy zdawali sobie z tego sprawę i nie mówili o „naukowej weryfikacji” wniosków wprowadzonych na podstawie innych reguł dowodzenia.
„Być |świadomym” - oznacza to, że zdajemy sobie sprawę z własnych procesów myślowych, a zwykle także ze zdarzeń zewnętrznych. Osoba, która utraciła świadomość (w wyniku śpiączki, szoku, zemdlenia lub ogólnego znieczulenia), nie ma kontaktu z rzeczywistością zewnętrzną i nie wie o tym, co się z nią dzieje. Jak jednak wszyscy wiemy, świadomość nie jest stanem typy „wszystko albo nic”, czymś, co mamy, albo nie mamy, lecz raczej procesem, aktywnością psychiczną, która może zmieniać się w pewnych granicach - od podwyższonej czujności, pobudzenia i wrażliwości, do niewrażliwości i senności.
Aby ludzki mózg mógł funkcjonować w sposób optymalny, potrzebuje on stymulacji, a także pewnej zmienności odbieranego przez siebie wejścia sensorycznego. Prawdopodobnie potrzebuje także pewnego poziomu aktywności poznawczej, polegającej na ocenianiu tych wejść, jak również na myśleniu i wyobrażaniu sobie. Jeśli poziom wejścia jest albo zbyt wysoki, albo zbyt niski, wówczas w funkcjonowaniu danej jednostki mogą wystąpić zaburzenia, przynajmniej chwilowe. Gdy sygnały wejściowe są przytłaczająco silne, wówczas dana osoba może „stracić” świadomość, broniąc się w ten sposób przed obciążeniem: może nie uznać realności bezpośredniego doświadczenia i „wyłączyć je”. Gdy wejście nie jest wystarczająco stymulujące, dana osoba może znudzić się i usnąć lub też mogą wystąpić u niej fantazje, marzenia na jawie, halucynacje itd., w których to mózg jest pobudzany przez różne „gry i zabawy” zapoczątkowane przez zachodzące w nim procesy wewnętrzne.
Zmienione stany świadomości wywołuje się także rozmyślnie, przyjmując alkohol, środki psychotropowe (pobudzające lub uspakajające); stany takie powstają także mimo woli w wyniku gorączki, postu, odwodnienia, zaburzeń w czynności gruczołów wydzielania wewnętrznego, braku snu, napadów padaczki oraz zatrucia. Wszystkie te drogi do zmiany świadomości mają wspólną cechę: zmieniają one zwykłe środowisko komórek mózgowych, czy to za pomocą środków chemicznych czy też zbyt słabej lub silnej stymulacji.
Jednakże zmienione stany świadomości można także wywoływać za pomocą środków psychologicznych, takich jak medytacja, skupienie, uczenie się, hipnoza oraz, być może, innymi metodami. Fascynujące jest to, że chociaż stany te są wywoływane przez zjawiska psychiczne, to jednak występują wtedy również zmiany fizjologiczne. Badacze ciężko pracują, ustalając korelacje między tymi dwoma rodzajami zjawisk. Jeśli chodzi o związki przyczynowe miedzy nimi, to są oni mniej przygotowani do wypowiadania twierdzeń na ten temat.
Ponieważ nikt inny nie ma bezpośredniego dostępu do twojej świadomości - ani ty nie masz dostępu do świadomości innych - przeto „cudownym faktem, nad którym należy się zastanowić”, jest (według słów Karola Dickensa) to, że „każde stworzenie ludzkie jest zbudowane w ten sposób, iż stanowi głęboki sekret i tajemnicę dla każdego innego”. Jednakże w znacznym stopniu stanowimy tajemniczy sekret również dla siebie samych. Wszyscy zostaliśmy w subtelny sposób ukształtowani przez typową dla kultury zachodniej orientację materialistyczną, przekonani o zasadniczej realności „rzeczy” i o doniosłości fizycznych działań w otaczającym nas świecie oraz naszych oddziaływań na ten świat. Oparłszy filozofię na tej „realności”, podnieśliśmy fizykę do pozycji „królowej nauk”. Nawet nasza nauka o zachowaniu w dużej mierze bada ludzi raczej jako byty fizyczne niż jako doznające istoty, chociaż bez wątpienia subiektywne doświadczenie jest ważną - być może centralną - cechą zjawiska człowieczeństwa.




Jak zmieniała się
wartość przypisywana
świadomości?




Nasza materialistyczna orientacja stanowi głęboką zmianę względem myśli wczesnochrześcijańskiej, w której śmiertelne ciało nie tylko było podporządkowane nieśmiertelnej duszy, lecz w rezultacie uważano je za „jednorazowe, nie podlegające zwrotowi opakowanie” dla niej. Osiągnięcie mistycznej jedności z Bogiem wymagało ćwiczenia się w |kontemplacyjnej |medytacji, dzięki której dusza mogła wyzwolić się od wszelkiej zależności od myśli czy wrażeń i bezpośrednio poznać Boga. Ćwiczenia transcendentalne opisane w XIV wieku przez Waltera Hiltona w „The Ladder of Perfection” (Drabina doskonałości) są w istocie podobne do ćwiczeń proponowanych przez, żyjącego w II wieku p.n.e., słynnego jogę Pantańdżali (Woods, 1914).
Zgodnie z poglądami epoki Renesansu dusza (w wyniku upadku Adama w Raju) to zmysły, rozum i zrozumienie. „Ze zmysłów powstaje pragnienie czy pożądanie, które wspólne jest ze zwierzętami; z rozumu powstaje wybór, który jest właściwy człowiekowi; ze zrozumienia, dzięki któremu człowiek może być (znowu) partnerem dla Aniołów, powstaje wola” (Castiglione, 1528). „W zrozumieniu, jakże podobny Aniołom” - taki był ostateczny opis potencjalnych możliwości ludzkich.
Mechanistycznej koncepcji Descartesa pozostało oddzielenie duszy i psychiki od materii i skierowanie uwagi nauki na badanie fizycznego działania „mechanizmu zegarowego” człowieka.
W początkowym okresie rozwoju psychologii jako dyscypliny naukowej (porównaj Rozdział 6) działała grupa psychologów niemieckich, których głównym przedmiotem zainteresowania było analizowanie struktury świadomości. Byli oni przekonani, że gdy wszystko rozłoży się na najprostsze jakości, to pozostaną wrażenia i uczucia. |Wrażenia definiowano jako to, czego doświadcza się w wyniku stymulacji którejś z dróg czuciowych (zapach, dotknięcie, widok itd.). |Uczucia definiowano jako doznania emocjonalne. Według tych psychologów, wspomnienia, wyobrażenia i wszystkie inne elementy świadomości można było ostatecznie sprowadzić do mieszaniny wrażeń i uczuć.
Wraz z pojawieniem się psychologii amerykańskiej, opartej na modelach fizyki oraz biologii i wywodzącej się z koncepcji pragmatycznej, zgodnie z którą realne i godne uwagi jest tylko obiektywne zachowanie i dające się zmierzyć bodźce, ciało utraciło swą duszę. Niektórzy mówią, że utraciło również głowę.
Lecz wahadło rozpoczęło już ruch powrotny. Zainteresowanie kwestiami świadomości, tworzeniem wewnętrznych reprezentacji zdarzeń zewnętrznych oraz bogatym życiem wewnętrznym, którego wszyscy doświadczamy, przyciągnęło wielu rygorystycznych badaczy pragnących wykroczyć poza akceptowane granice swej dyscypliny w dążeniu do zrozumienia natury świadomości ludzkiej, jej roli w zachowaniu oraz zachodzących w niej zmian. Ta reorientacja niektórych działów psychologii wynikła po części z zainteresowania psychologią humanistyczną, która przywiązuje dużą wagę do funkcjonowania całego organizmu człowieka. Odzwierciedla ona także nowy wzrost zainteresowania psychologów krajów zachodnich orientalnymi tradycjami zen i jogi oraz kontrolowaniem psychiki uprawianym pod różnymi nazwami. I wreszcie głęboki wpływ leków psychotropowych i środków farmakologicznych, radykalnie zmieniających spostrzeżenia, odczucia i sposób przetwarzania informacji u jednostek „normalnych”, dostarczył psychologom bodźca, skłaniając ich do podjęcia prób zrozumienia, w jaki sposób normalna świadomość może ulegać zmianom. Niezależnie od tego, jaka była geneza tych zainteresowań, badania nad zmienionymi stanami świadomości rozszerzały się obejmując wszelkie zmiany stanów psychicznych, czy to wywołane przez środki farmakologiczne, oddziaływanie fizjologiczne czy też manipulacje psychologiczne.




Charakterystyczne cechy
zmienionych stanów
świadomości




Nie jest rzeczą prostą ustalić kryteria pozwalające określić, kiedy normalna świadomość staje się świadomością „zmienioną”. Wynika to po części z naszego słabego poznania tak zwanej świadomości normalnej, która sama zdaje się składać z wielu stanów różniących się rodzajem i natężeniem.  Chociaż stany świadomości nieustannie zmieniają się, to w jaki sposób zdają się one wiązać ze sobą z możliwą do zidentyfikowania stałością - identyfikowaną oczywiście przez jednostkę, która kontroluje swą własną świadomość.
Użytecznych wyjaśnień dostarcza nam Charles Tart, jeden z pionierów badań nad zmienionymi stanami świadomości. Pisze on:


„Normalnym stanem świadomości każdej jednostki jest ten stan, w którym spędza ona większą część swych godzin czuwania. Założenie, że twój normalny stan świadomości i mój są zupełnie podobne, a ponadto podobne do normalnych stanów świadomości wszystkich normalnych ludzi, jest przyjmowane prawie powszechnie, chociaż słuszność tego założenia można kwestionować.  Zmienionym stanem świadomości dla danej jednostki jest taki stan, w którym odczuwa ona wyraźnie jakościową zmianę struktury (patern) swego funkcjonowania psychicznego; to jest odczuwa ona nie tylko jakąś zmianę ilościową (większe lub mniejsze pobudzenie, więcej lub mniej wrażeń wzrokowych, większa lub mniejsza lotność itd.), lecz także, że pewna jakość lub jakości jej procesów psychicznych są odmienne. Działają funkcje umysłowe, które zazwyczaj nie działają w ogóle, pojawiają się jakości percepcyjne, które nie mają żadnych normalnych odpowiedników itd. W wielu przypadkach granicznych, w których dana jednostka nie może wyraźnie rozróżnić, pod jakim właściwie względem jej stan świadomości różni się od normalnego, ilościowe zmiany w funkcjonowaniu psychicznym są bardzo wyraźne. Jednakże istnienie stanów granicznych i trudnych do opisania zjawisk nie wyklucza tego, że istnieją odczucia wyraźnych, jakościowych zmian w funkcjonowaniu psychicznym, które stanowią kryterium zmienionych stanów świadomości” (Tart, 1969, ss. 1-2).


Czy istnieją wspólne, charakterystyczne cechy wielu odmian zmienionych stanów świadomości? Jest zaskakujące, że opisano wiele takich podobnych cech, pomimo tego, że doznania te występowały w różnych okolicznościach (przeżycia religijne, wstrzyknięcie środka psychotropowego, medytacja, sytuacje silnego stresu). Następujące cechy często są wymieniane jako charakterystyczne dla zmienionych stanów świadomości:


Zniekształcenia procesów percepcyjnych, poczucia czasu i obrazu własnego ciała. Wspólną cechą jest zniekształcenie wielu zwykłych spostrzeżeń, łącznie ze wzrokowymi i słuchowymi, jak również spostrzegania czasu i przestrzeni. W doznaniu „transcendentalnym” mogą w ogóle nie występować żadne jakości sensoryczne, lecz w wielu zmienionych stanach świadomości występują zaostrzone wrażenia wzrokowe i słuchowe, złudzenia percepcyjne oraz halucynacje - to jest spostrzeżenia przy braku właściwych bodźców zewnętrznych. Często opisywane jest poczucie oddzielenia od własnego ciała.  Część ciała mogą wyglądać zupełnie inaczej niż zwykle i (lub) odczuwa się je jako zmienione; mogą wydawać się powiększone lub nieważkie, zdrętwiałe lub odłączone. Poczucie czasu często ulega ogromnym zmianom, tak że sekunda wydaje się godziną lub przeciwnie, godzina - chwilą. Nierzadkie są opisy doświadczenia „wieczności” lub „nieskończoności” w przeżyciach typu transcendentalnego. Przykładem takich zmian percepcyjnych jest zmieniony sposób odbierania barw, opisywany przez Huxleya.


Poczucie obiektywności i wykroczenia poza granicę własnego ja. Jest to poczucie, że patrzy się na świat z większym obiektywizmem, że jest się bardziej zdolnym do spostrzegania zjawisk jako niezależnych od siebie samego, a nawet od wszystkich istot ludzkich. Człowiek zdaje się być zdolny od oderwania się od swych osobistych potrzeb i pragnień oraz widzenia rzeczy takimi, jakimi są „naprawdę” - w pewnym podstawowym, ogólnym znaczeniu. Często takie transcendentalne doświadczenie pojawia się po długim wysiłku, zmierzającym do odrzucenia trosk i więzi tego świata, lecz nawet w takich okolicznościach zdaje się ono występować w sposób naturalny.


Niekiedy takie poczucie obiektywności jest doświadczane jako utrata kontroli, jako uczucie przebywania na zewnątrz siebie samego; uczucie to może być witane z radością lub wzbudzać opór; często zależy to od nastawienia i oczekiwań danej osoby przed wystąpieniem takiego zmienionego stanu świadomości. Jeśli ktoś ma poczucie, że traci własną, osobistą perspektywę, aby połączyć się z jakąś większą siłą, wówczas nie będzie opierał się tak bardzo, jak ktoś, kto czuje, że panowanie nad rzeczywistością wymaga mu się i może nie być w stanie odzyskać go w sposób dowolny.


Typową cechą mistycznych doznań religijnych jest odrzucenie „ziemskich trosk”, jak również utrata zainteresowania błahostkami biologicznej egzystencji. Dana osoba odrzuca to, co doczesne, dla tego, co duchowe, dla zespolenia się z Bogiem, naturą lub kosmicznymi siłami wszechświata.


Poczucie prawdy nie wymagające zewnętrznego potwierdzenia. Zmienionym stanom świadomości często towarzyszy ogromne poczucie pewności. Dana jednostka odczuwa, że doświadczenie to ma wielka wartość - wartość jedyną w swym rodzaju - i że żadne późniejsze „racjonalne” wyjaśnienie czy interpretacja nie mogą zmniejszyć jego wagi. Sama wiedza doświadczana jest na poziomie „intuicyjnym”, a nie na naszym zwykłym racjonalno-empiryczno-logicznym poziomie analizy. Jest tak, jakby „widziało się” istotne cechy ukryte za pozorami. Doświadczenie to jest odbierane jako bardziej „rzeczywiste” czy „prawdziwe” niż spostrzeżenie „zwykłej” świadomości. To samo dotyczy oczywiście złudzeń i halucynacji, co komplikuje ocenę objawień doznawanych w zmienionych stanach świadomości.


Pozytywna jakość emocjonalna. Radość, ekstaza, cześć, spokój i przepełniająca serce miłość często są wymieniane w opisach doznań transcendentalnych, gdy dana osoba dysponuje pewnym religijnym czy filozoficznym układem odniesienia dla interpretacji tych doświadczeń. W opisach mistyków Wschodu doznanie to w mniejszym stopniu polega na ekstazie, a w większym - na głębokim i niezwykle kojącym spokoju, dzięki któremu dana jednostka zdaje się być ze wszystkimi w harmonii. Jest to uczucie osiągnięcia ostatecznego stanu spokoju i uciszenia, co niektórzy przedstawiciele Zachodu krytykują, poczytując za gnuśność i rezygnację z odpowiedzialności.
W opisach mistyków chrześcijańskich doznanie to w mniejszym stopniu ma charakter uciszenia i spokoju, a w większym - żarliwej ekstazy. W niektórych opisach przeżyć pod wpływem narkotyków mówi się o głębokim lęku i braku radości, lecz w doznaniach transcendentalnych jakość emocjonalna jest zawsze pozytywna.


Paradoksalność. Opisy zmienionych stanów świadomości zwykle są sprzeczne, gdy analizuje się je na gruncie logicznym, racjonalnym. Dana osoba może opisywać doznania pustki, która wydaje się pełna i kompletna. Ktoś zdaje się odczuwać swą indywidualność jako rozszczepioną, a jednak istnieje najwyraźniej jakiś rodzaj „jaźni” spostrzegającej to rozszczepienie.  Dwoistość i przeciwieństwa życia zdają się być doświadczane równocześnie, zdają się łączyć w pewnym rozwiązaniu, a jednak zachowują swą odrębność. To tak, jakby się było Alicją w Krainie Czarów, gdzie sprzeczność jest podstawą harmonii.


Niewyrażalność. Często ludzie mówią o niemożności opisywania swych doznań. Ich jakości zdają się tak niezwykłe, że żadne słowa nie wydają się odpowiednie. Często również dane doznanie zdaje się zawierać tak wiele paradoksalnych cech, że opisywanie go nie ma sensu (występuje tu pewne prawdopodobieństwo do snów). Częstą cechą tych doznań jest jedność - siebie samego i innych lub tego, co wewnętrzne i tego, co zewnętrzne - lecz jest ona najtrudniejsza do wyjaśnienia w języku, który kładzie nacisk na rozróżnienia pomiędzy podmiotem i przedmiotem, pomiędzy osobą działającą i działaniem, pomiędzy czasem i miejscem.


Zjednoczenie i zespolenie. Wczesny okres socjalizacji dzieci polega w znacznej mierze na ćwiczeniu ich w wytaczaniu granic, takich jak „moje - nie moje”, oraz w rozpoznawaniu różnic i nieciągłości pomiędzy sobą samym a innymi, pomiędzy przeszłością, teraźniejszością i przyszłością, pomiędzy żywym i nieożywionym, pomiędzy rzeczywistością wewnętrzną i zewnętrzną oraz pomiędzy tym, co jest rzeczywiste, a tym, co wyobrażone i tylko potencjalnie możliwe. W zmienionym stanie świadomości ta odrębność własnego ja zanika, granice roztapiają się i następuje zespolenie własnego „ja” z tym, co poprzednio było „nie-ja”. To doświadczenie tożsamości zbiorowej, wszystkiego uczestniczącego we wszystkim, jest często szokujące dla umysłu człowieka Zachodu, ukształtowanego w kuźni indywidualizmu i własnej tożsamości.
Ponieważ ten rys charakterystyczny stanowi istotę doświadczenia transcendentalnego i ponieważ uwypukla on założenia dotyczące nas samych, z których zwykle nie zdajemy sobie sprawy, przeto przedstawiamy poniżej przykłady ilustrujące, w jaki sposób ludzie pochodzący z bardzo różnych środowisk doświadczają tego zjednoczenia i zespolenia. Najpierw przytoczymy autobiograficzny opis doświadczenia pod wpływem LSD:


„Ma sens stwierdzenie, że ja, John Robertson, przestałem istnieć, roztapiają się w podstawie bytu... w Bogu, w „nicości”, w ostatecznej realności czy też w jakimś innym podobnym symbolu zjednoczenia (...).  Mylące jest nawet samo użycie słów „ja doświadczyłem”, ponieważ w szczytowym momencie tego doświadczenia (który musiał trwać przynajmniej godzinę) nie było żadnego rozdwojenia pomiędzy mną samym a tym, czego doświadczałem. To raczej ja byłem tymi odczuciami (...). Było to szczególnie oczywiste wtedy, gdy po osiągnięciu tego mistycznego punktu szczytowego, odtwarzano nagranie Fantazji i fugi punktu g-moll Bacha.  Wydawało się, jak gdyby to nie było moje zwykłe „ja” słuchające tego nagrania, lecz że to ja sam byłem tą muzyką” (Robertson, w: Metzner, 1968, s. 880).


Z innej perspektywy opisuje doświadczenie transcendentalne współczesny mistrz zen, nieżyjący już Sokei-an Sasaki:


„Pewnego dnia oczyściłem mój umysł ze wszystkich pojęć, zrezygnowałem z wszelkich pragnień. Odrzuciłem wszystkie słowa, za pomocą których myślałem, i trwałem w spokoju. Czułem się trochę dziwnie, jak gdybym był wprowadzany w coś lub jak gdybym dotykał jakiejś nieznanej mi siły... I cyt! Wstąpiłem.  Utraciłem granicę mego fizycznego ciała. Oczywiście miałem swoją skórę, lecz czułem, że znajduję się w środku kosmosu. Mówiłem, lecz moje słowa straciły swe znaczenie. Widziałem ludzi przychodzących do mnie, lecz oni wszyscy byli tym samym człowiekiem. Wszyscy byli mną! Nigdy nie znałem tego świata. Wierzyłem przedtem, że zostałem stworzony, lecz obecnie muszę zmienić swój pogląd: ja nigdy nie zostałem stworzony - ja byłem kosmosem; żaden indywidualny pan Sasaki nie istniał” (cytowane w: Watts, 1957, s.  121).


Pewna studentka wyższej uczelni pod głęboką hipnozą powiedziała, że jej przeszłość i przyszłość są odległe i nieistotne, a jej teraźniejszość rozszerza się. Opisując swe doznania, powiedziała:


„Roztopiłam się, jestem tak rozrzedzona, że pokrywam właściwie wszystko.  W istocie przenikam jakby wszystko, ponieważ jestem tak rozrzedzona; mogę słyszeć, jak wszystkie małe przedmioty wibrują i mogę smakować te wszystkie rzeczy, takie, jak drewno, dywan, podłoga i krzesło. Naprawdę nie mogę już nic zobaczyć, chociaż myślę, że są tu różne barwy, lecz to jest takie wielkie, że prawie nie mogę tego zobaczyć, wszystko jest bardzo pomieszane, a ja po prostu jakbym wtopiła się we wszystko... Jestem nieodpowiedzialna!... Jestem wszystkim! Mogę trwać (...). Nie jestem już niczym, jestem wszystkim, a więc nie mogę zrobić niczego. Nie ma tu nikogo, nikogo kto by powiedział do mnie: „Hej, Wszystko, ty musisz zrobić to a ja to” (cytowane w: Zimbardo, Marshall i Maslach, 1971, s. 323).


Pisma jednej z największych mistyczek chrześcijańskich, żyjącej w XVI wieku, św. Teresy Avila, jeszcze silniej ukazują uniwersalną naturę tego doświadczenia (jednocześnie może ona być wyrażona w języku tej społeczności, z której pochodzi doznająca przeżyć osoba).


„W tej modlitwie zjednoczenia dusza czuwa wobec Boga, lecz jest całkowicie uśpiona wobec rzeczy tego świata i w stosunku do siebie samej. W ciągu krótkiego czasu, jaki trwa to zjednoczenie, jest ona jak gdyby pozbawiona wszelkiego czucia i nawet gdyby chciała, nie mogłaby pomyśleć o żadnej szczególnej rzeczy (...). Gdy więc Bóg podnosi duszę do zjednoczenia ze sobą samym, to zawiesza naturalne działanie wszystkich jej władz. Ona nie widzi, nie słyszy, nie rozumie, dopóty, dopóki jest zjednoczona z Bogiem (...). Bóg wchodzi do wnętrza tej duszy w taki sposób, że kiedy powróci ona do siebie, to zupełnie niemożliwe jest wątpienie, ze była ona w Bogu, a Bóg w niej... widzi to wyraźnie później, gdy już powróciła do siebie, nie z pomocą wzroku, lecz dzięki pewności, która w niej zamieszkuje i którą sam Bóg może jej dać” (cytowane w: James, 1902, ss. 303-314).


Inne cechy, niekiedy wzmiankowane w różnych sprawozdaniach, to uczucie odmłodzenia, przeżycie nagłej intensywnej emocji oraz skrajna podatność na sugestię (Ludwig, 1966).
W dalszej części tego rozdziału zapoznamy się z różnymi warunkami, które powodują zmiany w naszej świadomości, z podobieństwami i różnicami w doświadczeniach, które wywołują oraz tym, co wiadomo o towarzyszących im zmianach fizjologicznych. Omówienie różnych stanów świadomości zaczniemy od pewnego stanu, który jest znany nam wszystkim - stanu snu wraz z marzeniami sennymi, które czasami mu towarzyszą.




Sen i marzenia
senne




„Pomiędzy ciemnością, z której przychodzimy na świat, a ciemnością, w której znajdujemy kres, istnieje fala ciemności, która przypływa i odpływa każdego dnia naszego życia, a która obejmuje nas w sposób nieodparty.  Trzecią część życia spędzamy we śnie, który jest najzwyczajniejszą, a jednak głęboko tajemniczą dziedziną świadomości, gdzie dana osoba zdaje się żyć w odosobnieniu od czuwającego świata (...)” (Luce, 1965, s. 1).


Często myślimy o śnie w sposób negatywny, jako o |braku działania i świadomości, o interludium spełniającym jedynie funkcję regeneracyjną. W rzeczywistości badacze odkrywają, że jest to stan niezmiernie złożony - w czasie, gdy jesteśmy pogrążeni we śnie, w organizmie naszym występuje znaczna aktywność. Aktywność ta zdaje się być związana ściśle z wieloma aspektami naszego zachowania, włączając tu uwagę, emocje, pamięć i uczenie się. Tak więc badania nad snem mogą być jednym ze sposobów prowadzących do lepszego zrozumienia świadomości i stanu czuwania.
Jeśli sen stanowi tajemniczą część życia, to cóż dopiero powiedzieć o marzeniach sennych? Nasze sny gwałcą zwykłe zasady racjonalności, logiki, percepcji, czasu i przestrzeni, jak również wiele naszych nawyków i norm moralnych; dopóki jednak trwają, wydają się zupełnie normalne i realne. Nie istnieje żadna pewna wiedza na temat tego, dlaczego śnimy, co nasze sny oznaczają, czy w ogóle mają jakieś znaczenie. Niemniej jednak każdy z nas wie, że coś dziwnego, cudownego lub przerażającego zachodzi w naszych głowach wtedy, gdy odrzucamy zwykłą świadomość, która kieruje naszymi codziennymi krokami.




Zachowanie, które
nazywamy „snem”




„Jakkolwiek może być wiele różnorakich lub sprzecznych opinii dotyczących tego tematu, natura w sposób wystarczający zadbała o to, aby teoria miała wpływ na praktykę. Najpilniejszy badacz nie jest w stanie długo utrzymać otwartych oczu; raz na 24 godziny wesoły i ponury, bystry i tępy, hałaśliwy i cichy, pracowity i leń - wszyscy oni zostają pokonani przez łagodnego tyrana i wszyscy układają się w równości snu...”
Samuel Johnson


Wspólnym doświadczeniem wszystkich studentów jest konieczność zwalczania senności w ciągu tych nocy ostatniej szansy, kiedy wkuwają do końcowych egzaminów. Sen dla wielu jest stratą ograniczonego czasu, jakim dysponują.  Gdyby tylko można było obyć się bez niego, wówczas miałbyś prawie połowę więcej czasu na swe codzienne czynności. Chociaż jednak możesz |zmniejszyć czas potrzebny ci na sen, po to, by wykonać określone zadanie, to jednak następstwa długotrwałego, całkowitego pozbawienia snu sprawiają, iż bezsenność nie jest wcale stanem pożądanym.




Zbliżenie


Nie ma snu dla znużonego


„Szczególnie dramatyczny opis zmian świadomości, wynikający z długotrwałego braku snu, dotyczy przypadku Petera Trippa, „disc jockeya” z Nowego Jorku, który wziął udział w 200-godzinnym „maratonie” czuwania („wakathon”), dla poparcia akcji jednej z organizacji charytatywnych. W czasie tego „maratonu” był on pod obserwacją kilku lekarzy i poddawano go okresowym badaniom medycznym, a także dawano mu do rozwiązania testy wykonaniowe i psychologiczne. Od początku Tripp musiał walczyć ze sobą, aby powstrzymać się od zaśnięcia. Po dwóch dniach zaczął doznawać halucynacji wzrokowych, widząc na przykład pajęczyny w swych butach. Po 100 godzinach jego pamięć bardzo osłabła i miała wiele trudności z prostymi testami wykonaniowymi. Jego halucynacje stawały się coraz bardziej przerażające: garnitur tweedowy pewnego lekarza wydawał mu się ubiorem sporządzonym z włochatych gąsienic, a gdy poszedł do sąsiedniego hotelu, aby zmienić ubranie, zobaczył szufladę komody stojącą w płomieniach. Chcąc wyjaśnić sobie samemu te wizje, doszedł do wniosku, że ogień został rozmyślnie wzniecony przez lekarzy, aby go przerazić i wypróbować.
Proste zadanie algebraiczne, które uprzednio rozwiązywał z łatwością, obecnie wymagało tak nadludzkiego wysiłku, że Tripp załamał się, przerażony tym, ze jest niezdolny do jego rozwiązania, mimo iż dokładał wszelkich starań, by się z nim uporać. Uczeni obserwowali rzadkie widowisko: wykształcony artysta radiowy daremnie usiłujący rozwiązać zadanie na elementarnym poziomie.
„Po upływie 170 godzin po prostu nie można już było dłużej patrzyć na te męczarnie. Niekiedy Tripp nie był już pewny, czy jest sobą i często usiłował uzyskać jakiś dowód swojej tożsamości. Chociaż zachowywał się tak, jak gdyby czuwał, to jednak zapisy czynności bioelektrycznej jego mózgu przypominały zapisy charakterystyczne dla snu. W swych psychotycznych urojeniach był on przekonany, że lekarze spiskują przeciw niemu, aby posłać go do więzienia (...). Pod koniec 200 godzin bezsenności koszmarne halucynacje i rzeczywistość zlały się ze sobą i sądził on, że jest ofiarą sadystycznej zmowy lekarzy” (Luce, 1965, ss. 19-20).


Pozostawanie przez dłuższy czas bez snu może zmieniać wiele różnych reakcji fizjologicznych i psychologicznych. Niektóre ze skutków to: zmęczenie, bóle głowy, drżenie, zniekształcenia percepcyjne, trudności w koncentracji uwagi, zaburzenia orientacji, utrata pamięci krótkotrwałej, anomalie w zapisie czynności bioelektrycznej mózgu (EEG), a u niektórych ludzi myśli paranoidalne i żywe halucynacje podobne do tych, jakie miał wspomniany wyżej Tripp. Jednakże skutki pozbawienia snu nie są jedynie prostą funkcją czasu, przez jaki dana osoba pozostawała bez snu; zmienne środowiskowe, osobowościowe, motywacyjne oraz wiek również decydują o wpływie braku snu na zachowanie. Pewien przegląd badań nad całkowitym pozbawieniem snu kończy się następująco: „Chociaż dokładny charakter objawów będących wynikiem pozbawienia snu zależy od dodatkowych zmiennych, to jednak osoba pozbawiona snu nie jest normalna, gdyż występuje u niej upośledzenie, zarówno funkcji neurologicznych, jak i psychologicznych” (Freemon, 1972, s. 73).
Pomimo tego, że długotrwały brak snu wywołuje znaczne zaburzenia, skutki te są przemijające - jedna dobrze przespana noc i znowu funkcjonujemy normalnie. Nawet w grupie czterech zdrowych dorosłych mężczyzn, którzy byli pozbawieni snu przez 205 godzin i w związku z tym podlegali dokładnym badaniom, psychopatologiczne reakcje nie występowały poza okresem przebywania bez snu (Kollar i in., 1969).
Przymusowe pozbawienie snu jest w istocie skutecznym sposobem stosowanym przez policję w celu nakłonienia podejrzanych do składania zeznań. Metoda ta została najdokładniej opracowana przez pewnego naczelnika policji, który podczas czystki, przeprowadzonej w latach trzydziestych, przesłuchiwał starych działaczy partyjnych. Podobno trzymał on więźniów bez snu około 90 godzin, a następnie przesłuchiwał ich po krótkim jedynie okresie snu.  Więźniowie nie tylko przyznawali się do absurdalnych win (takich, jak uprawianie sabotażu przez wsypywanie gwoździków do masła), lecz ponadto sami zaczynali wierzyć, ze są winni przestępstw opisanych w ich fałszywych zeznaniach. (Jak na ironię, tą samą „psychologią stosowaną” posłużono się później w stosunku do owego naczelnika, gdy i on również został oskarżony o zdradę).
W badaniach nad snem psychologowie interesują się przede wszystkim zachowaniem |wewnętrznym - to jest procesami, co do których przyjmuje się, że zachodzą „we wnętrzu” każdego człowieka. Jak jednak mówiliśmy już, aby można było badać takie zachowanie, trzeba znaleźć jakiś sposób, który pozwoli uczynić je zewnętrznym, tak żeby można je było obserwować i mierzyć. Ten metodologiczny problem |eksternalizacji (uzewnętrznienia) |wewnętrznego |zachowania jest jednym z powtarzających się wciąż podstawowych problemów w psychologii.
Brak badań nad snem we wczesnym okresie rozwoju psychologii wynikał przede wszystkim z braku odpowiedniej metodologii. Przełomem metodologicznym w badaniach nad snem było wynalezienie |elektroencefalografii (EEG), która pozwoliła badaczom „podsłuchiwać” mózg (zob. Rozdz. 2). W roku 1937 Loomis i jego współpracownicy dokonali ważnego odkrycia, że zapis czynności bioelektrycznej mózgu zmienia się w chwili zapadnięcia w sen i wykazuje dalsze zmiany podczas całego okresu snu. Oznaczało to, że badacze mogli teraz obserwować w sposób ciągły zmiany zachodzące w czasie snu, jak również dokładnie określać jego początek i koniec. Ponadto stało się możliwe rozpoznawanie różnych poziomów |głębokości snu, jak również okresów, w których dana osoba prawdopodobnie miała marzenia senne.


Stany i stadia snu. Obecnie przyjmuje się powszechnie, że istnieją dwa stadia snu - regularnie powtarzający się stan, w czasie którego występują szybkie ruchy oczu („rapid eye movements”), określany jako faza |REM, oraz stan nazywany fazą NREM (|non rapid eye movement sleep”), który z kolei składa się z czterech stadiów, różniących się wyraźnie głębokością snu.




Zbliżenie


Elektroencefalograficzny zapis snu


„Zapis EEG reprezentuje aktywność elektryczną kory mózgowej, rejestrowaną za pomocą elektrod przymocowanych do powierzchni głowy. Uzyskiwane krzywe można opisać w kategoriach dwóch cech: |amplitudy (wysokości fali, gdy poziom napięcia przełoży się na ruchy rejestrującego pisaka) oraz |częstotliwości (liczba cykli - ruchów w górę i w dół na sekundę).
Amplituda i częstotliwości łącznie określają tak zwany wzorzec („pattern”) fal mózgowych. W zapisie czynności bioelektrycznej mózgu można również wyodrębnić „iglice” („spikes”) - może je rozpoznać wyćwiczony obserwator (a obecnie komputery).
Istnieje odrębny wzorzec występujący w stanie czujności („pogotowia”), jak również różne wzorce dla czterech stadiów snu w fazie NREM. Istnieje ponadto odrębny wzorzec występujący w tych okresach, gdy oczy śpiącego poruszają się szybko, to jest w fazach REM. Opracowano standardowy podręcznik służący do rzetelnego oznaczania stadiów snu (Rechtschaffen i Kales, 1968).


Mimo że miedzy czterema stadiami NREM występują wyraźne różnice, wykazano, iż różnica między fazą REM, a NREM jest najbardziej istotna.  Wydaje się również, że dotyczy to prawie wszystkich badanych ssaków.
Najważniejszą cechą snu w fazie REM jest całkowite zahamowanie dowolnej aktywności mięśniowej. Faza REM jest zatem okresem, kiedy ciało jest w zasadzie sparaliżowane i ruchy dowolne nie są możliwe.
Drugą cechą fazy REM jest to, że mózg zdaje się być (na podstawie różnych wskaźników) wzbudzony czy czuwający, chociaż dana osoba jest pozbawiona świadomości i zupełnie uśpiona. Dlatego tez niektórzy badacze nazywają fazę REM |snem |paradoksalnym.
Trzeci proces, który charakteryzuje fazę REM, zwany jest |aktywnością |okresową. Najwyraźniejszym jej przejawem są szybkie skokowe ruchy gałek ocznych, które poruszają się we wszelkich kierunkach. Występują także skurcze mięśniowe, zmiany wielkości źrenicy, skurcze ucha środkowego, a u mężczyzn - wzwód członka.
Czwartą charakterystyczną cechą fazy REM są znaczne zmiany fizjologiczne, zwłaszcza w autonomicznym układzie nerwowym. Zmiany te często obejmują duże, nieregularne fluktuacje tempa pracy serca oraz ciśnienia krwi. Takie „burze w układzie autonomicznym” mają doniosłe implikacje medyczne, ponieważ stwierdzono, iż ataki i niedomagania sercowe często występują we wczesnych godzinach rannych - w czasie, gdy dana osoba najprawdopodobniej znajduje się w fazie REM snu. Podczas gdy faza REM wiąże się z aktywnością kory mózgowej, to faza NREM wiąże się z jej dezaktywacją. Sen w fazie NREM wiąże się z percepcyjnym odizolowaniem się danej osoby od środowiska (Dement i Mitler, 1975).
W ciągu 8 godzin snu u przeciętnego, młodego, dorosłego, człowieka występuje pewien cykl złożony z różnych stadiów snu. Stadium czwarte (fazy NREM), najgłębszy sen, występuje w pierwszych godzinach snu, natomiast w ostatnich godzinach snu śpiący przechodzi na zmianę od stadium drugiego fazy NREM do fazy REM. Kolejne fazy REM są coraz dłuższe, chociaż występują one zwykle w odstępach wynoszących około 90 minut.
Sekwencja ta u poszczególnych osób różni się nieco, w zależności od warunków indywidualnych, lecz jest stosunkowo stała u zdrowych, młodych osób dorosłych. W cyklach snu nie stwierdzono różnic związanych z płcią, natomiast z wiekiem wiąże się pewna istotna różnica. U niemowląt i dzieci (do mniej więcej czwartego roku życia) faza REM i stadium czwarte stanowią znacznie większą część ich ogólnego czasu snu. U ludzi starszych czas snu w fazie REM jest nieco krótszy, a czas snu w stadium czwartym - o wiele krótszy w porównaniu z okresem, gdy byli oni młodsi. Wydaje się, że starsi ludzie śpią mniej, a w dodatku ich sen jest mniej głęboki (Roffwarg, Muzio i Dement, 1966).


Znaczenie przystosowawcze fazy NREM i fazy REM. Najpopularniejsze wyjaśnienie funkcji spełnionej przez sen - odpowiedź na pytanie, |dlaczego śpimy - głosi, że stanowi on okres regeneracji po zmęczeniu spowodowanym świadomą aktywnością. Wbrew przemawiającej do wyobraźni analogii pomiędzy osobą śpiącą a przepracowanym mięśniem w stanie odprężenia, „eksperymentalna” analiza snu nie dostarczyła mocnego poparcia dla koncepcji, zgodnie z którą sen jest procesem regeneracji” (Williams i in., 1973 s. 306). Być może, iż nasz sen nie jest sposobem odtworzenia tego, co utraciliśmy, lecz raczej sposobem zachowania energii w czasie, gdy nie ma potrzeby działania.


Zgodnie z tym poglądem, wysuniętym przez Webba (1971), sen wymusza brak aktywności organizmu wtedy, gdy wymagania środowiska w stosunku do niego są minimalne. Każdy gatunek wytworzył biologiczny, rytmiczny cykl aktywności i snu, zwany |rytmem |dobowym, dostosowanym do wymagań energetycznych i ekologicznego charakteru środowiska tego gatunku.
Wysuwano wiele przypuszczeń, co do funkcji spełnianych przez fazę REM, lecz żadne z nich (ani też one wszystkie razem) nie mogą wyjaśnić różnych zjawisk związanych z tym stanem. Oto niektóre z tych przypuszczeń: a) w fazie REM mózg zostaje oczyszczony z substancji neurochemicznych nagromadzonych w ciągu dnia; b) u noworodków i małych dzieci sen w tej fazie pobudza rozwój mózgu dzięki generowanej przez siebie aktywności; c) reorganizuje on czynność bioelektryczną mózgu zdeorganizowaną w fazie NREM; d) faza REM jest w jakiś sposób związana z marzeniami sennymi, stanowiąc być może „klapę bezpieczeństwa”, umożliwiającą rozładowanie silnych napięć, które inaczej ujawniłyby się na jawie.
Jest prawdopodobne, że dla uzyskania pełnego wyjaśnienia roli, jaką oba rodzaje snu odgrywają w naszym życiu, będziemy musieli poczekać do chwili opracowania lepszych metod badania mikrobiochemii żywego mózgu.




Spać, a może
i śnić




Przypadkowe odkrycie faz REM i NREM snu po raz pierwszy dostarczyło pewnego klucza fizjologicznych badań nad marzeniami sennymi. Podejrzewano, ze marzenia senne mogą występować jedynie w pewnych stadiach snu, lecz analiza zapisów czynności bioelektrycznej mózgu nie dostarczyła prostego wyjaśnienia tego zagadnienia.


Fizjologiczne korelaty marzeń sennych. Aserinsky i Kleitman, prowadząc badania nad snem w 1953 roku, zauważyli, że kilka razy w ciągu nocy występowały szybkie drgania zamkniętych powiek, co świadczyło o ruchach oczu. W tych okresach następowało przyspieszenie tempa pracy serca oraz oddychania, co sugerowało reakcje emocjonalne. Przypuszczajac, że faza REM była związana z marzeniami sennymi, eksperymentatorzy ci budzili swych badanych w tych okresach snu.


Badani ci prawie zawsze wówczas podawali, że śnili, podczas gdy rzadko czynili to wtedy, gdy budzono ich w innych okresach (Aserinsky i Kleitman, 1953; Dement i Kleitman, 1957).
Jednakże w miarę gromadzenia materiału dowodowego okazało się, że |nie |potwierdza on istnienia ładnego „czystego” związku między marzeniami sennymi a fazą REM. Badani najczęściej przypominali sobie występowanie marzeń sennych wtedy, gdy budzono ich w czasie ruchów oczu, lecz stwierdzono, że w wielu wypadkach przypominali sobie także marzenia senne wtedy, gdy budzono ich ze snu w fazie NREM, przy czym uzyskiwane dane liczbowe były uzależnione od zastosowanego określenia „marzeń sennych”. W tabeli podano, jaki procent badanych obudzonych ze snu w fazach REM i NREM (w dziesięciu badaniach) opisywał swe marzenia senne oraz jak w tych badaniach definiowano marzenia senne.
Badani obudzeni w czasie fazy REM przypominają sobie następujące po sobie obrazy wzrokowe, które tworzą spójną dramatyczną historię, są żywe, mogą mieć barwę i dźwięk. Pomimo dziwacznego czy fantastycznego charakteru akcji śpiący uznaje tę nierzeczywistą sytuację za „naturalną”. Natomiast marzenia senne związane z fazą NREM są zwykle pozbawione dramatycznej, fabularnej treści. Jest w nich dużo nie powiązanych ze sobą myśli, lecz bardzo mało wyobrażeń sensorycznych.


Prowadzi się badania w celu wykrycia procesów, które wywołują marzenia senne w fazach REM i NREM. Procesy nerwowe, stanowiące podłoże doświadczanych przez nas w trakcie marzeń sennych widoków, dźwięków, emocji i idei, muszą być bardzo złożone. Bodźce nerwowe muszą w jakiś sposób zastępować zewnętrzne bodźce zmysłowe, a intensywność tych wewnętrznych procesów musi być dostatecznie duża, aby mogły być one odbierane jako „rzeczywiste”.


„Badania nad powetowaniem sobie braku snu w fazie REM świadczą o naszej „potrzebie marzeń sennych”. Badanym, którzy zgłaszali się na ochotnika, pozwalano spać normalnie dopóty, dopóki nie zaczynali wchodzić w okres fazy REM. W tym momencie budzono ich natychmiast, a następnie pozwalano im ponownie zasnąć i spać tak długo, dopóki nie rozpoczęła się u nich następna faza REM. W ten sposób nie pozwalano im w zasadzie wcale na sen w fazie REM. Badanych z grupy kontrolnej budzono tę samą liczbę razy w czasie fazy NREM.
U badanych pozbawionych w czasie eksperymentu snu w fazie REM każdej kolejnej nocy rozpoczynało się coraz więcej okresów (tzn. faz REM). Ich dzienne zachowanie również znacznie się zmieniło, przy czym zaznaczył się wzrost wrażliwości, lęku i napięcia, trudności w skupieniu uwagi oraz potknięcia pamięciowe. Wielu badanych donosiło o znacznym wzroście apetytu i zyskiwało na wadze przeciętnie funt dziennie. Gdy w końcu pozwolono tym badanym spać bez zakłóceń, to „powetowali” oni sobie tę deprywację śniąc około 60% więcej niż normalnie. U badanych z grupy kontrolnej zmiany te nie wystąpiły” (Dement, 1960).


Badani w powyższym eksperymencie ludzie byli pozbawieni snu w fazie REM tylko przez pięć kolejnych nocy. Jakie byłyby skutki znacznie dłuższej deprywacji? Pozbawiono systematycznie snu w fazie REM koty aż przez 70 dni.  Nawet tak długa deprywacja nie spowodowała żadnego zasadniczego upośledzenia zachowania zwierząt. Jednakże wystąpiło drastyczne |spotęgowanie wszystkich zachowań popędowych, włączając tu agresję, popęd seksualny i głód. To, w jaki sposób faza REM wiąże się z regulacją pierwotnych popędów, jest fascynującym problemem, który dopiero trzeba będzie rozwiązywać.
Jeszcze bardziej pasjonujacym wynikiem badań nad marzeniami sennymi jest odkrycie ich możliwego związku ze schizofrenią. W badaniu, przeprowadzonym nad schizofrenikami w okresie nasilenia się u nich objawów choroby, stwierdzono, że nie występowało u nich wtedy normalne zjawisko „powetowania sobie” snu w fazie REM po okresie pozbawienia ich tego rodzaju snu (Zarcone i in., 1968). Nasunęło to Dementowi i jego współpracownikom myśl, że występujące u pacjentów symptomy choroby mogą być przejawem aktywności, która normalnie znalazłaby ujście w postaci marzeń sennych w fazach REM.
Jaki mechanizm mózgowy mógłby spowodować „przeniesienie się” aktywności charakterystycznej dla fazy REM na stan czuwania? Ostatnie badania zdają się wskazywać na pewien związek chemiczny występujący w mózgu, zwany |serotoniną. U kotów, którym zaaplikowano związek chemiczny hamujący wytwarzanie serotoniny w mózgu, zachowanie i zapis czynności bioelektrycznej mózgu były podobne do tych, jakie stwierdzono u kotów pozbawionych snu w fazie REM przez długi czas. Ponadto, gdy koty poddane działaniu tego związku pozbawiono możliwości zapadania w taki sen, to podobnie jak u pacjentów z rozpoznaniem schizofrenii, nie wystąpiło u nich zjawisko |powetowania sobie”. Wykazano, że wszystkie te dziwne, „psychotyczne” zachowania można było wyeliminować podając związki chemiczne, które powodowały wzmożone wytwarzanie serotoniny. Jednym z takich związków jest |chloropromazyna, środek uspokajający od dawna stosowany w leczeniu schizofreników (Dement, 1969).




* * *



Ryc. 7.4. Poruszająca się bez przerwy taśma nie pozwala kotom zapaść w fazę REM snu. Chociaż mogą one zdrzemnąć się krótko, zanim dotrą do końca pełznącej powoli taśmy, to jednak nie mogą zasnąć głęboko, gdyż wówczas dojeżdżają do końca urządzenia i budzą się w zbiorniku z wodą.


* * *





Wszystkie te dane eksperymentalne sugerują, że w mózgu istnieje pewien system, który reguluje zachowania popędowe, a normalnie „wyładowuje się” w marzeniach sennych w fazie REM. Jeśli funkcjonowanie tego systemu zostaje zakłócone (na przykład przez zahamowanie wytwarzania serotoniny), wówczas aktywność charakterystyczna dla fazy REM i zachowania popędowe występują w sposób niekontrolowany w stanie czuwania. Jest możliwe, że niewłaściwe funkcjonowanie tego typu może występować w stanie zwanym |schizofrenią, który omówimy dokładniej w Rozdziale 11.


Znaczenie snów. Pomimo niedawnych osiągnięć w dziedzinie fizjologicznej analizy snu i marzeń sennych, w ostatnich latach niewiele znaczących badań poświęcono zagadnieniu, co oznaczają marzenia senne i dlaczego śnią się nam takie a nie inne rodzaje snów.


„Freud o snach”. Według Freuda, treść snów ma dwa poziomy: |jawny i |utajony. Jawną treścią jest to, co pamiętasz i opowiadasz o zdarzeniach, które ci się śniły. Rzeczywiste znaczenie snu tkwi jednak w jego treści utajonej (ukrytej), w ideach reprezentujących nieświadome impulsy i pragnienia, które nie zostały zaspokojone w sposób jawny i pojawiają się w marzeniach sennych w zamaskowanej postaci. Treść jawną stanowi możliwą do zaakceptowania wersję danej historii, treść utajona reprezentuje wersję, która nie jest do zaakceptowania ze względów społecznych czy osobistych - niemniej jednak jest to wersja „prawdziwa, nieokaleczona”.
Według Freuda, w procesie socjalizacji kształtuje się w nas sumienie (superego), które kontroluje nasze myśli i działania, aby utrzymać nas na prostej i wąskej ścieżce. Nie dające się zaakceptować impulsy są wypierane ze świadomości („represjonowane”) w dziedzine nieświadomości. Jednakże nadal dążą one do przejawienia się, podobne ściśniętej sprężynie.  Przejawiają się one w naszym codziennym życiu w wielu postaciach: jako symptomy nerwicowe, przejęzyczenia, „zapomnienie” o tym, o czym nie |chcemy pamiętać oraz jako symbole w marzeniach sennych. Przejawiają się one w zamaskowanej postaci, aby oszukać cenzora, który w przeciwnym razie mógłby wykreślić je i zaaresztować autora.
We śnie czujny zazwyczaj cenzor odpręża się i dzięki różnym procesom psychicznym nie zaakceptowany, nie uświadamiany materiał przekształca się w możliwą do zaakceptowania, jawną historyjkę i w ten sposób zostaje on „przemycony”. Na przykład dzięki |przemieszczeniu przenosi się główny nacisk z centralnego, „nieprzyzwoitego” tematu na jakiś mało ważny, lecz „przyzwoity” element.
Według Freuda, dwie główne funkcje marzeń sennych polegają na tym, że chronią one sen i umożliwiają zaspokojenie pragnień. Zapewniają nam nieprzerwany sen rozładowując psychiczne napięcia, jakie wytworzyły się w ciągu dnia, oraz pozwalają nam osiągnąć nieświadome spełnienie naszych pragnień w halucynacyjnej postaci.
Ponieważ teoria Freuda kładła nacisk na doniosłe znaczenie wypartych impulsów seksualnych, nic więc dziwnego, że uważał on seks za główne źródło większości symboli w marzeniach sennych. Analiza przeprowadzona przez Freuda w jego klasycznej pracy „O marzeniach sennych” (tyt. oryg. „Die Traumdeutung”, 1900) świadczy wyraźnie, w jakim stopniu jawne symbole mogą być spostrzegane jako posiadające utajone odpowiedniki seksualne.


„ - Wszystkie wydłużone przedmioty, takie jak kije, pnie drzew i parasole (otwieranie tych ostatnich można porównać z erekcją) mogą reprezentować narząd męski - podobnie jak długa, ostra broń, taka jak noże, sztylety i piki (...). - Pudełka, szkatułki, skrzynie, szafki i piece, a także wydrążone przedmioty, okręty i naczynia wszelkiego rodzaju, reprezentują macicę. - Pokoje w snach są to zwykle kobiety; jeśli przedstawione są one z różnych stron, z wewnątrz i z zewnątrz, to interpretacja ta nastręcza niewiele wątpliwości (...). - Sen o przechodzeniu przez amfiladę pokoi, to sen o domu publicznym lub haremie (...). - Stopnie, drabiny lub schody, albo, jak to bywa, wchodzenie po nich w górę lub schodzenie w dół, reprezentuje akt płciowy. - Gładkie ściany, po których wspina się śniący, fasady domów (...) odpowiadają wyprostowanym ciałom ludzkim i są prawdopodobnie powtarzającymi się we śnie wspomnieniami wdrapywania się niemowlęcia na rodziców lub niańkę (...). - Kapelusz kobiecy można z dużą dozą pewności interpretować jako narząd rozrodczy, a co więcej, jako męski narząd rozrodczy. To samo dotyczy płaszcza (...). W snach mężczyzn krawat często pojawia się jako symbol członka (...). - Jest wysoce prawdopodobne, ze wszystkie skomplikowane mechanizmy i aparaty pojawiajace się w snach przedstawiają genitalia - z reguły męskie (...). Nie ma też żadnych wątpliwości, że wszelka broń i narzędzia są używane jako symbole narządu męskiego: na przykład pługi, młotki, strzelby, rewolwery, sztylety, szable itd. - W ten sam sposób wiele krajobrazów w snach, zwłaszcza zawierających mosty lub zadrzewione pagórki, można wyraźnie uznać za opisy genitaliów (...)” (ss. 354-365).


„Archetypy i zbiorowa nieświadomość Junga”. Karol Jung, uczeń Freuda, wykroczył poza freudowską analizę marzeń sennych - z jej skoncentrowaniem się na nieświadomości oraz wyparciem seksualnym wynikającym z własnych doświadczeń danej jednostki. Dla Junga istotne znaczenie miały tematy powtarzające się w snach. Był on przekonany, że tematy te są częścią |zbiorowej |nieświadomości śniącego i składają się z |archetypów egzystencji. Uważał on, że nieświadomość zbiorowa znajduje się na poziomie głębszym niż nieświadomość osobista i pochodzi z naszej historii ewolucji: sprawia ona, że widzimy świat w taki sam niemal sposób, jak nasi przodkowie. Surowcem marzeń sennych są zatem archetypy urodzin, śmierci, zmartwychwstania, władzy i Boga; archetypy te mogą także pojawiać się w innych wytworach, takich jak maski. Podczas gdy Freud uważał symbole senne za odbicie minionych konfliktów i zdarzeń, Jung był przekonany, że reprezentują one pewne aspekty obecnego życia danej jednostki oraz jej przyszłe możliwości. Uważał on, że symbole w snach dostarczają wskazówek dotyczących nie tego, kim śniący był, lecz tego, kim się staje.


Różnice pod względem treści snów związane z płcią i wiekiem. Jawną treść marzeń sennych można kwantyfikować w obiektywny, rzetelny sposób za pomocą standaryzowanych skal ocen, które opracowali Calvin Hall i Robert Van de Castle (1966). Gdy ten system kwantyfikacji zastosowano do pięciuset snów stu studentów wyższej uczelni, a także do snów podobnej liczby studentek, ujawniły się pewne prawidłowości.


„Sny kobiet rozgrywają się zwykle w znajomych wnętrzach domów; sny mężczyzn dzieją się w nieznajomym otoczeniu poza domem. Mężczyźni śnią więcej o grupach, kobiety więcej o znanych im, pojedynczych ludziach.  Kobiety koncentrują się bardziej na opisach wyglądu fizycznego postaci występujących w ich snach.
Inne różnice związane z płcią polegają na tym, że w marzeniach sennych mężczyzn częściej występują tematy związane z agresją, seksem, aktywnością fizyczną i osiągnięciami. W marzeniach sennych kobiet występuje więcej subtelnych form agresji, więcej emocji oraz więcej aktywności słownej”.


Wydaje się, że są to dokładnie te różnice, które charakteryzują stereotypowy obraz mężczyzny i kobiety w naszym społeczeństwie; w pewnym stopniu mogą one odzwierciedlać tendencyjność występującą w opisach, jakie badani podawali eksperymentatorom. |Opis snu nie jest tym samym, co |doświadczenie snu i podlega wpływowi zmiennych społecznych występujących w sytuacji, w której opisuje się swoje przeżycia. I znów mamy tu do czynienia z problemem polegającym na tym, że nie możemy obserwować bezpośrednio tego zachowania, które badamy - marzenia sennego - lecz musimy oceniać je za pośrednictwem pewnego obserwowalnego zachowania - w tym wypadku słownego opisu.




* * *



Ryc. 7.5. „Sen kupca o sukcesach” - tak zatytułowano ten drzeworyt z osiemdziesiątych lat ubiegłego wieku.


* * *





W znacznej części snów o treści związanej z agresją, opisywanych zarówno przez osoby dorosłe, jak i przez dzieci, śniący jest ofiarą, a nie agresorem. Dzieci zaś podają, że emocje odgrywają główną rolę w ich snach jako strach, a nie radosne spełnienie ich pragnień.


Koszmary senne. Czteroletni Adam wydał w nocy okrzyk przerażenia, budząc tym ojca, który wziął go na ręce, aby go uspokoić.


„Tam jest niedźwiedź, on mnie gryzie! Chce mnie zranić”.
„Nie ma żadnego niedźwiedzia; spałeś po prostu i śnił ci się straszny sen”.
„Ale ja się boję! To był prawdziwy niedźwiedź”.
„Połóż się znowu spać, niedźwiedzia nie będzie. Zobaczysz, że to był tylko straszny sen”.
„Ale skąd mam wiedzieć, że teraz jestem obudzony i że to mi się nie śni, i że ty nie jesteś częścią tego strasznego snu i że niedźwiedź nie wróci, gdy tylko zrobię to, co mówisz?”.


Istotnie, skąd to można wiedzieć? Czy naprawdę możemy być zupełnie pewni, że wiemy, co jest rzeczywiste, a co wyobrażone i która forma naszej świadomości jest normalna?
Kiedy ostatnio miałeś koszmarny sen? Koszmarne sny są zaskakująco powszechne; w pewnej próbce, złożonej ze studentów wyższej uczelni, 86% podało, że w ubiegłym roku miało przynajmniej jeden koszmarny sen, a 5% stwierdziło, iż sny takie miało przynajmniej raz na tydzień (Feldman i Hersen, 1967).
Częstym tematem koszmarów sennych są katastrofy, w których śniący jest bezradny i nie może niczego zrobić. Powszechnie wymienianymi centralnymi tematami koszmarów sennych są: niebezpieczeństwo, przerażenie, niemoc i śmierć. Bardzo często występuje także spadanie, unieruchomienie w chwili, gdy konieczne jest działanie, kąsanie przez zwierzęta. Zwierzęta należą do najczęstszych postaci koszmarów sennych opisywanych retrospekcyjnie przez osoby badane.
W badaniach laboratoryjnych nad koszmarami sennymi, w których osobę śniąca budzi się, a ona natychmiast opisuje treść koszmaru, występują pewne różnice tematyczne pomiędzy snami z fazy REM i ze stadium czwartego fazy NREM. Chociaż koszmary senne REM zawierają treści zagrażające i wzbudzające lęk, to jednak koszmary występujące w stadium czwartym zawierają na ogół więcej agresji skierowanej przeciw danej osobie - śni ona, że spada, jest miażdżona, zaklinowana itd., czemu towarzyszą krzyki, wokalizacje i większy strach niż w marzeniach sennych w fazie REM. Koszmary senne fazy REM często stanowią kontynuację niekoszmarnych snów z tej samej fazy (Fischer i in., 1970).
Chociaż jest wiele intrygujących pytań, które dotyczą przyczyn, korelatów i konsekwencji tych nocnych okropności, to jednak w chwili obecnej dysponujemy jedynie niewieloma uzasadnionymi odpowiedziami. Chociaż koszmarne sny od starożytności przyciągały uwagę pisarzy, filozofów, dramaturgów, lekarzy oraz naukowców i były przedmiotem wielu domysłów, to jednak wiedza na temat ich natury, przyczyn i przebiegu jest ciągle stosunkowo bardzo mała; są domysły i hipotezy, lecz niewiele jest sprawdzalnych założeń teoretycznych (Hersen, 1972). Warunkiem dalszych postępów w zrozumieniu zarówno koszmarów sennych, jak i zwykłych snów, jest ustalenie związanych z nimi procesów nerwowych; jednocześnie trzeba jednak zdawać sobie sprawę, że zjawiska te są realnymi procesami psychicznymi.




Deprywacja sensoryczna
i przeciążenie
sensoryczne




Zaburzenia procesów poznawczych, które występują w warunkach deprywacji sensorycznej, były zapewne pierwszymi zmienionymi stanami świadomości badanymi poważnie przez psychologów. Stwierdzono, że każda sytuacja, która charakteryzuje się znacznym lub długotrwałym obniżeniem normalnego poziomu wejścia bodźcowego lub funkcjonowania ruchowego danej jednostki, może spowodować wystąpienie tego rodzaju doznań. Wykazano, że długotrwałe odosobnienie, deprywacja sensoryczna i społeczna (jakiej podlega się w Arktyce lub na morzu), a długotrwałe unieruchomienie w opatrunku gipsowym lub w sztucznym płucu, powodują halucynacje i inne zmiany w funkcjonowaniu poznawczym.




Zbliżenie


Co powiedzieć nagiej zjawie?


„W pewnych skrajnych i niezwykłych warunkach wydaje się, że bodziec będący przyczyną spostrzeżenia pochodzi nie „z zewnątrz”, lecz „z wewnątrz” głowy. Złudzenie spostrzeżenia, w którym występuje percepcja rzeczywistości pod nieobecność zewnętrznej energii bodźcowej nosi nazwę |halucynacji lub omamu. W odróżnieniu od złudzeń percepcyjnych, które występują u większości obserwatorów, halucynacje są zjawiskami wysoce indywidualnymi. Ta właśnie cecha czyni je intrygującą zagadką dla psychologów i przedmiotem zainteresowania dla psychiatrów. Halucynacje uważa się za jeden z głównych wskaźników diagnostycznych psychozy i w związku z tym zostaną one omówione w Rozdziale 11. Jednakże halucynacje mogą być także spowodowane stresem emocjonalnym, deprywacją sensoryczną, hipnozą i środkami halucynogennymi, jak również brakiem snu.


Próbując ocenić, czy jakieś dziwne doznanie percepcyjne jest prawdziwą halucynacją, czy jedynie pseudohalucynacją - to znaczy jest spowodowane przez jakieś nieoczywiste zewnętrzne źródło bodźców - zastosuj siedem następujących testów:


1. Kontrola wolicjonalna - Czy możesz spowodować, że to coś zniknie?
2. Zablokowanie wejścia sensorycznego - Czy to coś jest nadal, gdy zablokujesz odpowiedni receptor zmysłowy (zasłonisz oczy lub zatkasz uczy?)
3. Walidacja interpersonalna - Czy inni ludzie w tej samej sytuacji opisują to samo doznanie?
4. Sprawdzian intermodalny - Czy możesz dotknąć tego lub kopnąć to?
5. Sprawdzian cech fizycznych - Czy może to wykryć także magnetofon lub światłomierz?
6. Koordynacja reakcji z bodźcem - Czy staje się to większe pod szkłem powiększającym? Czy poziom dźwięku zmienia się, gdy zbliżasz się do niego, lub oddalasz?
7. Jeśli zwrócisz uwagę nagiej zjawie, że nie ma na sobie ubrania, to czy zaczerwieni się?


Jeśli pierwsze dwie próby wypadły pozytywnie, a inne negatywnie, nie mów „Chodź”, lecz zgłoś się niezwłocznie do studenckiej przychodni zdrowia psychicznego”.


„W pewnym badaniu, w którym szesnaście osób poddano przez tydzień lub dłużej izolacji sensorycznej w pomieszczeniu, w którym wyeliminowano niemal zupełnie bodźce wzrokowe i słuchowe, u jedenastu osób wystąpiły halucynacje. Były to głównie błyski światła, mrugające światła, blado żarzące się światła itd., które były pozbawione kształtu i zwykle pojawiały się na obwodzie pola widzenia. Halucynacje te zwykle trwały bardzo krótko, mniej więcej od 5 do 10 sekund, chociaż w niektórych wypadkach podawano, że trwały one aż 15 minut. Wielu badanych donosiło o jednym lub dwóch krótkich okresach halucynacji w ciągu dnia; inni mieli tylko jeden albo dwa takie okresy w ciągu całego tygodnia. Pięć osób nie doniosło w ogóle o wystąpieniu halucynacji; kobiety zdawały się być mniej podatne na halucynacje.
Poza halucynacjami wzrokowymi w kilku wypadkach doniesiono o halucynacjach słuchowych. Były one zwykle bardzo realistyczne, takie jak szczekanie psa, dzwonienie budzika czy odgłosy pisania na maszynie. Opisano też dwie halucynacje dotykowo-kinestetyczne. Jedna z nich polegała na odebraniu wrażenia, że zimna stal naciska przedramię i policzki osoby badanej; drugą było wrażenie, że ktoś wyciąga materac spod osoby badanej. W większości wypadków o halucynacjach słuchowych i dotykowych donoszono w ciągu dwóch ostatnich dni odosobnienia.
Gdy badani po raz pierwszy opuścili to pomieszczenie, wówczas podawali oni, że odbierane obrazy były teraz bardziej żywe niż poprzednio.  Bardzopospolitym objawem była także nadwrażliwość na dźwięki, zwłaszcza w ciągu pierwszej nocy po zakończeniu eksperymentu, gdy badani słyszeli nawet najsłabsze dźwięki. Liczne dźwięki, które normalnie są raczej denerwujące, wydawały się przyjemne, a w niektórych wypadkach uznawano je nawet za rozkoszne. Hałasy ruchu ulicznego wydawały się szczególnie głośne, a nawet w pewnej mierze szokujące. Testy zastosowane po okresie odosobnienia nie wykazały jednak żadnych poważnych zmian percepcyjnych, a pomniejsze zmiany we wrażliwości zniknęły po upływie jednego dnia” (Zubeck, Pushkar, Sanson i Gowing, 1961).


Inne badania wykazały, że niski poziom natężenia rozproszonych bodźców wzrokowych i słuchowych wywiera nawet głębszy wpływ niż brak stymulacji. W jednym z takich badań stwierdzono następujące zmiany:


„Halucynacje wzrokowe były z początku na ogół zupełnie proste, lecz później stawały się bardziej żywe i złożone. Najpierw występowało ogólne świecenie w obrębie pola wzrokowego, następnie pojawiały się punkty lub linie świetlne, później geometryczne figury i wzory. Na koniec pojawiały się całe sceny. Jednemu z mężczyzn wydawało się, że widzi zbliżające się przedmioty i cofał głowę, gdy to się zdarzało; jeden był przekonany, że na jego okulary były rzutowane obrazy; inny czuł, że ktoś jest zarazem z nim w kabinie. Halucynacje te były żywsze niż normalne wyobrażenia i zdawały się być rzutowane jakby na ekran filmowy przed osobą badaną - nie polegały na widzeniu „oczyma duszy”, jak to bywa zwykle w wypadku wyobrażeń. Doznania takie badani mogli wytrzymać jedynie przez parę dni, mimo że płacono im 20 dolarów dziennie” (Heron, 1961).


Wyniki badań eksperymentalnych zdają się świadczyć wyraźnie, że posiadające znaczenie doznania zmysłowe są niezbędne dla normalnego funkcjonowania mózgu. Złożony, nieustannie aktywny mózg, który nigdy nie pozwala sobie na drzemkę, najwyraźniej wymaga, aby również otoczenie czuwało i prowadziło z nim stymulującą konwersację. Izolację sensoryczną można uważać za pewien sposób „destrukturalizacji środowiska”. Osoba badana, u której brak orientacji w przestrzeni i w czasie wywołuje niepewność i lęk, skłonna jest starać się ustrukturalizować środowisko i przywrócić znaczenie tej sytuacji. Pojawiające się wskutek tych usiłowań fantazje, halucynacje i zniekształcenia percepcyjne są zgodne z osobowością osoby badanej i jej dawniejszym środowiskiem, jak również z sytuacją eksperymentalną.
Zwiększona ilość odbieranych bodźców zmysłowych, nadmierna aktywność ruchowa oraz (lub) silne pobudzenie emocjonalne mogą sprzyjać wystąpieniu zmienionych stanów świadomości. Konieczność długotrwałego utrzymywania czujności może również powodować halucynacje lub zniekształcenia percepcji.  Często opisuje się takie doznania, których przyczyną jest długotrwała czujność w czasie pełnienia służby wartowniczej, żarliwa modlitwa, silne zaabsorbowanie umysłu jakimś całkowicie pochłaniającym zadaniem lub skupienie uwagi na jakimś obiekcie zewnętrznym czy odczuciu wewnętrznym.  Jednakże długie okresy zmniejszonej czujności również mogą prowadzić do powstawania wrażeń rytmicznej stymulacji czy też pływania w wodzie.
Wiele przypadków zmienionych stanów świadomości stwierdza się po takich nadmiernie stymulujących przeżyciach, jak rozruchy uliczne, religijne zebrania mające na celu odnowienie uczuć religijnych, długotrwały taniec (taki, jak uprawiany przez „wirujących” derwiszów), silny strach czy panika, stany transu w czasie pierwotnych ceremonii różnego rodzaju czy też momenty skrajnie silnej emocji (niezależnie od tego, czy emocją tą jest ekstaza miłosna czy też nieznośny żal i smutek).




Środki farmakologiczne
a zmiany w psychice




Sobota, 10 kwietnia 1965”
Doświadczałem krótkich chwil rozkojarzenia lub płytkich stanów nadrealności (...). Dokonując przeglądu obrazów, które pamiętałem z moich halucynogennych doświadczeń, doszedłem do nieuniknionego wniosku, że widziałem świat w sposób strukturalnie różny od tego, w jaki jest on zwykle spostrzegany. W innych przeżywanych przeze mnie stanach nadrealności formy i kształty, które widziałem, zawsze mieściły się w granicach mojej wzrokowej koncepcji świata. Natomiast wrażenia wzrokowe pod wpływem tej halucynogennej mieszaniny dymnej nie były takie same. Wszystko, co widziałem, znajdowało się przede mną na linii wzroku; powyżej lub poniżej tej linii wzroku nie było niczego.
Każdy obraz cechowała irytująca płaskość, a jednocześnie niepokojąca głębia. Być może, ściślejsze byłoby stwierdzenie, że obrazy te stanowiły konglomerat niewiarygodnie wyrazistych szczegółów umieszczonych wewnątrz pól o różnej jasności; światło w tych polach poruszało się, wywołując efekt rotacji.
Po dokonaniu analizy i dołożeniu starań, by przypomnieć sobie te doznania, byłem zmuszony odnaleźć szereg analogii w celu „zrozumienia”” tego, co „widziałem”” (Castaneda, 1968, s. 181-182).


Ten fragment z dziennika antropologa Carlosa Castanedy stanowi część fascynujacego opisu jego pięcioletniego „terminowania” u Indianina, meksykańskiego „czarownika” Don Juana, który ćwiczył go w poznawaniu i opanowywaniu świata „nadrealności” przez stosowanie peyotlu, bielunia („Datura stramonium”) i innych roślin wywołujących halucynacje (1968, 1971, 1972).
Takie zmiany w funkcjonowaniu psychiki i w charakterze świadomości, wywoływane przez środki farmakologiczne, spopularyzował Aldous Huxley, publikując w 1954 roku książkę „The Doors of Perception” (Drzwi percepcji).  Huxley przyjmował meskalinę, przeprowadzając osobiście eksperyment w celu sprawdzenia słuszności twierdzenia poety Williama Blake’a, zawartego w jego utworze „The Marriage of Heaven and Hell” (Małżeństwo niebios i piekła, 1973):


„Gdyby drzwi percepcji zostały otwarte, każda rzecz wydawałaby się człowiekowi taką, jaką jest, nieskończoną.
Ponieważ człowiek zamknął się w sobie, widzi wszystko przez wąskie szczeliny swych spraw”.


Doznania te były dla Huxleya doznaniami, które wykraczały poza jego spostrzeganie zwykłej rzeczywistości, prowadząc nie tylko do spostrzegania pozazmysłowego, lecz także do nowych form myślenia, bardziej mistycznych niż racjonalnych. Opisuje on ostatnie stadium odrzucenia własnego „ja”, przeżywane pod wpływem meskaliny, jako doświadczenie, w którym „istnieje „niejasna świadomość””, że Wszystko jest we wszystkim - że Wszystko jest w rzeczywistości każdym. Jest to, sądzę, największe zbliżenie się, jakie może osiągnąć skończony umysł, do „spostrzegania wszystkiego, co zdarza się wszędzie we wszechświecie””.
Środki farmakologiczne, które wpływają na procesy psychiczne, noszą nazwę środków |psychotropowych. Wśród nich te środki, które mogą wywoływać halucynacje zmysłowe, określa się jako środki |halucynogenne, te zaś, które mogą powodować niezwykłe formy myślenia i pobudzenia, przypominające formy psychotyczne, zwane są środkami |psychozomimetycznymi. Jeden z pierwszych badaczy zajmujących się tymi problemami, Humphrey Osmond, użył terminu „psychodeliczne” dla określenia psychologicznych skutków działania takich środków, jak LSD. |Psychodeliczny („psychodelic”) oznacza „przejawiający się w psychice” i termin ten miał być początkowo naukowo neutralnym terminem służącym do określenia środków farmakologicznych, które wywołują zmienione stany świadomości. Obecnie jest on powszechnie stosowany dla określenia środków halucynogennych.
Między eksperymentalnym zastosowaniem środków psychotropowych dla uzyskania samowiedzy lub przełamania ograniczeń percepcyjnych a nałogowym zażywaniem środków farmakologicznych, aby „czuć się dobrze” lub aby uciec od świata, jest wielka różnica. Jednakże w zbyt wielu wypadkach dokonuje się tego nieodwracalnego kroku prowadzącego do zależności od leków i do narkomanii. Kontynuując nasz główny temat - zmienione stany świadomości - w niniejszym podrozdziale przeprowadzimy najpierw krótką klasyfikację narkotyków najpowszechniej używanych w Stanach Zjednoczonych i wywoływanych przez nie podstawowych skutków, a następnie opiszemy te czynniki, od których częściowo zależy działanie danego narkotyku.




„Skład apteczny”




„Środek farmakologiczny” można definiować swobodnie jako każdy czynnik chemiczny, który oddziałuje na żywą protoplazmę. Definicja ta obejmuje szeroki zakres substancji (od witamin do tytoniu), które wywołują bardzo różne skutki: fizyczne, psychiczne i behawioralne. Istoty ludzkie zawsze wykazywały aktywną, badawczą ciekawość skutków i właściwości środków farmakologicznych. Nauczyliśmy się, że środki farmakologiczne mogą mieć silny wpływ na organizm - niektóre szkodliwy, niektóre uzdrawiający - a już w czasach przedhistorycznych nasi przodkowie odkryli, że środki farmakologiczne mogą mieć znaczny wpływ na ich subiektywne doznania.  Historia używania i nadużywania środków psychotropowych jest historią narkotyków - od konopi indyjskich do opium i nikotyny - wciągających ludzi we wszystkich czasach i na wszystkich kontynentach: od Sumerów, którzy cztery tysiące lat przed narodzeniem Chrystusa zażywali opium ze względu na jego euforyzujące działanie, do Indian północno-amerykańskich obecnie, którzy zażywali peyotl w czasie ceremonii religijnych.
My, Amerykanie, jesteśmy społeczeństwem wysoce uświadomionym, zażywającym mnóstwo środków farmakologicznych. Każdego ranka, południa i wieczora w całym państwie, miliony Amerykanów piją jedną filiżankę kawy za drugą, zapalają papierosa za papierosem. Kobiety, pragnąc uzyskać szczupłą, modną figurę modelki, proszą lekarzy o przepisanie pigułek odchudzających, a dyrektorzy i kierownicy zażywają środki uspokajające, by zachować zimną krew w obliczu różnych kłopotów w biurze czy w domu.
Są „coctail parties”, są pijani kierowcy, są miliony alkoholików; są narkomani w gettach i w willowych dzielnicach podmiejskich. Amerykanie są narodem aż zbyt dobrze zaznajomionym ze środkami farmakologicznymi - indywidualne wzorce używania i nadużywania tych środków kształtują się pod wpływem doniosłej roli, jaką odgrywają one w zachodniej medycynie, milionów dolarów wydawanych na reklamę oraz zwyczajów i oddziaływań społecznych.  Prawie każdy Amerykanin miał jakieś doświadczenia z takim czy innym środkiem farmakologicznym modyfikującym zachowanie.




Zbliżenie


„Prawdziwi przyjaciele to ci, co też palą ziele”


„Wśród czynników odpowiedzialnych za zażywanie narkotyków przez nieletnich uczniów największą rolę odgrywają naciski konformizmu społecznego. Zakrojone na dużą skalę badania, które w 1971 roku objęły ponad 8000 uczniów szkół średnich w stanie Nowy Jork, ujawniły, że uczniowie ci znacznie częściej palą marihuanę, jeśli czynią to także ich przyjaciele (Kandel, 1973).
W próbce tej 29% badanych podało, że pali marihuanę (16% w najniższej klasie i aż 41% w klasach najstarszych). Wśród „palących” trzecią część stanowili „nałogowcy” („heavy users”), którzy palili ją 40 razy lub więcej.  Ogromna większość tych „nałogowców” (90%) miała również do czynienia z różnymi innymi narkotykami.
W pewnej mierze wejście na drogę narkomanii jest uzależnione od modelującego wpływu rodziców; uczniowie, którzy spostrzegali swe matki jako osoby zażywające środki kojące, częściej zażywali marihuanę niż ci, którzy spostrzegali, że ich matki nie zażywają tych środków. Jednakże najbardziej uderzającym stwierdzeniem było to, że decydującą rolę odgrywają rówieśnicy.  Więź z innymi zażywającymi narkotyki nieletnimi była najważniejszym korelatem palenia marihuany przez tych uczniów „(...) spośród uczniów, którzy spostrzegali, że żaden z ich przyjaciół nie pali marihuany, tylko 7% używało tego narkotyku, w przeciwieństwie do 92% tych, którzy spostrzegli, że wszyscy przyjaciele go używają” (s. 1068).


Jak wynika z wykresu, wpływ najlepszych przyjaciół jest silniejszy od wpływu rodziców. Palenie marihuany wiąże się wprawdzie w niewielkim stopniu z zażywaniem środków psychotropowych przez rodziców, jednakże to, że twoi rodzice nie zażywają narkotyków, nie ma dużego wpływu, jeśli twój najlepszy przyjaciel to czyni - są wówczas szanse, że i ty będziesz zażywał je również. Z drugiej zaś strony, jeśli twój najlepszy przyjaciel nie zażywa narkotyków, to nie ma dużego znaczenia, jeśli czynią to twoi rodzice - są szanse, że ty nie będziesz ich zażywał.
Innym przykładem istotnej roli, jaką odgrywa zażywanie narkotyków wśród zaprzyjaźnionych ze sobą rówieśników, jest to, że stopień więzi między przyjaciółmi oparty na tym, czy zażywają oni marihuanę czy też nie, jest większy niż więź między nimi oparta na: paleniu tytoniu, piciu alkoholu, przeciętnej ocen, programie szkolnym, orientacji politycznej oraz wielu innych formach aktywności, podstaw społecznych i szkolnych. Wydaje się więc uzasadniony wniosek, że naciski społeczne ze strony rówieśników zachęcają do zażywania narkotyków, co z kolei stanowi podstawę do więzi między przyjaciółmi. Dlatego też jedynie pół żartem mówimy, że „prawdziwi przyjaciele to ci, co też palą ziele”.


Środki psychotropowe można podzielić na siedem głównych grup. Są to: 
tytoń, alkohol, konopie indyjskie, narkotyczne środki znieczulające (przeciwbólowe), środki nasenne, środki pobudzające oraz środki halucynogenne. Środki te pogrupowano według ich somatycznego, psychologicznego i behawioralnego oddziaływania, według ich toksyczności oraz stopnia tolerancji organizmu na ich działanie.
Zanim opiszemy pokrótce poszczególne kategorie tych środków oraz niektóre skutki ich oddziaływania na psychikę, warto podkreślić, że doznania szczytowe osoby zażywającej ich w wyjątkowych wypadkach lub eksperymentującej z tymi środkami mogą blaknąć przy ich wielokrotnym nałogowym zażywaniu. Również te skutki, które wywołuje dany środek wtedy, gdy przyjmuje się go podczas jakiegoś religijnego czy społecznego obrzędu, nie wystąpią prawdopodobnie wówczas, gdy przyjmuje się go „szybko i łatwo” dla polepszenia nastroju lub uspokojenia nerwów.


Tytoń. Aktywnym składnikiem jest w nim nikotyna. Tytoń pali się w postaci papierosów i cygar oraz w fajkach; jest on również używany do żucia. Małe dawki pobudzają autonomiczny układ nerwowy, natomiast duże dawki działają nań pobudzająco. Tytoń ma dużą zdolność wywoływania uzależnienia psychicznego, tolerancja na jego działanie rozwija się w stopniu umiarkowanym, a stałe jego używanie powoduje nieodwracalne uszkodzenie płuc, serca oraz naczyń krwionośnych.


Alkohol. Alkohol etylowy jest powszechnie używany jako napój. Ogólnie biorąc, alkohol poraża ośrodkowy układ nerwowy. Mała dawka powoduje odprężenie i ułatwia pozbycie się zahamowań. Zwiększona dawka prowadzi do upośledzenia zdolności oceniania, utraty koordynacji ruchowej, zwiększonej agresywności, gwałtownych zachowań i zmniejszonej kontroli nad emocjami.  Jeszcze większe dawki powodują poważne zatrucie i wreszcie ogólną utratę czucia, śpiączkę, porażenie układu oddechowego i śmierć. Alkohol charakteryzuje się dużą zdolnością wywoływania psychicznego i fizjologicznego uzależnienia, a także powoduje nieodwracalne uszkodzenia tkanek w takich narządach, jak mózg i wątroba. Objawy występujące po odstawieniu alkoholu u nałogowych alkoholików są bardzo poważne i trudne do wyleczenia bez długotrwałych intensywnych i skoordynowanych oddziaływań terapeutycznych.


Konopie indyjskie. Grupa ta obejmuje marihuanę, która jest mieszaniną liści, łodyg, kwiatów i nasion |konopi |indyjskich („Cannabis indica”), oraz silniej działający haszysz - żywiczny wyciąg z marihuany. Wydaje się, że jednym z „ubocznych skutków” - wypraw krzyżowych chrześcijan przeciwko mahometanom (1096-1270) było zapoznanie świata zachodniego z konopiami indyjskimi. (Dla niektórych żołnierzy amerykańskich tę samą rolę w procesie przekazywania międzykulturowego odegrała wojna w Wietnamie). Konopie indyjskie były stosowane w wielu wschodnich kulturach jeszcze przed narodzeniem Chrystusa, a w Indiach używa się ich od przeszło tysiąca lat - zarówno jako środka odurzającego, jak i pomocy w medytacjach (Blum, 1969).
Marihuana ma jedynie umiarkowaną zdolność wywoływania uzależnienia psychicznego, zaś jej stosowanie nie wywołuje uzależnienia fizjologicznego.  Wyniki wstępnych badań nie wskazują na powstawanie trwałych schorzeń na skutek jej używania, zaś dawka śmiertelna jest w zasadzie nieosiągalna.  Mechanizm chemiczny, który nadaje marihuanie jej odurzające właściwości, nie jest jeszcze dobrze poznany.
Przed kilkudziesięciu laty, kiedy marihuanę zażywali głównie muzycy, artyści i mieszkańcy getta, podawano, że wywołuje ona stany niezwykłej euforii, ekstazę i podobne do snów fantazje, potęguje zdolności twórcze i możliwości seksualne, a niekiedy przyprawia ludzi o szaleństwo. Obecnie, w latach siedemdziesiątych, gdy jej stosowanie nie jest już właściwie ograniczone żadnymi klarownymi, rasowymi, edukacyjnymi ani innymi demograficznymi barierami, marihuana stała się używką o charakterze towarzysko-rozrywkowym, od której oczekuje się raczej łagodnie przyjemnych, „spokojnych” skutków. Nie spotyka się już dawnych, przesadnych twierdzeń.
Marihuana zażywana w niewielkich ilościach wywołuje stan odurzenia bardzo podobny do stanu będącego skutkiem użycia alkoholu, powodując odprężenie i zmniejszenie zahamowań; wielu badaczy sądzi jednak, że marihuana w mniejszym stopniu wywołuje skłonności agresywne. Niektóre osoby zażywające ten środek donoszą o zwiększeniu swej zdolności koncentracji, inne o jej zmniejszeniu. Niektórzy uważają, że marihuana pobudza seksualnie, inni - przeciwnie. Zachowanie pod wpływem marihuany, w większym stopniu niż w wypadku innych środków psychotropowych, jest uzależnione od czynników społecznych i osobowościowych. Większe dawki mogą wywoływać następstwa podobne do skutków zażycia środków psychodelicznych - występuje zniekształcone poczucie czasu oraz pojawiają się nowe wymiary w percepcji.  Jednakże ten zmieniony stan świadomości można w większym stopniu kontrolować i na ogół jest on mniej intensywny, chociaż w wypadku wysokich dawek mogą wystąpić stany paniki oraz upośledzenie oceny i koordynacji ruchowej.


Środki narkotyczne o działaniu przeciwbólowym. Grupa ta zawiera opium, jego pochodne (na przykład morfinę i heroinę) oraz pewne środki syntetyczne. Narkotyki działają na ośrodkowy i parasympatyczny układ nerwowy i są stosowane w lecznictwie dla złagodzenia bólu. Swój wpływ przeciwbólowy wywierają one w dwojaki sposób. Po pierwsze, powodują podniesienie progów bólu, tak że potrzebny jest silniejszy bodziec, aby został on uznany za bolesny; po drugie, zmieniają one psychiczną reakcję na ból. Dana jednostka staje się obojętna na ból, chociaż zdaje sobie z niego sprawę. Występuje także poczucie ogólnej euforii, które towarzyszy (lub jest wynikiem) obojętności na troski osobiste i sprawy otoczenia. Występuje zmniejszenie popędu seksualnego, głodu i pragnienia.
Szybko rozwija się |tolerancja na ten środek (proces homeostatyczny, w wyniku którego skutki użycia danego środka zostają osłabione pod wpływem jego wcześniejszego zażywania) i występuje silne uzależnienie fizjologiczne i psychiczne. Narkotyk może być zażywany mimo braku jakichkolwiek przyjemnych skutków, jedynie dla uniknięcia traumatycznych symptomów powodowanych jego brakiem. Narkotyki nie powodują chronicznego uszkodzenia tkanek, lecz w początkowym okresie ich zażywania realnym niebezpieczeństwem jest śmierć w skutek przedawkowania. Przedawkowanie heroiny zdarza się często, ponieważ w nieuregulowanej sprzedaży ulicznej procent czystej heroiny, jak również chemicznych zanieczyszczeń, może zmieniać się w znacznym stopniu. Heroina jest głównym powodem śmierci Amerykanów w wieku od 18 do 25 lat, wyprzedzając pod tym względem wypadki, samobójstwa i raka (Smith i Gay, 1971).


Środki nasenne. Grupa ta zawiera barbiturany oraz niektóre środki.  Działają one przede wszystkim na ośrodkowy układ nerwowy, wywołując stan ogólnego zahamowania aktywności nerwowej.



Środki te są stosowane w medycynie jako środki uspakajające - w celu złagodzenia lęku i wywołania snu. Zażywanie środków nasennych powoduje senność, euforię, oszołomienie, brak koordynacji ruchowej, utratę pamięci i upośledzenie oceny, a wreszcie może doprowadzić do zwolnienia czynności oddychania, utraty świadomości, śpiączki i śmierci. W wypadku stałego ich stosowania rozwija się tolerancja, jak również uzależnienie fizjologiczne.  Środki te cechuje również wysoka zdolność wywoływania uzależnienia psychicznego.
Środki nasenne hamują aktywność nerwową. Z tego powodu wywoływane przez nie zmiany w sposobie przeżywania rzeczywistości polegają raczej na zobojętnieniu niż na wzmożonej świadomości. W dawkach terapeutycznych środki nasenne czy kojące są zadziwiająco skuteczne w selektywnym redukowaniu zachowania motywowanego przez lęk. Wywierają one również działanie hamujące i podobnie jak alkohol powodują lekko euforyczne oszołomienie, utratę zahamowań i sen. Uwalniają one od napięcia i niepokoju, dają poczucie odprężenia i wywołują dobry nastrój.


Środki pobudzające. Do kategorii tej należą amfetamina, metamfetamina (zwane „przyspieszaczami”), kokaina oraz kofeina (znajdująca się w kawie, herbacie oraz orzeszkach kola). Środki tego rodzaju pobudzają ośrodkowy układ nerwowy i wywołują wzrost ożywienia, czujności, aktywności oraz przyjemne odczucia, jak również zmniejszają apetyt. Amfetaminę w małych dawkach przepisuje się niekiedy jako „pigułki odchudzające”, z wątpliwymi zresztą rezultatami.
Środki pobudzające, takie jak metamfetamina, początkowo zmniejszają wrażliwość na uczucia innych i wywołują poczucie zwiększonych własnych możliwości, własnej nietykalności i siły. Jednakże większe dawki powodują nadwrażliwość, niepokój, paranoidalne lęki oraz halucynacje słuchowe.  Szybko wytwarza się wysoki stopień tolerancji na te środki, które łatwo wywołają również uzależnienie psychiczne; dla uzyskania pożądanych efektów trzeba wówczas przyjmować dożylnie duże ich dawki. Jednakże tych pożądanych efektów nie można długo utrzymać. Osoba używająca tych środków szybko zaczyna ich nadużywać.




Zbliżenie


Ludzie-kwiaty i wolna klinika w Haight-Ashbury


„David Smith, kierownik kliniki dla narkomanów w słynnej niegdyś dzielnicy San Francisco, Haight-Ashbury, opisuje nam swymi własnymi słowami ruch „ludzi-kwiatów”, który „wybuchnął” na scenie narkomanii w latach sześćdziesiątych. Jego klinika powstała jako medyczna, społeczna i psychologiczna reakcja na skutki tego ruchu.
„W okolicach zatoki San Francisco rozwinęło się szeroko rozpowszechnione przekonanie, że LSD i „rozszerzona” świadomość wprowadzają człowieka w to, co określano jako |kontrkulturę - kulturę, której poglądy były przeciwne do dominującej w Stanach Zjednoczonych idei kultury „wyższych klas”.  Kontrkultura kładła nacisk na miłość i pokój, negowała sens materialnego bogacenia się, koncentrowała się raczej na doznawaniu niż na racjonalnej myśli oraz odchodziła od destrukcyjnych sił, takich, jak wojna, skażenie środowiska, eksploatowanie mniejszości itp. Hipis był produktem tej wczesnej psychodelicznej subkultury, podobnie jak różne inne „wytwory”, które wywarły znaczny wpływ na nasze społeczeństwo, takie jak ostra muzyka rockowa, widowiska oddziałujące na wiele zmysłów oraz nasz język, w którym powstały takie słowa, jak „włączyć się”, „dostroić się”, „odpaść”, „robić swoje” itd. Zasadnicza filozofia polegała na tym, aby „odpaść” od dominującego systemu wartości społeczeństwa, „włączyć się” w zażywanie psychodelicznych środków chemicznych, „rozszerzyć” swoją świadomość i „dostroić się” do nowej filozofii.
Niestety, ogromna liczba młodych ludzi stłoczyła się na małej przestrzeni w San Francisco, w dzielnicy Haight-Ashbury, którą zaczęto uważać za stolicę świata hipisów. Wielu z młodych ludzi, którzy tam przybyli, było zupełnie zaburzonych psychicznie; inni byli naiwni i nie rozumieli stylu życia, do którego się przyłączyli. Zaczęli oni eksperymentować z najróżnorodniejszymi narkotykami, często zażywając LSD zupełnie bez rozeznania. Jeszcze bardziej destrukcyjne było to, że zaczęli oni w coraz większym stopniu wciągać się w zażywanie narkotyków o większym stopniu szkodliwości, a zwłaszcza amfetamin, czyli „przyspieszaczy” („speed”).
(...) Gdy Haight-Ashbury stało się „dzielnicą przyspieszaczy”, dokonywano w niej mnóstwa gwałtów i aktów przemocy. Opuściły ją prawdziwe, spokojne „dzieci-kwiaty”, pozostały zaś bardziej destrukcyjne jednostki. Osobnicy ci często zażywali środki uspakajające dla uciszenia swych nerwów. W rezultacie w Hashbury (Haszyszowie) dominują obecnie młodzi narkomani zażywający nałogowo heroinę, spośród których wielu zażywało uprzednio amfetaminy, a wielu zaczęło zażywać heroinę jako „obniżacza” („downer”) stanów napięcia.
Jednakże młodzi ludzie, którzy opuścili te dzielnicę, nie zawsze udawali się do domu czy powracali do swego poprzedniego środowiska, lecz często tworzyli komuny, czy to w mieście czy też na wsi. Wielu z nich próbowało „rozszerzać” swą świadomość bez zażywania narkotyków; inni nadal zażywali psychodeliczne chemikalia, aby utrzymać ten stan świadomości, który uznawali za tak wartościowy. W naszych badaniach stwierdziliśmy, że komuny, które przejęły bardziej stabilną strukturę rodzinną i powstrzymywały się od zażywania narkotyków, są zdrowsze i mają większe szanse przetrwania. W komunach nadal zafascynowanych narkotykami istnieją znacznie mniejsze szanse zapewnienia młodym ludziom i ich dzieciom właściwych warunków życia” (Smith, 1971, ss. 683-684).


Po kilku tygodniach czy miesiącach stosowania środków tego typu kształtuje się typowy wzorzec zachowania. Osoba używająca ich wstrzykuje duże dawki środka kilka razy dziennie (bezpośrednio po zastrzyku występuje intensywne uczucie określane jako „rausz”, którego brak odczuwa się później bardzo silnie) i pozostaje bez snu przez trzy do sześciu dni. W tym czasie osoba ta staje się bardziej napięta i niespokojna. Ten „kurs” („run”) kończy się przerwą w postaci głębokiego snu (określanego jako „załamanie” lub „krach” - „crashing”), który może trwać dzień lub dwa. Po obudzeniu się osoba ta jest tak rozdrażniona, że wydaje się to irracjonalne osobom nie zażywającym tego rodzaju środków. Jest to często uczucie bardzo przykre i osoba zażywająca środki pobudzające może rozpocząć nowy „kurs” lub przedłużyć go w celu uniknięcia tego uczucia.
Takie cykliczne następowanie po sobie „kursów” i „załamań” może powtarzać się przez kilka miesięcy. Ludzie używający „przyspieszaczy” nie mogą dobrze funkcjonować w zwykłym świecie. Opisany tu wzorzec zachowania, agresywność, paranoja i drażliwość sprawiają, że takiemu człowiekowi trudno jest utrzymać pracę czy nawet mieć normalnych „prostych” przyjaciół.
Okres nadużywania metamfetaminy mogą być przerywane okresami fizycznego czy psychicznego załamania lub konfliktów z prawem, mogą też zakończyć się śmiercią. Osoba nadużywająca metamfetaminy może zacząć wstrzykiwać sobie heroinę lub barbiturany („obniżacze”), aby złagodzić symptomy paranoi i lęk, którego często doświadcza wtedy, gdy zażyła zbyt wiele „przyspieszacza”. Mieszaninie różnych środków, zmiana uzależnień jeszcze bardziej komplikują problemy osoby nadużywającej tych środków.


Środki halucynogenne. Do środków halucynogennych, czyli psychodelicznych, zalicza się LSD-25, psylocybinę („magiczny grzyb”), meskalinę oraz DOM (STP; 2,5-dimethoxy-4-methylamphetaminę - przyp. red.), Chemiczny mechanizm ich oddziaływania nie jest w pełni poznany, lecz oddziałują one przede wszystkim na ośrodkowy układ nerwowy i zapewne zakłócają działanie filtrujących mechanizmów w mózgu (Shulgin, 1969). Środki tego typu bardzo przypominają pewne naturalne związki chemiczne odgrywające istotną rolę w różnych stadiach przewodzenia impulsów nerwowych. Środki halucynogenne mogą blokować działanie tych związków chemicznych lub zastępować je (Seiden, 1970).
Środki halucynogenne wywołują głębokie i specyficzne zmiany w percepcji, powodując większą wrażliwość na wszelkiego rodzaju bodźce (wzrokowe, słuchowe, dotykowe itd) oraz większa wrażliwość emocjonalną. Wywołują one także poczucie „bezczasowości”. W rzadkich przypadkach mogą one powodować reakcje psychotyczne.
Środki te powodują (po upływie 4 do 5 dni) wytworzenie się całkowitej tolerancji, która równie szybko zanika; nie powstaje uzależnienie fizjologiczne. Mają one również niewielką zdolność wywoływania uzależnienia psychicznego. Nie ma żadnych istotnych dowodów wskazujących, że środki te mogą powodować uszkodzenie mózgu czy jakichkolwiek tkanek (Irvin, 1971; 
Harvey, 1971).
Środki halucynogenne, czyli psychodeliczne, mają najsilniejsze działanie ze wszystkich środków wpływających na psychikę. Określenie „halucynogenne” nie jest całkowicie ścisłe, ponieważ po użyciu tych środków spostrzeżenia mają jednak pewne podłoże fizjologiczne. Używanie środków psychodelicznych rzadko powoduje rzeczywiste halucynacje. Częściej występują wyraźne zmiany w spostrzeganiu i interpretacji spostrzeżeń oraz pseudohalucynacje, w których dana jednostka zniekształca spostrzeżenia oraz wiąże z nimi inne znaczenia i obrazy, lecz zdaje sobie sprawę z ich rzeczywistego podłoża. Na przykład ściany mogą „roztapiać się” lub brązowa piana może wypełzać z rur, lecz ściany i rury znajdują się tam rzeczywiście i osoba będąca pod wpływem środka psychodelicznego zwykle zdaje sobie sprawę z tego, że występuje pewne zniekształcenie percepcji.
„Oddziałujące na psychikę” („psychoactive”) - to istotnie dobre określenie dla LSD i innych środków psychodelicznych. Różnorodność efektów jest oszałamiająca. Istnienie wydaje się bardziej interesujące. Może pojawić się poczucie „bezczasowości”, przez co minuta wydaje się godziną, a przeszłość, teraźniejszość i przyszłość wydają się jednym i tym samym.  Bodźce wszelkiego rodzaju mogą wydawać się przytłaczające; bodźce jednego rodzaju mogą być spostrzegane w innych postaciach, na przykład muzykę można oglądać w postaci fal zdumiewająco żywych barw. Można mieć doznania mistyczne. Pojęcia i wrażenia, które normalnie uważa się za paradoksalne, mogą wydawać się zadziwiająco zgodne ze sobą - czarne może być białym, życie i śmierć mogą istnieć wspólnie, można dostrzegać głębokie znaczenie w tym, co normalnie uważa się za banalne, kwiat może wydawać się kluczem do egzystencji.
Subiektywne opisy psychodelicznych przeżyć można podzielić na takie, które dotyczą przede wszystkim doznań zmysłowych, oraz na opisy wspomnieniowo-analityczne bądź integralne (Masters i Houston, 1966). Na poziomie sensorycznym odrzuca się utrwalone pojęcia i występuje zazwyczaj zmieniona czy „podwyższona” świadomość spostrzegania. Na poziomie wspomnieniowo-analitycznym zostają osłabione nawykowe interpretacje siebie samego, relacji względem innych oraz wspomnienia minionych doświadczeń.  Dana osoba może osiągnąć nowe rodzaje wglądu. Może nadawać nowe interpretacje mitom i symbolom. Na poziomie integralnym mogą wystąpić objawienia religijne lub doświadczenia mistyczne. Umysł danej osoby może błądzić z jednego poziomu na drugi, pozostając na nich w zależności od bodźców, osobowości i nastroju oraz ogólnych warunków.
Dla zilustrowania tych poziomów reagowania przytaczamy sporządzony przez obserwatora opis doświadczenia z użyciem środka psychodelicznego:


„Watts słuchał muzyki organowej i opisywał swoje doznania. „Każdy dźwięk zdaje się wychodzić z ogromnej gardzieli ludzkiej wilgotnej od śliny””.  Wrażenie na poziomie sensorycznym. Na poziomie analizy wspomnień może on „słyszeć księdza przebierającego specyficzny ton, słyszeć (...) namaszczony głos tego mistrza zwodzenia””. Lecz na symbolicznym poziomie doświadczenia głos księdza staje się „pierwotnym wyciem dzikiej bestii w dżungli””. W końcu na integralnym poziomie doświadczenia psychodelicznego pojawia się świadomość mistyczna i Watts oznajmia: „Mogę usłyszeć w tym jednym głosie równoczesną obecność całej historii człowieka oraz wszystkich form życia przede mną”” (Krippner, 1970, s. 41)


Przekształcenie działania takich środków, jak LSD, meskalina i peytol w doznania religijne, występujące w plemionach Indian amerykańskich na południowym zachodzie Stanów Zjednoczonych i w Meksyku, jest prawie niemożliwe do osiągnięcia w warunkach laboratoryjnych. Jednakże u badanych można wywoływać psychodeliczne, „transcendentalne” reakcje, jeśli oddziaływanie środka farmakologicznego uczyni się częścią ogólnego „religijnego” doświadczenia. Dokonano tego w opisanych poniżej niezwykłych i fascynujących badaniach (Pahnke, 1963, 1967).


„Czterdziestu studentów teologii przygotowywało się do doświadczenia z środkami farmakologicznymi najpierw przez uczęszczanie na spotkania „indoktrynacyjne”” na temat potencjalnych możliwości przeżyć religijnych.  Następnie połowa z nich otrzymała 30 tysięcy mikrogramów psylocybiny, przed wzięciem udziału w długotrwałym nabożeństwie wielkopiątkowym. Nabożeństwo to składało się z modlitw, pieśni, muzyki oraz medytacji. Pozostałych badanych przydzielono losowo do grupy kontrolnej, w której otrzymali oni aktywne placebo - kwas nikotynowy, który wywołuje wrażenie ciepła i mrowienia. Połączono tu zatem wpływ nastawienia, warunków oraz historii życia osób otrzymujących środek farmakologiczny w celu zmaksymalizowania religijnej interpretacji reakcji psychodelicznych.
W szczególnym kwestionariuszu, wypełnianym bezpośrednio po tym doświadczeniu, osoby w grupie otrzymującej psylocybinę opisywały znacznie więcej mistycznych „transcendentalnych” doznań, niż osoby w grupie kontrolnej otrzymującej placebo. Różnice te utrzymały się także w uzupełniającym wywiadzie przeprowadzonym 6 miesięcy później”.




Warunki wpływające
na efekty działania
środków farmakologicznych




Mógłbyś sądzić, że przyjęcie pewnej ilości jakiegoś środka farmakologicznego powinno mieć możliwy do przewidzenia efekt. Tymczasem sprawa przedstawia się inaczej. Przynajmniej pięć warunków, występujących przed zażyciem środka farmakologicznego lub w czasie jego zażywania, ma wpływ na jego działanie: skład chemiczny i dawka środka, stopień wytworzonej tolerancji na ten środek, „nastawienie” osoby przyjmującej ten środek, cechy osobowości danej jednostki oraz społeczno-psychologiczna sytuacja, w której przyjmowany jest ten środek.


Skład chemiczny i dawka. Najbardziej oczywistymi wyznacznikami reakcji na pewien środek farmakologiczny jest oczywiście skład chemiczny tego środka oraz wielkość dawki. Związek miedzy dawką i reakcją na dany środek można ustalić empirycznie, wytyczając krzywą, która obrazuje związek pomiędzy dawką a poziomem danej reakcji. Taką funkcję określającą związek między |dawką |a |reakcją można wyznaczyć dla danej |jednostki, lecz traci to sens, gdy łączy się ze sobą dane dotyczące wielu osób. Badania wykazały, że skutki środków farmakologicznych różnią się w zależności od wagi ciała oraz od szybkości, z jaką dany środek jest wchłaniany, rozkładany i wydalany, przy czym szybkości te mogą być różne u różnych osób. Tę samą reakcję można zatem wytworzyć u dwóch ludzi dając im różne dawki, a ta sama dawka może wywoływać różne reakcje (Klee i in., 1961).
LSD jest szczególnie interesujące pod względem farmakologicznym, ponieważ pewna część jego składu chemicznego przypomina serotoninę, związek chemiczny, który odgrywa kluczową rolę w przekazywaniu impulsów w ośrodkowym układzie nerwowym. Prowadzi się obecnie badania mające wyjaśnić, na czym polega związek między LSD i serotoniną. Inną godną uwagi właściwości LSD jest to, że minimalne ilości tego środka wywierają wyraźny skutek. Przeciętna dawka doustna LSD, która wywołuje wyraźny efekt psychiczny, wynosi od 100 do 350 mikrogramów (jeden mikrogram stanowi tylko jedną milionową część grama). Trzeba by około 30 tysięcy mikrogramów psylocybiny i ponad 35 tysięcy mikrogramów meskaliny, aby uzyskać efekt o podobnej intensywności.


„W pewnym dobrze kontrolowanym badaniu lekarze występujący w roli obserwatorów potrafili bezbłędnie określić, kiedy każdy z 12 badanych przyjął 1, 2, 4, 8, lub 16 mikrogramów LSD (na kilogram wagi ciała). W eksperymencie tym zastosowano tak zwaną podwójnie ślepą procedurę, w której zarówno trzej obserwatorzy, jak i badani nie wiedzieli, jaką dawkę LSD podano w danym czasie. U każdej osoby badanej każda kolejna wyższa dawka wywoływała wyraźnie większe upośledzenie funkcjonowania intelektualnego, roztargnienie oraz doznania wzrokowe i somatyczne. Gdy jednak obserwowano badanych w grupach, wówczas obserwatorzy nie potrafili określić na podstawie ich zachowania, którzy z nich otrzymali większą, a którzy mniejszą dawkę. Najwyraźniej w warunkach grupowych różnice w zachowaniu poszczególnych badanych nie wynikają jedynie z wziętej dawki, lecz odzwierciedlają także wpływy zmiennych społecznych (Klee i in. 1961).


Wytwarzanie tolerancji na dany środek. Uprzednie zażywanie danego środka przez jednostkę może wpływać na obecne oddziaływanie tego środka.  |Tolerancja, jak już wspominaliśmy poprzednio, oznacza proces, dzięki któremu oddziaływanie danego środka jest słabsze wskutek tego, że był on uprzednio przyjmowany.
Wiadomo, że istnieją trzy typy mechanizmy tolerancji (poznane w różnym stopniu). Po pierwsze, może wzrastać tempo w jakim organizm dezaktywizuje dany środek, dzięki czemu skutki zażycia tego środka są mniej długotrwałe.  Po drugie, komórki układu nerwowego mogą zaadaptować się do obecności tego środka, a zatem nie reagować nań w tym samym stopniu, jak początkowo.  Istnieje wreszcie pojecie tolerancji behawioralnej, dzięki której dany środek może stracić swój wpływ na określone zachowanie. Dla zilustrowania działania tego hipotetycznego mechanizmu przytaczamy opis eksperymentu dotyczącego wpływu amfetaminy na tempo naciskania dźwigni przez szczury.


„Gdy za pomocą stosowania odpowiedniego rozkładu wzmocnienia ustalono stałe, wolne tempo reagowania, wówczas początkowy efekt zastosowania pewnej dawki amfetaminy polegał na znacznym zwiększeniu tego powolnego tempa reagowania. Jednakże po wielokrotnym powtarzaniu tej dawki tempo reagowania powróciło do poziomu sprzed zastosowania amfetaminy. Zjawiska tego nie można było wyjaśnić w kategoriach wytworzenia się ogólnej tolerancji.  Wydaje się, że dostępność wzmocnienia przy wolniejszym tempie naciskania dźwigni pozwoliła zwierzętom nauczyć się opanowywania niekorzystnych skutków działania środka farmakologicznego, dzięki czemu osiągnęły one pewien rodzaj tolerancji behawioralnej” (Harvey, 1971).


Dany środek farmakologiczny może mieć wieloraki wpływ na organizm, a wytworzona tolerancja może nie dotyczyć w tym samym stopniu wszystkich jego skutków. Na przykład, narkotyki wywołują senność, zmniejszoną zdolność koncentracji, euforię, poczucie „oderwania” („detachment”), redukcję głodu, pragnienia oraz popędu seksualnego, uczucie ciążenia członków, mrowienia, zaparcie, mdłości oraz zwężenie źrenic. W odniesieniu do większości tych skutków może wytworzyć się taki stopień tolerancji, że dawki przekraczające znacznie śmiertelną uprzednio dawkę można stosować nie wywołując w efekcie żadnych następstw przyjemnych ani przykrych, z wyjątkiem zaparcia i zwężenia źrenic, które mogą występować w takim samym mniej więcej stopniu jak poprzednio.


Zbliżone środki farmakologiczne mogą także wywoływać zjawisko znane pod nazwą |tolerancji |krzyżowej („cross tolerance”). Oznacza to, że środki te są na tyle podobne do siebie, że mogą zastępować się nawzajem. Ich skutki i działanie są takie same; toteż tolerancja wytworzona pod wpływem jednego środka generalizuje się, tłumiąc również działanie innego środka. Na przykład, osoba zażywająca nałogowo heroinę ma także tolerancję na morfinę, ponieważ oba te środki zaliczają się do narkotyków; wielokrotne stosowanie LSD wytwarza tolerancję na meskalinę i psylocybinę. Prowadzi się badania naukowe nad mechanizmami fizjologicznymi, powodującymi powstawanie tolerancji krzyżowej, aby wykryć, w jaki sposób funkcje metaboliczne dróg układu nerwowego oraz poszczególnych okolic mózgu umożliwiają zastępowanie jednego środka farmakologicznego drugim.
Zjawisko tolerancji powoduje, że narkomani muszą nieustannie zwiększać dawki narkotyku lub częstość jego przyjmowania. Dzieje się tak, jak gdyby popyt był zawsze większy niż podaż, a ponadto - co czyni sytuację nieznośną - gdy uzyska się potrzebną ilość danego środka, to nie wystarcza on do wywołania takiego efektu, jak przedtem. Powoduje to nie tylko eskalację nadużywania tych środków, lecz także frustrację, lęk oraz eksperymentowanie z wszelkimi środkami, które mogłyby spowodować pożądane efekty.


Oczekiwania osoby zażywającej dany środek. Postawy, oczekiwania i motywy dotyczące całości doświadczeń związanych z zażywaniem danego środka wpływają na to, jakie to będą doświadczenia. Wiedza o tym, dlaczego ludzie przede wszystkim przyjmują dany środek, pomaga przewidzieć, czy skutkiem jego zażycia będzie euforia, lęk, religijne doznanie transcendencji czy inne doznania. Osoby zażywające środki psychotropowe znajdują w nich w pewnym stopniu to, czego szukają.
Wpływ zażycia LSD przez osoby biorące udział w eksperymencie nie jest na ogół tak głęboki, jak wtedy, gdy (w takiej samej dawce) zażywają go (w samotności lub wspólnie z przyjaciółmi) osoby pragnące „rozwinąć swoją osobowość” lub osoby poszukujące doznań estetycznych czy przeżyć religijnych. Na odczuwanie działania środków psychotropowych wpływa ponadto przeżywanie obaw dotyczących prawnych, medycznych, społecznych i behawioralnych konsekwencji zażywania tych środków.


„Pewien 34-letni nieżonaty, ciężko pracujący, biały mężczyzna, pełniący funkcję prezesa niewielkiej, lecz szybko rozwijającej się spółki, miał wiele obowiązków. Był on dobrze ubrany, jeździł samochodami doskonałych marek, miał własny samolot i stosował się do wymagań roli dziarskiego, wielkomiejskiego kawalera. Regularnie używał alkoholu, uczęszczał na wiele cocktail parties i palił dużo papierosów - około dwóch paczek dziennie. Pod wpływem namowy kolegów i z ciekawości zdecydował się spróbować palenia marihuany. Wypalił wspólnie z dwoma innymi osobami jeden papieros z marihuany; następnie wszyscy poszli na kolację. W trakcie rozmowy zauważył, że zapomniał tego, co powiedział przed chwilą, czym bardzo się zdenerwował.  Jego niepokój wzrastał, ponieważ czuł, że traci panowanie nad sobą; powiedział później, iż było to uczucie, jakie się ma - jego zdaniem - wtedy, gdy traci się rozum. Pozostałe dwie osoby, które wypaliły w przybliżeniu tę samą dawkę, bawiły się bardzo dobrze i nie wystąpiły u nich żadne przykre objawy. Jednakże on sam popadł w taką panikę, że musiano zabrać go do domu i dać mu środek uspakajający. Gdy wyspał się dobrze, nie odczuwał już żadnych dolegliwości, lecz swoje doświadczenie z marihuaną opisywał jako wyjątkowo nieprzyjemne i stwierdził, że o wiele bardziej woli alkohol. Późniejsze wywiady wykazały, że jednym z jego głównych zmartwień była obawa, że będąc pod wpływem marihuany zostanie zaaresztowany” (Smith i Mehl, 1970, s. 71).


Po dokonaniu przeglądu wyników badań dotyczących związku między oczekiwaniami osób badanych, dawką LSD oraz działaniem tego środka, Theodore Barber doszedł do wniosku, że „(...) co najmniej jedna trzecia wariancji reakcji na stosunkowo małą dawkę LSD (25-100 mikrogramów) jest niezależna od tego środka |jako |takiego i związana jest z czynnikami, które determinują reakcję na placebo, takimi, jak oczekiwania osób badanych co do skutków, jakie prawdopodobnie wystąpią” (1970, s. 17).


Mówiąc o zależności pomiędzy zmiennymi fizyczno-biologicznymi a psychologicznymi, trzeba podkreślić, że zmienne psychologiczne wpływają stosunkowo mniej na zachowanie wtedy, gdy zmienne fizyczne stają się silniejsze, większe, bardziej intensywne. Gdy silnie działające środki są podawane w dużych dawkach lub przyjmowane bez świadomości ich zamierzonych skutków, wówczas wpływają one na percepcję, myślenie, poczucie czasu i stabilność emocjonalną bez względu na sytuację psychologiczną i społeczną.


Cechy osobowości. W pewnym stopniu również cechy osobowości osoby zażywającej dany środek wpływają na skutki jego zażycia. W badaniach nad działaniem środków farmakologicznych stwierdzono, że zarówno ogólna intensywność reakcji, jak i ich jakości, wiążą się ze zmiennymi osobowościowymi osób badanych.


„Gdy osoby badane przyjmowały umiarkowane dawki LSD w standardowych warunkach (po wykonaniu baterii testów osobowości), wówczas ich zachowanie, zarówno obserwowane, jak i opisywane przez nich samych, było w istotny sposób związane z wynikami uzyskanymi przez nie w testach. Osoby, które najsilniej zareagowały na LSD, uzyskały wyniki świadczące o większej wrażliwości estetycznej, wyobraźni, skłonności do życia nieuporządkowanego, spontanicznego, „skierowanego do wewnątrz”, jak również o niskim stopniu agresji, rywalizacji i konformizmu. Osoby, na które LSD wywarł najmniejszy wpływ, uzyskiwały wyższe wyniki w testach mierzących dogmatyzm, sztywność oraz potrzebę kontroli” (McGlothlin, Cohen i McGlothin, 1967).


Inne badanie wykazało że istnieje związek między wynikami w testach osobowości przeprowadzonymi przed podaniem LSD a doświadczaniem lub niedoświadczaniem przez daną jednostkę uczuć wrogości i reakcji paranoidalnych w trakcie posiedzeń, w których znajdowała się ona pod wpływem tego środka (Linton i Langs, 1964).


Sytuacja społeczna. Środki psychotropowe zawsze przyjmuje się w takim lub innym środowisku społecznym - czy to jałowym i nudnym, jak w szpitalu, czy też w wesołym i podniecającym, jak na przyjęciu. Środki te są przyjmowane w obecności innych ludzi lub w samotności, wobec przyjaciół lub obcych, wobec ludzi, których uważa się za sympatycznych lub wrogich, ciekawych lub obojętnych. Zmienne społeczne, które łącznie stwarzają kontekst wewnętrzny, w jakim przyjmuje się tego rodzaju środki, mogą należeć do najważniejszych wyznaczników decydujących o wpływie danego środka na nastroje i emocje zażywającej go osoby.
Gdy eksperymentatorzy są przyjaźni i odprężeni oraz przekonani o wartości terapeutycznej testowanego środka farmakologicznego, wówczas stworzą oni środowisko społeczne, które prawdopodobnie uczyni osoby badane podatnymi i otwartymi na nowe doświadczenie. Z drugiej strony, gdy badacze są chłodni i bezosobowi, traktują osobę badaną jak „królika doświadczalnego” i oczekują, że środek psychodeliczny doprowadzi do dziwacznego, quasi-psychotycznego zachowania, wówczas będą oni zachowywać się w taki sposób, który sprzyja wystąpieniu u badanych podejrzliwości, lęku oraz innych negatywnych reakcji na doświadczenia z tym środkiem (Unger, 1963). Przyjmowanie środków tego rodzaju w samotności, zamiast w grupie, częściej prowadzi do lęku i depresji (Slater, Morinoto i Hyde, 1957).
Sytuacja społeczna nie odgrywa tak ważnej roli dla osoby zażywającej regularnie narkotyk, jak dla nowicjusza zażywającego go po raz pierwszy, który może używać tego środka dla „rozrywki” lub w celu pozanaukowym.  Oddziaływanie społeczne grupy nie tylko uspokaja zapewniając aprobatę dla danego działania, lecz pomaga także określić, jakie są „właściwe” procedury oraz ustanowić punkty porównawcze, dzięki którym osoba zażywająca dany środek może zidentyfikować i określić to, czego doświadcza oraz stwierdzić, jak dalece jest to „normalne” (Becker, 1967). Taki wpływ grupy na jednostkę nie ogranicza się oczywiście do sytuacji związanych z zażywaniem narkotyków, lecz odgrywa szczególnie ważną rolę wtedy, gdy dana osoba ma wejść w nową, wieloznaczną sytuację, w której nie ma żadnych obiektywnych wskazówek, a danej osobie bardzo zależy na wyniku („chcę, żeby to działało”, „chce być w porządku” itd.).
Podkultura osób zażywających narkotyki w dużych ilościach pozwala nam w nowy sposób spojrzeć na skutki stosowania i nadużywania danego środka.  Głównie dlatego, iż narkotyki są nielegalne, ich ceny są niezwykle wysokie - lecz gdy raz wpadnie się w nałóg, wysokość ceny nie ma znaczenia; narkoman („doper”) musi mieć swoją dawkę. Ze względu na coraz większe zapotrzebowanie, wynikające z rozwijającej się coraz bardziej tolerancji, dzienny koszt nałogowego zażywania heroiny może osiągnąć 200 dolarów lub więcej.
W jaki sposób ktoś może zdobyć 1400 dolarów tygodniowo na tylko ten jeden wydatek? Z pewnością nie uczciwą pracą. Do wyboru jest rozbój i włamania; aby jednak uzyskać ze „skoku” zysk 200 dolarów, może być konieczne zabranie mienia wartości do 1000 dolarów. Dla kobiet prostytucja może stać się jedynym środkiem umożliwiającym zaspokojenie takiego nawyku. Ludzie rozpoczynający zażywanie narkotyków - bez względu na ich płeć - mogą doprowadzić do tego, że powiększą liczbę osób zapadających na tak zwaną „chorobę amerykańską” - nałogowe zażywanie heroiny.


Narkoman różnymi sposobami zostaje włączony w świat przestępczy i często zaczyna przedkładać to dziwaczne, podniecające, niepewne życie ulicy nad normalne życie „frajerów”. Wyobraź sobie, że budząc się każdego ranka wiesz, iż będziesz musiał ukraść towary wartości 1000 dolarów lub będziesz musiała mieć stosunek z tuzinem obcych mężczyzn (którzy mogą należeć do policji obyczajowej, mafii lub mogą być nosicielami choroby wenerycznej)!  Jest to perspektywa, która nadaje swoisty koloryt drzwiom percepcji otwartym przez nadużywanie środków psychotropowych. Ogólnie mówiąc, wszystkie te zmiany w postawach i zachowaniu stanowią część skutków używania tych środków - podobnie jak cechy sytuacji społecznej, w którą zostają wplątani nowicjusze.
Reasumując, nie ulega zatem wątpliwości, iż w wyniku używania środków farmakologicznych możliwe staje się spostrzeganie niezwykłej rzeczywistości. Zmieniając czasowo funkcjonowanie ośrodkowego układu nerwowego i współczulnego układu nerwowego środki te mogą oddziaływać na:
1. |Organizm (zmiany tętna, oddychania, tempa pracy serca, wielkość źrenic, ciepłoty ciała, ciśnienia krwi oraz zmiany odruchów ścięgnistych);
2. |System |percepcji |wzrokowej (wyostrzenie lub zamglenie spostrzegania, rzutowanie wyobrażeń wzrokowych, zniekształcanie szczegółów lub tła, zmiana wymiarów itd.);
3. |System |intelektualny |wraz |z |uwagą (charakterystyczne dla snu poczucie oderwania, bierne nastawienie, obniżenie wyników w wykonywaniu zadań, duże roztargnienie, upośledzenie pamięci itd.);
4. |Poczucie |czasu (zmiana tempa, w jakim zachodzą wydarzenia, stapianie się przeszłości z przyszłością lub też pozorna nieistotność różnicowania tych aspektów perspektywy czasowej);
5. |System |emocjonalno-afektywny (bardziej skrajne lub bardziej zmienne nastroje).
Środki psychotropowe rzadko wywołują to, co można by nazwać reakcjami „ekstatyczno-transcendentalnymi”, w których osoby badane interpretują swoje doznania w kategoriach mistycznych, religijnych. W pewnym badaniu, które objęło ponad 200 osób, tylko 11 z nich (5%) doznało iluminacji, którą interpretowali oni jako przeżycie religijne (Masters i Houston, 1966). W innym badaniu tylko 3 osoby spośród 48 (6%) opisywało „transcendentalne” doświadczenia po przyjęciu 500 mikrogramów LSD (Johnson, 1968).
Jak mówi nam o tym historia, istoty ludzkie nigdy nie zadawalały się „rzeczywistością” taką, jaka jest dana ani też świadomością taką, jakiej się zwykle doświadcza. Poszukujemy sposobów wkroczenia w nowe dziedziny świadomości, wyjścia poza samo jedynie spostrzeganie pozorów, aby „ujrzeć” istotę rzeczy. Spośród wielu sposobów rozszerzania granic świadomości, jeden polega na zjadaniu lub paleniu roślin, jakich dostarcza przyroda.
Czy takie pragnienia, aby wykroczyć poza empiryczną rzeczywistość „tu i teraz” za pomocą zażywania środków psychotropowych, są „słuszne”, „dobre” i „właściwe” jest przedmiotem rozważań moralnych i społeczno-filozoficznych oraz ustaleń prawnych. Z punktu widzenia psychologii możemy powiedzieć, że codziennie miliony Amerykanów zażywają najrozmaitsze środki farmakologiczne, spośród których niektóre zmieniają niekiedy obraz ich świata. Takie doświadczenie ze środkami psychotropowymi może być banalnym społecznym przejawem młodzieńczego buntu wobec społeczeństwa (i konformizmu wobec „paczki”), jedynym w swoim rodzaju mistycznym objawieniem, drogą do szaleństwa lub biletem do więzienia - nie można jednak zaprzeczyć, że poprzez takie doświadczenia istoty ludzkie zmieniają swą świadomość, co prowadzi psychologów do zainteresowania się nową naturą świadomości ludzkiej.




Medytacja, joga
i zen




„Medytacja polega na uwolnieniu się”.
„Dzięki praktykowaniu zen osiąga się ostateczne oświecenie i wyzwolenie”.


Amerykańscy studenci są w trakcie odkrywania zjawiska |medytacji oraz korzyści płynących z tego sposobu zmieniania świadomości, który w ciągu stuleci był doskonalony przez Hindusów i Japończyków.
Na czym polega atrakcyjność medytacji oraz egzotycznych psychologii kultur Wschodu? I dlaczego musiało upłynąć tyle lat, zanim doceniono ich doniosłość na Zachodzie? Odpowiedzi na te dwa pytania są wzajemnie powiązane; podstawowe cechy zachodniej (a zwłaszcza amerykańskiej) kultury są zupełnie różne od podstawowych cech wschodniego sposobu życia, a niektórzy ludzie zaczynają kwestionować przydatność naszych wartości kulturowych jako wytycznych umożliwiających ukierunkowanie swego życia.
Świadomość indywidualna odzwierciedla społeczno-kulturowe 
„zaprogramowanie”, pod wpływem którego się rozwinęła. Kultura amerykańska kładzie nacisk na działanie, nastawienie na zewnątrz, dbałość o aprobatę innych, opanowywanie przyrody za pomocą techniki, liniowy charakter czasu, planowanie na przyszłość oraz racjonalno-logiczne procesy myślowe. Jest to antyteza tradycyjnego światopoglądu orientalnego.
Szeroko pojmowana „medytacja” obejmuje różne techniki, postawy i wartości, które stanowią alternatywę w stosunku do dominujących idei działania, racjonalności oraz ukierunkowania na zewnątrz, stanowiących podłoże doświadczenia kulturowego Zachodu. Osoby uprawiające medytację twierdzą, że w czasie niej następuje zmiana ukierunkowania świadomości na bardziej bierne i spokojne zogniskowanie wewnętrzne, a receptywne nastrojenie umysłu pozostaje w harmonii z naturą i życiem, takim, jakim „jest ono naprawdę” (nie jakim „mogłoby” czy „powinno” być). Wielu zwolenników medytacji utrzymuje, że oprócz stanu umysłowego i fizycznego odprężenia i spokoju odczuwają oni głębszą zmianę w sposobie i przedmiocie swego myślenia. Uważają oni medytację za jedyny w swoim rodzaju sposób uzyskania wiedzy o sobie samym, o strukturze własnej świadomości oraz o stosunku swego „ja” do wszystkiego innego („Wszystkiego”). Posługując się metaforą Roberta Ornsteina:


„Medytacja jest techniką służącą przyciemnieniu jasności dnia, tak żeby można było spostrzec wewnątrz siebie zawsze obecne, subtelne źródła energii. Stanowi ona rozmyślną próbę odseparowania się na krótki czas od biegu codziennego życia i „wyłączenia” aktywnego trybu funkcjonowania świadomości w celu wstąpienia w komplementarny tryb „ciemności”” (1972, s.  107).


Różni mistrzowie medytacji w różnych krajach używają rozmaitych technik, lecz dla nich wszystkich wspólne jest skoncentrowanie przez pewien czas uwagi i świadomości na jednym, niezmiennym źródłem stymulacji. Temu skupieniu uwagi może służyć usilne wpatrywanie się w jakiś przedmiot, wsłuchiwanie się w dźwięk powtarzanego wielokrotnie słowa, melodyjnej recytacji czy modlitwy lub też fizyczny ruch wykonywany w identyczny sposób, raz za razem.




* * *



Ryc. 7.7. Medytacja, niegdyś uprawiana niemal wyłącznie na Wschodzie, zyskuje sobie obecnie popularność również na Zachodzie, zwłaszcza wśród młodzieży.


* * *







Medytacja
transcendentalna




Wspominana na wstępie forma medytacji, która przyciąga tak wielu uczniów, zwana jest |medytacją |transcendentalną czyli TM. Jej twórca, Maharishi Mahesh Yogi, określa ją jako „skierowanie uwagi do wewnątrz, ku subtelniejszym poziomom myślenia, dopóki umysł nie wykroczy poza doznanie najsubtelniejszego stanu myślowego i nie osiągnie źródła myśli”. Medytacja transcendentalna uzyskała sobie wszelki rozgłos, gdy Beatlesi podróżowali do Indii i mistrza Mahesh Yogi w poszukiwaniu nowych wartości duchowych i wewnętrznego ukojenia.
Podstawowa procedura stosowana w medytacji transcendentalnej jest bardzo prosta, lecz przypisuje się jej daleko idące skutki. TM nie wiąże się z wierzeniami religijnymi ani też nie wymaga poważnych zmian stylu życia.
Medytujący siada po prostu wygodnie, zamyka oczy i przez krótki czas (zwykle 20 minut, dwa razy dziennie) zagłębia się w bezgłośnym, przebiegającym bez wysiłku powtarzaniu specjalnych dźwięków. Te cicho powtarzane specjalne dźwięki lub sylaby nazywane są |mantra. Nie są one nigdzie zapisane - są utrwalone w ustnej tradycji i nauczyciel przekazuje je uczniom indywidualnie. Mantra każdego z medytujących jest specjalnie dla niego wybranym dźwiękiem, który ma pomóc mu w doznaniu głębokiego odprężenia i rozjaśnienia umysłu. Technika medytacji transcendentalnej jest zaczerpnięta ze świętych ksiąg hinduskich - „Bhagawadgity i Wed”.
Medytację transcendentalną uważa się za pewną formę ćwiczeń jogi z zastosowaniem mantr. Pod pewnymi względami jest ona podobna do praktyk stosowanych zarówno w nabożeństwach chrześcijańskich, jak i żydowskich. W nich również są obrzędy mające odwrócić uwagę od zewnętrznego, materialnego świata i skupić ją na wewnętrznej rzeczywistości duchowej - takie, jak powtarzanie modlitw, śpiewanie lub melodyjne recytowanie hymnów, skoncentrowanie się na symbolicznych formach i ograniczenie ruchów ciała.  Jednakże w ciągu pokoleń takie ćwiczenia religijne zbyt często stają się automatycznymi rytuałami, które nie prowadzą osób praktykujących je do zmian świadomości tego rodzaju, jakie opisywali dawniejsi autorzy dzieł religijnych. Być może, iż popularność medytacji transcendentalnej jest ponownym odkryciem dla mieszkańców Zachodu tego, co niegdyś było żywotnym elementem w mistyce religijnych tradycji zachodnich.
Co powoduje medytacja transcendentalna? Po dokonaniu przeglądu fizjologicznych, psychologicznych i społecznych następstw TM, należałoby raczej zapytać: „Czy jest coś, czego TM „nie” powoduje?” Poniżej podajemy niektóre zmiany fizjologiczne, które według dwóch badaczy Roberta Wallace i Herberta Bensona (1972), występują pod wpływem medytacji transcendentalnej: zwiększony przepływ krwi, zmniejszone zużycie tlenu i wytwarzanie dwutlenku węgla, wzrost elektrycznej oporności skóry, wywoływanie czynności bioelektrycznej mózgu charakterystycznej dla stanu „czujności” („vigilance”) oraz ogólne „uspokojenie sympatycznego układu nerwowego” (zwykle nadmiernie pobudzanego stresami współczesnego życia).
W wielu innych badaniach wykazano korzyści płynące z medytacji transcendentalnej w postaci polepszenia wyników uczenia się oraz zmniejszenia lęku, wrogości i agresji. Stosuje się ją także skutecznie w celu zwiększenia efektywności terapii w odniesieniu do pacjentów psychiatrycznych, więźniów oraz narkomanów (bibliografię współczesnych badań z tej dziedziny opracowali Kanellakos i Ferguson, 1973, a ich oceny dokonał Schwartz, 1974).


Termin |joga, w jego popularnym zastosowaniu, oznacza medytację, w której główną rolę odgrywa przyjmowanie określonych postaw ciała oraz ćwiczenia oddechowe. Uprawianie jogi dla zdrowia bez jednoczesnego ćwiczenia dyscypliny duchowej jest powszechne |nie w Indiach, lecz w Ameryce.
Zgodnie ze ścisłą definicją tego terminu, joga „oznacza system wierzeń i praktyk, których celem jest osiągnięcie zjednoczenia indywidualnej jaźni z Najwyższą Rzeczywistością, czyli Jaźnią Uniwersalną” (Barber, 1970). Każdy z kilku różnych systemów jogi stosuje swe własne metody dla osiągnięcia ostatecznego stanu transu. Jeden z systemów, zwany |radżajoga, obejmuje osiem takich metod: samokontrola („jama”), praktyki religijne („nijama”), postawy ciała („asana”), regulowanie oddychania („paranajama”), tłumienie wrażeń zmysłowych wywoływanych przez przedmioty i zdarzenia zewnętrzne („pratjahara”), koncentracja, czyli skupienie uwagi na pewnym przedmiocie („dharana”), kontemplowanie pojedynczego przedmiotu przez długi czas („dhjana”) oraz utrata świadomości własnej koncentracji przez całkowite zatopienie się w medytacji („samadhi”).
Obserwacje, przeprowadzane nad wyćwiczonymi joginami (tzn. osobami praktykującymi jogę) w ściśle kontrolowanych warunkach wykazały, że w czasie trwania stanu medytacji („samadhi”), występuje ogromne zmniejszenie poboru tlenu i wytwarzania dwutlenku węgla (co wskazuje na obniżenie tempa przemiany materii), zmniejszenie szybkości oddychania, duże zmniejszenie tempa pracy serca (lecz nie do zera w żadnym z zarejestrowanych przypadków) oraz wzrost elektrycznej oporności skóry.
Pewien eksperyment potwierdził także zdolność kontroli nad bodźcami bólowymi, jaką przypisują sobie niektórzy jogini. Dwaj wyćwiczeni jogini zanurzali podczas medytacji ręce w wodzie o temperaturze 4???str.291 Celcjusza nie wykazując żadnych oznak bólu w czasie tego doświadczenia. Co więcej, zapisy EEG wykazały występowanie u nich przez cały czas trwania tego doświadczenia rytmu alfa, którego obecność podczas stresu czy bólu nie jest zwykle prawdopodobna (Anand, Chhina i Singh, 1961).
Z drugiej strony, gdy przeprowadzono poważne badania nad popularnymi pokazami publicznymi, takimi jak chodzenie po ogniu, palenie się żywcem, spanie na łożu z gwoździ itd., stwierdzono, iż są to albo oszustwa, które można wyjaśnić w prosty sposób, lub też, że pokazy te nie mają związku z prawdziwymi praktykami jogi. Na przykład leżenie na łożu z gwoździ nie jest wielkim wyczynem z zakresu kontroli psychiki nad ciałem, jeśli gwoździe są powbijane gęsto i są niezbyt ostre oraz jeśli dana osoba ma wysoką tolerancję na ból, rozluźnia mięśnie pleców i jest pod wpływem haszyszu czy opium. Niezbędna jest większa liczba dobrze kontrolowanych badań, aby można było ocenić, jak dalece ćwiczenie jogi umożliwia zmianę funkcjonowania organizmu ludzkiego.




Zbliżenie


„Nie będę czuł bólu ani krwawił”


„Przebywając jako młody człowiek w obozie koncentracyjnym, Jack Schwartz nauczył się zmniejszać do minimum ból przez zastosowanie dowolnej kontroli autonomicznej. W samoobronie „nauczył” siebie samego kontrolowania bólu, temperatury ciała, krwawienia i innych procesów wewnętrznych. Przed kilku laty, gdy Schwartz miał 48 lat, przeprowadzono intensywne badania nad zdumiewającą dyscypliną, jaką potrafił on „zgodnie ze swą wolą” narzucić swej psychice i swemu ciału (Gree, Green i Walter, 1972; Rorvik, 1972).
Nieco później, w celu zweryfikowania prawdziwości jego twierdzeń (połączonych z publicznymi demonstracjami) o władzy psychiki nad materią, Kenneth Pelletier (1974) przeprowadził w Langley Porter Neuropsychiatric Institute szereg rygorystycznie kontrolowanych badań.
Eksperymenty przeprowadzono w ekranowanym elektrycznie i dźwiękoszczelnym pomieszczeniu, przez cały czas w obecności dwóch lekarzy. Za pomocą różnych miar psychofizjologicznych (czynność bioelektryczna mózgu, praca serca, oddychanie, napięcie mięśniowe i czas krwawienia) określono podstawowy „poziom funkcjonowania” Jacka Schwartza. Zespół wykwalifikowanych psychofizjologów (z pracowni dr Josepha Kamiya) kontrolował w sposób ciągły przebieg tych czynności w czasie 24 posiedzeń testowych, w ciągu 6 kolejnych dni.
Aby zademonstrować autoregulację odczuwania bólu i występowania krwawienia, polecono Schwartzowi, by przebił swój biceps niewysterylizowanym drutem od robót dziewiarskich, a następnie starał się opanować krwawienie z rany. Wykonał on to trzykrotnie, bez żadnego uprzedniego przygotowania, na spontaniczne żądanie eksperymentatora.  Wszystkie wskaźniki neurologiczne i psychofizjologiczne były rejestrowane przed tymi demonstracjami, w czasie ich i po nich.
Obecny przy tych doświadczeniach lekarz podaje w swym sprawozdaniu, że po wyjęciu drutu |nie wystąpiło żadne krwawienie; nawet po umiarkowanie silnym naciśnięciu miejsca przekłucia pojawiła się jedynie jedna, mała kropla osocza. Po dwóch godzinach miejsce przekłucia zdawało się już być zagojone i stwierdzono, że drut (który, 30 sekund przed dokonaniem nim nakłucia, Schwartz przesuną gołą stopa po dywanie) nie spowodował żadnej infekcji.
Schwartz podał, że wcale nie doznał bólu - na podstawie zewnętrznych reakcji nie można było zaobserwować żadnych jego przejawów. Jeszcze bardziej godne uwagi było to, że to traumatyczne zdarzenie zewnętrzne nie zakłóciło psychicznego stanu medytacji u Schwartza. Zapis generowanego przez niego rytmu alfa (EEG) pozostawał bez zmiany przed demonstrowanym przekłuciem, w czasie niego i po nim.
|W |jaki jednak sposób utrzymywał on niezakłócony rytm alfa, eliminował ból i zmniejszał do minimum krwawienie? W swym sprawozdaniu Schwartz wskazał na zastosowanie technik poznawczych polegających na oderwaniu się („detachment”) i depersonalizacji. Stwierdził on:
„To jest bardzo proste. Robię to zmieniając jedno słowo. Nie wbijam drutu w |moją rękę; wbijam go w |jakąś rękę. Wychodzę ze swojego ciała i patrzę na tę rękę z oddalenia; dzięki takiemu oderwaniu się - staje się ona przedmiotem. Jest to tak, jak gdybym wbijał ten drut w poręcz fotela.  Nauczyłem się z równą łatwością wychodzić ze swej istoty, jak i wchodzić w nią” (Pelletier, 1974, s. 86).




Zen




Aczkolwiek zainteresowanie Zachodu doktryną i praktykami zen jest stosunkowo w nowe, historia tego kierunku sięga wstecz tysiące lat, w Indiach i Japonii poprzez buddyzmu, a w Chinach poprzez taoizm i konfucjanizm, jak również buddyzm. W przeciwieństwie do medytacji transcendentalnej, praktykowanie zen wymaga czegoś więcej niż tylko krótkich codziennych ćwiczeń. Jest to pewien sposób życia i kierująca nim filozofia. D. T. Suzuki, jeden z czołowych autorytetów w dziedzinie buddyzmu zen, reasumuje to poszukiwanie nowej orientacji życiowej w następujący sposób:


„Istota buddyzmu zen polega na uzyskaniu nowego spojrzenia na życie i wszelkie sprawy (...). Musimy spróbować przekonać się, czy istnieje jakiś inny sposób oceniania wszelkich spraw lub raczej, czy sposób, w jaki zwykle to robimy jest zawsze wystarczający, by zapewnić nam ostateczne zaspokojenie naszych duchowych potrzeb (...). Musimy starać się znaleźć jakiś sposób, który da nam poczucie spełnienia i zadowolenia. Zen proponuje to nam i zapewnia nam uzyskanie nowego punktu widzenia, przy którym życie przyjmuje świeższą, głębszą i bardziej satysfakcjonującą postać” (cytowane za: Stace, 1960, s. 89).


Stan umysłu do jakiego dąży się przez uprawianie medytacji zen, jest stanem „czujnej pustki”, w którym umysł jest podobny do zwierciadła, odbijającego po prostu to, co oddziaływuje nań z zewnątrz.


„Posługując się słownictwem zaczerpniętym z orientalnych filozofii, moglibyśmy powiedzieć, iż rzeczywistość psychiczna jest wodą, na której wiatr bodźców zewnętrznych wywołuje fale myśli i pragnień i która powraca do swego pierwotnego stanu wygładzając się, gdy wiatry ucichną” (Akishige, 1970, s. 3)


Słowo |zen oznaczało pierwotnie „spokojną medytację”, lecz z czasem termin ten objął „mądrość”, a obecnie celem zen jest „oświecenie”. Istnieją trzy środki, za pomocą których osoba praktykująca zen realizuje to oświecenie, czyli „zrozumienie bezpojęciowe” („satori”):
a) |zazen - ćwiczenia wpływające na podstawę oraz ciało, ćwiczenia mające regulować oddychanie oraz ćwiczenia służące kształtowaniu umysłu;
b) |koan - ćwiczenia intelektualne w medytowaniu nad zagadkami i pytaniami, których logicznie nie można nigdy rozwiązać, takimi jak: „Czym jest dźwięk klaskania w ręce?”, „Jak wyglądał człowiek, zanim jeszcze jego ojciec i matka spotkali się?”. Aby zrozumieć koan, trzeba odrzucić racjonalne procesy poznawcze, ponieważ koan można pojąć, lecz nigdy nie można go wyjaśnić. Skoncentrowanie się na znaczeniu koan uwalnia umysł od innych zainteresowań, aż w końcu pozostaje jedynie koan. Później koan również zanika, pozostawiając jedynie umysł jako „zwierciadło bez skazy”;
c)|sanshi-Mompo - „udanie się do mistrza z zapytaniem o drogę”. Praktyka ta polega na zdyscyplinowanym pobieraniu nauk przez ucznia u mistrza zen przez długi czas. Jest to pewien rodzaj porad, jakich mistrzowie zen udzielają mnichom; mogą oni w tym celu posługiwać się wyjaśnieniami, zaprzeczeniami, dylematami, sugestiami, wskazówkami, siłą, krzykami oraz nagłymi, nieoczekiwanym uderzeniami.
Jeśli zen przekształca umysł w zwierciadło, które w każdej chwili, natychmiast, odzwierciedla myśli i bodźce, to można przewidywać, iż badania nad mistrzami zen przy zastosowaniu EEG: a) ujawniłyby zapis czynności bioelektrycznej mózgu charakterystyczny dla aktywnego skupienia oraz b) wskazałyby brak habituacji w stosunku do powtarzających się bodźców. Oba te przewidywania zostały potwierdzone w przeprowadzonych niedawno badaniach.


„W szeregu badań nad osobami praktykującymi zen oraz kapłanami zen (którzy mieli za sobą do 30 lat „religijnych umartwień”), zapisy EEG w okresach praktykowania zen zmieniały swą zwykłą postać, wykazując większy niż zwykle procent rytmów alfa. Badacz wyciągnął stąd wniosek, że pojawiające się zmiany reprezentują specyficzny stan świadomości występujący przy praktykowaniu zen, mianowicie stan aktywnego skupienia umysłu (Yamaoka, 1969).
W innym badaniu eksponowano dwudziestokrotnie w odstępach piętnastosekundowych pewien dźwięk (trzask), jednocześnie obserwując określone zmiany czynności bioelektrycznej mózgu u trzech mistrzów zen i czterech badanych kontrolnych (spoczywajacych z zamkniętymi oczami).  Początkowo badani kontrolni reagowali na nowy bodziec, „zwracając uwagę” na niego, o czym świadczyło zablokowanie za każdym razem rytmu alfa. Jednakże następnie, gdy bodziec ten powtarzał się, nastąpiła w stosunku do niego habituacja - a nie był on już „zauważony”, a jego wystąpienie nie powodowało zablokowania tego rytmu.
W wyraźnym przeciwieństwie do badanych kontrolnych mistrzowie zen reagowali na każdą ponowną prezentację bodźca tak samo, jak za pierwszym razem, a mianowicie zablokowaniem rytmu alfa. Było to tak, jak gdyby ich otwartość na doświadczenie danej chwili powodowała spostrzeganie świata na nowo przy każdym dochodzącym zeń dźwięku” (Kasamatsu i Hirai, 1966).


Wyniki te są szczególnie godne uwagi, ponieważ habituacja jest jednym z najbardziej fundamentalnych psychologicznych procesów adaptacyjnych: u najrozmaitszych gatunków i w odniesieniu do niemal wszystkich reakcji organizmu, od zgięcia nogi do złożonych form eksploracji i zabawy, obserwuje się habituację przy wielokrotnym eksponowaniu danego bodźca (Welter, 1961). Istnieje nadzieja, że dalsze badania potwierdzą ten ważny wniosek, ponieważ weryfikuje on - w formie możliwej do zaakceptowania przez krytykę naukową - twierdzenia tych, którzy utrzymują, że stany świadomości wytwarzane przez zen istotnie głęboko zmieniają stosunek istot ludzkich do ich rzeczywistości wewnętrznej i zewnętrznej.




Zbliżenie


Biologiczne sprzężenie zwrotne: sterowanie psychiczne za pomocą urządzeń 
technicznych


„W ścisłym związku z danymi, dotyczącymi zmian fizjologicznych, jakie osoby praktykujące zen osiągają dzięki dyscyplinie psychicznej, pozostaje odkrycie, iż funkcje fizjologiczne, które uprzednio uważano za całkowicie niedowolne, można poddać pod kontrolę jednostki dzięki zastosowaniu technik warunkowania sprawczego („operant”). Jak już przekonaliśmy się, zademonstrowanie przez Neala Millera możliwości wywoływania zmian fizjologicznych drogą uczenia się dało początek nowej dziedzinie badań o fascynujących implikacjach. Ludzi można nauczyć sterowania różnymi, zachodzącymi wewnątrz organizmu procesami przez zastosowanie techniki zwanej |biologicznym |sprzężeniem |zwrotnym (|biofeedback”). W technice tej wykrywa się niewielkie zmiany zachodzące w ciele czy mózgu, a następnie wzmacniania się je i prezentuje danej osobie i (lub) badaczowi.  Skomplikowana technika rejestrowania i elektroniczne maszyny liczące umożliwiają danej osobie regulowanie tego, co w niej zachodzi - subtelnych zmian tempa pracy serca, ciśnienia krwi, temperatury i czynności bioloelektrycznej mózgu, które normalnie byłyby niemożliwe do zaobserwowania.
Te przebiegające nieustannie procesy biologiczne są więc udostępnione danej jednostce w postaci ciągłego sprzężenia zwrotnego. Ustala się pewien „cel”, taki jak zmiana czynności bioelektrycznej mózgu w określonym kierunku, a następnie dana jednostka nieustannie obserwuje swój postęp w kierunku tego celu. Przy zastosowaniu tej techniki badani potrafili zmieniać temperaturę skóry nawet o 5 st. C, zmniejszać ciśnienie krwi o 15%, zmniejszać lub zwiększać tempo pracy serca, odprężać napięte mięśnie, zmieniać na rozkaz występowanie rytmów alfa, beta i theta w zapisie EEG oraz modyfikować jeszcze inne czynności, które dawniej uważano za nie podlegające dowolnej kontroli człowieka.
W jednym z badań studenci wyższej uczelni po kilku tygodniach ćwiczenia się przy użyciu biologicznego sprzężenia zwrotnego potrafili zwiększać średnie tempo pracy serca aż o 35 uderzeń na minutę (Wells, 1973).  Istnieje nadzieja, że dzięki zastosowaniu tego sposobu podejścia w medycynie pacjenci będą mogli opanować nadmierne napięcie, bóle głowy spowodowane migreną oraz schorzenia serca, nawet jeśli choroby te można przypisać przyczynom natury psychicznej.
Jednakże obietnice, że za pomocą nowoczesnej techniki kontroli sprawczej można będzie leczyć nasze choroby i stworzyć życie pełne euforii w rytmie alfa, są obecnie dalekie od realizacji. Aczkolwiek w idealnych warunkach laboratoryjnych uzyskiwano statystycznie istotne zmiany, to na przykład nie otrzymano jeszcze istotnych, z klinicznego punktu widzenia, zmian w zakresie funkcjonowania serca (Blanchard i Young, 1973).
Należy także wskazać naszym studentom, zainteresowanym niekosztownymi urządzeniami do uzyskiwania biologicznego sprzeżenia zwrotnego (typu „zrób to sam”), jakie znajdują się na rynku, że wskazana tu jest ostrożność i sceptyzm. Nie jest prawdopodobne, aby przeciętna osoba potrafiła zmieniać w istotny sposób wytwarzanie rytmu alfa przy zastosowaniu taniego urządzenia i bez przejścia odpowiedniego szkolenia pod kierunkiem specjalisty. Ponadto wiara, że biologiczne sprzężenie zwrotne może przywrócić prawidłowe funkcjonowanie mózgu i ciała, jest niebezpieczna - lepiej dla osiągnięcia tego celu zmienić swe nawyki i styl życia. Staliśmy się zbyt mało odporni na ból oraz lęk o zbyt chętnie poszukujemy szybkich i łatwych rozwiązań - choć niby wiemy, że szczęścia nie uda się nabyć z gotowym opakowaniu”.




Hipnoza




„Robisz to, co chcesz”. Czy jest możliwe, abyś kiedykolwiek nie zrobił tego, co chcesz - lub nawet, być może, abyś zrobił to, czego nie chcesz?  To, czego - krótko mówiąc - chce kto inny? Słuchaj uważnie, mój przyjacielu, to mogłaby być dla ciebie przyjemna zmiana, oddzielić wolę od działania i przestać się zajmować obydwiema sprawami jednocześnie. Podział pracy, „sistema americana, sa”! Przypuśćmy, że pokazałbyś język tej dobranej i szanowanej publiczności - cały swój język, aż do samej nasady?”
„Nie, nie pokazałbym”, powiedział młody człowiek nieprzyjaźnie. 
„Pokazywanie języka jest oznaką złego wychowania”.
„Nic podobnego”, odparł Cipolla, „po prostu |zrobiłbyś to. Z całym należnym szacunkiem dla twojego wychowania oświadczam, że zanim policzę do dziesięciu, wykonasz zwrot w prawo i pokażesz swój język zebranemu towarzystwu, wysuwając go bardziej niż myślałeś, że potrafisz go wysunąć”.
Wpatrywał się w młodzieńca, a jego przenikające na wskroś oczy zdawały się zapadać głębiej w swych oczodołach. „Uno!”, powiedział. Pozwolił swej szpicrucie ześlizgnąć się po ręce i ścisnął nią raz w powietrzu. Chłopiec zrobił w tył zwrot i wystawił język tak daleko, że można się było przekonać, iż jest to naprawdę cały język, jaki miał do pokazania. Potem z kamienną twarzą obrócił się znowu wracając do swej uprzedniej pozycji”.
Tomasz Mann „Mario und der Zauberer” 1929,  (wyd. pol. „Mario i czarodziej”).


Ze wszystkich sposobów zmieniania świadomości, hipnoza jest sposobem chyba najpowszechniej znanym i najmniej rozumianym. Została ona spopularyzowana jako technika kierowania innymi dla własnej korzyści.  Shadow (Cień), bohater głośnego serialu radiowego w latach czterdziestych, posługiwał się hipnozą, aby „zaciemniać umysły ludzkie” i odkrywać „sekrety tajone w ludzkich sercach”. W filmie „Manchurian candidate” (Mandżurski kandydat) hipnoza została użyta dla przekształcenia zwykłego człowieka w fantastycznego, maniakalnego zabójcę.
Poważne badania nad hipnozą i jej zastosowaniem w praktyce ucierpiały od takich skojarzeń, a także w wyniku posługiwania się nią w celach rozrywkowych przez hipnotyzerów produkujących się na estradach. Ponieważ w „przemyśle rozrywkowym” potrzebne są łatwo dostrzegalne, szybko osiągalne efekty, przeto hipnotyzerzy każą ludziom zachowywać się w taki sposób, aby widownia była pewna, że normalnie tak by się nie zachowali; tak więc hipnotyzm na estradzie często poniża i degraduje wartości ludzkie i ma na ogół „złą prasę” (ryc. 7.10).




* * *



Ryc. 7.10. Hipnozę ceniono dawniej głównie ze względu na efekty estradowe, jakie można dzięki niej uzyskać. Obecnie psychologowie zaczynają traktować ją jako przedmiot poważnych badań.


* * *







Magnetyzm zwierzęcy
i mesmeryzm




W osiemnastym wieku lekarz wiedeński, F. A. Mesmer, wzbudził sensację lecząc chorych za pomocą |magnetyzmu |zwierzęcego. Sądził on, że wszechobecny fluid oddziałuje na planety i wszelkie żywe istoty. Choremu organizmowi można przywrócić jego harmonię z wszechświatem umieszczając na nim magnesy w celu wywołania przepływu uzdrawiającego fluidu magnetycznego.  W książce „The Influence of the Planets on the Human Body” (Wpływ planet na ciało ludzkie, 1776) pisał on:


„(...) za pomocą pewnych manipulacji (takich, jak dotykanie, głaskanie, słowem „magnetyzowanie”), a nawet po prostu jedynie za pomocą silnego aktu woli, można wytwarzać w ludziach energię, udzielać jej innym i powodować najbardziej zdumiewające i zdrowe skutki”.


Terapia Mesmera opierała się na zasadach starodawnego działania przez wiarę, przybranych w naukową terminologię, z dodatkiem odrobiny średniowiecznego mistycyzmu i starożytnej astrologii (Shor, 1972; Darnton, 1968). |Mesmeryzm zdobył sobie taką sławę, że setki pacjentów doznawało ulgi w cierpieniach, a tysiące nowych przybywało zewsząd w tym celu (ryc.  7.11). Aby sprostać zapotrzebowaniu, Mesmer „magnetyzował” prawie wszystko wokół i głosił, że kontakt z tymi przedmiotami będzie uzdrawiający.  Nadzieja uwolnienia się od cierpień skłaniała wielu ludzi do tego, że wiązali się razem w szereg, a następnie przywiązywali do specjalnego, namagnetyzowanego dębu.
Magnetyzm zwierzęcy został w końcu zdyskredytowany, jako nie mający żadnych podstaw fizycznych, przez komisję Francuskiej Akademii Nauk pod przewodnictwem Benjamina Franklina. Jej orzeczenie głosiło: „Nic nie świadczy o istnieniu magnetycznego, zwierzęcego fluidu; imaginacja bez magnetyzmu może wywoływać zmiany; magnetyzm bez imaginacji nie wywołuje niczego”.
Nieco później magnetyzm zwierzęcy zastąpiła hipnoza, która została w pewnym stopniu zaakceptowana przez naukę dzięki wysiłkom szkockiego chirurga, Jamesa Braida. Odkrył on w 1843 roku, że układ nerwowy można sztucznie wprowadzać w stan „nerwowego snu”, który nazywał „hipnozą”. Nazwa |hipnoza pochodzi od greckiego słowa „Hypnos”, które jest imieniem boga snu. Wykazano, że ten szczególny stan snu można wywoływać jedynie przez koncentrację uwagi czy „utkwienie wzroku”. Stwierdzono, że osoba znajdująca się w tym stanie jest podatna na sugestie słowne podawane przez hipnotyzera.
W okresie od 1845 do 1853 roku szkocki chirurg pracujący w Indiach, James Esdaile, wykonał blisko 300 bezbolesnych, poważnych operacji, łącznie z amputacjami i usuwaniem katarakty, stosując hipnozę jako jedyny środek znieczulający.




* * *



Ryc. 7.11. Mesmeryzm pod koniec XVIII wieku zyskał sobie niezwykłą popularność w salonach Wiednia. Rysunek przedstawia Antona Mesmera dokonującego jednego ze swych „cudownych” wyleczeń.


* * *





Jednakże odkrycie eteru spowodowało, że chirurdzy woleli stosować ten środek chemiczny, zamiast psychicznego środka w postaci hipnozy, chociaż wykazano, że ta ostatnia jest równie skuteczna, ma mniej skutków ubocznych, a w wielu typach operacji prowadzi do obniżenia wskaźnika śmiertelności.
W roku 1878 wybitny neurolog, Jean Charcot, zaczął demonstrować hipnozę w Paryżu. Chociaż jego teorie na temat hipnozy były właściwe tylko unowocześnionym mesmeryzmem, ważną jego zasługą było uzyskanie uznawania nauki dla badań nad hipnozą oraz fakt, że u niego studiowali hipnozę Freud i Breuer. Ci ostatni posługiwali się później hipnozą jako techniką służącą do badania nieświadomych procesów w histerii (aczkolwiek Freud zarzucił następnie hipnozę na rzecz techniki swobodnych skojarzeń).
Nowoczesna era psychologicznych eksperymentów nad hipnozą rozpoczęła się dopiero w latach trzydziestych naszego stulecia, wraz z pracami, jakie w tej dziedzinie podjął Clark Hull na Yale University. Opracowano standardowe procedury dla oceny głębokości hipnozy na podstawie obserwowalnych behawioralnych kryteriów. Ta działalność badawcza została nagle zahamowana, gdy osoba badana w jednym z eksperymentów wygrała proces sądowy wytoczony uniwersytetowi, twierdząc, że doznała szkód psychicznych w wyniku zastosowania wobec niej hipnozy. Tego rodzaju procesów sądowych przeciwko hipnotyzerom-naukowcom, było bardzo niewiele, lecz ten jeden wystarczył, aby Hull zrezygnował z tego kierunku badań i zajął się przez resztę swego życia badaniem zasad uczenia się - u szczurów.
W ostatnich latach w naukowych badaniach nad hipnozą przewodzą Ernest Hilgard ze Stanford University oraz Martin Orne z University of Pennsylvania. W wyniku twórczej działalności ich pracowni badawczych oraz naukowej ścisłości i pomysłowości, z jaką oni i ich uczniowie badają procesy, korelaty i konsekwencje hipnozy, tajemnica ustępuje miejsca pewnym faktom i sprawdzalnej teorii (Hilgard, 1973; Orne, 1970).




Zmiany świadomości
pod hipnozą




Nikt nie wie dokładnie, jak i dlaczego hipnoza „działa”, mimo że jest ona znana już tak długo. Szczególnie ciekawe w wypadku hipnozy jest to, że tak małe „wejście” - parę słów - może wywoływać tak silne zmiany w zachowaniu.  Niektóre skutki hipnozy są ściśle związane z sugestiami słownymi podawanymi przez hipnotyzera, jak w przypadku chłopca, który mimo swej woli pokazał publiczności język; istnieją także inne, niespecyficzne reakcje, które także z reguły towarzyszą hipnozie. U osób badanych występuje na ogół głębokie fizyczne i psychiczne odprężenie, pełny, regularny oddech, zmniejszenie napięcia, lęku, strachu oraz troski o to, jakie się robi wrażenie, jak również silna tendencja do zablokowania bodźców rozpraszających uwagę. W niektórych przypadkach osoby badane mogą doświadczać spontanicznej amnezji w stosunku do pewnych części procedury hipnotycznej; bez żadnej sugestii, aby to uczyniły. Osoby wysoce podatne na sugestię, które przeszły pewien trening w osiąganiu głębokich poziomów hipnozy, potrafią w sposób godny uwagi zmieniać swe poczucie rzeczywistości i kontroli.




Zbliżenie


Jak kamyk staje się różą?


„W czasie treningu grupy uczniów szkoły średniej, hipnotyzer (Chanon Rappaport) chciał, aby doświadczyli oni halucynacji zmysłowych. Trzymał on mały kamyk przed jednym z badanych i powiedział mu, że jest to róża niezwykłej piękności i zapachu. Gdy uczeń (widoczny na zdjęciu 7.12) zaczął opisywać zapach oraz wygląd tej „róży”, którą widział na polu pełnym kwiatów, wówczas zaczął nagle dyszeć, jego oczy napełniły się łzami wargi obrzmiały i zaczęło mu ciec z nosa.


U tego młodego człowieka wystąpiła pełna reakcja alergiczna na różę - jedna z wielu alergii, na którą cierpiał. Nowa sugestia hipnotyzera przekształciła tę „różę” z powrotem w kamyk, lecz opisana reakcja układu oddechowego była tak silna, że trzeba było przyjść mu z pomocą, stosując inhalator.


Do bardziej interesujących zmian świadomości, które są charakterystyczne dla doznań hipnotycznych, należą: zniekształcenia percepcyjne, zmiany pamięciowe, regresja (cofnięcie się w latach), wywoływane marzenia senne, sugestia posthipnotyczna oraz zmodyfikowane poczucie czasu.


Zniekształcenia percepcyjne. Niekiedy badani, gdy otrzymają odpowiednią sugestię, mogą spostrzec bodźce, które nie są fizyczne obecnie (halucynacja pozytywna) lub nie dostrzegają tych bodźców, które w rzeczywistości działają (halucynacja negatywna). Można sprawić, aby osoby badane znajdujące się pod hipnozą „ogłądały” wybrane przez siebie filmy; nie tylko relacjonują one poszczególne sceny we właściwym porządku chronologicznym, lecz często towarzyszą temu odpowiednie reakcje emocjonalne, od histerycznego śmiechu do gniewu (Erickson, 1939).
W trakcie demonstrowania studentom wstępnego kursu psychologii zjawiska halucynacji pozytywnych, zahipnotyzowano wykładowcę tego przedmiotu i polecono mu, aby oglądał dobrowolnie wybrany przez siebie film, którego obejrzenie sprawiło mu przyjemność. Gdy zapytano go, jaki film ogląda, ku wesołości licznie zebranych studentów oświadczył (z szelmowskim uśmiechem), że jest to „Behind the Green Door” (Za zielonymi drzwiami) - film na poły pornograficzny. Z drugiej strony, niektórzy badani mogą „nie widzieć” jednej ze wskazówek zegara, słów pisanych przez siebie samych lub nawet innej osoby znajdującej się w pokoju. Takie halucynacje są rzadsze i trudniejsze do osiągnięcia niż złudne doznania, w których zmianie ulegają raczej tylko pewne cechy bodźców, a nie ich całkowita obecność czy nieobecność. W jednej z najbardziej przekonywujących demonstracji tego zjawiska badani, którzy normalnie kaszlą i ksztuszą się pod wpływem amoniaku, będąc pod hipnozą, wąchają go chętnie, bez żadnych trudności oddechowych, jeśli im się powie, że są to egzotyczne perfumy. Podobnie, spostrzeganie temperatury pomieszczenia może pod wpływem hipnozy zmieniać się tak dalece, że badani będą dygotać w ciepłym pomieszczeniu lub też dostaną wypieków w zimnym pokoju, gdy powie im się, że pierwszy pokój jest zimny, a drugi - przegrzany. Redukcja bólu wiąże się z przekształceniem bodźca bólowego w taki sposób, że przestaje on wywoływać lęk, który jest głównym komponentem naszej reakcji bólowej (zob. Rozdział 9).
Niekiedy doznania halucynacji wywołuje się w trakcie procesu rodzenia dziecka, kiedy to hipnozę stosuje się jako środek znieczulający. Można sprawić, aby matka nie dostrzegała instrumentów chirurgicznych, nie odczuwała bólu i nie widziała krwi lub nawet można ją wysłać na halucynacyjne wakacje na Wyspach Karaibskich.
W jednym z badań stwierdzono, że u badanych, których zahipnotyzowano i polecono im widzieć obracający się bębenek, wystąpiły takie same szczególne ruchy oczu, jak wtedy, gdy rzeczywiście obserwowali takie zjawisko.  Natomiast badani ci nie potrafili naśladować tych ruchów w stanie czuwania, gdy polecono im tu czynić (Brady i Levitt, 1964, 1966).
W innym badaniu zahipnotyzowanych pacjentów ćwiczono w halucynacyjnym spostrzeganiu dwóch zielonych kół na białym arkuszu. Gdy rzutowali oni te halucynacyjne koła na czarne i białe tło, wówczas opisywali wystąpienie zwykłego kontrastu jasności: koło na białym tle wydawało się ciemniejsze, na czarnym zaś tle - jaśniejsze, tak że nie wydawały się już one takie same. Podobna grupa badanych, których poproszono, aby reagowali tak, jak gdyby byli zahipnotyzowani, nie opisywała wystąpienia tego kontrastu (Graham, 1969).


Zmiany pamięciowe. Ponieważ cenimy naszą pamięć i jej zdolność do rejestrowania wszystkich naszych ważnych doświadczeń i udostępniania ich na żądanie, przeto myśl, że można by sprawić, abyśmy zapomnieli ważne zdarzenia z naszego życia, wzbudza nie tylko zaciekawienie, ale i niepokój.
Psychologowie badają specyficzne amnezje, takie jak niezdolność do przypomnienia sobie określonego nazwiska, zdarzenia czy przedmiotu.  Wykazano (Orne, 1966), że kiedy zahipnotyzowanym osobom badanym powiedziano, że liczba trzy zniknie z ich pamięci (dopóki nie powie im się, że może powrócić znowu), to badani ci byli niezdolni do posługiwania się tą liczbą w jej właściwych funkcjach. Przy liczeniu badani ci podawali liczby: 
1, 2, 4, 5... lub 21, 22, 24, 25... Gdy poproszono ich, aby policzyli swoje palce, byli oni zdumieni odkrywając, że mają sześć palców przy każdej ręce: 
1, 2, 4, 5, 6! Zawodzili w prostych działaniach arytmetycznych: 6+6=12, a 6+7 również według nich było 12. Badani ci zdawali sobie sprawę z tej niezgodności i reagowali na nią zakłopotaniem, lecz nie mogli wyjaśnić jej ani usunąć przez ponowne odkrycie utraconej trójki. Zakłopotanie to było większe u badanych o większej wiedzy matematycznej, ponieważ niemożność wykonania prostych dodawań i odejmowań zawierających liczbę trzy podważała w sposób zasadniczy ich poczucie kompetencji. 


Badania wykazały, że amnezję hipnotyczną stwierdza się znacznie częściej u dzieci niż u dorosłych. Dzieci są bardziej podatne na sugestie hipnotyczne, a ponadto ich pamięć jest słabsza niż u dorosłych. W jednym badaniu, w którym porównywano amnezję dziesięciu określonych niedawno doświadczonych zdarzeń (sytuacje występujące podczas wykonywania grupowego testu podatności na sugestię), dzieci, które były hipnotyzowane, zapomniały istotnie więcej zdarzeń niż grupa porównawcza złożona z dzieci od 9 do 15 lat, które nie były hipnotyzowane (Cooper, 1972). Nie wykazano jednak przekonywująco, że zapominanie takie jest wynikiem „hipnozy”, a nie innych zmiennych działających w sytuacji testowania (Orne, 1966; Evans i Kilhlstrom, 1973).


Regresja. Regresja (cofanie się w latach; „age regression”) stanowi szczególny przypadek zniekształcenia pamięciowego. Niektóre osoby poddane hipnozie zdają się być zdolne do ponownego przeżywania minionych wydarzeń ze swego życia. Tego rodzaju przypomnienie tych zdarzeń różni się od zwykłego przypominania sobie minionych wypadków, ponieważ badany traci możliwość rozróżnienia pomiędzy aktualną sytuacją, w której odtwarza przyszłość a pierwotną sytuacją, która jest odtwarzana. Gdy „cofniętych w latach” poprosi się o opisywanie swych doznań, zwykle mówią o nich, jak o wydarzeniach zachodzących w danej chwili, używając czasowników w czasie teraźniejszym, zamiast w czasie przeszłym (podobnie jak to było w przypadku Chucka, opisanym w Rozdziale 4). Charakter pisma, mowa, maniery oraz przejawy emocji również na ogół dostosowują się do danego wieku. Gdy studentów wyższej uczelni „cofnie się” do lat niemowlęcych, wówczas opisują oni później, że nie czuli się sami mniejsi, lecz wszystko wokół siebie spostrzegali jako niezwykle duże - swoją kołyskę, butelkę do karmienia niemowląt, palec matki, a zwłaszcza olbrzymie twarze zaglądające do ich kołyski. Dzieje się tak dlatego, że proces wzrastania jest tak powolny i ciągły, iż nie spostrzegamy wzrostu naszego ciała. Ze względu na tę pozorną stałość wielkości naszego własnego ciała, jest prawdopodobne, że uczymy się posługiwać nią jako standardem, w porównaniu z którym oceniamy wielkość innych przedmiotów; znacznie rzadziej posługujemy się innymi przedmiotami dla oceny wielkości ciała. Być może miałeś podobne doznanie bez hipnozy - powróciwszy po latach w miejsce dobrze zapamiętane z czasów dzieciństwa, przekonałeś się, że wszystko wydaje się o wiele mniejsze niż „było” wtedy.
Wykonywanie pewnego prostego zadania przybliży ci po części doznania związane z regresją. Na linii zamieszczonej poniżej napisz swoje imię i nazwisko ołówkiem. Zastosuj się jednak do następujących trzech warunków: trzymaj ołówek bardzo mocno, pisz powoli (naciskając mocno) i zamknij oczy, gdy tylko postawisz pierwszą kreskę.


No cóż, czy sprzężenie zwrotne odbierane w trakcie wykonywania tego zadania ożywiło jakieś niejasne poczucie tego, jak czułeś się będąc malcem mniej więcej siedmioletnim? Spróbuj dać to zadanie swoim kolegom.


Niektórzy badacze posługiwali się zjawiskiem cofania się w latach dla uzyskania dowodów, że w pamięci przechowywane są wszystkie informacje sensoryczne. Jednakże w kontrolowanych warunkach eksperymentalnych przypuszczenie to nie zostało potwierdzone. Część tego, co przypominają sobie badani, nie są to autentyczne szczegóły z dzieciństwa, lecz wymyślone dodatki i zniekształcenia pamięciowe. Wykazano, że proporcja wiarygodnych wspomnień uzyskana od badanych „cofniętych w latach” |nie była większa, niż w przypadku nie zahipnotyzowanych osób badanych odgrywających rolę dzieci (O’Connell, Shor i Orne, 1970). Jednakże w tych samych badaniach, w których osoby badane zostały albo „cofnięte” za pomocą hipnozy do wieku 10 lat, albo też powiedziano im, aby odgrywały rolę dzieci w tym wieku, żaden z badanych będących pod hipnozą nie włączył zwrotu „na Boga” („under God”) do wygłoszonego przez siebie (uczniowskiego) ślubowania wierności (Pledge of Allegiance), podczas gdy uczyniła to połowa osób odgrywających rolę dziecka. Zwrot ten został dodany do ślubowania uchwałą Kongresu, z roku 1954, a zatem nie występował w ślubowaniu składanym przez te osoby badane, gdy miały one 10 lat. Rygorystyczne, eksperymentalne udowodnienie prawdziwości hipnotycznej regresji nasuwa poważne problemy metodologiczne.  Gdy osoby badane „cofnięte w latach” za pomocą hipnozy porównuje się z grupami kontrolnymi, to znaczną część ich regresywnego zachowania można przypisać intencjonalnemu naśladowaniu wcześniejszych zachowań, tendencyjności czy pomocy ze strony eksperymentatora, charakterystycznym wymogom sytuacji badania oraz innym proceduralnym artefaktom.


Wywoływane marzenia senne. Marzenia senne można wywoływać za pomocą sugestii hipnotycznej albo w trakcie posiedzenia (sny na jawie), albo wówczas, gdy dana osoba normalnie pójdzie spać wieczorem (wywoływane nocne marzenia senne). W podawanych osobom badanym sugestiach można określić charakter snu lub jego jakość emocjonalną albo też można nie podawać szczegółowych ograniczeń. Badanym mówi się także, aby zapamiętali swoje sny.
Jakie są sny wywoływane za pomocą hipnozy, w porównaniu ze zwykłymi marzeniami sennymi? W jednym z badań eksperymentatorzy stwierdzili, że mają one wiele wspólnego pod względem występujących w nich postaci, sytuacji oraz akcji. Analiza treści snów hipnotycznych ujawniła większą nieokreśloność, niejasność oraz metamorfozy kształtów. Uderzającą cechą snów hipnotycznych były transformacje własnego ja (doznania „przebywania poza własnym ciałem”, podwojenia jaźni itd.), innych ludzi lub przedmiotów („następnie zobaczyłem Jerry, a jej oddech zmienił się w błysk flesza”) oraz miejsc i stanów, takich jak unoszenie się na wodzie czy w powietrzu, spadanie i zmienianie wielkości (Hilgard i Nowlis, 1972).


Sugestia posthipnotyczna. Gdy osobie będącej w stanie głębokiej hipnozy podaje się sugestię, aby później, po zakończeniu posiedzenia hipnotycznego, wykonała pewne działanie w odpowiedzi na określony sygnał, to określa się to jako sugestię posthipnotyczną. Można też polecić, aby dana osoba zapomniała o źródle tej sugestii, tak, aby czuła się ona zmuszona zachować się w określony sposób, nie wiedząc dlaczego to robi. Nawet wtedy, gdy osoby badane opierają się sugestii posthipnotycznej, występują oznaki konfliktu.
Nic dziwnego, że zjawisko to wzbudza duże zainteresowanie, ponieważ wydaje się ono uderzającym przykładem nieświadomej kontroli nad zachowaniem. W rzeczywistości badania wykazały, że sugestie posthipnotyczne |nie są skutecznym środkiem zmuszania ludzi, aby zachowywali się oni w sposób, który normalnie uważaliby za niepożądany. Posthipnotyczne sugestie często nie są wcale skuteczniejszym środkiem zapewnienia uległości niż bezpośrednie polecenie wydawane czuwającym osobom. Mogą one być jednak użyteczne wtedy, gdy dotyczą zachowań, których dana jednostka, mimo chęci, nie może opanować, takich, jak na przykład palenie.


Zmiany perspektywy czasowej. Hipnozą można się posługiwać nie tylko dla ożywienia wspomnień przeszłości lub do wpływania na przyszłe reakcje, lecz w celu zmiany percepcji samego czasu.
„Czas” jest, w pewnym sensie, naszym największym wynalazkiem: dzięki niemu nadajemy znaczenie naszej przeszłości i cel naszej przyszłości.  Wszystko, co „naprawdę” posiadamy to teraźniejszość; bez założeń dotyczących czasu nie moglibyśmy stworzyć pojęć przyczynowości, stałość ani historii.
„Przeszłość” i „przyszłość” są w swej genezie pojęciami abstrakcyjnymi, w przeciwieństwie do zmysłowego podłoża naszego doświadczenia teraźniejszości. Przywykliśmy jednak myśleć o nich tak, jakby były fizycznie realne, tak realne, że teraźniejszość w istocie zostaje im podporządkowana. Instytucje społeczne regulują zachowanie indywidualne nakłaniając nas do oceniania naszych obecnych działań i kierowania nimi w zależności od naszej przeszłości i z uwzględnieniem przyszłości.


W rzeczywistości możemy stać się tak zaabsorbowani przeszłością i przyszłości, że całkowicie przestaniemy dostrzegać naszą teraźniejszość.  Pewien sprzedawca, poproszony, aby określił metaforycznie czas, odpowiedział: „Mam jeden pakunek wypełniony moimi doświadczeniami i druki - moimi oczekiwaniami - to wszystko”. „A co z teraźniejszością?” zapytano go.  Odpowiedział: „Jest to przejście między nimi”. W jakiej mierze |twoje codzienne życie stanowi takie przejście skądś dokądś, bez zwracania uwagi na to, gdzie |jesteś teraz?


„W pewnym badaniu, które miało na celu ustalenie skutków zmiany perspektywy czasowej, dwunastu osobom badanym ćwiczonym w zapadaniu w stan hipnozy oraz osiemnastu osobom z grupy kontrolnej wydano pod hipnozą polecenie, aby „pozwolili teraźniejszości rozszerzyć się i aby przeszłość i przyszłość stały się odległe i mało ważne”. Pod wpływem tej tylko jednej sugestii, zahipnotyzowane osoby badane (w przeciwieństwie do nie zahipnotyzowanych osób z grupy kontrolnej, spośród których niektóre odgrywały rolę osób zahipnotyzowanych) były zdolne zmienić swą percepcję czasu. Wystąpiły poważne zmiany w myśleniu, odczuwania i działaniu.
Temu stanowi „rozszerzonej teraźniejszości” towarzyszyło ogólne przejście od orientacji analityczno-racjonalnej do orientacji bardziej impulsywnej, spontanicznej, zmysłowej. Badani studenci wyższej uczelni stali się bardziej emocjonalni, mniej zahamowani i mniej posłuszni wymaganiom eksperymentatora, natomiast byli bardziej pochłonięci czynnościami wykonywanymi w danej chwili (ryc. 7.13).




* * *



Ryc. 7.13. Jeden z badanych mających poczucie „rozszerzonej teraźniejszości”, któremu powiedziano, że odczuwa gniew, nie znalazłszy pewnego nazwiska w książce telefonicznej, zaczął drzeć ją na kawałki.  Wystąpiło zjawisko „zarażenia” („contagion effect”), gdyż dwaj inni obecni przy tym badani przyłączyli się do destrukcyjnej aktywności, chociaż nie otrzymali takiej sugestii. Podobne „zarażenie emocjonalne”, utrata zahamowań i nieopanowane zachowanie wystąpiły w innych grupach, w których jednemu z badanych mówiono, że uważa on tę sytuację za zabawną.


* * *





Niektóre osoby badane stały się tak dalece zdezorientowane na teraźniejszość, że nie były zdolne odpowiadać na pytania dotyczące zdarzeń, które zaszły zaledwie przed paroma minutami:
Pytanie: „Jak się czułeś, kiedy lepiłeś z gliny?”
Odpowiedź: „Pamiętam, że czułem się bardzo, bardzo dobrze. Lecz to była glina, a teraz jest ołówek i papier. To jest zdumiewające, jak ołówek może zrobić znaki na papierze, które inni ludzie mogą czytać i rozumieć... Ja naprawdę nie mogę myśleć o lepieniu z gliny. Te pytania zakłócają mój proces myślowy. T wzbudza we mnie gniew. Ale ja nie dbam o to, ponieważ to wszystko jest fantastycznie zdumiewające. Mogę słyszeć krew krążącą w mych uszach... Teraz zastanawiam się, dlaczego tak jest. Nie ma już miejsca.  Okładka brulionu”.
Nawet gramatyka i charakter pisma podlegają zmianom, ponieważ one również są związane ograniczeniami, jakie zwykle nakłada przeszłość i przyszłość (Zimbardo, Marshall i Maslach, 1971). Reprodukowane obok próbki ukazują zmiany, jakie zaszły w perspektywie czasowej i charakterze pisma pewnej osoby badanej.


W kilku pracowniach psychologicznych prowadzone są badania, które mają na celu rozszerzenie naszej wiedzy na temat roli, jaką odgrywa czas w naszym zachowaniu i świadomości; w badaniach tych zmienia się w różny sposób perspektywę czasową, a następnie obserwuje się, w jaki sposób wpływa to na osoby badane.


„Dla wszystkich dróg w świecie istnieje tylko jeden kierunek, a czas jest jego jedyną miarą.
Tom Stoopard
„Rosencrantz and Guildenstern Are Dead”, 1967




Wyjaśnienia zjawiska
hipnozy




Hipnoza nie jest podobna do zwykłego snu, o czym świadczy porównanie zapisów EEG osób śpiących i zahipnotyzowanych. Jest to inny, zmieniony stan świadomości. Osoba znajdująca się pod hipnozą zgadza się zawiesić, odłożyć swoje zwykłe, krytyczne, „sprawdzające rzeczywistość” postawy i iść za sugestiami hipnotyzera. Procedury wprowadzenia w stan hipnotyczny wytwarzają stan wzmożonej, selektywnej uwagi. Dana osoba „odfiltrowuje” zakłócenia powodowane przez nieistotne elementy rzeczywistości oraz skupia się na zasugerowanych doświadczeniach i doznaniach.
Stan hipnozy można wywołać różnymi technikami; przekazuje się w nich osobom badanym, że powinny one: a) odprężyć się, b) skoncentrować, c) pozwolić działać swobodnie swej wyobraźni, d) zgodzić się dobrowolnie, aby umysł i ciało „zachowywały się w sposób niedowolny”, e) pozwolić, aby w razie potrzeby związki czasowe, przestrzenne, fizyczne i przyczynowe uległy zniekształceniu lub dysocjacji i wreszcie f) reagować na sugestie hipnotyzera.
Zasadnicze znaczenie dla całego tego procesu ma zmiana w systemie przekonań osoby znajdującej się pod hipnozą: zaczyna ona wierzyć, że |potrafi kierować ciałem i psychiką, w taki sposób, jaki uprzednio uważała za niemożliwy, lub że może przestać kierować zjawiskami, którymi uprzednio kierowała automatycznie. Celem treningu hipnotycznego jest pokierowanie daną osobą w taki sposób, aby umiała hipnotyzować samą siebie, to jest, aby potrafiła kierować różnymi fizjologicznymi i behawioralnymi procesami za pomocą autosugestii. O tym, w jakim stopniu techniki takie mogą zwiększać możliwość kontrolowania przez daną osobę wpływu zagrażającego środowiska, świadczy fakt, że nawet w ostatnim stadium raka intensywny ból może być poddany kontroli pacjentów w takim stopniu, iż nie potrzebują oni już uciekać się do morfiny w ostatnim okresie swego życia (Sacerdote, 1966).
Okazuje się, że istnieją różnice indywidualne w podatności na hipnozę; stwierdza się je w trakcie pierwszych formalnych prób zahipnotyzowania.  Okazało się, że ta obiektywna miara podatności na hipnozę jest dobrym predyktorem reaktywności na różne zjawiska hipnotyczne. Jednakże stwierdzono niewiele związków pomiędzy czynnikami osobowościowymi lub społecznymi a podatnością na hipnozę. W tabeli podano procenty ogólnej liczby badanych, którzy wykazywali różne poziomy podatności na hipnozę wtedy, gdy po raz pierwszy poddano ich procedurze polegającej na wywoływaniu i kontroli stanu hipnotycznego. Pomiary takie często wykazują wysokie korelacje z pomiarami przeprowadzonymi nawet dziesięć lat później (Hilgard, 1965). Niektórzy badacze uznali to za dowód, że podatność na hipnozę jest stosunkowo stałą cechą osobowości. Badania kliniczne Josephine Hilgard (1970) nad osobami poddawanymi hipnozie wykazały, że osoby ciekawe, śmiałe, o żywej wyobraźni są bardziej podatne na hipnozę niż osoby rywalizujące, opanowane, bojaźliwe.


Poziom Podatności Na Hipnozę Przy Pierwszej Próbie. Tabela przedstawia wyniki uzyskane od 533 badanych zahipnotyzowanych po raz pierwszy.  Podatność na hipnozę mierzono za pomocą 12-stopniowej „Stanford Hypnotic Susceptibility Scale”.


a) Ogólny Poziom; b) Wskaźnik podatności; c) Liczba badanych; d) Procent 
badanych
a) Bardzo wysoki; b) 11-12; c) 56; d) 11
a) Wysoki; b) 8-10; c) 100; d) 19
a) Średni; b) 5-7; c) 151; d) 28
a) Niski; b) 0-4; c) 226; d) 42
(Adaptowane z Hilgarda, 1965)


Badania przeprowadzone nad 140 parami bliźniąt i ich rodzinami (Morgan, 1973) potwierdziły przypuszczenie, że podatność na hipnozę może mieć pewien komponent genetyczny. Przy zastosowaniu „Stanford Scale of Hypnotic Susceptibility” (Stanfordzkiej Skali Podatności na Hipnozę) uzyskano istotnie wyższe korelacje dla bliźniąt jednojajowych niż dla bliźniąt dwujajowych i stwierdzono istotny wpływ dziedziczności.
Z drugiej strony, istnieją także dane świadczące o społecznym uczeniu się podatności na hipnozę, przy czym dla dzieci modelem jest prawdopodobnie zachowanie się rodzica tej samej płci. Wykazano również, że wskaźniki podatności na hipnozę można podnieść prezentując osobom badanym za pomocą magnetowidu wzory zachowań do naśladowania (Diamond, 1972). Ponadto u studentów wystąpił istotny wzrost wskaźników podatności na hipnozę po okresie uczestniczenia w eksperymentalnej „grupie spotkaniowej” („encounter group”), być może dzięki temu, że rozwinęło się u nich większe poczucie zaufania (Shapiro i Diamond, 1972).
Niektórzy badacze argumentują, że wszelkie zjawiska hipnotyczne odzwierciedlają jedynie silne stany motywacji. Theodore Barber (1970) wykazał, że wiele zachowań przypisywanych „stanowi hipnozy” można odtworzyć nawet u badanych niezahipnotyzowanych, dając im po prostu zbiór motywujących instrukcji w stanie czuwania.
Chociaż część następstw hipnozy można przypisać tej samej motywacji, która działa w przypadkach „uzdrawiania przez wiarę” (Frank, 1963), istnieje pewien skutek specyficzny dla hipnozy, którego nie można sprowadzić do „efektu placebo”.


„W pewnym dobrze kontrolowanym badaniu rejestrowano progi bólu, jak również subiektywne i fizjologiczne reakcje na stres w postaci bólu ischemicznego („ischemic pain” - ból na skutek niedokrwienia po zahamowaniu przepływu krwi tętniczej w ramieniu np. za pomocą opaski uciskowej).  Osobami badanymi było 24 studentów wyższej uczelni, mężczyzn, którzy zgłosili się na ochotnika i którym płacono za udział w eksperymencie.  Następnie przeprowadzono z nimi dwa dodatkowe posiedzenia o charakterze „podwójnie ślepej próby” - w jednym z nich byli oni przekonani, że pewien środek farmakologiczny (w rzeczywistości placebo) uśmierzył ból, a drugim powiedziano im po prostu pod hipnozą, że nie będą odczuwać żadnego bólu. Na podstawie przeprowadzonych uprzednio badań wiedziano, że połowa osób badanych jest wysoce podatna na hipnozę, druga zaś połowa nie jest na nią podatna.
Stwierdzono znaczny „efekt placebo” powodujący redukcję bólu, zarówno u badanych, którzy otrzymali placebo, jak i u tych, którzy byli poddani hipnozie; nie stwierdzono jednak korelacji pomiędzy stopniem podatności na hipnozę a wielkością reakcji na placebo.




* * *



Ryc. 7.15. Redukcja Bólu Za Pomocą Hipnozy I Placebo. Fakt, że redukcja bólu w trakcie hipnozy u wysoce podatnych na hipnozę badanych była większa niż u badanych o niskiej podatności na hipnozę lub w którejkolwiek z innych grup, wskazuje, iż hipnoza wywierała dodatkowy wpływ.


* * *





W procedurze hipnotycznej i w procedurze polegającej na podaniu placebo wystąpiło poza efektem placebo zjawisko zniekształcenia percepcyjnego (perceptual distortion effect) u tych badanych, którzy byli wysoce podatni na hipnozę i zostali wprowadzeni w stan głębokiej hipnozy; pozwoliło im to wytrzymywać ból istotnie dłużej niż badanym w jakiechkolwiek innych warunkach eksperymentalnych” (McGlashlin, Evans i Orne, 1969).


Inni badacze wykazali, że osoby badane (studenci i studentki wyższej uczelni) wyćwiczone w uzyskiwaniu za pomocą hipnozy stanu odprężenia i intensywnej koncentracji, potrafiły zmieniać temperaturę skóry obu swych rąk w zróżnicowany sposób w tym samym czasie. Zamieszczony obok wykres pokazuje zmiany temperatury skóry u jednej z osób badanych, której polecono, aby sprawiła, by jej lewa ręka była cieplejsza, a prawa ręka zmniejsza niż normalnie, a następnie, po pewnym czasie, aby powróciły one do temperatury normalnej. U niezahipnotyzowanych badanych z grupy kontrolnej, niezdolnych do osiągnięcia stanu tak głębokiej koncentracji, nie wystąpiły żadne wyraźne zmiany w żadnej z rąk (Maslach i in. 1972).




Ogólne spojrzenie
na problem zmian
świadomości




Wielu z nas zdaje sobie sprawę, że proces warunkowania kulturowego, któremu podlegaliśmy, ogranicza nasz osobisty rozwój. Nasza codzienna, „oswojona” świadomość jest w zbyt dużym stopniu wypełniona myślami i wrażeniami, które zostały w nas zaprogramowane po to, abyśmy spostrzegali świat w taki sposób, jak tego chcą inni. Nie „widzimy” go samodzielnie - takim, jakim jest lub jakim mógłby być.
Ludzie, którzy poszukują doznań związanych ze zmienionymi stanami świadomości, często czynią to po to, aby uwolnić się od tych społecznych ograniczeń nałożonych na ich uczucia, spostrzeganie i myślenie. Pragną oni nowych form wiedzy o sobie samym i naturze. Mają nadzieję znaleźć poczucie zadowolenia, spokój wewnętrzny oraz pewność, które nadadzą sens ich życiu i treść ich egzystencji.




Czy zmienione stany
świadomości są pożądane?




Zmienione stany świadomości niekiedy przyczyniają się do utwierdzenia wartości moralnych, rozwiązania konfliktów emocjonalnych, pomagają w osiągnięciu twórczego wglądu, umożliwiają osiągnięcie absolutnej radości i harmonii. Jak przekonaliśmy się, na przykład osoby praktykujące zen podlegają bardzo głębokim zmianom i kształtuje się u nich całkowicie nowa orientacja w stosunku do życia.
W niektórych kulturach wspólne doznawanie stanów zmienionej świadomości podczas obrzędów związanych z uzdrawianiem chorego ma nie tylko dobroczynny wpływ na chorą osobę, lecz także pomaga odtworzyć więzi społeczne, które umożliwiają włączenie izolowanych jednostek w daną społeczność.
Dla zbyt wielu osób poszukiwanie zmienionych stanów świadomości stanowi jednakże ucieczkę od trosk i doświadczeń zwykłej egzystencji. Niektórzy studenci, czując się sfrustrowani w swych ambicjach osiągnięcia powodzenia w swym społeczeństwie lub nie widząc żadnej możliwości uzyskania wpływu na politykę państwa, którą uważają za wypaczającą wartości ludzkie i obniżającą jakość życia, zwrócili się „do wewnątrz”, aby spróbować przynajmniej „zrobić porządek w swej własnej głowie”.
Tacy studenci nie „odpadają” zwykle od społeczeństwa, lecz już |są poza nim, odczuwając brak istotnych więzi z rodziną i rówieśnikami oraz brak jakiejś grupy, z którą czuliby się związani. Tam, gdzie zmienionych stanów świadomości poszukuje się z pobudek eskapistycznych, prawdopodobną konsekwencją jest dalsza izolacja danej jednostki od sensownych kontaktów społecznych.




Jak dalece „normalna”
jest zwykła świadomość?




Do tej pory mówiliśmy o zwykłej świadomości w taki sposób, jak gdyby była ona „cała z jednego kawałka”, jak gdyby była całością, pojedynczym, solidnym statkiem do wypraw w przestrzeń kosmiczną. Czy kiedykolwiek brałeś pod uwagę możliwość, że posiadasz nie jeden, lecz dwa rodzaje świadomości?  Z pewnymi poszlakami, przemawiającymi za taką możliwością zetknąłeś w się w Rozdziale 2, w którymi omawialiśmy badania Spery’ego i innych nad rozdzielonymi półkulami mózgowymi. Stwierdzono ostatnio, w sposób raczej pewny, że każda z półkul mózgowych jest wyspecjalizowana w wypełnianiu całkowicie odmiennych funkcji. U większości lewa strona mózgu zajmuje się werbalno-intelektualno-analitycznymi problemami, podczas gdy prawa półkula zajmuje się bardziej spontanicznymi, intuicyjnymi, doznaniowymi aspektami przetwarzania informacji. Wykazano, że tego rodzaju lateralna specjalizacja funkcji mózgowych (ich podział między dwie półkule) występuje tylko u ludzi i jest związana z rozwojem mowy.
Ponieważ lewa strona mózgu zwykle kieruje czynnościami mowy i bardziej sprawnymi ruchami prawej ręki (u ludzi praworęcznych), zatem od dawna przyjmuje się, że jest ona półkulą dominującą. Za przypuszczeniem tym przemawia fakt, że lewa półkula jest zazwyczaj cięższa niż prawa. Badacze obecnie zastanawiają się, czy nie pomylili oni przyczyny i skutków. Być może większy ciężar naszych lewych półkul mózgowych jest wynikiem tego, że wyżej cenimy funkcje racjonalno-analityczne, w których są one wyspecjalizowane, i częściej się tymi funkcjami posługujemy. Prowadzi się obecnie badania, chcąc ustalić, czy w społeczeństwach, które przypisują większe znaczenie intuicyjnym i doznaniowym aspektom życia, stosunek ciężaru dwóch półkul mózgowych nie przedstawia się inaczej niż w naszym społeczeństwie.
W każdym razie nagromadziło się dość dużo danych sugerujących, że te czynności dwóch półkul mózgowych reprezentują różne rodzaje świadomości.  Oba te rodzaje świadomości |uzupełniają |się wzajemnie, lecz jedna z nich nie może całkowicie zastąpić drugiej. Robert Ornstein z Langley Porter Neuropsychiatric Institute (1972) przytacza przekonywującą argumentację za koniecznością bardziej swobodnej interakcji między tymi dwoma rodzajami świadomości, jeśli mamy w pełni zrealizować nasze możliwości.




Streszczenie rozdziału




|Świadomość polega na zdawaniu sobie sprawy z własnych procesów myślowych i zdarzeń zewnętrznych. Nie jest ona zjawiskiem typu „wszystko albo nic”, lecz stanowi raczej kontinuum, zależne w pewnym stopniu od ilości informacji sensorycznej odbieranej przez mózg. |Zmienione |stany |świadomości mogą być wynikiem występowania zbyt dużej lub zbyt małej ilości bodźców, można je wywoływać środkami fizycznymi (takimi, jak alkohol lub środki farmakologiczne) lub środkami psychologicznymi (takimi, jak medytacja czy hipnoza). W ostatnich latach psychologowie wykazują coraz większe zainteresowanie badaniem świadomości jako pewnego aspektu funkcjonowania człowieka.
Do cech charakterystycznych, wspólnych dla różnych zmienionych stanów świadomości, należą: 1) zniekształcenie procesów percepcyjnych, poczucia czasu oraz obrazu własnego ciała, 2) poczucie obiektywności i wykroczenia poza granice własnego ja, 3) poczucie prawdy nie wymagające zewnętrznego potwierdzenia, 4) pozytywna jakość emocjonalna, 5) paradoksalność, 6) niemożność wypowiedzenia swych doznań słowami i wreszcie 7) zjednoczenie i zespolenie.
Sen jest chyba najbardziej znanym spośród zmienionych stanów świadomości.  Jest dość dziwne, że |brak |snu również powoduje zmienione stany świadomości, w których występują takie objawy, jak dezorientacja, halucynacje oraz zniekształcenia percepcji. Objawy te zwykle ustępują, gdy tylko osoba pozbawiona snu wyśpi się porządnie.
Obserwowanie i opisywanie zachowania w formie snu jest możliwe dzięki |elektroencefalografowi (EEG), który rejestruje czynność bioelektryczną mózgu. Można wyróżnić dwa rodzaje snu: fazę REM, w czasie której występują szybkie ruchy gałek ocznych, oraz fazę nie-REM, czyli NREM, w czasie której takie ruchy nie występują. Faza NREM składa się z czterech stadiów o różnej głębokości snu.
Głównymi cechami fazy REM są: 1) zahamowanie dowolnej aktywności mięśniowej, 2) zapis czynności bioelektrycznej mózgu podobny jak w stanie czuwania, 3) okresowa aktywność obejmująca szybkie ruchy gałek ocznych oraz inną aktywność mięśniową oraz 4) nieregularne zmiany (fluktuacje) w działaniu autonomicznego układu nerwowego. Natomiast faza NREM wiąże się z całkowitym oderwaniem od otoczenia. Sen nocny przebiega cyklicznie - polega to na przechodzeniu od fazy do fazy; niemowlęta spędzają wiele czasu w fazie REM, podczas gdy ludzie starsi - bardzo mało.
Odkrycie fazy REM dało początek pierwszym fizjologicznym badaniom nad |marzeniami |sennymi, ponieważ osoby obudzone w fazie REM prawie zawsze podają, że coś im się śniło. Marzenia senne występują także w czasie NREM, lecz tematem marzeń sennych w fazie REM jest zwykle działanie i mają one złożoną fabułę, podczas gdy w marzeniach sennych fazy NREM wyobrażenia zmysłowe występują rzadko.
Jednostka pozbawiona przez pewien czas snu w fazie REM „powetuje” to sobie później, przesypiając większą niż zwykle ilość czasu w fazie REM. U kotów, pozbawionych przez długi czas snu w fazie REM, wzrastała częstość zachowań popędowych - związanych z agresją, popędem seksualnym i głodem.  Wysunięto sugestię, że istnieje pewien związek między schizofrenią a mechanizmami snu w fazie REM.
Freud był przekonany, że marzenia senne pozwalają ujawnić się wypartym impulsom, przekształcając niemożliwą do zaakceptowania, wypartą |treść |utajoną w nieszkodliwą, symboliczną |treść |jawną, która zostaje zapamiętana. Sądził on, że główną funkcją marzeń sennych jest zaspokajanie pragnień i że większość symboli występujących w marzeniach sennych reprezentuje obiekty seksualne. Natomiast Jung sądził, że sny wywodzą się ze |zbiorowej |nieświadomości i zawierają symbole |archetypowe, uniwersalne w swym znaczeniu.
Różnice między snami opisywanymi przez mężczyzn i kobiety są odzwierciedleniem ról związanych z płcia, jakie występują w naszym społeczeństwie; nie wiadomo, czy różnice między tymi opisami odpowiadają rzeczywistym różnicom w treści snów. Sny dzieci częściej zdają się być odbiciem lęków niż spełnieniem pragnień. Aczkolwiek |koszmary |senne często występują zarówno u dzieci, jak u dorosłych, to jednak mało wiadomo na ten temat.
Długotrwała |deprywacja |sensoryczna lub niski poziom nieustrukturalizowanej stymulacji powoduje żywe halucynacje oraz zniekształcenia percepcyjne; zaburzenia te człowiek może wytrzymać jedynie przez krótki czas.
Do wywoływania zmienionych stanów świadomości od dawna stosuje się środki farmakologiczne. Wszelkie środki, które oddziaływają na procesy psychiczne, nazywa się środkami |psychotropowymi. |Środki |halucynogenne to takie środki, które wywołują halucynacje; dla ich określenia używa się także nazwy |środki |psychodeliczne. |Środki |psychozomimetyczne wywołują symptomy podobne do tych, jakie występują w psychozach.
Do środków psychotropowych, stosowanych w Stanach Zjednoczonych należą: 
tytoń, alkohol, konopie indyjskie (marihuana), narkotyczne środki znieczulające, środki nasenne, środki pobudzające i środki halucynogenne.
|Marihuana wywołuje lekkie uzależnienie psychiczne, natomiast nie wywołuje uzależnienia fizycznego. Skutki jej używania są zróżnicowane w zależności od czynników społecznych i osobowościowych występujących w danej sytuacji. |Narkotyczne środki |znieczulające, takie, jak morfina i heroina, uśmierzają ból i wywołują euforię. Środki te szybko powodują wytworzenie się tolerancji oraz silnego uzależnienia, zarówno fizjologicznego, jak i psychicznego. Niejednakowa jakość sprzedawanych pokątnie narkotyków często prowadzi do śmierci wskutek ich przedawkowania.
Do |środków |nasennych należą barbiturany i zbliżone środki farmakologiczne. Działają one hamująco na ośrodkowy układ nerwowy i są stosowane jako środki uspokajające. Łatwo wytwarza się uzależnienie psychiczne, natomiast długotrwałe stosowanie tych środków powoduje także powstanie uzależnienia fizjologicznego i tolerancji.
|Środki |pobudzające obejmują amfetaminę i metamfetaminę. Początkowo środki te wywołują ożywienie i zwiększają poczucie własnych możliwości, lecz przedawkowanie może powodować niepokój i paranoidalne lęki. Szybko wytwarza się uzależnienie psychiczne. Po okresie zażywania tych środków następuje zwykle „załamanie” i cykl ten powtarza się bez końca.
|Środki |halucynogenne, takie, jak LSD i meskalina, oddziałują na ośrodkowy układ nerwowy, zwiększając wrażliwość i powodując zniekształcenia percepcji. Tolerancja wytwarza się szybko i równie szybko zanika. Nie występuje uzależnienie fizjologiczne, a uzależnienie psychiczne jest niewielkie. W odpowiednich warunkach środki te mogą powodować religijne doznania transcendentalne.
Do czynników, które wpływają na działanie środków farmakologicznych, należą: 1) skład chemiczny danego środka i wielkość dawki, która może mieć różny wpływ na różne jednostki, 2) tolerancja wytworzona w wyniku uprzedniego zażywania danego środka, 3) oczekiwania osoby zażywającej, 4) cechy osobowości osoby zażywającej oraz 5) sytuacja społeczna, w której dany środek jest zażywany.
|Medytacja, |joga i |zen polegają na ćwiczeniu umysłu w oddziaływaniu na siebie samego, w celu wywołania zmienionych stanów świadomości. W technikach tych stosuje się całkowitą koncentrację na pojedynczym, niezmiennym bodźcu. |Medytacja |transcendentalna polega po prostu na skupieniu się i odprężeniu, bez obrzędów religijnych czy zmiany stylu życia. Powoduje ona mierzalne zmiany fizjologiczne i przynosi podobno wiele korzyści natury psychicznej. |Joga to połączenie medytacji z ćwiczeniami fizycznymi i ćwiczeniami oddychania. W swych tradycyjnych formach wymaga ona również przestrzegania pewnych zasad duchowych. Wyćwiczony jogin może wywoływać znaczne zmiany w swych procesach metabolicznych. |Zen stanowi pewną formę buddyzmu, polegającą na oczyszczaniu swego ja i poszukiwaniu oświecenia.
Spośród wszystkich zmienionych stanów świadomości hipnoza jest stanem najlepiej znanym i najmniej rozumianym. |Mesmeryzm, czyli „magnetyzm zwierzęcy”, zdobył dużą popularność w XVIII wieku jako rzekome „lekarstwo na wszystko”. |Hipnoza, w czasie której występuje niezwykle duża podatność na sugestię, stała się przedmiotem poważnych badań dopiero w paru ostatnich dziesiątkach lat.
Do zjawisk charakterystycznych dla stanu hipnozy należą: 1) zniekształcenia percepcji, 2) zmiany pamięciowe, takie jak amnezja, 3) regresja, 4) wywoływane marzenia senne, 5) reagowanie na sugestie posthipnotyczne oraz 6) zmieniona perspektywa czasowa. Hipnoza polega na wytwarzaniu stanu wzmożonej, selektywnej uwagi, w którym dana jednostka zgadza się niejako „zawiesić” rzeczywistość i koncentruje się na sugestiach hipnotyzera. Dzięki treningowi hipnotycznemu osoba badana może uzyskać zwiększoną zdolność regulowania swych własnych procesów fizjologicznych oraz zachowania. Podatność na hipnozę ma być może pewien komponent genetyczny i zdaje się być stała w czasie, aczkolwiek uczenie się również najwyraźniej odgrywa pewną rolę.
Przypuszcza się, że istnieją dwa rodzaje ludzkiej świadomości: 
intelektualno-racjonalna oraz intuicyjno-doznaniowa. Jedynie pozwalając na swobodną interakcję tych dwóch jakości możemy w pełni zrealizować nasze potencjalne możliwości.




Z Frontu Badań




Bierna uwaga: wrota do świadomości i kontroli autonomicznej (Dziękuję Susan Chandler i Joannie Taylor za ich pomoc w przygotowaniu tego artykułu.)


|Erik |Peper „San Francisco State University”


Bierna kontrola nad funkcjami autonomicznymi czy też zmienionymi stanami świadomości jest ważnym procesem, za pośrednictwem którego można wpływać zarówno na zdrowie fizyczne, jak i psychiczne. Dzięki badaniu takich procesów możemy poznawać nowe aspekty naszego rozwoju, a być może doprowadzić do zmian tradycyjnych poglądów na naturę zdrowia i choroby.
Idee prezentowane w tej pracy zaczerpnąłem z dwóch źródeł: po pierwsze, z moich badań nad ludźmi, którzy demonstrują niezwykłą zdolność panowania nad swą psychiką i ciałem (dalej będziemy nazywali ich „adeptami”), i po drugie, z systematycznych badań i obserwacji mechanizmów dowolnej kontroli autonomicznej. W 1971 roku prowadziłem badania nad moim pierwszym „adeptem”, Ramonem Torresem, młodym człowiekiem, który potrafił przebijać sobie policzki szprychami rowerowymi, stwierdzając, że nie odczuwa żadnego bólu. Potrafił on rzeczywiście utrzymać ten stan odprężenia podczas swych doświadczeń, o czym świadczyło wzmożenie aktywności alfa rejestrowanej za pomocą elektroencefalografu. Wyniki te są podobne do uzyskiwanych przez innego badanego, Jacka Schwartza.
Prowadząc badania nad adeptami staram się wykryć: „Co się dzieje?”, „Dzięki jakim środkom czy strategiom adepci ci uzyskują kontrolę autonomiczną czy też osiągają „kosmiczną świadomość?”, „W jaki sposób ich funkcjonowanie wewnętrzne można „przetłumaczyć” (tzn. uczynić obserwowalnym), a następnie umożliwić zwykłym ludziom (tzn. nie będącym „adeptami”) opanowanie go w takim stopniu, aby oni również byli zdolni posługiwać się tymi umiejętnościami?”. Adepci ukazują potencjał zdolności ludzkich i niekiedy ich możliwości zaprzeczają ogólnie przyjętym twierdzeniom psychologicznym. Na przykład stwierdzenia, że nie uczymy się podczas głębokiego snu, zostało poddane w wątpliwość w wyniku badań nad Swami Ramą, członkiem sekty buddyjskiej Shankaracharya w południowych Indiach.
Prowadząc badania nad tym joginem, doktor Elmer Green z kliniki Fundacji Menningera stwierdził, że jogin ów zapamiętywał wszystko, co zdarzyło mu się, gdy był pogrążony w stanie określonym jako „sen jogistyczny”, w czasie którego fale delta stanowiły 40% aktywności elektrycznej mózgu. Swami Rama potrafił dosłownie odtworzyć dziewięć z dziesięciu zdań wypowiedzianych do niego, gdy znajdował się w tym stanie, oraz sformułować własnymi słowami dziesiąte zdanie.
Te obserwacje przeprowadzone na pojedynczej osobie badanej nasuwają pewne wątpliwości co do słuszności uznanej teorii, zgodnie z którą w czasie głębokiego snu uczenie się nie zachodzi. Wskazują one, że najprawdopodobniej po prostu nie potrafimy odtworzyć przyswojonej informacji. Informacja ta jest zakodowana w mózgu i możemy wykorzystywać ją w naszym działaniu, lecz nie mamy do niej świadomego dostępu. Dalsze badania nad takimi osobami, jak Swami Rama potwierdzają spostrzeżenie, że informacja może oddziaływać na nas nawet wtedy, gdy znajdujemy się w stanie nieświadomości. Opisywany jest na przykład przypadek, w którym serce pacjenta w czasie operacji zatrzymało się zaraz po tym, gdy chirurg powiedział głośno: „Chciałbym, aby ten sukinsyn padł trupem” - nie mając na myśli pacjenta, lecz kogoś innego. Powyższa obserwacja daje nam szansę zrewidowania uznawanych przez nas granic funkcjonowania człowieka. Granice te często są określone przez nasze uwarunkowania kulturowe. Badania nad „adeptami” pozwalają nam przezwyciężyć te kulturowe ograniczenia i dojrzeć odmienny obraz rzeczywistości - taki, w którym wiara we własne możliwości wyznacza granicę tego, co jest możliwe.
W badaniach nad „adeptami” i ich zdolnością kontrolowania nieświadomych i autonomicznych funkcji ustaliliśmy, że: a) kontrolę nad organizmem osiąga się dzięki |biernej |uwadze, a nie aktywnym usiłowaniom oraz b) ważnym aspektom tej kontroli nie jest sam |proces i skierowana na niego uwaga - a NIE uwaga skupiona na wyniku czy na celu. Odnosi się to do wszystkich procesów fizycznych, emocjonalnych i umysłowych i z pewnością jest niezgodne z zaleceniami etyki protestanckiej, która pochwala usilne dążenie do celów i osiąganie ich. Taka orientacja przypisuje znaczenie jedynie konsekwencjom, a nie samemu procesowi - celom, a nie środkom. Możemy stwierdzić, że w przypadkach zaburzeń seksualnych głównym komponentem impotencji u mężczyzn czy oziębłości u kobiet jest zjawisko, które występuje wtedy, gdy dana osoba aktywnie „stara się” osiągnąć orgazm, zamiast pozwolić mu nastąpić samemu, wiedząc, że nic się nie stanie, jeśli tym razem on nie nastąpi. Jednym z pierwszych kroków w terapii zaburzeń seksualnych jest nauczenie danej osoby, aby „nie starała się”. Początkowe ćwiczenia w ramach takiej terapii polegają na nauczeniu ludzi, aby spostrzegali za pośrednictwem zmysłów, a nie intelektu. Rzeczywisty stosunek seksualny odkłada się na czas znacznie późniejszy, gdy już każda z osób przyswoi sobie odpowiednie umiejętności z zakresu komunikowania się z partnerem. Ćwiczenia takie mają na celu wyeliminowanie strachu przed niepowodzeniem. Sukcesem nie jest tu |osiągnięcie jakiegoś przyszłego celu, lecz świadomość |procesu przebiegającego w teraźniejszości, tu i teraz.  Świadomość tę osiąga się dzięki subtelnym sposobom uczenia się osiągania stanu biernej uwagi. Na przykład, bodźce seksualne mogą zapoczątkować stan podniecenia; powoduje on skierowanie biernej uwagi na odczucia seksualne, co umożliwia dalsze utrzymywanie się stanu podniecenia. Jeśli jednak ktoś stara się aktywnie, aby być podnieconym, to prawdopodobnie uda mu się jedynie doprowadzić do zaniku podniecenia. Niewątpliwie w tych sprawach droga do sukcesu nie polega na usilnych staraniach!
Dynamika pobudzenia seksualnego jest podobna do mechanizmów, które stanowią podstawę innych form kontroli autonomicznej. Na proces ten istotny wpływ wywiera |bierna |uwaga. Lecz czym jest bierna uwaga? Jest to działanie bez usilnego starania się! Jest to zezwalanie i ukierunkowywanie bez nakazywania. Badanie biernej uwagi wymaga od nas przeciwstawienia się stosowanym zwykle sposobom podejścia; przy badaniu biernej uwagi trudności wynikają z samej natury tego procesu. W momencie, w którym usiłujemy dokonać czegoś, hamujemy bierną uwagę. Jednakże schematy badań są zwykle zorientowane na wymagania i dokonywania. Zjawisko biernej uwagi ma zaś taki charakter, że próby badawcze, które koncentrują się na dokonaniach, w rzeczywistości eliminują właśnie to, co usiłuje się badać.
Jak wynika z analizy naszych własnych doznań, procesami oddziałującymi na bierną analizę i zakłócającym ją jest przewidywanie i staranie się. Ich wpływu można doświadczyć, gdy |staramy się wydalić kał lub oddać mocz.  Zanim przystąpisz do dalszego czytania tego artykułu, pójdź do łazienki i oddaj mocz. Uświadomisz sobie wiele fizycznych, emocjonalnych i społecznych ograniczeń, jak również napięć i zahamowań w swym organizmie: Jakie one są?  Czy nie czujesz się urażony wymaganiem, jakie wysunąłem wobec ciebie, abyś wykonał tę czynność w tym momencie? Czy twój organizm nie stawia oporu temu arbitralnemu wymaganiu? (zwróć uwagę na to, że aby oddać mocz, zwracasz na ten proces jedynie bierną uwagę i |pozwalasz moczowi płynąć). Gdy |starasz |się oddać mocz, na przykład w gabinecie lekarza, gdy poproszono cię o próbkę moczu do analizy, lub gdy korzystasz z toalety podczas przerwy w przedstawieniu teatralnym, a ludzie stoją w kolejce czekając aż skończysz, wówczas im bardziej się starasz, tym trudniej zapewne będzie ci osiągnąć powodzenie. Wobec tego albo czytasz napisy na ścianach toaletę, aby odwrócić swą uwagę, albo spłukujesz toaletę, aby inni ludzie nie wiedzieli, że jesteś tak napięty. Proces biernej uwagi polega na |zezwoleniu, aby dany proces po prostu przebiegał, co jest przeciwieństwem „normalnego” aktywnego usiłowania, który to styl działania został nam wpojony.
Z drugiej strony, bierną uwagę kształtuje się najlepiej w ćwiczeniach medytacyjnych. Uprawiając medytację człowiek uczy się skupionej, biernej uwagi, bez wkładania wysiłku, bez oczekiwania. Zamiast koncentrować się na wytworach umysłu (myślach i wyobrażeniach), co jest tak częstym przypadkiem w psychologii klinicznej, medytacja koncentruje się jedynie na |procesie; cokolwiek się dzieje, niech się dzieje. Maksymalizuje się istnienie w czasie teraźniejszym. Gdy ktoś przewiduje, martwi się, obawia itd., wówczas wykracza poza teraźniejszość - albo „przeżuwając” przeszłość, albo kłopocząc się o przyszłość”. Powinno się być tam, gdzie się jest, nie „przeżuwając”, nie martwiąc się ani nie śniąc, lecz przeżywając świat wewnętrzny i zewnętrzny taki, jaki jest. 
Ćwiczenia medytacyjne nie koncentrują się na wytworach. Najważniejsze jest „obserwowanie” procesu: |jak dana osoba to robi, a nigdy |dlaczego lub |po |co. Bez „grzebania się” w swych wrażeniach, w wyobrażeniach czy fantazjach uczymy się procesu biernej uwagi. Jest to uczucie podążania za prądem rzeki, a nie walki z nim. W codziennym życiu doświadcza się tego procesu jedynie sporadycznie i znamy to uczucie najlepiej z przyjemnych doświadczeń seksualnych. Zdarza się ono również w zmienionych stanach świadomości: „Chcę osiągnąć wysoki poziom kosmicznej świadomości” - w większości przypadków ów poziom świadomości pojawia się jednakże nieoczekiwanie, gdy człowiek nie stara się o to, a tylko poddaje się danemu procesowi.
Ten proces „działania bez wysiłku” modyfikuje wszelkie czynności. Proces ten jest bardzo podobny do nawykowych wzorców działania a zarazem bardzo od nich różny. Człowiek zwykle wysila się, gdy zajmuje się sportem (napięte mięśnie karku i ramion) lub gdy się uczy (zaciśnięte szczęki). Gdy ktoś wykonuje jakieś ćwiczenie bez wysiłku, wówczas rezultaty są zupełnie inne, niż gdy ćwiczenie to jest „forsowane”. Możesz na przykład spróbować wykonać następujące ćwiczenie polegajace na dotknięciu palcami rąk palców nóg; zwróć przy tym uwage na to, jak odmienne są twoje obecne odczucia w porównaniu z odczuciami powstającymi wtedy, gdy w zwykły sposób wykonujesz to ćwiczenie na zajęciach sportowych - kiedy |wysilałeś |się, aby dotknąć palcami swych stóp. Teraz dotkniesz ich bez wysiłku. Aby tego dokonać pozwól niech twoje ciało, kręgosłup i głowa pochylają się ku przodowi |bardzo |powoli. Zwracaj uwagę na drobne zmiany zachodzące w twoim ciele, gdy powoli zmienia się pozycję. Niech twoje ręce zwisają swobodnie, a nogi niech będą raczej ugięte niż sztywne. Pamiętaj, żeby twoja głowa i szyja były luźno opuszczone i abyś nie trzymał głowy podniesionej do góry. Zdawaj sobie sprawę z napięcia, lecz nie staraj się napinać czy dosięgać. Oddychaj powoli i głęboko. Pochylaj się coraz bardziej, nadal oddychaj powoli i przekonaj się, czy możesz pochylać się jeszcze więcej, nie naprężając szyi ani nie podnosząc głowy. Nie naprężaj się ani nie wychylaj, po prostu |pozwól swemu kręgosłupowi zginać się, a mięśniom grzbietu i nóg napinać się. Gdy pochylisz się tak bardzo, jak to jest możliwe bez wysilania się, to oddychaj nadal, a przy każdym wydechu poczujesz, że nadal „schodzisz w dół”. Następnie podnoś się, znów bardzo |powoli, krąg po kręgu, nie podnosząc głowy, pozwalając, aby głowa zwisała swobodnie. Bądź świadomy zmian zachodzących w pozycji twego ciała, zmian w kręgosłupie, gdy prostujesz się stopniowo, zmian w równowadze. Głowa niech będzie ostatnią częścią twego ciała, która przybierze pozycję pionową. Na koniec oddychaj spokojnie i uświadom sobie, jak twoje ciało czuje się w pozycji stojącej.  Wykonaj to ćwiczenie jeszcze raz; powinno ono zająć ci pięć minut.
Jeśli ćwiczenie to zostało wykonane bez „usiłowań”, lecz ze skierowaniem biernej uwagi na napinanie się mięśni, to prawdopodobnie wydarzyły się dwie rzeczy. Aktywność mięśniowa zmalała, a naczynia krwionośne rozszerzały się w tym miejscu, na którym skoncentrowana była bierna uwaga. Zarejestrowanie tych zmian fizjologicznych może wskazać badaczom, jakim typem uwagi posługuje się dana osoba.
Różne skutki procesów uwagi można zilustrować za pomocą następującego przypadku klinicznego: pewna młoda kobieta, cierpiąca na chorobę Raynauda (w której kończyny pozostają zimne), uczyła się podnosić temperaturę swych rąk przy zastosowaniu termicznego biologicznego sprzężenia zwrotnego („thermal biofeedback”). Zmiany w temperaturze jej skóry wyzwalały sygnały specjalnego aparatu, co wskazywało, że ręka staje się cieplejsza.  Biologiczne sprzężenie zwrotne dostarcza sygnału zewnętrznego, którym dana osoba może posłużyć się dla uświadomienia sobie subtelnych zmian w funkcjonowaniu wewnętrznym (takich, jak zmiana tempa pracy serca lub, w tym wypadku, temperatury skóry).



Na rycinie 7.17 widoczne są stopniowe postępy, jakie pacjentka ta czyniła w ciągu pierwszych sześciu minut ćwiczenia z wykorzystaniem biologicznego sprzężenia zwrotnego. W siódmej minucie przestała ona starać się aktywnie kontrolować swą temperaturę i zaczęła zwracać bierną uwagę na to, czego doświadczała. Chciała ona oczywiście odczuć wzrost temperatury, lecz nie wiedziała, jak osiągnąć ten cel. Jednakże na poziomie biologicznym jej organizm „wiedział”, jak to zrobić - ona musiała jedynie dostroić się do tego procesu. W chwili, gdy zrezygnowała z aktywnych usiłowań, wtedy temperatura jej ręki wzrosła gwałtownie (por. ryc. 7.17). Jeszcze bardziej interesujące jest to, że gdy pacjentka przestała się starać i pozwoliła, aby ciepło napływało do jej rąk, doświadczyła ona także wglądu, w jaki sposób sama wytworzyła swe dokuczliwe fizyczne objawy. Odmawiając osobom ze swego otoczenia swego zainteresowania i uczuć, wytworzyła u siebie fizyczne objawy chronicznej, obwodowej „oziębłości”.




* * *



Ryc. 7.17. Wykres przedstawiający wzrost temperatury skóry rąk kobiety, która uczyła się ogrzewać je przy zastosowaniu biologicznego sprzężenia zwrotnego. Po stopniowej zmienie temperatury w ciągu pierwszych sześciu minut nastąpił znaczny jej wzrost, gdy pacjentka zaprzestała aktywnych starań i jedynie skierowała na ten proces bierną uwagę. W ciągu 30 minut podniosła ona temperaturę skóry swych rąk o 22 st. Fahrenheita (tzn. 12,2 st. C; 0 st. C = 32 st. F, 1 st. C = 1,8 st. F).


* * *





Stwierdziłem, że gdy niedomagania systemu fizjologicznego zostają złagodzone, wtedy często ujawnia się podstawowy problem psychologiczny - jest to uderzająca demonstracja interakcji zachodzących między psychiką a ciałem. W procesie dążenia do uzyskania kontroli nad układem autonomicznym, przy zastosowaniu biologicznego sprzężenia zwrotnego, opisywana tu kobieta weszła w bliższy kontakt ze swymi świadomymi i nieświadomymi procesami, dzięki czemu była w stanie przywrócić stan harmonii między psychiką a ciałem. Jest to podstawa dla przekształcania stanów chorobowych w stan zdrowia.
Aby ułatwić opanowanie autonomicznej kontroli za pośrednictwem biernej uwagi, często stosuje się biologiczne sprzężenie zwrotne i trening autogeniczny. W treningu autogenicznym dana osoba zwraca bierną uwagę na swą rękę i mówi do siebie: „Moja prawa ręka jest ciężka” lub „Moja prawa ręka jest ciepła” i coś się dzieje: aktywność elektromiograficzna (mięśniowa) zmniejsza się, a przepływ krwi zmienia się w tych miejscach, na których skoncentrowana jest bierna uwaga.
Należy zdawać sobie sprawę, że wstępnym warunkiem wystąpienia biernej uwagi jest głębokie odprężenie się. Głębokie odprężenie się wzmaga ten proces i może nawet być uznawane za niezbędny jego warunek.  Najprawdopodobniej poszczególnym myślom odpowiada określona aktywność mięśniowa. Dlatego też „przeżuwanie” zdarzeń emocjonalnych może prowadzić do wzmożenia lęku. Często na przykład demonstruję tę zależność, posługując się biologicznym sprzężeniem zwrotnym, osobom ćwiczącym pod moim kierunkiem (osobom badanym w eksperymencie lub pacjentom). Rejestrujemy aktywność elektromiograficzną mięśni prostujących przedramienia, podczas gdy oni pozwalają tym mięśniom odprężyć się. Celowo używam słowa |pozwalać zamiast samego |odprężać |się, ponieważ „pozwalać” implikuje niestaranie się, podczas gdy „odprężać się” może oznaczać, że trzeba „zrobić coś na siłę”.  Gdy aktywność elektryczna w tych mięśniach spadnie do 1,0 mikrowolta (mięsień całkowicie odprężony), wtedy proszę ćwiczących, aby |wyobrazili sobie podniesienie palców, lecz aby nie poruszali nimi. Krzywa EMG wzrasta wtedy często aż do 2,5 mikrowoltów, wykazując, ze mięśnie kurczą się, mimo że nie było żadnych dostrzegalnych poruszeń ręką ani palcami, ani też świadomego usiłowania poruszania nimi.
Pewne aspekty biernej uwagi mogą także wyjaśnić korzystne dla zdrowia skutki stosowanych w hathajodze ćwiczeń zwanych asana - polegających na specyficznym napinaniu mięśni. Przy wykonywaniu asany „kompletne napięcie” nie jest celem, natomiast dana osoba spokojnie zwraca uwagę na obszar napięcia, pozwalając reszcie ciała odprężyć się. Osoba ta nie zwraca uwagi na cel końcowy ani na osiągnięcia („Jak bardzo potrafię się napiąć?”); zamiast tego spokojnie zwraca uwagę na proces. Przewidywaliśmy zatem, że aktywność mięśni prążkowanych zmaleje i że wystąpią zmiany w krążeniu krwi.  W przypadku asany napięcie |przyciąga naszą bierną uwagę. Rezultat jest ten sam - zmiana fizjologiczna. Asana skierowuje bierną uwagę na określone miejsce. Jeśli tak jest rzeczywiście, to twierdzenia o zbawiennych dla zdrowia skutkach ćwiczeń jogi mogą być uzasadnione. W hathajodze twierdzi się, że stanie na barkach (ze stopami podniesionymi ku sufitowi) wykonuje się w celu wzmożenia funkcji tarczycy. Dlaczego jednak miałoby to mieć takie skutki? Pozycja „do góry nogami” powoduje napięcie mięśni szyi; dana osoba doświadcza wówczas ucisku w obrębie szyi i w gardle, co przyciąga jej bierną uwagę. Zwracanie uwagi na to zjawisko może wywoływać wzrost ukrwienia i wpływać na pracę tarczycy. (Hipotezę tę można sprawdzić stosując termograf i urządzenie do kontroli biologicznej). Zbyt często wielu z nas stara się wykonywać asany bez biernego ukierunkowania uwagi.  Zwykle zakłada się, że dana osoba nauczy się biernej uwagi przez samo działanie; jednakże dana osoba może po prostu kontynuować aktywne usiłowania, ponieważ musimy oduczyć się nawyku pracowania dla osiągnięcia celów i nauczyć się „być częścią środków” (wiodących do celu - przyp.  tłum.). Obecnie próbuję badać występowanie zjawiska biernej uwagi podczas różnych stanów świadomości i podczas ćwiczeń medytacyjnych.
Bierna uwaga jest spoiwem, za pomocą którego łączymy nasze świadome i nieświadome procesy. Możliwości demonstrowane przez „adeptów” są ilustracją niektórych efektów posługiwania się bierną uwagą. Trening autogeniczny, biologiczne sprzężenie zwrotne, ćwiczenia medytacyjne i ćwiczenia jogi - oto techniki służące rozwijaniu tych samych zdolności. Dzięki temu paradoksalnemu procesowi - umożliwiającemu uchwycenie bez chwytania - otwieramy przed sobą nieskończony świat, w którym możemy rozwijać nasze potencjalne zdolności i uczestniczyć w przywracaniu i utrzymywaniu naszego zdrowia psychicznego, duchowego i fizycznego.




IV. Motywacja

do działania




8. Motywacja i seks w życiu człowieka
9. Emocje i kontrola poznawcza




Rozdział 8.
Motywacja i seks
w życiu człowieka




„Diabeł nakłonił mnie, abym to uczynił!” - oto jedna z odpowiedzi na pytanie: „Dlaczego ukradłeś bochenek chleba?”. Osoba ta nie wypiera się samego czynu, lecz zaprzecza, aby jakiekolwiek osobiste motywy skłoniły ją do kradzieży. W tym wypadku został wysunięty argument, że siła, która zdeterminowała czy spowodowała dane zachowanie, była tak potężna, iż przezwyciężyła opór jednostki. Inne odpowiedzi na to samo pytanie mogłyby brzmieć następująco: „Wziąłem go, aby pomóc ubogiej rodzinie w biedzie” lub „Głodowałem i nie miałem pieniędzy, aby kupić chleb, więc głód zmusił mnie, abym go ukradł”.
Chociaż jest wiele różnych odpowiedzi, które można by tu podać, to wszystkie one mają pewną wspólną właściwość: określają „powody działania”.  |Powody te zwykle są twierdzeniami o przypuszczalnych przyczynach zachowania, a przyczyny te dość często formułuje się w kategoriach |motywów.
Niektóre z tych motywów, takie jak głód, wywodzą się z biologicznych popędów organizmu. Inne, takie jak altruizm, rozwijają się w wyniku społecznych doświadczeń i społecznych potrzeb. Jeszcze inne, występujące w przypadkach działania pod wpływem namiętności, gniewu, z chęci zemsty, z ciekawości, przyczyn natury religijnej i mnóstwa innych, można by umieścić i między motywami biologicznymi a społecznymi.
Kiedy pytamy, co sprawia, że my, a także inne żywe organizmy, „funkcjonujemy”, wówczas zadajemy pytanie dotyczące motywacji. Czy siłą napędową zachowania człowieka są popędy i pragnienia? Dlaczego współzawodnictwo wyzwala najlepsze cechy u pewnych jednostek i zespołów, które „wznoszą się na wyżyny”, zaś najgorsze u innych, które zostają „zdegradowane psychicznie?” Dlaczego niektórzy ludzie są gotowi poświęcić swe życie za to, w co wierzą, podczas gdy inni są tak apatyczni, że zdają się nie dbać o nic? W jaki sposób można się nauczyć dzieci współdziałania z innymi? Co można zrobić, aby zwiększyć produktywność pracowników? W jaki sposób fabrykant może sprawić, aby ludzie „chcieli” produkować? Czy to prawda, że ludzie korzystający z pomocy społecznej nie chcą radzić sobie sami?
Odpowiedzi, jakich udziela się na takie pytania, implikują pewną koncepcję dotyczącą sposobu, w jaki czynniki motywacyjne wpływają na nasze życie. Wszelkie próby zrozumienia zachowania się organizmów opierają się zatem na zrozumieniu zasad motywacji.
Oprócz tego pragnienia zrozumienia motywacji istnieje także nadzieja, że będziemy mogli przewidywać zachowanie, a może i sterować nim, aby podnieść jakość własnego życia i życia innych ludzi. Co wiedza o motywacji mówi nam o technikach służących sterowaniu zachowaniem, jakimi posługują się nauczyciele, rodzice, przedstawiciele handlowi, politycy, treserzy zwierząt, artyści estradowi, osoby zajmujące się poradnictwem małżeńskim, terapeuci oraz inne osoby - z nami włącznie - zainteresowane wywoływaniem zmian w zachowaniu innych ludzi?




Pojęcie motywacji




Nikt nigdy „nie widział” motywacji, podobnie jak nikt nigdy nie „widział” uczenia się. Tym, co w rzeczywistości widzimy, dzięki systematycznej obserwacji sytuacji, bodźców i reakcji, są zmiany w zachowaniu. Aby wyjaśnić czy usprawiedliwić te obserwowane zmiany, wyprowadzamy wnioski o stanowiących ich podłoże procesach psychicznych i fizjologicznych - wnioski te są ujęte formalnie w samym pojęciu motywacji.
Wnioskując o istnieniu wewnętrznej motywacji - w celu wyjaśnienia zachowania - staramy się uprościć złożoną sieć możliwych wzajemnych powiązań w ten sposób, że postulujemy istnienie pojedynczej zmiennej pośredniczącej, która wiąże różne wejścia bodźcowe z różnymi wyjściami w postaci reakcji. Zamiast zatem próbować ustalić zmienne wiążące każdy aspekt sytuacji bodźcowej z każdym aspektem reakcji, postulujemy istnienie ogólnej |zmiennej |pośredniczącej, takiej, jak głód czy pragnienie (ryc.  8.1).
Psycholog, który postawiony w roli Sherlocka Holmesa, musi posłużyć się dostępnym materiałem dowodowym w postaci warunków bodźcowych i obserwowalnego zachowania, aby zidentyfikować tę podstawową zmienną wewnętrzną. Słowa, jakimi posługujemy się dla określenia stanów wewnętrznych odpowiadających tej zmiennej, implikują bez wyjątku związek przyczynowy” |cel, |zamiar, |intencja, |ukierunkowanie |na |cel, |potrzeba, |brak, |popęd, |pragnienie, |motyw. Psychologowie posługują się zwykle terminem |popęd („drive”), gdy przyjmuje się, że źródło motywacji ma przede wszystkim charakter biologiczny. Terminy |motyw i |potrzeba stosuje się częściej dla określenia motywacji psychologicznej i społecznej, co do której zakłada się na ogół, że jest ona przynajmniej w częście nabyta lub wyuczona. Jednakże istnieją różnice między psychologami, jeśli chodzi o sposób posługiwania się tymi pojęciami.




* * *



Ryc. 8.1. Popęd Jako Zmienna Pośrednicząca. Trzy czynniki (zmienne niezależne), które wpływają na zachowanie związane z piciem są przedstawione po lewej stronie schematu, a trzy sposoby mierzenia tego zachowania (zmienne zależne) są uwidocznione po prawej jego stronie. Każdym z trzech czynników po lewej można manipulować, powodując zmiany w miarach po prawej. Zamiast jednak postulować istnienie dziewięciu możliwych zależności, prościej jest postulować istnienie jednej zmiennej pośredniczącej - pragnienia jako mechanizmu, za pośrednictwem którego wszystkie zmienne po lewej wpływają na zmienne po prawej.


* * *





Niektórzy na przykład wolą używać terminu |potrzeby („needs”) jedynie w odniesieniu do potrzeb biologicznych (takich, jak potrzeba wody), niezależnie od tego, czy wywołują one rzeczywiste zachowanie mające zaspokoić tę potrzebę. Ponieważ nie ma świadomych korelatów niedoboru tlenu, nie motywuje on zachowania, aczkolwiek nadmiar dwutlenku węgla motywuje je.
Motywację charakteryzuje: a) wzbudzanie energii, b) ukierunkowywanie wysiłku na określony cel, c) selektywne zwracanie uwagi na istotne bodźce (przy zmniejszonej wrażliwości na bodźce nieistotne), d) zorganizowanie pojedynczych reakcji w zintegrowany wzorzec czy sekwencję oraz e) wytrwałe kontynuowanie ukształtowanej w ten sposób czynności, dopóki nie zostaną zmienione warunki, które ją zapoczątkowały. Poniżej przedstawimy różne stosowane przez psychologów sposoby posługiwania się pojęciem motywacji.




Wyjaśnianie zmienności
zachowania




Podstawową funkcją analizy motywacyjnej jest wyjaśnienie obserwowanej |zmienności zachowania. W jaki sposób możemy wytłumaczyć różnice w reakcji (na tę samą sytuację zewnętrzną), występujące między różnymi ludźmi lub nawet u tej samej osoby w różnym czasie? Kiedy warunki ćwiczenia i testowania oraz zdolności są jednakowe, a wyniki jednostek mimo to różnią się, wtedy różnice w zachowaniu przypisuje się motywacji.
Gdy na przykłąd jeden z dwóch walczących o tytuł bokserów, o równych umiejętnościach, wygra walkę, mówi się, że |chciał on bardziej zwyciężyć lub że bardziej |łaknął zwycięstwa. W sportach zespołowych mówi się, że drużyna, która najbardziej |pragnie zdobyć mistrzostwo, zdobywa je. Wynik ten - zwycięstwo drużyny A i przegraną drużyny B - wyjaśnia się jako różnicę w poziomie motywacji, która spowodowała, że drużyna A „dała z siebie więcej”.
Jednakże nie każde zachowanie wymaga wyjaśnienia motywacyjnego. Na przykład nagły ruch nogi wskutek uderzenia pod kolanem nie jest uważany za dowód istnienia popędu do wyprostowania nogi, lecz traktowany jako niemotywowany odruch. Żadne motywacyjne konstrukty nie są potrzebne dla wyjaśnienia, dlaczego ktoś umiera po porażeniu prądem o wysokim napięciu, natomiast nagła śmierć pozornie zdrowej, starszej osoby, wkrótce po umieszczeniu jej w domu starców, istotnie zdaje się wymagać wyjaśnienia w kategoriach motywacyjnych.
Nie jesz za każdym razem, kiedy jedzenie jest dostępne, ani nie uczysz się tyle, ile byś mógł, przed każdym egzaminem. Być może, nigdy nie poświęciłeś czasu ani energii na doskonalenie się w pewnych umiejętnościach, które są bardzo absorbujące dla innych ludzi. Często trudno nam zrozumieć taką jednostronną koncentrację wysiłku, jaką spotyka się u żonglerów, graczy w jo-jo, połykaczy ognia lub też - co tu ukrywać - u naukowców. Mówimy, że jemy, ponieważ jesteśmy „głodni” i że pracujemy usilnie, aby przewyższyć innych, ponieważ popycha nas pragnienie „osiągnięć”.
Gdyby |każdy w danym miejscu zachowywał się w ten sam sposób w odpowiedzi na pewne zdarzenie bodźcowe, to bardziej interesowałoby nas poznanie tego bodźca niż charakteru tych ludzi czy ich motywacji. Gdyby ktoś reagował identycznie za każdym razem, gdy powstaje pewna sytuacja, to nie interesowałoby nas, „dlaczego” zachowuje się on w ten sposób, a może nawet nie zauważylibyśmy tego związku. Tylko wtedy, gdy w systemie tym występują jakieś „zakłócenia”, odwołujemy się do pojęcia „motywacji”. Kiedy niepokoimy się zbliżającym egzaminem, a ktoś inny nie przejmuje się nim, kiedy podnieca nas jakieś doznanie, które kogoś innego pozostawia obojętnym, lub kiedy uzyskujemy znacznie lepszy lub gorszy wynik niż oczekiwaliśmy - tylko wtedy szukamy przyczyny w motywacji.




Wnioskowanie o ukrytych
dyspozycjach na podstawie
jawnych działań




„Jest zwyczajem prostego ludu nagradzać czyn i nie zwracać uwagi na motyw, ludzi uczonych zaś - nie przywiązywać wagi do czynu i otwierać duszę sprawcy”.
John Barth „The Sot-Weed Factor”, 1960


Większość z nas |zakłada, że zachowanie nasze jest stałe - niezależne od czasu i sytuacji. Jeśli nie jest ono takie, to wówczas przyjmujemy dalsze założenie, że to nie |my zmieniliśmy się w trwały sposób, lecz że nastąpiła |chwilowa zmiana warunków, która sprawiła, iż zachowujemy się inaczej. W takich wypadkach posługujemy się również pojęciami motywacyjnymi, aby wnioskować z tych obserwowalnych czynności zewnętrznych, jakie stany wewnętrzne oddziałują obecnie lub już od pewnego czasu.
Ponadto, w miarę jak ludzie opracowują coraz bardziej złożone koncepcje dotyczące dynamicznych przyczyn zachowania ludzkiego, nie zadowala ich przyjmowanie zachowania „za dobrą monetę”, lecz rozpatrują je jako widoczny wierzchołek ukrytej pod powierzchnią motywacyjnej góry lodowej. Znalezienie motywu czy syndromu motywacyjnego, który najlepiej „pasuje” do danego przypadku, staje się zatem fascynującą intelektualną grą.




Określanie wewnętrznego
źródła zachowania




Motywacja, gdy ujmuje się ją w sensie aktywizacji „celowego” lub „dążącego do celu” zachowania, zapewnia ukierunkowanie zachowania. W ten sposób pojęcie motywacji staje się zmienne z takim pojęciem jak „siła woli”, które implikuje, że źródła zachowania należy szukać |w |danej |osobie, a nie środowisku zewnętrznym. Uważa się, że motywacja dostarcza zachowaniu |energii, podobnie jak węgiel dostarcza energii piecowi.  Motywacja wewnętrzna jest zatem warunkiem poprzedzającym działanie zewnętrzne - jest sprężyną napędową zachowania.
Zupełnie inne przyczyny zmienności zachowania oraz inne istotne wyznaczniki przyczynowe danego działania podają radykalni behawioryści, którzy są zwolennikami podejścia zaproponowanego przez B. F. Skinnera, a zwanego warunkowaniem sprawczym (zob. Rozdział 3). Według nich ważne są nie wewnętrzne warunki poprzedzające daną reakcję, lecz to, co wydarzyło się po podobnych reakcjach w przeszłości. Według nich o ważnych różnicach w zachowaniu decyduje wzmocnienie |następujące |po reakcjach, a nie |poprzedzająca je motywacja. W podejściu tym kładzie się nacisk na rolę środowiskowej regulacji zachowania, na kontrolę zachowania przez bodziec.  Kierunek zachowania nadają czynniki wzmacniające - argumentują behawioryści. Według George’a Reynoldsa z University of California, „ten, kto posługuje się warunkowaniem sprawczym, rzadko wspomina o motywacji, ponieważ stała się ona pojęciem odnoszącym się jedynie do tych warunków, które sprawiają, iż dane zdarzenie stanowi wzmocnienie w danym czasie (...). Warunki motywacyjne stały się jedynie szczegółami technicznymi” (1967, s. 127). Zgodnie z tym poglądem motywacja jest mało ważnym, zakulisowym pracownikiem, który przygotowuje scenę dla wielkiej gwiazdy tego przedstawienia - |czynnika |wzmacniającego („reinforcer”). Dla osoby starającej się zmienić czyjeś zachowanie głód ma zatem wartość jedynie dlatego, że zwiększa efektywność pokarmu jako czynnika wzmacniającego.
Zwolennicy psychologii motywacyjnej odpowiadają na to, że motywacja nie tylko ma pośredni wpływ na zachowanie, czyniąc czynniki wzmacniające „odpowiednimi”, lecz także wpływa na zachowanie bezpośrednio. Motywowana jednostka wytwarza („emituje”) więcej reakcji, reaguje szybciej, częściej, z większym wigorem i wytrwałością niż jednostka nie motywowana. U swobodnie poruszających się zwierząt motywacja zapoczątkowuje poszukiwanie czynników wzmacniających w środowisku - aktywność ta nie jest możliwa w laboratoryjnych badaniach nad warunkowaniem sprawczym, w których eksperymentator kontroluje czynniki wzmacniające i ogranicza eksplorację stwarzając wysoce uproszczone, sztuczne środowisko, takie jak skrzynka Skinnera.




Przypisywanie intencji,
odpowiedzialności i winy




„Nie jesteśmy bardziej pomysłowi w wyszukiwaniach złych motywów dla dobrych czynów dokonywanych przez innych, niż dobrych motywów dla złych czynów, których sami dokonujemy.
Charles Caleb Folton „Lacon”, 1825


Niezależnie od tego, jakie jest właściwe miejsce motywacji w psychologii naukowej, zajmuje ona bardzo ważne miejsce w tradycji prawnej i religijnej, jak również w sposobie myślenia nauczycieli, pracowników społecznych oraz większości nas samych, którzy chcemy wiedzieć od czasu do czasu, co sprawia, iż zachowanie innych ludzi jest tak odmienne od naszego.
W sądownictwie konieczne jest odróżnianie zachowania nieumyślnego od zachowania dobrowolnego, zbrodni popełnionych pod wpływem namiętności od tych, które zostały dokonane z premedytacją, zdarzeń przypadkowych od zamierzonych. U podłoża takich ustaleń znajdują się zjawiska z dziedziny motywacji.




Zbliżenie


Kiedy zabójca nie odpowiada za zabójstwo?


„Ustalenie stanu umysłu sprawcy odgrywa zasadniczą rolę w naszym systemie sprawiedliwości, ten sam czyn -  odebranie życia innej osobie - uznawany jest za |morderstwo, jeśli jest czynem zamierzonym lub za mniej ciężką zbrodnię - zabójstwo - jeśli był nie zamierzony.
Możemy nauczyć się wiele o sposobie pojmowania natury ludzkiej, przyjętym w danym społeczeństwie, na podstawie tego, jak społeczeństwo to określa warunki, w których ktoś, kto pozbawia innego człowieka życia, nie jest pociągany do odpowiedzialności za ten czyn. Aby przekonać się, jak zróżnicowane mogą być tego rodzaju sądy, zaznacz poniżej warunki, które twoim zdaniem powinny „usprawiedliwiać” zabójcę i porównaj swoje odpowiedzi z odpowiedziami twych kolegów.


1. Niezdolność do posługiwania się rozumem, wynikająca z:
... a) młodocianego wieku,
... b) upośledzenia umysłowego,
... c) choroby psychicznej, okresowej lub chronicznej,
... d) tego, że zabójca nie jest człowiekiem - jest na przykład zwierzęciem.


2. Wpływ czynników, które ograniczają posługiwanie się wolną wolą:
... a) narkotyki i środki oszałamiające,
... b) lunatyzm.


3. Wpływ emocji, które biorą górę nad rozsądkiem:
... a) szalona zazdrość
... b) niepohamowany gniew.


4. Zachowania wynikające z sytuacji i wymagań roli, które zmieniają intencję czynu lub indywidualną odpowiedzialność:
... a) państwowy kat
... b) oficer policji na służbie,
... c) żołnierz na wojnie,
... d) obywatel w samoobronie,
... e) ojciec broniący rodziny,
... f) lekarz dokonujący eutanazji dla skrócenia cierpień nieuleczalnie chorego.


Również w pewnych ortodoksyjnych religiach, aby można było przypisać komuś winę za zły uczynek, musi on mieć nie tylko intelektualną zdolność odróżniania dobra od zła, lecz także motywowaną intencję odrzucenia dobra i związania się ze złem. Motywacja odgrywa ważną rolę w pojęciu „grzechu”, odnoszącym się zarówno do |uczynków, jak i do |pragnień. Na przykład „|pożądanie żony bliźniego swego” jest w równym stopniu pogwałceniem Dekalogu, jak kradzież czy przeklinanie.
W swych bardziej popularnych zastosowaniach pojęcie motywacji przekształciło się w „uniwersalne” pseudowyjaśnienie. Stanowi ono podstawę usprawiedliwień, gdy |ty nie robisz tego, co masz robić i podstawę oskarżeń - gdy inni zachowują się w sposób niepożądany.
Używając takich stereotypów motywacyjnych, jak „uczniowie o osiągnięciach mniejszych niż możliwości”, „bezrobotni uporczywie odmawiający podjęcia pracy”, „wyalienowana młodzież”, „bumelanci” i tak dalej, winą za istnienie danego |problemu obarcza się zwykle osobę lub grupę określoną w ten właśnie sposób.
Tego rodzaju stereotypy odwracają również uwagę od czynników występujących w danej sytuacji, które mogą być rzeczywistą przyczyną owych zjawisk. Na przykład w „West Side Story”, w songu „Gee, Officer Krupke” (Oh, panie komisarzu Krupke), „Jets” („Odrzutowce”) wyszydzają „motywacyjny” żargon stosowany przy wyjaśnianiu, dlaczego to są oni takimi „podejrzanymi typkami”.
Jak zaobserwował psycholog George Kelly (1958), nauczyciele najcześciej 
skarżą się, że ich uczniowie „po prostu nie mają takiej motywacji, jaką 
powinni mieć”. Wypytywana nauczycielka


„upierała się, że pewne dziecko nic nie robi - absolutnie nic - tylko siedzi! Sugerowaliśmy zatem, aby popróbowała podejścia niemotywacyjnego i pozwoliła mu „tylko siedzieć”. Poprosiliśmy ją, aby obserwowała, co dziecko robi wtedy, gdy „tylko siedzi”. W każdym wypadku nauczycielka potrafiła opisać pewne niezwykle interesujące zachowania. Analiza tego, co „leniwe” dziecko robiło wtedy, gdy leniuchowało, często pozwoliła jej po raz pierwszy zajrzeć w świat dziecka i dostarczyła jej pierwszych solidnych podstaw do porozumienia się z nim. Niektóre nauczycielki stwierdziły, że ich najleniwsi uczniowie potrafili podawać najbardziej nowatorskie pomysły; inne przyznały, że określenie „leniuchowanie” stosowały do tych czynności, których po prostu nie potrafiły zrozumieć czy ocenić (ss. 46-47).




Ustalanie związku
między procesami
fizjologicznymi
a zachowaniem




Stany motywacyjne są na ogół wywoływane przez |deprywację, czyli pozbawienie jednostki czegoś, co jest potrzebne do funkcjonowania biologicznego czy psychicznego. Na przykład, spędzenie pewnej liczby godzin bez pokarmu jest warunkiem bodźcowym, który wpływa na poziom głodu, a zatem zwiększa motywację do znalezienia pokarmu. Stany motywacyjne może także wywoływać obecność czynników szkodliwych, takich, jak bolesny wstrząs elektryczny, „smog” czy agresywny łobuz. Ponadto, stany te można też wywoływać podając bodźce warunkowane skojarzone z silnymi bodźcami bezwarunkowymi, na przykład ilustracje z „Playboya” lub też romantyczne historie miłosne. I wreszcie, jak przekonaliśmy się w Rozdziale 2, współczesna technika umożliwia bezpośrednie wywoływanie stanów motywacyjnych za pomocą elektrycznej lub chemicznej stymulacji różnych części mózgu. Podobnie, dokonując lezji mózgowych lub wprowadzając bezpośrednio do krwi, żołądka czy innych narządów pewne substancje, można sprawić, że zwierzę będzie głodne, spragnione lub pobudzone seksualnie.
Współcześni badacze nie poszukują już |pojedynczego procesu fizjologicznego stanowiącego podłoże danego popędu. Ich eksperymenty mają na celu zbadanie, w jaki sposób cała konstelacja systemów regulacyjnych współdziała ze sobą, wytwarzając określone stany motywacyjne. Okazało się także, że by zrozumieć wpływ na zachowanie motywacji o podłożu fizjologicznym, trzeba badać interakcję pomiędzy określonymi fizjologicznymi stanami organizmu a odpowiednim zbiorem obiektów czy zdarzeń bodźcowych w środowisku. Te ostatnie określa się jako |podniety („incentive stimuli”). Mogą one uruchamiać pewne sekwencje reakcji i służą jako sygnały ukierunkowujące reakcje we właściwy sposób (Bindra, 1969).  Motywacja wpływa zatem na zachowanie dzięki swej specyficznej funkcji |sygnalizowania („cueing”) i |uwrażliwiania („sensitizing”), jak również za pośrednictwem swego bardziej ogólnego działania aktywizującego, czyli „|dostarczającego |energii” („energizing”).




Funkcje wzbudzenia




Oprócz energii związanej z określonym stanem motywacyjnym może także występować bardziej rozproszone wzbudzenie („arousal”), będące wynikiem działania układu ogólnego wzbudzania („general arousal system”). To nie motywacja budzi nas ze snu czy wywołuje drzemkę w dusznych i nudnych salach wykładowych. To nie motywacja czyni nas czujnymi, gdy odkryjemy obecność dymu, słyszymy, że ktoś wypowiada nasze nazwisko lub widzimy, że światło zielone zmienia się na czerwone. W otoczeniu jest wiele sygnałów, na który szybko musimy reagować i wiele warunków, w których zachowanie zależy od ogólnego stopnia wzbudzenia organizmu. Efektywne działanie wymaga funkcjonowania wielu układów sensorycznych i ruchowych; to też często jest niezmiernie ważne, aby istniała możliwość wzbudzenia ich wszystkich jednocześnie i umożliwienia im optymalnego funkcjonowania w tym samym momencie.
Tę funkcję, polegającą na „budzeniu kory mózgowej” oraz sprawianiu, że organizm jest czujny i zdaje sobie sprawę z tego, co dzieje się w środowisku i ze środowiskiem, spełnia „siatkowaty układ aktywizujący” (RAS - „Reticular Activating System”). Układ ten jest wiązką włókien nerwowych biegnących z rdzenia kręgowego poprzez rdzeń przedłużony do korowych okolic mózgu. Włókna te otrzymują wejścia ze wszystkich zmysłów, dzięki czemu RAS pomaga organizmowi uzyskać lepszy kontakt ze swym środowiskiem, czyniąc go czujnym, pobudzonym i wrażliwym na zmiany w bodźcach środowiskowych (ryc.  8.2). To ogólne wzbudzenie może odgrywać ważną rolę w determinowaniu przejawianego ostatecznie zachowania.
Poziom aktywności może zmieniać się od niskiego poziomu w czasie snu do wysokiego poziomu charakteryzującego stan pobudzenia. W miarę jak wzbudzenie wzrasta, następuje ogólne zwiększenie siły reakcji instrumentalnych, bez względu na ich rzeczywistą użyteczność dla zaspokojenia wymagań motywacyjnych. Ten sam bodziec może spełniać zarówno funkcję |wzbudzającą („arousal function”), jak i funkcję |sygnalizacyjną („cue function”) - przykładem może tu być zapach pokarmu, który może zarówno inicjować poszukiwanie pożywienia, jak i wyznaczać kierunek tego poszukiwania. Niekiedy zaś za wzbudzanie aktywności i jej kierunek odpowiedzialne są za wzbudzanie aktywności i jej kierunek odpowiedzialne są różne bodźce - jak wtedy, gdy zmiany poziomo cukru we krwi wywołują uczucie głodu, a widok pokarmu kieruje nas ku niemu.




* * *



Ryc. 8.2. Widok z boku na mózg małpy, na którym pokazano siatkowaty układ aktywujący (RAS) w pniu mózgu, otrzymujący kolaterale z bezpośrednich dróg aferentnych i wysyłający włókna przede wszystkim do pól kojarzeniowych półkul mózgowych.


Ryc. 8.3. Wykres Funkcji W Kształcie Odwróconej Litery U


* * *





Bodźce sensoryczne mają małą zdolność kierowania zachowaniem wtedy, gdy poziom wzbudzenia jest bardzo niski lub bardzo wysoki. Przy bardzo niskim poziomie wzbudzenia informacje sensoryczne nie docierają; przy bardzo wysokim poziomie wzbudzenia dochodzi zbyt wiele informacji, co przeszkadza jednostce zareagować we właściwy sposób (selektywnie) na informację bodźcową. Tak więc pośredni poziom wzbudzenia zapewnia optymalne wyniki działania, ponieważ z istotnych bodźców sygnałowych („cue stimuli”) można wówczas wydobyć więcej użytecznej informacji, która posłuży do pokierowania zachowaniem. Wykazano, że taki pośredni poziom wzbudzenia jest najbardziej efektywny zarówno dla szczurów w labiryncie, jak i dla studentów rozwiązujących testy. Ten związek między wzbudzeniem a efektywnością działania obrazuje krzywa w kształcie |odwróconej |litery |U (ryc. 8.3).




Badania nad popędami
biologicznymi




Większość popędów biologicznych ma swe źródło w niezaprzeczalnych potrzebach biologicznych organizmu. Popędy te motywują zachowanie organizmu w ten sposób, że prowadzi ono do niezbędnych zmian środowiska wewnętrznego.  Na przykład popęd głodu motywuje organizm do szukania i spożycia pokarmu, który jest niezbędny dla podtrzymania przemiany materii. Długotrwała niemożność zaspokojenia tego popędu może spowodować pogorszenie stanu zdrowia, funkcjonowania intelektualnego, zwiększoną podatność na choroby, a wreszcie śmierć. Aby utrzymać się przy życiu organizm musi mieć pokarm, wodę, tlen, odpoczynek i sen. Potrzebuje on także pewnych środków umożliwiających utrzymanie stałej temperatury ciała oraz systemu sygnalizacyjnego (ból), który pozwolił uniknąć uszkodzeń ciała.
Jednakże popędy biologiczne gatunku nie ograniczają się bynajmniej do tych podstawowych potrzeb biologicznych jednostki. Każdy gatunek zamieszkujący Ziemię musiał uporać się z alternatywą: rozmnażać się czy wymrzeć. Aby więc zapewnić możliwość przekazywania życia przez jedno pokolenie następnemu, niezbędny jest popęd seksualny i popęd „macierzyński” (opiekowanie się niedołężnym  potomstwem). Nie jest jasne, czy te ostatnie popędy powinno się uważać za „biologiczne”, w tym samym sensie, jak głód czy pragnienie. Podobnie niepewny jest status „popędu do marzeń sennych” (o którego istnieniu świadczy zjawisko powetowania sobie braku snu w fazie REM, omawiane w Rozdziale 7) oraz popędu eksploracyjnego, czyli popędu ciekawości. Popędy wpływają na zachowanie od chwili urodzenia i są obecne nawet w okresie życia płodowego, chociaż normalnie w tym czasie są one zaspokajane autonomicznie przez środowisko, jakie wytwarza organizm matki.  Jednakże w ostatnich latach stwierdza się coraz większą liczbe niemowląt, które przychodzą na świat z jednym z najsilniejszych popędów, jaki można sobie wyobrazić - nałogowym pragnieniem narkotyków. Niemowlęta te, urodzone z matek, które nałogowo zażywały heroinę (lub choćby methadon) doświadczają przykrych doznań, charakterystycznych dla głodu narkotycznego, gdy po przecięciu pępowiny tracą swe „źródło zaopatrzenia”.




Popędy biologiczne
jako mechanizmy
homeostatyczne




Wszystkie biologiczne popędy, z wyjątkiem popędu seksualnego, chociaż różnią się pod względem swej intensywności, służą jako mechanizmy regulacyjne, które pomagają utrzymać jednostce równowagę fizjologiczną.  Organizm „dokłada wszelkich starań”, aby utrzymać stałość swego normalnego środowiska wewnętrznego - jest to proces zwany |homeostazą.
Popędy biologiczne mają swe źródło w warunkach fizjologicznych, które zaburzają równowagę organizmu; gdy stan wewnętrzny zostanie zaburzony, wówczas powstają warunki, które motywują organizm do aktywności poszukiwawczej. Taka aktywność ustaje dopiero wtedy, gdy zostanie osiągnięty cel i zostanie przywrócona równowaga biologiczna lub gdy zacznie dominować jakiś silniejszy motyw.
Wiele procesów homeostatycznych ma charakter głównie wewnętrzny i automatyczny. Należą do nich procesy utrzymywania stałej temperatury ciała oraz właściwej równowagi poziomów tlenu i dwutlenku węgla w krwiobiegu.  Inny rodzaj aktywności homeostatycznej, związanej z odżywianiem, jest bardzo złożonym procesem, dzięki któremu organizm utrzymuje stały poziom cukru we krwi.
Jednakże potrzeby biologiczne nigdy nie mogą być zaspokojone w sposób trwały, w związku z czym rozwinęły się złożone, wyższe formy aktywności - zwłaszcza u ludzi - przydatne do rozwiązania problemu powtarzających się okresowo zmian fizjologicznych. Wiele gatunków nie tylko uzyskało zdolność wykrywania bardzo małych zmian fizjologicznych jako sygnałów zmian równowagi organizmu, lecz także wytworzyło mechanizmy pozwalające przygotować się do wystąpienia pewnych potrzeb. Zwierzęta budują gniazda i gromadzą pokarm na zimę. My nie tylko nauczyliśmy się jeść, zanim zaczniemy odczuwać skurcze głodowe, lecz stworzyliśmy skomplikowane systemy uprawy roli, konserwowania pożywienia, przechowywania oraz wymiany dóbr w celu zapewnienia dostatecznego zaopatrzenia w pokarm przez cały czas.
Tak więc homeostaza jest czymś więcej niż automatycznym utrzymywaniem chemicznej równowagi organizmu w reakcji na specyficzne bodźce. Obejmuje ona także aktywne działanie organizmu, mające na celu stworzenie możliwie stałego środowiska fizycznego i społecznego. Jednakże posługując się pojęciem homeostazy, nie można wyjaśnić wszelkich typów zachowania, nawet na poziomie fizjologicznym. Jednostka może niekiedy zachowywać się w sposób niekorzystny dla utrzymania właściwego stanu organizmu lub nawet dążyć do celów, które mają niewielkie lub żadne znaczenie dla adaptacji: trudno jest wyjaśnić w kategoriach homeostazy, dlaczego niektórzy ludzie szukają „szczytów wzbudzenia” w „kolejkach górskich”, w wesołych miasteczkach lub w niebezpiecznych przeprawach łódką przez katarakty itp. Wyjaśnienie, że „jest przyjemnie, gdy ma się to już za sobą”, które odnosiłoby się również do walenia głową o ścianę, nie wydaje się zadawalające. Mógłbyś zrealizować interesujące badania, przeprowadzając wywiady z kolegami i członkami twojej rodziny, którzy są „poszukiwaczami superwzbudzenia” oraz tymi, którzy unikają takich sytuacji. Jakie są różnice między nimi? Dlaczego zachowują się oni właśnie w taki sposób?
Co więcej, wielu Amerykanów dosłownie głodzi się, starając się żyć zgodnie z aktualnym ideałem kulturowym: „Piękny jest ten, kto szczupły”. Na przykład, gdy jeden z autorów niniejszej książki poprosił studentów wstępnego kursu psychologii w New York University, aby podali swój rzeczywisty i idealny wzrost oraz wagę, to wielu spośród 90 mężczyzn i prawie każda z 70 kobiet określiła swoją idealną wagę jako |mniejszą od wagi rzeczywistej. Było tak zarówno w wypadku studentów i studentek, którzy mieli nadwagę (według tabeli wagi ciała stosowanej przez towarzystwa ubezpieczeniowe), jak i w wypadku wątłych, delikatnych studentek, które wydawały się raczej wychudzone. (Na marginesie możemy wspomnieć, że wystąpiła także wyraźna tendencja, wśród wszystkich mężczyzn i większości kobiet, do podawania idealnego wzrostu jako wyższego od rzeczywistego, niezależnie od tego, jak byli wysocy). Chociaż więc homeostaza jest wartościowym pojęciem, to jednak zdaje się, iż nie wyjaśnia ona wszystkiego. W dalszych rozważaniach nad potrzebami fizjologicznymi zwierząt trzeba stale pamiętać o tym, że ciało i psychika są nierozłączne.  Mimo że te „potrzeby” sklasyfikowaliśmy tu jako biologiczne, to jednak wszystkie one zawierają pewien element psychologiczny. Koncepcja ta będzie jeszcze ważniejsza później, gdy będziemy omawiać motywy biologiczne u ludzi.




Manipulacja i pomiar




Znaczna część naszej wiedzy o popędach biologicznych pochodzi z precyzyjnych badań nad zachowaniem zwierząt w warunkach eksperymentalnych.  Ponieważ pomiar i kwantyfikacja są jednym z podstawowych celów każdej nauki, psychologowie i fizjolodzy opracowali zatem liczne sposoby mierzenia siły popędów. Mierzą je zmieniając intensywność stymulacji popędowej i obserwując wpływ tych manipulacji na określony aspekt zachowania.
W celu wzbudzenia popędów eksperymentatorzy tak manipulują bodźcami, że zaburzają równowagę homeostatyczną organizmu. Najczęściej pozbawia się zwierzę potrzebnej substancji, takiej jak pokarm czy woda, zmienia się ilość kalorii przypadających na daną objętość pokarmu lub też zmienia się stężenie soli w wodzie. Jak już wiemy, coraz częściej w badaniach nad popędami biologicznymi stosuje się bezpośrednie drażnienie określonych obszarów mózgu prądem elektrycznym lub substancjami chemicznymi. Jeszcze innym sposobem eksperymentalnego manipulowania czynnikami wpływającymi na motywację jest zmienianie warunków środowiskowych przez wytwarzanie zbyt wysokiej lub zbyt niskiej temperatury czy też aplikowanie szkodliwych bodźców.
Zmienne zależne, czyli konsekwencje wzbudzenia popędów biologicznych, mierzy się za pośrednictwem różnych wskaźników reakcji. Należą do nich: a) ogólna aktywność ruchowa, b) aktywność autonomicznego układu nerwowego, c) zachowanie konsumacyjne (ilość spożytej substancji, latencja, czyli czas między podaniem bodźca a początkiem reakcji, oraz rozkład jedzenia i picia w czasie), d) tempo lub siła reagowania, e) szybkość uczenia się skojarzeń wzmacnianych przez odpowiednie biologicznie czynniki wzmacniające, f) odporność reakcji warunkowych na wygaszanie eksperymentalne, g) wskazywane preferencje, gdy dany jest wybór między alternatywnymi czynnościami lub pożądanymi substancjami („goal substances”), h) zakłócenie wykonywanej aktualnie czynności oraz i) wielkość przezwyciężonej przeszkody lub ilość wysiłku wydatkowanego dla osiągnięcia określonego celu.


Ta ostatnia miara stanowiła jedno z najwcześniejszych źródeł danych dotyczących względnej siły różnych popędów. Grupa psychologów z Columbia University w późnych latach dwudziestych naszego wieku skonstruowała „skrzynkę przeszkód”, w której motywowany szczur był oddzielony od obiektu swych pragnień naelektryzowaną siatką. Siłę różnych popędów (wzbudzanych przez deprywację) określano przeciwstawiając je stałemu poziomowi przykrej stymulacji, którą zwierzę musiało wytrzymać, aby dotrzeć do pokarmu, wody, reaktywnego seksualnie partnera lub swego własnego potomstwa. Behawioralnym wskaźnikiem siły popędy była liczba wskazująca, ile razy zwierzę przechodziło przez tę „naelektryzowaną siatkę” w określonym czasie.  (Wskaźnikiem takim mógł być także najwyższy poziom intensywności wstrząsu, które zwierzę zniosłoby dla uzyskania danego celu). Na wykresie (ryc. 8.4) przedstawiono typowe dane uzyskane za pomocą tej metody.




* * *



Ryc. 8.4. Mówisz, że wspiąłbyś się na najwyższą górę lub przepłynął najgłębszy ocean, lecz czy przeszedłbyś dla mnie po naelektryzowanej siatce w kolumbijskiej skrzynce przeszkód?


* * *





Motywujący wpływ pragnienia jest największy po krótkim okresie deprywacji, następnie, w miarę przedłużania się czasu deprywacji, wpływ ten maleje; podobnie jest w wypadku głodu. Ta krzywa w kształcie odwróconej litery U może jednak wynikać przede wszystkim z osłabienia spowodowanego długotrwałą deprywacją. Natomiast w wypadku celów seksualnych, szczury biegają w stałym tempie, bez względu na długość deprywacji (po pierwszych paru godzinach). Zaskakujące jest to, że szczury będące matkami przezwycieżają największe przeszkody, aby móc odzyskać swoje młode. Ten mocny dowód istnienia popędu macierzyńskiego u zwierząt nie był kwestionowany aż do niedawna.
Warto zwrócić uwagę na inny, interesujący aspekt tych badań. Mimo braku jakiejkolwiek deprywacji, zwierzęta przechodziły siatkę kilka razy. Co więcej, nawet wtedy, gdy po drugiej stronie nie było nic - z wyjątkiem szansy eksplorowania nowego środowiska - przekraczały one przeszkodę, być może motywowane przez popęd eksploracyjny. Przedstawiony tu schemat badawczy jest charakterystyczny dla wczesnych badań nad popędem, które koncentrowały się jedynie na deprywacji i ignorowały wpływ podniet zewnętrznych na motywowane zachowanie.
Zapoznajmy się teraz z próbką wykrytych istotnych faktów, dotyczących niektórych popędów biologicznych.




Natura głodu




Spośród wszystkich stanów motywacyjnych głód był przedmiotem największej liczby badań przeprowadzanych zarówno przez psychologów, jak i fizjologów - przede wszystkim dlatego, że łatwo jest go wywołać w laboratorium stosując bardzo prostą procedurę, a mianowicie deprywację. Niezliczone badania wykazały, że przebywanie pewnej liczby godzin bez pokarmu wytwarza stan bodźcowy, który wpływa na poziom głodu danego organizmu. Głodne zwierzę przerwie inne czynności i zacznie przetrząsać środowisko w poszukiwaniu pokarmu, który zje, gdy tylko go znajdzie. Ta |reakcja |konsumpcyjna jedzenia |redukuje, czyli chwilowo eliminuje, zespół warunków wewnętrznych, które nazywamy |popędem |głodu. Zachowanie konsumacyjne ustaje lub staje się mniej prawdopodobne, gdy zwierzę |nasyci |się (ma już dość pokarmu lub czynności jedzenia).


|Reakcja |instrumentalna - zachowanie polegające na poszukiwaniu lub pracy dla otrzymania przedmiotu stanowiącego cel - nasila się, w miarę, jak siła motywacyjna wzrasta, i słabnie wraz z jej redukcją. Aby więc skutecznie regulować pobór pokarmów, organizm musi być zdolny do wykrywania fizjologicznego stanu głodu, inicjowania i organizowania zachowania w postaci jedzenia, a następnie przerwania tego zachowania, gdy już przyjął dość pokarmu. Jak się przekonamy, charakter warunków wewnętrznych i mechanizmów regulacyjnych związanych z głodem i jedzeniem, oraz zaprzestaniem jedzenia, jest raczej złożony.




Co sprawia,
że jesteśmy
„głodni”?




Z subiektywnego punktu widzenia znamy uczucie głodu jako mnóstwo wrażeń, które zdają się pochodzić z okolicy żołądka. Lecz czym są właściwie te zmiany fizjologiczne i poznawcze, które wywołują wspomniane wrażenia? Czy to żołądek jest w pierwszym rzędzie odpowiedzialny za regulowanie odczucia głodu, czy wchodzą tu w grę inne czynniki?
Jedno z ogólnie znanych, wczesnych wyjaśnień wrażenia głodu pochodzi od fizjologa Waltera Cannona. Podejrzewał on, że uczucie głodu wywołują skurcze żołądka, które występują wtedy, gdy żołądek jest pusty. Głównych danych przemawiających za tym poglądem dostarczył eksperyment, który Cannon przeprowadził na swym asystencie Washburnie. Cannon namówił Washburna, aby ten połknął balonik z cienkiej gumy przymocowany do długiej rurki, której swobodny koniec był dołączony do urządzenia rejestrującego. Po nadmuchaniu balonika wszelkie zmiany ciśnienia spowodowane aktywnością żołądka były rejestrowane automatycznie w postaci wykresu. Washburn za każdym razem, gdy odczuwał skurcze głodowe, naciskał guzik, który uruchamiał znacznik, rejestrując w ten sposób czas trwania i częstość skurczów głodu (ryc.  8.5).




* * *



Ryc. 8.5. Zdjęcie przedstawia nieżyjąceggo już dr. Antona J. Carlsona, która połączona jest z balonikiem wprowadzonym do żołądka. Nacisk na ten balonik powoduje, że pisak porusza się w górę i w dół po obracającym się bębnie, rejestrując w ten sposób aktywność żołądka.


* * *





Rejestrowanie przez wiele godzin, w sposób ciągły, aktywności żołądka pozwoliło ujawnić dwa jej rodzaje: jeden związany z trawieniem i drugi wystęujący wtedy, gdy badany podawał, iż odczuwał ostry głód. Bezpośrednio po jedzeniu obserwowano jedynie regularne ruchy trawienne, natomiast w miarę jak żołądek stawał się pusty, zaczynały występować skurcze związane z głodem. Najpierw pojawiały się one co półtorej godziny, lecz stawały się częstsze, gdy czas pozostawania bez pokarmu przedłużał się. Po dokładnym przeanalizowaniu tych zapisów stwierdzono, że Washburn podawał, iż odczuwa skurcze głodowe |jedynie podczas silnych skurczów żołądka.


Cannon doszedł do wniosku, że „nieprzyjemne bóle” głodowe są rzeczywiście spowodowane silnymi skurczami pustego żołądka (Cannon, 1934).
Późniejsze badania, przeprowadzane przy zastosowaniu udoskonalonych urządzeń rejestrujących, wykazały że klasyczny wzorzec aktywności żołądka wykryty przez Cannona występuje dopiero wtedy, gdy balonik zostanie umieszczony w żołądku i nadmuchany (Penick, Smith, Wienske i Hinkle, 1963). Stwierdzenie to stanowi doskonałą ilustrację faktu, że technika pomiaru może wpływać na to, co się mierzy. W tym wypadku obecność balonika mogła |powodować skurcze, które mierzono. Nie możemy też oczywiście pominąć innych dowodów, zgodnie z którymi wielu ludzi istotnie doświadcza skurczów głodowych.
Początkowo entuzjazm dla teorii Cannona przygasał, w miarę jak gromadzono dowody, które były nie do pogodzenia z ideą, iż same skurcze żołądka są odpowiedzialne za uczucie głodu. Gdyby wrażenie głodu i zapoczątkowanie czynności jedzenia były jedynie wynikiem skurczów żołądka, to powinno być możliwe drastyczne zmodyfikowanie zachowania związanego z jedzeniem przez nie dopuszczenie informacji o skurczach żołądka do reszty ciała. Nie jest to jednak zgodne z faktami; liczne badania, w których usuwano chirurgicznie żołądek zwierzęcia lub przecinano prowadzące zeń drogi nerwowe wykazały, iż zwierzęta te jadły nadal, w niewielkim jedynie stopniu zmieniając swe normalne zachowanie związane z pobieraniem pokarmu. Na przykład, w jednym z eksperymentów szczury, którym usunięto żołądki, demonstrowały w zasadzie takie samo zachowanie związane z głodem, jak zwierzęta z grupy kontrolnej.  Uczyły się one labiryntów prowadzących do pokarmu równie szybko, jak zwierzęta z grupy kontrolnej i były równie aktywne, gdy zbliżał się czas karmienia. Jedyna różnica polegała na tym, że szczury pozbawione żołądków poszukiwały pokarmu częściej niż zwierzęta z grupy kontrolnej; można było tego oczekiwać, ponieważ do magazynowania pokarmu miały one jedynie jelita i dlatego musiały jeść częściej.
Cofer i Appley (1964) zwrócili uwagę na pewną istotną sprawę dotyczącą interpretacji tego i podobnych eksperymentów. Badania takie wykazują jedynie, że |utrzymanie raz już ukształtowanych form zachowania związanego z jedzeniem nie zależy wyłącznie od bodźców wytwarzanych przez skurcze żołądka. Nie jest jednak wykluczone, że organizm może wykorzystywać ten specyficzny bodziec głodowy we wczesnej fazie kształtowania zachowań związanych z jedzeniem; jest też możliwe, że organizm kieruje się zwykle bodźcami pochodzącymi ze skurczów żołądka, kiedy jednak pozbawiony jest tej informacji, to jest zdolny odpowiednio regulować pobieranie pokarmu, wykorzystując inne sygnały. Ponieważ zwierzęta użyte w tych badaniach były dojrzałe i doświadczone w czynności jedzenia, jest zatem prawdopodobne, że skojarzyły one jedzenie i reakcje związane z pokarmem z najróżniejszymi bodźcami, zarówno wewnętrznymi, jak i zewnętrznymi. Zachowanie ukierunkowane na pokarm, które obserwuje się po usunięciu żołądka, może być częścią wytworzonego uprzednio wzorca nawykowego, wywoływanego i utrzymywanego dzięki obecności różnych bodźców warunkowych. Chociaż więc skurcze żołądka odgrywają prawdopodobnie pewną rolę w regulacji czynności jedzenia, to jednak nie są one bynajmniej jedynymi, ani nawet najważniejszymi bodźcami, jakie tu wchodzą w grę.


Skład chemiczny krwi i głód. Dla organizmu bezpośrednim źródłem energii potrzebnej dla funkcjonowania komórek jest glukoza, czyli cukier zawarty we krwi. Sugeruje to więc, że zmiany w składzie chemicznym krwi powinny być w pewien sposób związane z głodem.
Już wczesne badania wykazały na przykład, że transfuzja krwi z organizmu wygłodzonego psa do organizmu psa niedawno nakarmionego może w pewnych warunkach spowodować u niego skurcze żołądka (Luckhardt i Carlson), 1915; 
Tschukitsew, 1929). Stwierdzono także, że krew pobrana z organizmu nakarmionego niedawno zwierzęcia i wprowadzona do organizmu zwierzęcia wygłodzonego, przerywa skurcze żołądka u tego ostatniego (Bash, 1939).
Gdy badanym osobom wstrzykuje się insulinę, wówczas poziom glukozy we krwi ulega u nich obniżeniu, co powoduje stan znany pod nazwą |hipoglikemii. Po wstrzyknięciu insuliny pacjenci i osoby badane w eksperymentach podają, że odczuwają głód, a także skurcze żołądka. U zwierząt po podaniu insuliny występują różne czynności instrumentalne związane z pokarmem.  
Jeśli brak glukozy wywołuje stan głodu, to zastrzyki glukozy powinny powodować wrażenie nasycenia, i wydaje się, że jest tak rzeczywiście.  Wstrzyknięcie glukozy hamuje czynność jedzenia u głodzonych uprzednio zwierząt, jak również hamuje czynność elektrycznego samodrażnienia okolic mózgu uważanych za ośrodki sytości (Balagura, 1968a). Nadal jednak nie jest pewne, w jaki sposób zmiany poziomu glukozy we krwi są rejestrowane w ośrodkowym układzie nerwowym tak, że umożliwia to odpowiednie kierowanie zachowaniem.


Czy „ośrodek pokarmowy” kontroluje odczuwanie głodu?
Wczesne badania wykazały, że lezje w różnych częściach podwzgórza wpływają na zachowanie związane z jedzeniem oraz na inne reakcje konsumacyjne, a jak się wydaje, nawet na niektóre motywowane zachowania.
Późniejszy rozwój technik elektrycznego drażnienia mózgu dał początek zdumiewającej ilości dalszych badań, których głównym obiektem było podwzgórze jako ośrodek zawiadujący głodem i innymi popędami biologicznymi.  Przyjmowano, że drażnienie określonych okolic podwzgórza wywołuje stany popędowe funkcjonalnie równoważne popędom występującym w sposób naturalny.  Nawet syte szczury można było motywować do uczenia się nowej reakcji, dla której wzmocnieniem był pokarm, drażniąc elektrycznie jedną z tych okolic, tak zwany „ośrodek głodu”. Przyjmowano też, że miejsca te mają wysoce wyspecjalizowane funkcje, przy czym jedna okolica podwzgórza kontroluje czynność jedzenia, inna - picia, jeszcze inna - agresję itd.
Jednakże w miarę jak gromadzi się nowszy materiał dowodowy, kilka kłopotliwych wniosków grozi zdetronizowaniem podwzgórza. Po pierwsze, dla wielu reakcji konsumacyjnych brak specyficznej lokalizacji anatonomicznej.  „Ośrodki” jedzenia i picia koegzystują z ośrodkami ogólnego zachowania eksploracyjnego. Co więcej, w limbicznym (rąbkowym) obszarze mózgu istnieje wiele pól, które zdają się wywierać bardziej specyficzny wpływ na stany motywacyjne niż podwzgórze. Wysunięto sugestię, że podwzgórze funkcjonuje jedynie jako „ośrodek połączeniowy” dla tych pól mających podstawowe znaczenie (Grossman, 1968).
Jeśli zwierzę je pokarm, gdy drażniona jest jedna okolica podwzgórza, a pije wodę, gdy drażniona jest inna okolica, to jest oczywiste, że pierwsza z nich zawiaduje „głodem”, druga zaś - „pragnieniem”. Jest to oczywiste, lecz widocznie nieprawdziwe, mówią badacze, którzy przeprowadzili prosty, lecz bardzo pouczający eksperyment.


„Stwierdzono, że gdy z klatki szczura, któremu drażniono pewną okolicę podwzgórza, usunięto obiekt początkowo preferowany przez to zwierzę (na przykład pokarm), to późniejsze drażnienie tego samego miejsca z równym prawdopodobieństwem wywoływało inne formy zachowania konsumacyjnego, takie jak picie lub ogryzanie drewna” (Valenstein, Cox i Kakolewski, 1968a).


Inne badania przeprowadzone przez tych samych badaczy wykazały, że zwierzęta eagujące jedzeniem na drażnienie podwzgórza nie przestawiają się na inny, znany im pokarm, gdy pierwszy zostanie usunięty - jak czynią to wtedy, gdy są one rzeczywiście pozbawione pokarmu. Co więcej, nie przestawiają się one nawet na inną formę tego samego pokarmu, na przykład wówczas, gdy gałki zostaną potłuczone na proszek (Valenstein i in., 1968b).
Kłopotliwy dla obrońców „podwzgórzowej” teorii motywacji jest również problem samodrażnienia. U zwierząt występuje niezwykle wysokie tempo reagowania, gdy dzięki temu uzyskują drażnienie elektryczne tych okolic mózgu, które zidentyfikowano jako „ośrodki przyjemności”. Niektórzy badacze stwierdzają, iż motywacja ta jest tak silna, że gdy szczury w skrzynce przeszkód uzyskują możliwość drażnienia tych ośrodków, to przekraczają siatke naelektryzowaną prądem o wyższym napięciu niż wtedy, gdy zastosowana jest jakakolwiek inna niż zwykła deprywacja i podnieta.
Kłopot w tym, że niektóre okolice podwzgórza, które są wzmacniającymi „ośrodkami przyjemności”, zdają się być także ośrodkami wytwarzającymi popęd, powodującymi czynność jedzenia (Hoebel i Teitelbaum, 1962). W jaki sposób to samo drażnienie może dostarczać wzmocnienia i wywoływać czynność jedzenia?
Ostatnio zaproponowano wyjaśnienie, które radykalnie zmienia wcześniejszy pogląd na role podwzgórza w motywacji; zgodnie z nim, drażnienie podwzgórza nie wytwarza bezpośrednio głodu, pragnienia czy innych popędów. Stwarza ono raczej warunki, które pobudzają aktywność nerwową, stanowiącą podłoże jakiejś dobrze ukształtowanej reakcji konsumacyjnej; akt wykonywania tej reakcji może być sam sobie wzmacniający (Velenstein, Cox i Kakolewski, 1970).
Problem ten nie jest jeszcze bynajmniej rozstrzygnięty i chociaż absolutne panowanie podwzgórza jest już być może skończone, z wyborem następcy trzeba poczekać, aż zostaną poczynione dalsze postępy w technice badań fizjologicznych i w projektowaniu eksperymentów nad zachowaniem.  Niemniej jednak poszukiwanie „ośrodka motywacji” przyniosło mnóstwo cennych informacji o motywowanym zachowaniu organizmów.


Wewnętrzne i zewnętrzne czynniki pobudzające. Każdy, kto znalazł się w pobliżu klatek z wielkimi kotami w ZOO, w czasie, gdy zbliżała się pora karmienia, zdziwił się, skąd lwy i tygrysy „wiedzą”, że zbliża się godzina obiadu. Drapieżniki te wspinają się, krążą, ryczą, drapią, zdają się aż kipieć od tej (niezmiernie interesującej dla oglądających) aktywności. Czy to popęd głodu „wpędza” je w ten stan szalonej aktywności? Czy mają one „zegar wewnętrzny”, który jest zsynchronizowany z zegarem w dyrekcji ZOO?
Takie zasadnicze pytania, dotyczące z przyczyn, dla których motywacja zdaje się wzmagać aktywność zwierzęcia, intrygują również psychologów.  Wczesne badania nad szczurami biegającymi w „kołach aktywności” zdawały się potwierdzać te obserwacje nad zwierzętami w ZOO: pozbawienie pokarmu do pewnego momentu sprawia, że zwierzęta stają się bardziej aktywne.


„Aktywizacja czy uwrażliwienie”? Ta prosta koncepcja aktywizacji została jednak zakwestionowana, gdy Campbell i Sheffield (1953) wykazali, że głodne szczury były istotnie bardziej aktywne niż szczury syte |tylko wtedy, gdy następowała zmiana w stymulacji środowiskowej (zwiększenie natężenia światła i ustanie dźwięku wydawanego przez wentylator). Być może głód - rozumowali oni - nie ma ogólnego działania aktywizującego, lecz raczej działa |uwrażliwiająco („sensitizing effect”); to jest, jego wpływ polega na obniżeniu progów reakcji na różne rodzaje bodźców.




* * *



Ryc. 8.6. Zapach Pokarmu Podnieca Niespokojną (Głodną) Bestię. Wykres ten przedstawia poziom aktywności u głodnych i nasyconych zwierząt przed i po pojawieniu się różnych bodźców. Gdy nie podawano żadnego  bodźca (grupa kontrolna), wówczas poziom aktywności sytych zwierząt malał z czasem, podczas gdy poziom aktywności głodnych zwierząt wykazywał lekki wzrost. Gdy jako bodźca użyto światła lub dźwięku, wówczas poziom aktywności sytych zwierząt wzrastał bardziej niż zwierząt głodnych. Gdy jednak jako bodziec zastosowano zapach pokarmu, wówczas poziom aktywności sytych zwierząt wzrastał jedynie nieznacznie, podczas gdy aktywność głodnych zwierząt nasilała się bardziej niż w jakichkolwiek innych warunkach.


* * *





W dalszych badaniach Sheffield i Campbell (1954) stwierdzili, że głód wzmagał aktywność w odpowiedzi na wszelkie nowe bodźce, lecz w |większym stopniu wzmagał aktywność w odpowiedzi na bodźce skojarzone z jedzeniem.
Wydawałoby się, że z adaptacyjnego punktu widzenia wzmożony popęd powinien czynić organizmy |selektywnie wrażliwymi na bodźce, które sygnalizują zdarzenia związane z zaspokojeniem popędu, a nie po prostu aktywnymi czy wrażliwymi w sposób niezróżnicowany. Zdaje się to wynikać z przeprowadzonych niedawno badań, w których porównywano reaktywność głodnych i sytych zwierząt na szereg bodźców. Głodne zwierzęta reagowały silniej niż syte na zapach pokarmu, lecz słabiej na światło i dźwięk (Tapp, Mathewson, D’Encarnacas i Long, 1970; ryc. 8.6).
Zachowanie eksploracyjne jest tego rodzaju aktywnością, którą głód zdaje się wzmagać. Należałoby oczekiwać, że na swobodzie, gdzie zwierzęta muszą zdobywać sobie pokarm, eksploracja pod wpływem głodu powinna mieć adaptacyjne znaczenie, pomagając zwierzęciu znajdować pożywienie.


„W pewnym eksperymencie laboratoryjnym wykazano, że gdy szczury zbadały już dokładnie jedną część swego środowiska, to sposobność eksplorowania nowego pomieszczenia była bardziej skwapliwie wykorzystywana przez szczury głodne niż przez syte. W kolejnych próbach głodne zwierzęta biegały szybciej ze znanej sobie do nie znanej części skrzynki (złożonej z dwóch pomieszczeń). Gdy zwiększono stopień nowości nie znanego środowiska, ich względna szybkość przedostawania się nie do zbadanej części jeszcze bardziej wzrosła” (Zimbardo i Miller, 1958; ryc. 8.7).


Fakty dotyczące motywacji rzadko umożliwiają proste uogólnienia, jakich pragnąłby dokonać ktoś, kto chciałby ująć zachowanie w regułach wyjaśniających. Wzmożony popęd istotnie zwiększa wrażliwość na bodźce zewnętrzne, |ale wpływ ten jest różny dla różnych gatunków, nie jest taki sam dla głodu i wszystkich innych popędów i zależy od tego, jakie bodźce są podawane i jakie zachowania się obserwuje.


„Czy sygnały zewnętrzne mogą odgrywać ważną rolę”? Jak często jadłeś posiłek dlatego, że zegar powiedział ci, iż czas jest to uczynić, nawet jeśli nie odczuwałeś głodu? Czy kiedykolwiek poczułeś się głodny tylko dlatego, że zobaczyłeś kogoś jedzącego wspaniałe ciastko z kremem lub poczułeś zapach świeżego chleba czy kurczęcia pieczonego na rożnie? Z pewnością sygnały zewnętrzne, takie jak wymienione powyżej, decydują niekiedy o tym, kiedy, co i jak dużo będziemy jedli.
W badaniach nad zachowaniem zwierząt wykazano doniosłe znaczenie wielu zewnętrznych sygnałów głodu. Wiadomo na przykład, że obecność jedzącego, głodnego szczura może wywołać reakcję jedzenia u szczura sytego. W wielu eksperymentach wykazano, że im bardziej znana jest zwierzęciu sytuacja związana z jedzeniem, w której jest ono badane, tym intensywniej będzie ono jadło (Bolles, 1967).




* * *



Ryc. 8.7. Wpływ Głodu Na Zachowanie Eksploracyjne. Zwierzęta głodne wbiegały do nieznanego środowiska szybciej niż zwierzęta nasycone, a różnica ta wzrastała w miarę ponawiania prób. Gdy stopień nowości nieznanego środowiska znacznie wzrósł, wówczas głodne zwierzęta wchodziły do niego początkowo nieco wolniej niż poprzednio, lecz wkrótce znowu przechodziły szybko ze starego pomieszczenia do nowego. Ponieważ nigdy nie karmiono ich w żadnej z obu części tej aparatury, przeto głód był najwyraźniej czynnikiem powodującym tę różnicę w aktywności.


* * *





Zewnętrzne sygnały środowiskowe mogą skojarzyć się ze stanami fizjologicznymi drogą warunkowania. Te „neutralne” sygnały mogą następnie uzyskać zdolność wywoływania reakcji związanych z pokarmem, a nawet uczucia głodu. Bardzo interesujący eksperyment, który przeprowadził Balaguer (1968b) sugeruje, w jaki sposób fizjologia głodu może uzależnić się od bodźców zewnętrznych. Po wstrzyknięciu szczurom insuliny, która obniża poziom cukru we krwi, ich zachowanie w formie poszukiwania pokarmu oraz zachowanie konsumacyjne wzmagało się, jak wspomnieliśmy poprzednio. Gdy ten wzorzec reakcji ustalił się, wówczas badacz nadal wykonywał te zastrzyki, lecz bez insuliny. Te zdarzenia, które w przeszłości zwykle poprzedzały S (bodziec bezwarunkowy), czyli wstrzyknięcie insuliny, stały się bodźcami warunkowymi. Zwierzęta reagowały na zastrzyki bez insuliny tym samym zachowaniem poszukiwania pokarmu, które poprzednio występowało u nich pod wpływem zastrzyków insuliny. Widocznie wyuczone skojarzenie sygnałów zewnętrznych z |nagłym |pojawieniem |się uczucia głodu może poddać czynność jedzenia pod kontrolę tych sygnałów. W normalnych okolicznościach głód wzrasta powoli i równie powoli jest redukowany; zatem trudniej jest wytworzyć skojarzenie pomiędzy jakimś określonym bodźcem warunkowym a bodźcem bezwarunkowym. Krótszy cykl występowania głodu u niemowląt może czynić je bardziej podatnymi niż dorosłych na środowiskową modyfikację poszukiwania pokarmu i czynności jedzenia.
W każdym razie aktywność lwów i tygrysów w porze karmienia można prawdopodobnie najlepiej wyjaśnić za pomocą dwóch czynników; zapachu przygotowywanego mięsa oraz zwiększonej liczby ludzi, takich jak my, którzy zawsze przybywają tu przed czasem karmienia. Jest jednak możliwe, że funkcjonuje u nich także „zegar wewnętrzny”. Czy potrafiłbyś wskazać sposób przeprowadzenia badania mającego na celu ustalenie, czy czynnik taki istotnie działa?


„Niedostatek pożywienia i wrażliwość na sygnały zewnętrzne”. Grecki filozof Diogenes powiedział: „Bogaty człowiek je, kiedy jest głodny, zaś człowiek ubogi je wtedy, kiedy może”. Zwierzęta żyjące w warunkach obfitości mogą regulować spożywanie pokarmu według sygnałów wewnętrznych, ponieważ pokarm będzie dostępny zawsze, gdy odczują jego potrzebę. Jednakże w wypadku zwierząt żyjących w warunkach niedostatku sytuacja jest zupełnie odmienna: gdy pożywienia brakuje i jest ono dostępne jedynie w nieregularnych odstępach czasu, bardziej przystosowawcze jest jedzenie w takich ilościach, jak to jest możliwe, gdy ma się sposobność; dlatego też bardziej adaptacyjna jest większa wrażliwość na sygnały zewnętrzne (takie, jak smak pokarmu) niż na sygnały wewnętrzne (takie, jak uczucie głodu).
Stwierdzono, że dzikie oposy (i niektóre inne gatunki) są bardzo wrażliwe na właściwości smakowe pożywienia i niewrażliwe na wewnętrzne sygnały głodu. Wysunięto sugestię, że sztywne określenie ilości przyjmowanych dziennie kalorii miałoby dla nich małą wartość, biorąc pod uwagę nieregularność zaopatrzenia w pokarm, podczas gdy wrażliwość na smak pokarmu pomaga w szybkim wykrywaniu i różnicowaniu poszczególnych składników odżywczych (Maller, Clark i Kare, 1965). Zwierzęta, które zasypiają na zimę, także muszą jeść ponad swe aktualne potrzeby fizjologiczne, zanim zacznie się okres ich bezczynności.
Natomiast szczury laboratoryjne „jedzą według kalorii”, utrzymując względną stałość ilości przyjmowanego pokarmu (zgodnie z wymaganiami energetycznymi). Szczury żyjące na swobodzie, gdzie zaopatrzenie w pokarm jest zmienne, utrzymują ten wzorzec regulacji wewnętrznej przez wytworzenie nawyku gromadzenia pokarmu. Gromadząc pożywienie, gdy jest ono dostępne, i zjadając je, gdy są głodne, zwierzęta utrzymują ilość przyjmowanego pokarmu na stałym poziomie.
Gdy jednak szczury są pozbawione pokarmu i nie mogą go gromadzić, wówczas następuje „przestawienie” regulacji jedzenia z wewnętrznej na zewnętrzną.  Głodne szczury znajdujące się w warunkach niedostatku będą jeść kierując się bardziej smakiem, otrzymywanego pożywienia niż jego wartością kaloryczną (Jacobs i Sharma, 1968). W pewnym sensie, gdy są one głodniejsze, stają się bardziej wrażliwe na sygnały zewnętrzne.
Gross (1968) wykazał, że zjawisko to utrzymuje się nawet wtedy, gdy szczurom ponownie zapewni się stały dostęp do pokarmu. Szczury, które poddawano deprywacji, reagują na eksperymentalną zmienność smaku i wartości kalorycznej swego pożywienia w ten sposób, że ignorują jego wartość kaloryczną i jedzą kierując się smakiem. Szczury, które były karmione normalnie, nadal pobierają tę samą ilość kalorii, pomimo zmian smaku pokarmów.




Skąd wiemy, że już
jesteśmy nasyceni?




Skąd głodny organizm wie, kiedy już dosyć zjadł? Mechanizm, dzięki któremu organizm zaprzestaje pobierania pokarmu, jest pod pewnymi względami analogiczny do mechanizmu zapoczątkowywania jedzenia, lecz różny od niego.  Jedna z hipotez głosi, że „pomiar” jest dokonywany w jamie ustnej, w zależności od ilości i cech smakowych przechodzących przez nią substancji.  Hipnozę tę sprawdzano w eksperymentach nad „pozornym karmieniem” („sham-feeding”), w których brały udział zwierzęta zoperowane chirurgicznie w ten sposób, że pokarm podawany do jamy ustnej był przeżuwany i połykany, lecz przez otwór w przełyku wydostawał się na zewnątrz i nie docierał do żołądka (James, 1963). Zwierzęta te istotnie przerywały jedzenie, lecz dopiero wtedy, gdy ilość przyjętego pokarmu była znacznie większa niż wtedy, gdyby pokarm docierał do żołądka. Widocznie pewien pomiar, oparty na sprzężeniu zwrotnym z jamy ustnej, występuje istotnie, lecz jest przybliżony i niedokładny.
Z drugiej strony, szczur potrafi doskonale regulować ilość przyjmowanego pokarmu i wody będąc pozbawiony doznań smakowych, zapachowych czy bodźców dotykowych z jamy ustnej i przełyku. W pewnym eksperymencie szczury nauczono wykonywania czynności dowolnych - w tym wypadku naciskania dźwigni - dla otrzymywania zastrzyków pokarmu bezpośrednio do żołądka. Zwierzęta te potrafiły regulować ilość przyjmowanego pokarmu, utrzymując swą wagę ciała na normalnym poziomie (Teitelbaum i Epstein, 1962).
W wielu badaniach wykazano dwoistą naturę mechanizmu nasycenia głodu.  Stwierdzono, że chociaż zwierzęta uczą się wykonywania nowych reakcji, aby otrzymać nagrodę w postaci pokarmu wstrzykiwanego bezpośrednio do żołądka, co zapewnia zapełnienie żołądka i zaspokojenie potrzeb metabolicznych, to jednak uczą się one znacznie szybciej wtedy, gdy pokarm jest pobierany normalnie, przez jamę ustaną. Wydaje się więc, że „pomiar” ilości pobieranego pokarmu jest łatwiejszy, gdy uwzględnia się zarówno czynniki oralne, jak i gastryczne.
Badacze stwierdzili, że głód określonego rodzaju pokarmu jest często wynikiem biologicznych potrzeb i braków - organizm poszukuje pokarmów, które zawierają substancje brakujące w jego diecie. Takie |łaknienie |z |niedostatku („deficiency craving”), jak się je nazywa, często przejawiają się szczególnie wyraźnie w zachowaniu zwierząt, które zostały pozbawione pewnych niezbędnych substancji. Na przykład szczury pozbawione tiaminy i soli będą wybierać pokarmy zawierające te substancje, nawet gdy mają do wyboru dużą liczbę różnorodnych pokarmów (Rozin, 1965). Podobnie szczury laboratoryjne hodowane na diecie beztłuszczowej, gdy da się im do wyboru tłuszcz, cukier lub pszenicę, wybierają tłuszcz, a szczury pozbawione czy to pszenicy, czy cukru znacznie częściej wybierają tę substancję, której im brakowało. Inne eksperymenty z krowami, świniami i kurczętami wykazały, że wszystkie one doskonale umieją regulować sobie swoją dietę. Zwierzęta je jedzą nie tylko dla uzyskania kalorii, lecz także dla zdobycia chemicznych składników niezbędnych dla dobrego odżywienia. Nie jest jednak jasne, w jaki sposób regulowane są takie „łaknienia z niedostatku”, aczkolwiek wydaje się, iż smak jest tu głównym czynnikiem. Richter (1943) wykazał w przekonywujący sposób, że szczury z przeciętnymi nerwami smakowymi |nie |potraią wybierać zrównoważonej diety.
Takie wybieranie sobie samemu diety stanowi dalszy dowód na to, że organizm jest wrażliwy nie tylko na ogólną ilość przyjmowanego pokarmu, lecz także na zachowanie równowagi w odżywianiu. Wiele dotychczas przeprowadzonych badań wykazało, że badani ludzie, podobnie jak zwierzęta, potrafią wybierać sobie pokarmy w taki sposób który zaspokaja specyficzne potrzeby organizmu i zapewnia zrównoważoną dietę.


W pewnych, klasycznych już badaniach, trzem świeżo odstawionym od piersi niemowlętom pozwolono wybierać swoje pożywienie spośród wielu różnych, zdrowych pokarmów.


Dwoje z nich wybrało sobie pokarm przez sześć miesięcy, trzecie - przez cały rok. Wszystkie przybierały normalnie na wadze i nie wykazywały żadnych oznak zaburzeń pokarmowych. Co więcej, jedno z niemowląt, które cierpiało na krzywicę na początku eksperymentu, wyleczyło się z niej samo wybierając duże ilości tranu, który zawiera witaminę D, potrzebną do wyleczenia krzywicy. Niemowlę to zrezygnowało z tranu, gdy pozbyło się już krzywicy.
Wszystkie trzy niemowlęta skłonne były jeść duże ilości jednego pokarmu przez pewien czas, a następnie przerzucały się na inny pokarm, pozwalając sobie na „hulanki jajeczne” czy „kaszkowe”. Jednakże na dalszą metę, przy zastosowaniu tego „samoobsługowego” systemu karmienia, niemowlęta na ogół wybierały samodzielnie to, co zaleciliby im eksperci od odżywania - i uzyskiwały zrównoważoną dietę. Przy końcu badań ich zdrowie i rozwój były normalne” (Davis, 1928).


Wiemy, że uczenie się i warunkowanie są to sposoby umożliwiające wpojenie organizmowi nawyków czy skłonności. Co się jednak dzieje, gdy te nawyki pozostają w konflikcie z biologicznymi potrzebami organizmu? Czy nabyte gusty zakłócają naturalną zdolność organizmu do wybierania tego typu pokarmu, którego on potrzebuje? Opisane poniżej badania sugerują odpowiedzi na te pytania.
Organizm, któremu usunięto gruczoły nadnerczy, wymaga anormalnych ilości soli. Zazwyczaj szczury po usunięciu nadnerczy będą pobierać dodatkowe ilości soli, woląc roztwory soli od roztworów glukozy, gdy mają je do wyboru. Jednakże szczury bardziej „doświadczone”, które przed operacją miały do czynienia zarówno z roztworami słodkimi, jak i słonymi, wybierają roztwór glukozy i giną (Harriman, 1955).


„Stwierdzono także, że szczury z niedoborem białka wybierają sacharozę a nie białko, gdy umieści się je w sytuacji testowej, w której poprzednio wybierały sacharozę. Jednakże w nowej i odmiennej sytuacji testowej wybierają one potrzebne białko. Najwyraźniej nawyk wybierania sacharozy jest w oryginalnych warunkach bodźcowych dostatecznie silny, by przezwyciężyć organiczną potrzebę białka. Badacz podsumował te wyniki stwierdzeniem, że „nawyki kształtują się zwykle zgodnie z potrzebą organizmu, lecz ukształtowane nawyki mają tendencję do utrzymywania się bez względu na potrzebę” (Young, 1961, 1968).


Niestety, ludzie cywilizowani, podobnie jak „wykształcone” szczury, wytworzyli wiele nawyków pokarmowych - takich, jak upodobanie Amerykanów do słodyczy i napojów orzeźwiających - które nie są zgodne z potrzebami organizmu. Tak więc „mądrość ciała”, chociaż znaczna w warunkach naturalnych, może zostać zepsuta przez przyswojone nawyki. Zagadnienie to rozpatrzymy bardziej szczegółowo później, przy omawianiu otyłości i innych aspektów popędu głodu u ludzi.




Tyrania głodu




„Miłość, interesy i rodzina, religia, sztuka i patriotyzm są jedynie cieniami słów, gdy człowiek głoduje”.
O. Henry „Cupid a la Carte”, 1907


Jak byś się czuł, gdybyś |musiał budzić się każdego ranka podobnie jak szczur w klatce lub ubogie dziecko w Kalkucie: całkowicie zdany na łaskę eksperymentatora lub natury? Jak odmienne byłoby |twoje życie, gdybyś musiał troszczyć się nieustannie, skąd wziąć następny posiłek, wypatrywać następnego deszczu, który by ci dostarczył czystej wody lub zdobywać kawałek brudnej podłogi, który byś nazwał swoim łóżkiem, gdy zapadnie ciemność?
Ogromna większość studentów czytających tę książkę nigdy nie będzie musiała kłopotać się takimi koniecznościami biologicznymi. Technika i dostatek przyniosły większości Amerykanów wolność od potrzeb fizjologicznych i dały im czas i energię, którą mogą poświęcać głębszym zainteresowaniom ludzkim. Popędy są tym, co najbardziej upodabnia ludzi do „nierozumnych zwierząt”. Życie spędzone na poszukiwaniu pokarmu, wody, bezpieczeństwa i partnera seksualnego byłoby życiem, które sprowadzałoby do minimum tę różnicę, na której wytworzenie ewolucja potrzebowała milionów lat. Czy bezcenne dary ewolucji w postaci rozumu, zdolności wyboru, abstrakcyjnych zdolności intelektualnych oraz twórczości trzeba oddawać za kromkę chleba? Głód jest jakby ogromnym walcem, który sprowadza nas znowu do poziomu najniższych zwierząt.
Dążenie do zapewnienia sobie środków egzystencji w świecie niedostatku jest jednym z najważniejszych i najtrudniejszych problemów stojących przed międzynarodową społecznością - jest problemem, który wymaga innowacyjnych rozwiązań na poziomie technicznym, politycznym, ekonomicznym, społecznym i psychologicznym. Z drugiej strony, dążenie do głodzenia się, występujące w świecie obfitości, stanowi problem, który chociaż mniej oczywisty i mniej powszechny, niemniej jednak jest warty rozpatrzenia, ponieważ również wypacza i obniża jakość ludzkiego życia.




Czy żyjesz, aby jeść,
czy jesz, aby żyć?




Więcej niż trzecia część ludności świata żyje w warunkach głodu lub niedożywienia, a jednak przeprowadzono stosunkowo mało badań nad wpływem długotrwałego, niewłaściwego odżywiania się na zachowanie człowieka i życie ludzkie (ryc. 8.8). Jak organizm przystosowuje się do takich warunków?  Jakie są psychologiczne konsekwencje niedożywienia? Pewne dość starannie zaplanowane badania laboratoryjne, które w czasie II wojny światowej przeprowadzono z grupą mężczyzn uchylających się od służby wojskowej z pobudek natury moralnej, dostarczają odpowiedzi na niektóre z tych pytań.


„W eksperymencie tym, trwającym blisko rok, brało udział 36 badanych, którzy zgłosili się na ochotnika. Eksperyment składał się z trzech faz: a) dwunastotygodniowego okresu kontrolnego, w czasie którego badani otrzymywali dobrze zrównoważoną dietę, mającą reprezentować jadłospis ludzi żyjących w dobrych warunkach ekonomicznych w Stanach Zjednoczonych; b) dwudziestoczterotygodniowego okresu niedożywienia (półgłodowania), w czasie którego badani otrzymywali dietę charakterystyczną dla europejskich obszarów głodu, i wreszcie c) dwudziestotygodniowego okresu rekonwalescencji, w czasie którego badani byli starannie odżywiani, aż do osiągnięcia normy wagowej. Eksperymentalna dieta „półgłodowa” składała się głównie z chleba, makaronu, ziemniaków, rzepy i kapusty. Dostarczała ona mniej niż połowę kalorii zawartych w „normalnej” diecie, otrzymywanej w okresie kontrolnym.




* * *



Ryc. 8.8. Głód jest głównym problemem egzystencji w wielu częściach świata, a dzieci są często najbardziej godnymi litości jego ofiarami. To dziecko powraca do zdrowia we francuskim szpitalu, po ewakuacji ze zniszczonej przez wojnę Biafry.


* * *





Przez cały czas trwania eksperymentu badani wykonywali stały program zajęć, obejmujący ćwiczenia fizyczne, utrzymywanie porządku w swych kwaterach mieszkalnych oraz kształcenie się. Każdego badanego poddawano regularnie sprawdzianom fizjologicznym i psychologicznym (Keys i in., 1950).
Zmiany fizyczne spowodowane dwudziestoczterotygodniowym okresem niedożywienia były oczywiście poważne. Ponieważ organizm usiłował przystosować się do znacznie ograniczonego „dopływu” kalorii (który spowodował spadek wagi ciała przeciętnie o 25%), nastąpiły duże zmiany w wydatkowaniu energii na różne funkcje organizmu. W okresie kontrolnym stwierdzono, że prawie równa ilość kalorii była wykorzystywana na realizowanie podstawowych funkcji metabolicznych oraz na dobrowolną aktywność fizyczną - nieco mniej niż 50% ogólnej liczby kalorii szło na każdy z tych rodzajów aktywności. Pod koniec okresu niedożywienia stwierdzono, że blisko 60% zredukowanego obecnie dopływu kalorii organizm zużywał na podstawowe funkcje metaboliczne, podczas gdy mniej niż 30% poświęcał na aktywność fizyczną. Organizm zdawał się przystosowywać w najbardziej efektywny sposób, jaki był możliwy, poświęcając większy procent ogólnej obniżonej liczby kalorii na utrzymanie swych niezbędnych funkcji, odpowiednio zaś mniejszy procent na dobrowolną (a zatem niekonieczną) aktywność fizyczną (Brozek, 1963).
Autorzy tego badania przyjęli termin „nerwica półgłodowa” 
(„semistarvation neurosis”) dla określenia uderzających zmian w osobowości, które wystąpiły w wyniku niedożywienia, a następnie znikły, gdy badani powrócili do normalnej diety. Główną cechą tej „nerwicy” była apatia. Dobry humor zniknął, a jego miejsce zajęła przygnębiająca atmosfera smutku i depresji. Badani mężczyźni zaczęli ubierać się niedbale, stali się mniej towarzyscy, bardziej nerwowi i drażliwi; byli też skłonni do gburowatości i nietaktów oraz wzajemnych „rękoczynów”. Miejsce pewności siebie zajęło poczucie niższości i depresja.
W dodatku pociąg seksualny obniżył się u nich znacznie, a w okresie rekonwalescencji powoli powracał do normy. Badani znacznie „ochłodli” w stosunku do swych sympatii, zaloty i umizgi urwały się. Mężczyźni ci stawali się praktycznie niezdolni do okazywania uczucia.
Testy zdolności intelektualnych, które badani wykonywali w różnych odstępach czasu, przez cały czas trwania eksperymentu, nie wykazały żadnych wyraźnych zmian, chociaż ogólny poziom wyników uzyskiwanych przez badanych w tych testach obniżył się nieco, prawdopodobnie z powodu ogólnego osłabienia fizycznego. Ze względu na  swe ciągłe zaabsorbowanie myślami o jedzeniu oraz niezdolności skupienia się na innych sprawach, badani byli przekonani, że w rzeczywistości nastąpił u nich spadek poziomu inteligencji.
Nie może być żadnych wątpliwości, że pod koniec okresu niedożywienia popęd głodu stał się dominującym czynnikiem w życiu badanych. Jedzenie, czy to bezpośrednio czy też pośrednio, dominowało w ich rozmowach, lekturze, czynnościach wykonywanych w czasie wolnym oraz w marzeniach sennych. Wielu mężczyzn poświęcało swe wolne chwile na czytanie książek kucharskich i kolekcjonowanie przepisów kulinarnych; niektórzy poważnie brali pod uwagę możliwość zmiany swego zawodu - chcieli zostać kucharzami” (Keys i in., 1950; Guetzkow i Bowman, 1946).


Przytoczone powyżej wyniki badań eksperymentalnych nad niedożywieniem stają się jeszcze bardziej przerażające, gdy uświadomimy sobie, ilu mężczyzn, kobiet i dzieci zmuszonych jest żyć w takich warunkach, nie tylko przez okres 24 tygodni (dla dobra nauki), lecz przez całe życie i dla niczyjego dobra.




Wyniszczenie organizmu:
czy z braku uczucia?




Podczas gdy w tej właśnie chwili niezliczeni ludzie w różnych częściach świata usiłują rozpaczliwie uchronić się od cichej śmierci głodowej, inni, być może nawet studenci tej samej co ty uczelni, umierają z powodu narzuconej sobie samemu głodówki. Są oni ofiarami rzadkiej, chronicznej i prawie niemożliwej do wyleczenia, wyniszczającej choroby, zwanej |anorexia |nervosa.
Tymi ofiarami swej niekontrolowanej decyzji, by przestać żyć, są prawie wyłącznie młode dziewczęta, często inteligentne i dobrze sytuowane, w wieku od kilkunastu do dwudziestu paru lat (Bruch, 1971). W pewnym momencie przestają one zupełnie jeść, odmawiają przyjmowania jakiegokolwiek proponowanego im pokarmu i zaczynają tracić znacznie na wadze. W końcu stają się tak osłabione, że nie mogą podnieść się z łóżka i trzeba je karmić dożylnie. Jeśli leczenie nie jest skuteczne, umierają z głodu.
Większość ludzi uważa za niepojęte, że dziewczęta z zamożnych rodzin mogą umierać z głodu. Jednakże kilku amerykańskich uczonych, będących specjalistami z zakresu zaburzeń w odżywianiu, niezależnie od siebie doszło do wniosku, że w ostatnich latach nastąpił w Stanach Zjednoczonych znaczny wzrost liczby zachorowań na anoreksję. Być może, niektóre młode kobiety są „predysponowane” do tego, aby stać się anoretyczkami, ponieważ nasza kultura obsesyjnie wynosi pod niebiosa zalety szczupłości i w ten sposób usilnie popiera cechy fizyczne związane z wczesnymi stadiami anoreksji.
Duncan (1973) tak opisuje symptomy tej choroby:


„Bezwzględne unikanie pokarmu przez anoretyczkę prowadzi do takich poważnych komplikacji jak na przykład zapaść krążenia. Inne objawy, takie jak niezwykle uporczywe zaparcie, depresja oraz anormalne zaabsorbowanie sobą, swym pożywieniem i swymi ćwiczeniami fizycznymi, stanowią nie tyle bezpośrednie zagrożenie dla życia, ile są środkami przyspieszającymi proces utraty wagi. Inna grupa objawów, jakie niekiedy występują w latach poprzedzających fazę głodówki, jest uważana za bezpośrednie fizyczne objawy chaosu emocjonalnego, który stanowi podłoże tych symptomów. Należy do nich całkowity brak menstruacji, niezdolność do odczuwania głodu oraz zmęczenie” (str.47).


Istnieją jednak znaczne różnice pomiędzy anoretyczką a ofiarą zwyczajnego głodu. Ludzie w stanie wygłodzenia, podobnie jak badani w eksperymencie nad niedożywieniem, odczuwają intensywne pragnienie jedzenia, podczas gdy anoretyczka nieugięcie utrzymuje, że nie odczuwa żadnej potrzeby jedzenia.  Wydaje się ona ofiarą swej własnej niezdolności rozpoznawania czy poprawnego interpretowania informacji i sygnałów ze swego własnego organizmu.
Co jest jednak przyczyną tego, że młode kobiety zachowują się w tak zgubny dla siebie sposób? Nie wiemy tego na pewno. Niektórzy badacze sugerują, że jest to rezultat braku chemicznej równowagi w organizmie. Inni dostrzegają w takich przypadkach pewną prawidłowość psychologiczną, zwracając uwagę, że często jakieś niepokojące zdarzenie zdaje się wywoływać podjęcie decyzji o zaprzestaniu jedzenia. Nie jest to świadomie sformułowana, racjonalna decyzja; wydaje się, iż jest ona nieświadoma i w pewnym sensie narzucona ciału przez psychikę. Jako przykłądy takich zdarzeń można wymienić niepomyślne zakończenie silnie przeżywanej miłości, oddzielenie od domu rodzinnego lub nadmierną zależność od jednego z rodziców, która utrzymywała się jeszcze po osiągnięciu pełnoletności.  Jednakże nawet przypadkowa uwaga o „tłuszczyku” u danej osoby może służyć jako sygnał do zaprzestania jedzenia.
Oczywiście zdarzenia takie nie wywołują anoreksji u większości ludzi.  Charakterystycznymi elementami w historiach wielu dziewcząt cierpiących na to schorzenie są: wcześnie pojawiające się skłonności autopunitywne (do karania siebie samego) oraz przejawiane, przed wystąpieniem anoreksji, nadmierne zainteresowanie pokarmami oraz unikaniem otyłości (Verville, 1967). Jedzenie ma często szczególne znaczenie dla rodziców tych dziewcząt, podczas gdy unikanie otyłości jest szczególnie ważne dla nich samych. Wysunięto także sugestię, że dziewczęta te nie chcą mieć wtórnych cech płciowych, uważanych za atrakcyjne przez chłopców, takich, jak piersi, biodra i pośladki, które zanikają przy dużej utracie wagi (Kessler, 1966).
Przyczyny, które stanowią podłoże tak dziwnej i przesadnej reakcji, są z pewnością złożone. Gdybyś jednak miał za zadanie leczenie pacjentki cierpiącej na anoreksję, to czy zacząłbyś od prób rozwikłania problemów psychologicznych (pamiętaj, że mogłaby ona zgodzić się w tym czasie na śmierć), czy też skoncentrowałbyś swoje wysiłki na tym aby nakłonić ją do jedzenia?




Nałóg jedzenia: nie tak
przyjemnie jest
być otyłym




W przeciwieństwie do anoreksji, która jest stosunkowo rzadka, otyłość jest przypadłością aż nazbyt pospolitą. Otyłość jest chorobą społeczną społeczeństwa dostatku, która prowadzi do bardzo poważnych następstw fizjologicznych. Jest faktem, że więcej ludzi umiera wskutek stanów chorobowych związanych z nadmierną wagą ciała niż wskutek jakiegokolwiek  z innych nałogów, włączając tu alkoholizm, palenie papierosów i narkomanię (Mayer, 1968).
Lecz konsekwencje otyłości mają charakter nie tylko fizjologiczny, lecz także psychologiczny. Przeprowadzona w 1972 roku ankieta Gallupa wykazała, że spośród ankietowanych obywateli Stanów Zjednoczonych 55% kobiet i 38% mężczyzn uważa się, że waży się zbyt dużo. Tłuste dziecko jest wyśmiewane przez towarzyszy zabaw („grubas, grubas!”), otyłe nastolatki są zwykle ignorowane przez rówieśników, a otyli dorośli usiłują desperacko albo ukryć swą masę, aby nie robić z siebie widowiska, albo też udają, że są zadowoleni ze swej otyłości.
Lecz cóż z wesołymi, tłustymi olbrzymami? Według większości otyłych ludzi, jest to albo mit, albo wyjątek, który zwraca szczególną uwagę, ponieważ z reguły tłuści ludzie nie są bynajmniej weseli!


Jim Fries, który uprzednio ważył 587 funtów, lecz obecnie zredukował swą wagę do 181 funtów po przeprowadzeniu specjalnej diety i poddaniu się operacji jelit, powiedział: „Świat jest urządzony dla ludzi o niewielkich rozmiarach. Ludzie otyli muszą być weseli. Każdy tego oczekuje, jednakże my wcale nie jesteśmy weseli. To jest nieszczęście. To jest samotność” („San Francisco Chronicle”, 14 listopada 1973).
Jest zaskakujące, że dopiero w ostatnich latach podjęto eksperymentalne badania nad otyłością. Chociaż organizacje, których zadaniem jest pilnowanie, aby ich opłacający składki członkowie - a jest ich dziesiątki tysięcy - |nie jedli (przez co nawet tracą oni nieco na wadze, przynajmniej chwilowo), świetnie prosperują pod względem finansowym, to jednak wysiłki badaczy zmierzają do tego, by wyjaśnić, co sprawia, że osoby otyłe jedzą tak dużo i tak często.
Czy osoba otyła jest żarłokiem, któremu brak silnej woli, jak głosi tradycyjny pogląd? Wydaje się, że nie, o czym świadczą wyniki badań przeprowadzonych w pracowniach Richarda Nisbetta z University of Michigan i Stanleya Schatchera z Columbia University. Badania Nisbetta (1972) sugerują, że otyłość u ludzi jest zaprogramowana biologicznie. Badania Schachtera (1971) wskazują na nadmierną zależność ludzi otyłych od bodźców zewnętrznych, które zachęcają do jedzenia, oraz na ich niewrażliwość na sygnały wewnętrzne, nakazujące im przestać jeść.


Urodzili się, aby być otyłymi? To, czy jesteś otyły, zależy od liczby i wielkości wyspecjalizowanych komórek tłuszczowych w twoim organizmie.  Komórki te („adipocyty”) magazynują tłuszcz w postaci kwasów tłuszczowych.  Żmudne badania, polegające na liczeniu i mierzeniu komórek tłuszczowych u osób o przeciętnej wadze i u osób otyłych, wykazały, że osoby otyłe różnią się od osób mających normalną wagę ciała większą |liczbą, a nie większymi rozmiarami tych komórek (Bjorntrop, 1972). W jednym z badań grupa osób otyłych miała trzy razy więcej komórek tłuszczowych niż grupa osób o przeciętnej wadze.
Doniosłe znaczenie tego faktu staje się oczywiste, gdy powiąże się go z kilkoma innymi zjawiskami: |liczba komórek tłuszczowych posiadanych przez osobę dorosłą nie zmienia się, lecz jest stała; dieta i głodówka nie zmieniają liczbę komórek tłuszczowych, lecz tylko zmniejszają ich wielkość, przejadanie się zwiększa masę komórek tłuszczowych, a nie ich liczbę.
Badania Nisbetta zostały oparte na wniosku (Hirsch, 1969), że jeśli masz dużą ilość komórek tłuszczowych, to twoja otyłość jest zaprogramowana przez naturę - jesteś konstytucjonalnie otyły. Dwa czynniki decydują o tym, ile komórek tłuszczowych będzie posiadać osoba w wieku dojrzałym: komponent genetyczny (otyli rodzą otyłych) oraz komponent wczesnego odżywania (przekarmianie w niemowlęctwie). W życiu człowieka występują okresy krytyczne, w czasie których odkładanie się tłuszczu jest najbardziej prawdopodobne. Występują one tuż przed urodzeniem, około dziewiątego miesiąca życia, następnie miedzy szóstym a dziesiątym rokiem życia i wreszcie pod koniec okresu dorastania. Ograniczanie ilości przyjmowanego pokarmu i nieopróżnianie talerzy do czysta, zwłaszcza w podanych wyżej okresach odkładania tłuszczu, może dopomóc w zapobieżeniu otyłości.
Jeśli masz stosunkowo niewiele komórek tłuszczowych, to nie możesz stać się otyłym nawet wtedy, gdy jesz zbyt wiele, jeśli zaczynasz od wysokiego poziomu wyjściowego komórek magazynujących tłuszcz, to trudno ci będzie nie stać się otyłym, gdy żyjesz w warunkach obfitości. W pewnym sensie, jeśli masz wysoki poziom wyjściowych komórek tłuszczowych, to będziesz „utajonym tłuściochem” nawet wtedy, jeśli będziesz szczupły wskutek zachowywania diety. To właśnie może być przyczyną tego, że kliniki leczące otyłość mają jedynie ograniczone, krótkoterminowe sukcesy - gdyż później „utajone tłuściochy” wracają wraz ze swym nadmiarem niedożywionych komórek tłuszczowych do świata pełnego wszelkich dobrych rzeczy.
Otyli pacjenci, którzy utracili dosłownie setki funtów pod wpływem radykalnego leczenia klinicznego, odzyskują zazwyczaj wszystkie te stracone funty lub ich większość, gdy tylko mają znów swobodny dostęp do jedzenia.  Konstytucjonalnie zaprogramowanej osobie otyłej jeszcze bardziej utrudnia utratę wagi to, że - zgodnie z panującym obecnie poglądem - „ośrodki pokarmowe” w mózgu regulują pobieranie pokarmu w taki sposób, aby utrzymać zapasy tłuszczu na poziomie wyjściowym charakterystycznym dla danej osoby.  Jeśli tak jest rzeczywiście, to ludzie ci żyjący w społeczeństwie, które nagradza szczupłość, są głodni przez cały czas, gdy utrzymują pożądaną społecznie wagę.


Włączyć czy nie wyłączać? Oto jest pytanie. Schachter i jego uczniowie podjęli próbę ustalenia, w jakich warunkach bodźcowych ludzie otyli jedzą więcej niż normalni, a w jakich warunkach - nie. Wydaje się oczywiste, że ludzie stają się otyli wtedy, gdy coś pobudza ich do tego, by jedli częściej i zjadali więcej pokarmu, niż to jest niezbędne ze względów odżywczych oraz (lub) wtedy, gdy kontynuują jedzenie nie zważając na wewnętrzne sygnały, by przestać. Lecz jakie sygnały „włączają” - lub nie są w stanie „wyłączyć” - takiego zachowania (to jest jedzenia)? Wysunięto hipotezę, że osoba otyła jest |bardziej od innych |wrażliwa na sygnały zewnętrzne związane z pokarmem, stosunkowo zaś |niewrażliwa na sygnały wewnętrzne.
Wyniki uzyskane w badaniach klinicznych wskazują na oba te czynniki. W jednym z badań stwierdzono, że otyli pacjenci jedli więcej, gdy zwiększono atrakcyjność ich fizycznego i społecznego środowiska. Jednakże ograniczyli oni drastycznie ilość spożywanego pokarmu, gdy musieli pić go przez rurkę połączoną z dystrybutorem płynów (Hashim i Van Italie, 1965). Ponadto, w przeciwieństwie do osób o normalnej wadze ciała, których wypowiedzi o odczuwanym głodzie są skorelowane z aktywnością gastryczną (skurczami głodowymi), u osób otyłych brak korelacji pomiędzy aktywnością żołądka a uczuciem głodu (Stunkard i Koch, 1964).


„W kontrolowanych badaniach laboratoryjnych, przeprowadzonych przez Schachtera, Nisbetta i ich uczniów, porównywano ilość pokarmu zjadanego w najrozmaitszych sytuacjach przez studentów wyższej uczelni wykazujących nadwagę oraz przez badanych z grupy kontrolnej o normalnej wadze ciała.  Ilość pokarmu spożywanego przez badanych o przeciętnej wadze malała, gdy wzbudzono w nich strach lub gdy mieli przeładowane żołądki, podczas gdy te warunki wewnętrzne nie miały żadnego wływu ma czynność jedzenia (konsumpcję krakersów) studentów otyłych.


Z drugiej strony, otyli badani jedli więcej niż normalnie, gdy podano im smaczne lody, natomiast mniej, gdy lody te były gorzkie.
Badani otyli jedli również więcej niż inni badani z grupy kontrolnej wtedy, gdy sądzili, że jest czas na obiad - na podstawie informacji zewnętrznej, a nie swego własnego zegara biologicznego. Wykazano to posługując się „fałszywym” zegarem, który można było przyspieszać lub zwalniać. Trzydziestominutowe posiedzenie eksperymentalne, przeprowadzone na krótko przed porą obiadową, zdawało się trwać albo 60 minut, albo tylko 15 minut. Studenci otyli jedli więcej, gdy zegar wskazywał, że była godzina #18#/00, niż wtedy, gdy wydawało się, że jest dopiero #17#/15. U osób z grupy kontrolnej różnica ta nie wystąpiła. I wreszcie, gdy przed osobami otyłymi postawiono talerz pełen orzeszków, jadły one więcej wtedy, gdy zwrócono ich uwagę na te orzeszki za pomocą jaśniejszego ich oświetlenia albo instrukcji, by myśleć o nich. Te różnice w wyrazistości sygnałów (cue salience) nie wpływały na ilość orzeszków zjadanych przez osoby badane o normalnej wadze”.


Badacze ci zwrócili także uwagę na analogię między wzorcami zachowania występujących u otyłych ludzi i u przejadających się (wykazujących |hiperfagię) szczurów. Obie te populacje wykazywały większą wrażliwość na smak, większą wrażliwość na wstrząsy elektryczne i wzmocnienie za pracę, krótsze czasy reakcji na bodźce sensoryczne oraz mniejszą gotowość do wydatkowania wysiłku dla uzyskania pokarmu. Wysunięto sugestię, że u takich osobników występuje pewien stan ośrodkowego układu nerwowego, który powoduje uogólnioną „wrażliwość zewnętrzną” („externality”) - nadmierną reaktywność na wszelkie bodźce zewnętrzne, przy czym pokarm jest tylko jedną ich kategorią.




Zbliżenie


Gdybyś był otyły, to czy chciałoby ci się rozwijać te przysmaki?


„Czy osoby otyłe jadłyby więcej niż te o przeciętnej wadze również wtedy, gdyby musiały zapracować na swe pożywienie? Aby odpowiedzieć na to pytanie, Schachter i Freedman (1971) przeprowadzili pomysłowy eksperyment, w którym porównywali, ile migdałów zjedli studenci otyli i studenci o normalnej wadze ciała, gdy migdały były w skorupkach bądź obłuskane. Podczas wypełniania kwestionariusza studenci pojadali migdały: otyli zjedli więcej obłuskanych migdałów niż badani o przeciętnej wadze ciała, lecz nie więcej wtedy, gdy trzeba je było obłuskiwać.
Jednakże jeszcze bardziej pomysłowe badanie pozwoliło sprecyzować oczywisty pozornie wniosek, że otyli nie będą pracować na swój obiad, jeśli nie otrzymują go do gotowego na półmisku. Singh i Sikes (1972) z University of Texas stworzyli warunki, w których wykazali, że jeśli otyli ludzie mają choć trochę uprzednich doświadczeń w działaniach zamierzających do uzyskania upragnionego pokarmu, to będą wkładać w nie wiele wysiłku, a zatem będą też jeść więcej niż osoby o normalnej wadze. Osoby otyłe pozostają w tyle tylko wtedy, gdy wysiłek potrzebny dla uzyskania pokarmu jest przykry, frustrujący i nie stanowi części zwykłego rytuału jedzenia danego pokarmu.
Badacze ci zorganizowali dla osób o normalnej wadze ciała i osób otyłych jedzenie dwóch rodzajów orzechów: obłuskanych (jak to jest zazwyczaj) i zawiniętych w folię (czego się zwykle nie stosuje). Osoby otyłe jadły więcej orzechów obłuskanych i mniej orzechów owiniętych w folię niż osoby o normalnej wadze ciała. W drugiej sytuacji, w której wysiłek potrzebny do uzyskania pokarmu był elementem uprzedniego doświadczenia, badanym ofiarowano cukierki czekoladowe zwinięte w folię (jak zazwyczaj) oraz nie zawinięte. Okazało się, że praca polegająca na odwijaniu zawiniętych cukierków czekoladowych nie stanowiła żadnej przeszkody dla otyłych badanych - pochłaniali je w takich ilościach i z taką łatwością jak osoby o normalnej wadze, niezależnie od tego, czy cukierki te były owinięte czy też nie”.


Przez wiele lat otyłość uważano za wynik czystego obżarstwa. Jednakże obecnie wydaje się, że otyłość może być związana z pewnymi wyznacznikami biologicznymi i (lub) nadmierną wrażliwością na sygnały środowiskowe, które inicjują i podtrzymują czynność jedzenia niezależnie od potrzeby fizjologicznej. W społeczeństwie obfitości, atrakcyjnych opakowań, dobrej kuchni oraz określonych pór jedzenia, takim jak rozwinięte technicznie społeczeństwo Stanów Zjednoczonych, nie jest bynajmniej dziwne, że zbyt wielu ludzi przejada się i staje się otyłymi. Być może, przewidywany niedobór pokarmu w nadchodzących latach będzie ukrytym błogosławieństwem dla ludzi otyłych, jak również dla nas, „utajonych tłuściochów”.




Pragnienie: inny popęd
utrzymujący organizm
przy życiu




Chociaż głód jest chyba najbardziej oczywistym z popędów fizjologicznych i najłatwiejszym do badania, istnieją także inne popędy, które są równie ważne dla życia. Główną rolę wśród nich odgrywają: „głód powietrza” (tlenu) oraz pragnienie. Jeśli jednak organizm ma utrzymać się przy życiu w nieprzyjaznym niekiedy środowisku, to należy również zaspokoić inne jego wymagania. Obejmują one, na poziomie jednostki, potrzebę snu, potrzebę utrzymania dostatecznie stałej temperatury ciała, potrzebę ochrony organizmu przed uszkodzeniem fizycznym oraz, na poziomie gatunku, popęd seksualny. W podrozdziale tym omówimy pragnienie jako popęd ważny dla utrzymania organizmu przy życiu. W ostatniej części niniejszego rozdziału zajmiemy się popędem seksualnym.
Podczas gdy większość zwierząt potrafi żyć tygodniami bez pokarmu, mogą one przetrwać jedynie parę dni bez wody. Ludzie, którzy przez długi czas byli całkowicie pozbawieni zarówno pokarmu, jak i wody, podają, że pragnienie w krótkim czasie zaczynało ich wręcz doprowadzać do szału, podczas gdy skurcze głodowe zwykle zanikały po paru dniach. King (1878) opisał ogromne cierpienia, jakich doświadczyli żołnierze oddziału kawalerii amerykańskiej, pozbawieni wody przez 86 godzin na pustyni w stanie Texas.  Gdy w końcu mieli oni sposobność napić się, to „chociaż pochłaniali wodę bez ustanku”, aż do przepełnienia żołądka, nie zaspokajała ona ich nieugaszonego pragnienia”.
Głód i pragnienie nie tylko różnią się intensywnością, lecz także zdają się mieć jakościowo odmienny wpływ na zachowanie, przynajmniej u zwierząt.  W eksperymentach ze szczurami stwierdzono, że spragnione zwierzęta uczą się znajdować nagrodę w postaci wody szybciej niż głodne zwierzęta uczą się znajdować pokarm, przynajmniej wtedy, gdy nagrody znajdują się w tym samym miejscu labiryntu. Gdy jednak szczury muszą się nauczyć biegania do różnych miejsc docelowych w kolejnych próbach, to głodne szczury, uczą się trafiać na zmianę do dwóch różnych miejsc znacznie szybciej niż szczury spragnione.  Sugeruje to, że motywacyjny stan głodu prowadzi do zmienności zachowania, podczas gdy pragnienie sprzyja reakcjom stereotypowym. Wynik ten można by zinterpretować w kategoriach adaptacyjnej doniosłości tych form zachowania.  W swym naturalnym środowisku szczur jest zwykle zmuszony poszukiwać pokarmu, podczas gdy miejsce zaopatrzenia w wodę pozostaje zwykle względnie stałe.




Fizjologia pragnienia




Uczucie pieczenia czy suchości w gardle zdaje się być dostatecznym bodźcem dla zapoczątkowania picia. Gdy zasoby wody w organizmie wyczerpują się, wówczas śluzówka w jamie ustnej staje się sucha: aby zlikwidowć tę suchość, dany osobnik pije (ryc. 8.10). Badania przeprowadzone przy użyciu techniki „|wstępnego |napełnienia” („preloading”), w której wstrzykuje się dużą ilość wody do żołądka zwierzęcia, wykazały, że zwierzę (któremu uprzednio nie pozwalano pić) zaczyna pić i kontynuuje tę czynność (w zmniejszonym tempie) nawet wtedy, gdy jego żołądek został wstępnie napełniony wodą o objętości dwa razy większej niż normalnie. To sugerowałoby, że przynajmniej jeden zbiór sygnałów związanych z zapoczątkowaniem picia, to sygnały oralne.
Jednakże „pomiar” ilości wody pobieranej przez jamę ustną nie jest niezbędnym warunkiem regulacji poboru wody. Gdy spragnione szczury muszą uczyć się naciskania dźwigni, aby otrzymać zastrzyki wody bezpośrednio do żołądka, wtedy po niedługim czasie potrafią one utrzymywać normalny poziom poboru wody (Teitelbaum i Epstein, 1962). Regulacja ilości pobieranej wody jest zatem możliwa bez sprzężenia zwrotnego z jamy ustnej czy gardła, a czynniki gastryczne również muszą wchodzić tu w grę.




* * *



Ryc. 8.10. „Pomiar Wody” U Różnych Gatunków. Wykres przedstawia związek między niedoborem wody a jej pobieraniem u różnych gatunków. Linia oznaczona jako „pomiar doskonały” reprezentuje hipotetyczny przypadek, w którym zwierzę wypija dokładnie tyle wody, ile wymaga jego organizm. U psów pomiar ten jest prawie doskonały, podczas gdy u innych gatunków jest on mniej dokładny albo na wszystkich poziomach niedoboru, albo po osiągnięciu pewnego krytycznego poziomu niedoboru wody. Z danych tych wynika w sposób oczywisty, że trzeba brać pod uwagę gatunek zwierzęcia, gdy na podstawie ilości wypijanej wody wyciąga się wnioski dotyczące siły pragnienia.


* * *





Jednakże wydaje się, że pragnienie jest redukowane w większym stopniu wtedy, gdy woda jest pobierana przez jamę ustną niż wtedy, gdy tę samą ilość wody wprowadza się bezpośrednio do żołądka zwierzęcia. Posługując się tempem naciskania dźwigni (za wzmocnienie w postaci wody) jako wskaźnikiem pragnienia, Neal Miller (1957) stwierdził, że spośród szczurów pozbawionych wody w najszybszym tempie naciskały dźwignię te, którym nie dano w ogóle wody, na drugim miejscu te szczury, którym wstrzyknięto po 14 cmó; wody do żołądka, a grupa która otrzymała po 14 cmó; wody przez jamę ustną, naciskała dźwignię w najwolniejszym tempie.
Z biologicznego punktu widzenia zwierzę nie pije oczywiście po to, aby zwilżyć swą jamę ustną czy wypełnić żołądek wodą. Chodzi raczej o zachowanie subtelnej równowagi płynów w organizmie, czemu służy system powiązanych ze sobą wzajemnie procesów fizjologicznych. Wszystkie zwierzęta nieustannie tracą płyny w wyniku pocenia się, wydalania i oddychania, niezależnie od tego, czy mają możność uzupełnienia swoich zasobów wody, czy też nie. W przeciwieństwie do pokarmu, woda nie jest magazynowana w organizmie „na zapas”; tak więc przy długotrwałej deprywacji ilości płynów pozakomórkowych, które otaczają komórki organizmu zmniejsza się, a stężenie szeregu substancji w tych płynach, przede wszystkim sodu i chloru, wzrasta.  Ciśnienie wytworzone przez ten brak równowagi powoduje przechodzenie wody - dzięki procesowi |osmozy - z wnętrza komórek do otaczających je płynów. W wyniku długotrwałej deprywacji następuje odwodnienie samych komórek. Wolf (1958) określa odwodnienie tkanek jako „prawdziwe pragnienie”, w odróżnieniu od miejscowej suchości w ustach i gardle, czyli „pragnienia fałszywego”.
Najpowszechniej uznawane wyjaśnienie homeostatycznej regulacji pragnienia zakłada istnienie |osmoreceptorów - specjalnych komórek receptorowych, prawdopodobnie zlokalizowanych w podwzgórzu, które reagują na sygnały informujące o wzroście ciśnienia osmotycznego w ten sposób, że zapoczątkowują picie. Poparcia dla tej teorii dostarczają przede wszystkim badania, w których zwierzętom wstrzykiwano roztwory soli, co powodowało, że więcej piły, nawet wtedy, gdy wypiły tyle wody, ile chciały, tuż przed wstrzyknięciem roztworu soli (Fitzsimmons i Oatley, 1968).
Okazuje się jednak, że teoria osmoreceptorów nie wyjaśnia całkowicie zjawiska pragnienia. Na przykład nie jest jeszcze dokładnie znany mechanizm, za pomocą którego receptory te sygnalizują reszcie ciała, że nadszedł czas, aby rozpocząć picie. Ponadto występuje wiele zjawisk niezgodnych z tą teorią; osobniki pocące się (tracące sól) piją wodę, mimo to jeszcze bardziej zaburza równowagę osmotyczną, a zwierzęta pozbawione soli zwiększają, zamiast zmniejszać, ilość pobieranej przez siebie wody.
Procesy synchronizacji poboru wody oraz przenikania wody z płynu pozakomórkowego do komórek są bardzo złożone. Zwierzę przestaje pić, zanim znaczna ilość wody opuści jego żołądek (zmniejszając w ten sposób stężenie soli w płynie pozakomórkowym”. Gdy w mózgach spragnionych szczurów implantowano czułą aparaturę rejestrującą, stwierdzono, że |uwodnienie („hydration” - powrót płynów do komórek) zaczyna się niemal natychmiast po dojściu wody do żołądka. Organizm zdaje się w jakiś sposób przewidywać, iż będzie dostępny płyn, który pozwoli wyrównywać brak płynu pozakomórkowego, i woda przechodzi do komórek, |zanim jej niedobór zostanie uzupełniony przez „dostawy” z żołądka.




Bodźce zewnętrzne
regulujące picie




Wyjaśnienie zjawiska pragnienia, które koncentruje się tylko na przyczynach fizjologicznych, nie obejmuje jednak wszystkich istotnych czynników. Pragnienie, podobnie jak głód, nie jest wyłącznie motywem fizjologicznym, chociaż jest najsilniejszym popędem biologicznym. Wykazano, że picie jest jest regulowane przez szeroki zakres czynników skojarzeniowych, które są niezależne od poziomu odwodnienia komórek czy innych fizjologicznych aspektów „prawdziwego pragnienia”.
Szczury piją więcej w sytuacjach nie podlegajacych zmianom niż w sytuacjach, które zmieniają się. Pojąc je w regularnych odstępach czasu można tak regulować ich czynność picia, że ilość pobranej przez nie wody będzie niezależna od stanu deprywacji (Collier, 1962). U ludzi picie i jedzenie zwykle towarzyszą sobie („dzban wina, bochen chleba...”). Oba te procesy mogą skojarzyć się ze sobą tak, że gdy rozpoczyna się bądź jedzenie, bądź picie, staje się ono reakcją sygnałowotwórczą („cue producing response”), wywołującą drugie z tych zachowań.


„Pomysłowa seria eksperymentów pokazuje, w jakim stopniu zachowanie konsumacyjne można poddawać pod kontrolę innych bodźców, a nawet innych stanów motywacyjnych. Eksperymentator potrafił nakłonić szczury do wypijania dużych ilości wody, uzależniając zakończenie bolesnego wstrząsu od czynności picia. Aby uniknąć otrzymywania wstrząsów elektrycznych, szczury uczyły się pić daleko więcej, niż było potrzebne dla osiągnięcia zadowolenia czy zaspokojenia potrzeb organizmu. Również głód stosowano dla wywołania picia. Głodne szczury nauczono wypijać ogromne ilości wody, karmiąc je po prostu dopiero wtedy, gdy wypiły pewną ilość wody” (Teitelbaum, 1966).


Jest oczywiste, że ten paradygmat warunkowania można rozszerzyć, uzależniając jakiekolwiek zachowanie konsumacyjne od jakiegokolwiek innego popędu czy układu bodźców.
Z drugiej strony, zachowanie konsumacyjne można zahamować, wiążąc z nim wystąpienie jakiegoś przykrego zdarzenia. Zasadę tę stosuje się w terapii behawioralnej, w której chodzi o regulację czynności jedzenia, picia, palenia, czy też zachowań seksualnych u pacjentów, którzy potrzebują pomocy. Myśl czy działanie związane z danym zachowaniem konsumacyjnym kojarzy się z jakimś przykrym następstwem, takim jak wstrząs, sztucznie wywołane mdłości czy też przykre wyobrażenie. Jednakże silny nałóg nadużywania pokarmu czy też alkoholu, jak również narkomanię, trudno jest usunąć w sposób trwały, bez względu na zastosowaną procedurę zmiany zachowania.
W każdym razie pragnienie, podobnie jak inne popędy, najwyraźniej nie jest pojedynczą, jednostkową zmienną pośredniczącą, jaką początkowo badacze mieli nadzieję znaleźć. Obecnie przedstawia się je jako heterogeniczny zespół („cluster”) czynników, obejmujących wiele ośrodków nerwowych, na które „mają różny wpływ rozmaite regulatory i które wpływają rozmaicie na różne systemy reakcji” (N. E. Miller, 1957, s. 1275).




Popęd seksualny




Przetrwanie pojedynczego organizmu nie zależy od zaspokojenia popędu seksualnego; niektóre zwierzęta i ludzie pozostają w celibacie przez całe życie bez widocznego upośledzenia ich codziennego funkcjonowania. Jednakże przetrwanie gatunku jest w istotny sposób uzależnione od popędu seksualnego. Ewolucja miała zatem problem do rozwiązania: jak zachęcić zwierzęta, aby dokonywały „altruistycznego” aktu przyjścia z pomocą gatunkowi. Nie był to łatwy problem, ponieważ akt seksualny wymaga zużycia dużej ilości energii i naraża daną jednostkę na znaczny stres. Rozwiązanie polega oczywiście na tym, że stymulacja seksualna dostarcza jednostce intensywnej przyjemności fizjologicznej. Orgazm służy jako ostateczny czynnik wzmacniający, który wynagradza cały czas, wysiłek i pracę, jakich wymaga proces doprowadzający do połączenia plemnika z komórką jajową.  Zachęta ta okazała się tak skuteczna, że skłania do „altruizmu” wykraczającego poza wymagania natury.
Liczne badania, przeprowadzone nad różnymi gatunkami, wykazały, że stan receptywności seksualnej wywołuje znacznie wyższy od normalnego poziom aktywności, napięcia i niepokoju. Jeśli więc uważa się receptywność seksualną za popęd, którego celem jest kopulacja, to seks można uważać za motyw, który wiąże oba te aspekty i prowadzi zarówno do zadowolenia indywidualnego (dzięki redukcji napięcia), jak i ostatecznie do przedłużenia trwania gatunku (dzięki skutecznej reprodukcji).




Co czyni seks odmiennym
od innych popędów?




Popęd seksualny z wielu powodów zajmuje w naszej analizie motywów jedyne w swoim rodzaju miejsce.
1.	Jak już wspomnieliśmy, nie jest on niezbędny do przetrwania jednostki, lecz jedynie do przetrwania gatunku.
2.	Jego wzbudzenie jest niezależne od deprywacji czy nasycenia, z wyjątkiem zmiennego okresu refrakcji po osiągnięciu przez daną jednostkę szczytu podniecenia seksualnego.
3.	Może być wzbudzony przez prawie każdy bodziec, jaki tylko można sobie wyobrazić.
4.	Wzbudzenia popędu poszukuje się równie aktywnie, jak i jego redukcji.
5.	Motywuje on niezwykle szeroki zakres różnorodnych zachowań i procesów psychicznych.
6.	Nie jest jasne, co stanowi końcową reakcję spełniającą („goal response”) popędu seksualnego, wskutek czego jego status jako funkcji homeostatycznej jest wątpliwy.





Formy zachowania
seksualnego




Jest zaskakujące, że badacze studiujący „zachowanie seksualne” nie są zgodni, co obejmuje ten termin. Niektórzy uważają, że istotne jest jedynie połączenie komórek rozrodczych w trakcie aktu rozrodczego; inni utrzymują, że termin ten dotyczy jedynie kopulacji w stosunku heteroseksualnym.  Jednakże kopulacja i zapłodnienie stanowią jedynie małą część większego, złożonego wzorca, który obejmuje także zwrócenie na siebie uwagi partnera (zwykle przy zastosowaniu odpowiedniej taktyki „popisywania się”), zaloty, grę wstępną („foreplay”), budowanie „gniazda” oraz opiekę nad młodymi, będącymi rezultatem związku seksualnego.
Przedmiotem tych ogólnych klasyfikacji zachowań, uważanych za „seksualne”, są konkretne, rzeczywiście obserwowane zachowania. Każdy komponent aktu seksualnego jest zachowaniem wywoływanym przez specyficzne bodźce wyzwalające; na zachowania te mogą wywierać różnorodny wpływ rozmaite czynniki nerwowe, hormonalne i środowiskowe.
Formy zewnętrznego zachowania seksualnego u zwierząt są godne uwagi zarówno ze względu na ich zróżnicowanie u poszczególnych gatunków, jak też na ich stałość w obrębie danego gatunku. Wpływ hormonów na zachowanie seksualne u samic jest najbardziej widoczny u niższych ssaków. W czasie owulacji, gdy estrogeny dostają się do krwiobiegu, samica traci swą uprzednią obojętność w stosunku do samca i staje się wysoce receptywna lub nawet agresywnie zaczepna w swym zachowaniu seksualnym. Zachowanie to znane jest jako |estrus, czyli ruja, i stanowi sygnał, że samica jest w stanie gotowości do zajścia w ciążę. Sygnały behawioralne nadawane do samca są to specyficzne dla danego gatunku, stereotypowe reakcje, mające przyciągnąć i skupić jego uwagę na okolicy genitalnej samicy. W wypadku niektórych gatunków zachowania seksualne samców również występują w określonym czasie.  Na przykład u pewnego gatunku jelenia („Virginia deer”) przed wystąpieniem okresu godowego samcom powiększają się jądra.




* * *



Ryc. 8.11. Zaloty Motyla Królewskiego


Zachowanie samicy a); Zachowanie samca b)
a) pojawia się - b) ściga w powietrzu - a) lata - b) dogadnia - a) siada na roślinie - b) wydziela podniecający seksualnie zapach - a) składa skrzydła - b) siada obok - a) przyzwala - b) kopuluje - a) i b) lot poślubny

(Adatowane z Browera i Cranstona, 1962)


* * *





Na reakcje seksualne u zwierząt, zwłaszcza u samic, wpływają także sygnały zapachowe. Ten „słodki zapach seksu” znany jest pod nazwą |feromonu. Samce rezusów wykazują zmiany fizjologiczne, takie jak powiększenie jąder, gdy poczują zapach związany z rują samic przebywających w sąsiednich klatkach, u których wywołano ją przez wstrzyknięcie hormonów.  Sprawny seksualnie samiec myszy wpuszczony do klatki z samicami powoduje zmianę cyklu estralnego u tych samic; u większości z nich natychmiast występuje estrus (Parkes i Beuce, 1961). Stłoczenie samic myszy w ciasnocie może wywołać u nich ciążę rzekomą, czemu zapobiega usunięcie im opuszki węchowej. Unasiennione samice myszy nie zajdą w ciążę, jeśli da się im do wąchania mocz obcego, dojrzałego samca. Takie „zablokowanie ciąży” występuje z większą częstotliwością, jeśli zapach ten pochodzi od samca z innego szczepu.
Zmienność form kopulacji ilustrują następujące przykłady: małpy pozostają połączone w kopulacji jedynie przez około 15 sekund, sobole aż przez 8 godzin.



Drapieżniki, takie jak niedźwiedzie i lwy, kopulują godzinami, podczas gdy ich ofiary, takie jak antylopy, kopulują najwyżej przez parę sekund, w czasie biegu. Samiec szczura przed właściwą kopulacją przeprowadza wiele (od 10 do 20) kolejnych krótkich intromisji.
Zapoczątkowanie reakcji seksualnej u większości zwierząt powoduje wystąpienie złożonego łańcucha bodźców i wzajemnych reakcji samca i samicy; muszą one być skoordynowane, aby nastąpiło skuteczne unasiennienie (Schein i Hale, 1965; ryc. 8.11). Jednakże nawet te pozorne mechaniczne formy zachowania są kontrolowane i regulowane dzięki doskonałej integracji mechanizmów hormonalnych i nerwowych - bardzo wrażliwych na bodźce środowiskowe.




Doniosłość wczesnych
doświadczeń




Wykazano, że czynnik wczesnego doświadczenia wpływa na zapoczątkowanie, utrzymanie i rozwój seksualnego zachowania u zwierząt. Badania wykazują, że wczesne doświadczenie społeczne jest koniecznym warunkiem normalnego zachowania seksualnego.




Zbliżenie


Kłopoty seksualne znudzonych zwierząt


„Im bardziej są inteligentne, tym więcej problemów zdają się mieć”.  Chociaż może to brzmieć jak wypowiedź psychologa zatrudnionego w przychodni uniwersyteckiej, to jednak w rzeczywistości są to słowa dyrektora ogrodu zoologicznego w San Francisco, Johna J. Springa, który jest przekonany, że jego podopieczni mają prawie tyle samo kłopotów natury emocjonalnej, co ludzie, którzy przychodzą gapić się na nie. Według Springa, głównym problemem zwierząt w niewoli jest nuda - problem, który często jest spowodowany niemożnością zaspokojenia seksualnego w warunkach przymusowego celibatu obowiązującego w ich purytańskim więzieniu. Oto niektóre przykłady kłopotów seksualnych zaobserwowanych u zwierząt w ogrodzie zoologicznym.
„Rogaty samiec okapi, imieniem Ralf, jest tak stęskniony za żeńskim towarzystwem (w ogrodzie tym nie ma innego okapi, krewniaka żyrafy), że w całkowitej frustracji drapie rogami o metalowy płot. Umieszczono go razem z żyrafami, lecz trzeba było go usunąć, gdyż zaczęły go kopać, gdy tylko poczynił propozycje seksualne pewnej żyrafie-samicy”.
„Pewna samica makaka, jedna z małp wąskonosych, tak rozpaczliwie chciała mieć małe, że ukradła innej samicy urodzonego niedawno potomka, imieniem Rudy, i nie chciała go oddać. Usunięto ją z klatki, a matka i dziecko czują się obecnie dobrze”.
„Henrietta, stara lwica (...) tak bardzo zirytowała się nieudolnymi zalotami swego nowego partnera, który nigdy przedtem nie kopulował, że ugryzła go w nogę. W końcu zdesperowana wpełzła pod niego, Lew pojął wreszcie o co chodzi i dosłownie oszalał”. („San Francisco Chronicle”, 2 listopada 1973).


Porównując pod względem różnych wskaźników samce szczurów wychowane w izolacji z samcami wychowywanymi w grupie, Zimbardo (1958) stwierdził, że ogół czynności seksualnych podejmowanych przez izolowane samce był stosunkowo nieefektywny. U szympansów izolacja społeczna ma jeszcze poważniejsze następstwa. Samiec musi uczyć się współżycia seksualnego, przy czym zwykle uczy go jakaś doświadczona samica. Samce natomiast uczą się przez kontakt z innymi samcami posługiwania się zachowaniem seksualnym zarówno w celach seksualnych, jak i nieseksualnych. Szympansica, „prezentując” się seksualnie, często potrafi wygrać ze znacznie większym samcem, zwłaszcza w rywalizacji o pokarm.
Wykazano, że młodym zwierzętom w większości gatunków potrzebne jest „odgrywanie” w zabawie zachowań, którego w wieku dojrzałym staną się częścią ich repertuaru seksualnego. Bez tej „praktyki” i kontaktu cielesnego, wzorce zachowania seksualnego w późniejszym życiu tych zwierząt będą najprawdopodobniej wadliwe.




Czy „miłość matczyna”
jest niezbędna?




Przyjmuje się powszechnie, że matki ludzkie i zwierzęce mają popęd biologiczny (tak zwany „instynkt macierzyński”) skłaniający do chronienia swego potomstwa i opiekowania się nim. Przytoczone poprzednio dane, które uzyskano w badaniach przeprowadzonych przy zastosowaniu skrzynki przeszkód, wskazują, że szczurzyce narażały się na większy ból, aby dostać się do jednego ze swych małych, niż w jakimkolwiek innym stanie motywacyjnym.  Literatura pełna jest przykładów matek ludzkich nie dbających wcale o własne życie, podczas ratowania swych dzieci z niebezpieczeństwa, oraz matek zwierzęcych skutecznie broniących swego potomstwa przed napaścią ze strony silniejszych fizycznie drapieżników.
Wysuwa się argument, że noszenie bólów porodowych oraz zapewnienie 
długotrwałej opieki niezbędnej dla utrzymania przy życiu niedołężnych 
malców wymaga istnienia takiego podstawowego popędu. Współczesnym wyrazem 
popędu macierzyńskiego jest oświadczenie dziewiętnastoleniej niezamężnej 
matki, która powiedziała: „(...) teraz po prostu musze opiekować się moim 
synkiem (...) występuję w filmach (pornograficznych), ponieważ zrobiłam i 
zrobię wszystko, co da mi pieniądze na wyżywienie Williama”
(„The Daily Californian”, 26 lipca 1970, s. 3).
Jednakże wrodzony i uniwersalny charakter tego popędu kwestionuje się na podstawie równie ważnych danych. Na Wyspach Murraya liczebną równowagę płci utrzymuje się zabijając noworodki tej płci, która zaczyna być reprezentowana zbyt licznie. Wiele matek w naszym społeczeństwie dobrowolnie oddaje swe dzieci do adopcji, a matki na Wyspach Andamańskich adoptują dzieci swych przyjaciółek, jednocześnie oddając swe własne. U niższych ssaków rozwój „właściwych” zachowań macierzyńskich może być uzależniony od odbierania pewnych specyficznych bodźców. Jeśli szczurzyce są hodowane w gumowym kołnierzu wokół szyi, który nie pozwala im wąchać i lizać własnych genitaliów, to brak im instynktu macierzyńskiego. Jeśli nie mogą lizać swych małych po urodzeniu ich, to nie tylko nie dbają później o nie, lecz nawet często je pożerają (Birch, 1956).
Cóż takiego daje matka swemu dziecku, co jest charakterystyczne jedynie dla relacji pomiędzy matką a dzieckiem? W jakich warunkach samice, które rodzą małe, nie stają się „matkami”? Pierwsze z tych pytań postawił Harry Harlow i wraz ze swymi współpracownikami z University of Wisconsin szukał na nie odpowiedzi w obszernym programie badawczym (1971); badania te zostały przeprowadzone na małpach. Drugie pytanie wyłoniło się w następstwie obserwacji, jakie poczynili oni przy badaniu „przyjemności dotykania” („contact comfort”; przyjemność wynikająca z kontaktu fizycznego) jako ważnego aspektu związku matki z dzieckiem.


Szczęście to matka z włochatej tkaniny. W serii eksperymentów małpy (makaki) odłączano od ich matek zaraz po urodzeniu i umieszczano razem z namiastkami matek.


„W klatkach mieszkalnych małych małpek umieszczano matkę zastępczą wykonaną z drewna pokrytego gąbką i włochatą tkaniną oraz matke drucianą - podobnej wielkości i kształtu. Połowa małpek mogła otrzymać pokarm z butelki przymocowanej do matki włochatej, druga połowa - od matki drucianej.


Wszystkie małpki mogły iść do którejkolwiek z matek w dowolnym czasie, zaś ilość czasu spędzonego z każdą matką rejestrowano automatycznie.
W miarę jak małpki stawały się coraz starsze i miały coraz więcej okazji do uczenia się, spędzały mniej czasu z dającą im mleko drucianą matką, więcej zaś czasu z matką z włochatej tkaniny, od której go nie otrzymywały.  Przyjemność dotykania, w nieporównanie większym stopniu niż karmienie, decydowała zatem o tym, którą z matek małpki wybierały. Co więcej, gdy wprowadzono bodziec wzbudzający strach (zabawkę przedstawiającą misia bębniącego w bęben), to małpki zawsze poszukiwały matki z włochatej tkaniny, bez względu na to, która matka dawała im mleko (ryc. 8.13).
Sprawdziany w sytuacjach otwartych (open field tests), w tym wypadku przeprowadzone poza klatką, w nowym otoczeniu, potwierdziły ten wynik. Małe małpki wykorzystywały matkę z tkaniny jako „bazę”, z której badały obce otoczenie, uciekając od niej zawsze, gdy coś je przestraszyło. Gdy umieszczono je w nowym pomieszczeniu bez matki, wówczas drżały i piszczały lub biegały od przedmiotu do przedmiotu, wrzeszcząc i skrzecząc.
Następnie małpki te oddzielono od ich zastępczych matek i sprawdzano ich pamięć afektywną („affectional retention”) codziennie przez pierwszych dziewięć dni, a przez następnych pięć miesięcy - w odstępach trzydziestodniowych (stosując sprawdziany w sytuacjach otwartych). Podczas sprawdzianu spędzały one swój czas na matce i nie eksplorowały innych obiektów, z tym wyjątkiem, że niekiedy przynosiły matce kawałek papieru.  Gdy matka ta była nieobecna, wówczas najpierw zachowywały się tak, jak podczas sprawdzianów przeprowadzanych w początkowym okresie, lecz stopniowo przezwyciężały strach i przystosowywały się do otwartej sytuacji. Gdy matkę nakryto przezroczystym pudłem z plastiku, to początkowo były zaniepokojone (znacznie mniej niż wtedy, gdy była nieobecna), ale nadal używały jej jako „bazy”. Przez cały ten okres nie było żadnych oznak zmniejszania się afektu, jakim małpki te darzyły swe matki z włochatej tkaniny.
Czterem małpkom z grupy kontrolnej wstawiono do klatek matkę z włochatej tkaniny i matkę drucianą po raz pierwszy wtedy, gdy miały 250 dni (od chwili odłączenia od piersi). Wszystkie piszczały i próbowały uciec.  Jednakże w ciągu 48 godzin zaczęły je badać, a po 10 dniach spędzały około 9 godzin dziennie na matce z tkaniny, przybiegając nawet do niej, gdy były przestraszone. Przyzwyczaiły się używać jej jako „bazy” podczas sprawdzianów w sytuacjach otwartych, lecz nigdy nie uciekały do niej tak pospiesznie, jak te, które miały ją od początku. Z matką drucianą spędzały one mniej niż pół godziny dziennie” (Harlow i Zimmerman, 1958).


Ogólnie biorąc, zachowania tych małpek w stosunku do matek z włochatej tkaniny były prawie identyczne z zachowaniami innych małpek wobec swych prawdziwych matek. Wydawało się, że u tych małpek wytworzyły się prawdziwe więzi emocjonalne i efektywne z matkami z tkaniny, które to więzi przetrwały przez długi czas, nawet gdy matkę z tkaniny usunięto. Z wyników tych wyprowadzono początkowo wniosek, ze istotnym elementem opieki matczynej jest po prostu przyjemność dotykania, której pozornie może dostarczyć każdy stary ręcznik z włochatej tkaniny. Gdy jednak te małpki dorosły, wówczas rozwinęły się u nich dziwne formy zachowania - powinniśmy więc być ostrożni i nie spieszyć się z przyłączeniem do ruchu głoszącego hasło: „Precz z Dniem Matki”.




* * *



Ryc. 8.13. Doniosłe Znaczenie „Przyjemności Dotykania”. Małe małpki usadawiały się blisko „włochatej matki” i spędzały mniej czasu w pobliżu „matki drucianej”, bez względu na to, która z nich dawała mleko.


* * *





Jednak nie można oszukać Matki Natury. Co zdarzyło się w następnym pokoleniu, gdy przyszedł czas, aby te wychowane bez matki małpki same stały się matkami? Stwierdzono, że wykazywane przez nie zachowanie heteroseksualne było całkowicie nieadekwatne. Pomimo usilnych starań, mających skłonić je do „małpich figli” (między innymi umieszczono tę kolonię na niezamieszkałej wysepce w ZOO i wprowadzono tam kompetentne seksualnie, wychowane na swobodzie małpy), nie dochodziło do związków seksualnych.




* * *



Ryc. 8.14. Małpy, które po urodzeniu oddzielono od matek i którym nie pozwalano obserwować zachowania innych osobników ich gatunku, albo odrzucały później swe własne dzieci, albo ignorowały je. Ta mała małpka była stale odpychana przez swą matkę, gdy próbowała przytulić się do niej.  Niekiedy matka, chcąc utrzymać swoje dziecko z dala od siebie, przyciskała mu twarz do drucianej podłogi ( u góry). Małe małpki, których próby uzyskania kontaktu z matką były ciągle udaremniane, często wspinały się na jej grzbiet (u dołu) i stopniowo wędrowały wokół niej, przesuwając się ku przodowi jej ciała.


* * *





Po wielu miesiącach jedynie 4 (z 18) urodzone w laboratorium samice zostały zapłodnione i urodziły małe.


„Pierwsza z tych matek, które same były wychowywane bez matki, po urodzeniu swego maleństwa ignorowała je i siedziała niemal bez ruchu w jednym kącie swej klatki mieszkalnej, wpatrując się godzinami w przestrzeń.  Jeśli człowiek obserwujący ją zbliżył się i zagroził małemu, albo jej samej, to nie podejmowała ona żadnego przeciwdziałania (...). Gdy małe rosło i stawało się ruchliwe, wówczas czyniło desperackie wysiłki, aby nawiązać kontakt z matką. Próby te spotykały się zawsze z odprawą ze strony matki. Odpychała ona swe małe od siebie lub pozbawiała je swobody ruchów przyciskają mu twarz do podłogi wyplecionej z drutu” (Harlow, 1965, ss.  256-257). 


Oprócz tych kilku deprywowanych społecznie samic, które urodziły po zapłodnieniu przez wytrwałych i cierpliwych samców, inne małpy wychowane bez matki zostały zapłodnione sztucznie. U tych dwudziestu w sumie matek zaobserwowano trzy wzorce funkcjonowania macierzyńskiego. Osiem matek brutalnie traktowało swe małe: odgryzały im palce, biły je i zabiłyby je pewnie, gdyby nie interwencja ze strony opiekunów. Siedem spośród tych samic było po prostu obojętnych wobec swych maleństw - ignorowały je, nie reagowały na ich potrzeby, nie opiekowały się nimi. Wreszcie pozostałych pięć określono jako „znajdujące się na pograniczu adekwatności pod względem zachowania macierzyńskiego”. Trzy z nich miały pewne minimalne kontakty społeczne z innymi małpami w czasie swego własnego dzieciństwa (Arling, 1966).
Pomimo nieustannych kar, jakie otrzymywały małe małpki za zbliżanie się do matki, nie ustawały one w swej walce o nawiązanie z nią kontaktu. W końcu „zdarzył się przypadek, że dziecko zaadoptowało matkę, a nie matka zaadoptowała dziecko” (Harlow, 1965, s. 259; ryc. 8.14). Na szczęście okazało się, że w następnych ciążach macierzyńskie zachowanie tych matek uległo poprawie.
W następnych badaniach Harlowowie stwierdzili, że małpki, które miały jedynie matki z włochatej tkaniny, wskazywały adekwatne, choć znacznie spóźnione przystosowanie heteroseksualne, jeśli dano im wiele okazji do interakcji z innymi małymi małpkami w okresie, gdy się rozwijały. Jednakże Harlowowie doszli do wniosku, że:


„(Z badań tych) wynika, że opieka matczyna jest ważna nie tylko jako źródło społecznego poczucia bezpieczeństwa, lecz także jako bardzo ważny czynnik w społecznym treningu małych; jesteśmy szczęśliwi mogąc stwierdzić, iż obecnie przekonaliśmy się, że prawdziwa opieka matczyna, u małp czy u ludzi, jest bardzo ważnym czynnikiem społecznym i że z tej opieki nie wolno rezygnować!” (Harlow i Harlow, 1966).




Seksualność człowieka 




„Drogi doktorze Reuben: czy nie sądzi Pan, że obecnie poświęca się stanowczo zbyt wiele uwagi seksowi? Studiuję wychowanie fizyczne i myślę, że byłoby znacznie lepiej, gdyby ludzie poświęcali się dobrym, czystym sprawom takim, jak sport i ćwiczenia fizyczne, zamiast trawić tyle czasu i energii na coś takiego, jak seks. Czy zgadza się Pan ze mną?” (Reuben, 1973).


A czy |ty zgadzasz się? Czy też nie?
Z powyższego listu wynika, że myśli o sprawach seksualnych (a co gorsze, czynności seksualne) są przeciwieństwem „dobrych, czystych spraw”. Taka postawa, zgodnie z którą seks degraduje czystość postępowania człowieka i szlachetność ducha ludzkiego, jest obecnie nieco mniej rozpowszechniona, niż była za czasów waszych rodziców i dziadków. Nie tak dawno temu podręczniki małżeńskie określały zachowanie seksualne jako „niebezpieczne zło, które niestety jest niezbędne dla przedłużenia rodu ludzkiego”.  Twierdzenie, że seks jest czymś grzesznym czy brudnym, było punktem wyjścia (a zatem i punktem dojścia) w dyskusjach o seksie u ludzi.
Ponieważ dawniej omawianie zachowania seksualnego stanowiło tabu dla mężczyzn i było nie do pomyślenia w wypadku osób należących do płci pięknej, przeto podręczniki małżeńskie wzięły na siebie ciężar edukacji seksualnej szerokich rzecz czytelników. Na ogół podręczniki te, chociaż pisane przez ludzi mających stopień doktora medycyny, miały na celu wpojenie trachu, poczucia winy, wstydu oraz potrzeby nieustannej czujności rodziców usiłujących stłumić w zarodku „ten występny nawyk!”


Trudno jest nam wyobrazić sobie psychologiczny wpływ takiej indoktrynacji na umysły niewypowiedzianej rzeczy rodziców, chyba że uświadomimy sobie, że bez tej ery represji wszelkich spraw seksualnych nie musielibyśmy być „wyzwalani” teraz, w latach siedemdziesiątych.




Zbliżenie


Opowieść o tym, jak było kiedyś


„Z pouczającego, pseudolekarskiego poradnika kieszonkowego, opublikowanego w 1902 roku (dr med. J. H. Kellogg „The Ladies Guide in Health and Disease” - Poradnik dla Pań w Zdrowiu i w Chorobie), który jest pełen pożytecznych wskazówek dla rodziców (dotyczących spraw płci i sposobów zapobiegania wybuchowi popędu seksualnego u ich dzieci), przytaczamy bez komentarza fragmenty rozdziału omawiającego jeden z najgorszych ludzkich nałogów: „samogwałt” (masturbację).
„|Złe |nawyki. - Wiele matek zupełnie nie zdaje sobie sprawy z ogromnego rozpowszechnienia wśród młodzieży sekretnego narowu, czyli samogwałtu. Jest on niezmiernie pospolity, zarówno wśród chłopców, jak i wśród dziewcząt.  Natura tego narowu jest taka, że może on być przyswojony i uprawiany przez miesiące i lata, a może i przez większą część życia, a osoby niewprawne w jego wykrywaniu nie podejrzewają nawet jego istnienia. Zetknęliśmy się z mnóstwem takich przypadków, w których niemożliwością było przekonać czułą matkę, że jej córka może być winna takiego występku, chociaż jego oznaki były zbyt oczywiste, by istniała możliwość pomyłki. Staranne studia nad tym nadmiernie rozpowszechnionym narowem i szeroka sposobność obserwacji przekonały nas, że jest on jedną z najważniejszych przyczyn wielkiego wzrostu liczby chorób nerwowych i chorób związanych z płcią, jaki zaznaczył się wśród kobiet w ostatnim półwieczu. Pewien autor obdarzony ostrym piórem, który poświęcił się prawie wyłącznie leczeniu chorób kobiecych, zadaje trafiające w sedno pytanie: „Dlaczego mielibyśmy zawahać się przed stwierdzeniem zdecydowanie i bez ogródek, że samogwałt stanowi w znacznej mierze podłoże słabości, bezbarwności, nerwowości i bylejakości całego społeczeństwa?””.
Matki umieszczają swe córki w szkołach z internatami, cieszących się dobrą reputacją - jako szkołach godnych szacunku, o wysokim poziomie nauczania - i wyobrażają sobie, że córki są tam bezpieczne; tymczasem dostają się one tam w takie towarzystwo, że jeśli unikną splamienia tym wstrętnym narowem, to można to uważać za cud (...).
(...) Ofiara tego złego nawyku prędzej czy później z pewnością poniesie karę, jaką natura nieodmiennie wymierza tym, którzy przekraczają jej prawa. 
Posłuszeństwo każdemu prawu natury wymusza nieuchronna kara; w szczególnej 
mierze dotyczy to tych spraw, które odnoszą się do narządów płciowych 
(...).

(...) nerwowość, histeria, newralgia i ogólna bezwartościowość dziewcząt z wstępującego w życie pokolenia w dużej mierze wynika z tej właśnie przyczyny. Blade policzki, podkrążone oczy, twarze pozbawione wyrazu i znużony wygląd wielu uczennic - które to objawy często przypisuje się przemęczeniu nauką - są spowodowane tą jedną przyczyną (...).
(...) wszystkie dziewczęta będą zaprzeczały bardzo gorąco, gdy zapytać je, czy oddają się temu nałogowi, nawet jeśli mówią prawdę na każdy inny temat (...). Dlatego też w większości przypadków uzyskanie takich dowodów nałogu, które uniemożliwiłyby popełnienie omyłki, wymaga największej czujności i ostrożności. Jedynym decydującym dowodem jest oczywiście przyłapanie dziecka na tej czynności.
(...) nawyk samogwałtu, jeśli został mocno utrwalony, nie jest bynajmniej łatwy do przełamania. Ofiara tego najstraszniejszego nałogu utrzymywana jest w najbardziej godnej pogardy niewoli, a żelazne okowy nawyku z każdym dniem zaciskają się coraz mocniej (...).
(...) matka powinna najpierw starannie przedstawić dziecku niezmierną 
grzeszność tego nawyku, jego ohydę i nikczemność, oraz straszliwe 
konsekwencje, jakie idą jego śladami (...). Gdy dziecko obudzi się rano, 
wówczas natychmiast powinno się zabrać je z łóżka i ubrać - od tego momentu 
powinno być ciągle zajęte, aż do czasu udania się wieczorem na spoczynek 
(...).

(...) poprawa nie jest jednak niemożliwa dla tego, kto naprawdę pragnie się poprawić; lecz praca nad poprawą musi zacząć się od umysłu. Nieczyste myśli i wyobrażenia, dotychczas pielęgnowane, muszą zostać wygnane. Umysł trzeba oczyścić z każdej skazy zła. Jest to zadanie, które wymaga niemałej cierpliwości, a w wielu przypadkach wprost nadludzkiej siły” (1902, ss.  144-165).


Dobrze jest porównać skutki tej represji seksualnej w minionych latach ze skutkami deprywacji pokarmowej w badaniach nad niedożywieniem, które opisaliśmy w niniejszym rozdziale. W pewnym sensie dane dotyczące nieustannego zaabsorbowania pokarmem, jakie wystąpiło wskutek jego braku, pozwalają sformułować wniosek, że „deprywacja może uczynić z rzeczy zwykłej potężny czynnik wzmacniający”. Seks stał się jednym z najpotężniejszych zgeneralizowanych czynników wzmacniających właśnie dlatego, że został „wyrzucony poza nawias”. To, co powinno być najbardziej naturalną, normalną czynnością, przyjemną zarówno wtedy, gdy trwa, jak i w swych następstwach, zostało w jednej skrajności przekształcone w źródło wszelkich ludzkich chorób oraz degradacji ciała i ducha, a w drugiej skrajności, wyolbrzymione w magiczne, mistyczne, kosmiczne zjednoczenie z Nirwaną.
Ten aspekt seksualnego tabu, który można by nazwać „nie oglądaj niczego złego, nie słuchaj niczego złego, nie mów niczego złego” widoczny jest także w podręcznikach psychologicznych, podobnie jak w okrężnych wzmiankach o sprawach „genitalnych” w licealnych podręcznikach higieny. Niewiele podręczników psychologicznych, aż do ostatnich lat, omawiało szerzej zachowanie seksualne; gdy to czyniły, chodziło o zachowanie seksualne zwierząt, a nawet wówczas rozważania te dotyczyły głównie aspektów fizjologicznych oraz anomalii wynikajacych z kastracji, deprywacji i innych nieszczęść.


Istnieją dwa główne powody takiego pomijania ważnego aspektu zachowania ludzkiego we wstępnych podręcznikach psychologii. Po pierwsze, przeprowadzono zadziwiająco małą liczbę badań psychologicznych nad zachowaniem seksualnym ludzi i wobec tego nie wiele jest pewnego materiału dowodowego, na którym można by oprzeć wnioski. Drugi powód po części wiąże się z tym, dla którego nie przeprowadzono większej liczby badań nad tym doniosłym tematem - nadal uważa się ten temat za zbyt „drażliwy”, aby pisać o nim w sposób otwarty. Jest to sytuacja niepomyślna, ponieważ trzeba jeszcze wiele dowiedzieć się o ludzkiej seksualności, wiele mitów rozproszyć, a tę wiedzę, jaką dysponujemy, udostępnić studentom interesującym się tym ogromnym, a nie omawianym tematem.
W tych nielicznych uczelniach, w których prowadzi się kurs z zakresu seksualności człowieka, jest to nie tylko kurs bardzo popularny - na nim bowiem dojrzali młodzi mężczyźni i dojrzałe młode kobiety, często w wieku dwudziestu lub więcej lat, dowiadują się tych rzeczy o seksie i o sobie samych, których powinni się dowiedzieć i przedyskutować je już przed kilkoma laty. Mimo tego, że niedawno opublikowano parę doskonałych podręczników z tego zakresu (zob. zwłaszcza Katchadourian i Lunde, 1972), to jednak te kursy i podręczniki reprezentują przede wszystkim kierunek biologiczny. W podręcznikach tych nie przeprowadzono ważnego rozróżnienia procesów seksualnych. Reprodukcja ma charakter biologiczny - seksualność ludzi jest zasadniczo procesem psychicznym, który może mieć konsekwencje biologiczne lub może ich nie mieć. Ludzie angażują się w czynności seksualne głównie z przyczyn natury psychologicznej, i to, czy doświadczenie to jest „pozytywne”, czy „negatywne”, zależy prawie wyłącznie od ich psychicznego ustosunkowania się do spraw seksu. Dla wielu osób najważniejszym elementem nie jest to, co dzieje się |podczas stosunku seksualnego, lecz postawy, motywy, oczekiwania, lęki i wartości kulturowe, które uprzednio im wpojono i które taszczą ze sobą, jak wielką niewygodną walizkę bez rączki.
Aby seksualność człowieka była traktowana jako przedmiot godzien badania psychologicznego, musi być „usankcjonowana” jako temat istotny z naukowego punktu widzenia. Po części dzieje się to wówczas, gdy skądinąd szanowani wykładowcy i autorzy podręczników po prostu oświadczają, że stanowi ona taki temat i włączają ją do swych wykładów i podręczników. Wymaga to również, aby badacze studiowali złożoną naturę seksualności ludzkiej.  Niełatwo jest tego dokonać.
Jeszcze przed kilkudziesięciu laty badania nad zachowaniem seksualnym u ludzi ograniczały się głównie do klinicznych i anegdotycznych opisów anomalii seksualnych, jak w klasycznym dziele Kraffta-Ebinga (1932) poświęconym zboczeniom. Impulsem do badań nad normalnym zachowaniem seksualnym ludzi były prace Kinseya i jego współpracowników (1948, 1953), aczkolwiek zebrane dane ograniczały się do sprawozdań z wywiadów o wątpliwej wartości. Dopiero Masters i Johnson (1966, 1970) przełamali tradycyjne tabu, obserwując bezpośrednio i rejestrując fizjologiczne i behawioralne wzorce ludzkich stosunków seksualnych, jak również przejawy nieadekwatności seksualnej.
Oczekuje się, że w następnym dziesięcioleciu nastąpi wielostronny przyrost naukowej wiedzy o naturze popędu seksualnego u ludzi. Interesujące będzie obserwowanie, czy zmiany w obyczajach społecznych i prawnych definicjach określających, co stanowi „akceptowalne” zachowanie seksualne, zmienią także ten wszechobecny wpływ motywacji seksualnej na nasze zachowanie. Obecnie seks nie tylko sam jest obiektem sprzedaży (w postaci prostytucji i pornografii), lecz także pomaga sprzedawać niemal wszystko, co można z nim skojarzyć, od widowisk rozrywkowych do samochodów, papierosów, a nawet pokarmów.




Zbliżenie


Trochę seksu uczyni z książki bestseller


„W pierwszym ćwierćwieczu bieżącego stulecia wydawca E. Haldeman-Julius sprzedał miliony egzemplarzy swych „Niebieskich książeczek” („Little Blue Books”). Jedną ze stosowanych przez niego technik zdobywania rynku było zmienianie tytułów książek, których sprzedano zbyt mało (Haldeman-Julius, 1928). Oto cztery książki, których sprzedawano tylko po kilka tysięcy egzemplarzy rocznie, gdy nosiły swe pierwotne tytuły:


Złote runo: 6000 egz.
Król się bawi: 8000 egz.
Nikt poza królem: 6000 egz.
Casanova i jego miłość: 8000 egz.


Dodajmy jednak trochę seksu, a zobaczymy, jak sprzedaż wzrośnie!


W poszukiwaniu jasnowłosej metresy: 50000 egz.
Lubieżny król bawi się: 38000 egz.
Nikt poza królem nie będzie cieszyć się wdziękami tej kobiety: 34000 egz.
Casanova: historia największego kochanka: 22000 egz.


Jak widać, liczba sprzedawanych rocznie tych samych książek - po zmianie tytułów - zmieniła się zdecydowanie.


Czy seks nadal pomaga sprzedawać książki? Wydawcy tanich książeczek kieszonkowych najwyraźniej są o tym przekonani. Wystarczy spojrzeć na ilustracje zdobiące okładki tych wydawnictw”.


Czy ludzie staną się bardziej hedonistyczni, żądni użycia i zdominowani przez namiętności seksualne, czy też mniej zaabsorbowani powabami płci i mniej od nich uzależnieni - bardziej zdolni do traktowania seksu jako po prostu naturalnej części życia - gdy „rewolucja seksualna” lat siedemdziesiątych przybierze na sile? Jakie twoim zdaniem będą na dalszą metę następstwa bardziej liberalnych praw dotyczących przerywania ciąży, pornografii i zboczeń seksualnych, edukacji seksualnej w szkołach, par kojarzonych przez komputer, małżeństw grupowych, publicznej nagości, środków zapobiegania ciąży i koedukacyjnych domów akademickich?
Podajemy jako ciekawostkę, że w „The International Thesaurus of Quotations (Międzynarodowym Skarbcu Cytatów), gdzie można by znaleźć cytat nadający się na zakończenie niniejszego wprowadzenia do naszych rozważań nad seksualnością ludzi, temat SEX (hasło 885) znajduje się pomiędzy SEVERS (ścieki - hasło 884) i SHAME (wstyd - hasło 886).




Skąd wiesz, czy jesteś
mężczyzną czy kobietą




To, jakiej jesteś płci, może być dla ciebie równie oczywiste jak to, co oznacza zachowanie seksualne. Jednakże twoja pewność zależy od pewnej liczby zmiennych związanych z płcią, co do których zakładasz, że są one zgodne. Są to: a) płeć genetyczna, zdeterminowana przez układ chromosomów XX lub XY, b) płeć hormonalna, zdeterminowana przez dominację androgenów lub estrogenów, c) płeć gonadalna, określona obecnością jąder lub jajników, d) płeć reprodukcyjna, wyznaczona przez wewnętrzne narządy rozrodcze, e) płeć fizyczna (morfologiczna), wyznaczona przez zewnętrzne narządy rodne, f) płeć przypisana, określona przez rodziców i lekarzy, oraz g) płeć psychiczna, czyli rola związana z płcią, wyznaczona przez wyuczone identyfikowanie się z płcią męską lub żeńską.
Wszystkie te wyznaczniki płci są zwykle ze sobą zgodne. Niekiedy jednak eksperymenty przeprowadzone przez naturę mieszają te zmienne w takie kombinacje, które są niespójne, tworząc w ten sposób |hermafrodytę (Powyższa definicja, zgodnie z poglądem częściej spotykanym w literaturze, odnosi się do hermafrodytyzmu rzekomego; hermafrodyzm prawdziwy występuje wtedy, gdy jednostka posiada jednocześnie męskie i żeńskie gonady - jądra i jajniki (przyp. red.)).: „jednostkę, u której istnieje sprzeczność pomiędzy dominującym wyglądem genitaliów zewnętrznych z jednej strony, a układem chromosomów płciowych, gonadami, hormonami czy wewnętrznymi strukturami rozrodczymi, czy to pojedynczo czy łącznie - z drugiej” (Hampson, 1965, s.  110).
Istnienie hermafrodytyzmu wskazuje, że |zróżnicowanie płciowe nie jest całkowite w momencie urodzenia się ani nawet nieco później.
Jeśli chodzi o wytworzenie takiego zróżnicowania, to istnieje tu pewien okres krytyczny. Wydaje się, że czas w, którym dziecko uczy się swego ojczystego języka, może być najpóźniejszym okresem, gdy zmiana przyporządkowania hermafrodytycznego dziecka do jednej z płci jest możliwa bez złego przystosowania psychicznego. Materiał dowodowy uzyskany w przypadkach, w których początkowe przyporządkowanie dzieci do pewnej płci zostało później zmienione przez ich rodziców, wskazuje, że im później zmiany te zostały dokonane, tym większe prawdopodobieństwo zaburzeń w funkcjonowaniu seksualnym i osobowościowym (Hampson, 1965).
Proces różnicowania seksualnego u ssaków, zachodzący w trakcie rozwoju płodowego, można zakłócić przez podanie hormonów lub usunięcie gruczołów płciowych (kastrację). Za pomocą tych technik produkowano eksperymentalnie zarówno „maskulinizowane samice”, jak i „feminizowane samce” wielu gatunków zwierząt. Najbliższą analogię u ludzi stanowi zespół znany pod nazwą |hermafrodytyzmu |wywołanego |przez |progestin („progestin-induced hermaphroditism”). Ten stan prenatalnej maskulinizacji był do połowy bieżącego stulecia wywoływany przypadkowo u nielicznych dzieci (które pod względem genetycznym były płci żeńskiej) zastrzykami hormonalnymi podawanymi ich matkom w celu zapobieżenia poronieniu. Niemowlęta te rodziły się z nieco maskulinizowanymi genitaliami żeńskimi, przy czym anomalie te były korygowane we wczesnym dzieciństwie. Chociaż badacze w latach sześćdziesiątych utrzymywali, że późniejsze zachowanie tych dzieci w okresie dzieciństwa było bardziej męskie (Money i Ehrhard, 1972), o czym świadczyły ich upodobania do zabawek, ilość wydatkowanej energii oraz „łobuzerstwo” („tomboyism”), to jednak uzyskane przez nich wyniki mogłyby z łatwością stanowić opis zachowania dzisiejszych normalnych, „wyzwolonych” małych dziewczynek.
To, w jakim stopniu „chłopcy będą chłopcami”, a „dziewczynki będą damami” zależy w znacznej mierze od stosowanych wobec nich we wczesnym okresie życia metod wychowawczych, które sprzyjają właściwej identyfikacji z rolą związaną z płcią lub powodują jej wypaczenie. Wszelkie różnice między biernymi, opiekuńczymi, uległymi dziewczętami i agresywnymi, energicznymi, dominującymi chłopcami służyły naturalnym funkcjom w przeszłości, lecz obecnie ich znaczenie zaczyna się kwestionować.




Pobudzenie seksualne
u mężczyzn i kobiet




Przez tysiące dosłownie lat, zarówno w społeczeństwach prymitywnych, jak i wysoko rozwiniętych cywilizacjach, w stosunkach między mężczyznami i kobietami obowiązywały podwójne normy seksualne - odmienne dla każdej z płci. Historia zarejestrowała najrozmaitsze niezwykłe środki i sposoby, jakie stosowali mężczyźni, aby kierować seksualnymi postawami, poglądami i zachowaniem kobiet. Jednakże nieustanne dążenie kobiet do równości seksualnej zachwiało archaicznymi podwójnymi normami i usunęło ze świadomości tysiące psychicznych pasów cnoty.


„Siła i jakość seksualizmu mężczyzny sięgają najwyższych szczytów jego ducha”.
Freidrich Wilhelm Nietzsche „Jenseitz von Gut und Bose”, 1886
(wyd. pol. „Poza dobrem i złem”).


„Jeśli kobieta nie ma w sobie maleńkiej domieszki nierządnicy, to z reguły jest sucha jak tyczka”.
D. H. Lawrence „Pornography and Obscenity”, 1930



Oczywistym bodźcem zewnętrznym, który wywołuje pobudzenie seksualne jest stymulacja dotykowa erogenicznych stref ciała. Inne bodźce tego rodzaju to bodźce wzrokowe i słowne oraz obrazy erotyczne, jak również indywidualne fantazje. Często słyszy się uogólnienie, że bodźce wzrokowe (nagie lub częściowo nagie ciała) łatwo pobudzają mężczyzn, natomiast nie działają w ten sam sposób na kobiety. Czy słyszałeś takie stwierdzenie? Czy sądzisz, ze jest ono prawdziwe? Jeśli nie, to jak sądzisz, dlaczego taki mit mógł się utrzymać? 
Problem, czy obrazowe przedstawienia nagości lub czynności erotycznych są równie podniecające dla mężczyzn, jak i dla kobiet, do niedawna nie był badany eksperymentalnie. Większość generalizacji dotyczących tej sprawy było opartych jedynie na intuicji i nie kontrolowanych obserwacjach, zaprawionych mocnymi, wartościującymi przekonaniami. Impulsu do badań w tej dziedzinie, która dotąd była tabu, dostarczyły przede wszystkim zagadnienia prawne i konstytucyjne, dotyczące cenzorowania sprośnych pism i pornograficznych materiałów oraz kontrola nad tymi potencjalnymi bodźcami zachowania antyspołecznego. Wzrost wskaźnika przestępstw w ogóle, a przestępstw seksualnych w szczególności, który zbiegł się w czasie ze zwiększoną dostępnością filmów i magazynów pornograficznych, skłonił wielu ludzi do upatrywania związku przyczynowego w tej korelacji czasowej.  Współczesne badania, mające na celu określenie następstw stykania się z materiałami pornograficznymi, dostarczyły nam również danych dotyczących zagadnienia, czy bodźce takie mogą działać pobudzająco seksualnie nie tylko na mężczyzn, ale i na kobiety.
Pierwsze badania, mające na celu określenie, jak kontrolowane eksponowanie bodźców erotycznych osobom badanym wpłynie na ich zachowanie poza laboratorium, przeprowadzono w RFN na Uniwersytecie w Hamburgu (Sigusch, Schmidt, Reinfeld i Wiedemann-Sutor, 1971). W jednym z tych badań, które objęło 99 studentów wyższej uczelni (płci męskiej), wykazano, że po obejrzeniu przezroczy i filmów erotycznych częstość masturbacji wzrosła u około czwartej części osób badanych (porównywano podawaną częstość masturbacji w dwóch 24-godzinnych okresach - poprzedzającym prezentację tych bodźców i następującym po niej). Gdy inna grupa, złożona ze 128 studentów i takiej samej liczby studentek wyższych uczelni oglądała filmy erotyczne, wówczas osoby obu płci podały, że następnego dnia znacznie wzrosła ich aktywność masturbacyjna. U kobiet wystąpił też niewielki, lecz statystycznie istotny, wzrost częstości pieszczot prowadzących do orgazmu („petting”) oraz stosunków seksualnych („coitus”). W innych badaniach prowadzonych przez tych samych autorów 72% badanych studentek wyższej uczelni podawało, że oglądanie filmów erotycznych wywołuje u nich pobudzenie fizjologiczne. W Danii i Stanach Zjednoczonych badaniami objęto pary małżeńskie, aby ustalić, czy bodźce pornograficzne potęgują zarówno reakcje autoerotyczne, jak i heteroseksualne.


„Pary małżeńskie mieszkające w domu akademickim dla małżeństw studenckich Uniwersytetu Kopenhaskiego zgłaszały się ochotniczo do badań nad wpływem bodźców erotycznych na ich postawy, procesy percepcyjne i zachowanie (Kutschinsky, 1971). Więcej niż połowa badanych nigdy nie oglądała filmu pornograficznego, lecz wielu wyraziło zainteresowanie takimi filmami. W ciągu jednogodzinnego posiedzenia grupowego, 70 osobom badanym pokazano dwa 15-minutowe, drastyczne filmy pornograficzne, przez 15 minut czytali oni magazyny pornograficzne i przez 15 minut słuchali tekstu o treści pornograficznej. Reakcje ich mierzono za pomocą szeregu kwestionariuszy, które wypełniali przed posiedzeniem, bezpośrednio po nim oraz po upływie 4 i 10 dni.
Ogólnie biorąc, całe to posiedzenie nie wywołało silnych reakcji afektywnych poza rozczarowaniem i znudzeniem. Kontakt z pornografią nie zmienił postaw wobec przestępstw seksualnych. Większość badanych obu płci podała, że bodźce te nie były podniecające seksualnie; miały one jedynie słaby wpływ na wzrost częstości masturbacji (wzrost netto w okresie „przed”-„po” wyniósł 11%); 29% badanych podało, że częstość stosunków seksualnych wzrosła, 70% - że pozostała bez zmiany, a 1% - że zmalała; ponadto nastąpiło ogólne zmniejszenie zainteresowania dewiacyjnego praktykami seksualnymi”.


Porównując reakcje u badanych obu płci stwierdzono, że mężczyźni mieli początkowo większe oczekiwania i później byli bardziej rozczarowani niż kobiety. Pod koniec posiedzenia mniej więcej czwarta część osób badanych każdej płci podała, że odczuwają „pobudzenie seksualne” i „pożądanie”.  Autor konkluduje, że „w trakcie posiedzenia wystąpiła tendencja do „rozgrzewania się”” kobiet (chociaż większość ich pozostała nieporuszona), podczas gdy mężczyźni raczej „stygli””(s. 145).
W tabeli podano, jaki procent osób badanych obu płci ocenił różne bodźce pornograficzne jako „podniecające”.


Ocena Podniecających Właściwości Materiałów Pornograficznych Dokonana Przez Mężczyzn I Kobiety. Wbrew tym i podobnym danym badacz doszedł do wniosku, że „jest faktem, iż ogólnie biorąc pornografia prezentowana w tym eksperymencie podobała się kobietom nieco mniej niż mężczyznom; podawały one, że odczuwają mniejsze podniecenie seksualne”(s. 147). Tak więc stare mity utrzymują się, mimo zaprzeczających im materiałów dowodowych!


Kolejność i typ: a) Mężczyźni (N=43); b) Kobiety (N=29); c) Różnica
1.	Film I (2 dziewczyny, 1 chłopiec): a) 42%; b) 35%; c) -7%
2.	Magazyn ilustrowany: a) 19%; b) 14%; c) -5%
3.	Tekst: a) 7%; b) 28%; c) +21%
4.	Film II (pary heteroseksualne i lesbijskie): a) 37%; b) 48%; c) +11%

(Adaptowane z Kutschinsky’ego, 1971)


Jedno z najbardziej wszechstronnych badań nad wpływem bodźców erotycznych na zachowanie seksualne przeprowadził zespół badaczy z Kalifornii (Mann, Sidman i Starr, 1971). Badali oni przez długi czas szczegółowe reakcje 85 par małżeńskich na szereg filmów erotycznych i nieerotycznych.


„Osoby badane, które były ochotnikami zwerbowanymi za pośrednictwem ogłoszeń w gazetach, reprezentowały „porządne” społeczeństwo: pochodziły z klasy średniej, pozostawały ze sobą w związku małżeńskim przynajmniej od 10 lat, większość żon była „gospodyniami domowymi”, mężowie reprezentowali przeważnie niższe szczeble wolnych zawodów lub zawody urzędnicze. Większość była zadowolona ze swego małżeństwa i z życia seksualnego, nie tolerowali wymiany partnerów czy seksu grupowego. Ich wiek wahał się w granicach od 30 do 64 lat, przy czym przeciętna wynosiła około 45.
Każda osoba badana wypełniała codziennie sprawozdania dotyczące różnych wskaźników, przez ogółem 84 dni (przed eksponowaniem filmów erotycznych, w trakcie ich eksponowania i po ich eksponowaniu). Ogólnie biorąc, wyniki „wykazały, że oglądanie filmów erotycznych, w porównaniu z oglądaniem filmów nieerotycznych lub nie oglądania żadnych filmów, nie spowodowało żadnych istotnych, specyficznych zmian w postawach osób badanych ...”(s.  171). Nie miały one żadnego trwałego wpływu na zachowanie seksualne osób badanych, chociaż były one bardziej aktywne seksualnie w domu w te wieczory, kiedy oglądały filmy erotyczne.
Biorąc pod uwagę większość wskaźników, mężczyźni i kobiety podobnie reagowali na filmy erotyczne; poważniejsze różnice wystąpiły w ocenach poszczególnych scen, przedstawiających różne praktyki seksualne w tych filmach. Co się tyczy reakcji fizjologicznych występujących podczas oglądania tych filmów, to okazało się, że pobudzenie pojawiające się pod wpływem tego filmu, który przez daną osobę został oceniony najprzychylniej, było silniejsze u kobiet niż u mężczyzn w wypadku 7 (z 8) zmiennych fizjologicznych”.


Na podstawowe pytanie - czy kobiety mogą być pobudzone przez obrazowe przedstawienie nagości lub aktywności erotycznej - dane z powyższych badań dostarczyły twierdzącej odpowiedzi: blisko 60% kobiet podawało, iż wystąpiły u nich doznania genitalne podczas oglądania filmu przedstawiającego grupową aktywność seksualną.
Chociaż te badania dostarczają wielu informacji, to jednak nasuwają wiele problemów metodologicznych (nie wspominając o moralnych czy etycznych). W badaniach kalifornijskich osoby badane podawały na przykład, że najbardziej podniecało je wypełnianie codziennych kwestionariuszy, które „uwrażliwiały” je na zagadnienia seksualne - bardziej niż oglądanie filmów erotycznych! To samo mogło dotyczyć kwestionariuszy w badaniach duńskich, w których proszono badanych, aby zapoznali się z zestawem 10 rysunków przedstawiających różne pozycje które chcieliby wypróbować. Nigdzie zasada nieoznaczoności Heisenberga nie działa wyraźniej, niż przy ocenianiu pobudzenia seksualnego: pomiar wpływa na mierzone zjawisko albo wzmacniając je, albo też hamując. Inny poważny problem metodologiczny dotyczy posługiwania się pośrednimi, subiektywnymi sprawozdaniami, podawanymi po ekspozycji bodźca, zamiast natychmiastowymi pomiarami fizjologicznych i behawioralnych reakcji na bodźce, przeprowadzanymi w trakcie ich odbierania. Reakcje seksualne także różnią się w zależności od warunków, w jakich dany materiał jest oglądany - są one inne w warunkach publicznych, „naukowych”, grupowych niż w warunkach prywatnych, nieformalnych.  Przeciętny człowiek są wiedzę o świecie czerpie przeważnie ze środków masowego przekazu, które informują go, „jak sprawy się mają”. Do jakich więc dojdzie on wniosków, jeśli chodzi o wpływ pornografii na przestępstwa seksualne? W roku 1969 Presidential Commission in Obscenity and Pornography (Prezydencka Komisja do spraw Sprośności i Pornografii) stwierdziła, że w zaleconych przez nią badaniach nie wykazano żadnego istotnego związku między tymi zjawiskami. Jednakże dziennikarz James Kilpatrick pouczał swych czytelników:


„Niektóre z tych „empirycznych badań”” były jawnie bzdurne.  Przyczynowości nie można zmierzyć menzurką ani przedstawić na wykresie. W tej wysoce subiektywnej dziedzinie zachowania ludzkiego prawdopodobnie nigdy nie będziemy wiedzieli dokładnie, co motywuję mężczyznę do gwałtu lub napaści seksualnej. Zdrowy rozsądek jest lepszym przewodnikiem od eksperymentów laboratoryjnych; a zdrowy rozsądek mówi nam, że pornografia musi przyczyniać się do wzrostu liczby przestępstw seksualnych” („San Francisco Chronicle”, 18#af875).




Wzorce pobudzenia
seksualnego i reakcji
seksualnych u ludzi




Aktywność seksualną można zaobserwować u niektórych niemowląt od chwili urodzenia się i może ona utrzymywać się do późnej starości. Jednakże wiek zbiera swoją daninę, ponieważ szczytowa intensywność popędu seksualnego u mężczyzn występuje pomiędzy okresem dojrzewania i wiekiem dwudziestu paru lat, a następnie stale się zmniejsza. W odniesieniu do kobiet ma zastosowanie mniej więcej ta sama ogólna zasada, lecz tu czynniki kulturowe komplikują sprawę.
Zmniejszanie się popędu seksualnego z wiekiem po części wiąże się raczej z pogorszeniem stanu zdrowia i większym zmęczeniem, niż z jakimś nieuniknionym „stygnięciem krwi”. Aczkolwiek w starszym wieku ilość androgenów zmniejsza się, to jednak badacze Kinseya opisują przypadki mężczyzn po pięćdziesiątce, którzy odbywali przeciętnie 14 stosunków tygodniowo: Mae West, mając lat ponad osiemdziesiąt, mogła nadal chełpić się pełnią seksapilu.


Złe odżywianie zmniejsza popęd seksualny (o czym wiemy z eksperymentów nad niedożywieniem), podobnie jak nadużywanie alkoholu czy środków farmakologicznych. Podobnie hamująco wpływa zaabsorbowanie problemami osobistymi, obawa przed konsekwencjami czy nadmierna dbałość o ocenę własnej sprawności seksualnej).


Różnice kulturowe w reakcjach seksualnych. Nigdy nie zdajemy sobie tak dobrze sprawy z tego, w jakim stopniu szeroki zakres doświadczeń kulturowych wywiera regulujący wpływ na nasz popęd seksualny i wzorce zachowania, jak wtedy gdy porównujemy siebie z ludźmi żyjącymi w innych kulturach. Przeprowadzona przez Margaret Mead (1938) porównawcza analiza zachowania dziewcząt samoańskich i amerykańskich wykazała, że zaburzenia fizjologiczne i napięcia psychiczne, które towarzyszą w Ameryce osiąganiu dojrzałości płciowej, muszą być wyuczone, ponieważ nie występują na Samoa.
Inny antropolog opisał wzorzec zachowania seksualnego, występujący u ludzi zamieszkujących wyspy Melanezji położone na południowo-zachodnim Pacyfiku, który jest niezgodny z wieloma naszymi podstawowymi pojęciami.


„Ponieważ przyjmuje się, iż popęd seksualny jest tak silny, że wymaga zaspokojenia i ponieważ przedmałżeńskie stosunki są zakazane, mężczyzn i kobiet zachęca się do masturbacji. Ponadto, w celu zaspokojenia tego popędu, wszyscy mężczyźni utrzymują stosunki homoseksualne - z pełnym przyzwoleniem społeczności. W późniejszym okresie nie występują jednak żadne oznaki zboczenia seksualnego polegającego na tym, że mężczyźni wybieraliby innych mężczyzn jako obiekty seksualne. Czystości przedmałżeńskiej przestrzega się tak ściśle, że niezamężne kobiety i nieżonaci mężczyźni są trzymani oddzielnie i nie pozwala im się nawet rozmawiać ze sobą czy patrzeć na siebie, jeśli się przypadkowo spotkają.  Powoduje to znaczną wstydliwość, skrępowanie i zakłopotanie w czasie „bolesnego okresu przystosowania” na początku życia małżeńskiego” (Davenport, 1965).


Różnice indywidualne: heteroseksualizm a homoseksualizm. W naszym kraju heteroseksualizm jest uznawany jako „właściwy” i „społecznie akceptowany” rodzaj aktywności seksualnej. Jest on oczywiście niezbędny dla reprodukcji (aczkolwiek niektóre ugrupowania lesbijskie rozważają możliwość sztucznego zapłodnienia dla osiągnięcia celu reprodukcji bez stosunku heteroseksualnego). Wiele naszych społecznych zwyczajów i instytucji opiera się na założeniu, że heteroseksualizm jest prawidłowym i właściwym sposobem utrzymywania związków seksualnych. Odmienne postępowanie jest uważane za „anormalne”, „grzeszne” i (często) występne.




* * *



Ryc. 8.16. Napis na trzymanej przez kobietę tablicy głosi: |Jestem |dumna |z |mego |syna |homoseksualisty.


* * *





Niedawne ujawnienie się grup homoseksualnych w wielu miasteczkach uniwersyteckich i większych miastach jest ważnym wskaźnikiem zarówno „faktu” istnienia homoseksualizmu, jak i potrzeby, aby „porządne” społeczeństwo przewartościowało swe postawy wobec społeczności homoseksualnej. Czy wiesz, że w większości stanów dobrowolne, intymne stosunki homoseksualne między dorosłymi osobami są traktowane jako przestępstwo? W siedmiu stanach czyny takie są zagrożone karą dożywotniego więzienia, a w trzydziestu pięciu innych maksymalna kara wynosi przynajmniej dziesięć lat więzienia. Do niedawna psychiatria uznawała homoseksualistę za osobę chorą, z poważnym „zaburzeniem umysłowym”, które należy leczyć tak długo, dopóki, „pacjent” nie odrzuci tego niewłaściwego upodobania na rzecz heteroseksualizmu. Kilku nadgorliwych „modyfikatorów zachowania”, zniecierpliwionych gadaniem i dociekaniem, po prostu dołącza elektrody i aplikuje homoseksualiście wstrząsy za każdym razem, gdy wystąpi u niego reakcja na bodziec wzrokowy „tej samej płci”. Pobudzenie wywoływane takimi bodźcami wkrótce wygasa i można teraz, przy zastosowaniu odpowiedniej procedury wzmacniania, „przeprogramować” daną osobę tak, aby podniecały ją obrazki przedstawiające osoby płci przeciwnej. (W niektórych przypadkach ta nowa reakcja generalizuje się z przezroczy terapeuty na rzeczywistych ludzi).


Czy jednak homoseksualizm jest zaburzeniem psychicznym? Czy powinniśmy omawiać go w Rozdziałach 11 i 12 niniejszego podręcznika?


„14 grudnia 1973 roku homoseksualiści byli chorymi psychicznie zboczeńcami seksualnymi.
15 grudnia 1973 roku homoseksualiści nie byli już chorymi psychicznie zboczeńcami”.


Przemiana ta nie była wynikiem masowej terapii, lecz głosowania członków zarządu American Psychiatric Association (Amerykańskiego Towarzystwa Psychiatrycznego). Oświadczyli oni, że homoseksualizm jest „zaburzeniem orientacji seksualnej” nie wymagającym leczenia, o ile dana jednostka nie życzy sobie tego.
Zmiana ta jest sygnałem nowego nastawienia wobec akceptowania odmiennych stylów życia. Heteroseksualizm jest normą statystyczną; do tej kategorii należy większość ludzi. Czy jednak wynika z tego, że jest on „normalny” w sensie psychologicznym czy osobistym, lub też, że homoseksualizm jest „anormalny”? Doniosłe znaczenie większej tolerancji w naszych poglądach na homoseksualizm polega na tym, że tolerancja taka pozwala wszystkim ludziom na większą swobodę autoekspresji i życia ukierunkowanego ku celom wyznaczonym zgodnie z preferencjami osobistymi, a nie jedynie podyktowanymi przez konwencję społeczną czy obawę wykrycia. Nie oznacza to, że „całe piekło wyrwie się na wolność” i każdy stanie się homoseksualistą, lecz że ci, którzy nimi są lub wolą być, nie muszą robić tego w wyniku buntu, urazu czy też odrzucenia wartości rodzicielskich i społecznych, lecz dlatego, że z różnych powodów natury osobistej uważają oni towarzystwo osób tej samej płci za bardziej pożądane niż osób płci przeciwnej.




Streszczenie rozdziału




Badanie motywacji polega na poszukiwaniu przyczyn zachowania. Motywów nie można zaobserwować bezpośrednio; są one |zmiennymi |pośredniczącymi, o których możemy jedynie wnioskować badając zależność między bodźcami i reakcjami. Motywacja obejmuje następujące aspekty: 1) wzbudzenie, 2) ukierunkowanie wysiłku, 3) selektywną uwagę, 4) organizację aktywności, 5) wytrwałość.


Wnioskujemy o istnieniu motywów, aby: 1) wyjaśnić różnicę między zachowaniem różnych jednostek, 2) wnioskować o wewnętrznych dyspozycjach na podstawie obserwowalnych zachowań, 3) określić wewnętrzne źródła zachowania, 4) przypisywać ludziom intencje, odpowiedzialność i winę, 5) ustalać związki między procesami fizjologicznymi a zachowaniem zewnętrznym.
Chociaż poszczególne stany motywacyjne powodują wzbudzenie, to istnieje także układ ogólnego wzburzenia, to istnieje jednakże także układ ogólnego wzbudzenia. Jest to |siatkowaty |układ aktywujący znajdujący się w rdzeniu przedłużonym w pniu mózgu i międzymózgowiu. Pośrednie poziomy wzbudzenia prowadzą do bardziej efektywnego zachowania niż poziom wysoki lub niski (|krzywa |w |kształcie |odwróconej |litery |U).
|Popędy |biologiczne wynikają z podstawowych potrzeb tkankowych organizmu. |Homeostaza jest to tendencja do utrzymywania stałego środowiska wewnętrznego w granicach niezbędnych dla równowagi fizjologicznej. Popędy biologiczne można badać pozostawiając organizm jakiejś związanej z popędem substancji lub poddając go jakiejś przykrej stymulacji, a następnie mierząc spowodowane w ten sposób zmiany w zachowaniu.
|Popęd |głodu jest przedmiotem największej liczby badań. Stan głodu wywołuje się pozbawiając organizm pokarmu. |Reakcja |konsumacyjna, w tym wypadku jedzenie, zaspokaja organizm i redukuje stan popędu.
Skurcze żołądka odgrywają pewną rolę w wywoływaniu uczucia głodu, podobnie jak poziom cukru we krwi. Podwzgórze odgrywa doniosłą rolę w procesach związanych z głodem i innymi popędami, nie jest jednak jasne, czy funkcjonuje ono jako „ośrodek motywacji”, czy tylko jako „ośrodek informacji” o stanach popędu.
Głód zdaje się wywierać wpływ „uwrażliwiający”, obniżając progi dla różnych rodzajów bodźców. Zarówno sygnały |zewnętrzne, jak i |wewnętrzne, mogą wywołać popęd głodu. Stwierdzono, że zwierzęta żyjące w warunkach niedostatku są bardziej wrażliwe na sygnały zewnętrzne; zwierzęta, które żyją w warunkach obfitości, są bardziej wrażliwe na sygnały wewnętrzne.  Badania wykazują, że |pomiar |ilości |pobieranego |pokarmu zachodzi zarówno w żołądku, jak i - w mniejszym stopniu - w jamie ustnej. Zarówno zwierzęta jak i ludzie mogą odczuwać |głód |specyficznych |rodzajów |pokarmu, zwłaszcza wtedy, gdy są pozbawieni potrzebnych substancji. Jednakże u ludzi „głody” te są zdeterminowane przez wyuczone preferencje.
Długotrwałe niedożywienie prowadzi do wzmacniającej się apatii oraz zaabsorbowania jedzeniem. |Anorexia |nervosa jest rzadką chorobą, której ofiary, zwykle młode kobiety, po prostu przestają jeść i coraz bardziej chudną. Przyczyny tej choroby nie są jeszcze dobrze poznane, lecz leczy się ją skutecznie za pomocą technik modyfikacji zachowania. |Otyłość, rezultat przejadania się, jest poważnym problemem dla wielu ludzi. Wyniki kontynuowanych obecnie dwóch kierunków badań sugerują, że a) ludzie otyli mogą mieć |więcej komórek tłuszczowych niż jednostki o przeciętnej wadze ciała oraz b) u otyłych jedzenie jest raczej reakcją na sygnały |zewnętrzne niż na sygnały wewnętrzne.
|Popęd |pragnienia w warunkach deprywacji jest silniejszy niż popęd głodu, a ponadto występują tu pewne różnice jakościowe. Na przykład, zachowanie zwierząt spragnionych jest zwykle stereotypowe, podczas gdy zachowanie zwierząt głodnych jest zmienne. Pomiar ilości pobranej wody zachodzi zarówno w żołądku, jak i w jamie ustnej. Fizjologiczną podstawą popędu pragnienia jest utrzymanie właściwej równowagi płynów w komórkach organizmu.
|Popęd |seksualny, w odróżnieniu od innych popędów biologicznych, nie jest niezbędny dla przetrwania jednostki - aczkolwiek jest oczywiście niezbędny dla przetrwania gatunku. Może być on wzbudzony przez prawie każdy bodziec, jaki tylko można sobie wyobrazić, a jego wzbudzenie jest równie aktywnie poszukiwane, jak i jego redukcja.
Zachowanie seksualne zwierząt jest regulowane przez czynniki fizjologiczne (takie, jak cykle estralny u samic) w znacznie większym stopniu niż u ludzi. Istnieją duże różnice między gatunkami pod względem częstości i czasu kopulacji, lecz u wszystkich gatunków wzorce reakcji zależą od złożonej wymiany sygnałów między samcem a samicą. Izolacja od rówieśników we wczesnym okresie życia może prowadzić do nieadekwatnego zachowania seksualnego w życiu dojrzałym.
Chociaż powszechnie uznaje się istnienie wrodzonego „popędu macierzyńskiego”, to jednak istnieją dane, które skłaniają do zakwestionowania tego twierdzenia. U zwierząt zaakceptowanie potomstwa przez matki zdaje się zależeć w dużym stopniu od sygnałów węchowych.
Wczesne badania nad przyjemnością wynikającą z kontaktu fizycznego wykazały, że małe małpki wychowywane ze sztucznymi matkami wolały o wiele bardziej matkę pokrytą włochatą tkaniną - nawet wówczas, gdy mleko dawała im „matka” zrobiona z drutu. Wydawało się, że u małpek tych kształtują się normalne reakcje afektywne w stosunku do ich matek zastępczych i sądzono, ze rozwijają się one normalnie. Jednakże w końcu okazało się, że gdy małpki wychowywane bez matek osiągnęły wiek dojrzały, to ich zachowanie seksualne było całkowicie nieadekwatne - a gdy niektóre z nich w końcu same stały się matkami, wówczas odrzucały swoje małe. Widocznie zarówno „prawdziwa” opieka macierzyńska, jak i interakcje społeczne z rówieśnikami są niezbędne dla adekwatnego przystosowania heteroseksualnego w wieku dojrzałym.
Jeszcze w początkach bieżącego stulecia seks uważano za „zło konieczne”, o którym nie mówi się w kulturalnym towarzystwie. Mogło to być jedną z przyczyn, dla których stał się on tak potężnym czynnikiem wzmacniającym w obecnych czasach. Do niedawna badania nad seksem u ludzi ograniczały się do sprawozdań klinicznych i wywiadów.
Różnice psychoseksualne między mężczyznami i kobietami zależą zarówno od czynników fizjologicznych (zdeterminowanych głównie przez hormony), jak i czynników psychologicznych (takich, jak wyuczona rola związana z płcią).  |Hermafrodyci (Porównaj przypis na s.339 (przyp. red.)) są to jednostki, u których występuje sprzeczność między zewnętrznymi i wewnętrznymi cechami płciowymi.
Przez długi czas przyjmowano, że mężczyźni i kobiety różnią się znacznie pod względem swych reakcji seksualnych, lecz niedawno badania podważają to założenie. W badaniach, w których stosowano kontrolowaną ekspozycję bodźców erotycznych (filmy lub literatura pornograficzna), zarówno mężczyźni jak i kobiety podawali, że bodźce wzrokowe wywołują u nich pobudzenie fizjologiczne. Pozostało jeszcze do rozwiązania wiele problemów metodologicznych, lecz kontrolowane badania w tej dziedzinie powinny przyczynić się w znacznym stopniu do zastąpienia mitów faktami.
Większość ludzi jest zdolnych do zachowań seksualnych przez większą część swego życia, aczkolwiek aktywność seksualna zmniejsza się na ogół z wiekiem. Czynniki natury psychologicznej, jak również zmiany w zdrowiu fizycznym mogą prowadzić do obniżenia się reaktywności seksualnej. Postawy seksualne i wzorce zachowania w wielkim stopniu są uzależnione od czynników kulturowych. |Homoseksualizm, który przez długi czas uważano za występny i (lub) patologiczny, zaczyna być traktowana jako kwestia osobistych preferencji, wymagająca leczenia tylko wtedy, jeśli dana osoba tego pragnie.




Z Frontu Badań.
Głodowanie otyłych ludzi




|Richard |E. |Nisbett „University of Michigan”


Mniej więcej dziesięć lat temu, gdy byłem studentem studiów podyplomowych na wydziale psychologii społecznej Columbia University, zacząłem badać zachowanie ludzi otyłych. Zarówno Stanley Schachter - mój ówczesny opiekun naukowy - jak i ja wierzyliśmy mocno, że otyłość może być rezultatem pewnego zaburzenia zachowania. Podobnie jak większość psychologów społecznych opowiadaliśmy się zdecydowanie za podejściem „środowiskowym”.  Byliśmy przekonani, że większość różnic między ludźmi wynika z odmiennej historii uczenia się. Schachter wysunął hipotezę, że niektórzy ludzie są otyli, ponieważ nie zwracają uwagi na sygnały fizjologiczne, które inicjują  i przerywają czynność jedzenia, są natomiast bardzo wrażliwi na zewnętrzne sygnały sensoryczne, takie jak smak, widok i zapach pokarmu. Przeprowadzone przez nas w następnych latach badania zdecydowanie potwierdziły przypuszczenie, że otyli ludzie są bardzo wrażliwi na sygnały zewnętrzne, lecz byłem zmuszony zmienić nasze początkowe założenia co do kierunku związku przyczynowego. Nie jestem już przekonany, że ludzie są otyli dlatego, że zachowują się w taki a nie inny sposób; sądzę raczej, że ich zachowanie jest pośrednim skutkiem ich usiłowań zmierzających do utrzymania wagi w normie.
Obecnie wyznaję pogląd, że w większości przypadków otyłość jest przede wszystkim wynikiem „złego planu” genetycznego. Wniosek ten wynika po części z prac nad tkanką tłuszczową prowadzonych przez Hirscha i Knittle’a na Rockefeller University oraz prac szwedzkiego fizjologa Pera Bjorntropa.  Stwierdzili oni, że otyłość jest głównie wynikiem zwiększonej liczby komórek tłuszczowych (chociaż w niektórych wypadkach stwierdzono niewielkie powiększenie rozmiarów tych komórek). Ustalono, że osoby otyłe mają trzykrotnie więcej komórek tłuszczowych niż jednostki o normalnej wadze ciała.
Doniosłe znaczenie tych prac dla wyjaśnienia zjawiska otyłości staje się oczywiste, gdy zdamy sobie sprawę z tego, że liczba komórek tłuszczowych u osoby dorosłej jest w zasadzie niezmienna. Dieta stosowana przez ludzi dorosłych może zmniejszyć |rozmiary komórek tłuszczowych, lecz nie ma praktycznie żadnego wpływu na ich |liczbę. Po przeprowadzeniu diety odchudzającej otyłej poprzednio osobie pozostaje ta sama, duża liczba komórek tłuszczowych, które mogą być ponownie „napełnione”, gdy siła jej woli osłabnie. I na odwrót, przejadanie się nie powoduje u dorosłych rozwijania się większej liczby komórek tłuszczowych. U ochotników rekrutujących się spośród więźniów, którym płacono za przybieranie na wadze, komórki tłuszczowe powiększały swe rozmiary, ich liczba pozostawała natomiast bez zmian. Jak się wydaje, oznacza to, iż jednostki, którym zdarzyło się mieć dużą liczbę komórek tłuszczowych, będą w rezultacie miały wysoki podstawowy poziom tłuszczu w organizmie. Innymi słowy, są one konstytucjonalnie „zaprogramowane”, do tego, by być otyłymi.
Dwa czynniki, które zdają się wpływać na ten poziom podstawowy tłuszczu, to wyposażenie genetyczne i być może wczesne doświadczenia z zakresu odżywiania się. Szczepy szczurów różnią się znacznie pod względem procentu tłuszczu w ciele. Wydaje się prawdopodobne, że u ludzi występują różnice genetyczne podobne do tych, które zaobserowano u szczurów. Dane dotyczące podobieństwa między rodzicami a dziećmi pod względem otyłości, chociaż oczywiście możliwe do zinterpretowania w kategoriach środowiskowych (otyli rodzice uczą swoje dzieci przejadania się), wykazują tak wysoką korelację, iż wydaje się wysoce prawdopodobne, że dziedziczność istotnie odgrywa pewną rolę w kształtowaniu się otyłości u ludzi. Pewien badacz stwierdził na przykład, że w obserwowanej przez niego grupie żadni szczupli rodzice nie mieli otyłego dziecka, podczas gdy żadni bardzo otyli rodzice nie mieli dziecka szczupłego.
Drugim czynnikiem, który prawdopodobnie odgrywa pewną rolę, jest odżywianie we wczesnym okresie życia: możliwe, że ilość pokarmu spożywanego w ciągu pierwszych paru tygodni życia wpływa na liczbe komórek tłuszczowych, jaką będzie mieć dorosły szczur. Wydaje się prawdopodobne, aczkolwiek nie wykazano tego jeszcze wyraźnie, że również u ludzi przekarmienie w ciągu pierwszych lat życia może wpływać na podstawowy poziom tłuszczu.
Hipoteza, iż ludzie różnią się pod względem poziomu podstawowego magazynowania tłuszczu, staje się jeszcze bardziej przekonywująca, gdy weźmiemy pod uwagę to, iż zgodnie z nagromadzonym ostatnio materiałem dowodowym, organizm stara się zachować masę tkanki tłuszczowej. Wydaje się, że sprawiają to ośrodki pokarmowe w podwzgórzu, które regulują pobór pokarmu tak, aby utrzymać ilość zmagazynowanego tłuszczu odpowiadającą jego poziomowi podstawowemu czy tak zwanej „wielkości wzorcowej”. Nie ma żadnych powodów, aby przyjmować, że ta „wielkość wzorcowa” jest taka sama u wszystkich jednostek o tej samej wysokości ciała i tej samej budowie kostnej. Przeciwnie, podwzgórze może może utrzymywać różne poziomy podstawowe tłuszczu u różnych jednostek, zachowując ten poziom, jakim dana osoba jest obdarzona - lub obarczona. Twierdzenie to sugeruje nowy sposób myślenia o otyłości. Wskazywałoby ono, że otyłość jest dla niektórych stanem „normalnym” czy „idealnym”. Ponadto, wynikałoby z niego, że wiele jednostek w populacji „z nadwagą” ma w rzeczywistości „niedowagę”. Osoba o wysokim poziomie podstawowym tkanki tłuszczowej będzie pod znacznym naciskiem społecznym ( a często i medycznym - ze strony lekarzy), aby tracić na wadze. Jednakże można oczekiwać, że jej podwzgórze będzie reagować na utratę wagi w mniej więcej ten sam sposób, jak ośrodkowy układ nerwowy szczupłej jednostki na głód. Taka osoba będzie w rezultacie cały czas głodować.
Istnieje w rzeczywistości wiele analogii między zachowaniem ludzi otyłych a zachowaniem głodnych ludzi i zwierząt. Jednakże przed omówieniem zachowania otyłych ludzi pomocne będzie opisanie, bardziej szczegółowo, zmian zachowania wywoływanych przez głód. Wiedza o niektórych zmianach tego rodzaju jest dość spopularyzowana, lecz wiele z nich nie jest bynajmniej szeroko znanych - nawet badaczom zajmującym się zagadnieniami związanymi z pobieraniem pokarmów i odżywianiem. 
Osobnik pozbawiony przez dłuższy czas pokarmu zjada oczywiście więcej, gdy nadarzy się okazja, oraz je szybciej, niż osobnik pozbawiony pokarmu przez czas krótszy. Jest także bardziej prawdopodobne, że wygłodzone osobniki będą również jadły w nowym lub obcym otoczeniu. Mniej oczywisty jest wpływ głodu na sposób, w jaki organizm reaguje na smak pokarmu. Do niedawna nikt nie analizował zależności między głodem a wrażliwością na smak. Większość badaczy po prostu zakładała, że głodny osobnik jest „niewybredny” i zjada duże ilości jakiegokolwiek dostępnego pokarmu, bez względu na jego właściwości smakowe. To założenie wydaje się obecnie błędne. Materiał dowodowy, pochodzący głównie z pracy Jacobsona i Sharmy, sugeruje, że zwierzęta przez długi czas pozbawione pożywienia zjadały proporcjonalnie więcej dobrze smakującego pokarmu i mniej niesmacznego pokarmu niż zwierzęta pozbawione pożywienia przez krótki czas.
Jacobs i Sharma oferowali psom i szczurom albo standardowy pokarm laboratoryjny, albo pokarm o smaku polepszonym dzięki dodaniu tłuszczu lub sacharyny, albo też pokarm, którego smak popsuto dodając do niego gorzką chininę lub celulozę. Zwierzętom albo pozwalano jeść, kiedy chciały („dieta ad libitum”), albo też pozwalano im tylko na jeden krótki posiłek co dwadzieścia cztery godziny. Zwierzęta z grupy deprywowanej i z grupy jedzącej do woli zjadały równe ilości pokarmu standardowego, lecz deprywowane zwierzęta zjadały znacznie więcej smacznego pokarmu i znacznie mniej niesmacznego pokarmu niż zwierzęta z grupy jedzącej do woli. Dane te sugerują więc, że zwierzę deprywowane staje się coraz bardziej wrażliwe na smak, zjadając proporocjonalnie więcej smacznego pokarmu i mniej niesmacznego pokarmu.
Głód ma także silny wpływ na inne rodzaje zachowania. Większość tego, co wiemy o wpływie silnego głodu na ogólne zachowanie, zawdzięczamy przeprowadzonym w czasie II wojny światowej klasycznym badaniom Keysa, Brozka i ich współpracowników nad wpływem niedożywienia na ludzi. Osobami badanymi byli mężczyźni uchylający się od służby wojskowej z pobudek natury moralnej, którzy zgodzili się na „ochotnika” utracić 24% wagi ciała w ciągu 24 tygodni. Dokonano tego ograniczając dzienny przydział pożywienia dla tych mężczyzn do około 1600 kalorii, wymagając od nich jednocześnie wykonywania normalnego, pełnego programu zajęć. W czasie tego eksperymentu u osób badanych wystąpiły trzy główne objawy: stawali się oni coraz bardziej skłonni do zaburzeń emocjonalnych, coraz bardziej apatyczni i mało aktywni oraz coraz mniej zainteresowani sprawami seksualnymi.
Przez cały okres niedożywienia badani byli bardziej drażliwi i wybuchy złego humoru występowały tak często, że trzeba było zrezygnować ze spotkań grupowych, jakie odbywały się w okresie kontrolnym. Występowały również okresy radosnego podniecenia, po których nieuchronnie następowały okresy depresji. W miarę, jak przedłużała się ta półgłodówka, testy psychologiczne ujawniały coraz więcej zaburzeń emocjonalnych i zjawisk patologicznych.
Mężczyźni ci odczuwali niechęć do wszelkiej aktywności. Woleli oni siedzieć i nic nie robić, niż zajmować się jakimś rodzajem lubianej uprzednio pracy czy zabawy. Ten brak |radości |życia objął również sferę seksualną. Wiele zaręczyn zostało zerwanych, niewielu mężczyzn spotykało się nadal z dziewczynami, masturbacja zaś i nocne wytryski ustały niemal zupełnie.
Pomimo to, że prawie w żadnym z badań nad otyłymi ludźmi nie weryfikowano, jak się zdaje, hipotezy, że ludzie otyli są głodni, to jednak sprawiedliwość każe przyznać, że najważniejsze sfery, w których stwierdzono różnice między zachowaniem osób otyłych i osób o normalnej wadze, odpowiadają niemal dokładnie sferom, na które oddziałuje głód. Podobnie jak głodne zwierzęta, tak i otyły człowiek zjada więcej na jednym posiedzeniu i je szybciej; osoba otyła wykazuje także większą gotowość do jedzenia, o czym świadczy fakt, że w nowym otoczeniu, w którym znajduje się pokarm, zaczyna jeść częściej niż osoba o normalnej wadze ciała.


I wreszcie, podobnie jak głodne zwierzę, otyły człowiek jest bardzo wrażliwy na smak, zjadając niezwykle duże porcje smacznych pokarmów i niezwykle małe porcje pokarmów niesmacznych.
U osób otyłych zachowanie związane z jedzeniem zdaje się być wyrazem stałego, umiarkowanie silnego głodu, i w wyraźnie małym stopniu wpływają na nie bodźce fizjologiczne, które u jednostek u normalnej wadze ciała zwiększają lub zmniejszają zainteresowanie jedzeniem. W jednym z eksperymentów Schachter prosił badanych otyłych i badanych o normalnej wadze ciała, aby „próbowali” różnych krakersów. Niektórzy z badanych zjedli przed badaniem dwie kanapki z pieczonym mięsem, a niektórzy nie jedli nic przez kilka godzin. Badani o normalnej wadze zjadali w ciągu „sesji próbowania” mniej krakersów - czemu, trudno się dziwić - jeśli zjedli wcześniej dwie kanapki, niż wtedy, gdy byli dłużej pozbawieni pokarmu.  Natomiast badani z „nadwagą” jedli równie dużo krakersów wtedy, gdy przed chwilą zjedli kanapki, jak i wtedy, gdy nie jedli nic o dłuższego czasu.  Podobnie stwierdziłem, że wypowiedzi dotyczące odczuwania głodu zmieniają się w zależności od poziomu deprywacji u badanych o normalnej wadze, lecz nie zmieniają się u osób otyłych. W innym badaniu, przeprowadzonym w supermarkecie, stwierdziłem, że jednostki o normalnej wadze, w miarę, jak nasila się u nich deprywacja pokarmowa, dokonują coraz większej liczby impulsywnych zakupów żywności, podczas gdy kupujący „z nadwagą” dokonują umiarkowanej ilości impulsywnych zakupów, bez względu na swój stan deprywacji. Wydaje się, jak gdyby długotrwały głód u otyłych osób całkowicie dominował nad sygnałami fizjologicznymi towarzyszącymi krótkotrwałym zmianom w stanie odżywienia.
Otyła osoba zdaje się być wyraźnie podobna w różnych sferach zachowania do głodujących badanych z eksperymentu Keysa. Ludzie z „nadwagą” zdają się być bardziej pobudliwi emocjonalnie niż jednostki o normalnej wadze ciała.  Schachter stwierdził, że badani z „nadwagą” są bardziej przestraszeni perspektywą otrzymania wstrząsu elektrycznego niż badani o normalnej wadze ciała. W innych badaniach stwierdzono, że dokładność dokonywanej korekty tekstu i odczytywania wskazówek przyrządów kontrolnych zmniejszyły się u otyłych badanych, gdy wysłuchali oni z taśmy magnetofonowej nagrań o dużym ładunku emocjonalnym. Wyniki uzyskiwane przez badanych o normalnej wadze ciała nie uległy pogorszeniu. Większa pobudliwość emocjonalna u osób otyłych znajduje także swój wyraz w wynikach, jakie uzyskują one w testach przystosowania psychicznego. Moore, Stunkard i Srole dokonali ponownej analizy danych zebranych w badaniach nad zdrowiem psychicznym losowej próbki mieszkańców centrum Manhattanu. Stwierdzono, że otyłe jednostki wykazywały więcej zaburzeń emocjonalnych. Jest interesujące, że respondenci o niższej pozycji społeczno-ekonomicznej byli bardziej otyli niż respondenci o wyższej pozycji. Zapewne jednostki o niższej pozycji społeczno-ekonomicznej są poddawane mniejszemu naciskowi społecznemu i (lub) medycznemu, aby tracić na wadze. Jeśli tak, to jest możliwe, że więcej osób spośród nich ma wagę ciała odpowiadającą poziomowi podstawowemu tłuszczu i że przede wszystkim otyłe osoby z klasy średniej i wyższej walczą o zredukowanie swej wagi i dlatego cierpią wskutek wynikających stąd zaburzeń emocjonalnych. Aby sprawdzić tę hipotezę, przeanalizowałem jeszcze raz dokonaną przez tych autorów ponowną analizę danych ze wspomnianych badań i stwierdziłem, że istotnie, wśród tych osób, które wykazywały wyraźne objawy zaburzeń emocjonalnych, były prawie wyłącznie jednostki z nadwagą o średniej i wyższej pozycji społeczno-ekonomicznej. 
Jeśli jest prawdą, że wiele osób z nadwagą cierpi na zaburzenia emocjonalne, ponieważ w rzeczywistości mają one niedowagę, to wszelkie podejmowane przez nie próby zmierzające do redukcji wagi powinny przynieść dalsze pogorszenie. Jest to tak bardzo ważna sprawa, że chciałbym podkreślić, iż dane dotyczące tego zagadnienia są sprzeczne i niekompletne.  Niektórzy badacze istotnie donoszą o pogorszeniu się, często poważnym, stanu psychicznego tych osób podczas odchudzania się, włącznie z depresją, drażliwością, a nawet psychozą i próbami samobójczymi. Jednakże inni badacze nie stwierdzają żadnych negatywnych skutków. Jest oczywiście możliwe, że te odmienne rezultaty wynikają z doboru różnych populacji pacjentów. Negatywne skutki mogły być obserwowane u pacjentów, u których poziom tłuszczu w organizmie był już poniżej poziomu podstawowego, a rezultaty mniej negatywne mogły występować u tych pacjentów, u których poziom tłuszczu na początku leczenia odpowiadał jego poziomowi podstawowemu w organizmie lub nawet przekraczał ten poziom.
Inne objawy głodu, opisane przez Keysa i jego współpracowników, również zdają się występować u osób otyłych. Mayer i jego współpracownicy stwierdzili, że otyli ludzie są bardzo mało aktywni i poruszają się stosunkowo niewiele, nawet wtedy, gdy zajmują się „aktywnymi” sportami.  Stunkard i jego współpracownicy ustalili, że podczas wykonywania określonych czynności zawodowych jednostkom otyłym udaje się chodzić znacznie mniej w ciągu dnia niż jednostkom o normalnej wadze ciała.
Zainteresowania seksualne u osób otyłych nie były dotąd dokładnie badane, lecz psychoanalityczka Hilda Bruch podaje, że jej otyli pacjenci (jako grupa) wykazywali wyraźnie niewielkie zainteresowania seksualne. We wstępnych badaniach stwierdziłem, że otyli studenci college’u (mężczyźni) miewają mniej orgazmów niż studenci o normalnej wadze ciała. To stwierdzenie dotyczy również wytrysków nocnych, w przypadku których względy społeczne odgrywają oczywiście niewielką rolę.


Jest więc oczywiste, że jednostka otyła i jednostka  głodna mają wiele wspólnego. Podobieństwa te nasuwają pytanie, czy istnieją również wskaźniki fizjologiczne świadczące o tym, że otyli są głodni. Wydaje się, że odpowiedź brzmi: tak. Najpowszechniej przyjętym fizjologicznym wskaźnikiem głodu jest poziom wolnych kwasów tłuszczowych (FFA) we krwi. Gdy organizm jest pozbawiony pokarmu (lub gdy jest mu zimno, albo gdy wykonuje ćwiczenia fizyczne) wówczas wolne kwasy tłuszczowe są mobilizowane z tkanki tłuszczowej dla zaspokojenia wymogów energetycznych. Gdy organizm spożywa pokarm, wówczas poziom FFA szybko spada.
W wielu badaniach wykazano, że poziom wolnych kwasów tłuszczowych jest wyższy u jednostek otyłych niż u jednostek o normalnej wadze ciała. Zakłada się zwykle, że to podniesienie poziomu FFA w krwi jednostek otyłych jest spowodowane po prostu większą ilością zmagazynowanego tłuszczu, który „przedostaje się” do krwiobiegu. Nie wydaje się jednak prawdopodobne, aby tak było w istocie. Dwaj badacze nie stwierdzili żadnego podniesienia się poziomu FFA u otyłych pacjentów, którzy przejadali się i przybierali na wadze w okresie bezpośrednio poprzedzającym przeprowadzanie testów. Co ważniejsze, gdy otyłe jednostki tracą na wadze, wówczas poziom wolnych kwasów tłuszczowych wzrasta coraz bardziej.
Być może równie ważnym faktem, dotyczącym poziomu FFA u tych otyłych osób, jest jego względna niezmienność: różnice spowodowane krótkotrwałymi zmianami w odżywianiu są niewielkie. W ciągu jednodniowego postu poziom FFA u otyłych osób wzrastał jedynie nieznacznie lub wcale. Natomiast osoby o normalnej wadze zaczynają od niskiego poziomu FFA, a po 20 - 24 godzinach deprywacji poziom FFA jest u nich taki, jak u otyłych osób. Ponadto spadek poziomu FFA, w odpowiedzi na pobór pokarmu, jest zarówno wolniejszy, jak i mniej kompletny, u otyłych badanych niż u osób o normalnej wadze ciała.
Te dane fizjologiczne są więc zgodne z danymi dotyczącymi zachowania.  Jednostki z nadwagą zachowują się tak, jak gdyby ich „przełącznik głodu” zaciął się na pozycji „włączone”. Zjadają one więcej podczas jednego posiedzenia, jedzą szybciej, są bardziej wrażliwe na smak, a krótkotrwałe zmiany w poziomie deprywacji nie wpływają w znaczny sposób na ich zachowania związane z jedzeniem, na ich wypowiedzi dotyczące odczuwanego głodu, nawet na to, jak bardzo atrakcyjne są dla nich produkty spożywcze w supermarkecie. Dane fizjologiczne uzasadniają to niezmienne występowanie objawów głodu: poziom FFA jest stale wysoki.
Jakie wynikają stąd wnioski dla otyłej osoby? Pewien znajomy lekarz, który dobrze zna opisane tu dane, przekazuje otyłym osobom następujące ostrzeżenie:


„Staram się wyjaśnić moim pacjentom, zanim zaczną zrzucać nadwagę, że muszą podjąć przemyślaną decyzję: dla niektórych osób lepszym wyjściem może być zaakceptowanie społecznych i zdrowotnych niebezpieczeństw związanych z otyłością, jakiekolwiek one są, i dalsze cieszenie się rozkoszami jedzenia.  Wskazuję im, że jeśli zdecydują się zrzucić nadwagę i utrzymywać „normalną” wagę ciała, to nigdy nie będą mogły znów jeść tak, jak jadły wtedy, gdy były otyłe. Trzeba im uświadomić, że będą w pewnym sensie „dietetycznymi kalekami”. Nigdy nie będą mogły swobodnie jadać posiłków, tak jak to czynią ich partnerzy o normalnej wadze ciała, którzy mimo to pozostają szczupli.  Zwracam im także uwagę na fakt, że nie jest to sprawiedliwe, ale czy jest czymś usprawiedliwionym urodzenie się niewidomym lub z jakąś anomalią fizyczną? Dla niektórych osób przykrości związanych z utrzymaniem normalnej wagi nie da się skompensować płynącymi z tego korzyściami. Widzę niewiele powodów, aby zmuszać tych ludzi do takiego postępowania”.


Moim zdaniem, z faktów tych wynika jeszcze ważniejszy wniosek. Ludzie otyli mogą być ostatnią uciśnioną grupą mniejszościową, w przypadku której nikt nie poczuje się winny z powodu dyskryminowania jej członków. Osoby zajmujące stanowiska kierownicze, policjanci i stewardesy są zwalniani z pracy z powodu otyłości. Jean Mayer i jego współpracownicy wykazali, że otyłe dziewczęta po ukończeniu szkoły średniej mają mniejsze szanse na przyjecie do wybranej uczelni niż szczupłe dziewczęta z takimi samymi stopniami i wynikami egzaminu. Każda otyła osoba dobrze wie, że inni ludzie uważają ją za osobiście odpowiedzialną za jej stan. Trzeba tu podkreślić, że psychologowie i psychoanalitycy - co rzuca na nich niekorzystne światło - w dużym stopniu przyczynili się do rozpowszechnienia i popierania tego wynikającego z uprzedzeń twierdzenia o braku kontroli wewnętrznej u osób otyłych. Istnieją powody, by mieć nadzieję, że w przyszłości ludziom nie będzie się przypisywać większej odpowiedzialności za ich wagę niż za ich wzrost.




Rozdział 9.
Emocje i kontrola poznawcza




„O Horacy,
Więcej jest rzeczy na ziemi i w niebie
Niż się śniło waszym filozofom” (Przekład Józefa Paszkowskiego. William Szekspir „Dzieła dramatyczne”. Warszawa 1980).
„William Szekspir „Hamlet” - 1;5


W jaki sposób psychika wpływa na zachowanie? Przez stulecia intrygowała ludzi zagadka tego, co wydawało się niefizycznymi |źródłami „energii” zawartymi w fizycznej substancji ciała. Tę esencję ludzkiego życia uważano za migoczący, efemeryczny ognik wewnętrznego ducha, duszy, umysłu, woli czy świadomości. Przyjmowano, że zaangażowanie tych sił dostarcza energii, która porusza machinę ludzką. W 40 roku przed narodzeniem Chrystusa rzymski poeta głosił: „Żadne przeszkody, żadne masy materii, jakkolwiek byłyby olbrzymie, nie mogą oprzeć się władzom umysłu; najodleglejsze regiony poddają się im; wszystko ustępuje; same Niebiosa stoją otworem” (Marcus Manilius Astronomica).
Można by więc oczekiwać, że władze umysłu będą głównym przedmiotem zainteresowania psychologii. Jednakże do niedawna relacja między psychiką a ciałem była mniej ważnym tematem, studiowanym jedynie przez małą grupkę badaczy. Jak więc przekonaliśmy się w poprzednich rozdziałach, doktryna obserwowalnego zachowania, wywołujących je przyczyn zewnętrznych oraz konsekwencji była w centrum zainteresowania psychologów przez ostatnie dziesięciolecia. W niewielkim stopniu tolerowano jakiekolwiek zjawiska, dla których nie potrafiono znaleźć fizycznych, biologicznych czy empirycznych wyjaśnień.
Obraz ten jednak zaczyna ulegać zmianie. Kanadyjski psycholog Donald Hebb, w swym przemówieniu wygłoszonym na posiedzeniu American Psychological Association (Amerykańskiego Towarzystwa Psychologicznego) we wrześniu 1973 roku stwierdził zdecydowanie: „Psychologia jest nauką o psychice: centralnym zagadnieniu, wielkiej tajemnicy, najtrudniejszym problemie spośród wszystkich” (1974, s. 74). Hebb zdefiniował „psychikę” („mind”) w następujących kategoriach: „psychika jest zdolnością myślenia, a myśl jest integracyjną aktywnością mózgu” (str. 75).
Chyba najbardziej intrygującymi ze wszystkich zjawisk związanych z psychiką ludzką są religijne cuda, uzdrowienia przez wiarę, śmierć zdrowych osób, na które rzucono „czary”, oddawanie życia za jakiś ideał, fakt, że są ludzie, których nie można przekupić, którzy nie mają „swojej ceny”, możliwość oddziaływania samych słów w hipnozie lub podczas „prania mózgów”, nieświadome motywy, konformizm wywoływany naciskiem jednomyślnej grupy oraz różnorodne potężne emocje, które stanowią podłoże nienawiści i miłości. Są one interesujące właśnie dlatego, że ich istnienie zdaje się podważać nasze elementarne pojęcia przyczynowości. Ponadto wskazują one, że możemy nie być jedynie biernymi ofiarami naszego bezpośredniego, fizycznego środowiska.  Jesteśmy raczej, z jednej strony uzależnieni od działających na nas sił zewnętrznych, a z drugiej strony, posiadamy możliwość sprawowania wewnętrznej kontroli nad środowiskiem. Przypuśćmy, że „wiara może tego dokonać”; czyżby wiara i nadzieja były bardziej wartościowymi dobrami? Czy fizyczna, zewnętrzna rzeczywistość jest stałym, niezmiennym i jedynym determinantem naszego zachowania? Przypuśćmy, że przyjęliśmy bardziej dynamiczny pogląd na nas samych, zgodnie z którym - przez realizowanie naszych możliwości wyboru - moglibyśmy odrzucać rzeczywistość taką, jak jest dana i stwarzać rzeczywistość społeczną i fizyczną?
Carl Rogers znajduje się w pierwszym szeregu tych, którzy wierzą w doniosłą rolę tej „wewnętrznej osoby” oraz zdolność jednostki do przekształcenia sytuacji, w których się ona znajduje, jak również własnego losu. Podkreśla on wagę stawiania tego rodzaju pytań, które zadaliśmy (i nadal będziemy zadawać).


„Zdolność osoby do odkrywania nowego znaczenia w siłach, które na nią oddziaływały, oraz w minionych doświadczeniach, które miały na nią władzę, jak również zdolność do świadomego zmieniania swego zachowania w świetle tego nowego znaczenia, jest bardzo ważna dla naszego sposobu myślenia - z czego nie zdawano sobie w pełni sprawy. Musimy zrewidować filozoficzną podstawę naszej pracy, dochodząc do punktu, w którym można uznać, że istnieją w jednostce siły mogące wywierać spontaniczny i doniosły wpływ na zachowanie, które to zachowanie nie jest przewidywalne na podstawie znajomości uprzednich oddziaływań i uwarunkowań” (1946, s. 422).


Ponieważ staramy się przedstawić wszechstronny, jednolity obraz determinantów zachowania ludzkiego, musimy zatem rozpatrzyć (chociaż pokrótce) pewne tematy, których zwykle nie przedstawia się w podręcznikach stanowiących wprowadzenie do psychologii: przypadki tak zwanej śmierci „voodoo”, cudowne uzdrowienia, czary, poczucie beznadziejności, zdolności kontroli poznawczej za pośrednictwem placebo (substancji nie mającej żadnych właściwości leczniczych) oraz wpływ hipnozy na odczuwanie bólu.
Zaczniemy jednak od |emocji - codziennego zjawiska, które znajduje się w węzłowym punkcie problemu psychika-ciało. Doznawanie emocji jest subiektywnym procesem psychicznym, chociaż emocje można wywołać za pomocą bodźców środowiskowych i pośredniczą w nich wyraźnie reakcje fizjologiczne.  Ponadto niewłaściwe „obchodzenie się” z reakcjami emocjonalnymi może doprowadzić jednostkę do zaburzeń psychicznych, chorób psychosomatycznych lub innych stanów chorobowych. Z drugiej strony, te emocje czynią niekiedy życie możliwym do zniesienia, a nawet pięknym. To one również sprawiają, że życie jest godne człowieka.




Zbliżenie


Więzienie: nie ma miejsca dla emocji


„Gdy ludzie tracą zdolność doświadczania emocji lub gdy ich ekspresja emocjonalna staje się niezróżnicowana i bezbarwna, wówczas przyjmuje się to za oznakę poważnego zaburzenia psychicznego, jak w przypadku autyzmu czy schizofrenii. Bez emocji niemożliwa jest empatia czy współczucie, miłość,  opieka i troska, ani też przeżywanie obawy przed konsekwencjami własnych działań. Osoba pozbawiona emocji staje się robotem, automatem i potencjalnie może być najbardziej niebezpiecznym wrogiem. Ponieważ jednak emocje powodują spontaniczne, impulsywne, często nieprzewidywalne reakcje indywidualne, przeto ważne jest ograniczanie ich przejawów w zinstytucjonalizowanych środowiskach. W instytucjach zobowiązanych do zajmowania się jednostkami „odbiegającymi od normy”, przejawy emocji uważa się za źródło potencjalnego niebezpieczeństwa i ogranicza się je do minimum. Dlatego też więzienia zamiast sprzyjać rozwijaniu u więźniów pełniejszej, bardziej normalnej ekspresji emocji, oddziałują w sposób wręcz odwrotny, stwarzając warunki, które wypaczają, hamują i tłumią emocje.
George Jackson w swej książce „Soledad Brother” (1971) oznajmia: 
„Poczyniłem ogromne postępy na drodze do uzyskania tego, czego będę osobiście potrzebował, jeśli moje plany mają przynieść sukces (...).  Stłumiłem wszelką emocję” (s. 37). Długoletni więzień zakładu poprawczego dla dorosłych (Adult Correctional Institution) na Rhode Island stwierdził, że „pokonał system” nauczywszy się, w jaki sposób wyłączyć wszelkie emocje tak, aby nie czuć już niczego względem nikogo. Teraz |oni nie mogą mu już nic zrobić. Nauczył się on tej „samokontroli” przebywając przez kilka lat w izolatce w więzieniu Maryland. Spodziewa się on, że będzie mógł znów włączyć swoje emocje, gdy stamtąd wyjdzie. My ze swej strony wątpimy, czy będzie to możliwe.
Więźniowie, którzy pozwalają sobie na ujawnianie swych emocji, przejawiają w ten sposób pewną |wrażliwość czy słabość i zwiększają w związku z tym prawdopodobieństwo, że zostaną wybrani przez strażników jako kandydaci na „informatorów” lub przez innych więźniów do roli kobiecej w przymusowych kontaktach seksualnych. Ponadto, im silniejsze są twoje uczucia w stosunku do innych ludzi, tym bardziej jesteś narażony na cierpienie, gdy są oni karani, lub gdy cię opuszczają, gdy umierają lub gdy zdradzają ciebie. W więzieniu, gdzie masz tak niewielką kontrolę nad charakterem twoich stosunków z innymi ludźmi, łagodne, serdeczne emocje przynoszą ostatecznie więcej cierpienia niż przyjemności, a zatem lepiej zupełnie się bez nich obywać.
Strażnikom wiedzie się również niewiele lepiej niż więźniom. Kontrolę nad swymi emocjami zaczynają oni od konieczności ukrywania swego strachu, związanego z pracą w sytuacji, w której ich życie wisi stale na włosku. To wypieranie się swego strachu wykracza poza „pogwizdywanie pogodnej melodyjki” - przekształca się w ciągłe podkreślanie swej nieustraszoności i szorstkości w interakcjach z więźniami i między sobą. Strażnik, który się boi, stanowi zagrożenie dla każdego innego strażnika, ponieważ nie można na niego liczyć w nagłej potrzebie - a jest to ewentualność, na którą strażnicy są zawsze przygotowani. Ponadto strażnik, który wykazuje jakąś serdeczność czy pozytywny stosunek emocjonalny wobec więźniów, jest podejrzany o to, że więźniowie „skaptowali” go jakoś, że bierze łapówki lub że w jakiś inny sposób jest pod ich wpływem.
Nic więc dziwnego, że podstawowa rada udzielana przez komendanta strażników swoim podwładnym w San Quentin brzmi: „Bądź zdecydowany i sprawiedliwy, lecz mało przyjazny wobec więźniów”. Nie wystarczy jednak, aby strażnicy ukrywali swoje emocje jedynie przed więźniami; muszą oni także ukrywać je przed sobą. Miedzy funkcjonariuszami zakładów poprawczych i więzień istnieje milcząca umowa, aby nigdy nie rozmawiać o swych uczuciach i emocjach miedzy sobą, a już z pewnością, aby nie mówić nowym pracownikom o tym, co czują „starzy wyjadacze”. Można oczekiwać, że takie ukrywanie intensywnie odczuwanych emocji będzie przemieszczane na rodzinę i przyjaciół, a także wyrażane w ukrytej „uwewnętrznionej” formie - w postaci chorób psychosomatycznych.
Tę analizę zjawiska tłumienia ekspresji emocji przez instytucję więzienia możemy rozszerzyć, obejmując nią większość instytucji społecznych, które oddziałują podobnie. Wydaje się, jak gdyby emocje stanowiły antytezę rozsądku, porządku i opanowania. Kiedy ostatnim razem byłeś świadkiem silnych emocji wyrażanych w jakimkolwiek zinstytucjonalizowanym środowisku, w którym się obracasz - zwłaszcza w środowisku wyższej uczelni? Kiedy, w istocie ty sam po raz ostatni zareagowałeś zgodnie z intensywnie odczuwanymi emocjami? Takie zredukowanie ekspresji emocjonalnej prowadzi do zaparcia się naszej własnej ludzkiej natury - niezależnie od tego, czy jesteśmy „strażnikami” czy też „więźniami” tego świata.




Emocje




Wyobraźmy sobie, że udało nam się stworzyć robota, który wygląda, mówi i porusza się dokładnie tak samo jak człowiek. Zastosowawszy skomplikowany system komputerowy moglibyśmy zaprogramować tego robota tak, aby myślał, rozwiązywał problemy i wykonywał różne czynności. Taki robot mógłby z pewnością wykonywać wiele rzeczy tak samo jak człowiek, ale podobnie jak mister Spock z powieści „Star Trek”, nigdy nie wyrażałby żadnych emocji. To jest nigdy nie uśmiechałby się, nie śmiał, nie płakał, nie rumienił itd.  Każdy człowiek poznawszy naszego robota prawdopodobnie odgadłby, że nie jest on człowiekiem, ponieważ nigdy nie okazuje żadnych uczuć znalazłszy się w „emocjonującej sytuacji”.
W jaki sposób moglibyśmy uczynić robota bardziej ludzkim? Jednym z możliwych rozwiązań byłoby „wbudowanie” w niego określonych reakcji związanych z pewnymi emocjami. Na przykład, gdybyśmy chcieli sprawić, aby robot wydawał się smutny, to moglibyśmy wyposażyć go w kanaliki łzowe i zaprogramować robota tak, aby płakał w tych samych okolicznościach, gdy robią to ludzie. Lecz |kiedy |właściwie ludzie płaczą?
Jeśli rozejrzymy się dokoła, przekonamy się, że niemowlęta płaczą, dopóki nie otrzymają pokarmu, małe zaś dzieci płaczą i grymaszą, dopóki nie dostaną ciastka lub ulubionej zabawki. Ludzie płaczą przy oglądaniu pewnych filmów, a czasami płaczą na ślubach. Płaczą, gdy uderzą się w palec lub w inny sposób się zranią. Aktorka lub aktor mogą płakać odgrywając dramatyczną rolę na scenie. Kontestujący studenci będą płakać, gdy znajdą się w oparach gazu łzawiącego. Ludzie często płaczą, gdy słyszą przemówienie wygłaszane przez wprawnego mówcę, a także płaczą krojąc cebulę. Matka będzie płakać, gdy dowie się, że jej syn został zabity na wojnie i będzie także płakać, gdy jej syn powróci z wojny do domu cały i zdrowy.
W tym momencie powiesz zapewne do siebie: „Chwileczkę, chwileczkę! Nie wszystkie te przykłady płaczu mają związek z emocją. A nawet wtedy, gdy mają, emocja ta nie musi być smutkiem!”. Wynika z tego w oczywisty sposób, że pojedyncza reakcja behawioralna, taka jak „płacz”, nie może sygnalizować obecności pojedynczej emocji. Lecz w takim razie skąd wiemy, że inni ludzie lub my sami doświadczamy jakiejś emocji? Dlaczego mówimy, że jesteśmy „smutni”, gdy słyszymy złe wieści, lecz nie mówimy tego, gdy kroimy cebulę?  Innymi słowy, |czym |jest złożony proces, który nazywamy emocją? Zanim będziemy potrafili zaprogramować naszego robota, to być może najpierw musimy dowiedzieć się, w jaki sposób |my zostaliśmy zaprogramowani - jak to się dzieje, że doświadczamy emocji. W jaki sposób rozpoznajemy różnicę między uczuciami szczęścia, smutku, gniewu i radosnego podniecenia?




Pojęcie emocji




Z dawien dawna ludzie usiłowali rozumieć ekscytujące stany |afektywne, których często doświadczają. Starożytni Grecy byli przekonani, że istnieją cztery charakterystyczne typy temperamentu emocjonalnego, zależnie od dominacji określonego płynu w ciele: temperament sangwiniczny (krew), melancholiczny (czarna żółć), choleryczny ( żółta żółć), flegmatyczny ( flegma).
Arystoteles jako pierwszy rozróżnił fizjologiczne i psychiczne komponenty emocji, które określił odpowiednio jako jej „substancję” i „formę, czyli ideę”. Siedemnastowieczni i osiemnastowieczni filozofowie sądzili na ogół, że emocje mają charakter instynktowny i są nieracjonalne, a zatem reprezentują zwierzęcą stronę ludzkiej natury. Emocjom przeciwstawiano specyficzne ludzkie właściwości - rozum i intelekt, które miały trzymać na wodzy emocje i kierować postępowaniem w sposób racjonalny. To sztywne przeciwstawienie tego, co emocjonalne i tego, co racjonalne implikowało nie tylko to, że emocje przeszkadzają i że są szkodliwe, lecz także to, iż są jakimś wypaczonym procesem psychicznym, różnym od myślenia i rozsądku oraz przeciwstawnym im. Wiele potocznych powiedzeń nadal podtrzymuje ten pogląd, na przykład: „Wzburzyło mnie to tak, że nie mogłem rozsądnie myśleć”, „Starałem się postąpić właściwie, lecz moje uczucia były silniejsze ode mnie” lub „W gorączce namiętności nie zdawałem sobie sprawy z tego, co robię”.
Gdy psychologia przekształciła się w formalną dyscyplinę odrębną od filozofii i fizjologii, wówczas jednym z wielu rozpatrywanych przez nią problemów stał się problem emocji. Psychologowie starali się zdefiniować emocje w sposób bardziej ścisły, lecz szybko stwierdzili, że jest to bardzo trudne zadanie. Niektórzy definiowali emocje jako motywy, podczas gdy inni sądzili, że emocje są procesem znacznie różniącym się od motywacji.  Niektórzy definiują emocje jako zmiany fizjologiczne, podczas gdy inni definiują je w kategoriach subiektywnych odczuć, doświadczanych i opisywanych przez daną jednostkę. Ten brak zgody co do definicji jest jednym z czynników, które utrudniają badania w tej dziedzinie.
Stosownie do różnych definicji emocji, psychologowie badają bardzo różne reakcje. Niektórzy z nich zajmują się rolą takich procesów neurofizjologicznych, jak aktywność mózgu, układu wydzielania wewnętrznego i autonomicznego układu nerwowego. Inni koncentrują sie na obserwowalnych ruchach ciała i wyrazach twarzy. Wielu badaczy opiera się na słownych opisach doświadczeń emocjonalnych, jak również na innych danych introspekcyjnych. Żadne z tych podejść nie zostało zaakceptowane jako całkowicie adekwatne; sugeruje się, że zadawalający opis emocji musi integrować w pewien sposób wszystkie te aspekty reakcji emocjonalnej.  Dostarczając wielu interesujących rezultatów, badania nad emocjami podlegają jednak niekorzystnemu wpływowi kilku czynników ograniczających.  Jednym z nich jest założenie (odziedziczone po filozofii racjonalistycznej), że emocje działają zakłócająco, że towarzyszy im zwykle dezintegracja jakiegoś racjonalnego, zachodzącego właśnie zachowania.  Chociaż pewne skrajne stany emocjonalne, takie jak panika czy trema aktorska, mogą przeszkadzać w działaniu i często istotnie przeszkadzają, to jednak model ten nie wydaje się adekwatny w wypadku wszystkich reakcji emocjonalnych. Leeper (1948) wysunął tezę, że emocje często spełniają pozytywną funkcję, zmuszając jednostkę do zorganizowania nowych reakcji przystosowawczych w stosunku do zmienionego środowiska.
Drugim czynnikiem ograniczającym użyteczność badań nad emocjami jest fakt, że ich przedmiotem są przede wszystkim negatywne emocje (głównie lęk i strach) i że nie uwzględnia się w nich emocji pozytywnych, takich, jak miłość, szczęście i zadowolenie.
Na koniec, w wielu z tych badań skoncentrowano się na |konsekwencjach stanów emocjonalnych i zwracano niewiele uwagi na warunki poprzedzające („antecedents”) występowanie emocji i na charakterystyczne cechy samych emocji.




Zbliżenie


Szczęście nie jest ulubionym tematem psychologów


„Czytając prace przeglądowe poświęcone tematowi emocji w literaturze psychologicznej, odnosi się wrażenie, że psychologowie obsesyjnie badają i omawiają przykre emocje i negatywne aspekty zachowania ludzi. W jednej z takich prac przeanalizowano treść 172 podręczników psychologicznych napisanych w ciągu ubiegłych 85 lat i stwierdzono, że przykrym emocjom poświęcono dwa razy więcej miejsca niż emocjom przyjemnym (Carlson, 1966).  W drugiej pracy tego typu podano, że spośród ponad 500 artykułów opublikowanych w czasopismach w latach 1935 - 1965, a dotyczących emocji, prawie 80% odnosiło się do przykrych emocji (Lindauer, 1968). W obu tych pracach pominięto materiał z zakresu psychopatologii - tak więc zaabsorbowanie psychologów przykrymi emocjami jest prawdopodobnie jeszcze większe niżby to wynikało z tych danych.
Ze stwierdzeniami tymi w drastyczny sposób kontrastują dane dotyczące dzieł literackich; dane te wyraźnie świadczą o preferencji przyjemnych, pozytywnych emocji. Dokładna analiza 18 standardowych zbiorów sztuk teatralnych, powieści, poezji i cytatów wykazała, że spośród wszystkich wzmianek o emocjach prawie ? (7303 z 10519) dotyczyło |przyjemnych emocji.
Spośród dwunastu najczęściej wymienianych emocji - dziesięć było przyjemnych (Lindauer, 1968). Strach, który w dziełach literackich występuje jedynie w 4% wzmianek o emocjach, jest jedną z najczęściej wspominanych emocji w pracach psychologicznych.
W jaki sposób można wytłumaczyć tę rozbieżność w sposobie patrzenia? Czy psychologowie przedstawiają rzeczy takimi, jakie są, podczas gdy literaci pozwalają nam uciec w świat, do którego prawdziwe życie nigdy nie może być podobne? Czy też psychologowie są nadmiernie zaabsorbowani „problemami” oraz zachowaniami, które trzeba modyfikować i korygować? Czy może tę bardziej zwyczajną, przyjemną, pozytywną stronę życia przyjmują oni po prostu za coś „oczywistego”? Czy istnieje jakieś bardziej zadowalające wyjaśnienie? Czy |ty wolisz czytać w gazetach i czasopismach materiały dotyczące tego co złe, grzeszne, co wiąże się z przemocą i negatywnymi doznaniami emocjonalnymi, czy też przeciwnie? Gdybyś ty był psychologiem, to czy wolałbyś badać pozytywne formy zachowania społecznego, czy też społeczne „problemy”, konflikty interpersonalne oraz patologię osobowości”?




Jak spostrzegamy
emocje u innych?




Sygnały behawioralne. Chociaż nigdy nie możemy bezpośrednio obserwować uczuć innej osoby, to jednak często dokonujemy ich oceny, jak wtedy, gdy mówimy: „Sprawiał wrażenie rozgniewanego, jak nigdy” lub „Ona wydaje się dziś taka smutna”.
W jaki sposób dochodzimy do takich klasyfikacji stanów emocjonalnych?  Moglibyśmy, oczywiście po prostu zapytać ludzi, co czują (zakładając, że ich odpowiedź będzie prawdziwa i dokładna). Jednakże, jak przekonaliśmy się już w Rozdziale 4, często posługujemy się |niewerbalnymi zachowaniami ludzi (np. ich wyrazem twarzy i ruchami ciała) jako wiarygodnymi sygnałami emocji, jakich doświadczają (ryc. 9.2). „Spojrzenie miłosne” komunikuje równie wiele uczuć (jeśli nie więcej), jak słowne zapewnienia o miłości.
Wykrywanie i interpretowanie niewerbalnych sygnałów o stanach emocjonalnych innych ludzi wymaga raczej subtelnej percepcji; są to umiejętności, których dość trudno jest się nauczyć. Społeczeństwa, które hamują silne przejawy emocji u jednostek, muszą kształtować konwencjonalne, zrytualizowane formy zachowania, obowiązujące w powtarzających się, naładowanych emocjonalnie sytuacjach, takich jak śluby i pogrzeby.  Rozpoznanie odpowiednich sygnałów niewerbalnych nie tylko prowadzi do właściwej reakcji zewnętrznej, lecz może również determinować doznanie emocjonalne. Dziecko może zatem nauczyć się doznawania smutku na pogrzebie obserwując po prostu niewerbalne reakcje dorosłych. Zjawisko to uchwycił Tołstoj w odpowiadaniu „Śmierć Iwana Iljicza” (1886), w którym opisuje zachowanie człowieka uczestniczącego w stypie po śmierci bliskiego znajomego.


„Piotr Iwanowicz wiedział, że podobnie jak należało przeżegnać się w tym pokoju, tak samo było trzeba uścisnąć rękę (wdowy), spojrzeć i powiedzieć: 
„Wierz... mi...” Uczynił więc to wszystko, a gdy to zrobił, poczuł, że pożądany rezultat został osiągnięty, że zarówno on, jak i ona, byli wzruszeni”.


„Zwierzę” w tobie. Pierwszym człowiekiem, który położył nacisk na zachowanie i ekspresję emocji, był Karol Darwin. W swej książce z 1872 roku „The expresion of the emotions in man and animals” (O wyrazie uczuć u człowieka i zwierząt) wysunął tezę, że wzorce emocjonalne są w dużej mierze dziedzicznymi, wrodzonymi reakcjami, które były użyteczne biologicznie w trakcie ewolucji. Na przykład zwierzęta, które przygotowują się do odparcia napaści, obnażają zęby, warczą i jeżą sierść. Jeśli takie demonstracje skutecznie odstraszają napastnika, to oczywiście miały one adaptacyjne znaczenie dla utrzymania się przy życiu. Pozostałości tego zachowania możemy zaobserwować u niektórych ludzi, którzy uśmiechają się szyderczo i zgrzytają zębami wtedy, gdy odczuwają wobec kogoś wrogość.
W jakim stopniu przejawy emocji są wrodzone (jak twierdził Darwin), a w jakiej mierze wchodzą tu w grę czynniki uczenia się społecznego?




* * *



Ryc. 9.2. Podczas pożaru szalejącego w szesnastopiętrowym biurowcu w Nowym Orleanie widzowie obserwują z niedowierzaniem i zgrozą, jak czworo ludzi skacze z wysokości na bruk, aby uniknąć płomieni.


* * *





Dla poparcia swego stanowiska Darwin wskazał na fakt, że na twarzach dzieci niewidomych i dzieci widzących w tych samych sytuacjach występują te same przejawy emocji. Jednakże nie możemy wykluczyć uczenia się w tym wypadku, ponieważ niewidome dzieci mogły być nagradzane za prawidłową reakcję i poprawiane, gdy wykazywały reakcję niewłaściwą. Darwin powoływał się także na uniwersalność przejawów emocji, zwłaszcza u niemowląt.
Ekman i Friesen (1969) potwierdzili uniwersalność różnych typów ekspresji we wszystkich kulturach, stwierdzili oni jednak, że emocje związane z określonymi sposobami ekspresji (a zatem i ich interpretacja) różnią się ogromnie w poszczególnych kulturach.


Twoja twarz jest jak otwarta księga... Nawet w jednej kulturze określona reakcja niewerbalna może odzwierciedlać jedną z wielu różnych emocji, jak przekonaliśmy się już na przykładzie płaczu. Jeśli nie istnieje jednoznaczny związek między wyrazem twarzy czy ekspresją behawioralną a określoną emocją, to zachowanie niewerbalne nie stanowi zbyt rzetelnego systemu komunikowania się. 
Wyniki wielu wcześniejszych badań nad odczytywaniem emocji z wyrazu twarzy potwierdzają na ogół ten pogląd.
Badanych poproszono, aby przyglądali się obrazkom przedstawiającym twarze ludzkie i określali emocje, jakie ich zdaniem wyrażają te twarze. Wbrew oczekiwaniom eksperymentatorów oceny poszczególnych osób badanych różniły się znacznie, co wskazywało, że ludzie nie potrafią zbyt dokładnie oceniać emocji. Jednakże badania Schlosberga (1952) wykazały, że wyrazy twarzy można określać za pomocą dwóch wymiarów: przyjemność - przykrość i odrzucenie - uwaga, uzyskując dość wysoki stopień zgodności między oceniającymi (ryc. 9.3). Później Schlosberg (1954) wykrył trzeci wymiar w wyrazach twarzy (intensywność, czyli poziom aktywacji) i opracował trójwymiarowy model emocji, który wywarł wpływ na wiele późniejszych badań.
Niedawne eksperymenty wykazały, że badani oceniający wyrazy twarzy przy zastosowaniu tego modelu wykazują bardzo dużą dokładność i zgodność (90% lub więcej) przy ocenianiu podstawowych, prostych emocji, takich jak strach, zdziwienie, szczęście, gniew, smutek, wstręt i zainteresowanie, a ponadto zgodność taka ma charakter międzykulturowy (Ekman, Sorenson, Friesen, 1969).




* * *



Ryc. 9.3. Są to niektóre spośród zdjęć użytych przez Schlosberga, rozmieszczone względem dwóch osi: przyjemność - przykrość oraz odrzucenie - uwaga. Jak widzimy na powyższym schemacie, uwzględnienie obu tych osi oraz odległość od punktu centralnego pozwala określić każde zdjęcie pod względem jakości oraz intensywności przedstawionych na nim doznań. Intensywne emocje umieszczono bliżej obwodu, bardziej neutralne - bliżej środka.


* * *





Zdolność dokładnego identyfikowania różnych emocji wzrasta wyraźnie z wiekiem, co wykazały badania nad dziećmi w Stanach Zjednoczonych i Francji (Izard, 1971).
Jednakże ludzie nie zawsze wyrażają takie czyste, proste emocje, jak szczęście i gniew. Często doświadczają oni złożonych czy mieszanych emocji, takich jak zakłopotanie, frustracja czy zazdrość, a ekspresja niewerbalna tych emocji jest raczej niejednoznaczna. W jaki sposób ludzie określają dokładnie te stany emocjonalne, skoro sygnały, aczkolwiek silne, są tak złożone? Jedno z rozwiązań polega na wnioskowaniu o emocji kontekstu sytuacyjnego. Jeśli więc widzimy kobietę płaczącą, gdy wita syna, gdy powrócił szczęśliwie z wojny, to powiemy, że jest ona szczęśliwa, uradowana i odczuwa ogromną ulgę. Gdybyśmy natomiast zobaczyli ją płaczącą po usłyszeniu wiadomości, że jej syn zginął, to określilibyśmy jej emocję jako smutek i rozpacz.
Takie opieranie się na sygnałach sytuacyjnych, gdy przejawy emocji są raczej niejednoznaczne, zostało zademonstrowane eksperymentalnie (Munn, 1940). Badanym pokazywano fotografię wziętą z magazynu „Life” i proszono ich, aby oceniali emocje doznawane przez osobę przedstawioną na tej fotografii. Z niektórych odbitek tej fotografii wycięto tło, tak że była widoczna jedynie dana osoba. Munn stwierdził, że badani określali emocje znacznie dokładniej, a ponadto zgodność między nimi była znacznie większa wtedy, gdy fotografie zawierały sygnały sytuacyjne w postaci tła. Doniosłe znaczenie tych sygnałów podkreślał także Frijda (1970), który twierdził, że emocje |zawsze interpretuje się w kategoriach ich związku z sytuacją.  Zauważył on, że badani, którzy oceniali wyrazy twarzy, rzadko posługiwali się prostymi słowami, takimi jak „rozgniewany” czy „szczęśliwy”. Zamiast tego zwykle opisywali jakąś sytuację, o której wnioskowali na podstawie ocenianego wyrazu twarzy - na przykład: „Ktoś opowiedział jej jakąś wstrętną historyjkę” lub „Ona zdaje się patrzeć na malutkiego kotka”.




Jak spostrzegamy
emocje u siebie?




Ze wszystkich opisanych powyżej powodów, próba zidentyfikowania emocji, której doświadcza ktoś inny, może często być złożonym procesem. Główną przeszkodą jest to, że nie możemy obserwować co się dzieje „wewnątrz” drugiej osoby i musimy opierać się jedynie na sygnałach zewnętrznych.  Jednakże w wypadku naszych własnych emocji mamy dostęp do ukrytego wnętrza, a zatem powinniśmy dokładnie wiedzieć wszystko o |naszych emocjach. Czy tak jest istotnie?


Komponent fizjologiczny. Podejmowano różne próby zmierzające do ustalenia związku między emocjami a procesami fizjologicznymi lub nawet do całkowitego wyjaśnienia emocji w tych kategoriach.


„Teoria Jamesa-Langego”. Bez wątpienia zawsze wtedy, gdy doświadczyłeś silnej emocji, miałeś uczucie, że jesteś wewnętrznie rozbity z powodu różnych zmian fizjologicznych. Gdyby ktoś zapytał cię, w jaki sposób powstaje ten stan wewnętrznego rozbicia, to prawdopodobnie odpowiedziałbyś, że twoje odczucie emocji (np. „ja się boję”) wywołuje następujące po nim fizjologiczne przejawy tej emocji (np. „a więc drżę”). Większość ludzi zgodziłaby się z twoim stwierdzeniem - ale nie William James.
W roku 1884 wysunął on tezę, że kolejność występowania odczucia emocji i zmian fizjologicznych jest |odwrotna w stosunku do „zdroworozsądkowej” kolejności, jaką przed chwilą sformułowałeś; innymi słowy, nasze odczucia zmian zachodzących w organizmie |są emocją (James, 1884), a posługując się współczesną terminologią można by powiedzieć, że „zmiany te stanowią proces pośredniczący”. Inaczej mówiąc, James sadził, że poznawczo doświadczane aspekty emocji są |wynikiem wzbudzenia fizjologicznego, a nie na odwrót.  Posługując się jego klasycznym przykładem, możemy stwierdzić, że widok niedźwiedzia wywołuje stan wewnętrznego wzbudzenia, który następnie spostrzega się jako strach.
Duński uczony pod nazwiskiem Lange zaprezentował podobną koncepcję mniej więcej w tym samym czasie i dlatego teoria ta jest znana jako |teoria |emocji |Jamesa-|Langego. Jej doniosłość polega na tym, iż jako pierwsza postulowała, że procesy trzewne („visceral”) wywierają pewien wpływ na zachowanie emocjonalne i w ten sposób poddała w wątpliwość pogląd, że procesy psychiczne rządzą reakcjami organizmu.


„Cannon daje ognia”. Było wielu ludzi, którzy na teorię Jamesa Langego zareagowali okrzykiem „To po prostu niemożliwe!”. Jednym z nich był fizjolog Walter Cannon. (Cannon oznacza po angielsku „działo” - przyp.  tłum.). Jego krytyka (1929) była najpoważniejszym atakiem przeciw tej teorii i wywarła duży wpływ na wiele późniejszych badań nad emocjami. Z teorii Jamesa-Langego wynika, że aby dana osoba doświadczała różnych emocji, muszą u niej występować dające się rozróżnić zespoły zmian fizjologicznych, które służą jej za sygnały. Cannon zakwestionował tę ideę przytaczając materiał dowodowy, świadczący, iż: 1) różnym emocjom towarzyszy |ten |sam stan narządów wewnętrznych, 2) narządy wewnętrzne są zbyt mało wrażliwe, aby zmiany w nich mogły być zauważone i wykorzystane jako sygnały, i wreszcie 3) zmiany w narządach wewnętrznych zachodzą zbyt powoli, aby mogły być źródłem odczuć emocjonalnych, które zmieniają się bardzo szybko. Wskazał on także na wyniki badań Maranona (1924), które były sprzeczne z teorią Jamesa-Langego; Maranon stwierdził, iż sztuczna stymulacja narządów wewnętrznych dokonywana za pomocą iniekcji adrenaliny wywoływała u danej osoby jedynie „zimne”, „pozorne” emocje (na przykład: 
„czuję się, |jak |gdybym się bała”), a nie prawdziwe emocje.


„Ośrodki” emocji”. Częściowo pod wpływem krytyki Cannona wielu badaczy zaczęło poszukiwać innych systemów fizjologicznych, które mogłyby być siedliskiem emocji. Ogólnie biorąc, wystąpiło zwiększone zainteresowanie ośrodkowymi mechanizmami nerwowymi.
Jedna z najbardziej popularnych teorii lokalizowała ośrodek kontrolujący emocje w układzie limbicznym, czyli rąbkowym (który obejmuje najstarsze części kory mózgowej oraz części wzgórza i podwzgórza). Jak przekonaliśmy się w Rozdziale 2, badacze stwierdzili, iż stymulacja i lezje różnych części układu limbicznego wywołują zmiany w reakcjach emocjonalnych.
Fakt, że układ limbiczny składa się z pierwotnych części mózgu, prawdopodobnie nadał wiarygodność idei, iż zlokalizowane są tam „pierwotne” emocje. Jednakże, jak zauważył Pribram (1960), te rzekomo stare filogenetycznie struktury osiągnęły najwyższy stopień swego rozwoju ewolucyjnego u ludzi, podobnie jak zwane „wyższe” struktury korowe, a zatem nie można ich nadal uważać za rzeczywiście pierwotne. Co więcej, badania wykazały, że układ limbiczny odgrywa rolę nie tylko w przebiegu emocji, lecz także w przebiegu funkcji poznawczych (na przykład lezje i drażnienie struktur limbicznych wpływają na sprawność rozwiązywania problemów).  Ponadto stymulacja i lezje części mózgu poza układem limbicznym również wywołują zmiany emocjonalne (Pribram, 1967). Stwierdzenia te zasugerowałyby, że emocje (a także zachowanie poznawcze) są pod kontrolą wielu różnych współdziałających ze sobą części mózgu, a nie jakiegoś jednego „ośrodka emocji”.


„Układ wydzielania wewnętrznego a emocje”. Fizjologiczny komponent emocji jest pod silnym wpływem czynności różnych |gruczołów |wydzielania |wewnętrznego. Gruczoły te wydzielają wytwarzane przez siebie substancje bezpośrednio do krwiobiegu, dzięki czemu są one roznoszone po całym ciele i wpływają na każdą część organizmu. Te substancje chemiczne noszą nazwę |hormonów (od greckiego słowa oznaczającego „pobudzam”). Jedną z funkcji gruczołów wydzielania wewnętrznego jest koordynacja procesów zachodzących w organizmie. Na przykład, w wypadkach nagłego strachu we krwi zaczyna krążyć pewien hormon, który wywołuje tak różnorodne procesy, jak rozszerzenie się źrenicy oka, zwężenie naczyń krwionośnych w ściance żołądka oraz wzrost szybkości krzepnięcia krwi w obecności powietrza.
Ośrodek nerwowy reguluje działanie układu wydzielania wewnętrznego znajduje się niewątpliwie w podwzgórzu. |Przysadka |mózgowa, niewielka struktura znajdująca się u spodu podwzgórza, wydziela szereg różnych hormonów, które wpływają na różne funkcje związane z rozwojem oraz z utrzymywaniem homeostazy. Przysadka mózgowa wytwarza także różne hormony „pośredniczące”, które działają wprost na inne gruczoły wydzielania wewnętrznego, takie jak na przykład |gruczoły |nadnerczy (gruczoł ten znajduje się na górnym biegunie nerki). Pod wpływem pobudzenia gruczoły nadnerczy wydzielają dwa hormony, |adrenalinę i |noradrenalinę (zwane także odpowiednio |epinefryną i |norepinefryną). Badania wykazały, że oba te hormony zdają się być związane z różnymi emocjami.


„Wczesne badania wykazały, że adrenalina jest ogólnie biorąc związana ze 
strachem, natomiast zarówno noradrenalina, jak i adrenalina występują w 
czasie reakcji gniewu. W organizmach zwierząt, które są bojaźliwe i 
utrzymują się przy życiu dzięki temu, że potrafią uciec od 
niebezpieczeństwa (np. króliki), wydzielana jest przede wszystkim 
adrenalina, podczas gdy u zwierząt, które zwykle atakują (np. lwy), 
wydzielane są również duże ilości noradrenaliny 
(Funkenstein, 1955).
W innych badaniach stwierdzono, że studenci, którzy otrzymali do 
wykonania frustrujące zadanie, przejawiali jedną z trzech emocji: strach, 
gniew skierowany na zewnątrz przeciw eksperymentatorom lub gniew skierowany 
„do wewnątrz” (obwinianie siebie samego). U studentów, którzy wyrażali 
gniew wobec otoczenia, stwierdzono na ogół wydzielanie noradrenaliny, 
podczas gdy u tych, którzy okazywali strach lub winili siebie, wydzielana 
była w większej ilości adrenalina (Funkenstein, King i Drolette, 1957). W 
nowszych badaniach nad układem wydzielania wewnętrznego wykazano, że w 
różnych warunkach stresowych następuje zarówno ogólny wzrost ilości 
wydzielanej adrenaliny i noradrenaliny, a także występują różnice między 
wydzielanymi ilościami powyższych substancji” 
(Brady, 1967).


Noradrenalina nie tylko jest wydzielana do krwiobiegu, lecz ponadto stwierdza się ją także w mózgu. Istnieją dane sugerujące, że środki farmakologiczne, które wywołują zmiany nastroju, powodują ten efekt w wyniku swego wpływu na gromadzenie się „noradrenaliny mózgowej” („brain norepinephryne”). 



Środki, które zwiększają akumulację noradrenaliny, wywołują euforię i hiperaktywność, podczas gdy środki, które redukują ilość noradrenaliny, wywołują depresję (Kety, 1967a).


„Fizjologiczne zróżnicowanie emocji”. Niektóre badania, na przykład poprzednio cytowane badania nad hormonami nadnerczy, wykazały istnienie związku miedzy emocjami a reakcjami fizjologicznymi. Podobnie Wolf i Wolff (1947) obserwowali dwa różne typy aktywności żołądka u pewnego pacjenta - jeden z nich występował wtedy, gdy pacjent był przestraszony, drugi zaś wtedy, gdy był on rozgniewany (ryc. 9.5). Jednakże, jak dotychczas, materiał dowodowy świadczący o zróżnicowaniu fizjologicznym nie jest całkowicie przekonujący. Odrębne wzorce reakcji fizjologicznych stwierdzono jedynie w wypadku prostych, silnych emocji, takich jak gniew i strach. U tych samych osób mogą występować odmienne wzorce wzbudzenia fizjologicznego, w zależności od tego, czy osoby te skupiają uwagę na czynnikach wewnętrznych, czy na czynnikach sytuacyjnych. Niektórzy badacze (np. Duffy, 1962) argumentują, że różnice fizjologiczne odpowiadają jedynie różnym |wielkościom tego samego ogólnego, niezróżnicowanego wzbudzenia. Aczkolwiek intensywność jest z pewnością jednym z aspektów emocji, to jednak podejście to wydaje się raczej ograniczone, ponieważ a) można być fizjologicznie pobudzonym, a jednak nie odczuwać emocji (np.  wtedy, gdy intensywnie trenujesz) oraz b) różnice między intensywnością wzbudzenia nie wytłumaczyłyby jeszcze |jakościowych różnic między doznaniami różnych emocji. Jeśli czujesz, że serce wali i odczuwasz skurcze w żołądku, to skąd wiesz, czy się boisz, czy jesteś podniecony, rozgniewany, czy też zakochany do szaleństwa?




* * *



Ryc. 9.5. Wrogość A Fizjologia Przewodu Pokarmowego. Wykres ten sporządzono na podstawie obserwacji przeprowadzonych u pacjenta, któremu otwarto żołądek dla celów naukowych. Pacjent ten początkowo odczuwał urazę i wrogość w wyniku pewnego poniżającego doznania. Gdy mówił o nim, wówczas jego wrogość wzrastała, a w żołądku wydzielała się większa ilość kwasu i śluzówka była bardziej zaczerwieniona. W miarę następowania zmian w jego nastroju, pojawiały się także odpowiednie zmiany fizjologiczne.


* * *





Nawet gdyby badacze wyposażeni w niezwykle czułe urządzenia rejestrujące i wzmacniające potrafili w końcu zidentyfikować wszystkie fizjologiczne korelaty każdej z emocji, to nie wyjaśniliby jeszcze, dlaczego ludzie |doznają właśnie tego, co czują, gdy są pobudzeni fizjologicznie.


Komponent poznawczy. Jeśli emocji nie da się sprowadzić do sygnałów informujących o aktywności fizjologicznej, to cóż można powiedzieć o spostrzeżeniach, oczekiwaniach, interpretacjach i innych tego rodzaju procesach poznawczych? Jaką rolę odgrywają one w emocji?


„Przepis na emocję: weź jedną część wnętrzności i jedną część poznania”.  Jak przekonaliśmy się w Rozdziale 6, informacja dostarczona przez napływające bodźce nie stanowi jeszcze wystarczającego wyjaśnienia, dlaczego widzimy rzeczy w taki a nie inny sposób. Jedynie dzięki poznawczej organizacji i interpretacji bodźców, które oddziałują na siatkówkę, możemy pojąć, „co się tam dzieje”. Podobnie współcześni psychologowie są przekonani, że emocja nie jest zdeterminowana jedynie przez reakcje fizjologiczne, lecz wymaga poznawczej oceny sytuacji bodźcowej.
Jedna z teorii głosi, że reakcje fizjologiczne (w zasadzie niezróżnicowane) determinują |intensywność emocji; natomiast dla określenia jej |jakości - jaka to jest emocja - ludzie wykorzystują istotne emocjonalnie dane poznawcze, opierając się na sygnałach odbieranych ze swego bezpośredniego otoczenia.


„Teoria ta była sprawdzona w pomysłowym eksperymencie, w którym u osób badanych (mężczyzn) wywołano przekonanie, że eksperymentator bada wpływ nowej mieszanki witaminowej na funkcjonowanie wzroku. Badani otrzymywali zastrzyk, a następnie udawali się do poczekalni - rzekomo po to, aby czekać na wystąpienie efektu zastrzyku. W wypadku badanych z grupy eksperymentalnej zastrzyk w rzeczywistości zawierał adrenalinę, która zwykle powoduje przyspieszenie tempa pracy serca, tempa oddychania, drżenie i niekiedy wzmożony napływ krwi do twarzy. W grupie kontrolnej badani otrzymywali zastrzyk placebo, które bezpośrednio nie powodowało żadnego fizjologicznego wzbudzenia.
Eksperymentatorzy manipulowali także poznawczą oceną stanu organizmu przez osoby badane. Pierwszej grupie osób badanych („adreno-poinformowani”) powiedziano o „ubocznych skutkach” zastrzyku; mieli więc oni właściwe wyjaśnienie swego pobudzenia. Drugiej grupie („adreno-nie poinformowani”) powiedziano, że nie będzie żadnych skutków ubocznych, podczas gdy trzeciej grupie („adreno-błędnie poinformowani”) powiedziano, że skutkami ubocznymi będzie drętwienie, swędzenie i ból głowy. Tak więc ostatnie dwie grupy były pozbawione właściwego wyjaśnienia swego stanu pobudzenia. Przewidywano, że badani z tych grup będą aktywnie poszukiwać w swym bezpośrednim otoczeniu właściwych wyjaśnień tego, co czują, a zatem będą bardziej podatni na wpływ wszelkich występujących w nim bodźców.
Każdy z badanych studentów zastawał w poczekalni innego studenta, czekającego rzekomo, podobnie jak on, na wystąpienie działania zastrzyku. W rzeczywistości był to pomocnik eksperymentatora, który wkrótce zaczynał zachowywać się w sposób „emocjonalny”. Wobec połowy osób badanych demonstrował on swe rozbawienie: bazgrał, rzucał samolociki z papieru, kręcił hula-hoop itd. W obecności pozostałych osób badanych stawał się coraz bardziej zirytowany i rozgniewany z powodu kwestionariusza, który eksperymentator dał im do wypełnienia, aż w końcu darł go i wypadał z pokoju. W obu tych sytuacjach eksperymentatorzy obserwowali przez jednokierunkową szybę osobę badaną i oceniali, w jakim stopniu jej zachowanie stawało się euforyczne lub gniewne. Badani wypełniali również kwestionariusze, w których opisywali własny stan emocjonalny.
Osoby badane w tych dwóch grupach, które nie znały właściwego wyjaśnienia swego pobudzenia, czuły się uszczęśliwione, gdy pomocnik eksperymentatora zachowywał się figlarnie, były zaś mniej szczęśliwe, gdy udawał on rozgniewanego. Przypuszczalnie spostrzegane zachowanie i nastrój pomocnika eksperymentatora wpływały na ich ocenę własnego nie wyjaśnionego pobudzenia. Natomiast właściwie poinformowani badani, którzy znali już odpowiednie wyjaśnienie swego pobudzenia fizjologicznego, nie byli podatni na nastrój pomocnika i efekty te u nich nie wystąpiły. Podobnie u badanych z grupy kontrolnej, u których nie występowało żadne fizjologiczne pobudzenie, lecz otrzymywali te same społeczne dane poznawcze, różnice te nie wystąpiły” (Schachter i Singer, 1962 - tabela; Schachter, 1971).


Ocena Własnego Systemu Emocjonalnego. Wskaźniki otrzymano odejmując oceny „gniewu” od ocen „rozradowania” - im wyższy dodatni wskaźnik, tym bardziej pozytywne odczucia emocjonalne. Zakres ocen od +4,0 do -4,0.


Emocja modelowana przez pomocnika eksperymentatora
Grupy badane: a) „Euforia”; b) „Gniew”
Adreno-błędnie poinformowani: a) +1,9; b) nie sprawdzano
Adreno-nie poinformowani: a) +1,8; b) +1,4
Adreno-poinformowani: a) +1,0; b)+1,9
Placebo - grupa kontrolna: a) +1,6; b) +1,6
(Adoptowane z Schachtera i Singera, 1962)


Wyniki te zdają się potwierdzać teorię, że jakość stanów emocjonalnych jest zdeterminowana przez czynniki poznawcze. Osoby badane znajdujące sie w stanie pobudzenia fizjologicznego (którego nie potrafły wyjaśnić) określały swoje emocje w różny sposób, zależnie od poznawczych aspektów sytuacji.  Wyniki takie podważają bezpośrednio wcześniejszą teorię emocji, która sugerowała istnienie związku przyczynowego między wzbudzeniem fizjologicznym a doświadczeniem poznawczym. Jednakże metodologiczna rzetelność opisanych powyżej badań również została podważona.




Zbliżenie


Krytyczna analiza eksperymentu Schachtera i Singera 


„Eksperyment opracowany przez Stanleya Schachtera i Jerome’a Singera w celu sprawdzenia ich koncepcji dwuczynnikowego procesu emocji jest badaniem niezmiernie doniosłym. Po raz pierwszy poddali oni niejasne pojęcie „emocji” badaniu eksperymentalnemu. Ponadto podejście ich przyczyniło się do wzmożenia wzajemnych oddziaływań pomiędzy ścisłymi („hard”) i mniej rygorystycznymi („soft”) metodami badania zjawisk psychologicznych. Są oni pionierami, jeśli chodzi o połączenie fizjologii, procesów poznawczych i psychologii społecznej w badaniach nad naturą emocji.
Teoria stanowiąca podstawę tych badań wywarła duży wpływ na ukształtowanie się nowych idei dotyczących procesu, dzięki któremu ludzie wyjaśniają sobie przyczyny lęku, strachu i innych emocji odgrywających centralną rolę w zachowaniu „neurotycznym”. W istocie, na teorii tej oparto nowy rodzaj terapii.
Jednakże mimo doniosłości teorii emocji Schachtera i Singera, ich eksperyment - chociaż pomysłowy - |nie jest wystarczającym testem tej teorii. Być może dlatego, że ludzie chętnie zaakceptowali uzyskane przez nich wyniki, a także z tego powodu, iż plan eksperymentu był tak złożony i kosztowny w realizacji, dopiero niedawno podjęto próbę powtórzenia ich badań (Marshall, 1976). Fakt, że Marshall nie udało się uzyskać powtórnie rezultatów otrzymanych przez Schachtera i Singera, zmusza nas do dokładniejszego przeanalizowania oryginalnego badania; gdy uczynimy to, stanie się oczywiste, że było w nim kilka niedociągnięć”.


„Sposób opracowania i interpretacji danych. Średnie różnice między poszczególnymi grupami, chociaż istote statystycznie, nie były duże. Stały się one istotne dopiero wtedy, gdy z grupy „placebo” i z grupy „adreno-nie poinformowanych” wyeliminowano kilku badanych (których określono jako tych, którzy „pobudzili się sami” lub „poinformowali się sami”). Zamiast przedstawić osobno oceny rozradowania i oceny gniewu, badacze |odejmowali jedną od drugiej uzyskując w ten sposób złożoną miarę |wględnej |emocji (większego lub mniejszego rozradowania), zamiast absolutnej miary „euforii” czy „gniewu”. Doprowadziło to do tego, że niektórych badanych określono jako „bardziej gniewnych” niż inni, podczas gdy w rzeczywistości byli oni jedynie „mniej szczęśliwi”. Największa różnica pod względem jakości doznań emocjonalnych pomiędzy warunkami mającymi wywołać gniew bądź euforię wystąpiła nie w grupie „adreno-nie poinformowanych”, lecz w grupie „adreno-poinformowanych”.


„Problemy metodologiczne. Adrenalina odziaływuje w różny sposób na różnych ludzi - czas wystąpienia i trwania objawów oraz ich intensywność zależą od ciężaru ciała i innych czynników. Badacze ani nie kontrolowali tej zmiennej, ani nie byli w stanie ocenić wielkości jej wpływu. Dawka była stała, pomimo różnic pod względem wagi ciała; nie próbowano ustalić, czy wzbudzenie utrzymywało się jeszcze wtedy, gdy współpracownik eksperymentatora zaczynał swe działanie. Miara fizjologiczna (szybkość tętna, po okresie aktywności, określona przez liczenie uderzeń pulsu wyczuwanych za pomocą ręki) nie pozwalała oddzielić wpływu adrenaliny od wpływu samej aktywności fizycznej.
Inna grupa problemów metodologicznych dotyczy sygnałów poznawczych dostarczonych przez współpracowników eksperymentatora. Rozgniewany współpracownik dostarczył dobrego uzasadnienia swego podniecenia (wtrącano się w jego sprawy intymne, był tym zakłopotany); szczęśliwy współpracownik nie oferował żadnego. Toteż jego demonstracja radosnych emocji nie dawała żadnego poznawczego |wyjaśnienia pobudzenia, jakie odczuwał badany; demonstracja ta mogła być tylko źródłem „zarażenia emocjonalnego” („emotional contagion”) czy naśladowania. Ponadto rozgniewany współpracownik wypadł z pokoju, wskutek czego zbity z tropu badany stawał przed perspektywą, że sam będzie musiał stawić czoła eksperymentatorowi - i prawdopodobnie lękał się, aby ten nie urządził mu awantury. Ponieważ nie ustalono, w jaki sposób współpracownicy byli spostrzegani przez każdego z badanych, nie możemy określić, czy byli oni oceniani jako „rozgniewani”, „w euforii”, „rozsądni” czy „dziwaczni”. Ponadto nie określano nastroju badanego przed podaniem środka farmakologicznego. Początkowe różnice nastroju badanych osób mogły zatem nakładać się na działanie tego środka w sposób niemożliwy do ustalenia.
Te i inne zarzuty mogą oznaczać albo to, że wnioski autorów mogłyby być bardziej zdecydowane, niż są (gdyby usunąć te i inne źródła zakłóceń) lub też, co bardziej prawdopodobne, są one zbyt uogólnione i może nawet fałszywe. Teoria ta, mimo że możemy odczuwać pokusę zaakceptowania jej, nadal oczekuje na definitywną weryfikację”.


„Teorie oceny poznawczej”. Aczkolwiek wielu badaczy zainteresowało się rolą procesów poznawczych w różnorodnych reakcjach (m. in. emocjonalnych), to jednak niewielu próbowało dociekać dynamiki takich procesów. Co oznacza stwierdzenie, że dane poznawcze determinują reakcję emocjonalną? Dwoje psychologów, którzy pracowali nad tym problemem, omawia tego rodzaju dane poznawcze w kategoriach oceny.
|Ocena („appraisal”) to inaczej oszacowanie znaczenia bodźca. Jedną z pierwszych osób, które posługiwały sie tym pojęciem w teorii emocji, była Magda Arnold (1960), która zaproponowała model sekwencyjny. Pierwszym krokiem w tej sekwencji jest |percepcja, dzięki której odbierane są bodźce zewnętrzne. Następnym krokiem jest |ocena, która polega na wartościowaniu bodźców jako dobrych i korzystnych lub złych i szkodliwych. Ocena ta następnie determinuje |emocję, którą definiuje się jako odczuwaną tendencję „ku bodźcom” ocenianym jako dobre lub „od bodźców” ocenianych jako złe.  |Ekspresję emocji określa się jako układ reakcji fizjologicznych, które towarzyszą odczuwanej tendencji. Mogą one być zorganizowane tak, by sprzyjały zbliżeniu lub wycofaniu się (unikaniu). Ostatnim krokiem jest |działanie, kiedy to występuje rzeczywiste zbliżenie lub wycofanie.
Temu sposobowi ujęcia problemu bardziej złożoną postać nadał Richard Lazarus (1968). Postuluje on dwa podstawowe rodzaje procesów oceny: |ocenę |pierwotną (primary appraisal), w której określa się, czy sytuacja jest groźna, czy nie, oraz |ocenę |wtórną (secondary appraisal), która polega na szacowaniu różnych możliwych sposobów radzenia sobie ze spostrzeganym zagrożeniem.


Jeśli sytuacja jest spostrzegana jako zagrażająca, to istnieją dwie możliwe |strategie |uporania |się |z |tą |sytuacją („coping strategies”): 
a) |działanie |bezpośrednie, takie jak walka lub ucieczka, z towarzyszącymi im negatywnymi stanami emocjonalnymi oraz b) |łagodzące |przewartościowanie („benign reappraisal”), w którym dana osoba zmienia ocenę sytuacji, uznając ją za mniej groźną, przez co redukuje negatywny stan emocjonalny. Pozytywne emocje następują po ocenie sytuacji jako niezagrażającej (włączając tu łagodzące przewartościowania). Cała ta analiza kładzie nacisk na interakcję między ocenami poznawczymi a reakcjami emocjonalnymi.

Obie te teorie wysuwają argumenty przeciw koncepcji neutralnego, niezróżnicowanego wzbudzenia, któremu później nadaje się znaczenie, jak to proponował Schachter. Postulują one, że |istnieją różne wzorce reakcji fizjologicznych, lecz że reakcje takie |nie determinują ani nie powodują emocji. Przeciwnie, komponent fizjologiczny uważa się za funkcję oceny poznawczej - zwykle następuje on później, lecz w każdym razie jest w nią włączony.




Stres




Pracownicy są pod stałym naciskiem ze strony szefa wymagającego od nich lepszej pracy. Sportowcy dążą ze wszystkich sił do uzyskania lepszych wyników. Widzom udziela się podniecenie drużyn walczących o mistrzostwo.  Przyjaciele patrzą bezradnie, jak ktoś im bliski umiera powoli na raka.  Ludzie w powyższych przykładach znajdują się w bardzo różnych sytuacjach, łączy ich jednak coś wspólnego - wszyscy doznają stresu. |Stres jest niespecyficzną reakcją organizmu na wszelkie stawiane mu wymagania (Selye, 1973). Aczkolwiek przyczyny stresu są liczne i zróżnicowane i mogą być albo przyjemne (takie, jak namiętny pocałunek) albo nieprzyjemne (takie, jak utrata pracy), to wszystkie one wymagają zmiany przystosowania, czyli readaptacji. Biologiczna reakcja stresu na takie wymagania (bez względu na ich źródło) jest zawsze w zasadzie taka sama. Jak przekonamy się nieco później, reakcja ta wiąże się z działaniem różnych hormonów i przebiega w kilku fazach. Wbrew popularnym poglądom, stres nie jest jakąś straszną sytuacją, której należy unikać; jest to raczej proces wywoływany nieustannie przez całe życie danej jednostki. Bez względu na to, co robisz, zawsze będziesz stawał wobec wymagań, aby wykonywać niezbędne zadania lub przystosowywać się do zmiennych oddziaływań. Zamiast unikać stresu, musisz nauczyć się, w jaki sposób można najlepiej sobie z nim radzić.




Zbliżenie


Skrajnie silne wzbudzenie emocjonalne


„Zniekształcające oddziaływanie niezwykle silnego stresu lub euforii, zmieniających rzeczywistość spostrzeganego świata, lepiej można zilustrować cytując Szekspira i autorów współczesnych piosenek, niż podając wyniki eksperymentów laboratoryjnych”.


Nie wszyscy autorzy zgodziliby się z taką definicją stresu psychologicznego. Wielu współczesnych psychologów przyjmuje, że stres jest reakcją organizmu na tak zwaną sytuację stresową, czyli na działanie takich czynników (stresorów), które wywołują |nadmierne |obciążenie systemu samoregulacji psychologicznej i wzbudzają stan napięcia emocjonalnego.  Zgodnie z tym stanowiskiem, nie wszystkie zadania czy wymagania stawiane jednostce są stresami. Realizacja zadań czy wymagań staje się sytuacją stresową dopiero wtedy, gdy zachodzą dodatkowe okoliczności, na przykład, gdy jednostka realizuje jakieś zadania pod groźbą kary, czy też, gdy zadanie to jest nowe i bardzo złożone.
Więcej danych na temat relacji pojęcia „stres” i „wymaganie” znajdzie Czytelnik w pracy J. Reykowskiego „Funkcjonowanie osobowości w warunkach stresu psychologicznego” (1966). Tam też przedstawione są różne, najczęściej spotykane w psychologii sposoby definiowania stresu (przyp.  red. nauk.).


„Makbet w udręce mówi:


Jeśli to sztylet, co przed sobą widzę, Z zwróconą ku mej dłoni rękojeścią? Pójdź, niech cię ujmę! Nie mam cię, a jednak Ciągle cię widzę. Fatalne widziadło! Nie jesteś ty dla zmysłu dotykania, Tylko dla zmysłu widzenia dostępny? Jestżeś sztyletem tylko wyobraźni? (...) (...) Albo mój wzrok błazen Jest w porównaniu z resztą moich zmysłów, Albo jest więcej wart niż wszystkie razem. Ciągle cię widzę, a na twojej klindze I rękojeści znamiona krwi, których Pierwej nie było. Nie ma ich w istocie.  Moja to krwawa myśl jawi je oczom (Przekład Józefa Paszkowskiego. William Szekspir „Dzieła dramatyczne”. Warszawa 1980.).
William Szekspir „Makbet” - II; I


Podobnie miłosne uniesienie może wywołać zniekształcenia percepcyjne, aczkolwiek odmiennej natury:


Czy gdzieś w sercu miasta rosną krzaki bzu? Czy możesz posłuchać skowronka w jakiejś innej dzielnicy? Czy nieodparty czar promieniuje z każdych drzwi? Nie, tak jest tylko na tej ulicy, gdzie ty mieszkasz” („On the street where you live” (Na ulicy, gdzie ty mieszkasz), Copyright © 1956 by Alan Jay Lerner and Frederick Loewe. Wykorzystano za zezwoleniem Chappell and Co., Inc.)




Następstwa stresu




Niekiedy reakcja fizjologiczna organizmu na powtarzające się, intensywne wzbudzenie stresowe jest nieprzystosowawcza i szkodliwa. Pogorszenie funkcjonowania organizmu mające charakter |psychogenny (tzn. takie, które ma źródło emocjonalne) określa się trafnie jako |zaburzenie |psychosomatyczne („psyche” = „dusza”, „soma” = „ciało”). Termin ten stosuje się w odniesieniu do objawów związanych z uporczywą reakcją stresową, takich jak szybkie tętno i wysokie ciśnienie krwi, a także do rzeczywistych uszkodzeń tkanki, jakie reakcja ta może spowodować, na przykład wrzodów żołądka. Ocenia się, że mniej więcej połowa wszystkich pacjentów, którzy zgłaszają się do lekarzy, ma objawy schorzeń wywodzących się przede wszystkim z zaburzeń emocjonalnych. Co więcej, niektórzy badacze są przekonani, że |wszystkie choroby i zaburzenia mają jakieś podłoże emocjonalne. Wykazano, że czynniki emocjonalne odgrywają istotną rolę w rozwoju niektórych przypadków choroby wrzodowej, wysokiego ciśnienia krwi, nieżytu jelit, bólów krzyża, zapalenia skóry, otyłości, astmy i wielu innych schorzeń.


Destrukcyjne emocje a choroby fizyczne. Lekarze doszli ostatnio do wniosku, że „idący przebojem” ludzie interesu, którzy żyją w dużym napięciu, są szczególnie narażeni na choroby serca. Według pewnego sprawozdania, zapadają oni siedem razy częściej na chorobę wieńcową niż osoby z ogólnej populacji (Friedman i Rosenman, 1960). Wykryto kilka charakterystycznych zjawisk występujących u mężczyzn zagrożonych chorobą wieńcową. Należą do nich: poczucie, że czas nagli, poczucie nieustannych wymagań zewnętrznych oraz podejmowanie czynności kompulsywnych mających odsunąć zagrażające zło (Jenkins, Rosenman i Friedman, 1967; Freidman i Rosenman, 1974).
Często słyszymy, że „duszenie w sobie” swych uczuć jest szkodliwe dla zdrowia. Wyniki badań potwierdzają ten pogląd, przynajmniej w odniesieniu do frustracji i powstrzymywanej agresji.


„W pewnych badaniach, w których wzięło udział ponad 160 studentów obu płci, wywoływano eksperymentalnie frustrację przez zablokowanie działania zmierzającego do celu lub przez zagrożenie ego. Niektórym badanym pozwolono wyrazić agresję wywołaną tą frustracją (fizycznie, słownie lub w wyobraźni), podczas gdy innym nie dano takiej możliwości.


Rezultaty badania wykazały, że po frustrującym doświadczeniu w istotny sposób wzrosło zarówno tempo pracy serca, jak i skurczowe ciśnienie krwi.  Sposobność wyrażenia agresji fizycznie lub słownie obniżała poziom tych objawów, natomiast u badanych, którym nie pozwolono wyrazić jawnie swych silnych uczuć, fizjologiczne zmiany utrzymywały się nadal” (Hokanson i Burgess, 1962).


Zespół psychologów holenderskich zademonstrował występowanie silnych reakcji astmatycznych pod wpływem bodźców psychologicznych u pacjentek, które cierpiały na astmę od pewnego czasu.


„U jednej z pacjentek, której pokazano fotografię mężczyzny w żałobie stojącego nad grobem, co przypomniało jej o śmierci i pogrzebie ojca, wystąpił nagły spadek pojemności życiowej płuc, o czym świadczyły trudności w oddychaniu. W innym przypadku pacjentce, której, gdy była dzieckiem, matka uśmierciła ulubioną rybkę, pokazano rybę - zabawkę pływającą w słoju na ryby; nie tylko wystąpiły u niej takie same trudności w oddychaniu, lecz ponadto uległa ona ciężkiemu atakowi astmy” (Dekker i Groen, 1958).


Czynniki psychologiczne mogą także występować w chorobach, które na pierwszy rzut oka zdają się mieć źródło czysto fizyczne.


„W jednym z badań stwierdzono, że wśród tysiąca telefonistek na trzecią część tej grupy przypadło 2\3 wszystkich wypadków absencji, głównie wskutek chorób układu oddechowego. Telefonistki o najwyższych wskaźnikach absencji różniły się od tych, które miały wskaźniki najniższe, przede wszystkim cechami psychicznymi: były one bardziej drażliwe, czuły się nieszczęśliwe i sfrustrowane. W grupie tej (w porównaniu z ogółem zatrudnionych) schorzenia układu oddechowego występowały 12 razy częściej” (Hinkle, Plummer, 1952).


Aczkolwiek długotrwały stres może prowadzić do najróżniejszych poważnych zaburzeń, to jednak wystąpienia reakcji psychosomatycznych nie można przewidywać jedynie na podstawie narażenia danej jednostki na stres behawioralny. Czynniki konstytucjonalne i specyficzne rodzaje minionych doświadczeń zdaje się wpływać nie tylko na to, czy stres spowoduje reakcję psychosomatyczną, lecz również na rodzaj tej reakcji.
Jak przekonaliśmy się już wcześniej, u ludzi, którzy nauczyli się wyrażać jawnie swój gniew wobec źródła stresu, występowały odmienne reakcje fizjologiczne niż u tych osób, które reagowały strachem lub obwinianiem samego siebie. Przekonywujących dowodów na to, że czynniki fizyczne i psychologiczne mogą łącznie spowodować chorobę, dostarczyły również badania przeprowadzane na myszach.


„Myszy poddawano stresowi przez trzy dni, podając sygnały zapowiadające wstrząsy elektryczne, następnie wstrzykiwano im wirus Coxsackie B i poddawano je stresowi przez dalsze cztery dni. Ani sam stres (w pewnych grupach kontrolnych), ani też sam wirus (w innych) nie wystarczyły, by spowodować jawne wystąpienie choroby. Jedynie kombinacja obu tych czynników - stresu środowiskowego i wirusa - powodowała wystąpienie choroby” (Friedman, Ader i Glasgow, 1965).


Po dokonaniu przeglądu dostępnych danych, dotyczących czynników związanych z zachorowaniem na chorobę infekcyjną lub odparciem jej, zespół lekarzy doszedł do wniosku, że „stosunkowo subtelne czynniki psychiczne i środowiskowe zdają się wpływać na podatność na szeroki zakres czynników infekcyjnych i pasożytniczych” (Friedman i Glasgow, 1966, s. 323).




Zbliżenie


Stres wynikający z konieczności przystosowania się do zmiany


„Doktor Thomas H. Holmes i jego współpracownicy (1970) skonstruowali skalę określającą wielkość stresu mierzonego w „jednostkach zmian życiowych” (LCU - „Life Change Units”). Holmes przewiduje, że istnieje ryzyko rozwinięcia się poważnej choroby (w ciągu dwóch lat), u ludzi, którzy uzyskali w sumie ponad trzysta punktów LCU. Być może warto, abyś obliczył swój własny wskaźnik LCU”.


„Zdarzenia: Skala siły wpływu


Śmierć współmałżonka: 100
Rozwód: 73
Separacja: 65
Kara więzienia: 63
Śmierć bliskiego członka rodziny: 63
Własna choroba lub uszkodzenie ciała: 53
Małżeństwo: 50
Utrata pracy: 47
Pogodzenie się ze współmałżonkiem: 45
Odejście na emeryturę: 45
Zmiana stanu zdrowia członka rodziny: 44
Ciąża: 40
Kłopoty seksualne: 39
Pojawienie się nowego członka rodziny: 39
Reorganizacja przedsiębiorstwa: 39
Zmiana stanu finansów: 38
Śmierć bliskiego przyjaciela: 37
Zmiana kierunku pracy: 36
Zmiana częstotliwości kłótni ze współmałżonkiem: 35
Kredyt ponad 10000 dolarów: 31
Pozbawienie prawa do kredytu czy pożyczki: 30
Zmiana obowiązków w pracy: 29
Syn lub córka opuszcza dom: 29
Kłopoty z teściową: 29
Wybitne osiągnięcia osobiste: 28
Żona zaczyna lub przestaje pracować: 26
Rozpoczęcie lub zakończenie nauki szkolnej: 26
Zmiana warunków życia: 25
Zmiana nawyków osobistych: 24
Kłopoty z szefem: 23
Zmiana godzin lub warunków pracy: 20
Zmiana miejsca zamieszkania: 20
Zmiana szkoły: 20
Zmiana rozrywek: 19
Zmiana w zakresie aktywności religijnej: 19
Zmiana aktywności towarzyskiej: 18
Kredyt lub pożyczka poniżej 10000 dolarów: 17
Zmiana nawyków dotyczących snu: 16 
Zmiana liczby członków rodziny zbierających się razem: 15
Zmiana w nawykach dotyczących jedzenia: 15
Urlop: 13
Boże Narodzenie: 12
Pomniejsze naruszenie prawa): 11


Kryzysy życiowe a zdrowie. Nawet w przypadku chorób, takich jak rak czy białaczka, urazy emocjonalne we wczesnym okresie życia mogą przyczynić się do rozwoju danej choroby. Bardziej zaskakujące są dowody, że wpływ takich wczesnych urazów psychicznych może występować nie wcześniej niż dopiero po wielu latach.


„W pewnym badaniu, w którym analizowano historię wczesnych urazów psychicznych u pacjentów chorych na raka, uraz psychiczny zdefiniowano jako doświadczenie, w którym „związki emocjonalne prowadziły do cierpienia i poczucia opuszczenia”.
Stwierdzono, że wśród 450 pacjentów chorych na raka 72% (w porównaniu z tylko 10% grupie kontrolnej, w której nie było chorych na raka) miało takie doświadczenia we wczesnym okresie życia. Wysunięto przypuszczenie, że pacjenci chorzy na raka reagowali jako dzieci na te kryzysy poczuciem winy i samoobwinianiem się. W okresie młodości i we wczesnym wieku dojrzałym uczucia te zostały przytłumione, ponieważ pragnienia i energia skoncentrowały się na szkole, pracy i istotnych relacjach z innymi ludźmi, zwłaszcza z małżonkiem. Jednakże, często dopiero po 40 latach, gdy sposób życia uległ zmianie, być może w wyniku wycofania się z pracy zawodowej lub śmierci małżonka, a osoby te nie potrafiły znaleźć żadnego zastępczego źródła satysfakcji i sensu w życiu, ich poczucie winy i nieadekwatność powróciły. Pierwsze objawy raka pojawiały się zwykle w okresie od 6 miesięcy do 8 lat po tym drugim kryzysie życiowym” (LeShan, 1966).


Grupa badaczy z University of Washington School of Medicine opracowała skalę oceny stopnia przystosowania, jakiego wymagają 43 różne zmiany życiowe zarówno przyjemne jak i nieprzyjemne.


„W grupie prawie 400 osób badanych stwierdzono regularną zależność między liczbą „jednostek zmian życiowych”, obliczonych według tej skali, a poważnymi zmianami stanu zdrowia (w okresie ocenianych dziesięciu lat).  Poważna zmiana stanu zdrowia wystąpiła u 37% osób o średnich wynikach na skali kryzysów życiowych i u 70% osób z wysokimi wynikami na tejże skali.  Ponadto u osób, które zwykle nie chorowały podczas epidemii grypy, zachorowanie na grypę było bardziej prawdopodobne po poważnej zmianie życiowej” (Rahe i Holmes, 1966).




Zbliżenie


Krytyczne spojrzenie na związek między „jednostkami zmian życiowych” a 
chorobą


„Zakrojone na szeroką skalę badania, które przeprowadzili Holmes i Rahe, zwróciły uwagę na ważny związek między czynnikami psychospołecznymi a chorobą somatyczną (Holmes i Masuda, 1974; Rahe, 1974). Ze względu na teoretyczne i praktyczne implikacje ich prac musimy zachować ostrożność przy akceptowaniu uzyskanego przez nich materiału dowodowego i być wystarczająco krytycznymi w naszej ocenie rezultatów ich badań. Podajemy niektóre kwestie budzące wątpliwości:


|Metodologiczne
|1. W wielu badaniach korelowano retrospekcyjne opisy zmian życiowych z retrospekcyjnymi opisami chorób. W niektórych badaniach osoby badane jednocześnie opisywały zmiany w życiu i choroby - a wówczas cel badań był aż nadto oczywisty. |2. Kiedy zmienną zależną jest występowanie choroby w okresie po badaniu, wówczas lepszym predyktorem choroby są LCU („jednostki zmian życiowych”) z poprzednich sześciu miesięcy niż LCU z poprzednich dwóch lat, jak to było we wcześniejszych badaniach. |3. Korelacje są na ogół dość niskie, choć istotne statystycznie dla dużych prób. |4. Niektóre zmiany życiowe (takie, jak zmiany dotyczące jedzenia i snu) mogą być wstępnymi objawami choroby, a wówczas nie niebyły one niezależne od przewidywanej zmiennej.


|Teoretyczne
|1. Nie podaje się żadnych konkretnych mechanizmów biologicznych tego związku. |2. Miara LCU może być lepszym predyktorem „zachowania polegającego na poszukiwaniu leczenia” („treatment-seeking behavior”) niż rzeczywistej choroby. |3. Przyczyną stresu może być także brak zmiany, gdy oczekuje się na nią, jak w przypadku oczekiwanego awansu lub przewidywanej prośby o randkę. |4. Nie uwzględnia się szerszego kontekstu, w którym zachodzą zmiany: kontaktów społecznych, zdolności uporania się ze stresem, ustalonych sposobów radzenia sobie z takimi zmianami. |5. Jakie są różnice między zmianami pozytywnymi i negatywnymi pod względem sposobu ich interpretowania przez daną osobę oraz późniejszej reakcji w postaci choroby? |6. Zapewne zarówno zmiany życiowe, jak i choroba, wiążą się z utratą bliskich kontaktów społecznych, co jest ważnym procesem pośredniczącym” (Według Cohena, 1975).


Psychika jako lekarstwo na schorzenia fizyczne. Wielu lekarzy od dawna zdawało sobie sprawę, że nawet wtedy, gdy objawy choroby wynikają przede wszystkim z przyczyn fizycznych, napięcie emocjonalne może utrudniać skuteczne leczenie. Ludzie niestali emocjonalnie, którzy cierpią na poważne organiczne zaburzenia, mogą pogrążyć się w związku z nimi w takiej depresji, że utracą swe normalne zdolności regeneracyjne. Sędzia śledczy w Baltimore stwierdził, że wiele osób umiera każdego roku po zażyciu dawek trucizny, które nie są śmiertelne, lub po zadaniu sobie niegroźnych ran.  Chociaż uszkodzenia te same w sobie nie były śmiertelne, najwyraźniej przekonanie o nieuchronnej śmierci uczyniło je takimi (Richter, 1957).
Na drugim krańcu tej skali znajduje się wiele udokumentowanych przypadków pacjentów, którzy tak mocno postanowili wyzdrowieć, iż dokonali tego wbrew opinii lekarzy, że stan ich jest beznadziejny. Donoszono, że starzy ludzie częściej umierają po świętach lub po dniu urodzin niż przed nimi, jak gdyby postanowili żyć aż do pewnej docelowej daty.
Czynniki emocjonalne są szczególnie ważne w takich organicznych chorobach, jak gruźlica, choroby serca, cukrzyca, padaczka. Na przykład podczas leczenia gruźlicy trzeba dbać o to, by nie powstały zaburzenia emocjonalne, ponieważ pacjentowi nie wolno zajmować się intensywnie ćwiczeniami fizycznymi i pozbawia go się w ten sposób ważnych, naturalnych sposobów rozładowania napięć emocjonalnych. Jeżeli nie podejmuje się starań, aby utrzymać pacjenta w pogodnym nastroju, to choroba, która w istocie jest organiczna, może nasilić się pod wpływem czynników emocjonalnych.
Jest prawdopodobne, że przynajmniej tylu pacjentów zostaje wyleczonych przez podtrzymujący na duchu sposób bycia lekarzy, ilu przez każde przepisywane lekarstwo. Obecnie zwraca się uwagę lekarzy, aby byli bardziej wrażliwi nie tylko na osobę pacjenta, lecz także na warunki społeczno-emocjonalne, w których on żyje. Aczkolwiek obecnie w kołach lekarskich poświęca się więcej uwagi znaczeniu „psychiki” w chorobach fizycznych, to jednak zaznaczający się ogólny trend, polegający na zastępowaniu instytucji lekarza domowego i „lekarzy-omnibusów” przez kliniki i specjalistów, może oznaczać, że potrzebom emocjonalnym pacjenta nie poświęca się tyle uwagi i troski, ile mógł okazać lekarz domowy.




Jak radzić sobie
ze stresem?




W jaki sposób reaguje jednostka, gdy stoi wobec sytuacji stresowej?  Rozwinęły się dwa zasadnicze sposoby podejścia do tego problemu; jedno koncentruje się bardziej na występujących wtedy zmianach fizjologicznych stresu, drugie zaś na czynnikach psychologicznych i poznawczych.


Ogólny zespół adaptacyjny. Teoretycznym podejściem, które pomaga wyjaśnić objawy psychosomatyczne, jest koncepcja |ogólnego |zespołu |adaptacyjnego („general adaptation syndrome”), którą stworzył Hans Selye (1956, 1973).  Według teorii Selyego, na reakcję organizmu będącego pod wpływem stresu składają się trzy zasadnicze stadia: |reakcja |alarmowa, |stadium |odporności i |stadium |wyczerpania.
1. |Reakcja |alarmowa („alarm reaction”), czasami zwana |reakcją |mobilizacyjną („emergency reaction”), składa się ze zmian fizjologicznych, które są pierwszą odpowiedzią organizmu na zadziałanie czynnika wywołującego stres, czyli |stresora. Stresorem jest każdy czynnik szkodliwy dla organizmu, czy to fizyczny (taki, jak nieodpowiednie jedzenie, brak snu, uszkodzenie ciała), czy psychologiczny (utrata miłości lub poczucie bezpieczeństwa). Reakcja alarmowa składa się z różnych skomplikowanych zmian biochemicznych zachodzących w organizmie, które zwykle mają te same ogólne właściwości - bez względu na charakter specyficznego stresora. To ostatnie stwierdzenie uzyskano poddając wielką liczbę zwierząt najróżniejszym warunkom stresowym, takim jak głodówka, infekcja, trucizny, skrajne zimno, skrajne gorąco, krwotoki wywołane chirurgicznie i inne. Bez względu na typ stresora obserwowano niemal taki sam ogólny wzorzec zmian fizjologicznych.

Wyniki te wyjaśniają podobieństwo ogólnych objawów choroby u ludzi cierpiących na różne schorzenia - wszyscy oni zdają się skarżyć na takie dolegliwości, jak ból głowy, gorączka, zmęczenie, ból mięśni i stawów, utrata apetytu oraz ogólne „złe samopoczucie”.
2. Jeśli kontakt z wywołującą stres sytuacją trwa nadal, to po reakcji alarmowej następuje |stadium |odporności, („stage of resistance”), druga faza ogólnego syndromu adaptacyjnego. Tutaj organizm zdaje się wytwarzać odporność na ten szczególny stresor, który wywołał reakcję alarmową.  Objawy, które występowały w pierwszym stadium stresu, znikają, pomimo że zakłócająca stymulacja trwa nadal, a procesy fizjologiczne, które uległy zakłóceniu w czasie reakcji alarmowej, zdają się powracać do normy.

Odporność na dany stresor zdaje się być w dużej mierze wywołana wzrostem poziomu wydzielania przedniego płata przysadki mózgowej oraz kory nadnerczy (ACTH oraz kortykosterydy, odpowiednio). Na przykład u pilotów wystąpiła wyraźnie ta reakcja kory nadnerczy podczas ćwiczeń w lądowaniu na odrzutowcach. Jest interesujące, że reakcja ta nie występowała u drugiego członka załogi odrzutowca. Reakcję stresową wywoływało zatem najwyraźniej nie samo narażenie na niebezpieczeństwo, lecz odpowiedzialność za wykonanie złożonego i niebezpiecznego zadania, którą musiał przyjąć na siebie pilot, a której nie ponosił jego bierny partner (Rubin, Miller, Arthur i Clark, 1969).
Jeśli oddziaływanie szkodliwego stresora trwa zbyt długo, zostaje osiągnięty punkt, w którym organizm nie jest w stanie dłużej utrzymać swej odporności. Wchodzi on wówczas w ostatnią fazę zmian związanych ze stresem, w |stadium |wyczerpania („stage of exhaustion”). Przedni płat przysadki mózgowej i kora nadnerczy nie są zdolne do dalszego wydzielania swych hormonów w zwiększonym tempie, co powoduje, że organizm nie potrafi dłużej przystosowywać się do nieustannego stresu. Wiele dysfunkcji fizjologicznych, które pierwotnie pojawiły się w trakcie reakcji alarmowej, zaczyna występować ponownie. Jeśli dany stresor nadal oddziałuje na organizm, to często następuje śmierć. Rzadko jednak się zdarza, aby stres nie został zredukowany przed osiągnięciem tego stadium wyczerpania.
Koncepcja ogólnego syndromu adaptacyjnego okazała się wyjątkowo wartościowa przy wyjaśnianiu zaburzeń psychosomatycznych. W kategoriach tego układu odniesienia wiele zaburzeń można rozpatrywać jako wyniki stresu lub procesów fizjologicznych związanych z adaptacją do stresu. Można także zrozumieć sens podawania dodatkowych ilości ACTH i kortyzonu przy leczeniu niektórych z tych chorób. Leczenie takie można mianować uważać za pewien sposób pomagania przedniemu płatowi przysadki mózgowej oraz korze nadnerczy w utrzymaniu odporności organizmu na pewien czynnik stresowy.
Pewien psycholog, po dokonaniu przeglądu badań Selyego i innych, reasumuje tę sytuację następująco:
„Być może, reakcje emocjonalne pełnią w zasadzie konstruktywną rolę obronną i adaptacyjną. Jeśli jednak aktywność czy reaktywność emocjonalna jest dostatecznie częsta, długotrwała lub intensywna, to staje się ona nieprzystosowawcza i destrukcyjna, co prowadzi do aberracji fizjologicznej i strukturalnego uszkodzenia danego organizmu, a nawet do śmierci. Organizm może zatem zostać uszkodzony lub zniszczony przez swe własne środki obronne” (Lachman, 1963, s. 27).


Poznawcze strategie radzenia sobie ze stresem. Sytuacje stresowe nie zawsze, oczywiście, prowadzą do choroby czy zaburzeń funkcjonowania. W jakich warunkach nie powodują one takich następstw? Badania, które przeprowadzono nad tym zagadnieniem konsekwentnie wskazują na doniosłe znaczenie czynników psychologicznych w radzeniu sobie ze stresem. To, w jaki sposób dana osoba spostrzega sytuację i jaką emocję odczuwa, może drastycznie wpłynąć na wynik zdarzenia.




Zbliżenie


Stres w pracy


„Charakterystyczne cechy każdej sytuacji pracy wpływają zwykle silnie na to, w jaki sposób ludzie spostrzegają swą pracę i reagują na towarzyszące jej stresy i napięcia. Na przykład w pewnych wydziałach wielkiego przedsiębiorstwa wprowadzono dla kierowników nowy system podejmowania decyzji, który okazał się bardzo nieefektywny. Frustracja, spowodowana niewłaściwą organizacją pracy, znalazła swe odbicie nie tylko w ich mniejszych zarobkach i konfliktach z personelem, lecz także w zwiększeniu częstości skarg na dolegliwości psychosomatyczne (Ruma, 1973).
W innych badaniach, których przedmiotem były skutki przejścia pracowników ze stałej płacy miesięcznej na stawiający większe wymagania system stawek akordowych, również stwierdzono negatywne reakcje psychiczne oraz towarzyszące im zmiany stanu zdrowia. Chociaż zatrudnione kobiety zarabiały więcej pieniędzy, gdyż ich przeciętna wydajność wzrosła o 11,3%, to uskarżały się one na większe napięcie i zmęczenie, a ponadto gwałtownie wzrósł u nich poziom wydzielania hormonów, które pojawiają się w chwilach występowania stresu (Levi, 1972).
Kontrolerzy ruchu powietrznego na chicagowskim lotnisku O’Hare są odpowiedzialni za życie ponad 37 milionów pasażerów rocznie; w tym okresie odbywa się tam ponad 660 tysięcy startów i lądowań samolotów (co 20 sekund jedno). Każde osłabienie nieustannej czujności, niewielki błąd w wydawanych poleceniach lub nienaciśnięcie jednego przełącznika mogą doprowadzić do tragicznej katastrofy lotniczej. Ten intensywny stres można porównać do zmęczenia frontowych żołnierzy i określa się go jako „collisionitis” (choroba zderzeniowa). Jego następstwa to wysokie ciśnienie krwi i choroba wrzodowa, połączone z innymi objawami stresu: lękiem, bezsennością, utratą apetytu, drażliwością i depresją (Martindale, 1976).
Zapewne jednak brak pracy, gdy pragnie się mieć pracę, jest gorszy niż praca wywołująca stres. Gdy statystyki zdrowotności zestawiono z cyklami koniunktury ekonomicznej dla okresu obejmującego 127 lat historii Stanów Zjednoczonych, to stwierdzono, że zwiększona śmiertelność występuje w 2-4 lata po okresach depresji gospodarczej (Brenner, 1973). Badanie to wskazuje na doniosłość politycznego, ekonomicznego i społecznego kontekstu zachowania. Uświadamia nam ono także wzajemne powiązania między naszą naturą biologiczną a ekosystemem.


„Ocena zagrożenia”. Jak przekonaliśmy się już w tym rozdziale, Richard Lazarus i jego współpracownicy stworzyli teorię emocji, która podkreśla rolę oceny poznawczej. Większość badań przeprowadzonych w celu sprawdzenia tej teorii skoncentrowano na tym, w jaki sposób dokonuje się pierwotnej i wtórnej oceny, aby uporać się ze skrajnie zagrażającymi sytuacjami.


„W jednym z eksperymentów osoby badane ogłądały film ukazujący bardzo brutalne operacje na genitaliach, przeprowadzane w ramach obrzędów inicjacji mężczyzn w pewnym pierwotnym plemieniu autralijskim. Za pośrednictwem ścieżki dźwiękowej, która towarzyszyła temu filmowi, albo podkreślano niebezpieczeństwa tej operacji, albo ukrywano te niebezpieczeństwa, albo też omawiano je w intelektualny, oderwany sposób.  Badacze wysunęli hippotezę, że te ścieżki dźwiękowe zmienią ocenę poznawczą zagrażającego filmu dokonywaną przez osoby badane (a zatem zmienią również ich reakcję emocjonalną na film).


Badacze wysunęli hipotezę, że te ścieżki dźwiękowe zmieniają ocenę poznawczą zagrażającego filmu dokonywaną przez osoby badane (a zatem zmienią również ich reakcję emocjonalną na film). Stwierdzono, że w porównaniu ze wzbudzeniem wytwarzanym przez sam film, poziomy wzbudzenia fizjologicznego były wyższe w wypadku „niebezpiecznej” ścieżki dźwiękowej, niższe zaś w wypadku ścieżki „ukrywającej” i „intelektualizującej”.


„W innym eksperymencie osoby badane, które obserwowały film o nieoczekiwanych dramatycznych wypadkach w sklepie z drewnem (takich, jak wypadek, w którym pewien człowiek obsługujący piłę tarczową został przebity pniem drzewa), wykazywały mniejsze wzbudzenie fizjologiczne, mierzone opornością elektryczną skóry (reakcja skórno-galwaniczna) oraz tempem pracy serca, jeśli przed obejrzeniem filmu „opracowywały poznawczo” („cognitively rehearsed”), czyli wyobrażały sobie zagrażające sceny. Trening odprężenia również pomagał zredukować stres, lecz sposobność przeprowadzenia oceny poznawczej była najwyraźniej bardziej skuteczna” (Folkins, Lawson, Opton i Lazarus, 1968).


Wyniki takie mają ważna implikacje nie tylko dla naszego intelektualnego zrozumienia tego, czym jest emocja, lecz także dla przygotowania ludzi, którzy będą narażeni na silny stres (jak w wypadku pewnych niebezpiecznych zawodów).


„Kiedy zbyt mały strach szkodzi”. Czy osoba, która nie odczuwa strachu w obliczu niebezpieczeństwa ma psychologiczną przewagę nad osobą martwiącą się zawczasu? Zgodnie z wynikami badań - niekoniecznie; w pewnych okolicznościach zbyt mały strach może mieć równie zły wpływ na zdrowie, jak strach zbyt wielki.


„Pewien badacz, Irving Janis, wysunął hipotezę, że gdy jednostka musi uporać się z zagrażającą sytuacją, jak w przypadku oczekiwania na poważną operację chirurgiczną, to umiarkowana wielkość uzasadnionego strachu przed tą operacją jest przydatna, sprzyjając późniejszemu przystosowaniu, zarówno psychicznemu, jak i fizycznemu.
Stwierdził on, że umiarkowany poziom strachu, który zapoczątkował „działalność polegającą na martwieniu się” przed rzeczywistym zetknięciem się z danym zdarzeniem, pomagał pacjentowi planować przyszłe reakcje i modulować stres oraz wywoływał pewien rodzaj „emocjonalnego uodpornienia”.  Skrajnie silny strach wywoływał ogólny zespół stresu, który omówiliśmy powyżej, i w ten sposób wprowadzał dodatkowe komplikacje fizjologiczne. Z drugiej strony, pacjent, który odczuwał niewielki strach przed operacją lub nie odczuwał go wcale, nie zajmował się psychicznym opracowywaniem (mental rehearsal) zbliżającego się zdarzenia i był gorzej przygotowany do uporania się z następstwami tej operacji. Gdyby osoba taka nagle uświadomiła sobie, że straciła kończynę, że jest niesprawna fizycznie lub doznaje silnego bólu, to skłonna była reagować uczuciem bezradności, pokrzywdzenia, rozczarowania i gniewu. Na wykresie 9.8 zilustrowano lepsze przystosowanie pooperacyjne w grupie pacjentów (studentów wyższej uczelni), których poziom strachu przed operacją był umiarkowany, w porównaniu z przystosowaniem grup o niskim lub wysokim poziomie strachu. Osoby o niskim poziomie strachu przed operacją najczęściej przejawiały gniew, najbardziej skarżyły się na personel szpitalny i wykazywały najwięcej zaburzeń emocjonalnych” (Janis, 1958).


Pacjentów o niskim poziomie strachu, wynikającym z wyparcia, fałszywego optymizmu lub ignorancji, można „zaszczepić emocjonalnie”, podając im informacje przygotowujące. Wykazano, że takie przygotowanie poznawcze daje dobre efekty.


„97 pacjentów Massachusetts General Hospital podzielono losowo na dwie grupy. W jednej z grup przeprowadzono tylko typowy, minimalny wywiad lekarski, podczas gdy druga grupa otrzymała dodatkowe istotne informacje o czekającej ich operacji. Anestezjolog, który przeprowadzał te rozmowy, nie mówił personalowi szpitalnemu ani chirurgom, którzy pacjenci należeli do której grupy, tak żeby utrzymać bez zmiany wszystkie inne aspekty ich hospitalizacji. Po operacji grupa ostrzeżonych zawczasu pacjentów wymagała znacznie mniejszych dawek (mniej więcej o połowę) morfiny niż grupa potraktowana rutynowo. Pacjenci nie tylko skarżyli się mniej, lecz stan ich zdrowia oceniono jako na tyle lepszy, że zwalniano ich ze szpitala przeciętnie prawie trzy dni wcześniej niż pacjentów, którzy nie byli przygotowywani poznawczo” (Egbert, Battit, Welch i Barlett, 1964).


„Kiedy strach skłoni cię do działania”? Badania - jak również twoje własne obserwacje - nie pozostawiają wątpliwości, że ostrzeżenia o niebezpieczeństwie nie zawsze są przyjmowane i nie zawsze pobudzają do działania. Nawet kiedy wierzy się w te ostrzeżenia, jak na przykład w wypadku chorób wenerycznych, nadużywania narkotyków czy związku między rakiem a paleniem papierosów, to niekiedy zwiększają one tylko pobudzenie emocjonalne danej jednostki, nie zwiększając jednak prawdopodobieństwa, że podejmie ona działania prewencyjne.


„Podczas badań dotyczących problemu, w jaki sposób można skłonić ludzi do 
działania na korzyść własnego zdrowia, jeden z badaczy zorganizował stoiska 
informacyjne na światowych targach w Nowym Jorku, na kilku targach 
stanowych, a także w uczelnianych ośrodkach zdrowia. Stwierdził on, że 
wielu ludzi najbardziej potrzebujących akcji prewencyjnej, unika jej, 
starając się utrzymać swe złudzenia o osobistym bezpieczeństwie. W grupie 
palaczy, których zachęcano do prześwietlenia klatki piersiowej promieniami 
Roentgena, 53% palaczy o umiarkowanym poziomie strachu było gotowych to 
uczynić, w porównaniu z tylko 6% palaczy o wysokim poziomie strachu; 
dowodzi to, że u osób o najwyższym poziomie strachu prawdopodobieństwo 
podjęcia działania mającego na celu ochronę zdrowia bynajmniej nie było 
najwyższe” 
(Leventhal, 1965).


Podobnie ludzie, którzy obawiają się, że mają chorobę weneryczną lub raka, często nie chcą zgłosić się do lekarza. Aby ostrzeżenia wywołujące strach były skuteczne, muszą one: a) wywoływać umiarkowany (nie nadmierny) poziom strachu, b) nie tylko wzbudzać strach, lecz także zmieniać ogólne postawy wobec podjęcia jakiegoś działania zmierzającego do wyeliminowania tej aktywności czy zjawiska, które są powodem strachu oraz c) dostarczyć wyraźnych wskazówek dotyczących tego działania - określających konkretnie, co dana osoba musi zrobić, jak i gdzie. Wreszcie zalecenia dotyczące działania częściej będą wypełniane, jeśli daną osobę nakłoni się do publicznego zobowiązania się, że postąpi w określony sposób.


„Któż więc boi się wielkiego, złego wilka”? Żołnierz mający wziąć udział w bitwie, chirurg przystępujący do swej pierwszej operacji, bokser przed spotkaniem z niepokonanym dotąd przeciwnikiem oraz spadochroniarz-nowicjusz przygotowujący się do skoku w przepaść - wszyscy oni odczuwają strach.  Jeśli nie potrafią opanować swego strachu, to ucierpi na tym ich działanie, co oczywiście może mieć dla nich katastrofalne osobiste konsekwencje.
W jaki sposób jednostka radzi sobie z niebezpieczeństwami nieodłącznie związanymi z taką sytuacją, jak sportowe skoki ze spadochronem? Chociaż ludzie, którzy uprawiają tę dyscyplinę sportu są wysoce motywowani, to jednak doświadczają oni niezwykle silnego strachu we wczesnych fazach treningu. Wpływ tej emocji na ich funkcjonowanie psychiczne oraz sposób sprawowania przez nich kontroli poznawczej nad swym strachem były przedmiotem badań w pomysłowym eksperymencie terenowym („field experiment”).


„27 spadochroniarzy sportowych, nowicjuszy, badano za pomocą baterii narzędzi pomiarowych w trzech różnych okresach: 2 tygodnie przed skokiem. I dzień przed nim oraz w dniu ich pierwszego skoku. Badano ich za pomocą list kojarzenia słów i testów projekcyjnych, przy czym obie te techniki zawierały pozycje różniące się pod względem związku z krytycznym zdarzeniem - skokiem ze spadochronem. Ponadto rejestrowano reakcję skórno-galwaniczną (RSG) oraz podstawowy poziom przewodności skóry jako wskaźniki aktywacji fizjologicznej.
W porównaniu z grupą kontrolną złożoną z osób w podobnym wieku, o podobnym wykształceniu (wyższa uczelnia) oraz miejscu zamieszkania, które nie uprawiały sportu spadochronowego, spadochroniarze 2 tygodnie przed skokiem reagowali mniej emocjonalnie na słowa, które nie były związane ze spadochroniarstwem. „Wynik ten zdaje się być przejawem różnic osobowościowych, ponieważ można go interpretować jako świadczący o tym, że spadochroniarze zamiast hamować swe emocje czy tłumić swe napięcia, mają skłonność do rozładowywania ich w aktywności ruchowej” (str. 13).
Z drugiej strony, z ogólnym stanem napięcia, wytwarzanym przez zbliżający sie termin skoku, spadochroniarze radzili sobie w złożony sposób. Badani technikami projekcyjnymi nie ujawniali strachu przed skokiem w swych reakcjach na obrazki o silnym związku ze spadochroniarstwem, chociaż wyrażali więcej strachu w reakcjach na obrazki mniej związane lub wcale nie związane z tym sportem. Jednakże ich reakcje fizjologiczne zdradzały ich: gdy termin skoku zbliżał się, wówczas gradienty RSG na obrazki silnie związane ze spadochroniarstwem były coraz bardziej strome (Fenz, 1964; ryc. 9.9).




* * *



Ryc. 9.9. Reakcja Ciała I Psychika Na Stres. W teście projekcyjnym spadochroniarze opowiadali historyjki o pokazywanych ich obrazkach, które w różnym stopniu wiązały się ze skokiem. Aczkolwiek ich reakcje werbalne wskazywały na mały strach w wypadku obrazków mających duży związek ze skokiem, to jednak ich reakcje skórno-galwaniczne, były wyraźnie silniejsze w wypadku tych właśnie obrazków, gdy zbliżał się czas skoku.


* * *





Stwierdzenia te są zgodne ze sprawozdaniem Parachute Club of America (Amerykańskiego Klubu Spadochronowego), które wskazuje, że niepowodzenia są najczęściej spowodowane niezdolnością skoczka do uzyskania kontroli poznawczej nad strachem (Moore, 1963).
Wypieranie się strachu może spełniać adaptacyjną funkcję, lecz gdy jest posunięte do przesady, może także przeszkadzać w wykonaniu zadań, które są uzależnione od złożonego, nietendencyjnego przetwarzania informacji.




Ból




Najbardziej chyba wymowna definicja bólu brzmi: „Szkoda, którą odczuwamy” (Sternach, 1968). Jest to szkoda, która może wynikać z uszkodzenia tkanki spowodowanego przez warunki zewnętrzne - stłuczenie kolana, oparzenia palca o gorący piec, silnego uderzenia, rany postrzałowej lub rany zadanej nożem.  Lecz ból może także pochodzić, jak wszyscy aż za dobrze wiemy, „z wewnątrz” nas, w postaci bólu zębów, bólu głowy, bolesnych skurczów miesiączkowych, bólu artretycznego, czy też uporczywego bólu towarzyszącego ostatnim stadiom raka. Nasza wrażliwość na ból może również być bardzo różna, od wzmożonego reagowania na każde słabe podrażnienie do całkowitego zablokowania wrażeń bólowych.




Zbliżenie


A ja dotrę do piekarni na czas


„Dramatyczne opowieści o żołnierzach na froncie, którzy nie zważając na swe poważne rany nie przestawali dzielnie walczyć, aby ocalić swe życie i zwyciężyć, nie stanowią tak przekonywującego dowodu kontroli poznawczej nad bólem, jak władza ducha nad ciałem zademonstrowana niedawno przez pewnego nowojorskiego piekarza.
George Keller, lat 53, pracuje w wielkiej piekarni nowojorskiej. W ciągu ostatnich 18 lat nie opuścił ani jednego dnia pracy. Codziennie przychodził punktualnie o 4 rano, aby przygotować piekarnię do pracy, lecz tuż przed Bożym Narodzeniem jego czyste konto było w niebezpieczeństwie. Gdy w chłodnych godzinach przedświtu opuszczał swój dom, został zaatakowany przez pięciu młodych ludzi, którzy zrabowali mu zegarek, a gdy im sie wyrwał, postrzelili go w klatkę piersiową, żołądek i pośladki.
Jednakże konto George’a pozostało czyste i nawet bez swego wiernego zegarka dotarł do piekarni na czas. Zdołał wsiąść do autobusu, dojechać nim do piekarni oraz przygotować piece i ciasto, po czym poszedł piechotą parę kilometrów na posterunek policji, aby zameldować o dokonanym przestępstwie.
George Keller został stamtąd natychmiast przewieziony do szpitala i poddany operacji, po której stan jego określono jako „krytyczny”. Gdy jednak jego szef przybył do piekarni, to wszystko jak zwykle było w doskonałym porządku. „Stary, solidny George” wykonał swoją pracę jeszcze raz. Lojalność wobec firmy była silniejsza niż ból i troska o własne dobro (komunikat Associated Press, 24 grudnia 1973).


Chociaż niekiedy pragniemy, abyśmy mogli być wolni od bólu, to jednak zdolność doznawania bólu i jego motywujące właściwości są w rzeczywistości jednym z najbardziej wartościowych darów natury. Ból należy rozpatrywać jako: a) |system |sygnałowy, który rozwinął się, aby ostrzegać nas o zagrożeniu integralności naszego organizmu oraz b) |system |obronny wyzwalający automatyczne odruchy wycofania, jak również motywowane zachowania unikania i ucieczki. Jako taki, jest on nieodzowny w borykaniu się z wrogim niekiedy środowiskiem oraz z chorobami i ostatecznym zniszczeniem żywej materii, którą jest nasze ciało.




Ból jako zjawisko
neurologiczne




Bodźcem związanym z odczuwaniem bólu jest duża lub szybka zmiana natężenia energii fizycznej, zdolna wywołać uszkodzenie tkanki. Wydaje się, że to |nie wyspecjalizowane receptory bólowe, lecz niezróżnicowane wolne zakończenia nerwów, rozsiane w całym ciele, są odpowiedzialne za recepcje bólu. Impulsy bólowe są przekazywane przez nerwy, które wchodzą do rdzenia kręgowego i po przejściu przez synapsy przesyłają impulsy różnymi szlakami rdzeniowymi do wzgórza, tworu siatkowatego i kory mózgowej.
Chociaż moglibyśmy sądzić, że ból, jakiego doznajemy, jest determinowany całkowicie przez bodziec powodujący go, to jednak wyniki badań nie potwierdzają tego poglądu. Przeciwnie, wielkość i jakość spostrzeganego bólu zależą nie tylko od wejścia sensorycznego, lecz także od wielu zmiennych psychologicznych. Zgodnie z tym, Melzack i Wall (1965) opracowali teorię bólu zwaną |teorią |kontroli |wejściowej („gate-control theory”), która integruje zarówno czynniki fizjologiczne, jak i psychologiczne. Postulują oni kontrolny system sprzężenia zwrotnego, który nieustannie moduluje wejście w postaci impulsów bólowych. Gdy ból występuje, wówczas aktywowane są selektywne procesy mózgowe, które sterują przychodzącymi danymi. Pod wpływem tego mechanizmu wyzwalającego komórki na każdym poziomie rdzenia kręgowego działają jako system kontroli wejściowej, zwiększając lub zmniejszając swą wrażliwość na przychodzące sygnały bólowe wędrujące wzdłuż nerwów. Dzięki temu systemowi aktywności ośrodkowego układu nerwowego (która stanowi podłoże uwagi, emocji i pamięci o uprzednich doświadczeniach), może modyfikować wejście aferentne za pośrednictwem procesów eferentnych.




Zbliżenie


Tajemnica akupunktury


„Po niedawnym otwarciu granic Chin dla Amerykanów w prasie pojawiło się mnóstwo opowieści o tradycyjnej chińskiej technice eliminowania bólu, zwanej |akupunkturą. Metoda ta polega na wkłuwaniu długich, cienkich igieł w pewne punkty ciała i zgodnie z opisami naocznych świadków - amerykańskich i brytyjskich lekarzy - rzeczywiście usuwa ona ból. Dziennikarz James Reston poddał się w Pekinie operacji usunięcia wyrostka robaczkowego przy zastosowaniu akupunktury; są też inne opisy zastosowania tej metody w poważnych operacjach różnego rodzaju. Chociaż są dowody, że akupunktura spełnia swoje zadanie, to jednak dla zachodniej medycyny jest zagadką, |w |jak |sposób tego dokonuje.
Według Melzacka (1973), teoria „kontroli wrót” (kontroli wejściowej) wskazuje na trzy różne sposoby, w jakie akupunktura może redukować ból: 1.  W nerwach czuciowych biegnących od powierzchni ciała do ośrodkowego układu nerwowego są duże włókna, których podrażnienie „zamyka wrota”, w układzie sygnalizacji bólowej i w ten sposób redukuje odczuwany ból. Być może, igły stosowane w akupunkturze podrażniają te duże włókna. 2. Gdy drażni się pewne części pnia mózgu, powoduje to głęboką długotrwałą analgezję (niewrażliwość na ból) w dużej części ciała. Widocznie te okolice pnia mózgu mogą „zamykać wrota” blokując sygnały wychodzące z miejsca oddziaływania bodźca bólowego. Być może, impulsy nerwowe wytworzone wskutek wbijania igieł służących do akupunktury pobudzają pień mózgu. 3. Włókna zstępujące z kory mózgowej mogą także oddziaływać na „wrota” i modyfikować odczuwanie bólu. Ponieważ kora mózgowa jest ośrodkiem wspomnień, oczekiwań, obaw itd., zatem te procesy psychiczne mogą mieć znaczny wpływ na doznania bólowe.


Ponieważ pacjenci poddawani akupunkturze wierzą w skuteczność tej procedury, a ponadto podaje się im także wyraźne sugestie, że nie będą odczuwać żadnego bólu, przeto ich nastawienie poznawcze może bardzo efektywnie redukować odczuwany przez nich ból.




Psychologiczne aspekty
bólu




Starając się zintegrować wyniki różnorodnych badań nad bólem i stworzyć podstawowy zbiór elementów charakteryzujących ból, Sternbach (1968) wysunął tezę, że reakcja na ból u ludzi zależy od: a) ich stylu funkcjonowania percepcyjnego, a zwłaszcza sposobu, w jaki reagują oni na lęk, b) wyuczonych skojarzeń bodźców fizycznych powodujących reakcje bólowe z kontekstem społecznym, w którym ten ból występuje, c) wewnętrznej modyfikacji sensorycznej tych reakcji bólowych przez różne wejścia poznawcze.


Cierpieć w milczeniu czy krzyczeć... Wypieranie się doznań strachu, stresu, czy bólu niekoniecznie musi być sprawą indywidualną, lecz może być to norma nabywana przez członków grupy etnicznej w wyniku pewnych doświadczeń kulturowych. Pacjenci, którzy przejawiają przesadne reakcje na ból, są niekiedy oddawani pod opiekę psychiatrów, podczas gdy w rzeczywistości przejawiają oni tylko wyuczone formy zachowania, aprobowane w ich grupie.


„Gdy pacjentów oddziału chirurgicznego w szpitalu Bronx poddano obserwacji i wywiadom (które przeprowadzono także z ich rodzinami i personelem szpitalnym), wówczas okazało się, że na podstawie ich przynależności do grupy etnicznej można było na ogół przewidzieć, w jaki sposób będą oni radzić sobie z odczuwanym bólem. Pacjenci żydowscy i włoscy wyolbrzymiali emocjonalnie intensywność odczuwanego bólu i nie krępowali się krzyczeć, by uzyskać pomoc ze strony rodziny czy personelu szpitalnego.  W odróżnieniu od nich, Irlandczycy i „starzy Amerykanie” (Anglosasi wyznania protestanckiego zamieszkali przynajmniej od trzech pokoleń w Stanach Zjednoczonych) przyjmowali flegmatyczne, „z dystansem”, rzeczowe nastawienie, które hamowało wszelkie publiczne okazywanie emocji. Gdy ból stawał się intensywny, wówczas izolowali się oni od otoczenia; jęczeli oni lub krzyczeli tylko wtedy, gdy byli sami.


Dalsze badania wykazały, że wspólne dla Żydów i Włochów demonstrowanie emocji wynikało z różnych postaw. Włosi koncentrowali się na bezpośrednich doznaniach bólu i ulgi w jego odczuwaniu, podczas gdy pacjenci żydowscy troszczyli się o znaczenie i przyszłe implikacje bólu, a ponadto nie mieli zaufania do metod łagodzenia bólu.
Chociaż zarówno Irlandczycy, jak „starzy Amerykanie”, byli „dobrymi” pacjentami, którzy nie robili hałasu, to jednak oni również zachowywali się tak pod wpływem zupełnie odmiennych postaw. „Starzy Amerykanie”, nie chcąc, by uważano ich za słabych czy bezradnych, wychodzili z założenia, że ból jest powszechnym doświadczeniem, z którym każdy ma do czynienia i którego okazywanie jest „niemęskie”. Gdy jednak osoba przeprowadzająca wywiad „sondowała” ich, wówczas pacjenci tacy otwarcie omawiali swe doznania i byli nastawieni optymistycznie do swej przyszłości, ponieważ „doktorzy są ekspertami”.
W odróżnieniu od nich, Irlandczycy nie chcieli mówić o swym bólu, zdawali się odczuwać potrzebę znoszenia go w samotności, jako jedynego w swoim rodzaju doświadczenia. Ich niezdolność czy niechęć do dzielenia się swymi odczuciami sprawiała wrażenie chłodu i obojętności. Badacz podaje, że wśród czterech grup pacjentów o różnym pochodzeniu etnicznym, pacjent Irlandczyk przedstawiał najsmutniejszy, najbardziej przygnębiający obraz... Nie przygotowany do myślenia kategoriami choroby i dbałości o zdrowie, odkrywa on w szpitalu świat cierpienia ludzkiego, którego jest częścią. Lecz jest on niezdolny do dzielenia swych emocji, lęków i obaw z jakąś bliską osobą, która zrozumiałaby je i ofiarowała mu jakąś pociechę i oparcie” (Zborowski, 1969, s. 235).
Zasadnicze rezultaty tego badania znalazły potwierdzenie w kontrolowanym eksperymencie laboratoryjnym, w którym ból wywoływano za pomocą wstrząsów elektrycznych u gospodyń domowych („housewives”) pochodzących z różnych grup etnicznych. Włoszki były najbardziej wrażliwe na ból - tolerancja na ból była u nich istotnie niższa niż w jakiejkolwiek innej grupie. Kobiety żydowskie potrafiły zgodzić się na najwyższy przyrost siły wstrząsu, gdy były motywowane (nakłaniane pochlebstwem) przez eksperymentatora.  Amerykanki pod względem fizjologicznym przystosowały się do wstrząsu łatwiej niż jakakolwiek inna grupa, Irlandki natomiast umyślnie tłumiły swe cierpienia i troskę o implikację bólu” (Sternbach i Tursky, 1965).


Były jednak ważne różnice, jeśli chodzi o doznawanie i interpretację bólu wywoływanego w laboratorium, w porównaniu z bólem, jakiego doznawali pacjenci w szpitalu. Na przykład w laboratorium, gdzie przyczyna bólu była oczywista i kontrolowana przez eksperymentatora, żydowscy pacjenci mieli wyższy próg bólu (w porównaniu z żydowskimi pacjentami szpitalnymi), ponieważ „ból laboratoryjny” nie sygnalizował złowieszczych przyszłych niebezpieczeństw.


Hipnotyczna kontrola nad bólem. Jak przekonaliśmy się w Rozdziale 7, hipnoza jest specyficznym stanem świadomości, który pozwala jednostce sprawować znaczną kontrolę poznawczą zarówno nad ciałem, jak i psychiką.


Z tego względu często stosuje się ją jako technikę pomagającą opanować ból. Przed odkryciem eteru na przykład, hipnozę stosowano powszechnie jako środek znieczulający. Hipnoza nie tylko skutecznie redukowała ból, lecz miała także tę dodatkową zaletę, że powodowała mniej skutków ubocznych.
Ernest Hilgard i jego współpracownicy przeprowadzili kilka badań nad hipnozą i bólem, w których ból wywoływano albo przez zanurzenie ręki osoby badanej do lodowatej wody lub też przez czasowe zahamowanie przepływu krwi w ręce za pomocą opaski uciskowej. Badani, po zahipnotyzowaniu ich i podaniu im sugestii o analgezji (niewrażliwości na ból), podawali, że odczuwany przez nich ból został albo zmniejszony, albo całkowicie wyeliminowany. U tych badanych, których można było łatwo zahipnotyzować, ból został zredukowany w większym stopniu niż u tych, którzy nie poddawali się łatwo hipnozie (Hilgard, 1969).
Inne badanie wykazało, że pod kontrolą hipnotyczną można niekiedy osiągnąć całkowitą niezależność reakcji bólowej od stymulacji środowiskowej.


|Osobom badanym (uczniom szkoły średniej, którzy zgłosili się na ochotnika) wymierzano szereg bolesnych wstrząsów elektrycznych o stałym natężeniu, zarówno przed otrzymaniem, jak i po otrzymaniu przez nich sugestii hipnotycznej o niewrażliwości na ból. Badani poddani hipnozie, w porównaniu z grupą kontrolną, podawali, że odczuwają znacznie mniejszy ból i przejawiali słabsze reakcje fizjologiczne na wstrząsy. Reakcje jednego z badanych na wstrząsy przedstawiono na rycinie 9.11. (Numerowane kreski oznaczają początek wstrząsu). Gdy tę osobę badaną zahipnotyzowano i powiedziano jej, „tym razem wstrząsy nie będą cię tak bolały”, reakcje jej stały się znacznie słabsze. W istocie reakcja na pierwszy wstrząs w tej serii wynosiła zaledwie 1\10 wielkości pierwszej reakcji w warunkach braku hipnozy. Po 8 wstrząsach osoba badana osiągnęła kontrolę nad wejściem sensorycznym i reakcja została całkowicie wyeliminowana” (Zimbardo, Rapaport i Baron, 1969).


Dewiacyjne zastosowanie motywacji bólowej. Zanim skończymy omawiać ten temat, pouczające może być rozpatrzenie dwóch dewiacyjnych zastosowań motywacji bólowej: bólu jako tortury i bólu jako rozkoszy.


„Ból jako tortura”. W czasach Inkwizycji, która panowała w Europie w wiekach średnich, wierzono, iż diabły są bardzo wrażliwe na ból.  Przekonanie to dostarczyło uzasadnienia dla poddawania kobiet uważanych za czarownice oraz mężczyzn owładniętych przez Szatana niewiarygodnym torturom. Jeśli ofiary reagowały objawami bólu - co nieodmiennie czyniły - dawały się poznać jako diabły i zostawały stracone. „Poczynając od XIII i XIV wieku zapanował taki terror, że nawet osoby najwyższego stanu, w momencie kiedy zostały oskarżone, porzucały godności, fortunę - wszystko - i szukały ratunku w ucieczce” (Michelet, 1962, ss. 314-315).
Gdy władza przeszła z rąk Inkwizycji w ręce państwa policyjnego, wówczas motywujące działania bólu przypisywano nie siłom szatańskim, lecz wyraźnej słabości ludzkiego ciała.


Koło tortur i but żelazny ustąpiły miejsca „śledztwu trzeciego stopnia”: 
torturom wodnym, wystawianiu na palące słońce itd. Jednakże ludzie uświadomili sobie także psychologiczne determinanty bólu, a zwłaszcza cierpienia wynikające z izolacji społecznej. W dawniejszych czasach przestępców zamurowywano na stałe, pozostawiając jedynie szczelinę, przez którą wrzucano im chleb codzienny. Tortura ta, ironicznie nazwana „in pace” (miejsce spokoju), stopniowo przekształciła się w „izolację” w zakładach karnych, a ostatnio w izolację psychiczną stosowaną na przykład jako część programu „prania mózgu”, realizowanego przez Chińczyków w czasie wojny koreańskiej (Schein, 1957).


„Ból jako rozkosz”. Łatwo przychodzi nam uznać ból za nieunikniony rezultat tortury, lecz ból jako źródło rozkoszy jest czymś mniej oczywistym. Jednakże od najwcześniejszych dni kościoła chrześcijańskiego, w pismach mistyków spotykamy się z przekonaniem, że znosząc ból można przekroczyć granicę cielesnych zmysłów i osiągnąć wyższy stan istnienia.  Bariera między bólem i rozkoszą zanikała, gdy cierpienie dla Boga stawało się najwyższym doznaniem, do którego można było aspirować w tym doczesnym życiu (ryc. 9.12).
„Bij mnie”, powiedział masochista. „Nie”, odpowiedział z okrutnym uśmiechem sadysta. Dziewiętnastowieczne pisma Leopolda von Sachter-Masocha oraz markiza de Sade dały nazwę perwersyjnej rozkoszy seksualnej, którą niektóre jednostki czerpią z zadawania bólu sobie lub partnerowi seksualnemu. Wysunięto sugestię, że warunkowanie w jednej próbie („one-trial conditioning”) może być odpowiedzialne za przypadki, w których doznawanie bólu staje się niezbędnym warunkiem gratyfikacji seksualnej.  Omawiając genezę tego wzorca zachowania, Paul Gebhard (1965) z Kinsey’s Institute for Sex Research (Instytut Badań Seksualnych Kinseya) wskazuje na wystąpienie niezwykłej kombinacji czynników sytuacyjnych, jakiej doświadczył pewien chłopiec w okresie dojrzewania. Przypadek on przypadek chłopca, który złamał rękę. W czasie, gdy ręka ta była pospiesznie składana bez znieczulenia, atrakcyjna pielęgniarka pieściła chłopca i trzymała jego głowę na swojej piersi. To doznanie „potężnej i ciekawej kombinacji bólu i pobudzenia seksualnego” wpłynęło nie tylko na to, że w wieku dojrzałym pociągały go kobiety, które nosiły uczesanie podobne do tego, które miała owa pielęgniarka, lecz także na jego stosunki heteroseksualne, które charakteryzowały się zarówno sadystycznymi, jak i masochistycznymi skłonnościami.




* * *



Ryc. 9.12. W tej słynnej rzeźbie Bernini przedstawił ekstazę św. Teresy.  Wydawało się jej, jak zapisała w swej autobiografii, że anioł przeszył jej serce ognistą włócznią, „a tak ogromna była słodycz, jaką wywołał we mnie ten silny ból, że nikt nigdy nie chciałby jej utracić”.


* * *







Bezradność,
beznadziejność sytuacji
i utrata kontroli
poznawczej




Psychologowie usiłują formułować ogólne prawa zachowania, aby móc wyjaśniać i przewidywać zachowanie oraz kierować nim. W przypadku jednostki, usiłującej uporać się z wymaganiami środowiska, samo istnienie zależy od jej zdolności zrealizowania tego celu. Odkrywanie związków przyczynowych nadaje sens zdarzeniom; zdolność przewidywania biegu zdarzeń wnosi porządek i regularność tam, gdzie w przeciwnym wypadku istniałby chaos i niepewność; kierowanie wydarzeniami za pomocą własnych, celowych działań prowadzi do aktywnego panowania nad środowiskiem, zamiast biernej zależności i ulegania mu. Niezdolność do sprawowania jakiejkolwiek kontroli nad własnym środowiskiem może mieć daleko sięgające, patologiczne skutki.




„Choroba rezygnacji”




U niektórych jeńców wojennych występowała brzemienna w tragiczne skutki reakcja, którą trafnie określano jako „chorobę rezygnacji” („give-up-itis”). W zespole tym utrata wszelkiej nadziei na odzyskanie kiedykolwiek wolności i wynikająca stąd utrata zainteresowania przyszłością prowadziły do śmierci z przyczyn emocjonalnych. Bruno Bettelheim (1960), psycholog, który sam przeżył pobyt w hitlerowskich obozach koncentracyjnych, w następujący sposób charakteryzuje taką reakcję, którą zaobserwował u niektórych ze swych współwięźniów:


„Więźniowie, którzy uwierzyli powtarzanym twierdzeniom strażników - że nie ma dla nich żadnej nadziei, że nigdy nie wyjdą z obozu inaczej niż jako trupy - którzy doszli do przekonania, że nie mają w ogóle żadnego wpływu na swe otoczenie, ci więźniowie byli, w dosłownym sensie, chodzącymi trupami.  W obozach nazywano ich „muzułmanami” (Muselmanner), ze względu na to, co błędnie uważano za fatalistyczną uległość wobec otoczenia; utarła się bowiem opinia, że mahometanie spokojnie przyjmują swój los.
(...) byli oni ludźmi, tak pozbawionymi uczuć, szacunku dla samego siebie, i jakiejkolwiek formy stymulacji, tak zupełnie wyczerpanymi zarówno fizycznie, jak i emocjonalnie, że oddali otoczeniu całkowitą władzę nad sobą” (ss. 151-152).
(ss. 151-152).


Jak podają Nardini (1952) i Schein (1957), u amerykańskich jeńców 
wojennych z wojny koreańskiej, przebywających w niewoli u Chińczyków, 
występowało podobne poczucie odrzucenia i opuszczenia przez własny naród, 
czemu towarzyszyło znoszenie ciągłego zastraszania, utrata szacunku dla 
siebie samego, codzienna niepewność istnienia, społeczna i psychiczna 
izolacja od innych Amerykanów (zaplanowana przez władze obozowe) i wreszcie 
poczucie daremności oporu czy ucieczki. Nawet po repatriacji i powrocie do 
życia cywilnego, u mężczyzn tych obserwowano „trupie” zobojętnienie. Jest 
to także wzorzec reakcji powszechnie spotykany u hospitalizowanych 
pacjentów cierpiących na depresję, którzy zdają się wycofywać łagodnie lub 
w ponurym napięciu, z wszelkich kontaktów społecznych. W niektórych 
przypadkach


„(...) występuje całkowity paraliż woli. Pacjent nie chce robić niczego, nawet tych rzeczy, które są niezbędne dla życia. W rezultacie może pozostawać we względnym bezruchu, jeśli nie jest popędzany czy ponaglany do aktywności przez innych. Czasami niezbędne jest wyciąganie takiego pacjenta z łóżka, mycie go, ubieranie i karmienie. W skrajnych przypadkach nawet możliwość porozumiewania się może być zablokowana przez bierność pacjenta” (Beck, 1967, s. 28).


Wykazano, że ten stan psychiczny, polegający na utracie poczucia kontroli poznawczej nad środowiskiem, nawet „normalne” jednostki czyni bardziej podatnymi biologicznie na wiele chorób. Badacze pracujący w dziedzinie medycyny zaczęli gromadzić materiał dowodowy sugerujący, że kiedy ludzie reagują na wydarzenia zachodzące w ich życiu bezradnością i poczuciem beznadziejności, to efektem tego jest złożona seria zmian biologicznych, które sprzyjają rozwojowi każdej potencjalnie obecnej choroby - nawet cukrzycy, choroby serca czy raka. Stwierdzenia te zostały wyjaśnione przez pewnego lekarza w analizie, która ma szerokie implikacje, wykraczające poza medycynę psychosomatyczną.


„Człowiek pozostaje w ciągłej interakcji z wieloma swymi środowiskami i na wielu poziomach organizacji - od subkomórkowego, biochemicznego do najbardzej zewnętrznych czy peryferyjnych środowisk - rodziny, pracy, a obecnie nawet swego wszechświata. Wysuwamy postulat, że gdy dana osoba psychicznie „daje za wygraną”, zaburza ciągłość swego stosunku do samego siebie i do swych wielu środowisk czy poziomów organizacji.
Dokonując takiego wyłomu, czyli wskutek utraty tej ciągłości, może ona stać się bardziej podatna na patogenne oddziaływanie swych środowisk zewnętrznych i (lub) może stać się bardziej odcięta od swych środowisk zewnętrznych i bardziej predysponowana do zaburzeń wewnętrznych. Choroba może zatem łatwiej pojawić się w takich okresach zaburzeń i zwiększonej podatności (Schmale, cyt. w: Brody, 1968, s. 11)




Śmierć voodoo




Niewiele jest zjawisk dotyczących człowieka, które tak przemawiają do wyobraźni, jak przypadki nagłej śmierci voodoo opisane w sprawozdaniach antropologów. Poniżej podajemy opis tego, co dzieje się w jednym z plemion z mężczyzną, który odkrywa, że jakiś wróg ustawił kość wycelowaną w niego w pewien określony sposób.


„Staje oszołomiony, z oczyma utkwionymi w zdradziecką „strzałę” i z wzniesionymi rękami, jak gdyby odpędzał śmiercionośne medium, które - jak sobie wyobraża - wpływa do jego ciała. Jego policzki bledną, oczy stają się szklane, a cała twarz wykrzywia się okropnie (...), próbuje krzyczeć, lecz głos więźnie mu zwykle w krtani i można jedynie ujrzeć pianę na jego ustach. Jego ciało zaczyna drżeć, a mięśnie kurczą się mimo jego woli.  Pochyla się do przodu i pada na ziemię, zdaje się być w omdleniu, lecz wkrótce potem wije się, jak gdyby w śmiertelnej agonii i zakrywając twarz rękami, zaczyna jęczeć. Po chwili staje się bardzo opanowany i pełznie do swej chaty. Od tego czasu choruje i dręczy się, odmawia przyjmowania pokarmu, trzyma się z dala od codziennych spraw swego plemienia. Jeśli nie nadejdzie pomoc w postaci odczynienia czarów rękoma Nangarri, czyli znachora, to jego śmierć jest jedynie sprawą stosunkowo krótkiego czasu” (Basedow; 1925, cyt. w: Cannon, 1942, s. 172).


Inne sprawozdania mówią o zdrowych ludziach, którzy zmarli nagłą śmiercią po odkryciu, że wkroczyli przeciw nadprzyrodzonemu światu, zjadając pokarm obłożony klątwą.


„Pewnemu młodemu podróżnemu, goszczącemu w domu przyjaciela, podano potrawę zawierającą mięso z drobiu. Zapytał on swego gospodarza, czy jest to dzika kura, ponieważ ten przysmak był zakazany dla młodzieży. Gospodarz odpowiedział „nie”, wiec chłopiec najadł się do syta i następnie poszedł swoją drogą. W parę lat później dwaj przyjaciele spotkali się znowu i starszy mężczyzna zapytał młodzieńca, czy jadł on kiedyś dziką kurę. Gdy młody człowiek odpowiedział „nie”, wówczas mężczyzna zaśmiał się i powiedział mi, że zjadł on zakazany pokarm przed paru laty w jego domu.  Usłyszawszy tę wiadomość, młody mężczyzna zaczął drżeć i w ciągu mniej niż 24 godzin był martwy” (Pinkerton, 1814).


Takie sprawozdania z wydarzeń obserwowanych w społecznościach, które wierzą w potęgę czarów i sił nadprzyrodzonych, zostały dokładnie przeanalizowane przez fizjologa Waltera Cannona (1942), który doszedł do przekonania o realności tego zjawiska. Niemnie jednak ludziom należącym do bardziej rozwiniętych naukowo i technicznie społeczeństw trudno jest uwierzyć w prawdziwość takich zjawisk. Nie wierzymy w czarną magię ani w czary, lecz w naturalne przyczyny racjonalnie powiązanych ze sobą zdarzeń.  Łącząc jednak śmierć voodoo z magią, nie bierzemy pod uwagę możliwości, że ostateczna przyczyna śmierci może w istocie stosować się do praw fizjologicznych uruchamianych przez poznawczy system przekonań osoby obłożonej klątwą żyjącej w społeczeństwie, które wpaja i wzmacnia takie przekonania. Aby zrozumieć, jak to jest możliwe, zapoznajmy się najpierw z tym, w jaki sposób niektóre społeczeństwa patrzą na zjawisko choroby.
Ponieważ wiemy już coś niecoś o roli oceny poznawczej we wzbudzeniu emocjonalnym, przeto łatwiej będzie nam zrozumieć tajemnicze przypadki nagłej śmierci, gdy uświadomimy sobie, że w wielu kulturach chorób nie dzieli się na psychiczne i fizyczne, tak jak u nas, ani też choroby nie przypisuje się wyraźnie przyczynom naturalnym w przeciwieństwie do nadprzyrodzonych. Choroby wczesne przypadki śmierci są częstsze w mniej rozwiniętych społeczeństwach, a zatem stanowią zawsze obecną troskę, podobnie jak ciężar leczenia chorego i opiekowania się nim. Chorzy są leczeni nie tylko przez fachowców czy specjalistów w dziedzinie medycyny - w leczeniu bierze udział rodzina i przyjaciele chorego, jak również ci, którzy z „urzędu” kierują obrzędem uzdrawiania.


„W pewnych badaniach międzykulturowych porównywano przekonania na temat chorób wyznawane przez grupę amerykańskich studentów i dorosłych wieśniaków meksykańskich (wśród których byli zarówno nie-Indianie, jak i Indianie mówiący po hiszpańsku). Klasyfikacja chorób przez studentów amerykańskich zdawała się opierać głównie na dwóch wymiarach: „Czy jest to choroba zakaźna?” i „Jak poważna jest ta choroba?”. Choroby natury emocjonalnej, takie jak niektóre psychozy i owrzodzenie żołądka, odróżniano od chorób o przyczynach organicznych.
W przeciwieństwie do powyższych stwierdzeń, analiza „meksykańskiego” systemu przekonań dotyczącego klasyfikacji chorób nie ujawniła wymiaru zaraźliwości jako takiej. Choroby klasyfikowano raczej jako wymagające albo „gorącego lekarstwa” (hot medicine) albo „zimnego lekarstwa (cold medicine) oraz jako choroby dziecięce (z których większość stanowiły choroby zakaźne) lub choroby starszego wieku, przy czym ta ostatnia kategoria obejmowała schorzenia narządów wewnętrznych i choroby spowodowane przez czary. Nie czyniono żadnej różnicy między chorobami fizycznymi i psychicznymi.
Taki system przekonań nie uwzględnia niebezpieczeństwa zarażenia się w 
przypadku epidemii, ponieważ choroby uważa się za przypadłości wynikające z 
przyczyn zewnętrznych (często o charakterze magicznym), w których to 
przypadłościach, procesy organiczne nie odgrywają czynnej roli. Jeśli wielu 
ludzi zapada na tę samą chorobę, to uważa się, że oddziałał na nich pewien 
wspólny, zewnętrzny czynnik, nad którym nie mają żadnej władzy. Stwarza to 
poważny problem dla pracowników publicznej służby zdrowia, którzy starają 
się zapobiegać szerzeniu się chorób”
(D’Andrade, Quinn, Nerlove i Romney, 1969).


Gdy jednostki zaakceptują przekonania swej społeczności dotyczące zewnętrznych przyczyn choroby, kapryśnych duchów i złych czarowników oraz nieodwracalności pewnych stanów chorobowych, wówczas łatwo zaczynają one akceptować nieuchronność swej zguby, w przypadku, gdy zostały napiętnowane jako winne wykroczenia przeciw nadprzyrodzonemu światu (Frank, 1961).  Poczucie „bezradności” u danej osoby jest następnie wzmacnianie przez przyjaciół i krewnych, którzy wierząc w ten fatalistyczny system, zaczynają wyzcofywać swe poparcie i w końcu zachowują się tak, jak gdyby śmierć już nadeszła.
Wiemy, że po długim okresie czujności czy stresu mogą wystepować u zwierząt owrzodzenia. Nietrudno zrozumieć, w jaki sposób stan skrajnego przerażenia, wzbudzony u ludzi, którzy wierzą, że są skazani na zgubę, może doprowadzić do nagłego pogorszenia stanu fizycznego i śmierci. Sugeruje się, że przyczyną śmierci w takich przypadkach jest wylew adrenaliny z wewnętrznej części gruczołów nadnerczy. Według tej teorii, adrenalina uszkadza ścianki naczyń włosowatych, umożliwiając przeniknięcie płynu do otaczających tkanek; wynikająca stąd redukcja ilości krążącej krwi wywołuje stan szoku, który prowadzi do coraz gorszego funkcjonowania serca i ośrodków nerwowych (Cannon, 1957).
Alternatywne wyjaśnienie fizjologiczne zaproponował Curt Richter (1957).


„Aby zademonstrować eksperymentalnie, że organizm pozbawiony nadziei utrzymania się przy życiu da za wygraną i zginie, zanurzał dzikie i oswojone szczury (pojedynczo) w naczyniu z wodą. Zwykle pływają one w takim zbiorniku przez około 60 do 80 godzin, zanim całkowicie wyczerpane utoną.  Jednakże szczury, którym obcięto wąsy, pozbawiając je w ten sposób ważnego źródła kontaktu ze środowiskiem, zachowują się w zupełnie odmienny sposób.
Gdy oswojonym szczurom obcięto wąsy przed zanurzeniem ich w wodzie, wówczas trzy spośród dwunastu osobników zginęły w ciągu dwóch minut, lecz pozostałe nie poddawały się i pływały przez 40 do 60 godzin. Gdy jednak procedurę tę powtórzono wobec dzikich szczurów, pozbawiając je w ten sposób kontaktu z ich naturalnym środowiskiem, wówczas wszystkie 34 zwierzęta zginęły albo w ciągu piętnastu minut od chwili umieszczenia ich w wodzie, albo nawet wtedy, gdy po prostu trzymano je w ręku. Ich rezygnacja jest jeszcze bardziej dramatyczna, gdy uświadomimy sobie, że są one „wyjątkowo dzikie, agresywne i podejrzliwe (...) nieustannie wypatrujące jakiejkolwiek drogi ucieczki”. Śmierć poprzedzało zwolnienie tempa pracy serca i obniżenie temperatury ciała, co wskazuje, że w tym przypadku śmierć była raczej wynikiem nadmiernej stymulacji układu parasympatycznego niż hiperaktywności gruczołów nadnerczy.
Za hipotezą, że pierwotną przyczyną tych przypadków nagłej śmierci było poczucie beznadziejności, przemawiają dwie obserwacje. Po pierwsze, gdy zwierzęta bliskie już śmierci wyciągnięto z wody, wówczas stawały się one w ciągu minuty lub dwóch agresywne i aktywne jak zawsze. Jeszcze bardziej przekonujące było stwierdzenie, że kiedy dzikie szczury kilkakrotnie przez krótki czas trzymano, a następnie uwalniano, a także kilka razy zanurzano je na krótko w wodzie („wstępny trening nadziei” - hope pretraining), to później nie poddawały się one i pływały aż do śmierci przez czas równie długi, jak szczury domowe”.


Zanim odrzucimy materiały dowodowe tego rodzaju, jako odnoszące się zapewne tylko do dzikich szczurów i „prymitywnych istot” ludzkich, musimy wziąć pod uwagę wyniki dokładnych badań nad przyczynami nagłej i nieoczekiwanej śmierci bardzo wielu amerykańskich żołnierzy, którzy nie brali udziału w walce w czasie, gdy umarli.


„Z tysiąca opisanych przypadków śmierci tego rodzaju, które wydarzyły się w okresie między 1942 i 1946 rokiem, badacze przeanalizowali 550 przypadków, w których młodzi, zdrowi fizycznie mężczyźni (poniżej 40 roku życia) umarli w ciągu 24 godzin od wystąpienia pewnych objawów, a umierając nie wykonywali żadnego wysiłku ani nawet nie byli aktywni fizycznie (większość spała). W stu czterdziestu przypadkach nie można było ustalić żadnej fizycznej przyczyny śmierci, po przeanalizowaniu wszelkich dostępnych protokołów i wyników autopsji dokonanych po śmierci” (Moritz i Zamchech, 1946).


W ciągu ubiegłych dwudziestu lat na University of Rochester badano wpływ stresu na choroby fizyczne. W ciągu sześciu lat ta jedna tylko placówka badawcza skatalogowała 170 przypadków śmierci wynikających z przyczyn natury psychologicznej. Występowanie zjawiska nagłej śmierci spowodowanej przyczynami tej natury nie ogranicza się bynajmniej do kultur pierwotnych i do zwierząt (Engel, 1971).




Zbliżenie


Śmierć po przyjęciu do szpitala


„W szpitalu miejskim w Baltimore nie chciano przyjąć młodej kobiety, która - chociaż bardzo wystraszona - zdawała się być zupełnie zdrowa.  Zgodzono się wziąć ją na obserwację, gdy przekonała personel, że jest przerażona z powodu tego, iż oczekuje swej śmierci w ciągu najbliższych paru dni. Opowiedziała ona dziwną historię, zgodnie z którą była ona jednym z trzech noworodków - dziewczynek odebranych przez położną w leśnych ostępach Florydy. Z jakiejś nieznanej przyczyny położna rzuciła śmiertelną klątwę na każde z tych dzieci: - że pierwsze z nich umrze przed osiągnięciem szesnastego roku życia, drugie przed ukończeniem 21 lat, a trzecie przed osiągnięciem 23 lat życia.
Dwie z tych „klątw” najwyraźniej zostały już spełnione. Pierwsza dziewczyna zginęła w wypadku samochodowym mając 15 lat. Druga została przypadkowo zastrzelona podczas awantury w nocnym klubie w wieczór swych 21 urodzin. Nic więc dziwnego, że pacjentka, ostatnia pozostała przy życiu z tej trójki, była przerażona.
Rankiem, następnego dnia po przyjęciu do szpitala, znaleziono ją w szpitalnym łóżku martwą - zaledwie dwa dni przed dniem 23 urodzin.


Chociaż „klątwa” ta mogła mieć jedynie przypadkowy związek z dwoma wcześniejszymi wypadkami śmierci, to jednak można powiedzieć, że |spowodowała śmierć trzeciej kobiety - ponieważ |uwierzyła ona, że klątwa ta posiada taką moc - i wskutek tego psychicznie i fizjologicznie „zastraszyła sie na śmierć”.




W beznadziejnych
sytuacjach ludzie
stają się bezradni




Systematyczne badania nad poczuciem beznadziejności, które wiąże się ze 
zjawiskiem nagłej śmierci, rozpoczęły się dopiero niedawno. Na ogół 
psychologowie o orientacji behawioralnej skłonni byli unikać takich mało 
ścisłych pojęć, jak „nadzieja” czy „beznadziejność”. Były jednak niekiedy 
wyjątki, gdy tego rodzaju pojęć poznawczych używano w odniesieniu do 
oczekiwania sukcesu w osiągnięciu swych celów. W psychologii celowościowej 
E. C. Tolmana oczekiwanie osiągnięcia celu jest uznawane za istotny element każdej czynności dowolnej. Tolman wykazał, że organizm podejmuje działanie tylko wtedy, gdy oczekuje, że działanie to prowadzi do pożądanego stanu docelowego („goal state”).

Oczekiwanie, że własne zachowanie może spowodować zmiany w środowisku, wytwarza stan nadziei i motywuje działanie. Apatia i bezczynność są konsekwencjami poczucia beznadziejności, która następuje po nieskutecznych reakcjach. Gdy organizm, ludzki czy zwierzęcy, dojdzie do przekonania, że nic, co może zrobić nie usunie zagrożenia, wówczas popada w stan biernej rezygnacji.
Jest bardzo możliwe, że przynajmniej u ludzi, podstawowym czynnikiem wzmacniającym, który podtrzymuje różnorodne zachowania przez długi czas, jest potwierdzenie własnej |kompetencji (White, 1959). Źródłem wzmocnienia jest tu uzyskiwanie panowania nad własnym środowiskiem zewnętrznym lub wewnętrznym, a nie samo tylko zaspokajanie pragnień czy minimalizowanie przykrości. Zarówno radość dziecka uczącego się chodzić, jak i duma, alpinisty zdobywającego trudny i niebezpieczny szczyt, wynikają ze spostrzegania siebie jako aktywnej, zdolnej do skutecznego działania osoby - co jest jedną z naszych największych radości; z drugiej strony, spostrzeganie siebie jako bezradnego pionka sterowanego przez innych ludzi jest jednym z najbardziej gorzkich doświadczeń.
Zaakceptowanie tego sterowania, czyli kontroli („control”) przez czynniki zewnętrzne czy „los” nie ma charakteru „wszystko albo nic”, lecz jest różne i zależy od naszych doświadczeń - od tego, czy przekonaliśmy się, że to, co robimy, ma jakiś wpływ na bieg rzeczy. Rotter (1966) uważa ten wymiar - to, w jakim stopniu jednostka uważa się za sterowaną (kontrolowaną) przez środowisko - za stałą cechę osobowości. Niektóre jednostki sądzą, że posiadają znaczny, wewnętrzny, osobisty wpływ na to, jakie wzmocnienia otrzymują. Na drugim krańcu tego kontinuum znajdują się ci, którzy są przekonani, że środowisko zewnętrzne - siły, na które nie mają wpływu - determinują to, co się dzieje, i że nic, co moglibyśmy zrobić, nie zmieniłoby ostatecznego rezultatu.


Wyuczona bezradność. Co dzieje się z organizmem, gdy jego władza nad środowiskiem i poczucie kompetencji ulegają destrukcji? Jak byś się czuł, gdybyś odkrył, że traumatyczne zdarzenia spotykają cię nadal - bez względu na wszelkie wysiłki z twej strony, zmierzające do tego, aby zdarzenia te zredukować czy wyeliminować?


Wróć myślą do czasów, gdy chodziłeś do szkoły podstawowej i przypomnij sobie następującą scenę: Wasza pani pyta klasę o jakieś codzienne zjawiska, które niemal każdy zna. Po każdym pytaniu podnoszą się wszystkie ręce w gorącym oczekiwaniu. „Niech pani mnie zapyta, proszę mnie zapytać, ja znam na to odpowiedź” - taki refren przebiega przez twój umysł i umysły twoich kolegów i koleżanek.
W końcu wasze oczy spotykają się. Słyszysz swoje nazwisko, wstajesz, odpowiadasz dumnie, a nauczycielka uśmiecha się. Gdy siadasz, wówczas następne pytanie znów wywołuje podniesienie lasu rąk; niektórzy koledzy są wywoływani, inni nie - i lekcja kończy się. Czego nauczyłeś się w tej sytuacji, a czego nauczyli się twoi koledzy, którzy |nie zostali zapytani?  Czy byli tacy, którzy w gruncie rzeczy nie byli |nigdy zauważani? Czego oni nauczyli się przy tej okazji?
Odpowiedzi są oczywiste. Ty otrzymywałeś wzmocnienia za podniesienie ręki i za poprawną odpowiedź, nadal więc robiłeś to i teraz jesteś na wyższej uczelni. U twoich kolegów reakcja podnoszenia ręki została po prostu wygaszona. Lecz czy to jest wszystko, czego uczyliście się w tej sytuacji?
Psycholog O. Hobart Mowrer (1960) sądzi, że specyficzne reakcje fizyczne, takie jak podnoszenie ręki, były jedynie mało istotnymi komponentami całego wzorca reakcji emocjonalnych, które zachodziły w tej sytuacji. Ty zostałeś „uwarunkowany” w taki sposób, że odczułeś |nadzieję w powyższej sytuacji; stało się tak, ponieważ twoje poprzednie reakcje przynosiły gratyfikację - zmieniały one coś w taki sposób, który był dla ciebie pożądany. Twoi nie zauważani koledzy zostali „uwarunkowani” inaczej - mieli poczucie, że ta sama sytuacja nie niesie żadnej nadziei - ponieważ ich reakcje były nieskuteczne, nie przynosiły żadnych pozytywnych konsekwencji. Twoje poczucie nadziei zachęca cię do szukania dalszych szans, do większej aktywności, do bardziej optymistycznego zapatrywania się na możliwość osiągnięcia sukcesu i zdobywania większej kompetencji w opanowywaniu środowiska; wykonujesz więcej reakcji, a niektóre z nich prawdopodobnie zostaną wzmocnione. Natomiast poczucie beznadziejności hamuje nie tylko reakcję odpowiadania na pytania, lecz także myślenie, które musi ją poprzedzać, jak również ciekawość intelektualną oraz aktywne zaangażowanie się w cały proces uczenia się. Ludzie, którzy nauczyli się czuć się bezradni w sytuacjach, które są beznadziejne, usuwają się, zniechęcają i rezygnują. Być może jeszcze gorsze jest to, że często zaczynają obwiniać samych siebie, a nie sytuację, za swój niefortunny stan.
Ten ogólny problem po raz pierwszy został poddany weryfikacji eksperymentalnej przed trzydziestu z górą laty.


„W badaniu tym głodnym szczurom wymierzano wstrząs elektryczny - po dziesięciu sekundach od chwili, gdy zaczęły jeść. Zwierzętom w jednej grupie dano możliwość sprawowania kontroli nad wstrząsem, ponieważ kończył się on, gdy zeskoczyły one z naelektryzowanej kraty. Zwierzęta w drugiej grupie nie miały żadnej kontroli nad wstrząsem. Stwierdzono, że zwierzęta, które mogły kontrolować wstrząs, jadły częściej niż te, które nie miały nad nim kontroli - mimo że jedne i drugie otrzymywały taki sam wstrząs.  Eksperymentatorzy wysunęli hipotezę, iż wymierzanie nieuniknionego wstrząsu powodowało, że zwierzęta jadły mniej, ponieważ wytworzyło się u nich „poczucie bezradności” (Mowrer i Viek, 1948).


Ostatnio spekulacje te zostały przeniesione na mocny grunt empiryczny w wyniku pomysłowych badań nad wyuczoną bezradnością, jakie na University of Pennsylvania przeprowadzili psycholog Martin Seligman i jego współpracownicy (Seligman i Maier, 1967); Overmier i Seligman, 1967; 
Seligman, 1973, 1974, 1975). Początkowo badania były przeprowadzane na psach, a obecnie są powtarzane na ludziach. Prace Seligmana ukazują nam, w jaki sposób dobrze kontrolowane badania laboratoryjne mogą doprowadzić do sformułowania zasad mogących mieć szerokie zastosowanie w problematyce psychiatrycznej, przede wszystkim do tworzenia nowych form terapii i nowych idei dotyczących przeprogramowania naszego środowiska w taki sposób, by wzbudzało w ludziach więcej nadziei. Wykryte zasady są obecnie rozwijane tak, by można je było zastosować do terapii przypadków depresji, chorób psychosomatycznych, przypadków nagłej śmierci oraz negatywnych skutków pobytu w zakładach leczniczych i opiekuńczych.
W Rozdziale 3 omawialiśmy badania Seligmana w związku z wpływem pawłowskiego warunkowania awersyjnego na późniejsze uczenie się unikania.  Obecnie zajmiemy się ponownie tymi badaniami, ponieważ wiążą się one ze zjawiskiem wyuczonej bezradności.


„U psów, których ruchy były skrępowane przez pawłowską uprząż wytworzono reakcje warunkowe na ton sygnalizujący bolesny wstrząs, od którego nie mogły one uciec. Następnego dnia psy te umieszczono w urządzeniu składającym się z dwóch pomieszczeń, gdzie miały one uczyć się prostej reakcji instrumentalnej polegającej na przeskoczeniu barierki w celu uniknięcia wstrząsu, jaki otrzymywały w pierwszym pomieszczeniu. Psy z grupy kontrolnej, których poprzednio nie poddawano warunkowaniu, szybko nauczyły się unikać wstrząsu. Natomiast 2\3 psów, które poprzedniego dnia doświadczyły nieuniknionego wstrząsu, zdawało się z rezygnacją akceptować go, zamiast uczyć się od niego uciekać. Nawet jeśli któryś z tych psów przypadkowo uciekł od wstrząsu, przeskakując przez barierkę, to w następnej próbie po prostu siadał i przyjmował wstrząs”.


Jak widać, u zwierząt tych wystąpił zarówno brak motywacji, jak i opóźnienie w uczeniu się. Seligman sugeruje, iż uprzednie doświadczenie w uprzęży dało tym psom smutną lekcję: że ich reakcje nie mają żadnego wpływu na traumatyczne środowisko. Nadzieja została wygaszona, a jej miejsce zajął strach i poczucie bezradności. Lekcję tę psy zapamiętały sobie dobrze. W pierwotnym badaniu skutki owego wcześniejszego „treningu bezradności” zdawały się zanikać po 48 godzinach, lecz późniejsze badania wykazały, że można je utrwalić. Wielokrotne wystawienie na nieunikniony wstrząs powodowało, że zwierzęta nie starały się uciec od niebezpieczeństwa, nawet jeszcze po upływie tygodnia. Badania wykazały także, że psy rasowe silniej reagowały na warunki wywołujące bezradność niż kundle o nieznanej historii, które być może musiały nauczyć się wytrwałości, aby utrzymać się przy życiu w środowisku, które było nieprzyjazne i tak nie przewidywalne, jak w laboratorium. Wyuczona bezradność nie występowała, gdy psom dano możność wyłączenia prądu (przez naciśnięcie klawisza) w czasie trwania pierwotnej sytuacji, w której otrzymywały one wstrząs w uprzęży. Gdy później umieszczono te psy w tak zwanej skrzynce wahadłowej (wspomnianym urządzeniu z dwoma pomieszczeniami), wówczas uciekały one od wstrząsu. Swe doświadczenia w zakresie sterowania otoczeniem przeniosły one na sytuację traumatyczną i nie poddawały się biernie.


Eksperymenty nad bezradnością, przeprowadzane na psach, powtórzono na studentach wyższej uczelni.


„W eksperymencie tym zastosowano trzy grupy: grupę „braku możliwości 
ucieczki”, w której osoby badane nie mogły wyłączyć silnego hałasu, „grupę 
ucieczki”, w której badani mogli wyłączyć hałas, oraz „grupę kontrolną”, 
wobec której nie stosowano hałasu. Gdy grupy te poćwiczyły przez pewien 
czas w tych warunkach, wówczas dawano im „skrzynkę wahadłową” - pudełko z 
dwoma przegródkami. Gdy osoba badana trzymała palec w jednej z nich - to 
rozlegał się głośny hałas, który ustawał, jeżeli przesunęła ona palec do 
drugiej przegródki. Stwierdzono, że zarówno badani z „grupy ucieczki”, jak 
i z grupy kontrolnej nauczyli się wyłączać hałas, przesuwając palec do 
drugiej przegródki, podczas gdy badani, którzy doświadczyli niemożności 
ucieczki, nie uciekali od hałasu, lecz pozostawali bierni”
(Hiroto, 1074).


Jeśli podniety dla reagowania dostarcza oczekiwanie, że reakcje te przyniosą ulgę od bólu, strachu lub pozwolą uniknąć innych awersyjnych sytuacji, to podnieta ta traci skuteczność, gdy ktoś zaobserwuje, że nie ma związku między jego reakcjami a zdarzeniami następującymi w środowisku.  Wyuczona bezradność, która jest wynikiem tych doświadczeń, ma szkodliwy wpływ nie tylko na behawioralną adaptację do zagrażającego środowiska, lecz także na funkcjonowanie fizjologiczne. Wyniki tych badań są niezgodne z wynikami dobrze znanych badań nad „małpami na stanowiskach kierowniczych”.




Zbliżenie


Potulny dostanie wrzodów


„U małp na stanowiskach kierowniczych rozwijają się wrzody” - taki wniosek wyciągnięto ze słynnych badań przeprowadzonych w 1958 roku; wniosek ten cytowany często zarówno w popularnej prasie, jak i w podręcznikach psychologii (Brady i in., 1958). Badacze umieszczali parę małp w pomieszczeniu, gdzie obydwie otrzymywały wstrząsy elektryczne po pojawieniu się sygnału świetlnego, jeżeli jedna z nich nie nacisnęła przełącznika, który zapobiegał wystąpieniu serii wstrząsów. Małpę operującą przełącznikiem określono oczywiście jako |małpę |na |stanowisku |kierowniczym („executive monkey”), ponieważ na niej spoczywała cała odpowiedzialność. Druga małpa nie mogła zrobić niczego, aby zapanować nad tą sytuacją. W badaniu tym u małp na stanowisku kierowniczym rozwijały się wrzody i małpy te zdychały; małpy bierne pozostały zdrowe.
Zdaje się stąd wynikać oczywisty wniosek, że ten „nacisk na rezultaty” był przyczyną wrzodów - wniosek, który gdyby okazał się prawdziwy, miałby oczywiste implikacje dla ludzi pracujących na kierowniczych stanowiskach.  Ostatnio wysunięto jednak sugestię, że wniosek ten jest prawdopodobnie fałszywy; przypuszczalnie był on wynikiem tendencyjnego wyznaczania małp do dwóch grup eksperymentalnych. Zamiast małpy wyznaczać losowo do pełnienia funkcji „kierowniczych” lub „biernych” badacze wybierali na „stanowiska kierownicze” te małpy, które wykazały najwięcej inicjatywy przy naciskaniu dźwigni dla uniknięcia wstrząsu - te, które startowały najszybciej.  „Ślamazary” były osobnikami kontrolnymi. Od tego czasu stwierdzono, że małpy, które reagują najszybciej w wypadku stosowania wstrząsów, są od początku najbardziej „pobudliwe” (być może mają najniższy próg bólu i lęku). Wniosek trzeba zatem przeformułować: |pobudliwi kierownicy częściej zapadają na wrzody niż |niepobudliwi obserwatorzy.


Gdy Joy Weiss na Rockefeller University (1968, 1971) losowo wyznaczył szczury do pełnienia funkcji „kierowniczej” i „biernej”, to bezradne zwierzęta znosiły to gorzej: więcej traciły na wadze, piły mniej, częściej wydalały kał i poważniej zapadały na wrzody niż zwierzęta na stanowiskach „kierowniczych”. Jest więc możliwe, że u kierowników rozwijają się wrzody nie tyle z powodu ich większej odpowiedzialności czy nawet ciężkiej pracy, lecz dlatego, że biorą na siebie więcej niż mogą podołać”.


Zapobieganie i leczenie bezradności. Wszyscy ludzie mają do czynienia z traumatycznymi zdarzeniami i sytuacjami, na które nie mają wpływu. Istnieje szereg czynników, które, jak wykazano eksperymentalnie, zapobiegają poczuciu bezradności, mogącemu wystąpić w naszym codziennym życiu, łagodzą je lub leczą. Do czynników tych należy immunizacja, możliwość przewidywania wynikająca z przesądów, przekonanie o sprawowaniu kontroli oraz terapia retroaktywna.


„Immunizacja” przeciw wyuczonej bezradności”. Najważniejszy rodzaj terapii ma charakter prewencyjny - jednostka zostaje „zaszczepiona” przeciw wyuczonej bezradności przez uprzednie ćwiczenie się w panowaniu nad otoczeniem („mastery training”). W laboratorium ćwiczenie to polegało na stworzeniu dostatecznej liczby sytuacji, w których psy miały możność wpływania na swe środowisko, zanim zostały poddane nieuniknionym wstrząsom.  Gdy później psy te umieszczono w „skrzynce wahadłowej”, gdzie mogły uniknąć wstrząsu, wówczas czyniły to, w odróżnieniu od bezradnych psów, które nie przeszły uprzednio ćwiczenia w panowaniu nad otoczeniem.
Implikacje tych badań dla zrozumienia ludzkich stanów bezradności są oczywiste. Właściwym czasem na rozpoczęcie takiego ćwiczenia w panowaniu nad otoczeniem jest dzieciństwo - a |ty powinieneś koniecznie nauczyć tego w przyszłości swoje dziecko, ponieważ we współczesnym społeczeństwie coraz więcej jest sił, które sprawiają, że ludzie czują się anonimowi, nie zauważani, wykorzystywani i bezsilni.


„Przewidywalność jako czynnik służący zdredukowaniu niepewności”. Nawet wtedy, gdy nie można uniknąć awersyjnej stymulacji, można zredukować jej zakłócający wpływ czyniąc ją przewidywalną.


„W jednym z badań, gdy zwierzęta nauczyły się już naciskać dźwignię dla uzyskania pokarmu, wówczas reakcja ta została zahamowana przez wymierzenie im wstrząsu. Gdy jednak wystąpienie tego wstrząsu stało się przewidywalne, wówczas zwierzęta znów zaczęły regularnie wykonywać tę reakcję. U sześciu zwierząt (z ośmiu należących do grupy nie mogącej przewidzieć wstrząsu) po 45 dniach rozwinęły się wrzody, podczas gdy u żadnego z ośmiu zwierząt w grupie mogącej przewidzieć wstrząs wrzody nie wystąpiły” (Seligman, 1968; ryc. 9.14).


Gdy wydarzenia są nieprzewidywalne, wówczas stres i lęk są silniejsze, a częstość zapadania na wrzody żołądka jest większa. Sygnalizując wstrząs nie tylko można zapobiec powstawaniu wrzodów, lecz także można zredukować strach i lęk, jakie wywołuje niepewność co do zagrażających w przyszłości wydarzeń. Badani wolą wstrząs, który poprzedzony jest sygnałem ostrzegawczym, od wstrząsu niesygnalizowanego (Lockard, 1963). Szczury wolą przewidywalne wstrząsy trwające cztery razy dłużej i trzy razy silniejsze niż wstrząsy nieprzewidywalne (Badia, Culbertson i Harch, 1973). Ludzie, którym dano do wyboru otrzymanie zawczasu informacji albo o intensywności, albo o chwili wymierzenia wstrząsu, częściej domagali się informacji o momencie jego wystąpienia niż informacji o jego intensywności (Jones, Bentler i Petry, 1966). Ponadto osoby badane chciały otrzymywać nieuniknione wstrząsy natychmiast - aby „skończyć z tym” - a nie czekać na odroczony wstrząs (Gibbon, 1967; Knapp, Kause i Perkins, 1959).
Pewne stosunkowo niedawno przeprowadzone badanie pozwoliło wzbogacić te podstawowe stwierdzenia dotyczące wpływu jaki zarówno behawioralna, jak i percepcyjna kontrola nad środowiskiem wywiera na reakcje fizjologiczne badanych ludzi.


„Studenci (mężczyźni), którzy zgłosili się na ochotnika, pracowali przez pół godziny przy wykonywaniu trudnego zadania, będącego warunkiem uniknięcia wstrząsu. Aby uniknąć wstrząsu, musieli oni nacisnąć przycisk startowy, reagować szybko przez naciskanie właściwej dźwigni po zapaleniu się jednej z szeregu lampek, po czym natychmiast przystąpić do wykonywania następnej próby. Przeciętnie co 45 minut mylili się w którymś miejscu i otrzymywali bolesny wstrząs. Poziom ich wzbudzenia pod wpływem stresu określono rejestrując wzrost skurczowego ciśnienia krwi (ciśnienie tętnicze w czasie skurczu serca).
Najpierw dwunastu osobom badanym z grupy eksperymentalnej dano możność zażądania minuty przerwy wtedy, kiedy chcieli, podczas gdy 12 osób badanych ze zrównanej grupy kontrolnej otrzymywało tyle samo przerw, ale nie na żądanie.




* * *



Ryc. 9.14. Chroniczny Strach Wywołany Przez Niemożliwy Do Przewidzenia Wstrząs. Ustalono podstawowe tempo naciskania dźwigni bez stosowania wstrząsu; następnie tempo to przyjęto za 100%. Na wykresie zaznaczono tempo naciskania dźwigni (w procentach tempa podstawowego) w przypadku stosowania przewidywalnego i nieprzewidywalnego wstrząsu. Gdy zaczęto stosować wstrząsy, wówczas tempo początkowo spadło w obu tych grupach, lecz w grupie z przewidywalnym wstrząsem tempo naciskania dźwigni wkrótce zaczęło znów stale wzrastać.


* * *





Jedna różnica miała zatem charakter poznawczy: badani w jednej grupie wiedzieli, że maja kontrolę nad reakcją unikania - polegającą na żądaniu przerwy - w drugiej zaś grupie wiedzieli, że nie mają na to wpływu. W czasie eksperymentu skurczowe ciśnienie krwi było stale wyższe u badanych bezradnych, wskazując na wyższy u nich poziom wzbudzenia (i przypuszczalnie stresu).
W drugiej części badania (w której wzięły udział inne osoby badane) przerwę przeznaczoną na odpoczynek poprzedzał sygnał wskazujący, że zbliża się „wyzwolenie”. Badani wykonywali to samo zadanie, co poprzednia grupa, a w trakcie pracy otrzymywali bodziec warunkowy sygnalizujący, że za 30 sekund będzie przerwa. Po tym sygnale badani musieli kontynuować pracę aż do rozpoczęcia się minutowej przerwy przeznaczonej na odpoczynek.
Chociaż osoby badane po otrzymaniu „sygnału bezpieczeństwa” otrzymywałyby wstrząsy równie często i równie silne jak przed nim i nie miały żadnego wpływu na jego wystąpienie, to jednak dzięki temu, że wiedziały o zbliżającej się przerwie, uzyskiwały kontrolę percepcyjną (perceptual control) ich ciśnienie krwi spadało znacznie zaraz po pojawieniu się sygnału. Gdy w dodatku mieli wpływ na czas pojawienia się sygnału bezpieczeństwa (a więc mieli zarówno kontrolę percepcyjną, jak i behawioralną), wówczas redukcja stresu fizjologicznego była jeszcze większa, chociaż liczba sygnałów i okresów odpoczynku pozostała bez zmiany (Hokanson, DeGood Forrest i Brittain 1971).


„Przesądy dające poczucie sprawowania kontroli”. Wszystkie sytuacje, które bada się w sztucznych warunkach pracowni psychologicznej, mają swe odpowiedniki w naszym życiu codziennym. Bezradność często wiąże się z usiłowaniami kontrolowania środowiska za pomocą magii. Przesądy kwitną wtedy, gdy ludzie nia mają kontroli nad swym środowiskiem, a jednak muszą podejmować ryzykowne decyzje. Chociaż koncepcje dotyczące funkcji, jaką spełniają zachowania magiczne, mają charakter spekulatywny, to jednak duże rozpowszechnienie przesądów jest faktem. W wypadku wyuczonej bezradności mamy do czynienia z związkami pomiędzy naszymi reakcjami, konsekwencjami środowiskowymi oraz spostrzeganiem możliwości kontroli. Przekonaliśmy się, że możliwość kontroli zapobiega wystąpieniu bezradności. Zaskakujące jest jednak to, że rzeczywista kontrola nie ma istotnego znaczenia. Natomiast ważne jest po prostu przekonanie, że sprawuje się kontrolę.


„W pewnym badaniu, dotyczącym stresu miejskiego oraz braku możliwości kontroli, wykazano, że przekonanie osób badanych, iż mogą wyłączyć nie dający się kontrolować głośny dźwięk, powodowało osiąganie przez nich lepszych wyników w zadaniach polegających na korekcie tekstów i rozwiązywaniu problemów, w porównaniu z wynikami uzyskiwanymi przez bezradne osoby badane. Wyniki były również lepsze wtedy, gdy badani byli przekonani, iż osoba, która mogła wyłączyć hałas, jest dostępna - mimo że hałas nie był wyłączany” (Glass i Singer, 1972).


Wyniki te sugerują, że przesądy ludzkie spełniają psychologicznie ważną funkcję. Przesądy chronią przed wyuczoną bezradnością, dostarczając przesądnej osobie złudzenia sprawowania kontroli.




Zbliżenie


Zabobony jako kulturowe mechanizmy kontroli poznawczej


„Psychologowie skłonni są przyjmować zbyt wąski sposób patrzenia na genezę i funkcje zabobonów i przesądów.



Koncentrując się na tym, jak jednostki uczą się zabobonnych nawyków, mogą nie zwracać uwagi na sposób, w jaki różne kultury przekazują takie nawyki swym członkom.
Magiczne obrzędy wytwarzają poczucie sprawowania kontroli. Możemy przypuszczać, że zabobonne zachowanie nasila się wówczas, gdy ludzie czują się zagrożeni, bezradni, kontrolowani lub pozbawieni wystarczającej wiedzy, aby podejmować decyzje, które mogą mieć istotne znaczenie dla przetrwania.  W społeczeństwach, które funkcjonują na poziomie gospodarki naturalnej i są uzależnione od kaprysów przyrody, jeśli chodzi o zdobycie codziennego chleba, ryby czy zwierzyny, magiczne zaklęcia i obrzędy stwarzają złudzenie sprawowania kontroli. Jest to w końcu coś, co społeczność może uczynić, aby pomóc przeważyć szalę tego losu, zamiast biernie czekać na koniec suszy lub wygaśnięcie zarazy.
W pewnym plemieniu, w którym polowanie jest głównym źródłem pożywienia, ktoś musi zadecydować o tropieniu zwierzyny w porze jej wędrówek. Stado nie zawsze obiera tę samą drogę i oczekiwanie w złym miejscy może spowodować, że plemię nie będzie miało co jeść. Takie zasadnicze decyzje wiązałyby się ze zbyt wielką odpowiedzialnością pojedynczej osoby, a więc odpowiedzi poszukuje się zwykle za pomocą magicznych praktyk. Rzuca się na przykład kości na ziemię, a ich układ „odczytuje się” jako wiadomość od bogów, gdzie należy tropić stado. Jeśli myśliwym nie powiedzie się, to przyjmuje się, że bogowie są niezadowoleni, a zatem trzeba podjąć jakieś nowe działania, aby odzyskać ich łaskę. Tak więc nawet wtedy, gdy magiczne działanie nie przynosi pomyślnych konsekwencji, to prowadzi do jakiegoś działania - co pomaga zapobiec poczuciu bezradności lub pozbyć się go.
Zabobonne wierzenia pomagają także wyjaśnić niezwykłe, nienaturalne zdarzenia i „niekonsekwencje” w czyimś życiu. Jeśli zdrowe dziecko zachoruje, to w wielu krajach świata przyjmuje się, że ktoś musiał rzucić na dziecko „urok”, i że trzeba go „odczynić”. Niemowlęta w Puerto Rico, we Włoszech i w innych krajach często ubiera się w specjalne kolory i zakłada się im amulety (często w kształcie rogu), aby uchronić je przed urokiem.  Brzmi to dziwnie, lecz czy ty nie „odpukiwałeś w nie malowane drzewo”, aby odwrócić „pecha”?
Siłę takich wierzeń („zabobonnych” dla niektórych, lecz przez wielu uważanych za „religijne”) ilustruje historia, która niedawno zdarzyła się na Hawajach. 21 listopada 1973 roku pewien robotnik na budowie stadionu Halawa spadł i zabił się - jeszcze jeden z wielu wypadków na tej budowie.  Robotnicy przypomnieli sobie, że w lipcu 1971 roku wielebny Abraham K.  Akaka odmówił pobłogosławienia budowy stadionu, ponieważ w tym czasie kilku ludziom zamieszkałym na terenie budowy władze nie przyznały zastępczego mieszkania. Ponadto pewna kobieta, sprzeciwiająca się wzniesieniu stadionu, w czasie uroczystego rozpoczęcia jego budowy w 1971 roku modliła się w języku hawajskim do starych hawajskich bóstw. W rezultacie wielu robotników porzuciło pracę.
Znaleziono więc zabobonne wyjaśnienie dla tej tragedii. Jeśli wypadek został spowodowany przez klątwę, to przyszłym wypadkom można by zapobiec przez odwołanie tej klątwy i udzielenia od nowa błogosławieństwa. Kobietę tę przekonano, aby odwołała swą „klątwę”, a wielebny Mr. Akaka zgodził się pobłogosławić w pełni budowę stadionu, ponieważ znaleziono mieszkania dla przesiedlonych mieszkańców. Zadowoleni robotnicy powrócili do pracy” („Honolulu Advertiser”, 24 listopada 1973).


W badaniach Hiroto (1974) nad wyuczoną bezradnością u studentów badani, którzy byli przekonani, że uzyskiwane w skrzynce wahadłowej wyniki są zdeterminowane przez przypadek, byli bardziej bezradni niż badani, u których wywołano przekonanie, że „skrzynka wahadłowa” stanowi test umiejętności. Ponadto przy użyciu testu osobowości badanych podzielono na grupy, zgodnie z ich przekonaniem o istnieniu wewnętrznych lub zewnętrznych źródeł kontroli. Studenci „wewnętrznie sterowni” sądzili, że mają wysoki stopień kontroli nad środowiskiem, podczas gdy badani „zewnętrznie sterowani” byli przekonani, że konsekwencje środowiskowe są w dużej mierze niezależne od ich zachowania. Osoby „zewnętrznie sterowane” łatwiej stawały się bezradne w sytuacji testowej, w której zagrażał wstrząs elektryczny, niż badani „wewnętrznie sterowani”.
Przekonanie o możliwości kontroli nad środowiskiem oraz spostrzeganie, że wyniki zadania są zależne od własnych umiejętności, stanowią ważne czynniki zapobiegające bezradności. Jednostka, która wierzy tylko w los, łatwo rezygnuje, kiedy znajdzie się w awersyjnych warunkach. Spostrzeganie własnej wiedzy, umiejętności i działania jako efektywnych - nawet jeśli jest to „tylko” przekonanie przesądne - chociaż nie zmieni warunków, to jednak zapobiegnie psychicznym następstwom bezradności: depresji, bierności i śmierci z przyczyn psychosomatycznych.
Z drugiej strony, kiedy akceptujesz przesądne przekonanie, że niewykonanie jakiegoś określonego zachowania będzie mieć przykre konsekwencje, to zawierasz „bezterminowy kontrakt na nieszczęście”. Jest niemożliwością, aby okazał się on fałszywy, ponieważ nie ma żadnej granicy czasu, w ciągu którego ma cię spotkać nieszczęście - „może nie dzisiaj i nie jurto, lecz w końcu zobaczysz”. Przesądy nie określają dokładnie, kiedy czy gdzie trzeba będzie zapłacić za niepodporządkowanie się. W rezultacie przekonanie to zawsze okaże się prawdziwe, jeśli poczekasz dostatecznie długo na zapłatę.


„Terapia retroaktywna”. Jeśli nie zapobiega się wystąpieniu poczucia bezradności, to można je złagodzić za pomocą postępowania terapeutycznego, które stosuje się już po wytworzeniu się tego stanu. Takie postępowanie terapeutyczne po ujawnieniu się problemu nosi nazwę |terapii |retroaktywnej. Poczucie beznadziejności u dzikich szczurów zamkniętych w klatce eliminuje się po prostu przez kilkakrotne zanurzenie ich w wodzie na parę minut, a następnie uwolnienie ich. Parę takich prób wystarczy, aby ponownie nauczyły się one „mieć nadzieję”; stają się one po tym znów agresywne, usiłują uciec i nie dają „za wygraną”. Stwierdzono, że u biernych psów w badaniach Seligmana można było przełamać syndrom wyuczonej bezradności, jeśli przeciągnięto je siłą (niekiedy aż 200 razy) z pomieszczenia, gdzie otrzymywały wstrząsy, do pomieszczenia „bezpiecznego”, dzięki czemu odkrywały ponownie, iż reagowanie może przynieść ulgę i rozwijały samorzutną aktywność.
Objawy wyuczonej bezradności u tych psów wykazywały znaczne podobieństwo do depresji u ludzi. Depresja jest obecnie najbardziej rozpowszechnionym zaburzeniem psychicznym w Stanach Zjednoczonych, a częstość jej występowania jeszcze wzrasta. Gdy depresja staje się chroniczna, wówczas może prowadzić do alkoholizmu, długotrwałej hospitalizacji, a niekiedy do samobójstwa. W Rozdziałach 11 i 12 omówimy dokładniej depresję i jej leczenie, lecz warto tu wspomnieć, że badania Seligmana wykazały wyraźne podobieństwa w zachowaniu bezradnego psa i u osoby w stanie depresji (bierność, negatywizm, brak energii), to zaś sugeruje, iż terapia w stosunku do ludzi cierpiących na depresję mogłaby być podobna do sposobu postępowania wobec bezradnego psa - mogłaby polegać na uczeniu efektywnego działania, odzyskiwania kontroli nad otoczeniem, ponownego odkrywania, że reakcje wywołują pożądane konsekwencje środowiskowe. Może to oznaczać program kształtowania reakcji przez nakłanianie danej osoby do wykonywania choćby minimalnych reakcji, które są zawsze wzmacniane, a następnie stopniowe zwiększanie złożoności i intensywności wzmacnianej reakcji dopóty, dopóki nie będzie ona podejmowana z własnej inicjatywy.




Nadzieja, wiara
i placebo




Jeśli zjawiska zaburzeń psychosomatycznych, wyczerpana wskutek stresu oraz wyuczona bezradność obrazują negatywny wpływ psychiki na ciało, to jakie są dowody świadczące o jej pozytywnym działaniu?
Wiara, zdefiniowana jako przekonanie o czymś mimo braku wiedzy lub mimo niemożności empirycznego potwierdzenia, jest istotnym elementem religii i religijnych uzdrowień. Bezwzględna wiara we wszechmoc Boga może stanowić potężne źródło motywacji opartej na oczekiwaniu („expectancy motivation”).  W jednym z badań 71% pacjentów wyznania rzymskokatolickiego stwierdziło, że ich wiara religijna pomogła im przetrwać kryzys operacyjny, a ich karty chorobowe wykazały, że wymagali oni znacznie mniejszych dawek morfiny niż pacjenci innych wyznań (Egbert, 1969). Sekty uzdrowicielskie, takie, jak Christian Science, oraz sanktuaria cudownych wyleczeń, takie, jak Lourdes we Francji, przyciągają miliony wiernych ze wszystkich stron świata.  Istnieje bogaty, dobrze udokumentowany materiał dowodowy, zgodnie z którym poważne choroby zostawały wyleczone, chromi odrzucali kule, a niewidomi odzyskiwali wzrok po wzięciu udziału w religijno-emocjonalnych pielgrzymkach do takich miejsc (Cranston, 1955).
Wyleczenia takie, czy to sceptycznie uważane za uzdrowienia psychiki, czy też akceptowane jako wyleczenia z choroby organicznej, stanowią dla wyleczonej osoby rzeczywistą ulgę od prawdziwego bólu, kalectwa i cierpienia, trwających nieraz przez całe życie. Nasze wcześniejsze rozważania na temat bólu i złożonej interakcji psychiki i czynników organicznych, jaką stwierdzono w genezie chorób, powinny wykazać, jak trudno jest ustalić, czy ból jest „realny”, czy też krwawiący wrzód istnieje wyłącznie w czyjejś psychice.
My, ludzie nowocześni, wierzymy w lekarzy, w obrzędowe wizyty w gabinetach oraz w pigułki, jakie zapisują. Ta wiara jest tak silna, że nawet wtedy gdy zastosowana pigułka czy procedura stanowi w rzeczywistości |placebo (nie ma żadnych właściwości leczniczych), to jednak mogą one uwolnić daną jednostkę od bólu i innych objawów choroby. Lecz jak dalece skuteczna może być w rzeczywistości taka pigułka zawierająca jedynie sproszkowany cukier?


„W badaniach, które objęły 4681 pacjentów leczonych za pomocą placebo z ponad 20 rozmaitych schorzeń lub dolegliwości, z przeziębieniem, padaczką i stwardnieniem rozsianym włącznie, pozytywne rezultaty osiągnięto w 27% przypadków (Haas, Fink i Hartfelder, 1959). Według innego sprawozdania, placebo przyniosło ulgę w bólach głowy w 58% z 4588 przypadków. Ogólnie biorąc, leczenie za pomocą placebo przyniosło pozytywne rezultaty w przypadkach około 1/3 wszystkich pacjentów badanych w 15 seriach testowych (Beecher, 1959). Nawet ból spowodowany nieuleczalną chorobą organiczną zmniejszał się. Podobnie w badaniach, w których porównywano ulgę w bólu, jaką przynosiły zastrzyki placebo i zastrzyki morfiny 122 pacjentom cierpiącym na bóle z powodu ran pooperacyjnych, 39% pacjentów doznało ulgi od placebo, podczas gdy morfina przyniosła ulgę 67% pacjentów. Chroniczny ból spowodowany rakiem został złagodzony u 65% pacjentów, którzy otrzymali zastrzyk 10 miligramów morfiny. Jednakże 10 miligramów placebo w równym stopniu pomogło 42% innych pacjentów także chorych na raka” (Beecher, 1959).


|Wiara, że placebo doprowadzi do złagodzenia bólu, wystarczy więc, aby spowodować poważną psychiczną (a może i fizjologiczną) reorganizację. Wiara taka nie tylko redukuje ból, lecz może nawet wywołać nowe „objawy”.  Pacjenci leczeni za pomocą placebo uskarżają się na różnorodne „ujemne skutki uboczne”, jakie występują po podaniu leku-placebo, takie, jak mdłości, bóle głowy, senność i zmniejszona koncentracja.
Jednakże przekonanie pacjenta może uczynić coś więcej niż nadać skuteczność obojętnemu środkowi: może ono nawet |odwrócić zwykłe farmakologiczne działanie danego lekarstwa. Ipecac, środek, który normalnie stosuje się w celu wywołania wymiotów (na przykład w przypadkach zatrucia), „działał uzdrawiająco na pacjentki, cierpiące na mdłości w związku z ciążą, gdy zasugerowano im, że otrzymają skuteczny przeciw nim środek” (Haas i in., 1959, s. 27).
Pozytywne reakcje na placebo stanowią „problem” właśnie dlatego, że placebo działa tak dobrze wtedy, kiedy się tego nie oczekuje. Jak można sprawdzić skuteczność „prawdziwego” lekarstwa czy procedury terapeutycznej, gdy ludzie tak łatwo reagują na swe oczekiwania, zamiast na fizyczne właściwości środka leczniczego?
Warto poznać cechy, które odróżniają osoby reagujące na placebo od osób nie reagujących na nie. Te osoby, którym placebo przynosiło ulge w bólach pooperacyjnych, zwykle uczęszczały regularnie do kościoła, były gadatliwe, lękliwe, zależne, skoncentrowane na sobie i zaabserbowane swymi procesami fizjologicznymi. Osoby nie reagujące na placebo były zwykle sztywne, miały skłonność do wycofywania się, i były raczej intelektualnie krytyczne niż emocjonalnie reaktywne (Lasagna i in., 1954).
Ogólnie biorąc, gdy poda się placebo tym, którzy wierzą w zalecenia lekarzy i w autorytety, to doznają oni redukcji |lęku dotyczącego ich choroby i w związku z tym następuje złagodzenie bólu i polepszenie stanu zdrowia. Ponieważ nawet najbardziej racjonalnie krytyczna i intelektualnie sceptyczna osoba może zachować pewne „irracjonalne” wierzenia z dzieciństwa, przeto każdy może być osobą potencjalnie reagującą na placebo.




Kontrola poznawcza
motywacji




„Głodny lis zobaczył piękne, winne grona zwisające z wysokich podpór w winnicy. Próbował wielokrotnie dosięgnąć ich, skacząc jak najwyżej zdołał, lecz wszystkie jego wysiłki były próżne, ponieważ grona wisiały zbyt wysoko. Zmęczony swymi usiłowaniami, opuścił w końcu winnicę. Z udaną obojętnością powiedział: „|Naprawdę |nie |byłem |specjalnie |głodny. Poza tym myślałem, że te winogrona są dojrzałe, lecz teraz wiem, że są kwaśne”.
Ezop „Lis i winogrona”, VI w. p.n.e.


Czy lis powiedział, że nie był głodny, ponieważ usiłował przez racjonalizację złagodzić swój stan wzmożonego popędu? Czy też w rzeczywistości skutecznie zredukował swój popęd głodu za pomocą procesu poznawczego? Gdy nie dostajemy tego, czego chcemy (lub potrzebujemy), gdy musimy odłożyć na później gratyfikację lub znosić jakiś nieprzyjemny, awersyjny stan, czy też deprywację, wówczas możemy regulować działanie bodźców biologicznych i środowiskowych za pomocą kontroli poznawczej („cognitive control”). Myśl może ująć daną sytuację w pewien sposób, a procesy poznawcze - w inny. Ludzie nie muszą reagować na sytuację, taką, jaka jest im dana; mogą oni, za pomocą swej wyobraźni |określić sytuację tak, by dopasować ją do swych potrzeb, motywów i uznawanych wartości.
Aby zweryfikować tę podstawową ideę, przeprowadzono szereg badań w pracowniach psychologii społecznej na uniwersytetach New York, Duke i Ohio State. Ponad 1000 osób badanych stawiano w różnych sytuacjach, w których wzbudzano w nich silne popędy biologiczne (głód, pragnienie, ból) lub silnie społecznie motywujące stany (motyw osiągnięć, motyw aprobaty, frustrację, agresję). Rejestrowano negatywny wpływ tych stanów motywacyjnych na zachowanie i funkcje fizjologiczne. Następnie osoby badane proszono, aby poddały się jeszcze raz tym samym procedurom lub aby zgodziły się przeżyć jeszcze silniejsze wzbudzenie.
W pewnych warunkach osoby badane zgadzały się kontynuować swój udział w badaniach po otrzymaniu dostatecznego „uzasadnienia” (pieniądze, nacisk społeczny lub przekonywujące argumenty), aby to czynić. W innych warunkach osoby badane zgadzały się brać nadal udział w badaniach, gdy dano im do |wyboru, aby to uczyniły lub zrezygnowały, chociaż otrzymały one jedynie minimalne uzasadnienie.
Jak sądzisz, w których warunkach wzbudzenie motywacyjne miało w drugiej serii badań |mniejszy wpływ na osoby badane? Ci, którzy zgodzili się nadal uczestniczyć w badaniach pod silnym naciskiem i przy dostatecznym uzasadnieniu, cierpieli tak samo, jak w pierwszej fazie badań. Jednakże te osoby badane, które dobrowolnie zgodziły się znosić nieprzyjemne doświadczenia przy jedynie minimalnym uzasadnieniu tego wyboru, kontrolowały poznawczo wpływ stymulacji w drugiej fazie badań. Wstrząsy elektryczne nie bolały tak bardzo, jak za pierwszym razem, badani byli mniej spragnieni i głodni, mniej agresywni i bardziej zdolni do tolerowania frustracji i niepowodzeń itd. Osoby badane z grupy, która otrzymywała niewielkie uzasadnienie, nie tylko mówiły i działały w ten sposób, lecz również na poziomie fizjologicznym nie reagowały tak silnie na bodziec motywacyjny. Było to tak, jak gdyby to one same wyperswadowały sobie przesadne obawy - no i patrzcie, miały rację. Motywacja została dopasowana do przyjętych zobowiązań dotyczących zachowania. Ostatecznie „idiotyzmem” byłoby zgadzanie się na przyjmowanie bolesnych wstrząsów bez żadnych wystarczających powodów, gdy miało się możność zrezygnowania, czyż nie?  Jednakże decyzja ta nie byłaby tak niekonsekwentna czy niespójna, gdybyś przekonał sam siebie, że wstrząsy te nie są zbyt bolesne. Istotnie, wstrząsy o tym samym napięciu były przez te osoby badane oceniane jako mniej bolesne (w porównaniu z osobami z grupy kontrolnej, które nie miały wyboru, lecz otrzymały dostateczne uzasadnienie; Zimbardo, 1969).
Możemy zatem obecnie stwierdzić, że procesy kontroli poznawczej mogą wprowadzić spójność tam, gdzie jej brakuje, nawet jeśli wymaga to zmiany zwykłej relacji pomiędzy bodźcem fizycznym a reakcją organizmu na niego.  Lecz jak daleko sięga wpływ kontroli poznawczej?




Kontrola poznawcza
śmierci




Czym jest starość w społeczeństwie, które tak ceni młodość? W najlepszym razie ludzie w podeszłym wieku są tolerowani - częściej są oni ignorowani, daje im się odczuć, że są bezużyteczni i stanowią ciężar dla swej rodziny.  W przybliżeniu co dziesiąty Amerykanin ma ponad 65 lat, a procent ten będzie wzrastał w miarę, jak wzrasta przeciętna długość życia. Dwie trzecie osób w tym wieku cierpi na jakieś chroniczne schorzenia, takie jak wysokie ciśnienie krwi, choroby serca czy artretyzm. Coraz więcej spośród nich odsyła się do domów opieki, których w Stanach Zjednoczonych jest około 30 tysięcy. „Przypomina to wyrzucanie starych samochodów na stertę złomu”, skomentował te fakty Charles Boucher, wyższy urzędnik Brytyjskiego Ministerstwa Zdrowia.
Jakie konsekwencje ma dla osób starszych to, że ich rodzina zmusza je do przeniesienia się do domu starców?


„W pewnym starannie udokumentowanym badaniu nad 40 osobami, których podania o przyjecie otrzymał pewien dom opieki w Cleveland (stan Ohio), stwierdzono, że 23 osoby zmarły w ciągu miesiąca od chwili przesłania pocztą tego podania. Okazało się, że wśród zmarłych ogromną większość stanowiły te osoby, których podania zostały przesłane przez ich rodziny, w przeciwieństwie do tych osób, które same wysłały podania” (Ferrare, 1962).


Wyniki tych badań sugerują istnienie ważnego związku pomiędzy spostrzeganiem możliwości wyboru w sprawie przeniesienia się do domu opieki, a omawianym wcześniej zjawiskiem „nagłej śmierci”. Wydaje się prawdopodobne, że skrajna bezradność jest powszechna wśród ludzi, którzy czują, że nie mają innego wyjścia, jak tylko opuścić swój własny dom i przenieść się do obcego, pełnego beznadziejności otoczenia, bez żadnych powiązań z przeszłością, niepewną teraźniejszością i najgorszymi oczekiwaniami na przyszłość. Natomiast porównywalna grupa osób, które były przekonane, że nadal zachowały swobodę wyboru i że nie muszą przenosić się do domu opieki, jeśli nie chcą tego uczynić, łatwiej mogła przestrukturalizować poznawczo swe środowisko tak, by życie w nim uczynić znośnym. Ten kierunek rozumowania znajduje potwierdzenie w wynikach innego badania - należących do najbardziej dramatycznych w naszej literaturze psychologicznej - uzyskanych przez tego samego badacza.


„Po przeprowadzeniu wywiadu z każdą z 55 kobiet starających się o przyjęcie do domu opieki, podzielono je na dwie grupy: pierwszą, złożoną z 17 kobiet, które były przekonane, że nie mają żadnego innego wyboru - muszą iść do domu opieki, oraz drugą, złożoną z 38 kobiet, które uświadamiały sobie, że mają inne możliwości, mimo że zamierzają pójść do tego domu. W ciągu dziesięciu tygodni od czasu przyjścia do domu opieki w grupie nie mającej wyboru wszystkie kobiety, oprócz jednej, zmarły. Zupełnie odmienna sytuacja była w grupie mającej wybór, gdzie wszystkie kobiety, oprócz jednej, żyły nadal. Analiza danych medycznych wykazała, że między kobietami należącymi do obu grup nie było różnic w stanie zdrowia w czasie przyjmowania ich do zakładu” (Ferrare, 1962).


Jeśli możność dokonania wyboru jest zmienną niezależną przyspieszającą lub opóźniającą śmierć, to danie ludziom poczucia, że mogą dokonać wyboru, powinno przedłużyć ich życie. Nawet tym, którzy nie mają rzeczywistego wyboru, jeśli chodzi o przeniesienie się do domu opieki, można by przedstawić szereg minimalnych wyborów, takich jak wybór dnia, w którym mają wprowadzić się do tego domu, piętra, na którym mają zamieszkać, jednej z kilku różnych czynności, którymi mają się zajmować itd. Jeśli przekonanie o własnej bezradności prowadzi do śmierci, to manipulowanie środowiskiem w celu stworzenia „złudzenia wyboru” i sterowania otoczeniem przez swe decyzje powinno opóźnić śmierć i przedłużyć życie. Takie badania trzeba będzie dopiero przeprowadzić.
Filozof egzystencjalista, Jean-Paul Sartre (1957), powiedział, że „człowiek stwarza sam siebie” i „przez swój wybór angażuje całą ludzkość i nie może uniknąć dokonywania wyboru”. Jeśli bezradnej, pogrążonej w poczuciu beznadziejności osobie nie można dostarczyć sensownej alternatywy, to jej ostatnim wyborem może być śmierć. Jeśli społeczeństwo nie dostarcza swym obywatelom sensownych możliwości, to jakość życia społecznego obniża się.




Streszczenie rozdziału




Ludzi od dawna intrygowała zagadka niefizycznej „psychiki” w fizycznym ciele. Niektórzy psychikę i duszę uważali za podstawową i trwałą rzeczywistość; inni, jak na przykład przedstawiciele behawioryzmu amerykańskiego, nieomal całkowicie ignorowali ich istnienie. Obraz ten jednak się zmienia.
|Emocje, trudne do obiektywnego zdefiniowania, były przedmiotem wielu badań. Jednakże badania te koncentrowały się na ogół na ich zakłócających czy negatywnych aspektach.
Emocje u innych określamy w dużej mierze na podstawie ich zachowania niewerbalnego; zewnętrzne przejawy emocji są w dużej mierze wyuczone - zgodnie z normami i oczekiwaniami kulturowymi. Darwin wysunął sugestię, że pewne wzorce ekspresji emocjonalnej są wrodzone - zarówno u zwierząt, jak i u ludzi. Jednakże znaczenie takich wzorców ekspresji może być odmienne w różnych kulturach. Proste emocje można oceniać z pewnym stopniem dokładności i zgodności, nawet w rozmaitych kulturach, lecz to samo zachowanie, na przykład płacz, może występować w kilku różnych emocjach.  Niekiedy odbieramy sprzeczne lub niejednoznaczne sygnały i skłonni jesteśmy opierać się przede wszystkim na wskazówkach sytuacyjnych.
Zgodnie z |teorią |Jamesa-|Langego, zjawiska fizjologiczne poprzedzają i powodują odczuwanie emocji, lecz poszukiwanie specyficznych reakcji wewnętrznych, związanych z różnymi emocjami, przyniosło jedynie umiarkowane sukcesy. Współczesne badania nad czynnikami fizjologicznymi w emocjach koncentrują się na roli |mechanizmów |nerwowych (zwłaszcza |układu |limbicznego, czyli rąbkowego) oraz pewnych gruczołów wydzielania wewnętrznego (zwłaszcza |przysadki |mózgowej i |gruczołów |nadnerczy).  |Adrenalina (epinefryna) jest hormonem, który zdaje się być najbardziej związany z reakcjami strachu, podczas gdy |noradrenalina (norepinefryna) wiąże się przede wszystkim z reakcją gniewu.
|Sygnały |fizjologiczne prawdopodobnie wpływają na |intensywność odczuwania emocji, lecz ich |jakość - to, jaką emocję się odczuwa - zależy częściowo od |sygnałów |poznawczych, jakich dostarcza interpretacja sytuacji prze daną jednostkę.


Skomplikowane badania Schachtera i Singera dostarczyły poparcia dla tej teorii, lecz w ich badaniach wykazano szereg skaz metodologicznych. |Ocena, zarówno znaczenia i powagi sytuacji, jak i możliwych strategii radzenia sobie z nią, odgrywa niewątpliwie doniosłą rolę w determinowaniu odczuwanej emocji.
|Stres jest reakcją organizmu na wymagania środowiska, pozytywne lub negatywne. Jest on nieuniknioną częścią życia i musimy nauczyć się radzić sobie z nim, a nie próbować go uniknąć. Chroniczny stres spowodowany nieustannym naciskiem lub stłumionymi emocjami może prowadzić do |choroby |psychosomatycznej lub zwiększonej podatności na emocje. Istnieje wyraźny związek miedzy |wskaźnikami |kryzysów |życiowych a kłopotami ze zdrowiem.  Czynniki emocjonalne mogą także przeszkadzać w wyleczeniu się z choroby.
Reakcje organizmu na stres można wyjaśnić w kategoriach |ogólnego |zespołu |adaptacyjnego, który składa się z |reakcji |alarmowej (|mobilizacyjnej), |stadium |odporności |oraz |stadium |wyczerpania.
Możliwość dokonania |oceny |poznawczej zwiększa naszą zdolność radzenia sobie również z wysoce zagrażającymi sytuacjami. Nawet negatywne emocje mogą być przystosowawcze. Pacjenci, którzy odczuwają umiarkowany strach przed operacją, podlegają mniejszemu stresowi i szybciej wracają do zdrowia niż ci, którzy przed operacją odczuwają albo silny, albo słaby strach.  Ostrzeżenia przed niebezpieczeństwem, które wytwarzają jedynie umiarkowany strach, częściej skłaniają do działania niż ostrzeżenia, które wzbudzają u ludzi większy strach. Warunkiem większej skuteczności ostrzeżeń są także wyraźne wskazówki co do sposobu niezbędnego działania oraz zmiana postawy wobec tego działania. Ludzie narażeni na możliwe do przewidzenia niebezpieczeństwo, jak w wypadku skoku ze spadochronem, mogą nauczyć się radzić sobie ze swym strachem w skomplikowany, pośredni sposób.
Ból służy zarówno jako system |sygnałowy, jak i system |obronny (odruchowy), chroniąc organizm przed fizycznym uszkodzeniem. Poznawcze aspekty bólu są złożone i obejmują styl funkcjonowania percepcyjnego, wyuczone skojarzenia oraz poznawczą modyfikację wejścia sensorycznego. W sposobie reagowania na ból spowodowany zabiegami chirurgicznymi występują znaczne różnice kulturowe, związane z różną interpretacją tego bólu. Pod hipnozą można osiągnąć znaczny stopień kontroli poznawczej nad bólem.  Dewiacyjne zastosowania bólu obejmują posługiwanie się bólem jako torturą albo też jako źródłem mistycznego zjednoczenia lub rokoszy seksualnej.
Przekonanie, że nie ma się żadnego wpływu na swoje środowisko, może prowadzić do rezygnacji i w końcu do śmierci, nawet u zdrowych poprzednio jednostek. Takie przypadki śmierci z przyczyn natury emocjonalnej mogą zdarzać się w obozach koncentracyjnych lub jako reakcja na klątwę voodoo. W wielu kulturach nie czyni się różnicy między chorobami fizycznymi i psychicznymi ani też między ich naturalnymi i nadprzyrodzonymi przyczynami.  W przypadkach śmierci voodoo lub jej podobnych niezwykle silne przerażenie może prowadzić do gwałtownego wydzielania się adrenaliny, co wywołuje stan wstrząsu; w okolicznościach tego typu śmierć może też być spowodowana zbyt silnym podrażnieniem parasympatycznego układu nerwowego. Badania laboratoryjne i kliniczne wskazują na rolę |bezradności i |poczucia |beznadziejności w uruchamianiu tego mechanizmu.
Sugeruje się, że poczucie |kompetencji i kontroli nad środowiskiem mają podstawowe znaczenie dla przetrwania; uczucie bezradności prowadzi do biernej rezygnacji - zarówno u ludzi, jak i u zwierząt. Badania wykazały jednak, że takiej bezradności można zapobiegać lub leczyć ją kilkoma sposobami, a mianowicie za pomocą: 1) |immunizacji, czyli uprzednich doświadczeń w sterowaniu otoczeniem, 2) |możności |przewidywania nieuniknionych, przykrych zdarzeń, 3) wynikającego z |przesądów przekonania o możliwości sterowania otoczeniem tam, gdzie w rzeczywistości jej nie ma, oraz 4) |terapii |retroaktywnej, czyli ćwiczeniu efektywnego działania w takich sytuacjach, w których nadzieja i sterowanie są możliwe.
Podobnie jak wiara, że się umrze, może spowodować śmieć zdrowej osoby, tak i wiara, że się wyzdrowieje, może spowodować cofnięcie się fizycznych objawów choroby. Nawet w nieuleczalnej chorobie |placebo może skutecznie łagodzić ból. Wiara może nawet odwrócić zwykłe działanie środka farmakologicznego. Ludzie, którzy reagują łatwo na placebo, różnią się pewnymi cechami osobowości od osób nie reagujących na nie.
Poczucia przewidywalności i kontroli są silniejsze wtedy, gdy spostrzega się |spójność danej sytuacji; dla uzyskania takiego spostrzeżenia możemy narzucić tę spójność za pomocą |kontroli |poznawczej, wywołując zmiany w naszych własnych motywach, uczuciach, postawach i nawet stanach biologicznych, takich jak głód. U ludzi starszych, którzy mają poczucie, że utracili kontrolę nad swym życiem i nie pozostawiono im żadnego wyboru, nawet śmierć może być ostatnim aktem kontroli poznawczej - ostatnim wyborem.




Z Frontu Badań.
Eliminowanie depresji
i wyuczonej bezradności




|Martin |E. |P. |Seligman „University of Pennsylvania


Bezradność, którą wywołano u ludzi w warunkach laboratoryjnych, dając im nierozwiązywalne zadania lub stosując niemożliwy do uciszenia hałas, prowadzi do powstawania objawów, z których wiele jest takich samych, jak w przypadku „naturalnej” depresji. Stwierdziliśmy, że zarówno studenci cierpiący na depresję, jak i osoby badane, u których wytworzono stan bezradności, biernie poddają się hałasowi, nie próbując przed nim uciec, nie rozwiązują anagramów, mają trudności w spostrzeganiu figur przy próbach rozwiązywania zadań, oceniają zbyt nisko własną efektywność przy rozwiązywaniu zadań wymagających określonych umiejętności oraz przemawiają „minorowy” nastrój. Jestem przekonany, że możemy wykorzystać te uderzające analogie, aby ustalić za pomocą badań laboratoryjnych, jakie rodzaje terapii skutecznie przyczyniają się do wyeliminowania depresji w warunkach naturalnych. Zanim przytoczę swą argumentację, chciałbym najpierw dokonać przeglądu kilku rodzajów terapii, które mogą być pomocne w przypadkach depresji, i które wynikają z koncepcji depresji opartej na pojęciu wyuczonej bezradności.
Nie ma uniwersalnego lekarstwa na depresję: jeśli pozostawi się ją bez interwencji, to często ustępuje ona sama w ciągu paru tygodni lub miesięcy.  Istnieją jednak różne rodzaje terapii, o których sądzi się, że łagodzą depresję, i które są zgodne z teorią wyuczonej bezradności. Zgodnie z tą teorią, głównym celem skutecznej terapii powinno być doprowadzenie pacjenta do tego, by uwierzył, że jego działania przynoszą pożądane rezultaty, że jest on, krótko mówiąc, człowiekiem funkcjonującym efektywnie.
Terapia może skutecznie łagodzić depresję, jeżeli zapewnia pacjentowi uzyskanie kontroli nad ważnymi dla niego następstwami. W ramach terapii realizowanej pod nazwą Tuscaloosa Plan w szpitalu Veterans Administration w Alabamie wysyła się pacjentów z poważną depresją do „sali antydepresyjnej”.  W sali tej pacjentów poddaje się reżimowi „łagodnego przymusu”: poleca się im polerować kawałek drzewa, a następnie gani się ich za polerowanie „pod włókno”. Polerują oni wówczas „z włóknem”, a wtedy mówi się im, że znowu źle robią. Następnie poleca się im przystąpić do liczenia około miliona małych muszelek rozrzuconych po sali. To systematyczne nękanie trwa tak długo, dopóki dana osoba nie powie w końcu asystentowi:”Dajcie mi spokój!” lub coś w tym rodzaju: „Dość już tego liczenia muszelek!”. Pacjent zostaje wówczas natychmiast wypuszczony z sali i przeproszony. W ten sposób zmusza się pacjentów do przejawienia jednej z najskuteczniejszych reakcji, jakimi dysponują ludzie dla uzyskania wpływu na innych, a mianowicie |gniewu; kiedy zaś ta reakcja zostaje wydobyta z ich zubożałego repertuaru, wówczas otrzymują oni silne wzmocnienie. Taktyka ta może przełamać depresję - w sposób trwały.
W terapii określanej jako „trening stanowczości”, pacjent aktywnie ćwiczy wykonywanie reakcji społecznych nacechowanych stanowczością, podczas gdy terapeuta odgrywa rolę dominującego szefa lub męża, któremu mówi się prawdę w oczy, lub też żony trzymającej męża pod pantoflem, która żałuje swego sposobu postępowania i prosi o przebaczenie. I tu także pacjent wykonuje reakcje, które przynoszą wspaniałe efekty. Ludziom z lekką depresją wychodzi prawdopodobnie na dobre, jeśli zwrócą w sklepie nabyty „bubel” lub odniosą sukces przy ladzie sklepu mięsnego, otrzymując dokładnie taki kawałek mięsa, jakiego sobie życzą.
Stopniowe stawianie pacjenta w sytuacjach, w których po działaniu następuje wzmocnienie, wzmaga jego tendencję do aktywnego reagowania i może skutecznie eliminować depresję. Podczas leczenia depresji, polegającego na stopniowaniu zadań, Elaine Burgess najpierw nakłaniała pacjentów do wykonania jakiegoś błahego zachowania, takiego jak przeprowadzenie rozmowy telefonicznej (podkreśla ona z naciskiem, że decydujące jest, aby pacjent odniósł sukces, zamiast jedynie zaczynać i reagować z działania), a następnie dawała pacjentom zadania stawiając przed nimi większe trudności - pacjent otrzymywał wzmocnienie za ich pokonanie w postaci uwagi lub zainteresowania ze strony terapeuty. Nawiasem mówiąc, Burgess i jej współpracownicy wskazują na rolę „wtórnych korzyści” w depresji: twierdzi się często, że osoby cierpiące na depresję „wykorzystują” swe objawy w sposób instrumentalny, aby uzyskać współczucie, uczucie i uwagę. Leżąc przez cały dzień w łóżku i płacząc, zamiast iść do pracy, mężczyzna cierpiący na depresję może spowodować, że jego flirtująca żona zwróci na niego większą uwagę, a może nawet uda mu się ją odzyskać. Wtórne korzyści przeszkadzają w leczeniu i w czasie terapii istnieje pokusa, aby spróbować usunąć nagrody, które podtrzymują depresję. Niezbędna jest tu także ostrożność: wtórne korzyści mogą wyjaśniać trwałość lub utrzymywanie się niektórych zachowań depresyjnych, nie wyjaśniają jednak, w jaki sposób one |powstają. Teoria bezradności sugeruje, że powstrzymywanie się od aktywnego reagowania ma swe źródła w spostrzeżeniu pacjenta, że nie ma on możności wpływania na uzyskiwane przez siebie rezultaty. Bierność pacjenta z depresją może mieć zatem dwa źródła: 1) pacjenci mogą być bierni z przyczyn instrumentalnych, ponieważ pozostawianie w stanie depresji zapewnia im współczucie, miłość i uwagę ze strony otoczenia oraz 2) pacjenci mogą być bierni, ponieważ są przekonani, że żadna reakcja, jaką mogą wykonać, nie doprowadzi do uzyskania kontroli nad otoczeniem.  Porównując pierwszą i drugą przyczynę, można by dojść do wniosku, iż wtórne korzyści, chociaż stanowią praktyczną przeszkodę w terapii, są w depresji dobrą oznaką: sygnalizują one, iż pacjent wierzy, że istnieje jakaś reakcja (aczkolwiek bierna), którą może on wykonywać z pewnym skutkiem. Steven Maier stwierdził, że psy, których bierność była wzmacniana zakończeniem wstrząsu elektrycznego, nie były nawet w przybliżeniu tak bezradne, jak te psy, których żadna z form reagowania nie miała wpływu na zakończenie wstrząsu. Podobnie w przypadku pacjentów, którzy posługują się swą depresją jako sposobem uzyskania kontroli nad innymi, rokowanie może być lepsze niż w przypadku tych, którzy skapitulowali.
Wraz z mymi współpracownikami poddaliśmy 24 hospitalizowanych pacjentów terapii podobnej do zastosowanej przez Burgess (w formie stopniowania zadań). Pacjentom tym w ciągu jednogodzinnego posiedzenia dawaliśmy zadania werbalne o stopniowo rosnącej trudności i chwaliliśmy ich za udane wykonanie każdego z zadań. Najpierw prosiliśmy ich o przeczytanie fragmentu tekstu. Następnie prosiliśmy ich o przeczytanie nowego fragmentu głośno i z ekspresją. Potem prosiliśmy ich o przeczytanie jeszcze innego fragmentu z ekspresją i wyjaśnienie go swymi własnymi słowami; następnie o przeczytanie głośno, z ekspresją, plus objaśnienie i podanie argumentów przemawiających za stanowiskiem autora. Na samym szczycie tej hierarchii było zadanie, w którym pacjentów proszono o wybranie jednego z trzech tematów i wygłoszenie improwizowanej mowy. Wszyscy pacjenci wygłosili tę mowę (każdy, kto pracował z hospitalizowanymi pacjentami cierpiącymi na depresję wie, iż zwykle nie wygłaszają oni improwizowanych przemówień). Nastrój dziewiętnastu z pośród dwudziestu czterech pacjentów poprawił się natychmiast w istotny sposób - mierzono to za pomocą skali opartej na własnych ocenach osoby badanej. Aczkolwiek nie obserwowaliśmy, jak długo trwała ta poprawa, to jednak uwaga wygłoszona przez pewnego uśmiechniętego pacjenta jest pouczająca: „Wiecie, w szkole średniej zawsze lubiłem dyskutować i zapomniałem, jak dobry byłem w tej dziedzinie”.
Trening w podejmowaniu decyzji może odgrywać ważną rolę w leczeniu depresji. Pacjenci cierpiący na depresję często mają trudności w podejmowaniu decyzji, nawet błahych - na przykład, jakie ubranie włożyć.  Pacjent może nauczyć się podejmowania decyzji dzięki zastosowaniu sposobu podobnego do sposobu stosowanego w terapii stopniowanych zadań. Pierwszym zadaniem pacjenta byłoby tu podjęcie jakiejś błahej decyzji - na przykład jaki program telewizyjny obejrzeć. Gdy pacjent bez trudu podejmuje decyzję na tym poziomie, wówczas wymaga się od niego coraz poważniejszych decyzji, aż wreszcie nauczy się z większą łatwością podejmować ważne decyzje.
Łatwo jest przeoczyć fakt, że ludzie cierpiący na depresję często wykazują pewne braki w sferze umiejętności społecznych: nie potrafią oni opowiadać dowcipów, umówić się na randkę, „postawić się”, gdy ktoś ich wykorzystuje. Umiejętności społecznych można nauczyć. Trening „efektywności osobistej” pomaga prawdopodobnie w przypadkach depresji dlatego, że wyposaża pacjenta w nowe reakcje, które umożliwiają mu uzyskanie kontroli nad ważnymi źródłami gratyfikacji społecznej.
Terapie „zorientowane na wgląd”, takie jak psychoanaliza, mogą być skuteczne dzięki temu, że pomagają pacjentowi uświadomić sobie czynniki, które powodują jego bezradność i w ten sposób pomagają mu uwolnić się od nich. Depresja znika, gdy cele, które z jakiejś przyczyny wydawały się nie do urzeczywistnienia, zdają się wchodzić w zasięg jego możliwości lub zostają w istotny sposób zmodyfikowane, albo też zastąpione przez takie cele, które można osiągnąć. Skuteczna terapia oparta na wglądzie („insight therapy”) wiąże się zatem ze spowodowaniem zasadniczej zmiany w postawach wobec przyszłości, z zapewnieniem danej jednostce możliwość ustanawiania sobie możliwych do zrealizowania celów oraz planowania efektywnych strategii osiągania tych celów.
Trzeba jednak podać pewne zastrzeżenia dotyczące wszelkich psychologicznych form leczenia depresji. W przypadkach poważnych depresji pacjent często jest tak zamknięty w sobie, że trening umiejętności społecznych, terapia poznawcza, „terapia stopniowanych zadań” i inne skutki tego rodzaju nie przyniosą w ogóle żadnego skutku. Pacjent po prostu nie interesuje się tymi celami. W przypadku tak poważnej depresji (która przeważnie będzie mieć podłoże raczej fizjologiczne niż psychologiczne) należy zastosować leczenie za pomocą antydepresyjnych środków farmakologicznych, lub wstrząsów elektrycznych. Fizykalne terapie tego rodzaju złagodzą prawdopodobnie poważne objawy depresji. Gdy objawy takie zostaną zredukowane i z pacjentem można już nawiązać kontakt, wówczas celowe jest stosowanie terapii psychologicznej.
Utrzymuje się, że wiele różnych innych form terapii, od psychoanalizy do grup T, pozwala wyleczyć depresję. Nie mamy jednak dotychczas wystarczającego materiału dowodowego, pochodzącego z dobrze kontrolowanych badań, aby móc ocenić efektywność jakiejkolwiek formy psychoterapii w leczeniu depresji. Materiał dowodowy, jaki przedstawiłem, ma charakter wybiórczy: omówiono tylko nieliczne rodzaje terapii, które wydają się zgodne z koncepcją bezradności. Jest możliwe, że kiedy inne terapie są skuteczne, to również dzieje się dlatego, że przywracają one pacjentowi poczucie skuteczności działania. Potrzebny jest nam eksperymentalny materiał dowodowy pozwalający wyodrębnić efektywną zmienną, występującą w psychologicznym leczeniu depresji - obecnie jesteśmy w stanie już tego dokonać.
Napotykamy dwie trudności, które trzeba przezwyciężyć, aby przeprowadzić zadawalające badania nad tym, jakie rodzaje terapii są skuteczne w przypadkach depresji; trudności te to samorzutne przemijanie oraz „ukryte wymagania badanej sytuacji”.
Depresja jest, na szczęście, zwykle stanem, który sam przechodzi z czasem. Większość depresji pochodzenia psychologicznego słabnie coraz bardziej, w miarę jak wydarzenia, które je spowodowały, stają się coraz bardziej odległe w czasie. To, co babcia mówiła ci o „czasie, który leczy wszystkie rany”, jest w dużej mierze prawdziwe. Weźmy jako przykład ludzi, którzy stracili pracę; niektórzy z nich cieszą się z tego (ci się nie liczą), inni martwią się tym przez parę dni, inni - parę tygodni, a niektórzy - parę miesięcy. Jest to ważna rzecz, o której powinien wiedzieć pacjent cierpiący na depresję, ponieważ w takim stanie często wydaje mu się, że nastrój ten będzie trwał wiecznie. Jest to jednak fakt niewygodny dla badacza starającego się określić skuteczność terapii. Aby móc sprawdzić skuteczność terapii X, potrzebna jest grupa kontrolna - nie poddaje się jej terapii, lecz bada się ją dwukrotnie: przed rozpoczęciem terapii X w grupie eksperymentalnej i po jej zakończeniu. W tym czasie u wielu nieleczonych osób depresja ustępuje i często nie stwierdza sie żadnych istotnych różnic między grupą poddaną terapii X a nie leczoną grupą kontrolną.
Druga trudność, jaka występuje przy ustalaniu rzeczywistej efektywności terapii w przypadkach depresji, wiąże się z tym, co określa ją jako „ukryte wymagania” („demand characteristics”) badań empirycznych. Badani (lub pacjent), których ktoś posiadający autorytet prosi o wzięcie udziału w badaniach, chcą być „dobrymi” badanymi. Ci, którzy domyślają się jaka jest hipoteza eksperymentatora (i którym się on podoba), mogą starać się, aby została ona potwierdzona. W badaniach nad skutecznością terapii miary stosowane do oceny depresji są zwykle bardzo oczywiste i łatwo pozwalają określić takie „ukryte wymagania” (np. „Czy czujesz się smutny?”). Badany, który lubi terapeutę, może powstrzymać się od odpowiedzi „tak” i w ten sposób zniekształca rzeczywiste wyniki leczenia.
David Klein przeprowadził pierwsze z serii badań, w których obie te trudności zostały przezwyciężone; z tych eksperymentów laboratoryjnych możemy dowiedzieć się, jakie rodzaje terapii eliminują depresję.  Przypomnijmy sobie, że u osób nie cierpiących na depresję, u których w laboratorium wytworzono poczucie bezradności, występuje ten sam zespół objawów, co u osób z depresją, które przychodzą do laboratorium i nie są tam poddawane żadnemu postępowaniu wstępnemu, a mianowicie: nieuciekanie przed hałasem, zniekształcone oczekiwania co do osiągnięć w testach umiejętności, niepowodzenia w rozwiązywaniu anagramów i spostrzeganiu figur oraz obniżony nastrój. Objawy te, z wyjątkiem ostatniego, nie są zbyt podatne na wpływ „ukrytych wymagań”. Badanym niełatwo domyślić się, że eksperymentator oczekuje od nich, aby siedzieli trzymając rękę w aparacie zwanym „skrzynką wahadłową” („shuttlebox”) i nie uciekali przed hałasem (tzn. nie czynili ręką ruchu powodującego wyłączenie hałasu - przyp.  tłum.). Ponadto osoby cierpiące na deresję, jak i osoby, u których wywołano poczucie bezradności, można badać natychmiast, zanim objawy zdążą ustąpić.  Każdą terapię, którą można „zminiaturyzować” i zaadaptować do warunków laboratoryjnych, można prowadzić z tymi osobami przez okres na przykład godziny, a następnie możemy sprawdzić, czy wspominanych wyżej pięć objawów zostało wyeliminowanych pod wpływem tej terapii.
Klein przeprowadził pionierskie badania nad eliminowaniem poczucia bezradności i depresji. Grupy osób nie cierpiących na depresję, u których poprzednio wywołano poczucie bezradności przy zastosowaniu nie dającego się wyłączyć hałasu, oraz grupy osób z depresją nie uciekały przed hałasem; występowały u nich również zniekształcone oczekiwania co do wyników, które osiągną w testach umiejętności. Inne grupy osób „bezradnych” oraz cierpiących na depresję poddano terapii polegającej na doświadczeniu sukcesu. Osobom tym dano zadania o charakterze poznawczym, które potrafiły z powodzeniem rozwiązać. Zgodnie z tym, czego należało oczekiwać na podstawie koncepcji wyjaśniającej depresję w kategoriach poczucia bezradności, uporanie się z problemami poznawczymi spowodowało ustąpienie objawów polegających na nieuciekaniu przed hałasem oraz na zniekształcaniu oczekiwań.
Zastosowanie w rzeczywistej psychoterapii osób dotkniętych depresją procedur terapeutycznych skutecznych w laboratorium nie wymaga dużych modyfikacji. W eksperymentach Kleina możliwe do rozwiązania zadania stanowiły skuteczną terapię poczucia bezradności. Nie proponujemy, aby terapeuta dawał do rozwiązania pacjentom cierpiącym na depresje zadania polegające na różnicowaniu. Sugerujemy natomiast, aby dawał on pacjentowi możliwe do rozwiązania zadania, które pacjent ten uznaje za ważne. Na przykład, zwolnionemu z pracy księgowemu możemy dawać takie zadania z podręcznika księgowości, z którymi potrafi on sobie poradzić (jeśli jednak pacjent cierpi na depresję właśnie dlatego, że |jest księgowym a nie aktorem, to zadania takie byłyby oczywiście niestosowne). Ustalenie, które zadania są ważne dla pacjenta, nie tylko sprawi, że sukces da mu więcej zadowolenia, lecz także pomoże nakłonić pacjenta do podjęcia wysiłku, aby zrobić cokolwiek - co w wielu przypadkach jest sprawą bardzo trudną.  Zadania najlepiej jest dawać pacjentowi po jednym, w kolejności od najłatwiejszego do najtrudniejszego, tak aby sukces na każdym etapie był bardziej prawdopodobny.
Jestem przekonany, że schemat badawczy zastosowany przez Kleina pozwoli nam ustalić, jakie rodzaje terapii będą w rzeczywistości skuteczne w odniesieniu do pacjentów cierpiących na depresję. Każdą potencjalną terapię, która daje się zminiaturyzować, można zastosować wobec naszych badanych: trening stanowczości, uczenie się przejawiania gniewu, trening relaksacyjny, farmakoterapię. Te rodzaje terapii, które usuwają zaburzenia występujące podczas wykonywania zadań w laboratorium, będą prawdopodobnie funkcjonować także w klinice; te, które nie eliminują tych zaburzeń, będą prawdopodobnie nieskuteczne.
Końcowe uwagi dotyczą następującego zagadnienia: do jakich typów depresji model bezradności i nasze badania nad terapią mają największe zastosowanie?  Klasyfikacja depresji jest nieuporządkowana i kontrowersyjna: wyróżnia się na przykład depresje proceduralne i reaktywne, neurotyczne i psychotyczne, jednobiegunowe i dwubiegunowe („unipolar8bipolar”) - oto tylko parę z proponowanych podziałów. To trudne zagadnienie wymaga badań empirycznych. W naszych badaniach dzieliliśmy studentów college’u na grupę wykazującą depresję i nie wykazującą depresji za pomocą „Beck Depression Inventory” (Inwentarza Depresji Becka). W tej technice pomiarowej objawy afektywne, behawioralne, poznawcze i somatyczne łączą się razem, uzyskując pojedynczy wskaźnik nasilenia depresji. Skala tego rodzaju nie pozwala dokonywać rozróżnień zgodnych z zaproponowanymi podziałami depresji. Dalsze badania tego typu, jak opisany powyżej, mogą wykazać, które osoby - czy te przejawiające główne objawy afektywne, behawioralne, poznawcze czy też somatyczne - najwłaściwej będzie uważać za przypadki „depresji bezradności” i które z nich reagują na poszczególne rodzaje terapii. Jestem przekonany, że „depresja bezradności” nie będzie dokładnie odpowiadać żadnej zaproponowanej dotychczas podkategorii depresji. Jeśli przedstawiony tu model jest trafny, to mogłoby być wskazane dokonanie zmian w stosownych określeniach diagnostycznych. Niektóre osoby cierpiące na depresję, które wykazują bierność, negatywne nastawienie poznawcze oraz inne objawy wyuczonej bezradności, u których zaburzenia pojawiły się po utracie kontroli nad ważnymi dla nich sprawami, można by z powodzeniem sklasyfikować jako przypadki „depresji bezradności”. Osoby zaliczone do tej kategorii mogłyby szczególnie dobrze reagować na terapie sprawdzone w badaniach tego rodzaju, jakie przeprowadzamy. Inne osoby cierpiące na depresję, które nie wykazują takich objawów, a historia ich choroby miała inny przebieg, mogłyby być szczególnie wrażliwe na inne rodzaje terapii.
W każdym razie wydaje się możliwe, że w następnym dziesięcioleciu dowiemy się, jakie rodzaje terapii eliminują depresję spowodowaną przez poczucie bezradności i dzięki temu będziemy potrafili łagodzić nieznośne cierpienia, które doprowadzają wiele osób cierpiących na depresję do postępowania szkodliwego dla nich samych, a niektóre z nich - nawet do samobójstwa.




V. Osobowość, patologia

i terapia




10. Teoria i pomiar osobowości
11. Dewiacja, patologia i szaleństwo
12. Terapia jako sposób modyfikacji zachowania





Rozdział 10.
Teoria i pomiar
osobowości




„Byłem zaskoczony, kiedy moi koledzy ze szkoły średniej imienia Jamesa Monroe przyznali mi w głosowaniu tytuł „Jimmie Monroe”! To znaczyło, że mam „najlepszą” osobowość w szkole (...). No cóż, to jest najlepszą wśród starszych chłopców („Janie Monroe” - to był analogiczny tytuł dla dziewcząt).
Był to pierwszy konkurs, w jakim kiedykolwiek zwyciężyłem, i nic nie musiałem zrobić w tym celu - żadnych rozgrywek, żadnych testów - po prostu musiałem tylko być sobą. To było dość łatwe, ponieważ w tych wypadkach, gdy próbowałem być kimś innym, zawsze okazywałem się sobą.
Było oczywiście przyjemnie mieć najlepszą osobowość, lecz chętnie oddałbym ją za wymarzoną przeze mnie zdolność zmiany osobowości za każdym razem, gdybym tego zapragnął - raz w maminsynka, raz w supermena. A przeskoki między Dr. Jekyllem a Mr. Hyde’em?. A co z „trzema twarzami Ewy”?  Czy trzy całkowicie różne osobowości nie byłyby lepsze niż jedna zawsze ta sama osobowość?
Ludzie mogli mnie zbyt łatwo rozszyfrować, wiedzieli „skąd przyszedłem”.  Ludzie lubili mnie, ponieważ byłem „cały na wierzchu”. Czuli się przy mnie swobodni, jak w starych pantoflach lub jak przy słuchaniu „starego, dobrego jazzu”. Mogli na mnie liczyć. Byłem niezawodny. Można mnie było „wziąć za słowo”. „Jesteś słownym chłopakiem” mówił posterunkowy spotykając mnie w czasie obchodu. Nawet moja dziewczyna napisała mi w moim pamiętniku: „Nie umiem liczyć po łacinie - nie umiem liczyć po grecku - nie umiem liczyć po zalusku - lecz mogę liczyć na ciebie”. Byłem po prostu zbyt stały - to co zrobię, można było przewidzieć tak łatwo, jak to, że słońce wzejdzie na wschodzie.
Mieć osobowość numer jeden było rzeczą najwspanialszą dlatego, że - ciekawa rzecz - zaledwie rok wcześniej, gdy byłem uczniem w North Hollywood High School, nie miałem właściwie żadnych przyjaciół, żadnych randek i - jak przypuszczałem - w ogóle żadnej osobowości. Te dzieciaki uważały mnie za mądralę z Nowego Jorku, o zabawnym nazwisku, a co gorsza, nie należałem do żadnych „kółek”. Czułem się odrzucony, stałem się nieśmiały po raz pierwszy w życiu i wolałem czytanie od marnowania czasu na rozmowę z ludźmi. „Osobowość” to bzdura” - było to wówczas moje ulubione powiedzenie.
Lecz, jak mówi moja siostra, „nie można stłumić dobrej osobowości”, i moja „najlepsza osobowość” nie mogła oczywiście zostać stłumiona.  Przypuszczam, że po prostu trzymałem ją w ukryciu, dopóki nie wróciłem do Nowego Jorku, gdzie mogła być lepiej oceniona. Przez te lata fakt, że byłem Jimmie Monroe, był dla mnie źródłem stałego zadowolenia, ponieważ wiedziałem, że nawet gdybym został całkowicie zdeformowany w strasznym wypadku motocyklowym, to ludzie zawsze mogliby powiedzieć: „On może nie jest przystojny, lecz ma naprawdę miły charakter”.
W języku potocznym, tak jak i w powyższym opisie, „osobowość” jest czymś zbliżonym do „atrakcyjności”, „czaru osobistego”, „siły charakteru” czy „charyzmatu”.
Jest to cecha silnie zaznaczona u gwiazd filmowych i tych polityków, którzy nam się podobają, podczas gdy reszta spośród nas musi zadowolić się posiadaniem jej w mniejszym stopniu. Gdy jednak psychologowie posługują się słowem |osobowość, to ma ono bardziej neutralne i bardziej uniwersalne znaczenie, oznacza mianowicie „to, co charakteryzuje daną jednostkę”. Lub też, w bardziej formalnym ujęciu, osobowość jest „ogólną sumą tych sposobów reagowania na ludzi (i obiekty) oraz sposobów wchodzenia z nimi w interakcje, które są charakterystyczne dla danej jednostki” (Ferguson, 1960, s. 2).
Prawdopodobnie już jako dziecko stworzyłeś i stosowałeś swój własny system oceniania swojej osobowości i osobowości innych. Było to dla ciebie bardzo ważne, abyś potrafił odróżnić przyjaciół od wrogów, ocenić nastrój i humor rodzeństwa oraz rodziców, ocenić i „rozszyfrować” rywali oraz poznać własne mocne i słabe strony. Twoje oszacowania były w istocie prymitywnymi ocenami osobowości. Każdy z nas, dzień w dzień, działa opierając się na czymś, co moglibyśmy nazwać |naiwnymi |ukrytymi |teoriami |osobowości.  Konstruując tę teorię wykorzystujemy niemal te same źródła informacji, z których korzystają psychologowie konstruujący wyrafinowane teorie osobowości.


Źródła te obejmują informacje dotyczące historii życia danej osoby, jej obecnych sposobów zachowania, jej nawyków, zainteresowań, postaw oraz przyszłych celów czy aspiracji. Główna różnica polega na tym, że nasze naiwne, nieformalne teorie opierają się głównie na intuicji i przypuszczeniach, podczas gdy teoretycy osobowości opracowali obiektywne procedury i narzędzia pomiarowe, na których opierają swe oceny osobowości.  Wielu różnych osobników, takich jak chiromaci, jasnowidze i wróżbici, zarabia na utrzymanie dzięki wykorzystaniu naiwnych teorii osobowości.
Taki osobnik jest wykwalifikowanym pseudouczonym, który w swej działalności opiera się na naiwnej teorii osobowości zbudowanej dzięki wnikliwym obserwacjom, znajomość natury ludzkiej oraz dużej dozie |tupetu.  Podstawowe narzędzia tego fachu, to umiejętność szybkiego klasyfikowania ludzi na podstawie wieku, wyglądu, stanu cywilnego itd., oraz dobra orientacja, jakiego rodzaju problemy najczęściej mają ludzie, należący do danej kategorii.




Specyficzność i stałość:
kluczowe problemy
teorii osobowości




We wszelkich rozważaniach nad osobowością istotne znaczenie mają dwa związane ze sobą zagadnienia:
1. Co sprawia, że ludzie zachowują się podobnie?
2. Co sprawia, że ludzie zachowują się różnie?

Pierwsze pytanie ma doprowadzić do ustalenia minimalnej liczby warunków, czynników i zmiennych, które mogą wyjaśnić występowanie tych samych reakcji u wszystkich istot należących do gatunku ludzkiego, drugie pytanie - do wyjaśnienia przyczyn różnic występujących w zachowaniu poszczególnych osób w reakcji na pozornie tę samą sytuację. Tutaj problem polega na wyjaśnieniu indywidualnej specyficzności, tej zmienności reakcji, której nie można przypisać sytuacji bodźcowej.
Z jednej strony badania nad osobowością nie różnią się zatem od ogółu badań psychologicznych, w których dąży się do zrozumienia |całości zachowania człowieka, prócz tego jednak teoretyk osobowości szczególnie interesuje się zagadnieniem, dlaczego zachowanie ludzi różni się nawet wtedy, gdy już ustali się wszystkie znane czynniki środowiskowe.




Jak różne jest to,
co normalne?




Rozpowszechniony jest pogląd, który podtrzymują autorzy kącików porad w czasopismach, zgodnie z którym ludzie normalni funkcjonują bardzo podobnie.  Co więcej, aby być „normalnym” człowiek |powinien rzekomo funkcjonować tak samo jak ci, którzy są do niego w pewien sposób podobni (na przykład pod względem wieku, płci czy wykształcenia). Rodzicom zmartwionym tym, że ich dziecko nie zaczęło jeszcze chodzić, podaje się wiek, w którym „normalne” dziecko stawia pierwsze kroki; dorastającej młodzieży mówi się, kiedy według wyników badań „normalne” jest rozpoczęcie chodzenia na randki - to znaczy, kiedy zaczyna na nie chodzić przeciętny nastolatek.
Mit o „normalnych”, przeciętnych funkcjach człowieka został obalony w wyniku dokładnej analizy przeprowadzonej przez Williamsa (1956), która wykazała ogromny zakres zmienności położenia, wielkości i działania wewnętrznych narządów człowieka. Prawie każdy narząd może być u niektórych normalnych osób kilka razy większy niż u innych osób - równie normalnych.  Na przykład niektóre żołądki mają pojemność sześć do ośmiu razy większą niż inne. Podobnie badanie 182 normalnych, młodych mężczyzn wykazało, że tempo pracy serca wynosiło u nich od 45 do 105 uderzeń na minutę. Normalna zdolność przepompowywania krwi przez serce waha się od 3 do 11,2 litra na minutę. Podobne różnice stwierdzono pod względem struktury nerwowej, składu chemicznego i aktywności organizmu oraz reakcji na środki farmakologiczne i różne bodźce.
Gdy do tak dużego zakresu różnic fizjologicznych doda się nieskończoną różnorodność doświadczeń życiowych jednostek, to trudno się dziwić, że występuje taka duża różnorodność zachowań ludzkich, a nawet u ludzi znajdujących się w tej samej sytuacji. Te różnice międzyjednostkowe są przeszkodą dla-badaczy szukających praw ogólnych i zwykle albo przezwycięża się je badając silne bodźce w prostych sytuacjach lub też eliminuje się je przez „uśrednianie” zróżnicowanych reakcji dużej liczby osób badanych.
Jednakże większość teoretyków osobowości ujmuje ten „problem” zupełnie inaczej. Ponadto zróżnicowanego zachowania ludzi nie uważają oni za problem, który należy przezwyciężyć, lecz za problem, |który właśnie należy |badać.
Nie oznacza to, że psychologowie zajmujący się osobowością nie są zainteresowani wykrywaniem ogólnych praw. Podobnie jak w innych dziedzinach psychologii, wielu teoretyków osobowości jest przekonanych, że w końcu psychologowie wykryją reguły, które można będzie stosować do wszystkich istot ludzkich. Lecz w teorii osobowości reguły te muszą także móc wyjaśnić różnice między ludźmi. Nie wszystkie teorie osobowości kładą nacisk na różnice indywidualne, lecz wszystkie muszą móc je wyjaśnić. Muszą one wyjaśnić, co czyni jedną osobę różną od innej, co sprawia, że dany człowiek zachowuje się konsekwentnie w różnych sytuacjach, co sprawia, że ludzie po upływie pewnego czasu albo pozostają tacy sami, albo zmieniają się.




Osobowość jako
coś stałego




Co właściwie |charakteryzuje jednostkę? Nie myśląc właściwie o tym, potrafimy rozpoznawać naszych przyjaciół, nawet jeśli nie widzieliśmy ich od pewnego czasu. Jeśli znamy kogoś dostatecznie dobrze, to potrafimy go rozpoznać nawet gdy ktoś inny opisuje jego zachowanie. („Ach, to musiał być Jim. On zawsze tak postępuje”). W jaki sposób potrafimy tego dokonać?  Kluczem zdaje się tu być |stałość. Potrafimy rozpoznawać poszczególnych ludzi i opisywać ich innym za pomocą stałych charakterystycznych dla nich cech. Nawet jeśli czyjeś zachowanie jest zawsze nieprzewidywalne, to jest to coś, co możemy o nim powiedzieć, co odróżnia go od ludzi mniej zmiennych.
Lecz sprawa ta jest bardziej złożona. Spróbuj wykonać następujący test.  Pomyśl o dwóch osobach, które mają ważne znaczenie w twoim życiu - jednej, którą lubisz, i jednej, której nie lubisz. Czy któraś z nich jest przede wszystkim „dobra” (silna, łagodna, rozumiejąca) lub przede wszystkim „zła” (słaba, okrutna, nietaktowna)? Czy też zależy to od okoliczności? Teraz pomyśl o sobie samym i odpowiedz na oba te pytania.
Najczęściej rezultaty tego prostego eksperymentu ujawniają nam, że uważamy innych dobrze nam znanych ludzi za zawsze dobrych bądź zawsze złych, niezależnie od sytuacji, podczas gdy siebie samych uważamy za bardziej zmiennych. Ten paradoks uwypukla naszą potrzebę przypisywania stałości zachowaniu ludzi i formułowaniu stałych wzorców reakcji i cech, gdy charakteryzujemy inne osoby.
Ta skłonność do przypisywania stałości innym ludziom jest szczególnym przypadkiem bardziej ogólnej tendencji do spostrzegania stałości we wszystkich zdarzeniach; jest częścią ogólnego procesu organizowania naszego świata w taki sposób, aby uczynić go spójnym, uporządkowanym i łatwiej przewidywalnym. Musimy więc postawić pytanie, czy ta stałość, którą spostrzegamy u ludzi, która stanowi podstawę teorii cech osobowości, rzeczywiście istnieje u obserwowanych ludzi, czy tylko w umysłach naiwnych obserwatorów i wyrafinowanych teoretyków osobowości.




Zbliżenie


„Wydaje mi się, że ludzie są na ogół dość stali”


„Pogląd, zgodnie z którym ludzi można charakteryzować za pomocą pewnych dominujących cech, które przejawiają w różnych sytuacjach, wydaje nam się zapewne bardziej uzasadniony, niż wiele innych przekonań zgodnych z tak zwanym zdrowym rozsądkiem. Wszyscy znamy ludzi „towarzyskich”, „nieśmiałych”, „uczciwych”, znamy „impulsywnych mężczyzn” i „niesamodzielne kobiety”. Wbrew naszemu przeświadczeniu o trafności takich intuicji, badania przyniosły wiele materiału dowodowego, który sugeruje, że nasze intuicje są po prostu fałszywe.
Mamy tu do czynienie z interesującym paradoksem: z jednej strony nasz naiwny pogląd jest zgodny z podstawowym założeniem większości teorii osobowości - mianowicie, że |istnieje stałość osobowości, przejawiająca się w różnych sytuacjach. Wszystkie teorie osobowości starają się wyjaśnić, dlaczego istnieje ta indywidualna stałość i w jaki sposób się ona przejawia. Z drugiej strony, systematyczne badania, w których próbuje się przewidywać zachowanie danej osoby w określonej sytuacji na podstawie wskaźników cech osobowości lub jej zachowania w odmiennych sytuacjach, wykazują, iż przewidywalność taka jest dość ograniczona. Rozwiązania tej sprzeczności dostarczy być może przeanalizowanie powodów, dla których, zarówno nam, jak i teoretykom osobowości, może się wydawać, iż stałość |charakteryzuje jednostki w większym stopniu, niż to jest w rzeczywistości.
Istnieje przynajmniej 10 powodów, dla których nasza intuicja mówi nam, że to, co naszym zdaniem charakteryzuje daną osobę w jednej sytuacji, cechuje ją też we wszystkich lub w większości sytuacji (zaadaptowane według pracy Bema i Allena, 1974).
1. Każdy z nas posługuje się „ukrytą teorią osobowości” („implicit personality theory”), za pomocą której wiąże obserwowane zachowanie z cechami, o których istnieniu wnioskuje, a następnie przewiduje inne, nie obserwowane zachowania. Teorie takie skłaniają nas, aby na miejsce brakujących obserwacji tego, co jest, wstawiać to, co |powinno |być - zgodnie z naszą teorią osobowości. Dokonujemy ponadto nadmiernych uogólnień dostępnego materiału dowodowego, dotyczącego tych obszarów psychiki, w których istnieje pewna stałość (takich, jak zdolności intelektualne czy styl poznawczy), na te obszary, gdzie w rzeczywistości stałość nie występuje.
2. Przy opisywaniu ludzkiego zachowania zbytnio polegamy na języku cech, mający w naszym słowniku ponad 18 000 nazw cech. Skłonni jesteśmy |myśleć w kategoriach tego języka, jaki mamy do naszej dyspozycji - raczej w kategoriach cech niż sytuacji.
3. Przyczyną takiego nadmiaru nazw cech indywidualnych jest zapewne nacisk, jaki, zarówno w psychologii jak i w naszym społeczeństwie, kładzie się na jednostkę. Skłonni jesteśmy umiejscawiać „problemy” raczej w ludziach niż w sytuacjach. Wynika stąd tendencja do przyczepiania ludziom etykietek - stosownie do ich „problemu”, a etykietki te często przywierają do nich na stałe.
4. Nie doceniamy subtelnych czynników sytuacyjnych, które mogą wywoływać różne reakcje u różnych ludzi. Ignorujemy zwłaszcza wpływ sytuacji, gdy oddziałuje ona na innych, a nie na nas.
5. Widzimy zwykle pewnych ludzi tylko w ograniczonej liczbie sytuacji (niekiedy tylko w jednej, jak w wypadku nauczycieli i uczniów w szkole) i uogólniamy nasze obserwacje na inne, nie obserwowane sytuacje.
6. Często inni będą zachowywać się w taki sposób, w jaki ich zdaniem chcielibyśmy, aby się zachowywali - wskutek tego skłonni jesteśmy wyolbrzymiać przypisywaną im stałość (lecz niekiedy zachowują się oni zupełnie inaczej wobec innego obserwatora).
7. Przeważnie mamy możność wyboru sytuacji, w jakiej chcemy się znaleźć i wybieramy te sytuacje, w których - jak przewidujemy - będziemy czuli się dobrze i z którymi potrafimy sobie poradzić. Sytuacje te są zwykle sytuacjami znanymi nam, w których możliwość zetknięcia się z nowymi bodźcami, konfliktem czy wyzwaniem są ograniczone. Nic więc dziwnego, że zachowujemy się w stały sposób w sytuacjach, które wybraliśmy ze względu na ich stałość.
8. Nasze oceny dotyczące innych ludzi często opierają się nie na naszych własnych obserwacjach ich zachowania, lecz na tym, co oni sami mówią nam o swym postępowaniu. Takie „sprawozdania o sobie” („self-reports”) często są stronnicze.
9. Nasze pierwsze wrażenia silnie nas ukierunkowują i późniejsze oceny reinterpretuje się tak, aby pasowały do pierwotnego, „prawdziwego” poglądu.  Gdy jakieś przekonanie raz się ukształtuje, to trzeba niewielu dowodów, aby je podtrzymać, lecz wielu, aby je obalić.
10. Skłonni jesteśmy widzieć stałość tam, gdzie jej nie ma, ponieważ przywykliśmy utożsamiać stałość z dobrocią, rzetelnością, solidnością itd.  Jak wyraził to Mark Twain: „Niektórzy twierdzą bałamutnie, że tkwienie w koleinach rutyny oznacza stałość - i cnotę, a wydostanie się z tych kolein jest niestałością - i grzechem” („Consistency”, 1923).



Teoretycy osobowości różnią się znacznie pod względem sposobu opisywania tej stałości oraz sposobu, w jaki próbują ją wyjaśnić. W niniejszym rozdziale omówimy najpierw szereg sposobów pojmowania osobowości. Następnie przejdziemy do rozpatrzenia skomplikowanego procesu pomiaru osobowości - opiszemy w jaki sposób stosuje się testy i inne narzędzia, usiłując zmierzyć i sprowadzić do liczb oraz kategorii to, co jest przedmiotem dociekań teoretyków.




Różne sposoby
myślenia o osobowości




Możemy przedstawić tu jedynie nieliczne z wielu usystematyzowanych teorii osobowości. Te teorie, które wybraliśmy, reprezentują cztery podstawowe sposoby ujmowania osobowości. Większość z nich implikuje lub wyraźnie formułuje konkretne wyjaśnienia przyczyn niepowodzeń i trudności z przystosowaniem; opracowano specyficzne metody terapii w powiązaniu z wieloma z tych teorii - omówimy je w Rozdziale 12.




Freud i jego następcy:
stałość jako wynik walki




Pod koniec XIX stulecia, po tym, gdy Darvin dobitnie przypomniał, iż ludzie i zwierzęta mają wiele wspólnego, wielu psychologów próbowało wyjaśnić stałość zachowania jednostki mówiąc o „instynktach”. Jeśli ktoś nieustannie wszczynał bójki z innymi ludźmi, to mogło to być spowodowane wrodzonym „instynktem wojowniczości”. Jeśli ktoś był skąpy, to był to „instynkt gromadzenia”. Jednakże tego rodzaju wyjaśnienia niewiele wnoszą.  Jeśli psychologowie chcieli wyjaśnić nowy rodzaj zachowania, to mogli tylko postulować istnienie nowego instynktu; uzyskiwali w ten sposób nowy termin psychologiczny, lecz wcale danego procesu psychologicznego nie rozumieli lepiej niż przedtem. Do lat dwudziestych naszego stulecia, według autora jednej z prac przeglądowych (Bernard, 1924), zaproponowano co najmniej 849 różnych kategorii instynktów. Najwyraźniej potrzebne było bardziej inspirujące podejście. Zdaniem wielu dostarczyły go prace Zygmunta Freuda.


Poglądy Freuda. Według teorii Freuda, podwaliny osobowości dorosłego człowieka zostały położone w jego wczesnym dzieciństwie. Nie tylko normalny rozwój osobowości przebiega w sposób ciągły, przez lata i stadia, lecz także źródła lęków i nerwic ludzi dorosłych można wykryć we wczesnym okresie ich życia. Ponieważ myśli Freuda w całej ich złożoności nie da się zawrzeć na kilku stronach, omówimy zatem pokrótce jedynie kilka najważniejszych pojęć (ryc. 10.2).


„Stadia rozwoju psychoseksualnego”. Według psychoanalitycznej teorii Freuda, rozwój osobowości w dzieciństwie dzieli się na |stadia |psychoseksualne. W każdym ze stadiów dominują instynktowne, nie wyuczone popędy biologiczne, które mają charakter |hedonistyczny (poszukiwanie przyjemności). Podczas każdego z tych kolejnych okresów satysfakcji zmysłowej dostarcza stymulacja innych erogenicznych stref ciała - ust, odbytu oraz genitaliów. Te szeroko pojęte siły seksualne określa się terminem |libido, obejmują zaś one ogół satysfakcji, jakiej jednostka doznaje w związku ze stymulacją ciała. W każdym ze stadiów rozwoju różny poziom zaspokojenia czy frustracji popędów składających się na libido („libidinal drives”) dostarcza okazji dla konfliktu intrapsychicznego.  Nadomiar czy to gratyfikacji, czy to frustracji w jednym ze stadiów uniemożliwia normalne przejście do następnego i mówi się, że prowadzi do |fiksacji na tym stadium. Fiksacje takie wpływają zatem na charakter przyszłych interakcji danego człowieka z jego otoczeniem. Przyjmuje się zatem, że fiksacja analna prowadzi do ukształtowania się charakteru obsesyjno-kompulsywnego, z takimi cechami, jak skąpstwo, schludność, upór, a fiksacja oralna ma być determinantem narkomanii, kompulsywnego jedzenia, jak również skłonności do sarkazmu i gadatliwości.
Najbardziej pierwotnym stadium rozwoju psychoseksualnego jest stadium |oralne, w którym rejon ust jest nie tylko związany z karmieniem, lecz jest równocześnie zasadniczym źródłem stymulacji oraz kontaktu z otoczeniem. Nie ulega wątpliwości, że niemowlęta i małe dzieci spędzają znaczną część czasu na czynnościach ssania nie mających charakteru pokarmowego (takich, jak ssanie kciuka czy palca u nogi).
W następnym stadium, |analnym, głównym źródłem gratyfikacji jest najpierw wydalanie odchodów, a następnie ich zatrzymywanie. Przyjemność, jaką dziecko czerpie zarówno z czynności wydalania, jak i obecności jego produktów, w większości kultur jest sprzeczna z wymaganiami społecznymi i w końcu zostaje stłumiona i poddana regulacji.
W następnym okresie satysfakcji erotycznej dostarcza przede wszystkim eksploracja i stymulacja własnego ciała, a zwłaszcza członka u chłopców i pochwy u dziewcząt. Po tym stadium |fallicznym następuje |stadium |latencji, w którym seksualność na parę lat „schodzi do podziemia”; wreszcie, w okresie dojrzewania jednostka osiąga stadium |genitalne - przechodząc od autoerotyzmu do stymulacji przez kontakt z narządami płciowymi innych osób.




* * *



Ryc. 10.2. Przed Freudem zakładano, że główny wpływ na działania ludzi ma świadoma myśl i racjonalny wybór, odnoszone do aktualnych sytuacji. Freud reprezentował pogląd, że myśli i zachowania, z których dana osoba zdaje sobie sprawę, stanowią jedynie niewielką część jej doświadczeń i że główne czynniki oddziałujące, zarówno na świadome myśli, jak i obserwowalne zachowania, mają charakter irracjonalny, nieświadomy i historyczny, przy czym każda warstwa wpływa na warstwy położone nad nią.


* * *





Dzieci pokonując te stadia, uczą się identyfikacji z właściwą rolą seksualną, rozwija się u nich „sumienie” (Superego), częściowo w wyniku uporania się z miłością seksualną do rodzica przeciwnej płci (sytuacja Edypa) i przygotowują się do odpowiedniego kulturowo heteroseksualizmu wieku dojrzałego.


Chociaż szkic ten zadaje gwałt subtelności myśli Freuda, z którą powinieneś zapoznać się dokładniej (Porównaj S.Freud „Psychopathology of Everday Life” i „Wstęp do psychoanalizy”), to jednak w ogólnym zarysie przedstawia jego koncepcję rozwoju osobowości. Należy tu dodać, że ten wspaniały obraz psychiki dziecka nie był wynikiem bezpośredniej obserwacji dzieci, lecz przede wszystkim własnej, analitycznej introspekcji Freuda oraz jego psychoanalitycznych wywiadów z dorosłymi pacjentami, które obejmowały historyczną rekonstrukcję ich przeszłości.


„Eros i Tanatos”. Na podstawie swych obserwacji Freud doszedł do wniosku, że źródłem energii dla wszelkiego rodzaju zachowań są dwa podstawowe „popędy”, które występują u każdej jednostki już w momencie urodzenia się.  Nazwał te dwa popędy „Eros” i „Tanatos”. |Eros, „popęd seksualny”, czyli instynkt życia” (dzięki tej koncepcji Freud zyskał w pewnych kręgach opinię „obleśnego starucha”) w rzeczywistości oznaczał coś więcej, niż zwykle mamy na myśli mówiąc o popędzie seksualnym. Eros obejmował wszelkie dążenia do twórczej syntezy; według Freuda dążenie do zjednoczenia seksualnego było tylko jednym z przejawów tego popędu. |Tanatos, „popęd agresji”, czyli „instynkt śmierci”, obejmował wszelkie dążenia do samozagłady, niszczenia porządku, kształtu i regularności. Freud zakładał, że aktywność psychiczna, podobnie jak aktywność fizyczna, wymaga energii. Jak już wspominaliśmy, energia twórczego popędu nosi nazwę |libido - Freud nie zaproponował odrębnego terminu dla energii psychicznej związanej przypuszczalnie z Tanatosem.


„Id, superego i ego”. Freud tłumaczył różnice indywidualne tym, że różni ludzie radzą sobie ze swymi podstawowymi popędami (Erosem i Tanatosem) w różny sposób. Aby wyjaśnić te różnice, przedstawił on obraz ciągłej wojny między dwiema częściami osobowości, id oraz superego, dla których rozjemcą jest trzeci komponent jaźni, a mianowicie ego.
|Id uważa się za pierwotną, nieświadomą część osobowości, magazyn podstawowych popędów. Id działa w sposób irracjonalny - impulsy domagają się wyrażenia i zaspokojenia - „wszystko jedno jak” - bez względu na to, czy to, co pożądane, jest możliwe do uzyskania lub moralnie akceptowane.




* * *



Ryc. 10.3. Fotografia ta, wykonana w 1912 roku, przedstawia Zygmunta Freuda z córką Anną, która również wniosła duży wkład do teorii psychoanalizy.


* * *





|Superego jest „składem wartości” danej jednostki, łącznie z postawami moralnymi wpojonymi przez społeczność. Superego właściwie odpowiada z grubsza |sumieniu; rozwija się ono, gdy dziecko |internalizuje zakazy rodziców i innych dorosłych dotyczące pewnych rodzajów działań. Superego obejmuje także |ja |idealne, które rozwija się, gdy dziecko internalizuje poglądy innych ludzi dotyczące tego, jakiego rodzaju osobą powinno ono starać się zostać. Toteż superego, reprezentacja społeczeństwa w jednostce, często jest w konflikcie z id - reprezentującym dążenie do przetrwania. Id chce robić po prostu to, co mu się podoba, podczas gdy superego nalega, aby robić to, co jest „słuszne”.
W tym konflikcie |ego odgrywa rolę rozjemcy. Ego reprezentuje posiadany przez daną jednostkę obraz rzeczywistości fizycznej i społecznej, wiedzę o tym, co do czego prowadzi i co jest możliwe w takim świecie, jaki jest aktualnie spostrzegany. Część funkcji ego polega na wybieraniu takich rodzajów działań, które zaspokoją impulsy id, nie pociągając za sobą niepożądanych konsekwencji. Ego zahamowałoby zatem prawdopodobnie impuls, by latać skacząc z urwiska, i mogłoby zastąpić to lotem na szybowcu lub przejażdżką na „diabelskim młynie” w wesołym miasteczku. Gdy id i superego są w konflikcie, wówczas ego stara się zwykle znaleźć jakiś kompromis, który przynajmniej w części zadowoli oboje. W tym celu ego może posłużyć się jednym lub kilkoma nieświadomymi „mechanizmami obronnymi” (tabela).  Ponieważ model Freuda zakłada, że każdy popęd („urge”) jest związany z energią psychiczną, przeto każdy z tych mechanizmów zapewnia znalezienie jakiegoś ujścia dla energii związanej z niemożliwym do zaakceptowania popędem. Na przykład w mechanizmie znanym jako |pozorowanie |reakcji („reaction formation”), energia zostaje związana z wyrażeniem przeciwnego impulsu („Ja nienawidzę go, ja go kocham. Czy nie widzisz, że dręczę go z miłości?”).
Według teorii freudowskiej, wszyscy doznajemy pewnych popędów, które nie są akceptowane w naszym społeczeństwie, a zatem wszyscy posługujemy się w pewnym stopniu tymi mechanizmami obronnymi. Jednakże nadużywanie ich prowadzi do |nerwicy. Ludzie, którzy mają nerwicę, wydatkują tak wiele swej energii na zmianę kierunku niemożliwych do zaakceptowania popędów, ich ukrywanie oraz znajdowanie dla nich innego ujścia, że pozostaje im niewiele energii na produktywne życie i zadawalajace stosunki z ludźmi.
Wiemy już, że konflikty, na których skupiają swą uwagę zwolennicy teorii psychoanalitycznej, pojawiają się według nich w różnych stadiach rozwoju psychoseksualnego. Uważa się, że zdolność danej jednostki do przystosowania się w późniejszym życiu jest zdeterminowana przede wszystkim przez doświadczenia z okresu wczesnego dzieciństwa. Jeśli bolesne konflikty z w dzieciństwie nie zostały odpowiednio rozwiązane, lecz jedynie uległy wyparciu, to w wieku dojrzałym będą one nadal - chociaż nieuświadamiane - wpływać na myśli, uczucia i zachowanie danej jednostki, powodując napięcie emocjonalne i trudności w przystosowaniu.
Według koncepcji Freuda, zdrową, czyli dobrze przystosowaną osobą, jest taka osoba, która potrafi z powodzeniem „kochać i pracować”. Miał on dość pesymistyczny pogląd na szansę uniknięcia nerwicy - wyrósłszy w epoce wiktoriańskiej (być może z tego właśnie powodu) był przekonany, że każde społeczeństwo musi uczyć swe dzieci, iż większość przejawów ich podstawowych popędów jest zła (stąd też prawie każdy będzie musiał bronić się przed nimi niemal przez cały czas). Jak się przekonamy, ci, którzy przyszli po nim, mieli bardziej optymistyczny pogląd na możliwość uniknięcia wypierania konfliktów oraz zachorowania na nerwicę.


„Psychopatologia „normalnego” zachowania”. Jakie są dowody na to, że konflikty opisywane przez Freuda rzeczywiście występują? Odpowiedź Freuda na to pytanie przeszła do kultury masowej jako „freudowskie przejęzyczenie się”. Według Freuda, nasze nieakceptowane popędy, chociaż zahamowane, stłumione czy wyparte nadal starają się znaleźć swój wyraz. Nasze pragnienie wyznania naszych wyobrażonych wykroczeń przeciw społeczeństwu „wydobywa się z nas wszystkimi porami” i przybiera wiele różnych postaci.  Na przykład „zapominanie” o ważnym spotkaniu z dentystką lub ciągłe spóźnianie się na randkę z określoną osobą mogą nie być przypadkowe, lecz mogą stanowić przykład tej skłonności dla wyrażania tego, co naprawdę |czujemy. Przywitanie niepożądanych gości słowami: „Jak mi przykro - ach, chciałem powiedzieć, jak mi przyjemnie, że przyszliście” może ujawniać prawdziwe uczucia gospodarza czy gospodyni. Gdy spiker w radiu, czytając ogłoszenie o „Chlebie Barbary Ann” („Barbara Ann Bread”), przeczytał błędnie słowa: „Barbara Ann for the best in bread” („Najlepszy chleb u Barbary Ann”) jako „Barbara Ann for the breast in bed” („Pierś w łóżku u Barbary Ann”), to czy ujawnił on publicznie swoje popędy?
Według Freuda, takie przejęzyczenia mają swe znaczenie, przy czym znaczenie to zawarte jest w nieświadomej intencji. Takie „błędy” można wyjaśnić na podstawie ostatecznego sensu wypowiedzi, nawet jeśli słuchacz oczekiwał innego jej znaczenia lub mówiący pozornie miał co innego na myśli. Freud był przekonany, że przejęzyczenia takie nieodmiennie wskazują rzeczywistą intencję (ryc. 10.4).


„Objawy jako sygnały”. Freud był przekonany, że poważniejsze zaburzenia, takie jak irracjonalne obawy, paraliż bez fizycznej przyczyny czy też dający się opanować lęk, również mają znaczenie w życiu jednostki, wyrażając jej poczucie bezradności i skłaniając innych, aby się nią zajmowali. Uważał on takie objawy za sygnał jakiegoś ukrytego konfliktu; zadaniem terapeuty było odkrycie związku pomiędzy danym objawem a powodującym go problemem.         


Freud postulował zatem zasadę |determinizmu |psychicznego, odnoszącą się zarówno do zachowania normalnego, jak i anormalnego; zasada ta głosi, że zjawiska psychiczne nie występują przypadkowo, chociaż mogą wydawać się  przypadkowe, lecz wszystkie są sensownie powiązane (okaże się to, jeśli zbadamy je dostatecznie głęboko). Jak przekonaliśmy się w Rozdziale 7, sądził on, że nawet w marzeniach sennych przejawiają się w pełnej znaczenia, aczkolwiek zamaskowanej postaci, ukryte, nieświadome procesy.  Freuda nazywano „największym egotykiem świata”, ponieważ miał on nadzieję, poddając każdą własną myśl i działanie bezlitosnej, mikroskopowej analizie, że odkryje prawdziwe znaczenie uczuć i działań wszystkich innych ludzi.




* * *



Ryc. 10.4. Przyszła Teściowa. Jako ćwiczenie w wykrywaniu „freudowskich przejęzyczeń” przeczytaj powyższy list (najpierw szybko, a potem jeszcze raz, bardziej niż uważnie). Jaki komunikat matka przekazuje nieświadomie swemu synowi, który właśnie zawiadomił ją o swych zaręczynach z dziewczyną z Richmond w stanie Virginia? (Ostatecznie zdanie listu w tłumaczeniu polskim brzmi: „Patrzymy w przyszłość z nadzieją, że nie stracimy syna, lecz córkę”).


* * *





Krytyka teorii freudowskiej. Krytycy wysunęli zarzut, że bardzo trudno jest ocenić wartość teorii psychoanalitycznej, ponieważ formułuje ona bardzo niewiele przewidywań sprawdzalnych empirycznie. Za pomocą tej teorii można wyjaśnić bardzo wiele, lecz większość tych wyjaśnień dokonuje się „po fakcie”. Niektórzy krytycy wskazują także, że terapia psychoanalityczna jest taką sytuacją uczenia się, w czasie której pacjenci otrzymują wzmocnienie za wypowiadanie stwierdzeń zgodnych z teorią. Stąd wypowiedzi psychoanalityków, że teoria znajduje „potwierdzenie” w tym, co stwierdzają oni u swych pacjentów, mogą być nieco podejrzane. Ponadto wykazano, że język psychoanalizy jest narzucony pacjentowi przez terapeutę - nie jest wspólny dla ich obu. Jako taki staje się on jednostronną formą komunikacji, która nie może dopomóc danej jednostce w zrozumieniu swych wewnętrznych emocji i uczuć (Holt, 1970).
Wysuwa się też zarzut, że teoria Freuda rozwinęła się z rozważań opartych na pracy klinicznej z ludźmi cierpiącymi na nerwicę i inne trudności w przystosowaniu, ludźmi, z którymi było coś „nie w porządku”. Tak więc teoria ta ma niewiele do powiedzenia o osobowości zdrowych osób lub o stylach życia, które nie mają charakteru defensywnego.
I wreszcie, duża część materiału dowodowego, na którym opiera się ta teoria, jest uzależniona od zapamiętania przez analityka tego, co zdarzyło się w trakcie godzinnego posiedzenia terapeutycznego. Oznacza to, że zdarzenia te musiały przejść przez „filtr teoretyczny” terapeuty, który ma tendencję do odsiewania danych niezgodnych z uznawaną przez siebie teorią osobowości. Co więcej, informacje uzyskiwane przez terapeutę są uzależnione od pamięci pacjenta. Freud był w istocie poważnie skonsternowany, gdy stwierdził, że wielu jego pacjentów opowiadało mu o wczesnych urazach seksualnych, które naprawdę nigdy się nie wydarzyły. Rozwiązał on ten problem rozstrzygając, że ważne jest |przekonanie pacjenta, iż coś się zdarzyło, nawet jeśli wspomnienie to jest niezgodne z prawdą.
Jednakże nawet najsurowsi krytycy Freuda uznają, że pod pewnymi względami wniósł on cenny wkład do współczesnej myśli:
1. Wprowadzając pojęcie nieświadomych przyczyn zachowania (w przeciwieństwie do twierdzenia racjonalistów, że nasza wola panuje w pełni nad naszym zachowaniem), Freud jako pierwszy położył nacisk na rolę, jaką nieświadome i irracjonalne procesy odgrywają w motywowaniu zachowania ludzkiego (ryc. 10.5).





* * *



Ryc. 10.5. „Zgoda, w gruncie rzeczy jest to wołanie o pomoc psychiatryczną - lecz w pewnym sensie jest to także napad rabunkowy”.


* * *





2. Chociaż większość współczesnych psychologów jest przekonana, że Freud kładł zbyt duży nacisk na rolę czynników seksualnych to jednak psychoanaliza utorowała drogę naukowym badaniom nad seksualnością i ukazała jej doniosłe znaczenie jako źródła trudności przystosowawczych.
3. Psychoanaliza zwróciła uwagę na doniosłe znaczenie doświadczeń z okresu dzieciństwa dla późniejszego rozwoju osobowości i przystosowania.



Teorie neofreudowskie. Wielu z tych, którzy przyszli po Freudzie, utrzymało stworzony przez niego obraz osobowości: pola bitwy, na którym nieświadome pierwotne impulsy walczą z wartościami społecznymi. Jednakże większość wprowadziła pewne zmiany. Niektórzy, jak Carl Jung i Alfred Adler, zaproponowali innych kandydatów do tytułu najważniejszego „pierwotnego impulsu” na miejsce freudowskiego szeroko zdefiniowanego popędu seksualnego. Adler skoncentrował się na poczuciu mocy, twierdząc, iż ludzie przede wszystkim dążą do przewagi nad innymi, aby skompensować uczucia niższości, których doświadczali, gdy byli mali i bezradni. Jung położył nacisk na doniosłe znaczenie uniwersalnych symboli i predyspozycji - |archetypów - dziedziczonych, jego zdaniem, w „zbiorowej nieświadomości”, wspólnej dla wszystkich członków rodu ludzkiego. Rozszerzył on także freudowski obraz rozwoju osobowości, sugerując, że „jaźń” („self”) pojawia się w wieku około 30 lat, aby połączyć te elementy osobowości, które rozwinęły się do tej pory. Inni neofreudyści, tacy jak Hartmann, Kris, Rapaport, a ostatnio Schafer, rozwinęli freudowski opis ego i jego funkcjonowania, czyniąc je równie ważnym jak id i superego i nie uważając go jedynie za rozjemcę między nimi. Jeszcze inni, jak Karen Horney i Erich Fromm, byli przekonani, iż Freud kładł zbyt silny nacisk na biologiczne oddziaływania na osobowość, kosztem wpływów społecznych i próbowali przywrócić właściwą równowagę tych czynników. Nieco bardziej szczegółowo rozpatrzymy teorię autorów, którzy posunęli się najdalej w podkreślaniu społecznej natury osobowości: Erika Eriksona i Harry’ego Stacka Sullivana.


„Portret jednostki sporządzony przez Eriksona”. Na podstawie swych klinicznych obserwacji nad dziećmi, dorastającą młodzieżą, studentami wyższej uczelni oraz starszymi osobami Erikson (1950) w swej książce „Childhood and Society” (Dzieciństwo a społeczeństwo) wzbogacił teorię rozwoju osobowości o trzy ważne idee. Po pierwsze, przez analogię do stadiów psychoseksualnych, postulował on psychospołeczne stadia rozwoju ego, w których jednostka kształtuje nowe nastawienia wobec siebie samej i innych ludzi ze swego otoczenia. Po drugie, rozwój osobowości rozpatrywał jako proces trwający nieustannie przez wszystkie fazy życia, a nie jako proces zakończony w okresie niemowlęctwa. Po trzecie, stwierdził, iż każde z tych stadiów wymaga nowego poziomu interakcji społecznej, co może zmienić przebieg rozwoju osobowości albo w kierunku pozytywnym, albo negatywnym.
Erikson zidentyfikował osiem stadiów rozwoju psychospołecznego, określających cykl ludzkiego życia od niemowlęctwa do starości. W każdym stadium najważniejsze znaczenie ma pewien szczególny konflikt; aczkolwiek nigdy nie zostaje on rozwiązany raz na zawsze, to jednak musi on być rozwiązany w takim stopniu, aby dana jednostka mogła uporać się skutecznie z konfliktami powstającymi w późniejszych stadiach.
1. |Zaufanie |czy |nieufność (pierwszy krok życia; odpowiada stadium oralnemu u Freuda). Zależnie od jakości opieki, jaką otrzymuje niemowlę, uczy się ono ufać swemu otoczeniu, spostrzegać je jako uporządkowane i przewidywalne lub też uczy się być podejrzliwe, lękliwe i nieufne wobec chaosu i nieprzewidywalności otoczenia.
2. |Autonomia |czy |zwątpienie (drugi i trzeci rok życia; odpowiada okresowi analnemu u Freuda). Zależnie od przebiegu rozwoju zdolności ruchowych i umysłowych oraz od tego, czy dziecko miało sposobność do manipulowania oraz badania otoczenia, powstaje jego poczucie autonomii, adekwatności i autokontroli. Nadmierny krytycyzm lub ograniczanie możliwości ćwiczenia się dziecka w eksploracji i innych zachowaniach sprawiają, że staje się ono nieśmiałe i wątpi we własną adekwatność.
3. |Inicjatywa |czy |poczucie |winy (czwarty i piąty rok życia; odpowiada stadium fallicznemu u Freuda). Zależnie od sposobu, w jaki rodzice reagują na inicjowaną przez dziecko aktywność - intelektualną, jak również ruchową - będzie ono albo samodzielne i przedsiębiorcze, albo też pełne poczucia winy i przekonane, że jest niezręcznym intruzem w świecie dorosłych.
4. |Pracowitość |czy |poczucie |niższości (szósty do jedenastego roku życia; odpowiada fazie |latencji w teorii freudowskiej, kiedy to dziecko jest najmniej zaabsorbowane sprawami seksualnymi). Zainteresowanie dziecka tym, jak wszystko działa i jak ono samo powinno działać, prowadzi do ukształtowania się pracowitości poprzez odkrywanie prawidłowości, organizowanie i podporządkowanie własnego świata oraz pilność. Można wywołać poczucie niższości u dziecka, gdy te jego wysiłki są odrzucane jako niemądre, złośliwe czy kłopotliwe. W tym właśnie stadium oddziaływania spoza domu zaczynają wywierać większy wpływ na rozwój dziecka - przynajmniej u dzieci amerykańskich z klasy średniej.
5. |Tożsamość |czy |przemieszanie |ról (okres dorastania, od dwunastego do osiemnastego roku życia). W tym okresie u jednostki zaczyna się rozwijać zdolność spostrzegania zjawisk w różnoraki sposób; potrafi ona patrzeć na pewne sprawy z punktu widzenia innej osoby, zachowywać się różnie w różnych sytuacjach, zgodnie z tym, co wydaje się odpowiednie. Odgrywając te różnorodne role, dana osoba musi rozwijać zintegrowane poczucie własnej tożsamości jako odrębnej od wszystkich innych, lecz spójnej i możliwej dla niej do zaakceptowania. Jeśli nie dokona się taka „integracja” tożsamości, to pojawia się następująca alternatywa: albo dana jednostka nie wie, kim właściwie jest, albo też przybiera „negatywną tożsamość” - jakąś rolę społecznie nieakceptowaną, jak na przykład „dziwaka-narkomana” lub też „błazna klasowego”.
6. |Intymność |czy |izolacja (dojrzała młodość). Gdy jednostka osiągnie wiek dojrzały, to jej usiłowania zmierzające do nawiązania kontaktu z innymi ludźmi mogą doprowadzić do intymności (związku-seksualnego, emocjonalnego i moralnego - z innymi osobami) lub do izolacji - braku bliskich stosunków personalnych.
7. |Wielkoduszność |czy |zaabsorbowanie |sobą (wiek średni). W tym okresie doświadczenia życiowe jednostki mogą rozszerzyć zakres jej zainteresowań tak, by nie ograniczały się do niej samej, lecz objęły rodzinę, społeczeństwo lub przyszłe pokolenia. Taka przyszłościowa orientacja może się nie rozwinąć i zamiast tego dana osoba, podobnie jak Scrooge w „Wieczorze wigilijnym” Dickensa, może interesować się tylko sprawami materialnymi i własnym dobrobytem.
8. Poczucie spełnienia czy rozpacz (wiek starczy). W tym ostatnim stadium życia człowiek spogląda wstecz. na to wszystko, co było, i w przód - na niewiadomą śmierci. W wyniku rozwiązań dokonanych na każdym z poprzednich stadiów może cieszyć się spełnieniem życia mając poczucie zadowolenia z siebie. Lecz rozpacz zagląda w oczu temu, kto stwierdza, że źle pokierował swoim życiem i że było ono niezadowalające. Jest zbyt późno, by patrzeć wstecz z gniewem lub w przyszłość z nadzieją i cykle życia takiej osoby kończy się jękiem rozpaczy.



Ponieważ nasz świat zmienia się coraz szybciej, stając się zarówno mniej stabilnym, jak i bardziej złożonym, przeto wydaje się, iż „kryzysy tożsamości”, które przeżywa tak wielu studentów, lepiej można zrozumieć w świetle bardziej tradycyjnych poglądów Freuda, które wywodzą się ze względnie statycznej koncepcji tradycyjnych problemów, jakie przed jednostką stawia jej społeczne i fizyczne środowisko.


„Społeczna koncepcja Sullivana”. Sullivan, podobnie jak Freud, stwierdził, że napięcie wynikające z niezaspokojenia potrzeb fizjologicznych często skłania ludzi do działania. Jednakże, w odróżnieniu od Freuda, był on przekonany, że nasze podstawowe potrzeby nie mają charakteru biologicznego, lecz wywodzą się z interakcji z ludźmi, i że te ukształtowane interpersonalnie cechy „ludzkie” mogą bezpośrednio oddziaływać na funkcjonowanie fizjologiczne lub modyfikować je. Na przykład w większości kultur istnieją mniej lub bardziej wypracowane zbiory reguł, określających kiedy i w jaki sposób można jeść, wydalać itd.
Sullivan posunął się tak daleko, że zidentyfikował osobowość nie jako coś, co tkwi w danej osobie, lecz jako „względnie trwały układ („pattern”) powtarzających się sytuacji interpersonalnych, które charakteryzują życie ludzkie” (1953, s. 111). Osobowość oznacza zatem dla niego stałość nie pod względem cech wewnętrznych, lecz pod względem tego, jak dana osoba zachowuje się |w |stosunku |do |innych |ludzi. Aby jednak osobowość przejawiła się, ci inni ludzie nie muszą być obecni fizycznie (ani też nawet nie potrzebują istnieć rzeczywiście), ponieważ dana osoba może wchodzić w interakcję z ludźmi zarówno w rzeczywistości, jak i w wyobraźni.  Na przykład ludzie potrafią „przeżuwać” długo w myśli to, co „powinni powiedzieć” policjantowi, który ich zatrzymał, lub mogą nawet przeżywać w wyobraźni interakcję z fikcyjną postacią z książki czy filmu.
Dla wyjaśnienia stałości zachowania interpersonalnego Sullivan wprowadził pojęcie „dynamizmu” i „personifikacji”. |Dynamizm jest długotrwałym, powtarzającym się wzorcem zachowania (inni teoretycy nazywają prawie to samo |nawykiem). Na przykład o kimś, kto zazwyczaj zachowuje się we wrogi sposób wobec pewnej osoby czy grupy osób, mówi się, że przejawia dynamizm wrogości; osoba, która skłonna jest nawiązywać lubieżne stosunki, przejawia dynamizm lubieżności itd. Dynamizmem może być każda nawykowa reakcja, czy to w formie postawy, uczucia, czy też skierowanego na zewnątrz działania.
Szczgólnie ważnym dynamizmem jest |system |ja („self-system”), który według Sullivana rozwija się, gdy dana jednostka uczy się unikać zagrożenia własnego bezpieczeństwa. Uczy się ona na przykład, że jeśli robi to, co podoba się jej rodzicom, wówczas nie zostanie ukarana. Następnie zaczyna więc stosować nawykowe „środki bezpieczeństwa”, które na pewne formy zachowania („dobre” ja) pozwalają, innych zaś („złe” ja) - zakazują.
|Personifikacja jest to wyobrażenie, jakie dana osoba ma o kimś innym.  Jest to zespół uczuć, postaw i poglądów, które w dużej mierze determinują zachowanie danej osoby wobec tego kogoś. Personifikacje wyuczone w niemowlęctwie mogą pozostawać nietknięte i wpływać na reakcje dorosłej osoby wobec ludzi. Dzieci, które personifikują swego ojca na przykład jako apodyktycznego i wrogiego, mogą zacząć personifikować innych starszych mężczyzn jako apodyktycznych i będą wobec tego reagować na niektórych nauczycieli i pracodawców, jak gdyby byli oni apodyktyczni i wrodzy, niezależnie od tego, czy w rzeczywistości są tacy, czy też nie.  Personifikację wspólną dla pewnej grupy ludzi Sullivan nazywał |stereotypem. Oto przykłady stereotypów często spotykanych w kulturze amerykańskiej: „długowłosy radykalny student”, „intelektualista w wieży z kości słoniowej”, „dobrze zapowiadający się młody pracownik na kierowniczym stanowisku, mający dom w dzielnicy podmiejskiej” oraz „męska, szowinistyczna świnia”.
Sullivan określił siedem stadiów rozwoju osobowości występujących w 
społeczeństwach zachodniej Europy. Są to: a) niemowlęctwo, b) dzieciństwo, 
c) okres późnego dzieciństwa („juvenile era”), d) preadolescencja, e) wczesny okres dojrzewania, f) późny okres dojrzewania, g) dojrzałość (Dokładną charakterystykę wszystkich stadiów rozwoju osobowości znajdzie Czytelnik w pracy Clary Thompson „Psychoanaliza: narodziny i rozwój”.  Warszawa 1965, PWN, s. 227-228 (przyp. red. nauk.)). Nacisk kładzie się tu na rodzaj stosunków interpersonalnych oraz na sposób myślenia, który staje się możliwy po osiągnięciu określonego stadium. Sullivan przyznawał, że w innych społeczeństwach proces ten może przebiegać nieco inaczej.

Aczkolwiek Sullivan przywiązywał dużą wagę do wpływu czynników społecznych na rozwój osobowości, to jednak uznawał on także potencjalny wpływ jednostek na społeczeństwo. Często krytykował współczesne społeczeństwo, dając wyraz przekonaniu, iż pod wieloma względami wpływa ono na rozwój osobowości w sposób sprzeczny z osobistymi potrzebami ludzi i hamuje raczej niż ułatwia, pełną realizację potencjalnych możliwości ludzkich. Jednocześnie, ponieważ był przekonany, że ludzie pozostają elastyczni przez całe życie, przeto optymistycznie zapatrywał się na ich szansę życia w zgodzie z nakazami społeczeństwa, o ile nie zacznie ono działać w sposób tak irracjonalny i represjonujący, że jednostki będą usiłowały raczej |je |zmieniać, niż po prostu przystosowywać się do niego.




Teorie pola: stałość
jako wynik realizacji
własnego ja




Te sposoby ujmowania osobowości, które należą do powyższej kategorii, w znacznie większym stopniu zajmują się rolą jaką w zachowaniu ludzkim odgrywa centralna koordynacja, jak i indywidualne samosterowanie.  Przedstawimy tu pokrótce trzy takie teorie. Wszystkie one są pod silnym wpływem |teorii |pola („field theory”), koncepcji, która zrodziła się przez analogię do nauk fizycznych. Model ten, zapożyczony z nauki o polach elektromagnetycznych, postuluje pola sił, które są w dynamicznej i nieustannie zmieniającej się równowadze. Psychologowie posługujący się tą teorią uważają, że zjawiska psychiczne, podobnie jak zjawiska fizyczne, reprezentują wypadkową interakcji wielu sił, a zmiana zachodząca gdziekolwiek w tym systemie wpływa na cały system. Uważa się zatem, że zachowanie nie jest kształtowane przez kombinacje sił, które tworzą całe pole.


Teoria Goldsteina. Teorią osobowości, która zapożyczyła wiele idei z teorii pola, jest |teoria |organizmu |jako |całości („organismic theory”); czołowym jej przedstawicielem jest Kurt Goldstein (1963). Jako neuropsychiatra zajmujący się żołnierzami, którzy w czasie pierwszej wojny światowej doznali uszkodzeń mózgu. Goldstein przyjął zasadę, że poszczególne objawy można zrozumieć tylko wtedy, gdy nie będzie się ich uważać jedynie za wynik poszczególnych chorób czy uszkodzeń, lecz za wytwór organizmu funkcjonującego jako całość. Organizm jest jednością, a to, co się zdarza w jakiejkolwiek jego części, wpływa na całość. Organizacja jest naturalną właściwością organizmu, a dezorganizacja oznacza chorobę.  Aczkolwiek części składowe trzeba wyodrębniać dla celów badań psychologicznych i medycznych, to jednak u danej osoby nie funkcjonują one w izolacji.
Teoria ta kładzie nacisk przede wszystkim na regularny rozwój wrodzonych potencjalnych możliwości organizmu. Uznaje ona jednak, że odpowiednie środowisko jest nieodzownym warunkiem, aby ten rozwój mógł nastąpić.  Zgodnie z tym, czego można by oczekiwać, teoria ta zakłada, iż organizm jest motywowany przez jeden dominujący, a nie przez kilka różnych, niezależnych popędów. Tym popędem, który Goldstein nazwał |samorealizacją („self-actualization”), jest nasze nieustanne dążenie do zrealizowania naszych wrodzonych potencjalnych możliwości.


Teoria „własnego ja” Rogersa. Do najlepiej znanych przedstawicieli teorii traktujących organizm jako całość należy Carl Rogers (ryc. 10.6), który zdobył uznanie także jako terapeuta. Kładzie on nacisk na prywatny świat jednostki, świat doznań, który nazywa |polem |fenomenologicznym („phenomenal field”). To właśnie spostrzeżenia i interpretacje dokonywane przez daną jednostkę determinują jej późniejsze zachowanie. Aby więc zrozumieć czyjeś zachowanie, nie wystarczy znać obiektywną sytuację: musimy zrozumieć, jak tę sytuację widzi dana osoba.
Odrębną częścią tego pola jest |pojęcie |o |sobie („self-concept”), które rozwija się w wyniku interakcji danej jednostki ze środowiskiem. Ludzie zachowują się w sposób zgodny z posiadanym obrazem samego siebie i skłonni są odrzucać lub zniekształcać napływającą informację, która jest zagrażająca dla ich „ja”. Doznanie może być zatem |ujęte |w |formę |symboliczną („symbolized”), w którym to przypadku staje się ono wyraźnie i świadomie spostrzegane, może nie być poddane symbolizacji i pozostaje poniżej poziomu świadomości lub też wreszcie może zostać zignorowane.
Dla Rogersa, podobnie jak dla Goldsteina, najbardziej podstawowym popędem oddziałującym na człowieka jest popęd samorealizacji. Niestety, popęd ten niekiedy popada w konflikt z potrzebą aprobaty, czyli |pozytywnej |oceny („positive regard”) zarówno ze strony siebie samego, jak i innych. Jeśli znaczące osoby z otoczenia dziecka wyrażają konsternację na widok niektórych rzeczy, które ono robi, nie wyjaśniając mu, że ta dezaprobata odnosi się do |zachowania, a nie do |niego jako osoby, wówczas dziecko może zacząć robić i myśleć tylko to, co jest akceptowane przez otoczenie (przypomnijmy sobie rozróżnienie pomiędzy karaniem reakcji a karaniem osoby - Rozdział 3) (Sytuacja, w której jednostka jest akceptowana przez otoczenie pod tym warunkiem, że spełnia jego określone wymagania, nosi nazwę |aprobaty |warunkowej („conditional regard”) - przyp. tłum.)




* * *



Ryc. 10.6. Carl Rogers znany jest nie tylko jako teoretyk osobowości, lecz także jako jedna z czołowych postaci w dziedzinie psychoterapii humanistycznej i uwrażliwiającej.


* * *





W tym przypadku rozwinie się |niezgodność („incongruence”) miedzy „prawdziwymi” uczuciami dziecka i jego czynnościami, z jednej strony, a tym, co „może być zaakceptowane” - z drugiej. Choroba umysłowa pojawia się wtedy, gdy ktoś nie ośmiela się być sobą, czyli w efekcie nie zdaje sobie sprawy ze swych prawdziwych doznań.
Rogers jest jednak przekonany, że gdy dana jednostka wyraźnie spostrzega i właściwie symbolizuje istniejące możliwości wyboru, to wybierze drogę rozwoju. Wyzdrowienie jest więc możliwe dzięki własnemu, wewnętrznemu dążeniu pacjenta do rozwoju i do osiągnięcia pełni osobowości („wholeness”), a zadaniem terapeuty jest, jak przekonamy się w Rozdziale 12, zapewnienie pacjentowi atmosfery bezpieczeństwa i zachęcanie go do czynienia dalszych wysiłków.


Teoria samorealizacji Maslowa. Innym teoretykiem, który uznał samorealizację za płodne pojecie, był Abraham Maslow. Mając poczucie, że psychologia skoncentrowała się zbytnio na słabościach człowieka, nie dostrzegając jednocześnie jego mocnych stron, Maslow starał się uzupełnić ten obraz badając zdrowe emocjonalnie jednostki.


Uznawał on naturę ludzką za, w zasadzie, dobrą, lecz jednocześnie uważał, że wrodzona tendencja do rozwoju i samorealizacji jest raczej słaba i krucha, łatwo ulega naciskom społecznym. Maslow rozróżniał |motywację |wynikającą |z |niedoboru („deficienci motivation”), przy której jednostka stara się przywrócić swą fizyczną czy psychiczną równowagę, oraz |motywację |wzrostu („growth motivation”), przy której jednostka stara się wyjść poza to, co zrobiła i czym była w przeszłości; ludzie mogą powitać z radością niepewność, wzrost napięcia, a nawet cierpienie, jeśli uważają je za drogę wiodącą do spełnienia.
Według Maslowa, wrodzone potrzeby człowieka tworzą |hierarchię ważności.  Gdy potrzeby na jednym poziomie są zaspokojone, wówczas zaczynają dominować potrzeby znajdujące się na poziomie następnym. Jeśli zatem zaspokojone są potrzeby fizjologiczne, takie jak głód i pragnienie, to wówczas zaspokojenia żądają potrzeby należące do następnego poziomu - potrzeby bezpieczeństwa. Po nich idą w kolejności potrzeby przynależności i miłości, potrzeby szacunku i potrzeby samorealizacji. Na szczycie tej hierarchii potrzeb znajduje się siódmy poziom - potrzeba „transcendencji”. Maslow dodał ten poziom, aby reprezentował on najwyższą z ludzkich potrzeb, która wykracza poza samorealizację, pragnienie tożsamości, a nawet poza własne „jednostkowe człowieczeństwo”. „Psychologia transpersonalna” stała się odrębną dziedziną badań nad wyższymi stanami świadomości oraz poszukiwaniami duchowymi jako podstawowymi aspektami ludzkiego życia (ryc.  10.8).
Chociaż dla większości ludzi samorealizacja jest nadzieją czy celem, czymś, czego się pragnie i do czego się dąży, to jednak nieliczni zdają się osiągać w pełni ten cel. Maslow przeprowadził studia nad grupą takich osób, aczkolwiek nigdy nie określił wyraźnie, w jaki właściwie sposób je dobrał i jak przeprowadził swoje badania. Włączył do niej zarówno postacie historyczne, takie jak Beethoven i Lincoln, jak i osoby żyjące w czasie przeprowadzania tego badania, włącznie z Einsteinem i Eleanor Roosvelt. Na podstawie wyników tych badań Maslow sformułował listę piętnastu cech charakteryzujących osoby, które osiągnęły samorealizację (Maslow, 1954). A czy ty na podstawie poniższych kryteriów uznałbyś siebie za „zrealizowanego”?
1. Osoby, które osiągnęły samorealizację, spostrzegają rzeczywistość w sposób bardziej adekwatny i pozostają z nią w bardziej zadawalających relacjach, to znaczy |żyją |one |bliżej |rzeczywistości i natury, potrafią dokładnie oceniać innych i potrafią tolerować niejednoznaczność czy niepewność łatwiej niż większość ludzi.
2. Potrafią one |akceptować |siebie i swe różne cechy z małym poczuciem winy czy lęku, a jednocześnie potrafią łatwo akceptować innych.
3. Wykazują one dużą |spontaniczność, zarówno w myśleniu, jak i zachowaniu, aczkolwiek rzadko wykazują skrajną niekonwencjonalność.
4. Są one |skoncentrowane |na |problemach, a nie na własnym ja, często poświęcają się rozwiązywaniu ogólnych problemów społecznych, traktując to jako swą misję życiową.
5. Posiadają one |potrzebę |zachowania |sfery |prywatności, a niekiedy nawet prawa do samotności, i potrafią patrzeć na życie z „odległego”, obiektywnego punktu widzenia.





* * *



Ryc. 10.8. Hierarchia Potrzeb. Według Maslowa, potrzeby z „niższych” (od 1 wyżej) poziomów dominują tak długo, dopóki nie zostaną zaspokojone. Gdy jednak są one w dostatecznym stopniu zaspokojone, wówczas uwagę i wysiłek jednostki absorbują potrzeby „wyższe”.
1. Potrzeby fizjologiczne
2. Bezpieczeństwa 
3. Miłości
4. Przynależności
5. Szacunku
6. Samorealizacji
7. Transcendencji



* * *





6. Są one stosunkowo |niezależne |od |swej |kultury |i |środowiska, lecz to, że przekraczają konwencje, nie jest spowodowane chęcią odróżnienia się od innych.
7. Potrafią |głęboko |cenić podstawowe doznania życiowe, nawet w wypadku rzeczy, które robiły czy widziały wiele razy przedtem.
8. Wiele z nich doznało |mistycznych |przeżyć, takich jak głęboka ekstaza, uczucie, że otwierają sie przed nimi bezkresne horyzonty lub też poczucie, że są bardzo potężne, a jednocześnie bardzo bezradne, przy czym doznania takie pozostawiały po sobie przekonanie, że wydarzyło się coś ważnego.
9. Mają one |głębokie |zainteresowania |społeczne oraz zdolność utożsamiania się i współodczuwania z ludźmi w ogóle.
10. Są one zdolne do bardzo |głębokich, |dających |zadowolenie |stosunków |interpersonalnych, zwykle raczej z niewieloma osobami.
11. Są one |demokratyczne w swych postawach wobec innych, wykazując szacunek dla wszystkich ludzi, bez względu na ich rasę, wyznawaną religię, poziom dochodów itd.
12. Odróżniają wyraźnie cele od środków służących do ich osiągnięcia, lecz częściej niż osoby niecierpliwe umieją czerpać radość z tych środków, to znaczy z |działania |zmierzającego |do |realizacji |celu.
13. Mają one |poczucie |humoru, przy czym ich żarty są zwykle filozoficzne i niezłośliwe.
14. Są one wysoce |twórcze, każda na swój własny, indywidualny sposób. 
Występuje u nich zjawisko „pierwotnej twórczości („primary creativity”), która wywodzi się z nieświadomości” i prowadzi do naprawdę oryginalnych, nowych odkryć. Cecha ta przejawia się w dowolnej dziedzinie, jaką obierze sobie osoba, która osiągneła samorealizację, i należy ją odróżnić od tego rodzaju „produktywnej twórczości” („producitive creativity”), jaka znajduje swój wyraz w sztuce, muzyce, poezji, nauce czy w wynalazkach. Osoba, która osiągnęła samorealizację, będzie oczywiście wykazywać oba te rodzaje twórczości w każdej z tych dziedzin.
15. Są one |odporne |na |wpływy |kulturowe („enculturation”). Innymi słowy, chociaż są dostosowane do swej kultury, to jednak są od niej niezależne i nie podporządkowują się ślepo wszelkim jej wymaganiom.

Posiadając wszystkie te cechy, osoby, które osiągnęły samorealizację, są szczególnie zdolne do kochania i bycia kochanym w najpełniejszy sposób.
Charakterystyczne dla osób, które osiągnęły samorealizację, są różnego rodzaju |doznania |szczytowe („peak experiences”). Są to „momenty największego szczęścia i spełnienia” - doznania te mogą pojawiać się z różnym stopniem nasilenia i w najróżniejszych sytuacjach: w miłości seksualnej, w trakcie przeżyć rodzicielskich, aktywności twórczej i percepcji estetycznej, jak również przy podziwianiu natury lub nawet podczas intensywnego uczestniczenia w zajęciach sportowych.
Reprezentanci teorii pola, tacy jak Goldstein, Rogers i Maslow, kładą zatem nacisk na podstawowy popęd do samorealizacji, jako czynnik organizujący wszystkie różnorodne siły, których wzajemna gra nieustannie stwarza to, czym jest dana osoba. Rozwinęli oni teorie, które wydają się bardziej „ludzkie”, niż wiele poprzedzających je, przy czym podkreślają w nich doniosłe znaczenie sposobu, w jaki ludzie spostrzegają swój świat, a także przypisują dużą wagę zjawisku zdrowia i procesom rozwoju.


Krytyka teorii samorealizacji. Krytyka tego podejścia koncentruje się na mglistości centralnego pojęcia „samorealizacji”. Po pierwsze, nie jest jasne, w jakim stopniu samorealizacja jest raczej dążeniem ukształtowanym społecznie niż tendencją wrodzoną. Po drugie, nie jest ona na tyle dobrze zdefiniowana, aby być efektywnym predyktorem zależności behawioralnych. Za pomocą tych teorii trudno jest zatem wyjaśnić te specyficzne rodzaje stałości, które charakteryzują poszczególne jednostki, chyba, że czynią to w sposób bardzo ogólny. Ponadto ten sposób podejścia do tematu nie zainicjował dużej liczby badań, lecz raczej pewien sposób pojmowania osobowości ludzkiej.




Teorie czynnikowe:
stałość jako wynik
zbioru cech




Inny sposób myślenia o osobowości polega na opisywaniu i wyjaśnianiu specyficznych zbiorów właściwości ludzkich.


Teoria cech i rozwój analizy czynnikowej. Jeden z najwcześniejszych i najbardziej bezpośrednich sposobów opisywania stałości ludzkiej polegał na określeniu |cech („traits”). Jeśli ktoś był zawsze przyjazny, to posiadał on cechę „przyjazności”, jeśli osiągał dobre wyniki w sportach - to cechą tą były „zdolności sportowe”. Cechy były traktowane podobnie do instynktów - z tego względu, że podobnie jak instynkty uważano je za właściwości wewnętrzne, natomiast zagadnienie, czy dana cecha jest wrodzona, czy też nie, pozostawiano otwarte.
Nic więc dziwnego, że zwolennicy teorii cech popadli w te same kłopoty, co przedstawiciele teorii instynktów: ich listy cech zdawały się ciągnąć w nieskończoność i nie było dwóch takich list, które zgadzałyby się ze sobą.  Następnie przyszło komuś na myśl, że być może niektóre cechy są bardziej „podstawowe” niż inne: że kłopotliwa mnogość |cech |powierzchniowych („surface traits”) może odzwierciedlać interakcje znacznie mniejszego, bardziej uporządkowanego zbioru |cech |źródłowych (source traits; Cattell, 1957). Z początku nie było to zbyt przydatne, gdyż każdy mógł tylko zgadywać, które cechy są powierzchniowe, a które źródłowe. Proponowane listy cech źródłowych były krótsze, lecz nadal zgodność między nimi była niewielka. Później jednak weszło do akcji potężne narzędzie matematyczne, zwane |analizą |czynnikową („factor analysis”).
Analiza czynnikowa jest techniką matematyczną (związaną z zastosowaniem algebry macierzy) pozwalającą zredukować wielką liczbę obserwowanych zjawisk do mniejszej liczby bardziej podstawowych zmiennych. Przypuśćmy, że na początek wielu ludziom daliśmy do wykonania dużą baterię testów osobowości i w ten sposób dla każdej osoby otrzymaliśmy sto wskaźników (przypuszczalnych miar cech). Chcemy dowiedzieć się, w jaki sposób te wskaźniki są związane ze sobą wzajemnie, jeśli jednak skorelujemy wszystkie wskaźniki dla jednej tylko osoby, to otrzymamy 4950 różnych liczb do ocenienia. Aby zinterpretować sensownie tę ogromną ilość danych, z których wiele może być redundantnych (tzn. mierzących to samo), stosuje się techniki matematyczne i statystyczne, w celu ustalenia minimalnej liczby czynników, które mogą wystarczająco adekwatnie wyjaśnić całą tę macierz korelacji.
Czynnikom tym nadaje się nazwy odpowiadające ogólnej właściwości, którą zdają się one reprezentować, na przykład „towarzyskość” czy „impulsywność”.  W ten sposób analiza czynnikowa odpowiedzi na sto pytań z testów osobowości pozwoliłaby wyodrębnić pięć lub sześć czynników, których w istocie dotyczyła większość tych pytań.


Dlaczego wyniki uzyskane za pomocą tej metody są tak ważne? Dla zwolenników teorii cech były one wprost fascynujące, ponieważ analiza czynnikowa umożliwiła badanie testów mających określić różne cechy oraz wykrywanie, czy w rzeczywistości mierzą one tę samą rzecz, czy też różne rzeczy. Gdy w kilku testach stwierdzono ten sam czynnik, to wydawało się rozsądne przyjąć, że musi on reprezentować jedną z „cech źródłowych”, które teoretycy ci tak bardzo starali się znaleźć. Tu była zaś do dyspozycji obiektywna, matematyczna procedura, którą mogli się oni posłużyć dla wykrycia podstawowej struktury osobowości ludzkiej. Kilku z nich od razu zabrało się do dzieła, próbując zrealizować ten cel. Omówimy tu pracę jednego z tych badaczy, a mianowicie J. P. Guilforda.


Teoria czynnikowa Guilforda. Guilford zidentyfikował dwie grupy ogólnych czynników osobowościowych (hormetyczne i temperamentalne), jak również grupę czynników odnoszących się do specyficznych rodzajów funkcjonowania intelektualnego.


„Czynniki hormetyczne”. Cechy hormetyczne są to cechy, które bezpośrednio wiążą się z motywacyjną sferą osobowości danej jednostki. (Słowo |hormetyczny pochodzi z języka greckiego i oznacza „wprawiający w ruch” lub „pobudzający”). Czynniki te zależą od fizycznych potrzeb organizmu oraz od rodzaju doświadczeń danej jednostki; tak więc mogą one być nieco różne w różnych społeczeństwach.



Obejmują one potrzeby, postawy i zainteresowania.
Długoletnie, systematyczne badania Guilforda, Cattella, Eysencka oraz wielu innych ujawniły wiele dających się mierzyć potrzeb, postaw i zainteresowań, co do których uważa się, że ukierunkowują nasze zachowanie i świadomość oraz podtrzymują naszą aktywność, dopóki nie osiągniemy pewnego celu.




* * *



Ryc. 10.9. Profil Testowy Kandydatki. Ocena: Poleca się p. Suzan Ortez na stanowisko urzędniczki w dziale inwentaryzacji. Jest ona osobą bystrą i energiczną, zdolną do wytężonej pracy w sytuacji stresowej. Ponadto jest ambitna. Co więcej, jest bardzo chętna do współpracy i życzliwa, powinna chętnie przyjmować polecenia i wskazówki.
Jeśli chodzi o charakter jej zainteresowań, to p. Ortez dobrze znosi ogromną liczbę szczegółów, jaka wiąże się z tym rodzajem pracy. Trzeba pamiętać, że p. Ortez bardzo chce zostać kiedyś księgową i ma potrzebne do tego zdolności - w istocie jest ona niezwykle uzdolniona do prac o charakterze rachunkowym. Pani Ortez wykazuje zatem zdolności umożliwiające jej nie tylko pracę na wskazanym stanowisku, lecz także osiągnięcie w końcu jej celu - pracy w księgowości. Zaleca się kierownictwu, aby - jeśli okoliczności pozwolą - zachęciło ją do uczęszczania na kursy wieczorowe, by mogła przygotować się do awansu na stanowisko księgowej. Wydaje się, że byłoby to równie korzystne dla kierownictwa, jak i dla p. Ortez, ponieważ istotnie ma ona duże możliwości rozwoju.


* * *





Przykładem takich potrzeb może być ambicja, potrzeba swobody, agresywność, a zainteresowania tego rodzaju to na przykład upodobanie do przygód, zamiłowanie do dokładności oraz zamiłowania estetyczne. Lista czynników hormetycznych, które były przedmiotem badań, nie jest bynajmniej wyczerpana i badania w tej dziedzinie trwają nadal. Wielu psychologów zajmuje się tą tematyką i jest interesujące, że ich stwierdzenia są w zasadzie zgodne - sytuacja zupełnie odmienna od tej, jaka często powstaje wśród badaczy stosujących mniej obiektywne sposoby podejścia.
a
„Czynniki temperamentalne”. Guilford i jego współpracownicy prowadzili także badania nad czynnikami temperamentu, które określają |sposób, w jaki jednostka działa w pewnych typach sytuacji. Właściwości takie mierzy się za pomocą skal, takich, jak „Guilford-Zimmerman Temperament Survey” - jest to inwentarz służący do opisu samego siebie, który opracowano na podstawie wyników badań prowadzonych przy zastosowaniu analizy czynnikowej. Każda z dziewięciu cech została wyrażona jako wymiar o dwóch skrajnych punktach; wynik danej jednostki wypada w którymś miejscu na skali pomiędzy tymi punktami. Następnie można wykreślić profil wysokich i niskich wyników, uzyskiwanych przez daną osobę, odpowiadający tym dziewięciu cechom temperamentu (podobnie jest w przypadku zainteresowań i zdolności). Skalę tę stosuje się często dla przewidywania prawdopodobnego powodzenia danej jednostki pracy na różnego rodzaju stanowiskach; na rycinie 10.9 przedstawiono taki przykładowy profil testowy.
Chociaż test ten dostarcza miar kilku cech, to jednak należy pamiętać, że żadna cecha nie występuje sama. Każda jest uwarunkowana i modyfikowana przez wszystkie inne cechy i właściwości danej jednostki. Na przykład osoba bardzo dominująca, a jednocześnie wysoce koleżeńska, będzie miała osobowość bardzo różniącą się od osobowości kogoś, kto jest równie dominujący, lecz mało koleżeński.


„Czynniki intelektualne”. Jeszcze bardziej ambitną próbą poklasyfikowania czynników, zgodnie z pewnym układem odniesienia, jest |model |struktury |intelektu opracowany przez Guilforda. Guilford klasyfikuje czynniki intelektualne według |treści (typu informacji), według rodzaju |wytworu (formy) oraz według |operacji, jaka wchodzi w grę. Wyróżnia pięć rodzajów operacji (ocenianie, wytwarzanie konwergencyjne, czyli zbieżne, wytwarzanie dywergencyjne, czyli rozbieżne, pamięć oraz poznawanie), sześć rodzajów wytworów (jednostki, klasy, relacje, systemy, transformacje oraz implikacje) i wreszcie cztery rodzaje treści (figuralne, symboliczne, semantyczne oraz behawioralne).
Różne zdolności intelektualne reprezentują różne kombinacje treści, wytworów oraz operacji. Innymi słowy, każdy z czterech typów treści może przyjmować formę każdego z sześciu rodzajów wytworów (4 x 6 = 24). Na tych dwudziestu czterech rodzajach informacji można przeprowadzić pięć typów operacji (24 x 5 = 120). Mamy zatem ogółem sto dwadzieścia możliwych zdolności intelektualnych. Przykładem jednej z takich zdolności jest rozumienie słów („verbal comprehension”), które w tym systemie klasyfikuje się jako |poznawanie |jednostek o treści |semantycznej.
Ten model teoretyczny jest analogiczny do okresowego układu pierwiastków chemicznych. Dzięki takiemu systematycznemu układowi odniesienia można postulować istnienie pewnych czynników intelektualnych zanim jeszcze zostały one wykryte, podobnie jak to było w wypadku pierwiastków chemicznych. W roku 1961, kiedy to Guilford przedstawił ten model, zidentyfikowanych było prawie 40 zdolności intelektualnych. Od tego czasu badacze wykryli wiele innych zdolności, tak że ostatnio ich liczba zbliżyła się do stu (Guilford, 1973).


Krytyka teorii cech. Nie ulega wątpliwości, że zwolennicy teorii czynnikowej opracowali bardzo efektywne sposoby opisywania i wyjaśniania nawet bardzo złożonych form stałości w kategoriach cech indywidualnych. 
Zarzuty wysuwane pod adresem tego sposobu podejścia są trzech rodzajów: 
teoretyczne, metodologiczne i empiryczne.


Z teoretycznego punktu widzenia krytykuje się głównie to, że zwolennicy teorii czynnikowej przedstawiają osobowość jako zbiór cech, lecz w niewielkim jedynie stopniu pomagają nam zrozumieć, w jaki sposób cechy te wiążą się ze sobą tworząc spójny system, który uważamy za osobowość.
Pod względem metodologicznym podejście to oskarża sie o tworzenie skal, które są „nieczyste” lub niewłaściwie nazwane. Na przykład, kilka różnych miar określanych jako „lęk” („anxiety”) nie wykazuje wysokich korelacji między sobą. Z drugiej strony, wysuwa się zarzut, że zbyt często wysokie korelacje między skalami wynikają po prostu z zastosowania identycznych pytań w różnych skalach - inaczej sformułowanych, lecz w rzeczywistości badających to samo. Wreszcie skale przeznaczone do mierzenia poszczególnych cech są niekiedy skażone zmienną aprobaty społecznej (skłonnością osób badanych do zaznaczenia takich odpowiedzi, które ich zdaniem są aprobowane) lub tendencją do zgadzania się czy „potakiwania” („acquiescence”; skłonność do zgadzania się z prawie każdym twierdzeniem).
Z empirycznego punktu widzenia najmocniej skrytykował teorię cech Walter Mischel (1968). Według niego, różne wymiary osobowości, uzyskane za pomocą analizy odpowiedzi kwestionariuszowych, wyglądają pięknie na papierze, lecz nie korelują z niczym (prócz innych odpowiedzi kwestionariuszowych) na tyle wysoko, aby można było na nich polegać w wypadku jakichkolwiek zastosowań, poza decyzjami dotyczącymi grubego odsiewu.
Co więcej, Mischel wątpi, czy te cechy i czynniki są w ogóle „w” danej osobie. Zgromadził on imponujący zbiór danych świadczących o tym, że cechy nie mające charakteru poznawczego (intelektualnego) nie są dobrymi predyktorami zachowania, ponieważ samo zachowanie w różnych sytuacjach jest zmienne i niekonsekwentne. Argumentuje on przekonywająco, że ten brak „ładnego, czystego układu” wysokich korelacji nie wynika z niedoskonałych pod względem metodologicznym narzędzi służących do oceny osobowości, lecz raczej z fałszywego założenia, iż |istnieje jakiś centralny rdzeń dyspozycji osobowościowych, który należy wykryć.
Mischel, podobnie jak zwolennicy teorii społecznego uczenia się (którą omówimy w następnym podrozdziale), kładzie nacisk na czynniki sytuacyjne, które wywołują zachowanie oraz warunki wzmacniające, które je podtrzymują.  Zachowanie danej osoby jest stałe, gdy te warunki podtrzymujące są stałe; jest ono niezmienne w różnych warunkach wtedy, gdy ważne cechy bodźcowe pozostają te same. Gdy jednak cechy te zmieniają się, wówczas zachowanie również się zmienia (jest niestałe lub niekonsekwentne), bez względu na to, jaki może być ów rdzeń trwałych dyspozycji. Zgodnie z jego poglądem, zachowanie stosuje się do praw uczenia się, a stałość, jaką przypisujemy „cechom behawioralnym”, wynika po prostu z faktu, że dla większości z nas przez większą część czasu warunki wywołujące i podtrzymujące zachowanie pozostają w zasadzie takie same.
Czy pogląd taki czyni jednostkę mechanicznym automatem pozbawionym indywidualności i odrębnego charakteru? Przeciwnie, stwierdza Mischel: właśnie upierając się przy istnieniu niezmiennych cech, wbrew zmienności, jaką obserwujemy, zadajemy gwałt złożoności zachowania ludzkiego. Uznanie faktu, że ludzie reagują na subtelne zmiany w ich środowisku, jest opowiedzeniem się za ludzką adaptacyjnością i elastycznością.




Teorie uczenia się:
stałość jako wynik
wyuczonych nawyków




Większość psychologów eksperymentalnych spogląda nieco podejrzliwie na teorie osobowości i ich twórców. Ogólnie biorąc, koncentrują oni swą uwagę na wyszukiwaniu stałych relacji pomiędzy obserwowalnymi warunkami bodźcowymi i obserwowalnym zachowaniem, przyjmując możliwie najmniej założeń co do nieobserwowalnych procesów (takich, jak „osobowość”).  Nieliczni próbują jednak rozszerzyć teorię uczenia się S-R tak, aby mogła ona wyjaśnić bardziej złożone rodzaje stałości w zachowaniu ludzkim. Przez długi czas najbardziej znanymi wśród nich byli John Dollard i Neal Miller.


Dollard i Miller: rzecznicy pojednania. Dollard, socjolog i antropolog, oraz Miller, psycholog eksperymentalny, który poddał się psychoanalizie w czasie programu szkoleniowego w Wiedeńskim Instytucie Psychoanalizy, połączyli zainteresowanie problemami tego rodzaju, którymi zajmowali się Freud, z uznaniem dla metodologicznego rygoryzmu teorii uczenia się Hulla.  Starali się oni zatem znaleźć jakiś sposób pogodzenia ze sobą tych dwóch sposobów podejścia. Na pierwszy rzut oka bogata (złożona) teoria Freuda wydaje się bardzo odmienna od tego rodzaju stwierdzeń, jakie zwykle są wynikiem badań nad szczurami biegającymi w labiryncie. Jednakże w rzeczywistości istnieją pewne istotne podobieństwa. Po pierwsze, koncepcja Freuda, podobnie jak teoria Hulla, była teorią |redukcji |napięcia: w obu tych teoriach przyjmowano, że organizm działa w celu zredukowania „napięcia” wytworzonego przez nie zaspokojone popędy. Po drugie, obie te teorie kładą nacisk na doniosły wpływ |wczesnego |okresu |uczenia się na zachowanie organizmu w późniejszym życiu. Chociaż w obu tych systemach teoretycznych używa się bardzo odmiennej terminologii do formułowania swych wniosków, to jednak dostarczają one modeli funkcjonowania człowieka, między którymi istnieją ważne analogie.
Dollard i Miller (1950) koncentrują się na procesie uczenia się, czyli wytwarzania nawyków. Omawiają one cztery najważniejsze elementy tego procesu: popęd, sygnał, reakcję oraz wzmocnienie (nagrodę). |Popędy skłaniają organizm do działania, |sygnały wskazują, jakie zachowanie jest właściwe (doprowadzi do redukcji popędu), |reakcja to właśnie owo zachowanie, |wzmocnienie zaś zwiększa siłę związku między sygnałem a reakcją dzięki temu, że redukuje napięcie spowodowane popędami.
Interesującym przykładem, który pokazuje, w jaki sposób Dollard i Miller przekładają pojęcia Freuda na język eksperymentalnej teorii uczenia się, jest ich analiza takiej cechy osobowości, jak „niezdecydowanie”. Rozpatrzmy - proponują oni - przypadek zakochanego mężczyzny zastanawiającego się nad małżeństwem. Znalazł on już doskonałą partnerkę i poczyniono odpowiednie przygotowania. Lecz w miarę zbliżania się dnia ślubu wątpliwości mężczyzny wzmagają się. W końcu ku konsternacji wszystkich zainteresowanych, cała impreza zostaje odwołana w ostatniej minucie. Po tygodniu narzeczony decyduje się, aby pomimo wszystko mieć to już za sobą. Lecz kiedy nadszedł dzień ślubu, małżeństwo znów nie dochodzi do skutku. Jak wytłumaczyć takie niezdecydowane, pełne wahania zachowanie? I w jaki sposób wyjaśnić fakt, że jest mnóstwo mężczyzn, którzy pomimo narastających wątpliwości w ostatniej minucie nie cofają się i żenią się ze swymi wybrankami?
Miller (1944) podaje cztery zasady, wywodzące się z badań nad zwierzętami, które zdają się być pomocne w zrozumieniu tego rodzaju konfliktowej sytuacji:
1. Tendencja do zbliżania się do upragnionego celu staje się tym silniejsza, im bliżej celu znajduje się dany osobnik (|gradient |dążenia).
2. Tendencja do oddalania się od wzbudzającego strach miejsca czy obiektu również staje się silniejsza w miarę tego, jak dany osobnik zbliża się do niego (|gradient |unikania).
3. Siła tej drugiej tendencji (do oddalania się) wzrasta szybciej niż siła pierwszej tendencji (do zbliżania się). Innymi słowy - gradient unikania jest bardziej stromy niż gradient dążenia.
4. Siła każdej z tych tendencji zmienia się wraz z siłą popędu stanowiącego podłoże danej tendencji. Można więc powiedzieć, że duża siła popędu podnosi niejako cały gradient na wyższy poziom. Zamieszczone na następnej stronie dwa wykresy (ryc. 10.11) pokazują, w jaki sposób zasady te pomagają nam zrozumieć zachowanie dwóch różnych typów narzeczonych.  Powyższy przykład ilustruje w ciekawy sposób podejście zastosowane przez Dollarda i Millera, lecz w większym stopniu dotyczy ono zachowania ludzi w krótkotrwałych sytuacjach niż tych rodzajów stałości - w czasie i przestrzeni - którymi zwykle zajmują się teoretycy osobowości.



Teoria społecznego uczenia się. Współcześni teoretycy uczenia się chwalą metody eksperymentalne i sprawdzalne twierdzenia Dollarda i Millera, lecz krytykują ich pod dwoma innymi względami.




* * *



Ryc. 10.11. Ja Się (Nie) Żenię Dzisiaj Rano. Pierwszy wykres przedstawia, co wynikałoby ze sformułowanych przez Millera zasad w wypadku narzeczonych, którzy ciągle odwołują ślub. Jednocześnie pragnął oni małżeństwa i obawiają się go, lecz kiedy do ślubu jest jeszcze daleko, gradient dążenia przebiega znacznie wyżej od gradientu unikania: tendencja do dążenia jest silniejsza niż tendencja do unikania, a więc nadal podtrzymują swe plany małżeńskie.  Później, gdy dzień ślubu jest coraz bliższy, siła tendencji do unikania coraz mniej ustępuje sile tendencji do dążenia, aż wreszcie w pewnym momencie tendencja do unikania staje się silniejsza. Przez krótki czas narzeczeni ci mogą jeszcze nie rezygnować ze swych planów, wiedząc, jak bardzo wiadomość o odwołaniu ślubu zdenerwowałaby bliskich. Wkrótce jednak tendencja do unikania staje się o wiele silniejsza niż tendencja do dążenia i decydują się odwołać ślub. Decyzja ta powoduje jednak, iż wracają oni do punktu wyjścia: dzień ślubu jest znów odległy i tendencja do dążenia staje się silniejsza niż tendencja do unikania. Dlatego tez znowu zmieniają swe zamiary. Z zasad sformułowanych przez Millera wynikałoby, że narzeczeni tacy mogliby się wahać bez końca, jeśli ich przyszli małżonkowie nie zdecydowaliby, że mają już dość i nie zerwaliby z nimi.
Drugi wykres pokazuje, co może zachodzić w wypadku narzeczonych, którzy mają wątpliwości wzrastające w miarę zbliżania się dnia ślubu, lecz mimo wszystko nie cofają się i zawierają związek małżeński. Oni również od początku mają obawy, lecz także od początku silniej pragną zawarcia małżeństwa. Chociaż więc siła obu tych tendencji wzrasta, a gradient unikania wzrasta szybciej, to jednak w ich wypadku gradient dążenia przebiega wyżej od gradientu unikania, aż do momentu zaślubin - a wiec ślub dochodzi do skutku.
Źródło: Neal E. Miller „Experimental Studies of Conflict” in J. McV. Hunt (ed.). „Personality and the Behavior Disordes”, Copyright 1944 renewed © 1972, The Ronald Press Company, New York.


* * *





Po pierwsze, za ważne ograniczenie ich teorii uczeni ci uznają fakt, iż Dollard i Miller przy tworzeniu teorii, która zgodnie z ich oczekiwaniami miała stosować się do ludzi, oparli się tak mocno na wynikach badań nad |zwierzętami. Po drugie, uważają oni za niezbędne badanie zachowania ludzkiego w środowisku |społecznym, a nie w odosobnieniu (na przykład badania nad ludźmi siedzącymi osobno i uczącymi się list nonsensownych sylab eliminują wiele procesów interpersonalnych, które są najbardziej charakterystyczne dla ludzi).
Teoria uczenia się społecznego („social learning theory”) nie rozpatruje ludzi jako istot miotanych wewnętrznymi siłami ani też jako bezradnych pionków poruszanych przez wpływy środowiskowe. Stwierdza ona, że „funkcjonowanie psychiczne najlepiej można zrozumieć w kategoriach ciągłej wzajemnej interakcji pomiędzy zachowaniem i oddziaływującymi nań warunkami” (Bandura, 1971). Specyficzne właściwości każdej jednostki są zdeterminowane przez takie czynniki, jak bodźce społeczne, społeczne i osobiste wzmocnienia, historia uczenia się itd.




Zbliżenie


Nerwowa Nellie, czy zaangażowana, krytyczna osoba? Dwa spojrzenia na to 
samo zachowanie


„Komisja egzaminacyjna ocenia właśnie kandydatów do szkoły medycznej. W trakcie takiej rozmowy jedna z kandydatek, Nellie, przedstawia członkom komisji swoje przekonanie, że poddają oni studentów niepotrzebnemu stresowi, że przyczyniają się do nadmiernej rywalizacji o stopnie i do braku zainteresowania wiedzą wśród studentów oraz że nie znają obecnych realiów studenckiego życia ani nie troszczą się o to. Mówi szybko i głośno, jąka się, przejawia emocje i nieufność oraz nie patrzy w oczy żadnemu z członków komisji.
Jak zachowanie to mógłby ocenić członek komisji reprezentujący tradycyjne podejście psychodynamiczne i rozpatrujący osobowość w kategoriach cech, w porównaniu z członkiem komisji o orientacji społeczno-behawiorystycznej?
|Analityk
Studentka ta jest pełna wrogości i urazy; ma zarówno niską samoocenę, jak i małą siłę ego; potrzebuje uczucia i oparcia, lecz nie potrafi poprosić o nie z obawy przed odrzuceniem; ma tendencję do niezależnego myślenia połączoną z silną potrzebą doznawania aprobaty społecznej; jest na ogół porządna, czysta, skąpa i łatwo ją sprowokować do agresywności.
Źródłem problemów tej kandydatki jest „oczywiście” ambiwalentny stosunek do rodziców (miłość-nienawiść), będący następstwem jej doświadczeń związanych z surowym treningiem czystości. Występujący u niej zespół „analno-kompulsywny” (porządek, czystość i skąpstwo) doprowadził do nadmiernego polegania raczej na myślach i słowach niż na uczynkach, do lęku przed jakimkolwiek wyrażeniem swej wrogości oraz do jąkania się wskutek tłumionego gniewu. Wszystkie obserwowane u niej zachowania są jedynie „zasłoną dymną” skrywającą jej prawdziwy, głęboko ukryty problem.
„Zalecenie”: Kandydatka przejawia brak dojrzałości emocjonalnej oraz niezdolność do uporania się z problemami osobistymi; przyjęcie jej do szkoły medycznej byłoby niewątpliwie ryzykowne (prawdopodobnie byłyby z nią kłopoty).
|Behawioralna
Członkowie komisji częściej przerywają i słuchają mniej uważnie, gdy kandydatka mówi powoli i spokojnie. Słuchają oni bardziej uważnie, gdy mówi ona szybko i głośno, a zatem wzmacniają takie jej zachowanie. Łatwo zauważyć, że są oni niezadowoleni z tego, co mówi kandydatka: ta postawa wywołuje u niej z kolei negatywny afekt. Zmieniając swój zwykły sposób mówienia, kandydatka zakłóca schemat sprzężenia zwrotnego, do którego przywykła, i zaczyna się jąkać. Wzmaga to jej lęk, ponieważ wie, że między innymi ocenia się jej zrównoważenie. Stara się zapanować nad sobą i uniknąć negatywnych reakcji członków komisji, nie patrząc im prosto w oczy. Nie przestaje mówić, ponieważ czynność ta wzmacnia jej wyobrażenie o sobie samej jako o kimś zajętym sensowną aktywnością społeczną. Spodziewa się ona, że kiedy przerwie, może to oznaczać koniec rozmowy - a także odrzucenie jej kandydatury.
„Zalecenie”: Komisja powinna zbadać słuszność twierdzeń przedstawionych przez kandydatkę zwrócić uwagę na swoją własną negatywną reakcję na krytykę, a także uwzględnić niezależność działania i dojrzałość myślenia wykazaną przez kandydatkę.


W przeciwieństwie do innych teorii uczenia się, ta teoria kładzie nacisk na specyficzne dla ludzi procesy poznawcze, które są istotne dla nabywania i utrzymywania różnych form zachowania. Teoria ta wskazuje, że ludzie mogą uczyć się nie tylko przez bezpośrednie doświadczenia, lecz także w sposób |zastępczy - przez obserwację innych ludzi. Ponadto ludzie potrafią „przedstawić” sobie zdarzenia zewnętrzne za pomocą |symboli, co pozwala im przewidywać możliwe konsekwencje działań, bez konieczności rzeczywistego odczucia ich „na własnej skórze”. Ponadto ludzie są zdolni do |procesów |samoregulacyjnych, za pomocą których oceniają swe własne zachowanie (stosownie do osobistych norm) i dostarczają sobie własnych wzmocnień (na przykład samoaprobaty lub samopotępienia). Te zdolności autoregulacji pozwalają ludziom kierować swymi własnymi działaniami i nie poddawać się wpływowi sił zewnętrznych.
Czołowym przedstawicielem tego sposobu ujęcia osobowości jest Albert Bandura. Przyczynił sie on do rozwoju tej teorii przede wszystkim dzięki swym pracom nad |uczeniem |się |przez |obserwację („observational learning”). Stosownie do wyników tych badań, znaczna część naszego zachowania została wyuczona lub zmodyfikowana w wyniku obserwowania |modeli przejawiających te zachowania. Modelami tymi mogą być rodzice, nauczyciele, rówieśnicy, aktorzy telewizyjni, postacie z komiksów itd. Wpływ modelowania jest zdeterminowany przez cztery powiązane przez cztery powiązane ze sobą wzajemnie procesy:
1. |Proces |uwagi. Ludzie będą się uczyć od modelu tylko wtedy, jeśli zwracają uwagę na istotne elementy zachowania tego modelu i rozpoznają je.  Większe prawdopodobieństwo wywarcia wpływu na obserwatora występuje w wypadku tych modeli, które są atrakcyjne lub spostrzegane jako podobne do obserwatora, a także w wypadku tych modeli, z którymi styka się on wielokrotnie lub które demonstrują ważne, funkcjonalne zachowania. Niektóre modele (np. oglądane w telewizji) tak skutecznie przyciągają uwagę, że widzowie będą uczyć się modelowanych czynności nawet przy braku specjalnych podniet, które by ich do tego skłaniały.
2. |Procesy |przechowania |w |pamięci. Wpływ danego modelu jest uzależniony od zdolności danej osoby do pamiętanego zachowania modelu nawet wówczas, gdy model ten zniknął już ze sceny. Dwa procesy, które pomagają w lepszym przechowaniu, to kodowanie symboliczne oraz powtarzanie w myśli modelowanych zachowań.
3. |Procesy |odtwarzania |motorycznego. Nawet jeśli ludzie uczą się nowych zachowań przez obserwowanie modelu, to nie mogą oni wykazać znajomości tych zachowań, o ile nie potrafią wykonać modelowanych czynności. 
4. |Wzmocnienie |i |procesy |motywacyjne. Wykonywanie wyuczonego zachowania zależy także od tego, czy będzie ono nagradzane, czy karane.  Jeśli występują pozytywne podniety, to modelowanemu zachowaniu będzie się poświęcać więcej uwagi, zostanie ono lepiej wyuczone i będzie częściej wykonywane.



Ponadto Bandura stwierdził, że modelowanie może mieć także inne konsekwencje niż po prostu wyuczenie się specyficznego zachowania. Wykazał on na przykład, że zachodzi także „modelowanie zasad”, w czasie którego dzieci uczą się kierować swym zachowaniem za pomocą tych samych podstawowych zasad, którymi kierowały się obserwowane przez nich modele, nawet wówczas, gdy mają one do czynienia z sytuacją całkowicie odmienną od tych, w których obserwowały modele. Modelowanie może także spowodować |rozhamowanie reakcji, które poprzednio nauczono się hamować. Na przykład, jeśli dobrze ubrana osoba (atrakcyjny model) przechodzi przez ulicę przy czerwonym świetle, to inne osoby, które czekały na zielone światło, mogą naśladować jej działanie.


Krytyka teorii uczenia się. Reasumując, zwolennicy teorii uczenia się uważają stałość ludzkiego zachowania za rezultat uczenia się nawyków.  Najsilniejszą stroną ich sposobu podejścia do tematu jest formułowanie hipotez i wniosków w formie nadającej się do weryfikacji eksperymentalnej.  Prace ich dały zatem początek wielu interesującym badaniom, a także doprowadziły do opracowania szeregu skutecznych procedur terapeutycznych. W głównym zarzucie wysuwanym pod adresem tych teorii podkreśla się jednak, że są one zbyt atomistyczne i „środowiskowe”: niewiele mówią one o mechanizmach, które wiązałyby między sobą poszczególne zachowania i nadawały im zgodny kierunek, a ponadto wyłączają z badań większość zachowań, których nie można uważać za wyuczone.




Geneza i rodzaje
różnic indywidualnych




„Nigdy, od stworzenia świata, nie było dwóch przypadków zupełnie 
analogicznych”.
Lord Chersterfield „Letters to his son”, 1748
(wyd. pol. „Sztuka szczęśliwego życia w społeczności”)


Gdy obserwujemy ludzi i ich zachowanie w sposób dorywczy, niesystematyczny, wówczas uderza nas niezwykłe podobieństwo między nimi. Im jednak dokładniej się przypatrujemy i im bardziej subtelnie nastawiamy nasz analityczny aparat, tym lepiej uświadamiamy sobie różnice i nieciągłości.  Podobnie, jeśli położymy obok siebie swoje ręce, dłońmi ku górze, to zauważymy, że każdy palec lewej ręki jest identyczny z odpowiadającym mu palcem prawej ręki. Jeśli jednak przyjrzymy się bliżej swoim palcom, to dostrzeżemy, jak różnią sie linie papilarne na każdym z nich. Podobnie, jak nie zanotowano przypadków dwóch identycznych odcisków palców, tak samo nie ma dwóch ludzi, nawet wśród „identycznych” bliźniąt, którzy by nie byli różni pod wieloma względami.
Chociaż celem badań naukowych jest wykrywanie ogólnych prawd oraz regularnych prawidłowości, to jednak badania te są motywowane przez istnienie zróżnicowania, ekscentryczności oraz przypadków, które nie chcą dostosować się do oczekiwań. Gdyby ludzie byli identyczni, wówczas można by zrezygnować zupełnie z psychologii na rzecz fizyki i biologii organizmów ludzkich. Jednakże nie są oni identyczni i zadaniem psychologii jest dążenie do wykrycia źródeł tej tajemnicy: jakie są przyczyny tego, że różni ludzie w tej samej sytuacji niekiedy zachowują się zupełnie odmiennie?
Jeśli chodzi o nas samych, to rzadko zastanawiamy się, dlaczego postąpiliśmy tak a nie inaczej, jeśli wszyscy inni ludzie postępują tak samo. Tylko wtedy, jeśli zachowujemy się inaczej niż inni, lub kiedy ktoś inny zachowuje się odmiennie od reszty ludzi, zatrzymujemy się na chwilę, by zastanowić się, dlaczego tak się dzieje. W takiej właśnie chwili rozpoczęły się badania nad różnicami indywidualnymi i osobowością.




Różne sposoby podejścia
do badania różnic
indywidualnych




Jak wskazywaliśmy na początku niniejszego rozdziału, jednym z kluczowych problemów dla teoretyka osobowości jest formułowanie praw zachowania, które mogłyby wyjaśnić jego specyficzność. Niektórym wydaje się to wewnętrzną sprzecznością. Jak może istnieć nauka o jedynych w swym rodzaju, specyficznych przypadkach?
Jak już mówiliśmy, psychologowie skłonni są przyjmować jeden z dwóch sposobów podejścia w swych próbach „pogodzenia ze sobą tego, co niemożliwe do pogodzenia”. Podejście |nomotetyczne zakłada, że wszystkie istoty ludzkie, chociaż tak różne, różnią się po prostu pod względem stopnia, w jakim posiadają te same właściwości. Podejście to jest charakterystyczne dla teorii cech oraz wszelkich prób przewidywania zachowania na podstawie standaryzowanych skal lub testów. Podejście |idiograficzne, zakłada, że człowiek jest czymś więcej niż sumą pewnych właściwości i że przewidywania oparte na wartościach przeciętnych mają ograniczoną przydatność, gdy chcemy zrozumieć poszczególne jednostki lub im pomóc. Podobnie jak w przypadku każdej „całości”, pewne cechy osób występują jedynie wtedy, gdy funkcjonuje ona właśnie jako całość - są to cechy, których obecności nigdy nie wykażą poszczególne pomiary mające ustalić, w jak dużym stopniu lub w jak małym stopniu dana osoba posiada pewną, wyodrębnioną właściwość. Podejście to jest charakterystyczne dla prac większości klinicystów.
Podobny nieco spór w dziedzinie badań nad osobowością dotyczy względnej dokładności subiektywnych, klinicznych ocen w porównaniu z ocenami opartymi na testach obiektywnych i procedurach statystycznych. W latach pięćdziesiątych zagadnienie to sformułowano w kategoriach |predyktywnej |wartości ocen klinicznych w porównaniu z ocenami statystycznymi (Meehl, 1954).
Przewidywanie statystyczne opiera się na prostym stosowaniu jakiegoś równania lub tablicy statystycznej do zbioru danych. Takie przewidywanie może być dokonywane przez każdego, kto wie, jak odczytywać tablice lub stosować dany wzór. Przewidywanie kliniczne opiera się na umiejętnościach indywidualnego klinicysty, który na podstawie obserwacji, wywiadów, testów projekcyjnych, swego wykształcenia i doświadczeń dokonuje przewidywań dotyczących przyszłego zachowania danej jednostki.
Jak dotąd, badania nad względną efektywnością tych dwóch sposobów wypadały na korzyść podejścia statystycznego (Meehl, 1965; Sawyer, 1966).  Niektórzy krytycy twierdzą jednak, że w badaniach, na podstawie których wysunięto te wnioski, przeciwstawiano procedurom statystycznym |naiwne, nie zaś |wyrafinowane oceny kliniczne (Holt, 1971). W tej sytuacji pytanie, czy przewidywanie statystyczne jest lepsze od wyrafinowanego przewidywania klinicznego, pozostaje otwarte do czasu przeprowadzenia dalszych badań - lecz obowiązek przeprowadzenia dowodu spoczywa obecnie na klinicystach.




Jaźń i tożsamość




„Gdy mówię „ja”, to myślę absolutnie jedynym w swoim rodzaju, czego nie można pomylić z niczym innym”.
Ugo Betti „The Inquiry”, 1944


Co masz na myśli, gdy mówisz „ja”? Weź kartkę papieru i ponumeruj kolejne wiersze od jednego do dwudziestego. W każdym wierszu napisz jakieś stwierdzenie zaczynające się od słowa „Jestem...” Gdy skończysz listę, wówczas poklasyfikuj swoje odpowiedzi według podanych niżej czterech kategorii (Kuhn i McParthland, 1954).


„Postaw literę |A po stwierdzeniach, które odnoszą się do twego „ja” jako istoty fizycznej (wielkość, waga, barwa, płeć).
Postaw literę |B po stwierdzeniach, które odnoszą się do twego „ja” w rolach instytucjonalnych (student, obywatel, gracz w piłkę nożną, wodzirej).
Postaw literę |C po stwierdzeniach, które odnoszą się do twego „ja” działającego lub odczuwającego w charakterystyczny sposób w interakcjach społecznych (szczęśliwy, lękliwy, religijny, nieśmiały).
Postaw literę |D po stwierdzeniach, które ujmują twoje „ja” w oderwaniu od interakcji z innymi, od specyficznego kontekstu czy struktury społecznej. Takimi ogólnymi, nieróżnicującymi stwierdzeniami byłyby na przykład następujące określenia: „Jestem człowiekiem”, „Jestem sobą”, „Jestem zjednoczony z kosmosem” itd.


Policz, jaka część twych twierdzeń o sobie samym należy do każdej z tych kategorii i zorientuj się, jakiego rodzaju osobę one określają. Porównaj to swoje „ja” z „ja” jakiegoś kolegi oraz z „ja” kogoś starszego od ciebie.  Istnieją dane przemawiające za tym, że w poprzednich pokoleniach dominowała kategoria |B, w przypadku zaś dzisiejszych studentów bardziej prawdopodobne jest, że większość stwierdzeń będzie należała do kategorii |C (Zurcher, 1972). Twierdzenia typu |B odzwierciedlają jaźń, która czerpie swą tożsamość ze struktury społecznej, podczas gdy pojęcie o sobie typu |C jest charakterystyczne dla nie ustalonej tożsamości, lecz dla procesów „ja” opartych na bieżących doznaniach. Louis Zurcher określił typ |C jako |jaźń |zmienną, jaźń która przystosowuje się do szybkich zmian społecznych przez gotowość do pozostawania plastyczną i aktywnie zmieniającą się, a nie zakotwiczoną w ugruntowanej sytuacyjnie tożsamości, gdy struktura społeczna nie jest stabilna. Jest zupełnie możliwe, że kategoria |D, która pojawiała się stosunkowo rzadko w ubiegłych latach, stanie się w końcu dominującym typem pojęcie o sobie, jeśli tempo zmian społecznych nadal będzie wykazywać tak oszałamiające przyspieszenie. Jaźń typu |D jest jaźnią oderwaną od istoty fizycznej, od struktury społecznej i interakcji ze środowiskiem - jest to jaźń niezależna - jaźń „unosząca się swobodnie” („free-floating self”), zakotwiczona jedynie w abstrakcjach.


Pojęcie o sobie. Większość teoretyków, którzy zajmują się rozwojem pojęcia o sobie („self-concepcion”), na ogół zgadza się, że ten najbardziej osobisty aspekt natury ludzkiej jest wytworem naszej społecznej interakcji z innymi. Charles Cooley w 1902 roku wprowadził pojecie „jaźni odzwierciedlonej” („looking-glass self”), która wytwarza sie jako odbicie ocen, jakie naszym zdaniem inni nam „wystawiają”. George Herbert Mead rozwinął koncepcję, zgodnie z którą w pojęciu o sobie odzwierciedlamy poglądy innych ludzi, twierdząc, że jaźń rozwija się w wyniku adaptowania jako własnych, nastawień, jakie inni mają wobec nas. Z czasem zaczynamy myśleć o sobie w sposób zgodny z tym, w jaki inni ludzie zachowują się wobec nas.




Zbliżenie


„Chciałem, żeby mnie po prostu zauważono”


„Postępuj wobec innych tak, jak chciałbyś, aby oni postępowali wobec ciebie” - jest to, oczywiście, Złota Reguła dobrych stosunków społecznych, lecz co zrobić, jeśli inni nie dbają o ciebie na tyle, aby zauważyć twoje istnienie? Dla wielu młodych ludzi stosunki społeczne są przykrymi zdarzeniami niosącymi niepewność. Zamieszczone poniżej wymowne błaganie o zrozumienie i uznanie społeczne pochodzi od pewnego młodego człowieka, który odsiedział wyrok 4 lat więzienia za posiadanie marihuany.
„Muszę nauczyć się, jak się porozumiewać. Muszę wiedzieć, jak poznawać potrzeby innych ludzi. Chcę, żebyś mnie tego nauczył (...). Muszę wiedzieć, jak wyrażać moje uczucia tak, żeby nikt nie rozumiał ich źle. Boję się wyrazić mój gniew i urazę, ponieważ boję się, że ktoś mnie źle zrozumie (...). Muszę palić długą fajkę, nosić długie włosy, woskuję i układam sobie staranie wąsy, oraz noszę różne ubiory po to, aby przyciągnąć uwagę ludzi.  Lecz obawiam się, że może już odstraszyłem niektórych z was. Nie chciałem was odstraszać, po prostu chciałem, aby mnie zauważono, ponieważ jestem samotny. Chcę czuć się swobodnie. Chciałbym nie wymachiwać przed tobą rękami, lecz obawiam się, że mógłbyś mnie nie zauważyć. Muszę to robić po to, aby czuć się swobodnym, aby upewnić się, że wokół mnie nie ma już celi więziennej, że mam do swej dyspozycji więcej przestrzeni niż ty. Muszę przypominać sobie, że już nie jestem w więzieniu, ponieważ w więzieniu byłem bardzo samotny. Ciągle jestem bardzo samotny. Chce mi się płakać.  Obawiam się płakać, ponieważ boję się tego, co ktoś mógłby o mnie pomyśleć.  Boję się, że ktoś mógłby pomyśleć, że nie jestem istotą ludzką. Boję się, że ktoś mógłby nazwać mnie „maminsynkiem”. Boję się, że ktoś mógłby po prostu nie zrozumieć mnie. Boję się, że ktoś mógłby nie objąć mnie, czy po prostu nie wziąć mnie za rękę, czy nawet po prostu nie dotknąć mnie. Boję się dotykać innych ludzi, ponieważ obawiam się ludzi. Chcę, żeby mnie dotykano. Chcę czuć ciepło kogoś innego. Chcę czuć więcej aniżeli tylko ciepło pojedynczej, innej osoby. Pragnę przyjaciół (...). I teraz ty wiesz o moim gniewie, i jestem szczęśliwszy niż byłem przedtem, zanim wygłosiłem do ciebie tę mowę. Tego jednak było |strasznie |mało!!!” (Robert C. Olcott, 1973). 


Według Williama Jamesa, ta |jaźń |społeczna jest zaledwie jedenym z trzech komponentów jaźni - przy czym pozostałe dwa komponenty to |jaźń |materialna i |jaźń |duchowa („spiritual self”). Ta społeczna część naszego pojęcia o sobie nie jest jakimś jednolitym bytem; nosimy ze sobą tyle jaźni społecznych, ilu jest ludzi, którzy nas znają i mają o nas pewne wyobrażenie. Możemy więc cierpieć pewien „niedostatek jaźni” wskutek tego, że inni nas nie zauważają lub wskutek uświadomienia sobie, że wyobrażenie innych o nas jest nieprzyjemne, negatywne. Odczuł to przykro jeden z naszych studentów, kiedy matka powiedziała mu, że uważa go za |nudziarza, podczas gdy on zawsze sądził, że akceptuje go ona i ocenia jako „poważnego” i „wytrwałego”. Brak jaźni społecznej wynikający z faktu, że jest się „nie zauważanym” przedstawił wymownie Ralph Ellison (1952) opisując, jak czuje sie czarny człowiek w społeczeństwie białych.


„Jestem człowiekiem niewidzialnym. Nie, ja nie jestem duchem w rodzaju tych, które nawiedzały Edgara Allana Poego; ani też nie jestem jakąś ektoplazmą z waszych hollywoodzkich filmów. Jestem człowiekiem materialnym, z krwi i kości - i można by nawet powiedzieć, że posiadam rozum. Jestem niewidzialny, zrozumcie, po prostu dlatego, że ludzie nie chcą mnie dostrzec. Dzieje się coś podobnego, jak z głowami bez ciała, które widzicie czasami w widowiskach cyrkowych; wydaje mi się, jak gdybym był otoczony zwierciadłami, z twardego, zniekształcającego szkła. Gdy ludzie zbliżają sie do mnie, to widzą tylko moje otoczenie, siebie samych lub wytwory własnej wyobraźni - słowem wszystko prócz mnie” (s. 3).


Oprócz jaźni wywodzącej się z ocen innych ludzi, nasze pojęcie o sobie bierze się z tego, że określamy w kategoriach cech te zachowania, które, jak obserwujemy, występują u nas samych często lub z dużym nasileniem.  Formułujemy także ocenę o sobie samych dzięki procesom społecznego porównywania (które zostaną omówione w Rozdziale 13). Oceniamy jakość naszych idei, poprawność naszych opinii, stosowność naszych emocji, a także wielkość naszych zdolności, porównując je z zachowaniem innych. Na koniec można wykazać, że gdy tylko wytworzyliśmy takie czy inne pojęcia o sobie, to |zniekształcamy informację napływające zarówno z naszego środowiska, jak i z naszej pamięci, w taki sposób, aby były one zgodne z tym obrazem. Gdy więc myślimy dobrze o sobie i mamy pozytywną samoocenę, wówczas negatywne „sprzężenie zwrotne” traktuje się jako wyjątek od reguły. Z drugiej strony, jeśli wytworzyliśmy niską samoocenę, to pozytywne „sprzężenie zwrotne” zmieniają ją w niewielkim stopniu, ponieważ również uważa się je za niekonsekwentny wyjątek, podczas gdy każde niepowodzenie czy przykre doświadczenie akceptuje się łatwo jako „oczekiwany” materiał dowodowy.
Nasze pojęcie o sobie wpływa nie tylko na nasze stosunki z innymi ludźmi, lecz także na nasze poczucie niezależności (osoby o niskiej samoocenie są na ogół bardziej konformistyczne niż osoby o wysokiej samoocenie), na cele, do których aspirujemy i - co być może jeszcze najważniejsze - na jakość naszego osobistego życia emocjonalnego.
Kryzysy tożsamości. Powyższe krótkie omówienie powinno pomóc w rozumieniu, dlaczego okres dojrzewania jest w życiu człowieka okresem wypełnionym |kryzysami |tożsamości. Jest to czas przejściowy, w którym jaźń dziecięca przestaje pasować do nowego ciała, pojawiających się pragnień seksualnych, zmniejszonej zależności od rodziców, odchodzenia od domu rodzinnego, związków z przyjaciółmi, kontaktów z nowymi ideami i doświadczeniami. Dorastający chłopak czy dziewczyna są nieustannie zmuszani do odrzucania starych etykietek i wygodnych pojęć o sobie, które przestały już być dla nich odpowiednie, zanim jeszcze znaleźli dogodne ich substytuty. Potrzeba pojęciowego zorganizowania doświadczeń w stałe kategorie, tak aby zredukować lęk wytwarzany przez niepewność, jest według Kennetha Gergena (1971) siłą napędową w tym okresie „tożsamości w chaosie”. Ostatnio staje się oczywiste, że drugi kryzys tożsamości rozwija się u mężczyzn i kobiet w wieku średnim. Po przeżyciu swego życia, zgodnie z akceptowaną społecznie receptą, wielu z tych czterdziesto- czy pięćdziesięciolatków zdaje sobie sprawę, że nie byli oni uczciwi wobec siebie samych. Po zastanowieniu się, czego chcą od pozostałych im lat życia, coraz więcej z tych ludzi porzuca swą bezmyślną pracę od dziewiątej do piątej, strzyżenie trawników, odkurzanie mebli, spotykanie się z „tymi, jak im tam” itd. Jest jeszcze zbyt wcześnie, aby ocenić, czy to stadium kryzysowe „obywateli w wieku przedemerytalnym” doprowadzi do chaosu społecznego, czy też do spokojnego przezwyciężenia tradycyjnych, ograniczających pojęć o tożsamości.


Poziomy I Stadia Rozwoju Ocen Moralnych Wg Kohlberga


Poziom - Podstawowa ocen moralnych - Stadia rozwoju


I. Wartość moralna związana jest z zewnętrznymi, quasi-fizycznymi zdarzeniami, złymi uczynkami lub quasi-fizycznymi potrzebami, a nie osobami ani standardami.

Stadium 1: Orientacja na posłuszeństwo i karę. Egocentryczna uległość wobec większej siły lub prestiżu, czyli nastawienie na unikanie kłopotów. 
Obiektywna odpowiedzialność
Stadium 2: Orientacja naiwnie egoistyczna. Właściwym działaniem jest takie, które instrumentalnie zaspokaja potrzeby własne i niekiedy innych ludzi. Świadomość relatywizmu wartości w zależności od potrzeb i punktu widzenia każdej z osób działających. Naiwny egalitaryzm oraz nastawienie na wymianę i wzajemność świadczeń.


II. Wartość moralna związana jest z wypełnianiem dobrych lub właściwych ról, podtrzymywaniem konwencjonalnego porządku oraz spełnianiem oczekiwań innych osób. 

Stadium 3: Orientacja „dobrego chłopca”. Nastawienie na uzyskanie aprobaty innych ludzi, podobanie się innym i pomaganie im. Stosowanie się do stereotypowych wyobrażeń o większości, czyli „naturalnego” zachowania w danej roli; ocena według intencji.
Stadium 4: Orientacja na utrzymywanie porządku społecznego oparta na poszanowaniu autorytetów. Nastawienie na „spełnianie obowiązków”, okazywanie szacunku autorytetom, utrzymywanie istniejącego porządku społecznego dla niego samego. Liczenie się z uzasadnionym oczekiwaniem ludzi.


III. (1) Wartość molarna związana jest ze stosowaniem się do wspólnych (lub mogących być wspólnymi) standardów, praw czy obowiązków. 

Stadium 5: Orientacja legalistyczna, oparta na „umowie społecznej”.  Uznawanie, że w regułach i standardach, umożliwiających osiągnięcie porozumienia, występuje pewien element dowolności. Obowiązek definiuje się w kategoriach umowy, unikając pogwałcenia woli lub praw innych osób, oraz w kategoriach woli i dobra większości.
Stadium 6: Orientacja na zasady i sumienie. Nastawienie nie tylko na rzeczywiście obowiązujące reguły społeczne, lecz na zasady wyboru odwołujące się do logicznej uniwersalności i spójności. Orientacja, w której główną rolę odgrywa sumienie (jako czynnik ukierunkowujący) oraz wzajemny szacunek i zaufanie.


Przypis 1. W swych późniejszych pracach (np. „Moral Stages and Moralization”. „The Cognitive Developmental Approach”. W: T. Lickona (ed.) „Moral Development and Behaviour”, 1976) Kohlberg uznał za konieczne wprowadzenie stadium przejściowego 485, które zaliczył do trzeciego, postkonkwencjonalnego poziomu, aczkolwiek oceny moralne nie są w nim jeszcze oparte na uniwersalnych wartościach i zasadach (jak w stadiach 5 i 6). W stadium tym, które stwierdzano często u studentów college’ów, jednostka „wyzwolona” z moralności konwencjonalnej (i często odrzucająca obowiązujące formy życia społecznego) stoi niejako „poza społeczeństwem”, kierując się w swych ocenach moralnych subiektywnymi, dowolnie wybranymi wartościami moralnymi. Jednostka taka przyjmuje, że człowiek ma obowiązek postępować zgodnie ze swym sumieniem, lecz jej wybory często oparte są raczej na emocjach, gdyż „sumienie” jest traktowane jako coś względnego i dowolnego; uznaje, że każdy ma prawo swobodnego wyboru, o ile nie narusza podobnych praw innych ludzi. Ze stadium tego - według Kohlberga - jednostka przechodzi w końcu do stadium piątego (przyp. tłum.)
(Źródło: Kohlberg, 1967, s. 171)




Czynniki rozwojowe




Nie powinno nas dziwić, że wielu teoretyków osobowości kładzie taki nacisk na wczesne doświadczenia, skoro czynniki rozwojowe wpływają na to, w jaki sposób poszczególne jednostki różnią się od siebie. Omówimy tu pokrótce dwa takie czynniki: rozwój moralny i różnice związane z płcią.


Rozwój moralny. To, co zrobimy lub czego nie zrobimy w danej sytuacji może zależeć od tego, co |możemy zrobić, ile od tego, co naszym zdaniem |powinniśmy zrobić. Zagadnienia „powinności” obejmują także oceny moralne, na podstawie których podejmuje się pewne działania lub ogranicza się je.
Funkcjonowanie osobowości w znacznym stopniu jest uzależnione od wpływu poziomu rozwoju moralnego, który osiągnęła dana jednostka.
Lawrence Kohlberg (1967, 1969a, 1968b) opracował test konfliktów moralnych pozwalający określić, w którym z sześciu stadiów rozwoju moralnego znajduje się określony człowiek. Dziecko przechodzi przez te stadia w niezmienionej kolejności, od pierwszego do szóstego, aczkolwiek tempo przechodzenia do konwencjonalnego i postkonwencjonalnego („zasadniczego” - „principled”) poziomu moralności może być różne u różnych dzieci, a niektóre z nich mogą nigdy nie osiągnąć najwyższych poziomów rozwoju moralnego. Struktura tej analizy pozostaje pod wyraźnym wpływem stworzonego przez Piageta modelu rozwoju poznawczego (zob. Rozdział 5).
Rozwój moralny w wieku dojrzałym charakteryzuje się zwykle: porzuceniem dziecięcych sposobów myślenia (w większym stopniu niż ukształtowaniem myślenia na wyższym poziomie), ustabilizowaniem się czwartego stadium moralności konwencjonalnej, większą zgodnością między oceną moralną a działaniem moralnym, zintegrowanym posługiwaniem się strukturami moralnymi oraz zastosowaniem refleksji moralnej do własnego życia.


Różnice związane z płcią. Fakt urodzenia się mężczyzną lub kobietą stanowi główne źródło różnic indywidualnych w odniesieniu do mnóstwa właściwości, cech i zachowań. Niektóre z tych różnic wiążą się z anatomią i strukturą fizyczno-biologiczną. Inne kształtują się pod wpływem odmiennych sposobów, w jakie dzieci każdej płci są socjalizowane i „programowane” przez swą społeczność. W tabeli (powyżej) przedstawiono zestawienie niektórych ważnych różnic związanych z płcią (pełniejszy opis można znaleźć w następujących pracach: Maccoby i Jacklin, 1974; Watson i Johnson, 1972). W Rozdziale 13 i zamieszczonym po niniejszym rozdziale eseju Sandry Bem omówimy dokładniej sposób, w jaki różnice związane z rolą seksualną prowadzą do stereotypów.




Niektóre zmienne
osobowościowe
i typy osobowości




Spośród wielu zmiennych osobowościowych i typów charakteru, które były przedmiotem badań, wybraliśmy cztery, które naszym zdaniem mogą być szczególnie interesujące.




Wewnętrzne czy zewnętrzne
umiejscowienie kontroli




W jakim stopniu jesteś przekonany, że to, co ci się zdarza, to, jaka 
będzie przyszłość, jest zdeterminowane przez siły |zewnętrzne w stosunku do 
ciebie - los, przypadek, inne osoby obdarzone władzą, nieprzewidywalne 
wydarzenia na świecie - a w jakiej mierze, twoim zdaniem, ten determinujący 
wpływ ma charakter |wewnętrzny, to znaczy jest zależny od ciebie? Ludzie 
różnią się pod względem tych przekonań, co prowadzi do przyjęcia przez nich 
odmiennych poglądów na temat umiejscowienia ośrodka kontroli zachowania. To 
rozróżnienie dotyczące „wewnętrzności-zewnętrzności” spotyka się w wielu 
teoriach osobowości
(Collins i in., 1973).
W swym klasycznym dziele „The Lonley Crowd (Samotny tłum) socjolog David Riesman i jego współpracownicy (1950) wyróżnili dwa typy charakteru ludzi żyjących we współczesnym społeczeństwie, którzy różnią się tym, że albo są kierowane z wewnątrz albo też przez otoczenie, Osoba |wewnętrznie |kierowana („inner-directed”) jest stereowana przez wartości i cele zaszczepione jej we wczesnym okresie życia przez „starszych” społeczeństwa.  Natomiast jednostki |kierowane |zewnętrznie, to znaczy przez inne osoby („other-directed”) uważa się za bardziej wrażliwe na wpływ społeczny ze strony ich rówieśników.
Przekonaliśmy się, że według poglądów takich humanistów, jak Abraham Maslow, idealnym charakterem jest charakter osoby, która osiągnęła |samorealizację, która jest niezależna zarówno od zewnętrznych ograniczeń jak nakładanych przez grupę rówieśników, jak też od ograniczeń wewnętrznych nałożonych przez proces socjalizacji. Ta samorealizacja pozwala na większą autonomię i rozwijanie twórczości dzięki wyzwoleniu się z zależności od innych ludzi, a także odrzuceniu ograniczeń nakładanych przez wcześniejsze zasady życiowe.
Wymiar |introwersji - |ekstrawersji, który określa się za pomocą „Eysenck Personality Inventor” (Inwentarz Osobowości Eysencka; Eysensck i Eysenck, 1968), ujawnia różnice indywidualne pod względem stopnia, w jakim ludzie potrzebują innych osób jako źródła nagród i jako „nauczycieli” właściwego zachowania. Wylewny, impulsywny ekstrawertyk potrzebuje ludzi, aby wchodzić z nimi w interakcję, podczas gdy pełen rezerwy, ostrożny introwertyk w mniejszym stopniu korzysta ze stymulacji dostarczanej przez innych ludzi, a w większym stopniu polega na książkach czy też źródłach o charakterze niespołecznym.
Temu rozróżnieniu osobowości „wewnętrznej - zewnętrznej” poświęcono wiele uwagi w związku z pracami Rottera (1954, 1966) oraz Lefcourta (1966, 1972), którzy wyróżnili rozmaite typy zgeneralizowanych oczekiwań czy też przekonań dotyczących |wewnętrznej |bądź |zewnętrznej |kontroli |wzmocnień.  Ludzie „wewnętrzni” spostrzegają, że nagroda jest uzależniona od ich własnego zachowania i (lub) ich osobistych przymiotów. Ludzie „zewnętrzni” spostrzegają, że nagrody pojawiają się niezależnie od ich działań i są pod kontrolą sił zewnętrznych.
Podczas gdy inne koncepcje „wewnętrznych”, bądź „zewnętrznych” typów osobowości kładą nacisk na |genezę celów, wartości i motywów danej jednostki, to w zaproponowanej przez Juliana Rottera (1971) koncepcji kontroli wewnętrznej bądź zewnętrznej, istotne są |strategie osiągania celów - bez względu na pochodzenie tych celów. Pomiar umiejscowienia kontroli („locus of control”) u poszczególnych jednostek przeprowadza się głównie za pomocą kwestionariusza z przymusowym wyborem (Skala I-E Rottera). Ktoś, kto jest przekonany o wewnętrznej lokalizacji kontroli, powinien uważać świat za przewidywalny, za miejsce, gdzie działania człowieka mają swoje konsekwencje. Z drugiej strony, dla osoby o zewnętrznej lokalizacji kontroli świat jest nieprzewidywalny, a zachowanie człowieka nie musi doprowadzać do uzyskiwania nagród ani też umożliwiać uniknięcia przykrości.
„Wyuczona bezradność” (którą omawialiśmy w Rozdziałach 3 i 9) w oczywisty sposób jest związana ze zmienną umiejscowienia kontroli. Osoby o wewnętrznej lokalizacji kontroli unikają sytuacji, w których mogą utracić kontrolę nad swymi wzmocnieniami oraz potrafią wytrwale oczekiwać końcowego sukcesu, pomimo początkowych strat i niepowodzeń. Osoby o zewnętrznej lokalizacji kontroli w sytuacjach eksperymentalnych dotyczących wyuczonej bezradności szybciej poddają się i rezygnują.
Istnieją dane przemawiające za tym, że osoby o wewnętrznym umiejscowieniu kontroli są bardziej odporne na wpływ społeczny, mniej konformistyczne i bardziej niezależne niż osoby przekonane o zewnętrznej lokalizacji kontroli. Ponieważ skuteczne kierowanie własnym zachowaniem wymaga planowania relacji między środkami i celami oraz zdolności do „omijania” przeszkód w drodze do „upragnionych celów”, przeto osoby o zewnętrznym umiejscowieniu kontroli powinny częściej wykorzystywać dostępną w danej sytuacji informację, która jest istotna dla podejmowania przez nie decyzji i dla ustanawiania celów. Przewidywanie to było weryfikowane różnymi sposobami. W jednym z badań eksperymentalnych osoby o zewnętrznej lokalizacji kontroli posługiwały się wyuczoną uprzednio informacją w większym stopniu niż osoby o wewnętrznej lokalizacji kontroli, gdy od obu tych grup wymagano podejmowania decyzji, w których uwzględnienie zdobytej wiedzy było korzystne. Natomiast wśród pacjentów chorych na gruźlicę (zrównanych pod względem długości przebywania w szpitalu i klasy społeczno-ekonomicznej), osoby o wewnętrznym umiejscowieniu kontroli posiadały więcej obiektywnych informacji o swej chorobie niż osoby o zewnętrznym umiejscowieniu kontroli (Seeman i Evans, 1962).
Osoby o wewnętrznym umiejscowieniu kontroli podejmują swe decyzje bardziej rozważnie, o czym świadczy dłuższy czas namysłu, który wzrasta wraz z trudnością decyzji. Reagują one także odmiennie na zadania, których rozwiązanie zależy od umiejętności bądź przypadku, koncentrując się bardziej w sytuacji wymagającej umiejętności. U osób o zewnętrznej lokalizacji kontroli nie wystąpiły różnice pod względem stopnia koncentracji lub roztargnienia w trakcie rozwiązywania zadań wymagających albo umiejętności, albo takich, których wynik zależał od przypadku.
Związek zmiennych etnicznych i społeczno-ekonomicznych z lokalizacją kontroli można podsumować w następujący sposób:


„We wszystkich opisanych badaniach nad różnymi grupami etnicznymi, grupy, których pozycje społeczną cechuje minimalna władza, czy to ze względu na klasę społeczną, czy też rasę, uzyskują na ogół wyniki wskazujące na silnie rozwiniętą zewnętrzną lokalizację kontroli. Analizując problem przynależności do określonych klas społecznych w obrębie grup rasowych można stwierdzić, że podwójne upośledzenie w postaci przynależności do niższej klasy i „niższej kasty” zdaje się produkować osoby najbardziej przekonane o zewnętrznym umiejscowieniu kontroli. Być może, iż apatię oraz to, co często określa się jako typowy dla niższej klasy brak motywacji dla osiągnięć, można wyjaśnić jako rezultat niewiary w to, że wysiłek się opłaca” (Lefcourt, 1966, s. 212).


Wielu ubogich ludzi i mieszkańców trzeciego świata nauczyło się, że w ich sytuacji polityczno-ekonomiczno-społecznej mają oni w rzeczywistości mały wpływ na swe życie i są uzależnieni od złożonego zbioru warunków zewnętrznych. Mają oni znacznie mniej możliwości wyboru niż inni ludzie, jeśli chodzi o to, gdzie będą mieszkać, pracować i bawić się. Ubóstwo czyni wykształcenie luksusem, lecz bez wykształcenia oraz umiejętności i „dyplomów”, jakie ono daje, ubodzy ludzie są przyjmowani do pracy jako ostatni, zwalniani jako pierwsi, nawet w wypadku stanowisk nie wymagających żadnych kwalifikacji. Mamy tu do czynienia z paradoksalną sytuacją: u tych, którzy są w dużym stopniu sterowani z zewnątrz, kształtuje się |przekonanie o zewnętrznej lokalizacji kontroli, co z kolei prowadzi do mniejszego zaangażowania w działania, które mogłyby w końcu zmienić ten stan rzeczy.  Przysłowie: „Głową muru nie przebijesz” jest częścią tego systemu przekonań. Innym jego elementem jest rezygnacja z możliwości osiągnięcia jakiejkolwiek zmiany w życiu |doczesnym połączona z oczekiwaniem na nagrodę w życiu przyszłym. 
Jednym z zadań szkoły powinno być dopomożenie ludziom w ocenie, jakie aspekty własnego życia mogą zmienić w wyniku swych działań, a w odniesieniu do jakich jego aspektów jest to mniej prawdopodobne. Orientacja „zewnętrzna” (eksternalistyczna) może być równoznaczna ponuremu, samospełniającemu się proroctwu, a w pewnych okolicznościach może być nawet niebezpieczna dla życia. Wskazywano na przykład, że stosunkowo większa liczba przypadków śmierci w wyniku huraganów na pewnych obszarach południowych stanów USA może być wynikiem większej skłonności do przyjmowania orientacji „eksternalistycznej” na tych terenach. W jednym z badań stwierdzono, że „eksternaliści” skłonni byli reagować na ostrzeżenia o zbliżającym się huraganie fatalizmem i bezczynnością, zamiast podejmować aktywnie jakieś kroki mające na celu uchronienie się od niebezpieczeństwa (Sims i Baumann, 1972).
Niedawno udokumentowano w USA istnienie ciekawej, lecz przygnębiającej zależności między przeciętnymi wynikami na Skali I-E a sytuacją w państwie.  W ciągu 10 lat (od 1962 do 1971 roku) wystąpiła znaczna zmiana wyników uzyskiwanych na tej skali przez studentów wyższych uczelni. Czy potrafisz przewidzieć, w jakim kierunku? Wojna wietnamska, rozruchy studenckie, wzrost liczby przestępstw oraz masowe akty przemocy - wszystko to pomogło przesunąć wyniki w kierunku „eksternalistycznym”. Z dokonanego niedawno przeglądu literatury (Phares, 1976) wynika wyraźnie, że spostrzegane umiejscowienie kontroli stanowi nie tylko względnie stałą cechę charakteryzującą ludzi bez względu na sytuację (zgeneralizowane przekonanie o swej zdolności oddziaływania na otoczenie i możliwość realizowania swych celów), lecz można je także uważać za przewidywanie o stosunkowo specyficznym charakterze, zdeterminowane przez konkretne sytuacje środowiskowe, w których dana osoba funkcjonuje. Jedynie najbardziej skrajni „internaliści” potrafią niekiedy zachować optymizm i pozostać aktywni wówczas, gdy sytuacja wydaje się beznadziejna.
W warunkach ekonomii niedostatku możemy oczekiwać dominacji „eksternalizmu” z towarzyszącym mu pesymizmem i fatalizmem. Jednakże musimy liczyć na to, że działania pewnych „internalistów” zmieniają bieg zdarzeń nawet w sytuacjach z pozoru beznadziejnych.


„O Boże, daj mi pogodę ducha, abym pogodził się z tymi rzeczami, których nie mogę zmienić, odwagę - abym zmienił te rzeczy, które mogę zmienić - oraz mądrość - abym odróżnił jedne od drugich”.
Reinhold Niebuhr




Makiaweliści (prawie)
zawsze zwyciężają




Wyobraź sobie, że wraz z dwoma innymi ludźmi znalazłeś się w następującej sytuacji. Na stole położono 100 dolarów, które zostaną podzielone między was w taki sposób, na jaki zgodzi się |dwoje z was. Sprawiedliwy byłby oczywiście podział po 33,33 dolara dla każdego z was - gdybyście wszyscy trzej musieli zadecydować, w jaki sposób podzielić tę sumę. Jednakże samolubna para mogłaby wyłączyć z podziału trzeciego partnera, a wtedy każdy z tej dwójki uzyskałby po 50 dolarów. Jedna z osób podsuwa tobie tę możliwość. Zanim zdążyłeś zgodzić się lub odmówić, „wystawiony do wiatru” partner proponuje, że da ci pięćdziesiąt jeden dolarów, zatrzymując 49 dolarów jako swój udział i eliminując z podziału tę drugą osobę. Co uczynisz? Czy będziesz manipulował innymi, w celu zmaksymalizowania swojego udziału, zanim dojdziesz do porozumienia, które wykluczy jednego z dwóch pozostałych partnerów, albo też pozwoli im podzielić równo to, co pozostało po odliczeniu twojej części? Czy też jest prawdopodobne, że będziesz musiał targować się, aby uzyskać niewielką część nagrody i nie zostać wykluczonym z podziału przez pozostałe dwie osoby? Gdy sytuację taką rzeczywiście zaaranżuje się w eksperymencie, to po wielu próbach typowy układ wyników jest następujący: jedna osoba uzyskuje około 53 dolarów, jedna 30 dolarów, a jedna dostaje tylko 17 dolarów. Którą z tych trzech osób byłbyś ty?
Niccolo Machiavelli stworzył w swych pismach (zwłaszcza w „Księciu”, 1532 oraz „Uwagach Machiawela wysnutych z Liwiusza historii rzymskiej”, 1531) początki społecznej teorii osobowości, która pomaga odpowiedzieć na to pytanie. Interesowało go, w jaki sposób można manipulować ludźmi, oraz jakie cechy i sposoby działania różnią tych, którzy umieją wywierać wpływ na innych, od tych, którzy ulegają wpływowi.


Cechy makiawelistów. Na podstawie anegdotycznych opisów sposobu postępowania i charakteru ludzi wywierających wpływ na inne osoby, psycholog z Columbia University, Richard Christe, skonstruował skalę kwestionariuszową do mierzenia „makiawelizmu”. Składa się ona z twierdzeń wyrażających różne przekonania na temat taktyki, innych ludzi i moralności.  Oto przykłady twierdzeń należących do każdej z tych grup (Christe i Geis, 1970):


|Taktyka
„Wysoki poziom makiawelizmu: „Uzasadnione kłamstwo jest często dobrą rzeczą”.
„Niski poziom makiawelizmu: „Jeśli coś jest moralnie dobre, kompromis jest wykluczony”.


|Pogląd |na |ludzi
„Wysoki poziom makiawelizmu: „Większość ludzi nie wie naprawdę, co jest dla nich najlepsze”.
„Niski poziom makiawelizmu: „Barnum nie miał racji, gdy powiedział, że co minutę rodzi się frajer”.


|Moralność
„Wysoki poziom makiawelizmu: „Użycie podstępu w prowadzeniu wojny jest rzeczą chwalebną i zgodną z honorem”.
„Niski poziom makiawelizmu: „Lepiej jest być człowiekiem skromnym i uczciwym niż mężnym i nieuczciwym”.


Skala makiawelizmu pozwala odróżnić ludzi o niskim bądź wysokim poziomie makiawelizmu na podstawie tego, w jakim stopniu akceptują oni zalecane przez Machiavellego reguły postępowania w stosunkach międzyludzkich.  Możliwe staje się umieszczenie a jednym krańcu kontinuum ludzi, którzy uznają |relatywne normy zachowania („Nigdy nie podawaj nikomu prawdziwych powodów swego postępowania, jeśli nie jest to użyteczne”), a na drugim krańcu tych, którzy uznają normy |absolutne („Uczciwość jest zawsze najlepszą polityką”). Pomiędzy tymi skrajnościami mieszczą się poglądy osób z grupy „pośredniej”, która akceptuje pewną część makiawelistycznej filozofii.
W zasadzie filozofia ta jest filozofią pragmatyzmu: „Jeśli coś jest skuteczne, to posłuż się tym”. W opisanej powyżej grze o sto dolarów lwią część stawki z reguły zdobywają ci, którzy uzyskują wysokie wyniki na skali makiawelizmu. Są oni włączani do każdej koalicji, podczas gdy osoby uzyskujące niskie wyniki na tej skali mogą być szczęśliwe, jeśli zostaną włączone do jakiejkolwiek koalicji, i z reguły muszą się zadawalać resztkami. Osoby uzyskujące średnie wyniki na skali makiawelizmu otrzymują tylko niewiele mniej niż wtedy, gdy dokonywany był sprawiedliwy podział sumy na trzy części.
W innych sytuacjach eksperymentalnych okazało się, że osoby o wysokim poziomie makiawelizmu nie oszukują więcej, lecz oszukują lepiej. Gdy kłamią, to potrafią patrzeć w oczy swemu rozmówcy i przekonywać go, że nie oszukują. Gdy rywalizują z innymi studentami, to skuteczniej „wykańczają psychicznie” swoich przeciwników (usilniej nad tym pracują i wymyślają bardziej pomysłowe sposoby przeszkadzania im). Gdy zachowują się irracjonalnie lub w sposób niezgodny ze swymi osobistymi postawami, to potrafią tolerować ten dysonans i nie zmieniają swoich postaw w celu dostosowania ich do zachowania. W eksperymentach manipulują nie tylko innymi badanymi, lecz często również eksperymentatorem.


Co czyni człowieka makiawelistą? Dewiza makiawelisty brzmi: „Zachowaj zimną krew, gdy inni wychodzą ze skóry”. Makiaweliści zachowują dystans emocjonalny, nie angażują się w zachowanie innych ani nawet swoje własne. W swym zachowaniu kierują się tym, co poznali na drodze racjonalnej, a nie tym, co odczuwają emocjonalnie.
Makiaweliści czują się doskonale w sytuacjach, które odznaczają się trzema ogólnymi właściwościami:
a) interakcja odbywa sie twarzą w twarz (nie jest bezosobowa ani też pośrednia);
b) zasady i wytyczne obowiązują w minimalnym stopniu, dzięki czemu mają oni znaczną swobodę w improwizowaniu i stwarzaniu wieloznaczności;
c) wzbudzenie emocjonalne jest wysokie (a więc przeszkadza w wykonywaniu zadań) u osób o niskim poziomie makiawelizmu, lecz nie u nich.

Przewidywania dotyczące zachowania osób o wysokim poziomie makiawelizmu w sytuacji oddziaływania społecznego muszą brać pod uwagę |interakcję tej cechy oraz społeczno-psychologicznych właściwości sytuacji. Osoba o wysokim poziomie makiawelizmu jest osobą, która nauczyła się pewnej strategii, pewnego spójnego układu zachowań, które są wzmacniane jedynie w niektórych sytuacjach. Nie można zatem przewidzieć zachowania makiawelisty jedynie na podstwie wyniku uzyskanego przez niego na skali badającej tę cechę.




Osobowość autorytarna




Zniszczenia spowodowane przez hitlerowski faszyzm podczas II wojny światowej i zagrożenie, jakie stanowił on dla demokratycznych społeczeństw, spowodowały, że reprezentanci nauk społecznych zaczęli interesować się procesami psychologicznymi, które uczyniły go nie tylko możliwym, lecz i efektywnie funkcjonującym. Po wojnie badacze z University of California w Berkeley postanowili przekonać się, czy istnieje zespół postaw politycznych, wartości ekonomicznych i społecznych oraz cech osobowości, który charakteryzowałby „osobowość antydemokratyczną” (Adorno, Frenkel-Brunswick, Levinson i Sanford, 1950). Czy jest możliwe zidentyfikowanie potencjalnego faszysty, którego struktura osobowości czyni szczególnie podatnym na propagandę antydemokratyczną?
Badacze ci zaczęli od skonstruowania skali mającej mierzyć |etnocentryzm - skłonność do przyjmowania negatywnych postaw wobec wszelkich grup innych niż własna. Osoby uzyskujące wysokie wyniki na tej skali, wykazują ogólną tendencję do dzielenia świata na „szlachetne” grupy, których sami są członkami („in-groups”), które należy popierać, oraz odrażające grupy zewnętrzne („out-groups”), których trzeba unikać lub też odrzucać je i atakować, gdy zaczną zagrażać. Skalą tą zbadano wielką grupę osób i do dalszych systematycznych badań wybrano tylko te osoby, które uzyskały na niej bardzo niskie lub bardzo wysokie wyniki (to jest osoby skrajnie tolerancyjne i skrajnie nietolerancyjne). Następnie zaczęto poszukiwać struktur charakterologicznych w stały sposób związanych z tymi przeciwstawnymi typami.
Stwierdzono, że osoby, które przejawiały nietolerancję na skali etnocentryzmu, podawały także w sposób systematyczny sztywne, ograniczone, wyrażające uprzedzenia odopwiedzi na skali antysemityzmu, na skali konserwatyzmu politycznego i ekonomicznego oraz na skali faszyzmu. Ta ostatnia, ukryta pod nazwą „|Skali F”, pozwoliła wykryć zespół cech osobowości skupionych wokół następujących właściwości:
a) konwencjonalizm - posłuszeństwo i szacunek wobec autorytetu;
b) autorytarna uległość - idealizowanie autorytetu, połączone z niezdolnością kwestionowania czy krytykowania go;
c) autorytarna agresja - odrzucenie wszelkiego naruszania konwencjonalnych wartości;
d) anty-intracepcjonizm - niechęć do wglądania w motywy, odrzucanie introspekcji czy analizy psychologicznej;
e) przesądy i stereotypy - myślenie sztywnymi kategoriami, potrzeba ładu i formalnej rutyny;
f) zaabsorbowanie siłą i „twardością” - spostrzeganie ludzi jako silnych i dominujących lub jako słabych i podporządkowujących się;
g) destruktywność i cynizm - poniżanie wszystkich ludzi nie należących do tej rodziny czy grupy, której jest się członkiem;
h) występowanie projekcji w spostrzeżeniach - dyspozyja do spostrzegania złych sił działających we wrogim środowisku, pełnym zagrażających ludzi;
i) nadmierne zainteresowanie sprawami seksualnymi - przesadne potępienie (i ambiwalencja) w odniesieniu do przejawów seksualizmu i swobody seksualnej.



Wysokie wyniki na tych czterech skalach są charakterystyczne dla |osobowości |autorytarnej, którą jeden z autorów opisuje następująco:


„(...) słaba w zasadzie i zależna jednostka, która poświęciła swą zdolność autentycznego przeżywania siebie lub innych po to, by utrzymać wątpliwy ład i bezpieczeństwo. W typowym przypadku przybierając pozory fałszywej siły staje ona wobec świata, w którym sztywne, stereotypowe kategorie zastępują uczuciowe, zindywidualizowane doznania, do których jest ona niezdolna. Taka osoba, pozbawiona wewnętrznych wartości, wykazuje brak samoświadomości i unika introspekcji. W swych ocenach kieruje się punitywną (nastawioną na kary), konwencjonalną moralnością będącą odbiciem zewnętrznych standardów, wobec których czuje się niepewna, ponieważ nie udało jej się uczynić ich naprawdę własnymi. Jej stosunki z innymi są uzależnione od takich względów, jak władza, sukces i przystosowanie; w tych stosunkach ludzie są raczej środkiem nić celem, a osiągnięć nie ceni się dla nich samych. W jej świecie - dobra, potężna grupa, której jest ona członkiem (|in |group) jest w zasadniczy sposób przeciwstawiona niemoralnej, słabej grupie zewnętrznej. Z tych wszystkich względów stara się ona związać z tą pierwszą, a jej fundamentalne poczucie słabości i pogardy do siebie zmuszają ją do nieustannej, zaprawionej goryczą walki zmierzającej do udowodnienia sobie i innym, że w rzeczywistości należy do tego, co silne i dobre. Uprzedzenia wobec wszelkiego rodzaju grup zewnętrznych i barw, są bezpośrednią konsekwencją takiej struktury osobowości” (Smith, 1950, s. 776).


Korelaty autorytaryzmu. Stwierdzono różne stałe korelacje pomiędzy wysokim poziomem autorytaryzmu (mierzonym za pomocą czterech skal stosowanych w badaniach kalifornijskich) a innymi zachowaniami. Ci, którzy uzyskują wysokie wyniki na tych skalach, częściej zmieniają swe postawy pod wpływem stwierdzeń przypisywanych autorytetom niż pod wpływem zwykłej informacji - a niekiedy przyjmują nawet postawy sprzeczne z własnymi poglądami, jeśli popiera je jakiś cieszący się szacunkiem autorytet.
W innych badaniach stwierdzono, że „autorytatyści” wykazywali większą sztywność przy rozwiązywaniu problemów w warunkach zagrożenia ego, zachowywali się w sposób bardziej punitywny i protekcjonalny wobec osób z niższych warstw społecznych, gdy pełnili na obozach funkcje doradców, mniej chętnie uczestniczyli w eksperymentach psychologicznych jako osoby badane, częściej przypisywali swoje własne postawy innym, oceniali preferencje swoich zwierzchników dokładniej niż preferencje swych rówieśników (w przeciwieństwie do osób, które uzyskiwały niskie wyniki na skali autorytaryzmu), wykazywali większą wrogość wobec osoby o niskiej pozycji niż wobec osoby o wysokiej pozycji, jeśli obie popełniły ten sam błąd.


Próba oceny koncepcji osobowości autorytarnej. Założenia metodologiczne, leżące u podstawy omówionych powyżej badań nad tym specyficznym „typem osobowościowo-społecznym” oraz ich implikacje, zostały poddane uzasadnionej krytyce (Christie i Jahoda, 1954). Główne zarzuty były następujące: a) dokonano nadmiernych uogólnień na podstawie danych uzyskanych od wyselekcjonowanych (o skrajnych cechach) grup osób badanych - dokładnym badaniom poddane zostały jedynie osoby o najwyższych i najniższych wynikach na skali etnocentryzmu; b) wyniki uzyskane za pomocą oryginalnej skali mogły być zniekształcone przez ogólną |tendencje |do |zgadzania |się („acquiescence set”) - osoby uzyskujące wysokie wyniki mogły być „potakiwaczami”, którzy byli skłonni często wyrażać zgodę i w ten sposób mogli uzyskać wysokie wyniki nie będąc autorytarystami; c) niskie wyniki na skali autorytaryzmu były dodatnio skorelowane z inteligencją i wykształceniem, co, być może, odzwierciedlało większą zdolność tych osób do zaznaczania „akceptowanych” odpowiedzi; d) związek między zachowaniem w wieku dorosłym a doświadczeniami z okresu dzieciństwa osób badanych ustalono na podstawie niezweryfikowanych |introspekcyjnych |sprawozdań dorosłych, którzy przypominali sobie swoje dzieciństwo; w ten sposób związek ten mógł być ustalony na podstawie zniekształconych wspomnień.
Portret osoby uzyskującej wysokie wyniki na Skali F - neurotyczna, sztywna i niezdolna do efektywnego działania - jest zapewne przerysowany. W wielu sytuacjach osoba o wysokich wynikach na Skali F będzie zdolna do działania w sposób bardziej zdecydowany niż osoba o niskich wynikach na tej skali, ponieważ jej bardziej uproszczony sposób patrzenia na rzeczy sprawia, że będzie ona mniej skłonna do analizowania wieloznaczności, niespójności, „odcieni szarości”. Jest też prawdopodobne, że liberalne wartości uznawane przez badaczy i innych psychologów pracujących w tej dziedzinie, predysponowały ich do zbytniego podkreślenia niepożądanych aspektów autorytaryzmu.
Jednocześnie występowała tendencja do identyfikowania autorytarystów jedynie z prawicowymi konserwatystami. Jednakże sztywność i autorytaryzm spotyka się nie tylko na politycznej prawicy. Wskazywano, że niektóre osoby reprezentujące radykalną lewicę, chociaż różnią się pod względem swych ideologicznych celów od reakcyjnej prawicy, to jednak są w równym stopniu autorytarne w swych interpersonalnych działaniach i stosowaniu taktyki siły.
Pomimo swych znanych wad omówiony sposób podejścia do badań nad postawami antydemokratycznymi otworzył fascynującą dziedzinę dociekań intelektualnych dotyczących natury istot ludzkich. Wykazano, że postawy polityczne i społeczne mogą być przyjmowane dlatego, iż służą potrzebom osobistym - w obronie własnego poczucia bezpieczeństwa, i poczucia własnej wartości, a nie ze względu na racjonalny materiał dowodowy. To, co zaczęło się jako literacko-historyczna analiza, rozwinęło się w badanie socjologiczne i doprowadziło do integracji metod i podejść badawczych stosowanych w psychologii osobowości i psychologii społecznej.
Być może, iż najbardziej trwała wartość tego programu badawczego polega jednak na zwróceniu naszej uwagi na fakt, że autorytaryści, czy to z lewicy, czy z prawicy politycznej, są ukształtowani, a nie urodzeni. W czasie normalnego procesu kształtowania spójnej, zwartej osobowości określona kombinacja wczesnych doświadczeń życiowych i warunków społecznych może spowodować wypaczenie osobowości. Stojąc wobec gwałtownych zagrożeń i oszałamiających zmian wobec obecnego życia, współczesna osobowość autorytarna, która potrzebuje przewidywalnego świata jeszcze bardziej niż reszta nas wszystkich, osiąga tę przewidywalność dzięki sztywności „psychicznego kaftana bezpieczeństwa”, który izoluje ją od wątpliwości rodzących się w nieustannych próbach przystosowania się do zmieniających się warunków. Dzięki identyfikacji z siłą zewnętrzną lub ze sztywną ideologią, ludzie o takiej osobowości unikają konieczności ukształtowania swych własnych wartości i formułowania niezależnych sądów, lecz dzieje się to kosztem ich własnych doznań i własnej indywidualności.




Milczący świat
nieśmiałych studentów




„Interesuje mnie nieśmiałość, ponieważ była ona zawsze dla mnie prawdziwym więzieniem zwłaszcza w okresie, gdy uczęszczałam do szkoły średniej. Nieśmiałość, w świetle mych doznań, jest przewrażliwieniem na punkcie własnej osoby, zahamowaniem swego naturalnego „ja” wywoływanym przez pewne sytuacje i ludzi. Jest to intensywna świadomość samego siebie połączona z uczuciem ograniczenia - poczucie, że każde twoje działanie jest obserwowane przez innych - męczące usiłowanie, aby wymyślić coś nadającego się do powiedzenia - suchość w ustach - jakieś skrzeczenie wydobywające się z gardła - palący rumieniec na policzkach - uczucie, że jesteś nie taki, jak inni ludzie, że jesteś drętwy i sztywny - jest to tęsknota za spontanicznością. W jaki sposób można by przezwyciężyć swoje poczucie nieśmiałości? W jaki sposób można by pomóc innym uwolnić się od tej przypadłości? Ilu jest ludzi tak nieśmiałych jak ja? (list od Suzan, studentki Stanford University, 1973).


Pojęcie |nieśmiałość ma różne znaczenie dla różnych ludzi, lecz w zasadzie jest to świadomość własnej niezdolności do podjęcia działania, które chce się podjąć i co do którego wiadomo, jak to zrobić. Nieśmiałość jest obawą przed negatywną samooceną i (lub) negatywną oceną ze strony innych. Osoba nieśmiała wyróżnia się milczeniem, gdy inni mówią, bezruchem, gdy inni się poruszają, izolacją, gdy inni nawiązują przyjazne kontakty.  Nieśmiałą osobę charakteryzuje zatem raczej nieobecność reakcji zewnętrznych, niż obecność jakichś niezwykłych reakcji.
W skrajnych przypadkach nieśmiałość istotnie staje się narzuconym sobie samemu więzieniem, w którym dana osoba odgrywa zarówno rolę znienawidzonego strażnika, który nieustannie zmusza do przestrzegania przepisów „nie wolno”, jak i pogardzanego więźnia, który potulnie się do nich stosuje. W pewnych okolicznościach nieśmiałość może doprowadzić do poważnego stanu patologicznego, powodującego całkowite wycofanie się z kontaktów społecznych w dręczącą samotność. Skrajna nieśmiałość przekształca się stopniowo w brak pewności siebie oraz lęk przed spotykaniem nowych ludzi i znajdowaniem się w nowych sytuacjach. Istnieją także ludzie, którzy są „nieśmiali” z wyboru - to jest czują się oni lepiej w towarzystwie rzeczy, projektów, idei, książek itd., aniżeli w towarzystwie ludzi. W razie konieczności potrafią oni przyłączyć się do tłumu i nie mają żadnych obaw przed przebywaniem z ludźmi, jeśli jednak inne okoliczności tego nie wymagają, to wolą raczej być sami (typ spopularyzowany przez aktorkę Gretę Garbo).
Dążąc do lepszego zrozumienia tej zmiennej osobowościowej, której - dziwna rzecz - nie poświęcano dotąd niemal wcale uwagi w badaniach empirycznych, zespół badaczy ze Stanford University zacząć zbierać dane dotyczące częstości występowania i natury nieśmiałości u studentów (Zimbardo, Pilkonis i Norwood, 1974). Jak odpowiedziałbyś na następujące pytania, zamieszczone w ich kwestionariuszu?


„Czy obecnie uważasz siebie za osobę nieśmiałą”?
Tak ... Nie ...


„Czy był kiedykolwiek okres w twoim życiu, w którym uważałeś się za osobę nieśmiałą”?
Tak ... Nie ...


W próbce składającej się z kilku tysięcy studentów wyższej uczelni i uczniów szkół średnich, więcej niż 40% określiło się jako „nieśmiałych”, a ponad 80% podało, że są lub kiedyś byli „nieśmiali”. Chociaż nieśmiałość można przedstawiać na pewnym kontinuum intensywności, to jednak ludzie myślą o sobie jako o „nieśmiałych” lub „nie nieśmiałych”. Jest prawdopodobne, że w ogólnej populacji jest zbliżona liczba ludzi, którzy określają siebie jako „nieśmiałych”, jak i ludzi, którzy nie uważają siebie za nieśmiałych. Nieśmiałość wiąże się z introwersją, lecz jest czymś innym; więcej niż trzecia część badanych, którzy uważali się za ekstrawertyków, uważała się za nieśmiałych, a niektórzy introwertycy uważali, że nie są nieśmiali.
Mały procent badanych (8%) określił nieśmiałość jako cechę „pożądaną”, podczas gdy trzecia część (35%) stwierdziła, że nieśmiałość jest albo „niepożądana” albo „bardzo niepożądana” (Reszta badanych uznała ją za cechę ani pożądaną, ani niepożądaną). Jednakże większość badanych, zarówno nieśmiałych, jak i nie uważających siebie za nieśmiałych, była zgodna, co do ujemnych konsekwencji nieśmiałości:
a) stwarza ona problemy natury towarzyskiej; utrudnia spotykanie nowych ludzi, zawieranie nowych przyjaźni, czerpanie radości z potencjalnie przyjemnych doświadczeń;
b) ma ujemne konsekwencje emocjonalne; wywołuje poczucie samotności, izolacji, depresji;
c) przeszkadza w uzyskaniu pozytywnej oceny ze strony innych osób (na przykład osobiste zalety danej jednostki nigdy nie ujawniają się ze względu na jej nieśmiałość);
d) utrudnia obronę słusznych spraw, wyrażanie poglądów, wykorzystanie możliwości;
e) naraża na niesłuszne, negatywne oceny ze strony innych (na przykład ktoś może być niesłusznie uważany za niekoleżeńskiego, snoba czy niedołęgę);
f) powoduje trudności poznawcze i trudności w zakresie ekspresji, zmniejsza zdolność jasnego myślenia w obecności innych i skutecznego komunikowania się z nimi;
g) sprzyja nadmiernemu przewrażliwieniu na punkcie własnej osoby i zaabsorbowaniu sobą samym.

Nieśmiałość można analizować w kategoriach wywołujących ją warunków, jak i relacji, które powoduje. W tabeli podano, jaki procent z grupy 800 „nieśmiałych” badanych stwierdził, że wymieniona sytuacja czy grupa ludzi wzbudza w nich nieśmiałość, jak również wywołuje u nich różne podane reakcje.


Doniosłe znaczenie tego procesu „samookreślenia” (to jest procesu doprowadzającego do myślenia o sobie samym jako o „nieśmiałym” lub „nie nieśmiałym”) przejawia się wyraźnie w sposobie opisywania przez te dwie grupy warunków występowania u nich stresu, leku i obaw. Nieśmiałe osoby badane uważały nieśmiałość za cechę, którą noszą |w |sobie i która ujawnia się od czasu do czasu w różnych sytuacjach, a w stanie utajonym istnieje nawet wtedy, gdy czują się swobodnie w towarzystwie innych ludzi. Natomiast osoby badane nie uważające się za nieśmiałe wskazywały, że to sytuacje „zewnętrzne”, a nie jakaś wewnętrzna dyspozycja, powodują występowanie u nich przykrych reakcji. Podobnie, te same objawy, które dla nieśmiałych badanych były oznakami ich nieśmiałości, dla osób nie uważających się za nieśmiałe były wskaźnikami, że znajdują się one pod naciskiem społecznym.  Wydaje się zatem, że „śmiali” ludzie uczą się czegoś o sytuacjach na podstawie swoich reakcji na nie, podczas gdy ludzie nieśmiali nieustannie uczą się od nowa czegoś o sobie samym - mianowicie tego, że są nieśmiali.
Aczkolwiek nieśmiałość jest indywidualnym sposobem reagowania, to jednak kształtują ją i podtrzymują podstawowe wartości społeczne i programowanie kulturowe. Nieśmiałość występuje częściej w kulturach zorientowanych na jednostkę niż w kulturach zorientowanych na grupę lub społeczeństwo. Tam, gdzie kulturowe przypisują zbyt dużą wartość rywalizacji i osiągnięciom i regulują zachowanie za pośrednictwem wstydu i społecznych oczekiwań - tam nieśmiałość kwitnie. Tam natomiast, gdzie najważniejsze są cele grupowe, jak w izraelskim kibucu lub w Chinach, nieśmiałość nie jest częstym zjawiskiem. Porównania międzykulturowe wykazują także, że pojęcie nieśmiałości i jego interpretacja mogą różnić się od naszych. W próbce studentów Uniwersytetu Tokijskiego, którzy na ogół byli dość nieśmiali, część ich uznawała nieśmiałość za cechę pozytywną, ponieważ według nich nieśmiały człowiek wywiera wrażenie skromnego i sympatycznego, nie wzbudza u innych lęku, nie jest agresywny, potrafi być dobrym słuchaczem itd. (G.  Hatano, 1975).
Pomoc dla studentów cierpiących z powodu nieśmiałości mogłaby polegać na zakładaniu i prowadzeniu przez samych studentów „klinik nieśmiałości”, w których nieśmiali studenci działaliby jako „asystenci społeczni, którzy: a) stwarzają atmosferę, w której nie podlega się ocenom, b) przekazują informację o powszechnym występowaniu nieśmiałości, c) pomagają swoim nieśmiałym rówieśnikom spojrzeć z innego punktu widzenia na konsekwencje nieśmiałości, d) uczą konkretnych metod ćwiczenia pewności siebie, skutecznych w sytuacjach wywołujących nieśmiałość.




Pomiar osobowości




Każda próba określenia czy szacowania cech indywidualnych opiera się na przekonaniu, że „wszystko to wiąże się jakoś ze sobą”. Innymi słowy, takie szacowanie zawsze polega na próbie przewidywania różnorodnych spójnych sposobów zachowania się danej jednostki na podstawie znacznie węższego zakresu cech, które możemy określić bezpośrednio. W niniejszym podrozdziale omówimy niektóre sposoby podejścia do problemu przewidywania na podstawie niewielu informacji, lecz najpierw musimy zastanowić się, dlaczego podejmuje się próby takiego określania osobowości, wbrew temu, że często wiąże się to z trudnościami i kłopotami.




Po co?




Jedno z pytań najczęściej zadawanych w związku z testami psychologicznymi brzmi: „Po co to wszystko?”. Studenci, którzy muszą wykonywać testy psychologiczne, czują się niekiedy odczłowieczeni, „umieszczeni w szufladkach”, które nie pozostawiają miejsca dla wykazania swej indywidualności. Kandydaci na pracowników - zwłaszcza ci, którzy pochodzą z grup mniejszościowych - niekiedy mają poczucie, że testy są stosowane przeciwko nim. Jest to istotnie prawdziwa ironia, ponieważ głównym celem stosowania testów psychologicznych jest zwykle możność |lepszego określenia cech indywidualnych osoby testowanej. Jeśli teoretycy osobowości starają się znaleźć płodne teoretycznie sposoby ujęcia różnych rodzajów stałości w zachowaniu indywidualnym, to twórcom i użytkownikom testów psychologicznych chodzi o przewidywanie, które z tych rodzajów stałości będą wykazywane przez poszczególne jednostki w określonych warunkach. Zwykle starają się dokonać tego dla jednego z trzech ogólnych powodów.
1. |Przewidywanie |powodzenia. Bardzo wiele testów psychologicznych stosuje się w poradnictwie zawodowym jako „egzaminy wstępne” do różnych szkół oraz przy doborze pracowników. W tego rodzaju sytuacjach testy stosuje się w celu określenia prawdopodobieństwa, że dana jednostka osiągnie powodzenie w danej dziedzinie zawodowej, w określonej szkole czy na pewnym, konkretnym stanowisku pracy.
2. |Ustalenie |sposobu |postępowania. Drugim zasadniczym obszarem zastosowania testów psychologicznych jest szkoła i klinika. Testy dostarczają tu informacji pozwalających rozstrzygnąć, jakie rodzaje postępowania pedagogicznego czy terapeutycznego będą pomocne w odniesieniu do danej osoby. W niektórych przypadkach stosuje się je w celu ustalenia, czy dzieci, które są opóźnione intelektualnie lub wykazują zaburzenia emocjonalne, należy kierować do klas specjalnych. W innych przypadkach służą do zbadania stopnia i charakteru zaburzeń psychicznych, w celu ustalenia, jaki rodzaj terapii będzie prawdopodobnie najbardziej skuteczny.  Niekiedy stosuje się je w celu sprawdzenia hipotezy, że jedną z przyczyn schorzenia fizycznego czy gorszego niż przeciętne funkcjonowania są trudności natury psychologicznej lub neurologicznej.
3. |Wzbogacanie |wiedzy. Na koniec testy psychologiczne stosuje się w badaniach mających na celu udoskonalenie naszych koncepcji dotyczących sposobów funkcjonowania ludzi. Część tych badań polega na sprawdzeniu teorii osobowości tego rodzaju, jakie omawialiśmy powyżej. W innych badaniach chodzi o opracowanie nowych testów, które zwiększą naszą zdolność przewidywania, kto osiągnie powodzenie w danej dziedzinie lub kto odniesie korzyść z danego typu postępowania terapeutycznego. W jeszcze innych chodzi o ustalenie, w jaki sposób przebiega rozwój człowieka: w jakim wieku u dzieci rozwijają się poszczególne umiejętności, postawy i sposoby radzenia sobie ze światem. We wszystkich tych badaniach testowych chodzi o to, aby dowiedzieć się czegoś więcej: przyczynić się do rozwoju psychologii jako nauki teoretycznej i stosowanej.





Narzędzia do pomiaru
osobowości




Opracowując narzędzia przeznaczone do ilościowych „pomiarów” osobowości, psycholog ma do czynienia z pojęciami trafności, rzetelności, obiektywności i normalizacji. Wskaźnik |trafności pokazuje, w jakim stopniu dane narzędzie w rzeczywistości mierzy to, co ma mierzyć. Dane narzędzie nie może być „trafne” w sensie abstrakcyjnym, jest ono trafne w odniesieniu do określonego celu, przy czym trafność tę ocenia się według wyraźnie sformułowanych kryteriów, takich jak przewidywanie powodzenia na wyższej uczelni lub w określonym zawodzie.
|Rzetelność narzędzia pomiarowego wskazuje, w jakim stopniu ludzie uzyskują takie same względne wyniki we wszystkich kolejnych pomiarach (jeśli nie brać pod uwagę zmian zachodzących w samych osobach badanych, a związanych ze stanem ich zdrowia, zmęczeniem itd.).


Rzetelność szacuje się przeprowadzając powtórne badanie („retest”) lub polecając ocenić to samo zachowanie różnym osobom. Narzędzie pomiarowe nie może być trafne, o ile nie jest przede wszystkim rzetelne, lecz rzetelność nie gwarantuje jeszcze, że jest ono trafne.
Częstym powodem nierzetelność testów psychologicznych jest brak |obiektywności procedur obliczania wyników tych testów. Jeśli wyniki jakiegoś testu trzeba ustalać na podstawie subiektywnej oceny, to różni ludzie mogą przypisywać tej samej osobie badanej bardzo różne wyniki (jeżeli nie poda się szczegółowych reguł obliczania wyników).
Aby narzędzie pomiarowe było rzeczywiście użyteczne, musi być ono |znormalizowane - to znaczy zastosowane (w standardowych warunkach) w dużej grupie osób reprezentatywnych dla populacji, dla której to narzędzie jest przeznaczone. Procedura taka dostarcza |norm, dzięki czemu wynik każdej osoby badanej można porównać z wynikami innych osób w określonej grupie.  Oczywiście test trzeba dawać do wykonania wszystkim osobom badanym w ten sam sposób i w tych samych warunkach, gdyż inaczej porównania byłyby bezwartościowe.


Skale ocen. Niektóre rodzaje zachowania, na podstawie których można by określać indywidualne właściwości, trudno jest psychologowi obserwować bezpośrednio. Mogą być one na przykład zbyt intymne lub przebiegać w zniechęcająco długim czasie. Toteż, aby oszacować te rodzaje zachowania, użyteczne bywa polecenie innym ludziom, znającym osobę badaną, ażeby podali swoje wrażenia dotyczące jej zachowania. Narzędziem służącym do uzyskania takich danych jest skala ocen. Istnieją dwa rodzaje skal ocen, |relatywne i |absolutne; każdy z nich ma pewne zalety i wady. Często stosuje się je łącznie z wywiadem, jak również dla zarejestrowania subiektywnych wrażeń wyniesionych z dłuższego okresu kontaktowania się. Skale obu tych typów mają tę zaletę, że dostarczają wartości liczbowych, które można poddać analizie ilościowej.


„Relatywne skale ocen”. Relatywna skala ocen może być stosowana wtedy, gdy ocenia się kilku badanych. Typową metodą jest podporządkowanie „w kolejności zasług”. Oceniający porządkuje grupę osób wskazując „najlepszą”, potem „najlepszą” spośród pozostałych itd., dopóki wszystkie osoby z tej grupy nie zostaną „porangowane” pod względem cechy, która jest przedmiotem pomiarów. Metoda ta wskazuje pozycję każdej osoby w stosunku do pozycji wszystkich innych w tej grupie.


„Absolutne skale ocen”. W wypadku absolutnych skal ocen sędzia przypisuje każdej osobie badanej pewien wynik w związku z każdą ocenianą cechą. Każdą osobę porównuje się z pewnym standardem ustalonym niezależnie od rozpatrywanej grupy jednostek. Sędzia może na przykład oceniać każdego kandydata na siedmiopunktowej skali czystości lub może znaznaczać na liście wszystkie przymiotniki, które stosują się do danego kandydata.
Wyniki uzyskiwane na obu typach skal ocen obarczone są dwoma ważnymi rodzajami błędów oceny, spowodowanymi bądź efektem halo, bądź stereotypami.  |Efekt |halo (efekt aueroli) jest to tendencja do oceniania sympatycznej lub inteligentnej osoby jako „dobrej” również pod innymi względami.  |Stereotypy są to ukształtowane z góry oczekiwania co do cech osoby należącej do pewnej kategorii osób (Rosjan polityków). Oba te rodzaje błędów można zminimalizować, polecając sędziemu oceniać wszystkie osoby pod względem tylko jednej cechy naraz, dzięki czemu będzie mniej prawdopodobne, że wcześniejsze oceny danej osoby będą wpływać na oceny późniejsze.
Ponieważ jednak wynik na skali ocen nieuchronnie zależy od subiektywnych ocen osób osób szacujących, przeto zwykle uważa się ją za „gorszą” od bardziej obiektywnych testów psychologicznych (które opiszemy poniżej).  Zapewne wartości ocen zależy zarówno od zdolności sędziego do oceniania innych, jak też od przyjętych przez niego definicji cech będących przedmiotem oceny. W pewnym stopniu czynniki te można ocenić sprawdzając, jak dalece dwie grupy sędziów są zgodne w swych ocenach tych samych jednostek i jak konsekwentni są ci sami sędziowie w ocenianiu tych samych jednostek w kolejnych badaniach.


Próbki zachowania. W technikach polegających na „pobieraniu próbek” zachowania badający po prostu obserwując zachowanie danej osoby w pewnej typowej sytuacji, a badany - nie zdając sobie sprawy z tego, że jest obserwowany - zachowuje się tak, jak zwykle.


„Interesującą technikę pobierania próbek zachowania dla oceny zdolności kierowniczych, opracowano w czasie II wojny światowej w Office of Strategic Services (amerykańskim Urzędzie Służby Strategicznej). Sytuacje aranżowano w ten sposób, aby były one jak najbardziej podobne do tych, z którymi kandydat mógł się zetknąć w rzeczywistości. Na przykład test konstrukcyjny zawierał zadanie, w którym kandydat miał wznieść pewien fragment zaplanowanej konstrukcji, kierując ludźmi, którym potajemnie podano instrukcję, aby wszelkimi sposobami starali się sabotować to zadanie.  Obserwatorzy oceniali zachowanie kandydata znajdującego się w tego typu sytuacji stresowej” (Fortune, 1946).


Dokonane później oceny takich testów wykazały, że są one znacznie bardziej kosztowne i mniej trafne (w przeliczeniu na godzinę czasu badania) niż inne obiektywne testy psychologiczne. Jednakże takie techniki pobierania próbek zachowania mogą być wartościowe jako uzupełnienie bardziej konwencjonalnych procedur testowych.


Wywiad. Wywiad od dawna jest główną techniką stosowaną przez psychologów klinicznych i psychiatrów w czasie badania i leczenia zaburzeń osobowości.  Technika ta jest równie szeroko stosowana przez pracodawców przy doborze nowych pracowników.
Wywiad może być dość swobodny i nie ustrukturalizowany - „znormalizowany” tylko w tej mierze, iż oczekuje się, że dwoje ludzi będzie razem przebywać w gabinecie przez pewien czas, a jedno z nich będzie mówić więcej niż drugie. Jednakże w tej postaci wywiad okazał się narzędziem raczej mało wiarygodnym; uzyskiwane w ten sposób informacje nie pozwalają dobrze przewidywać przyszłego zachowania, przynajmniej w sytuacji pracy. Ta mała wiarygodność wynika prawdopodobnie częściowo z błędów oceny, takich jak efekt halo i stereotypy, o których wspominaliśmy już w związku ze skalami ocen. Ponadto wszelkie kształtowane w ten sposób wrażenia są zniekształcane przez filtr percepcyjny osoby przeprowadzającej wywiad oraz przez pragnienie jej rozmówcy, aby wywrzeć na niej dobre wrażenie.


Wielu z tych trudności można uniknąć stosując |znormalizowany |plan |wywiadu, dzięki któremu ustalone z góry pytania zadaje się w ustalonym z góry porządku. Wywiad przeprowadzony w ten sposób dostarcza danych, które są mniej podatne na tendencyjność przeprowadzającej go osoby i które można obliczać i oceniać w sposób obiektywny.


Techniki projekcyjne. Niewątpliwie „widziałeś” czasami w chmurze twarz lub kształt zwierzęcia. Jeśli jednak wspomniałeś o tym kolegom, to mogło okazać się, że oni dostrzegają w niej drzewo lub zamek, lub coś całkiem innego. Psychologowie wykorzystują podobne zjawiska w |projekcyjnych technikach pomiaru osobowości.




* * *



Ryc. 10.13. Plama atramentowa podobna do użytych w teście Rorschacha. Co w niej widzisz? Zapytaj paru swoich kolegów, co oni widzą? 


* * *





Osobie badanej przedstawia się znormalizowany wzór wieloznacznych czy neutralnych bodźców - plam atramentowych lub obrazków, które nie mają określonego znaczenia, lecz mogą być interpretowane w różny sposób i zachęca się ją do swobodnego interpretowania tego co w „nich widzi”. Osoba badana może zatem dokonywać projekcji („rzutować”), to znaczy nadawać pewien specjalny osobisty sens każdemu neutralnemu bodźcowi - podobnie jak ty spostrzegałeś chmurę jako twarz lub zwierzę. Psychologowie sugerują, że takie projekcie odzwierciedlają różne potrzeby oraz sposoby emocjonalnego przystosowania jednostki i w ten sposób pomagają ujawnić jej podstawową strukturę osobowości.
W testach projekcyjnych trudno jest „fałszować” odpowiedzi, ponieważ nie ma w nich odpowiedzi „dobrych” lub „złych”; ponadto mają one tę zaletę, że docierają do głębszych poziomów potrzeb i lęków niż inne metody pomiaru.  Nie są one jednak całkowicie zadawalające. Jedno z poważnych ograniczeń polega na tym, że psychologowie muszą opierać się w dużej mierze na własnej subiektywnej ocenie przy kategoryzowaniu i obliczaniu odpowiedzi osoby badanej. Chociaż ustanowiono obiektywne normy dla oceny różnych typów reakcji, to jednak nadal wymagana jest umiejętna interpretacja ze strony badacza. Oznacza to, że ocena badacza wpływa na ostateczny „wynik” w większym stopniu niż w wypadku testów bardziej obiektywnych. Ponadto, aby posługiwać się testami protekcyjnymi jako narzędziem diagnostycznym, niezbędne jest długotrwałe szkolenie.


„Test Rorschacha”. |Technika |Rorschacha, jedna z najstarszych metod projekcyjnych, wykorzystuje jako bodźce szereg plam atramentowych. Niektóre są biało-czarne, niektóre barwne, ponadto różnią się one kształtem, cieniowaniem i złożonością. Badani oglądają karty z plamami w określonej kolejności i opisują to, co „widzą” na każdej z nich. Często dostarcza to informacji o ich strukturze osobowości, której nie uzyskuje się za pomocą wywiadów klinicznych. Na przykład sposób, w jaki badani reagują na barwę plam, może nam wiele powiedzieć o ich reakcjach emocjonalnych na otoczenie (ryc. 10.13).
Specjaliści w stosowaniu testu Rorschacha analizują nie tylko treść wypowiedzi, lecz także uzyskują wskazówki na temat funkcjonowania osobowości na podstawie „stylu” reagowania. Czy reaguje ona na cały bodziec czy tylko na jego część? Czy próbując ująć wieloznaczny materiał testowy osoba badana częściej posługuje się pojęciami związanymi z formą i strukturą, czy też z ruchem i działaniem? Takie analizy pomagają klinicyście zidentyfikować sposób spostrzegania świata przez daną jednostkę, obszary konfliktu oraz rozmiar występujących u niej zaburzeń.
„Test Apercepcji Tematycznej (TAT)”. Inną techniką projekcyjną jest |Test |Apercepcji |Tematycznej. Test ten składa się z trzech serii po 10 obrazkach, przy czym każdy obrazek przedstawia inną sytuację. Badanemu poleca się wymyśleć opowiadanie o każdym obrazku - ma on opisać przedstawioną na nim sytuację, zdarzenia, które do niej doprowadziły, powiedzieć, co odczuwają postacie na obrazku oraz podać, jak się ta sytuacja zakończy. Oceniając strukturę i treść tych historyjek, jak również zachowanie osoby badanej przy ich opowiadaniu, badacz stara się wykryć cechy osobowości badanego. Na przykład badacz mógłby określić osobę badaną jako „sumienną”, jeśli wymyślała opowiadania TAT o „ludziach, którzy dotrzymują swych zobowiązań” i opowiadała je w sposób bardzo poważny i uporządkowany.
Interpretacja opowiadań TAT (jak również testu Rorschacha) jest w bardzo dużej mierze zależna od subiektywnej oceny klinicysty, który wyprowadza wnioski co do motywów osoby badanej, uznawanych przez nią wartości, jej postaw, mechanizmów obronnych itd. W zasadzie klinicysta konstruuje teorię dotyczącą badanego, która wyjaśnia w możliwie jak największym stopniu, historię jego życia i przyczyny jego odpowiedzi. W praktyce TAT stosuje się łącznie z kilkoma rodzajami technik oceny osobowości, które razem tworzą zrównoważony zestaw, czyli |baterię |testów.


Kwestionariusze osobowości. Typowe kwestionariusze osobowości wymagają od badanego, aby podał informację o |sobie |samym. Prosi się go, aby podał, co lubi robić, a czego nie lubi, jakimi emocjami reaguje zwykle w pewnych sytuacjach, czy podziwia czy też potępia różne znane postacie z życia publicznego itd.
Kwestionariusz osobowości jest wartościowy z tego względu, że wnika pod powierzchnię pozorów, docierając do osobistych doznań i uczuć danej jednostki. Jest on także wygodny do stosowania, ponieważ nie wymaga usług grupy osób oceniających czy przeprowadzających wywiady. Główną jego wadą jest to, że osoby badane nie w pełni rozumieją same siebie, a zatem nie zawsze mogą dokładnie odpowiedzieć na pytanie. Ponadto, jeśli chcą - łatwo mogą kłamać o sobie samych, starając się, aby odpowiedzi wypadły bardziej korzystnie.
Pierwsze kwestionariusze osobowości opracowano po to, by móc klasyfikować jednostki pod względem ich zainteresowań zawodowych lub zaburzeń psychicznych. Wiele takich narzędzi pomiarowych opracowano przy zastosowaniu procedury statystycznej zwanej |analizą |pozycji („item analysis”). Psychologowie ustalają, na które pytania większość członków określonych grup odpowiada w zgodny sposób. Na podstawie takich informacji opracowuje się system obliczania wyników pozwalający wykrywać, którą grupę dana osoba przypomina najbardziej pod względem swych zainteresowań czy osobowości.
W powszechnym użyciu jest kilka kwestionariuszy zainteresowań tego typu.  Są one szczególnie odpowiednie do badania osób mających wkrótce podjąć decyzję co do wyboru zawodu. Najpowszechniej stosowany w USA jest „Strong Vocational Interest Blank” (Kwestionariusz Zainteresowań Zawodowych Stronga), a to ze względu na swoją wysoką trafność.
Zasada opracowywania wyników uzyskiwanych za pomocą tej techniki opiera się na założeniu, że osobie, która odpowiedziała na znaczną większość pytań w taki sam sposób, jak na przykład lekarze, wykonywanie zawodu lekarza prawdopodobnie przynosiłoby satysfakcję.
Istnieje poważny materiał dowodowy, że młodzi ludzie, którzy wybierają zawody zgodne z wynikami uzyskiwanymi w kwestionariuszach zainteresowań, osiągają większą satysfakcję w swej pracy niż ci, którzy nie wybierają zawodów zgodnie z tymi wysiłkami.




Inteligencja a testy
inteligencji




Inteligencja jest to zdolność korzystania z doświadczeń oraz wykraczania poza to, co jest dane, by dojść do tego, co jest możliwe. To właśnie dzięki rozwojowi intelektualnemu ludzie potrafili przezwyciężyć swą fizyczną słabość i osiągnąć przewagę nad silniejszymi i liczniejszymi zwierzętami.  Nic więc dziwnego, że inteligencja jest naszą najwyżej cenioną własnością. 
Lecz czym jest inteligencja? Jaka jest jej geneza? Jak można ją oszacować? 
Jakie z niej płynął korzyści?
Zagadnienia takie intrygowały uczonych przez stulecia. We Francji w roku 1799 powstała jedyna w swoim rodzaju sposobność do badania natury inteligencji ludzkiej. Trzech sportsmenów „schwytało” nagie dziecko, w wieku zapewne 12 lat, w lasach okręgu Averyon. Po tygodniu pobytu w niewoli chłopiec ten uciekł w góry, lecz ujęto go ponownie tej samej zimy.
W następnym roku wzięto go do Paryża, gdzie zainteresowanie naturą tego dzikiego człowieka-zwierzęcia osiągnęło szczytowy punkt. Czyżby to był „człowiek natury” Rousseau, „szlachetny dzikus” nie zepsuty cywilizacją?  Czy też byłby to rzadki przypadek „tabula rasa” Johna Locke’a - nie uformowany, czysty umysł, który można przeistoczyć w normalną istotę ludzką przez kształcenie i wychowanie? Inni byli po prostu ciekawi. Tak samo jak w wypadku pojawienia się jakiegoś nieznanego, dziwnego zwierzęcia.
Tym, co ujrzeli, było „odrażająco brudne dziecko wykonywujące spazmatyczne ruchy i i miotane częstymi konwulsjami, dziecko, które nieustannie kołysało się w przód i w tył, podobnie jak niektóre zwierzęta w menażerii, które gryzło i drapało tych, którzy mu się przeciwstawiali, które nie okazywało żadnego uczucia tym, którzy opiekowali się nim i które, krótko mówiąc, było obojętne na wszystko i na nic nie zwracało uwagi” (Itard, 1962, s. 4).
Dziecko to przekazano pod opiekę i w celu kształcenia młodemu, pełnemu entuzjazmu i poświęcenia lekarzowi, nazwiskiem Jean Marc Gaspard Itard.  Przez następnych pięć lat Itard pracował z tym dzieckiem (któremu dano imię Wiktor) jako nauczyciel, uczony i rodzic. Sprawozdanie Itarda z jego sukcesów i porażek („De I’education d’un homme sauvage”; O edukacji dzikiego człowieka), które w 1962 roku opublikowano w USA w postaci broszury zatytułowanej „The Wild Boy of Aveyron” (Dziki chłopiec z Aveyron) jest pasjonującą lekturą; podobnie interesujący jest film, który nakręcono na podstawie tej książki.
Ówcześni lekarze specjaliści uznali Wiktora za „nieuleczalnego idiotę”, który przypuszczalnie został porzucony przez rodziców z powodu swego upośledzenia umysłowego. Jednakże Itard był przekonany, że cywilizujący wpływ edukacji wystarczy, aby przeobrazić niedorozwinięte „dzikie” dziecko w normalnego, dorosłego człowieka. W swej optymistycznej, „środowiskowej” koncepcji Itard nie uwzględnił tego, że w wielu wypadkach doświadczenie musi pojawić się w odpowiednim czasie w trakcie rozwoju. W odniesieniu do niektórych zmian, jakie pragnął wprowadzić Itard, było już najwyraźniej zbyt późno; w wypadku innych osiągnął znaczne sukcesy.
Reasumując, młody dzikus zaczął swą edukację z następującymi brakami: był niezdolny do skupienia uwagi, miał słabą pamięć, nikłe zdolności oceniania i naśladowania, był niemy - wydawał tylko pomruki, wykazywał niską inteligencję i słabą wrażliwość sensoryczną, był wreszcie „niewrażliwy na wszelkiego rodzaju oddziaływania moralne”. Jednakże jakoś |utrzymał |się przy życiu - samotne dziecko w dzikiej puszczy, o której niebezpieczeństwach świadczyły dwadzieścia trzy blizny na jego ciele.
Itard podzielił obszar swych oddziaływań pedagogicznych na trzy dziedziny: zmysły, intelekt i emocje. Co się tyczy zmysłów to działanie wszystkich z nich, poza słuchem uległo znacznej poprawie. Wiktor przyswoił sobie zdolność różnicowania percepcyjnego przedmiotów za pomocą dotyku, wzroku i smaku - czego nie potrafił na początku swego kształcenia.
Percepcja stanowiła podstawę rozwoju funkcji intelektualnych - „wielkiego dzieła przekazywania idei”. Wiktor nauczył się wiązać przedmioty z abstrakcyjnymi znakami i symbolami. Nauczył się pojęć względnej wielkości, wagi, barwy, trwałości oraz innych porównań. Nauczył się także kopiować pisemnie słowa, których znaczenie znał. Potrafił odtwarzać je później z pamięci i posługiwać się nimi dla wyrażenia swych potrzeb i porozumiewania się w prosty sposób z innymi ludźmi, osiągając w ten sposób „swobodną i ciągłą wymianę myśli”.
Jednakże Wiktor nie potrafił nigdy opanować mówionego języka z wyjątkiem dwóch słów: „lait” (mleko) oraz „Oh Dieu” (O Boże). Niestety, niepowodzenia Wiktora w tej dziedzinie (które mogły pozostawać w związku z jego defektem słuchu) doprowadzały Itarda do rozpaczy.
Troska, cierpliwość i poczucie bezpieczeństwa, jakie zapewnił Wiktorowi jego nauczyciel, znalazły swoje odbicie również w jego rozwoju emocjonalnym. Stał się on „wrażliwy na okazywaną mu troskę, pieszczoty i uczucie, cieszył się ze swych dobrych uczynków, wstydził się swych błędów i żałował za swe wybuchy” (s. 101). Lecz również i tutaj Itard błądził zakładając, że wartości jego własnego, cywilizowanego życia społecznego są jedynymi, jakie można zaakceptować. Uważał on za nieuleczalną wadę swego młodego dzikusa „jego nieumiarkowane upodobanie do otwartych przestrzeni i jego obojętność w stosunku do większości przyjemności życia społecznego” (s. 101).
Nie ulega wątpliwości, że niektóre, choć nie wszystkie, defekty, jakie występowały początkowo u dzikiego chłopca z Aveyronu, zostały zredukowane lub całkowicie usunięte pod wpływem doświadczenia. Jednakże na korzyść natywistów, którzy podkreślają doniosły wpływ dziedziczności, przemawia prosty fakt, że zachowanie Wiktora nie stało się tak normalne, aby nie można go było odróżnić od zachowania innych chłopców w tym samym wieku. Nie dowiemy się nigdy, czy Wiktor urodził się upośledzony umysłowo, czy też granice jego możliwości rozwoju zostały obniżone przez brak kontaktu z ludźmi i brak kształcenia we wczesnym okresie jego życia.
Wiktor żył około 40 lat, co w tej epoce nie było niczym niezwykłym.  Wiedza zdobyta w trakcie jego kształcenia została wykorzystana przez Edwarda Seguina, a następnie przez Marię Montessori, której metoda nauczania dzieci normalnych przez zaangażowanie wszystkich ich zmysłów na równi z intelektem rozwinęła się z jej wcześniejszych prac z upośledzonymi umysłowo. Trwałe znaczenie prac doktora Itarda wykracza zatem poza postawiony sobie przez niego konkretny cel - „ucywilizowania dzikusa z Aveyronu” - ukazując nam, jak przedwczesny był jego wniosek, sformułowany po jednym z niepowodzeń: „Ponieważ moja praca idzie na marne, a twoje wysiłki są bezowocne, wracaj do swojej puszczy i do swojego zamiłowania do prymitywnego życia” (s. XVII).


Testy inteligencji. Największe postępy w doskonaleniu testów osobowości osiągnięto w odniesieniu do pomiaru inteligencji.
Testy inteligencji początkowo były pomyślane jako demokratyczne narzędzia mające umożliwić uzdolnionym dzieciom przechodzenie na wyższe szczeble publicznego systemu kształcenia jedynie na podstawie uzyskiwanych wyników w obiektywnym teście i chroniące je przed subiektywnymi uprzedzeniami nauczycieli. Obecnie psychologowie pracują nad usunięciem innych źródeł stronniczości oceny, które wkradają się do konstruowania, stosowania i określania wartości testów inteligencji. Realna wartość takich testów polega na tym, że pozwalają nam one stwierdzić, jak wyniki uzyskane przez dane dziecko przedstawiają się w porównaniu z normami opracowanymi dla grupy dzieci, która jest najbardziej podobna do badanego dziecka - pod względem języka, środowiska kulturowego i społeczno-ekonomicznego, możliwości kształcenia i ogólnych form doświadczenia życiowego - w celu ustalenia oddziaływań pedagogicznych najbardziej korzystnych w jego przypadku na określonych stadiach rozwoju.


„Pierwsza skala Bineta”. W 1904 minister oświaty publicznej we Francji utworzył komisję, złożoną z lekarzy, pedagogów, uczonych i urzędników państwowych, w celu zbadania problemu uczenia dzieci opóźnionych umysłowo w szkołach publicznych. W ramach tej komisji ważną pracę wykonali: Alfred Binet, uczony reprezentujący młodą wówczas naukę - psychologię, oraz lekarz Teodor Simon. W odróżnienia od Itarda byli oni przekonani, że zanim będzie można opracować program nauczania, konieczne jest wypracowanie pewnego sposobu mierzenia inteligencji dzieci, którymi się zajmowali.
Binet i Simon przygotowali test inteligencji zawierający sytuacje problemowe, którego wyniki można było obliczyć w sposób obiektywny; sytuacje te były różnego rodzaju, różnice środowiskowe miały niewielki wpływ, a ich rozwiązywanie wymagało raczej zdolności oceniania i rozumowania, a nie jedynie mechanicznej pamięci.
Binet przedstawia wyniki swych testów dla umysłowo opóźnionych dzieci w kategoriach wieku, w jakim prawidłowo rozwinięte dzieci potrafią uzyskać analogiczny wynik. Wynik ten nazwano |wiekiem |umysłowym dziecka. Gdy wynik jakiegoś dziecka w teście był równy średniej arytmetycznej wyników pięciolatków, to mówiono, że wiek umysłowy tego dziecka wynosi pięć lat - bez względu na to, jaki był jego wiek rzeczywisty (wiek życia).
Szerokie zastosowanie przez Bineta testów inteligencji wykazało jednoznacznie, że inteligencja jest cechą pozwalającą się stopniować.  Wyniki większości ludzi skupiają się wokół średniej, a jednocześnie nie ma żadnej luki pomiędzy człowiekiem tępym, przeciętnym i bystrym. Ten |rozkład |normalny wyników przedstawiony jest poniżej.




Zbliżenie


Krzywa „normalna”


„Wykres zamieszczony na rycinie 10.14 przedstawia rozkład wyników, jakiego należałoby oczekiwać, jeśli u tysiąca przypadkowo dobranych osób dokonałoby się pomiarów ciężaru ciała, ilorazu inteligencji czy innych ciągłych cech.



Każda kropka reprezentuje wynik określonej jednostki. Linia podstawy, czyli |oś |pozioma, przedstawia różne wielkości tego, co się mierzy, na przykład różne wielkości I.I; |oś |pionowa pokazuje, ile osób posiada daną cechę w określonym stopniu, którego miarą jest uzyskany przez nie wynik.


Zwykle pokazuje się tylko krzywą wypadkową, ponieważ określa ona częstość z jaką występowała każda wielkość danego wskaźnika. Rzeczywiste krzywe są jedynie przybliżeniem krzywej hipotetycznej, lecz zbliżają się do niej znacznie w przypadku bardzo dużych próbek.


Krzywa ta jest bardzo przydatna dla psychologów, ponieważ wiedzą oni, że w dużej, losowo dobranej grupie na dany segment rozkładu będzie przypadał stały procent przypadków. Na przykład, jeśli dana cecha ma rozkład normalny, to 68,2% przypadków zmieści się w środkowej, trzeciej części całego zakresu wyników.
Odchylenie standardowe, jak wspomnieliśmy w Rozdziale 1, jest miarą zmienności wyników. Wskazuje ono typową wielkość, o którą wyniki różnią się od średniej. Im bardziej rozproszone są wyniki, tym większe będzie odchylenie standardowe. Większość wyników w tym rozkładzie przypada między trzema standardowymi odchyleniami powyżej średniej i trzema standardowymi odchyleniami poniżej niej, lecz zwykle w rzeczywistym rozkładzie nieco wyników będzie niższych i nieco wyższych.
Odległość odchylenia standardowego od średniej można zaznaczyć wzdłuż linii podstawy tej krzywej, jak to uczyniono na rycinie 10.15. Ponieważ odchylenia standardowe są równo rozmieszczone wzdłuż całego zakresu wyników, przeto są one dogodnymi punktami podziału przy klasyfikacji.  Dalsze wyjaśnienia dotyczące odchylenia standardowego i zastosowania zarówno tej miary, jak i krzywej normalnej, możesz znaleźć w Dodatku”.


Jak wyglądała skala Bineta? Dobre pojęcie o niej dają poniższe przykłady dotyczące umiejętności oczekiwanych od prawidłowo rozwiniętych osób w różnym wieku (Binet i Simon, 1911).


„Trzy lata: Potrafi na żądanie wskazać nos, oczy i usta.
Pięć lat: Potrafi policzyć cztery monety.
Siedem lat: Potrafi pokazać prawą rękę i lewe ucho.
Dziewięć lat: Potrafi zdefiniować znane słowo nie ograniczając się do podania zastosowań; to znaczy podaje, w jaki sposób słowo to wiąże się z innymi pojęciami.
Dwanaście lat: Stosuje trzy podane mu słowa w jednym zdaniu.
Dorosły: Podaje trzy różnice miedzy prezydentem a królem”.


Gdy coraz więcej dzieci badano testami i coraz więcej ich poddawano powtórnemu badaniu, to po upływie pewnego czasu stwierdzono, iż dzieci opóźnione umysłowo zwykle pozostają coraz bardziej w tyle za ogółem dzieci, w miarę jak stają się coraz starsze. Na przykład czteroletnie dzieci o wieku umysłowym równym trzy lata, w wieku lat ośmiu będą prawdopodobnie miały wiek umysłowy wynoszący jedynie sześć lat. Chociaż więc stosunek między wiekiem umysłowym i wiekiem życia pozostaje bez zmiany (3\4 =6\8), to jednak ogólne opóźnienie wzrosło od jednego roku do dwóch lat.
Toteż już we wczesnym okresie rozwoju testów inteligencji psychologowie przyjęli zwyczaj wyrażania stosunku między wiekiem umysłowym, czyli wiekiem inteligencji (W.I.) a wiekiem (W.Ż.) w postaci proporcji (Stern, 1914).  Proporcja ta znana jest pod nazwą |ilorazu |inteligencji (I.I.) i oblicza się ją jak następuje:
I.I. = W.I 8W.Ż razy 100



Jeśli dziecko, które ma osiem lat (W.Ż. = 8) uzyskało w teście wynik taki, jaki powinno uzyskać dziecko dziesięcioletnie (W.I. = 10), to I.I.  będzie równy 10/8 razy 100, czyli 125 (mnożenie przez sto pozwala wyeliminować ułamki). Jeśli W.Ż. dziecka wynosi 10 lat, a W.I. wynosi 8 lat, to I.I. będzie równy 8/10, czyli 80. Gdy dana osoba uzyskuje wyniki, przy których jej wynik inteligencji równy jest wiekowi życia (W.I. = W.Ż.), to I.I. tej osoby wynosi 100 - jest to „normalny”, czyli „przeciętny I.I.


„Stanfordzka wersja testów Bineta”. Pojęcie I.I. zostało wykorzystane przy opracowywaniu testów inteligencji przez L. M. Termana ze Stanford University, który zbadał prawie 3000 dzieci skalą Bineta i innymi testami.  Uporządkował on te testy według poziomów wieku umysłowego i w 1916 opublikował stanfordzką wersję testów Bineta powszechnie znaną jako |Stanford-|Binet, która wkrótce stała się standardowym narzędziem w psychologii klinicznej, psychiatrii i poradnictwie pedagogicznym.
W roku 1937 Terman i Maud A. Merrill opublikowali poprawione wydanie testu Stanford-Bineta (Terman i Merrill, 1937). Ta nowa wersja miała na celu skorygowanie niedogodności i braków poprzedniej skali w sposób następujący:
1. Rozbudowano test w górnym zakresie skali inteligencji, tak aby można wykrywać różnice między dorosłymi o wysokiej inteligencji.
2. Wprowadzono testy umożliwiające badanie dzieci, które ukończyły zaledwie dwa lata życia. Dla dzieci w wieku od dwóch do pięciu lat, to jest w okresie, gdy rozwój umysłowy jest bardzo szybki, zapewniono zestawy testów w odstępach półrocznych, a dla dzieci starszych - w odstępach rocznych.
3. Skala z 1937 roku zawierała dwa komplety podobnych materiałów (wersje równoległe), aby wówczas, gdy niezbędne jest przeprowadzenie retestu, psycholog nie potrzebował troszczyć się o wpływ ćwiczenia, wynikający z dwukrotnego badania tym samym testem.
W miarę upływu czasu nawet najstaranniej skonstruowany test staje się przestarzały i wymaga rewizji. Odnosi się to zwłaszcza do testów werbalnych, ponieważ znaczenie słów zmienia się, a słowa uprzednio rzadkie nagle uzyskują wysoką popularność. Słownik dziecka czy osoby dorosłej w obecnych czasach, ukształtowany pod wpływem telewizji i wypraw kosmicznych, różni się bardzo od słownika osób, które badano w czasie, gdy po raz pierwszy wprowadzono testy inteligencji. Na przykład w wydaniu testu Stanford-Bineta z roku 1916 „Mars” był bardzo trudnym słowem dla dzieci, równie trudnym jak słowo „conscientious” (sumienny, skrupulatny - Terman, 1916). W wydaniu z 1937 roku słowo to było bardziej znane, nie trudniejsze niż słowo „skill” (umiejętność - Terman i Merrill, 1937). W końcu lat pięćdziesiątych, gdy wyprawy kosmiczne były codziennym przedmiotem rozmów, nazwa tej planety stała się mniej więcej tak znana, jak będące w codziennym użytku słowo „eyelash” (rzęsa - Terman i Merrill, 1960). Test Stanford-Bineta został ponownie skorygowany w roku 1960.


„Testy wykonaniowe”. Nawet wersja testu Stanford-Bineta z roku 1960, chociaż mierzy ona w pewnym stopniu również inne zdolności, jest testem opartym przede wszystkim na posługiwaniu się słowami lub na zdolności do myślenia i porozumiewania się za pomocą języka pisanego. W przypadku dziecka głuchego lub dziecka, które nie pochodzi z rodziny mówiącej po angielsku, test Stanford-Bineta nie daje zatem często sprawiedliwego wyniku.
W tej sytuacji konieczne było opracowanie testów zwanych testami wykonaniowymi, w których reakcje słowne zastępuje się reakcjami ruchowymi.  Niekiedy nawet instrukcje podaje się bez użycia mowy. Testy wykonaniowe zawierają takie zdania, jak tak zwane |wkładanki („form boards”), to jest deski z różnymi otworami, do których osoba badana musi dopasować klocki właściwego kształtu i wielkości, tak szybko, jak potrafi; |testy |uzupełniania |obrazków („picture completion tests”), w których badany patrzy na niekompletny obrazek i rozstrzyga, która z kilku przedstawionych części w sposób najbardziej sensowny będzie pasować do pustego miejsca; 
|testy |dopasowania („matching test”), w których klocki lub inne przedmioty trzeba ułożyć w taki sposób, by były one zgodne z pewnym wzorem przedstawionym jako model.


„Wais oraz Wisc”. Wechsler Adult Inteligence Scale (Skala Inteligencji dla Dorosłych Wechslera; Wechsler, 1955) oraz Wechsler Inteligence Scale for Children (Skala Inteligencji dla Dzieci Wechslera, Wechsler, 1949) składają się z testów werbalnych i testów wykonaniowych.  WAIS oraz WISC są do siebie podobne w treści, a różnią się głównie poziomem trudności. Skala WISC została znormalizowana dla dzieci w wieku od 2 do 15 lat. Skala WAIS jest przeznaczona dla osób w wieku lat 16 i starszych. Oba testy składają się z dwóch części - werbalnej i wykonaniowej. Część werbalna obejmuje testy wiadomości ogólnych, rozumienia, słownikowe, podobieństwa między słowami, arytmetyczne oraz zakresu pamięci (powtarzanie za badającym szeregu cyfr).
Część wykonaniowa także zawiera różne testy. W teście układania wzorów z klocków osoba badana stara się odtworzyć wzory pokazane na kartach, dopasowując do siebie barwne klocki, w których każda z sześciu powierzchni jest inna. W teście podporządkowania obrazków zadanie polega na ułożeniu szeregu obrazków we właściwej kolejności, tak aby przedstawiały one sensowną historyjkę.




* * *



Ryc. 10.16. Profile Zdolności Intelektualnych, Typowe Dla Różnych Zwodów
Profile zdolności: Naukowiec, matematyk - Inżynier - Przedstawiciel 
handlowy - Księgowy
Werbalne: 98 - 90 - 85 - 90
Liczbowe: 99 - 98 - 80 - 95
Percepcyjne: 95 - 85 - 80 - 95
Przestrzenne: 85 - 90 - 60 - 70
Rozumowanie: 95 - 85 - 80 - 85
Płynność: 85 - 80 - 70 - 70
(Za zezwoleniem Psychological Services, Inc., 1963)


Inne testy wykonaniowe to labirynty (zastosowane jedynie w WISC), wykrywanie, czego brakuje na poszczególnych obrazkach, składanie przedmiotów z elementów oraz szyfrowanie.


Podstawowe zdolności umysłowe. Chociaż niewątpliwie jest wiele sytuacji, w których przydatna jest znajomość ogólnego poziomu inteligencji danej osoby, określonego za pomocą ilorazu inteligencji, to jednak współczesne badania wykazały, że „inteligencja ogólna” reprezentowana wynikiem w postaci I.I., w rzeczywistości składa się z szeregu „inteligencji specjalnych”, czyli |zdolności |podstawowych, które są względnie niezależne od siebie. U dwóch ludzi, którzy uzyskali ten sam I.I. może występować bardzo różny układ specyficzny zdolności i deficytów: jedna osoba może odpowiadać najlepiej na pytania wymagające rozumowania słownego i abstrakcyjnego, inna zaś najlepiej rozwiązuje zadania wymagające pamięci i sprawności motorycznej. Rycina 10.16 przedstawia profile sześciu podstawowych zdolności umysłowych w układzie typowym dla różnych zawodów.


Znaczenie I.I. dla zachowania. Jaka jest osoba, która ma I.I. równy 100? 
Co osoba ta potrafi zrobić takiego, czego nie potrafi wykonać osoba mająca 
I.I. równy 70? Wykwalifikowani psychologowie, jak również nauczyciele i lekarze mający do czynienia z przypadkami odbiegającymi od normy, kojarzą się różne wartości I.I. z określonymi obrazami zachowania adaptacyjnego.

Konstruktorzy różnych testów sugerują rozmaite klasyfikacje I.I., zwykle w postaci kategorii, z których każda obejmuje pewien zakres ilorazów inteligencji. Znaczna większość ludzi ma I.I. w granicach od 84 do 116 na skali Stanford-Bineta i uważa się ich za osoby posiadające |przeciętną inteligencję. Poniżej tego jest przedział, który określa się jako |ociężałość |umysłową lub jako |granicę |normy; osoby należące do tego przedziału nie osiągają dobrych wyników w szkole, lecz mogą skończyć osiem klas i zwykle potrafią się same utrzymywać. Osoby z I.I. poniżej 68 klasyfikuje się zwykle jako |upośledzone |umysłowo, chociaż wiele z nich może utrzymywać się samodzielnie, podczas gdy niektórzy ludzie z I.I.  powyżej 68 przebywają w zakładach.
Osoby mające iloraz inteligencji |powyżej przeciętnego klasyfikuje się jako osoby o |wysokiej inteligencji; mogą one zostać prawnikami, inżynierami, nauczycielami itd. Osoby mające I.I. powyżej 132 są |szczególnie uzdolnione; stanowią one grupę o najwyższych możliwościach, jeśli chodzi o osiągnięcia akademickie i abstrakcyjne myślenie.
Są to jedynie przybliżone klasyfikacje, oparte na wynikach w teście, który mierzy przede wszystkim zdolności potrzebne do pracy szkolnej.  Poziom, na którym poszczególne jednostki funkcjonują w rzeczywistości, zależy także od wielu innych czynników, takich jak ich motywacja, nawyki pracy, stawiane im wymagania, ich pogląd na własne zdolności oraz stopień, w jakim minione doświadczenia rozwinęły ich potencjalne możliwości.




Streszczenie rozdziału




|Osobowość można zdefiniować jako „ogólną sumę tych sposobów reagowania na innych ludzi (i obiekty) oraz sposobów wchodzenia z nimi w interakcje, które są charakterystyczne dla danej jednostki”. W badaniach nad osobowością chodzi o wyjaśnienie zarówno podobieństw, jak i różnic pomiędzy jednostkami. Charakteryzujemy innych na podstawie stałości ich zachowania i prawdopodobnie skłonni jesteśmy spostrzegać w ich zachowaniu większą |stałość niż ta, jaka w rzeczywistości występuje.
Wszyscy opisujemy ludzi, z którymi mamy do czynienia, na podstawie |naiwnych |teorii |osobowości stworzonych metodą prób i błędów. Istnieją liczne, bardziej usystematyzowane, formalne teorie osobowości, wśród nich |teoria |freudowska i |teorie |neofreudowskie (|psychoanalityczne), |teorie |pola, |teorie |czynnikowe oraz |teorie |uczenia |się.
Freud kładł wielki nacisk na wczesne doświadczenia, będąc przekonany, że wszystkie podwaliny osobowości człowieka dojrzałego (a także anomalii psychicznych) zostają położone w dzieciństwie. Wyróżnił on pięć stadiów |rozwoju |psychoseksualnego (|stadium |oralne, |analne, |falliczne, |stadium |latencji oraz |stadium |genitalne), których podstawą są instynktowne popędy biologiczne oraz interakcja z rodzicami.
Według teorii Freuda, wszelkie zachowania są (nieświadomie) aktywizowane przez dwa podstawowe popędy: |Eros (instynkt „seksualny”, czyli „instynkt życia”) oraz |Tanatos (instynkt „agresywny”, czyli „instynkt śmierci”).  Energia, która stanowi podłoże Erosa, nosi nazwę |libido. Według Freuda, osobowość składa się z trzech części: |id („magazynu” podstawowych popędów), |superego („sumienia”) oraz |ego, które pełni funkcje arbitra i dokonuje oceny rzeczywistości. Ego często czyni użytek z nieświadomych |mechanizmów |obronnych, których nadużywanie powoduje nerwicę.
Nawet poważne zaburzenia zachowania uważa się za przejaw procesów nieświadomych, ponieważ zgodnie z |zasadą |determinizmu |psychicznego, każde zachowanie, bez względu na to, jak bardzo irracjonalne mogłoby się wydawać, ma swoje |przyczyny. Największym wkładem Freuda w badanie osobowości było podkreślenie znaczenia: a) |procesów |nieświadomych, b) |popędu |seksualnego oraz c) |doświadczeń |z |okresu |dzieciństwa.
Przedstawiciele |teorii |neofreudowskich, tacy jak Jung i Adler, kładli mniejszy nacisk na rolę popędu seksualnego podkreślając natomiast znacznie innych podstawowych popędów lub oddziaływań społecznych.
Erik Erikson rozwinął koncepcję stadiów psychoseksualnych Freuda, wprowadzając pojęcie |stadiów |psychospołecznych. Postulował on istnienie 8 stadiów rozwoju, charakteryzujących się dominującymi w nich konfliktami.  Wyróżnił następujące stadia: |zaufanie „versus” |nieufność, |autonomia „versus” |zwątpienie, |inicjatywa „versus” |poczucie |winy, |pracowitość „versus” |poczucie |niższości, |tożsamość „versus” |przemieszanie |ról, |intymność „versus” |izolacja, |wielkoduszność „versus” |zaabsorbowanie |sobą oraz |poczucie |spełnienia „versus” |rozpacz.
Harry Stack Sullivan także kładł nacisk na doniosłe znaczenie interakcji społecznej. Wprowadził on pojęcie |dynamizmu (długotrwały, powtarzający się wzorzec zachowania, taki jak |system |ja) i |personifikacji (naszego wyobrażenia o innych).
Zwolennicy |teorii |pola uważają, że osobowość i zachowanie są kształtowane przez równowagę i interakcję wielu sił. Teoria |organizmu |jako |całość Goldsteina kładzie nacisk na rozwijanie się wrodzonych potencjalnych możliwości organizmu jako całości, aktywizowanych przez podstawowy popęd |samorealizacji. Teoria |własnego „|ja” Rogersa kładzie nacisk na |pole |fenomenologiczne - osobisty świat jednostki. |Pojęcie |o |sobie |samym rozwija się u danej jednostki w wyniku jej interakcji ze środowiskiem i stara się ona zachowywać w sposób zgodny z tym pojęciem o sobie.
W swej |teorii |samorealizacji Maslow położył nacisk na problem osób zdrowych emocjonalnie. Zgodnie z tą teorią potrzeby ludzkie tworzą hierarchię -od potrzeb fizjologicznych przez potrzeby bezpieczeństwa, potrzeby przynależności i miłości, potrzeby szacunku oraz potrzeby samorealizacji, aż do potrzeby transcendencji. Dopiero wtedy, gdy potrzeby na niższych poziomach są zaspokojone, jednostka może swobodnie zajmować się zaspokajaniem potrzeb na wyższych poziomach.
Zwolennicy |teorii |czynnikowych wykorzystują w swej pracy technikę statystyczną, zwaną |analizą |czynnikową, starając się zidentyfikować specyficzne |cechy osobowości. Guilford wyróżnił dwa odmienne typy cech: 
|czynniki |hormetyczne (motywacyjne) i |czynniki |temperamentalne.  Zastosował on również techniki analizy czynnikowej do zbadania inteligencji, konstruując trójwymiarowy model |struktury |intelektu.  Behawioryści społeczni, tacy jak Mischel, twierdzą, że stałość zachowania wynika raczej z podtrzymujących i wzmacniających warunków środowiskowych niż z trwałych cech jednostki.
Zwolennicy |teorii |uczenia się stanowią wśród teoretyków osobowości grupy badaczy najbardziej zainteresowanych eksperymentalnym podejściem do tematu. Dollard i Miller zaczęli od nadania freudowskim pojęciom formy bardziej nadającej się do badań eksperymentalnych; badali oni relację pomiędzy |popędem, |sygnałem, |reakcją i |wzmocnieniem. Teoria |społecznego |uczenia |się Bandury podkreśla znacznie procesów samoregulacyjnych i uczenia się przez obserwację, w czasie którego dana osoba uczy się obserwując zachowania |modelu.
Niektórzy psychologowie badający różnice indywidualne przyjmują podejście |nomotetyczne, studiując podobieństwa między jednostkami. Inni wybierają podejście |idiograficzne, utrzymując, że każda jednostka jest czymś więcej niż sumą pewnej liczby części. W badaniach nad osobowością |przewidywania |statystyczne, jak dotąd, okazały się trafniejsze niż |przewidywania |kliniczne.
Nasze |pojęcie |o |sobie jest w głównej mierze wytworem interakcji z innymi. Jesteśmy skłonni przyjmować wyobrażenia, które inni ludzie mają o nas, i oceniać nasze zachowanie dokonując porównań społecznych. |Kryzysy |tożsamości powstają wtedy, gdy nasz „stary” pogląd na siebie przestaje być odpowiedni w naszej zmieniającej się sytuacji życiowej, jak na przykład w wieku dorastania lub w wieku średnim. Do |czynników |rozwojowych, które wpływają na różnice osobowościowe, należy rozwój moralny, w którym można zidentyfikować 6 różnych stadiów, oraz uczenie się roli związanej z płcią.
Zmienną osobowością, która ostatnio jest przedmiotem wielu badań, jest |wewnętrzna lub |zewnętrzna |lokalizacja |kontroli. „Internaliści” przypisują sobie posiadanie większej kontroli nad swym otoczeniem niż „eksternaliści” i są mniej skłonni do przejawiania wyuczonej bezradności.  Ograniczenia społeczno-ekonomiczne mogą być czynnikiem wpływającym na powstawanie przekonania o zewnętrznym umiejscowieniu kontroli.
Badacze zidentyfikowali stałą cechę, określoną mianem |makiawelizmu; wiąże się ona z umiejetnością pewnego rodzaju oddziaływania społecznego, znanego jako „manipulowanie” innymi w pewnego typu sytuacjach. Osoby wykazujące tę cechę w |wysokim |stopniu doskonale czują się w sytuacjach „twarzą w twarz”, w sytuacjach, gdy reguły i wytyczne odgrywają minimalną rolę i gdy inni ludzie są pobudzeni emocjonalnie.
Terminu |osobowość |autorytarna używa się dla określenia osób, które uzyskują wysokie wyniki na skalach mierzących |antysemityzm, |konserwatyzm |polityczny |i |ekonomiczny oraz |postawy |faszystowskie. Osoby takie wykazują zwykle uprzedzenia wobec członków wszystkich obcych grup oraz okazują większy respekt i uległość w stosunku do autorytetów niż osoby uzyskujące niskie wyniki na tych skalach.
„Nieśmiali” studenci różnią się od „śmiałych” przede wszystkim tym, że pewne zachowania i odczucia przypisują własnej „nieśmiałości”. Studenci, którzy nie uważają się za nieśmiałych, doświadczają wielu takich samych uczuć, lecz przypisują je czynnikom sytuacyjnym, a nie wewnętrznym.
Testy przeznaczone do pomiaru osobowości stosuje się zwykle w jednym z trzech celów: a) dla |przewidywania |powodzenia w szkole lub pracy, b) dla |ustalenia |sposobu |postępowania pedagogicznego lub terapeutycznego, c) dla |wzbogacenia |naszej |wiedzy o ludzkim zachowaniu. Narzędzie psychometryczne, aby było najbardziej dokładne i użyteczne, musi być |trafne, |rzetelne, |obiektywne |i |znormalizowane na grupie osób reprezentatywnej dla tej populacji, dla której jest ono przeznaczone.
Dokładny pomiar zachowania wymaga standaryzacji sytuacji i narzędzi pomiarowych, jak w wypadku |skal |i |ocen; jednakże wyniki uzyskiwane na tych skalach obarczone są błędami spowodowanymi takimi zjawiskami, jak |efekt |halo i wpływ |stereotypów. Techniki |pobierania |próbek zachowania polegają na obserwowaniu zachowania osoby badanej w jakiejś typowej sytuacji, czy to naturalnej, czy symulowanej. Często stosowaną techniką jest |wywiad; |wywiady |standaryzowane zmniejszają możliwość wystąpienia błędów w ocenie.


|Techniki |projekcyjne, takie jak test Rorschacha i Test Apercepcji Tematycznej polegają na prezentowaniu wieloznacznych lub neutralnych bodźców i ustalaniu, jakie znaczenie osoba badana na nie „rzutuje”. Innym, często stosowanym narzędziem pomiarowym jest |kwestionariusz |osobowości.  Pionierami testów inteligencji, byli na początku bieżącego stulecia we Francji, Simon i Binet. Testy te opierają się na porównywaniu poziomu funkcjonowania intelektualnego danej jednostki z poziomem innych osób w tym samym wieku. |I.|I., czyli |iloraz |inteligencji wskazuje, jaki jest stosunek |wieku |umysłowego do |wieku |życia. Trzy najpowszechniej stosowane testy inteligencji ogólnej to test Stanford-Bineta, który składa się przede wszystkim z testów werbalnych oraz skale Wechslera (jedna dla dorosłych i jedna dla dzieci), z których każda zawiera zarówno testy werbalne, jak i wykonaniowe. Inteligencja nie jest pojedynczą zdolnością, lecz obejmuje szereg |podstawowych |zdolności |umysłowych, które starają się zidentyfikować zwolennicy analizy czynnikowej. Przyjmuje się, że osoby, które w teście Stanford-Bineta uzyskują I.I. pomiędzy 84 a 116, mają inteligencję przeciętną. Jednakże osiągnięcia osoby o danym I.I. zależą również od wielu czynników pozaintelektualnych.




Z Frontu Badań.
Androgynia psychiczna
a tożsamość płciowa




|Sandra |Lipsitz |Bem „Stanford University”


Dla większości ludzi, zarówno dorosłych jak i dzieci, świadomość przynależności do płci męskiej lub żeńskiej stanowi bardzo istotny aspekt ich pojęcia o sobie samym. Aby sprawdzić, czy twierdzenie to dotyczy również ciebie, spróbuj wyobrazić sobie, jak byś się czuł, gdybyś spojrzawszy jutro rano w lustro przekonał się, że w sposób nagły i cudowny zmieniłeś płeć. Jaki byłby twój stosunek do siebie samego, do twojego sposobu odnoszenia się do innych ludzi i do sposobu, w jaki inni ludzie odnoszą się do ciebie? Czy nadal miałbyś te same cele życiowe, te same zainteresowania, te same przyjaźnie, w taki sam sposób poruszałbyś się, w taki sam sposób wyrażał gniew, smutek czy radość, czy nadal miałbyś to samo poczucie tożsamości? Czy zdarzenie to stanowiłoby tylko fizyczną zmianę w twoim ciele (zmianę, do której przystosowanie się wymagałoby oczywiście, trochę czasu), czy też wymagałoby ono głębokiej zmiany w twym pojęciu o sobie, a może nawet w twoim zachowaniu? Podejrzewam, że to ostatnie stwierdzenie byłoby prawdziwe w odniesieniu do większości ludzi.
Dla wielu ludzi fakt, że są męscy lub kobiecy również stanowi bardzo istotny aspekt pojęcia o sobie. W społeczeństwie amerykańskim oczekuje się, że mężczyźni powinni być męscy, kobiety - kobiece, a żadna z płci nie powinna być zbyt podobna do drugiej. Mężczyźni powinni być szorstcy, dominujący i nieustraszeni, kobiety zaś mają być łagodne, współczujące i wrażliwe na potrzeby innych. Jeśli mężczyzna delikatnie i czule opiekuje się swym maleńkim dzieckiem lub woli balet od piłki nożnej, to jego męskość zostanie zakwestionowana; podobnie zostanie zakwestionowana kobiecość kobiety, która w agresywny sposób broni swych klientów w sądzie lub która odmawia podporządkowania się życzeniom swego męża. W społeczeństwie amerykańskim męskość i kobiecość uważa się za biegunowe przeciwieństwa i dlatego osoba, która zapuszcza się na terytorium drugiej płci, podejmuje pewne ryzyko. Nawet standardowe testy psychologiczne męskości i kobiecości odzwierciedlają ten sposób ujęcia: osoba badana może uzyskać wynik świadczący o jej męskości bądź kobiecości, lecz większość testów nie pozwala stwierdzić, że jest ona zarówno męska, jak i kobieca.
W zasadzie dana osoba może być oczywiście |zarówno męska, jak i kobieca.  Dziecko może bawić się zarówno samochodzikami, jak i lalkami; dorastający chłopiec czy dziewczyna mogą grać w koszykówkę między garażami, a także zarabiać pomagając w miejscowym szpitalu; pan lub pani mecenas może w agresywny sposób bronić swoich klientów w sądzie, a potem w domu kochająco czule opiekować się niemowlęciem. W zasadzie dana osoba może także łączyć w pojedynczym akcie te komplementarne sposoby odnoszenia się do świata. Na przykład, kierownik lub kierowniczka może krytykować postępowanie pracownika otwarcie, lecz zarazem delikatnie i ze zrozumieniem. Pojecie dwupłciowości, czyli androgynii (z greckiego „andro” - mężczyzna i „gyne” - kobieta), odnosi się właśnie do tego połączenia zachowań i cech osobowości, które tradycyjnie uważa się za męskie lub kobiece. Zgodnie z tą definicją, jednostką androgyniczną jest zatem ktoś, kto jest |zarówno niezależny, jak i opiekuńczy, |zarówno agresywny, jak i łagodny, |zarówno stanowczy, jak i uległy, |zarówno męski, jak i kobiecy, zależnie od stosowności tych różnych zachowań w danej sytuacji.
Czy jednak androgyniczni ludzie naprawdę istnieją? I czy w jakimś sensie są oni w lepszej sytuacji niż ludzie, którzy nie są androgyniczni? Celem moich badań w ciągu ostatnich kilku lat była próba wykazania, że a) tradycyjne role związane z płcią ograniczają zachowanie ludzi pod wieloma ważnymi względami oraz, że b) androgynia psychiczna znacznie rozszerza zakres otwartych dla każdego zachowań. Moim zdaniem, koncepcja androgynii jest bardzo atrakcyjna, przede wszystkim dlatego, że obie te sfery- męskość i kobiecość - są równie fundamentalne. We współczesnym złożonym społeczeństwie, takim jak społeczeństwo amerykańskie, dorosła osoba musi oczywiście umieć polegać na sobie i realizować swe cele, lecz z drugiej strony, musi także dostrzegać człowieczeństwo innych istot ludzkich, być wrażliwa na ich potrzeby i troszczyć się o ich dobro, jak również musi umieć oczekiwać od nich emocjonalnego oparcia. Wydaje się więc, że warunkiem w pełni efektywnego funkcjonowania człowieka jest całkowite zignorowanie jego męskości i kobiecości w bardziej zrównoważoną, pełniejszą, prawdziwie androgyniczną osobowość. 
Aczkolwiek nie przeprowadzano wcześniej badań, które odnosiłyby się bezpośrednio do pojęcia androgynii, to jednak istnieje już obszerny materiał dowodowy świadczący o tym, że występowanie wyraźnie ukształtowanych cech psychicznych związanych z płcią („sex-typing”) nie zawsze jest pożądane. Na przykład, wysoki wskaźnik kobiecości u kobiet jest z reguły skorelowany z wysokim poziomem lęku, niską samooceną i jednocześnie z niską akceptacją społeczną. A chociaż wysoki wskaźnik męskości u chłopców koreluje w okresie dorastania z lepszym przystosowaniem psychicznym, to jednak w wieku dojrzałym jest on skorelowany z wysokim poziomem lęku, wysoką neurotycznością i niską samoakceptacją. Ponadto wyższy poziom rozwoju intelektualnego koreluje dość konsekwentnie z tak zwanym skrzyżowanym występowaniem cech psychicznych powiązanych z płcią („cross sex-typing”), to jest z męskością u dziewcząt i kobiecością u chłopców. Stwierdzono, że męscy chłopcy i kobiece dziewczęta mają |niską inteligencję ogólną, |mniejszą wyobraźnię przestrzenną i |mniejsze zdolności twórcze.




Badania nad androgynią




Aby móc dowiedzieć się czegoś o osobie androgynicznej, musiałam najpierw opracować nowy inwentarz ról związanych z płcią, taki, w którym męskość i kobiecość traktowałoby się jako dwa niezależne wymiary, a nie jako przeciwne krańce jednego wymiaru. Powstał w ten sposób BSRI - „Bem Sex Role Inventory” (Inwentarz Ról Związanych z Płcią, opracowany przez Bem), który uwzględnia dwadzieścia „męskich” cech osobowości (na przykład ambitny, łagodny, polegający na sobie, niezależny, stanowczy) i dwadzieścia „kobiecych” cech osobowości (na przykład uczuciowy, łagodny, rozumiejący, wrażliwy na potrzeby innych). Wybrałam te a nie inne cechy dlatego, że zarówno mężczyźni jak i kobiety stwierdzili, iż są one tymi, które w społeczeństwie amerykańskim są bardziej pożądane u jednej płci niż u drugiej. BSRI zawiera także dwadzieścia cech neutralnych (na przykład prawdomówny, beztroski, zarozumiały, niesystematyczny), które służą jako pozycje buforowe.
W teście tym cechy męskie, kobiece i neutralne pomieszano tworząc z nich jedną listę, a osobę badaną prosi się, aby zaznaczyła na skali od 1 („Nigdy lub prawie nigdy prawdziwe”) do 7 („Zawsze lub prawie zawsze prawdziwe”), w jakim stopniu każda z tych cech do niej się odnosi. Średnia liczba punktów przypisanych przez daną osobę cechom męskim stanowi jej wskaźnik męskości; średnia liczba punktów przypisanych przez daną osobę cechom kobiecym stanowi jej wskaźnik kobiecości.
Na podstawie tych dwóch wskaźników daną osobę klasyfikuje się następnie jako męską (wysoki wskaźnik męskości - niski wskaźnik kobiecości), kobiecą (wysoki wskaźnik kobiecości - niski wskaźnik męskości) lub adrogyniczną (wysoki wskaźnik męskości - wysoki wskaźnik kobiecości). Zgodnie z tą definicją ponad jedna trzecia mężczyzn i kobiet uczęszczających na wstępny kurs psychologii na Stanford University w 1975 roku, scharakteryzowała siebie jako osoba o „typowych” dla własnej płci cechach, jedna czwarta - w przybliżeniu - scharakteryzowała siebie jako osoby adrogyniczne, mniej zaś niż jedna piąta opisała siebie jako osoby o cechach psychicznych typowych dla przeciwnej niż własna płci. (Ci, którzy opisali siebie jako zarówno mało męskich, jak i mało kobiecych, nie będą omawiani w niniejszym artykule).


Unikanie zachowania typowego dla przeciwnej płci. Dysponując już inwentarzem BSRI, mogłem postawić pytanie, czy tradycyjne role związane z płcią rzeczywiście prowadzą niektórych ludzi do ograniczania swego zachowania - zgodnie ze stereotypami związanymi z płcią. Aby znaleźć odpowiedź na to pytanie, powiedziałam studentom, że potrzebne są nam fotografie tej samej osoby wykonującej wiele różnych czynności: otrzymane zdjęcia zestawiliśmy w trzydzieści par i poprosiliśmy, aby studenci z każdej pary wybrali tę czynność, którą woleliby wykonywać za zapłatą.  Niektóre z tych czynności były męskie (zbić ze sobą gwoździami dwie deski, przymocować sztuczną przynętę do haczyka wędki), niektóre kobiece (wyprasować serwetki, nawijać przędzę na kłębek), niektóre zaś neutralne (grać w jo-jo; obierać pomarańcze).
Przewidywaliśmy, że męscy mężczyźni i kobiece kobiety będą konsekwentnie odrzucać czynności typowe dla przeciwnej płci, |mimo |że |zawsze |płacono |więcej za ich wykonywanie. I mieliśmy słuszność. Osoby badane o „typowych” cechach swej płci o wiele częściej niż inne osoby unikały zachowań, nawet błahych, skojarzonych z płcią przeciwną. Co więcej, gdy rzeczywiście wymagano od nich wykonania kilku czynności typowych dla przeciwnej płci, wówczas męscy mężczyźni i kobiece kobiety odczuwali największy niepokój i czuli się najgorzej.


Niezależność i opiekuńczość. W świetle tych danych, wykazujących, że tradycyjne role związane z płcią istotnie ograniczają podejmowanie prostych, codziennych zachowań, ważnym staje się pytanie, czy tradycyjne role związane z płcią ograniczają również jednostkę w bardziej poważny sposób. A zwłaszcza, czy męscy mężczyźni wykazują niski stopień czułości i opiekuńczości? Czy kobiece kobiety wykazują małą niezależność? Czy androgyniczni mężczyźni i kobiety potrafią być |zarówno niezależni, jak i opiekuńczy? Wybrałam te właśnie zachowania, ponieważ sądzę, że są to najbardziej wartościowe cechy związane z męskością i kobiecością i ponieważ jestem przekonana, że cechy te są niezbędne da efektywnego funkcjonowania dorosłego człowieka.
W naszych badaniach nad niezależnością osoby badane proszono, aby oceniły szereg karykatur pod względem tego, jak bardzo są one zabawne. Jednocześnie osoby badane słuchały |nagranych |na |taśmie |magnetofonowej głosów osób, które podawały fałszywe oceny karykatur (były przekonane, że słuchają odpowiedzi innych badanych). Stwierdziliśmy, że „kobiecy” badani, zarówno mężczyźni, jak i kobiety, byli znacznie mniej niezależni w swych ocenach niż wszystkie inne osoby badane.
W naszym pierwszym badaniu nad opiekuńczością badanym studentom stworzono możliwość interakcji z sześciotygodniowym kotkiem. Przewidywaliśmy, że „męscy” badani będą słabiej reagować na kotka niż wszyscy inni. I mieliśmy słuszność; lecz jedynie w odniesieniu do mężczyzn! Wyniki uzyskane przez kobiety były zaskakujące. Podobnie jak androgyniczni mężczyźni, również androgyniczne kobiety reagowały bardzo silnie na kotka, natomiast kobiety „kobiece” reagowały znacznie |słabiej, a kobiety „męskie” zajęły miejsca pośrednie.
Ponieważ wydawało się możliwe, że „kobiece” kobiety mogą po prostu uważać zwierzęta za nieatrakcyjne, przeprowadziliśmy dwa dalsze badania nad opiekuńczością. Wykorzystaliśmy w nich rzeczywiste kontakty interpersonalne; sytuacje, w których wzbudzenie u osób badanych uczuć opiekuńczych było bardziej prawdopodobne. W jednym z tych badań dochodziło do interakcji z pięciomiesięcznym niemowlęciem, w drugim - z „samotnym, nieszczęśliwym” studentem (w rzeczywistości pomocnikiem eksperymentatora).  W obu tych badaniach stwierdziliśmy, że „męskie” osoby badane, zarówno mężczyźni jak i kobiety, były mniej wrażliwe czy opiekuńcze od pozostałych osób.




Podsumowanie




Rozpatrując wyniki wszystkich tych badań łącznie, jakie możemy wyciągnąć teraz wnioski o skutkach „typizacji” seksualnej i androgynii? Moim zdaniem, androgyniczni mężczyźni i kobiety doskonale funkcjonowali w tych badaniach.  Nie unikali jakiegoś zachowania tylko dlatego, że stereotypowo uważa się je za bardziej odpowiednie dla drugiej płci, a także potrafili być zarówno niezależni, jak i opiekuńczy. Natomiast „męscy” badani wykazywali małą opiekuńczość , a „kobiecy” badani - małą niezależność. Zarówno zatem u mężczyzn, jak i u kobiet „typizacja” seksualna (tzn. posiadanie cech typowych dla danej płci) rzeczywiście powoduje ograniczenia zachowania danej osoby, androgynia zaś istotnie rozszerza jej zakres możliwości.
Ponieważ przynajmniej jedna trzecia mężczyzn w wieku studenckim opisuje siebie jako „męskich”, jest zatem szczególnie przykre, że ci „męscy” mężczyni byli stosunkowo niewrażliwi i nieopiekuńczy w sytuacjach zaaranżowanych przez nas w celu rozbudzenia w nich czułości. Nie wiem, oczywiście, czy „męscy” mężczyźni nie chcieli po prostu jej okazywać, czy też byli zbyt zahamowani emocjonalnie, aby nawet doświadczyć tych delikatnych uczuć, które staraliśmy się u nich wywołać. W każdym jednak razie ich partnerzy w interakcji otrzymywali od nich mniej wsparcia emocjonalnego, niż uzyskiwaliby od innych.
Nie możemy oczywiście wyciągać wniosku, że męskość hamuje wszelką czułość u „męskich” mężczyzn. Oczywiście żadna z naszych sytuacji laboratoryjnych nie oddziaływała tak silnie, jak powiedzmy choroba dziecka czy też zachowania przyjaciela, któremu zdaje się grozić załamanie nerwowe. Możemy jednak wyciągnąć wniosek, że ich próg dla odczuwania czułości jest wyższy niż u wszystkich innych mężczyzn i kobiet, których obserwowaliśmy. I to jest już, jak sądzę, wystarczającym powodem do troski.


Tożsamość seksualna. Jak dotąd, w artykule tym z całym naciskiem chciałam wykazać, że posiadanie pojęcia o sobie samym (jako o jednostce „męskiej” bądź „kobiecej”) prowadzi przede wszystkim do ograniczenia zachowania, do zamykania się w więzieniu stereotypowej roli związanej z płcią. Zgodnie z powyższym sugerowałam, że najlepszym rodzajem tożsamości, jeśli chodzi o role związane z płcią, jest |nieutożsamianie |się z żadną z nich.
Lecz co można powiedzieć o naszej tożsamości jako mężczyzn lub kobiet?  Dla większości ludzi fakt, że |jest się mężczyzną lub kobietą, stanowi bardzo istotny aspekt ich pojęcia o sobie. Jeśli wszyscy mamy stać się androgyniczni psychicznie, to co pozostanie z naszego poczucia przynależności do płci męskiej lub żeńskiej?
Chciałabym stwierdzić, że nawet gdybyśmy wszyscy stali się androgyniczni psychicznie, to świat istot żywych nadal składałby się z dwóch płci, a podział na mężczyzn i kobiety nadal byłby jednym z pierwszych i najbardziej podstawowych podziałów, jakich uczyłyby się małe dzieci i nikt nie dorósłby nieświadomy swej płci czy choćby obojętny na nią. Ostatecznie, jeśli nawet ktoś jest androgyniczny psychicznie, to jego płeć nadal ma pewne głębokie implikacje |fizyczne.
Właśnie dlatego, że istnieją biologiczne „dane”, których nie można zmienić, chyba że za pomocą bardzo radykalnej operacji chirurgicznej, wydaje się mi, że niezbędnym warunkiem zdrowia psychicznego czy dobrego samopoczucia musi być posiadanie zdrowego poczucia własnej fizycznej męskości czy kobiecości. |Skłonna |jestem |natomiast |twierdzić, |że |zdrowe |poczucie |fizycznej |męskości |czy |kobiecości |obejmuje |niewiele |więcej, |niż |możność |odczuwania |całkowitego |zadowolenia |ze |swego |ciała, |takiego, |jakie |widzi |się |w |lustrze. Płeć człowieka decyduje ostatecznie o naturze jego ciała i dlatego powinien on umieć akceptować swoje ciało niemal bez zastanowienia, być z niego zadowolonym, a może nawet lubić je.
Lecz poza odczuwaniem zadowolenia ze swego ciała, płeć człowieka nie powinna mieć żadnego wpływu na jego wartość, zachowanie czy styl życia. Tak więc, aczkolwiek sugerowałabym, że kobieta powinna czuć się zadowolona z faktu, że może rodzić dzieci, jeśli chce, to jednak nie wynika stąd, że powinna ona chcieć rodzić dzieci, ani też, że powinna siedzieć w domu z dziećmi, które rodzi. Podobnie, aczkolwiek sugerowałabym, że mężczyzna powinien czuć się bardzo zadowolony z faktu, że ma członek, który jest zdolny do wzwodu, to bynajmniej nie wynika stąd, że mężczyzna powinien pełnić bardziej aktywną rolę w czasie stosunku seksualnego ani nawet, że jego partnerami seksualnymi powinny być koniecznie tylko kobiety.
Na koniec chciałabym stwierdzić, że zdrowe poczucie własnej fizycznej męskości czy kobiecości staje się bardziej prawdopodobne właśnie wtedy, gdy wyeliminuje się sztuczne ograniczenia płci i gdy człowiek ma w końcu możliwość być „własną” i jedyną w swoim rodzaju mieszanką temperamentów i zachowań. Gdy płeć przestanie pełnić funkcję więzienia, to wtedy i tylko wtedy będziemy zdolni zaakceptować jako bezsporny fakt, że jesteśmy mężczyznami albo kobietami, w dokładnie tym samym sensie, w jakim akceptujemy „jako dany” fakt, ze jesteśmy ludźmi. Wtedy i tylko wtedy będziemy zdolni uznać fakt naszej fizycznej męskości czy kobiecości za fakt tak oczywisty, i niekwestionowany, że rzadko zdarzy się nam myśleć o nim, stwierdzać, że jest on prawdą, obawiać się, że mógłby być zagrożony, lub życzyć sobie, aby było inaczej.


Podstawowy paradoks androgynii. Pojęcie androgynii psychicznej zdaje się ustanawiać pewien model zdrowia czy dobrego samopoczucia psychicznego, zarówno dla mężczyzn, jak i kobiet, który jest wolny od narzuconych kulturowo definicji męskości czy kobiecości (w sensie psychologicznym).  Jeśli bowiem istnieje jakiś ostateczny wniosek wynikający z pojęcia androgynii, to jest on równoznaczny ze stwierdzeniem, że |zachowanie nie powinno mieć żadnej płci.
Istnieje tu jednak pewien paradoks, ponieważ pojęcie androgynii zawiera pewną wewnętrzną sprzeczność i stąd zawarte są w nim zarodki jego własnej destrukcji, Jak wynika z analizy tego słowa, pojęcie androgynii zakłada, że męskość i kobiecość (w sensie psychologicznym) reprezentują odrębne elementy, które muszą być zintegrowane, jeśli osobowość człowieka ma być uwolniona z ograniczającego jej wolność więzienia stereotypowych ról związanych z płcią. Gdy jednak ten wniosek płynący z pojęcia androgynii zostanie w rzeczywistości przyswojony przez kulturę (jeśli w ogóle tak się stanie kiedyś), to pojęcia psychicznej męskości i kobiecości przestaną istnieć jako odrębne elementy. Gdy zatem androgynia stanie się rzeczywistością, to „pojęcie androgynii stanie się zbędne i będzie jedynie reliktem wcześniejszej ery szowinizmu płci (seksizmu).




Rozdział 11.
Dewiacja, patologia
i szaleństwo




To, co nieznane, niezwykłe, niewyjaśnione i tajemnicze, zawsze szczególnie fascynowało ludzi. Rzeczy takie pobudzają ciekawość, chęć poznania, zachęcają do badań, lecz jednocześnie wywołują strach. Pierwsza z tych reakcji została zinstytucjonalizowana przez naukę, oświatę i sztukę, druga - prowadzi do zainteresowania pogańskimi praktykami religijnymi, czarami, magią, okultyzmem oraz niezidentyfikowanymi obiektami latającymi.  Nie możemy opanować tego, czego nie potrafimy zrozumieć, a jeśli to coś jest wobec nas nieprzyjazne, to może w końcu zapanować nad nami lub nawet nas zniszczyć. Co gorsza, gdyby jakiś człowiek odkrył tajemnicę tych nieznanych sił, to mógłby zdobyć władzę nad nami wszystkimi. Ten podstawowy wątek przenika nasze historie o duchach, stare seriale filmowe z gatunku science-fiction oraz literackie opowieści grozy. Wydaje się, jak gdybyśmy - zdają sobie sprawę z naszej własnej kruchości i śmiertelności - tęsknili za wszechmocą i nieśmiertelnością, i odczuwali wobec nich przerażenie.




Psychopatologia
i choroba psychiczna




Niewiele jest dziedzin psychologii, którymi studenci interesowaliby się bardziej niż psychopatologią i dynamiką zaburzeń psychicznych. Przeciętny człowiek często w istocie stawia znak równości między psychologią a nauką o schorzeniach psychicznych. Jednakże, pomimo tej fascynacji |badaniem anormalnych procesów, niewielka jest tolerancja, a jeszcze mniejsza troska, w stosunku do osób, u których takie procesy występują. W naszym społeczeństwie „osoba psychicznie chora” jest |napiętnowana w taki sposób, jaki nie dotyka osoby chorej fizycznie. Badania wykazały, że na ogół ludzie zdają się obawiać i unikać jednostek uważanych za „chore psychicznie”.  Osoby takie zawsze izolowano od innych. W różnych okresach i w różnych miejscach jednostki dotknięte napadami, wizjami czy halucynacjami czyniono prorokami lub szamanami i czczono je jako wybrańców powołanych do przekazywania boskiego posłania. Częściej jednak społeczeństwo odrzucało je, wypędzało, izolowało, torturowało lub zabijało (Ryc. 11.1).
Pomimo naszego zakorzenionego uprzedzenia wobec ludzi klasyfikowanych jako „psychicznie chorzy” lub „o ograniczonej poczytalności” (termin prawniczy) wiele już sie zmieniło w naszym poglądzie na przyczyny niezwykłego, dziwacznego i zaburzonego zachowania niektórych ludzi. Zanim powstało współczesne pojecie „chorób psychicznych”, zachowania takie przypisywano owładnięciu duszy i ciała przez demony, niewidzialne moce, które uważano za przyczynę zła, bólu i cierpienia, jakie wszędzie były widoczne. Jedyną nadzieję pokładano w powstrzymywaniu tych duchów przed wtargnięciem do ciała, jeśli bowiem raz znalazły one doń wejście, to proces ich wypędzania mógł równie łatwo spowodować śmierć, jak powrót do zdrowia.  Ludzie nosili czarodziejskie maskotki, amulety (zwykle sporządzone z różnych części świętych zwierząt), aby odstraszyć złe duchy.
Owładnięcie przez demony tłumaczyło zarówno chorobę fizyczną, jak i anomalie umysłowe; tak więc leczenie w obu przypadkach polegało na wypędzaniu złych duchów za pomocą czarów, obrzędów magicznych, preparatów ziołowych i wysysających krew pijawek. W zbiorze pism „lekarzy-czarowników” praktykujących w Anglii przed jej podbojem przez Normanów w 1066 roku, znajdujemy następującą receptę: „Gdy diabeł owładnie człowiekiem czyli kieruje nim od wewnątrz przez chorobę; napój na wymioty, czyli emetyk; łubin, biskupie ziele, lulek - utrzyj to razem, dodaj piwa, aby otrzymać płyn, niech stoi przez noc, dodaj 50 ziaren przeczyszczającego środka i wodę święconą - wypić z dzwonu kościelnego” (cytowane przez Margottę, 1967, s. 292).




* * *



Ryc. 11.1. Ta czaszka z epoki neolitu jest niemym świadectwem jednej z najwcześniejszych prób leczenia zaburzeń psychicznych: wywiercenie dziury w czaszce „pacjenta” miało umożliwić ucieczkę złym duchom. Zawieszanie na obracającej się „huśtawce”, mające przywracać rozum osobom cierpiącym na zaburzenia psychiczne, oraz łóżko ograniczające swobodę ruchów niespokojnym pacjentom stosowano niecałe sto lat temu.


* * *







Zbliżenie


Szatan i czarownice


„Stare wierzenia nigdy nie umierają, po prostu trwają w uśpieniu, dopóki nie nadejdzie właściwy czas, aby mogły ożyć. Egzorcyzmy, które mogłyby wydawać się prymitywnym obrządkiem minionych wieków, stały się znowu modne.  W związku z popularnością filmu „Egzorcysta” wyszło na jaw, że obrządek egzorcyzmowania złego ducha był w istocie praktykowany z pewną regularnością przez cały czas - jedynie rozmiary i popularność tych praktyk zmalała.
We współczesnym obrzędzie chrztu w kościele katolickim nadal dokonuje się takiego egzorcyzmowania złego ducha, ponieważ zakłada się, że niemowlę jest pod jego władzą w wyniku grzechu pierworodnego popełnionego przez Adama w Raju. „Wypędzam cię, duchu nieczysty!” stwierdza kapłan. Wiara w opętanie przez szatana występuje także wśród mormonów, żydowskiej sekty hasydów oraz w innych grupach religijnych. Badania przeprowadzone w 1974 roku przez Center For Policy (Ośrodek Badań Politycznych), które objęły 3546 dorosłych w całych Stanach Zjednoczonych, wykazały, że 48% badanych było |pewnych, że diabeł istnieje, a dalszych 20% uważało to za |prawdopodobne („Time”, 29 kwietnia 1974, s. 99).
Niegdyś, w 1692 roku, jeszcze większa część społeczeństwa wierzyła w istnienie szatana i czarownic. Gdy osiem młodych dziewcząt mieszkających w Salem w stanie Massachusetts zostało dotkniętych niezwykłą chorobą, dla której nie było jakiegoś oczywistego medycznego wyjaśnienia, wówczas za najtrafniejszą diagnozę uznano „czary”. Zachowanie dziewcząt z początku charakteryzowały zaburzenia mowy, dziwaczne gesty i postawy ciała oraz napady drgawek. (Dopiero |po podaniu chorym wyjaśnienia, że są to czary, pojawiły się u nich halucynacje i systemy urojeń). Nastąpiły „polowania na czarownice”, oskarżenia, procesy i wyroki. Nim się to skończyło, 19 mężczyzn i kobiet zostało powieszonych, a jeden mężczyzna zmarł wskutek tortur. Dalszych 150 czarownic i czarowników zostało uwolnionych, gdy w 1693 roku gubernator zarządził ogólną amnestię. Kryzys ten zakończył się równie nagle, jak się zaczął.
Godną uwagi próbę nowego wyjaśnienia tego szaleństwa w Salem podjęła Linnda Caporael (1976). Przytacza ona przekonywające dowody na rzecz hipotezy, iż dziwne zachowanie tych dziewcząt miało racjonalne powody natury fizjologicznej, których nie wykryto, ponieważ ówcześni purytanie nic o nich nie wiedzieli. Prawdopodobnie przyczyną był |sporysz - grzybek pasożytujący na zbożu i zawierający wiele substancji chemicznych, które po spożyciu chleba żytniego z ziarna zanieczyszczonego tym grzybkiem powodują napady drgawek i inne zaburzenia. „Nie znając objawów zatrucia sporyszem i będąc świadkami drgawek, zaburzeń psychicznych i zaburzeń percepcji purytanie z Nowej Anglii uznali czary za najlepsze wyjaśnienie tych zjawisk (...). Jest prawdopodobne, że to sporysz był owym Szatanem z Salem” (s.  26).


Wielki rzymski lekarz Celsus tuż przed narodzeniem Chrystusa uczynił ważny krok w kierunku ukształtowania światłego poglądu na choroby psychiczne, który to pogląd w istocie został proklamowany stulecia wcześniej przez Hipokratesa, lecz nie zwrócił na siebie uwagi ludzi mu współczesnych. Celsus zamieścił w swym klasycznym dziele „De medicina” rozdział, w którym sklasyfikował i opisał różne zaburzenia psychiczne.  Jednakże jego poglądy na terapię nie były tak światłe. Zalecał on głodzenie oraz bicie łańcuchami nadmiernie pobudzonych pacjentów.
Gdy w wiekach średnich wzrosła siła i znaczenie Kościoła, wtedy wszystko to, co nie było słuszne i właściwe, dobre i zdrowe uważano za dzieło diabła i czarownic. Ten pogląd, że anomalie psychiczne są przejawem mocy szatana, nie tylko doprowadził do „błędów i wypaczeń” Inkwizycji i do polowań na czarownice w całej niemal Europie i Nowej Anglii, lecz przez stulecia uniemożliwiał wszelkie analityczne, empiryczne badania zaburzeń psychicznych. Dopiero radykalne zmiany społeczne i intelektualne, jakie wprowadziła epoka Odrodzenia sprawiły, że miejsce przesądów mógł zająć rozum i badania naukowe.
Dziedziną medycyny, która poczyniła wielkie postępy już w czasach Odrodzenia, jest |neurologia, zajmująca się funkcjonowaniem i zaburzeniami funkcjonowania mózgu, rdzenia kręgowego i całego układu nerwowego.  Konsekwencją tego było oddzielenie umysłu i duszy wraz z ich mistycznymi i duchowymi cechami, od działania materialnego układu nerwowego, który może być przedmiotem badań medycyny; dzięki temu badania nad zaburzeniami psychicznymi zyskały podstawy naukowe i szacunek uczonych. Za jednym pociągnięciem model medyczny przekształcił szaleństwo i owładnięcie przez demony w „chorobę psychiczną” czy „chorobę nerwową”.
Podobnie jak klasyfikowano choroby fizyczne, aby umożliwić rzetelniejszą diagnozę i ujednolicone leczenie, tak samo w XVIII stuleciu pojawiła się klasyfikacja (|nozologia) psychiatryczna zaburzeń psychicznych, emocjonalnych i behawioralnych. W XIX stuleciu neurologowie niemieccy główną uwagę poświęcali opisowi, klasyfikacji i starannym eksperymentom w dziedzinie fizjologii układu nerwowego, patologii komórkowej oraz organicznemu podłożu chorób psychicznych. Natomiast dla psychiatrii francuskiej w tym okresie charakterystyczna była |dynamiczna orientacja w wyszukiwaniu przyczyn zaburzeń emocjonalnych, przede wszystkim zaburzeń neurotycznych. Zygmunt Freud, student medycyny z Wiednia, studiował w Paryżu w roku 1885, a po powrocie do Wiednia opracował (wraz z Józefem Breuerem) metodę swobodnych skojarzeń, która stała się metodologicznym kamieniem węgielnym psychoanalizy.
Freud, w większym stopniu niż ktokolwiek inny, przyczynił się do tego, że badanie i leczenie anormalnego zachowania stało się akceptowaną, modną i pobudzającą intelektualnie formą działalności naukowej. Osiągnął to odrzucając statystyczny w zasadzie model cierpiącej jednostki, przedstawiający ją jako bierną ofiarę demonów lub choroby. Freud przyjął bardziej dynamiczny pogląd, uznając jednostkę za aktywny (aczkolwiek nieświadomy) czynnik w jej dolegliwościach psychicznych.
Tymi siłami dynamicznymi, wyjaśniającymi wiele „anormalnych” zachowań, były według Freuda (jak przekonaliśmy się w poprzednim rozdziale) nieświadoma motywacja i wyparcie nieakceptowanych impulsów. Freud rozwinął teorię psychoanalityczną w takim kierunku, że ukazywała ona racjonalność wielu zachowań neurotycznych, które uważano za irracjonalne i bezsensowne.  Postulując, by nerwicę uważać za kontynuację tych „normalnych procesów” związanych z konfliktem psychicznym i obroną ego, Freud włączył neurotyka z powrotem do społeczeństwa. Freud przywrócił duszę w postaci superego (sumienia) i ponownie zjednoczył psychikę z układem nerwowym, tak że można było leczyć całą osobę.
Koncepcje Freuda zostały szybko zaadoptowane przez amerykańskich psychologów klinicznych i psychiatrów jako podstawa terapii psychoanalitycznej (którą opiszemy w następnym rozdziale). Johnowi Dollardowi i Nealowi Millerowi (1950) pozostało tylko wyrazić pewne podstawowe pojęcia Freuda w języku teorii uczenia się, dominującej w początkach lat pięćdziesiątych naszego wieku, aby pozyskać większy szacunek dla myśli psychoanalitycznej wśród psychologów o orientacji badawczej i uczynić ją bardziej dla nich użyteczną.
Systematyczne badania naukowe anormalnych form zachowania człowieka zaczęto prowadzić stosunkowo niedawno. Tradycyjnym podejściem badawczym było stadium przypadku, w którym analizuje się dogłębnie przypuszczalne przyczyny, objawy i przebieg „choroby psychicznej” u pojedynczego pacjenta.  Studenci często są zaskoczeni dowiadując się, że monumentalne dzieło Freuda opiera się głównie na takich studiach przypadków, a nie eksperymentach, wymagających stosowania kontrolowanych obserwacji i porównań. Intensywne stadium pojedynczego przypadku jest wartościowe głównie jako źródło idei i hipotez. Ocena słuszności tych hipotez wymaga takiej samej naukowej metodologii, jak ich weryfikowanie w każdej innej dziedzinie psychologii.  Dopiero w ostatnich dziesięcioleciach zbieranie danych na wielką skalę, sprawdzanie hipotez wyprowadzonych z teorii i rygorystyczna ocena metod terapeutycznych stały się jedną z podstaw psychopatologii.
Niemożliwe jest dokładne ustalenie, w jakiej mierze problemy psychiczne i emocjonalne są uwikłane w innych, bardziej oczywistych problemach, takich jak rozwody, zbrodnie, wojny, uprzedzenia i samobójstwa. Wiemy jednak, że „zaburzenia osobowości” często prowadzą do konfliktów społecznych, a niekiedy do aktów agresji skierowanych przeciw innym ludziom lub przeciw samemu sobie. Choroba fizyczna może powodować poważne zaburzenia psychiczne; z drugiej strony, wiele zaburzeń fizycznych ma swe początki w sferze emocjonalnej.
Nieprzeliczona liczba ludzi cierpi każdego roku wskutek jakiejś postaci choroby psychicznej, choroby nerwowej czy zaburzenia emocjonalnego. W tej właśnie chwili więcej ludzi w Stanach Zjednoczonych przebywa na leczeniu szpitalnym z powodu „problemów psychicznych” niż z jakiejkolwiek innej choroby. Szanse wystąpienia poważnego załamania emocjonalnego wynoszą 1:10; dwa i pół miliona ludzi leczonych jest każdego roku w Stanach Zjednoczonych z powodu takich załamań. Obecnie szacuje się, że w Stanach Zjednoczonych choroby psychiczne pociągają za sobą koszty pieniężne pociągające rocznie 20 miliardów dolarów. Nikt nie potrafi oszacować kosztów w postaci cierpienia i utraty potencjału ludzkiego. Aczkolwiek są to tylko suche liczby, to jednak pozwalają one ocenić rozmiar problemu, jaki stanowią choroby psychiczne w Stanach Zjednoczonych. Schizofrenia jest jedną z najpoważniejszych chorób psychicznych, wymagającą hospitalizacji pacjentów i ich długotrwałego leczenia: oczekuje się, że więcej niż 2% wszystkich dzieci urodzonych w 1960 roku w Stanach Zjednoczonych będzie cierpień na schizofrenię w którymś okresie swego życia (wszystkie oceny zaczerpnięte z wydanego w 1970 roku sprawozdania „National Clearing House for Mental Health Information” - Narodowej Centrali Informacji o Zdrowiu psychicznym; publikacja numer 5027).
Depresja jest w naszych czasach schorzeniem numer jeden, powodującym prawie 100000 hospitalizacji rocznie i dotykającym codziennie miliony spośród nas. Depresja doprowadza do tragedii samobójstwa więcej niż 20000 ludzi rocznie w samych tylko Stanach Zjednoczonych. Ocenia się, że w Stanach Zjednoczonych co 26 minut ginie ktoś śmiercią samobójczą. Na każde samobójstwo przypadają trzy, które nie zostały zarejestrowane lub były „nieudane”. Alkoholizm stanowi osobisty problem dla ponad 5000000 ludzi w Stanach Zjednoczonych, problem zaś społeczny dla ich rodzin, przyjaciół i pracodawców, a także dla niewinnych ofiar śmiertelnych wypadków samochodowych spowodowanych nadużyciem alkoholu. Nadużywanie środków farmakologicznych decyduje o „stylu życia” ponad 100000 narkomanów w Stanach Zjednoczonych, a stanowi poważny problem dla dalszych setek tysięcy tych, którzy przywykli do innych typowych lekarstw; lecz nadużywanie tych środków jest w równym stopniu problemem dla społeczeństwa, które usiłuje uporać się z tym zjawiskiem i jego konsekwencjami w postaci zbrodni i aktów przemocy. Szacuje się, że koszty zbrodni i przestępczości przekraczają 20 |miliardów dolarów rocznie, nie mówiąc już o braku wzajemnego zaufania w społeczeństwie, które to zjawisko towarzyszy wysokim wskaźnikom przestępczości.




Chory! Chory. Chory?




Czy szaleństwo, podobnie jak piękno, egzystuje w umyśle obserwatora, czy też istnieje „realnie”, niezależnie od oceny społecznej i kulturowych uprzedzeń obserwatora, jak na przykład śmierć? Niektóre próby znalezienia odpowiedzi na to pytanie wyraźnie podważają same podwaliny współczesnej psychiatrii. Problemem tym zajmiemy się w niniejszym podrozdziale.
W chorobie fizycznej istnieją wyraźnie, określone, zwykle zadające się mierzyć oznaki patologii. Na przykład białaczkę rozpoznaje się na podstawie nietypowego stosunku liczby białych ciałek krwi do czerwonych ciałek krwi, raka - na podstawie niekontrolowanego wzrostu guzów, paraliż zaś - na podstawie degeneracji nerwów i braku reakcji mięśniowej. Natomiast choroba psychiczna występuje wtedy, gdy ktoś mówi, że jest ona obecna.
Patologię psychiczną określa się zatem nie na podstawie faktów fizycznych, lecz faktów społecznych. Obserwuje się zachowanie, nie tkankę, a ktoś musi ocenić dane zachowanie i osądzić, czy jest ono patologicznie.  Obecnie uznajemy ludzi za psychicznie chorych przeważnie na podstawie pewnej kombinacji następujących przesłanek (zaadoptowane na podstawie następujących prac: Wegrocki, 1939; W. W. Scott, 1958; Allport, 1960):
1. Dana osoba jest pod opieką psychiatrów.
2. Szanowani, wpływowi członkowie danej społeczności (nauczyciele, sędziowie, rodzice, małżonkowie, duchowni) twierdzą zgodnie, że dane zachowanie reprezentuje określony stopień złego przystosowania.
3. Psychiatra lub psycholog kliniczny stawia diagnozę zaburzenia psychicznego.
4. Wyniki uzyskiwane przez tę osobę w psychologicznych kwestionariuszach osobowości odbiegają w określonym stopniu od norm wyznaczonych dla grupy uznanej za normalną.
5. Dana osoba sama deklaruje się jako „psychicznie chora”, czy to „explicite”, czy też przez wyrażanie uczuć rozpaczy, lęku i nieadekwatności.
6. Zachowuje się publicznie w sposób, który zwraca uwagę na jej zachowanie jako odbiegające od norm akcetowanych przez większość innych członków danej społeczności.





Model medyczny:
dlaczego niektórzy
mają go dość




Uzasadnione jest stwierdzenie, że poważne postępy, jakie poczyniono w badaniach i leczeniu nieprzystosowawczego zachowania, można przypisać przyjęciu „modelu medycznego”. Jednakże z innej perspektywy założenia tego modelu oraz orientację, do której prowadzi, można poważnie krytykować jako wytaczające fałszywy kierunek zarówno badaniom, jak i możliwym rozwiązaniom tego problemu.
W modelu medycznym zastosowanym do problemów psychologicznych i psychiatrycznych przyjmuje się następujące założenia: a) zachowanie anormalne jest objawem choroby stanowiącej jej podłoże; b) objawy zewnętrzne są oznakami wewnętrznych stanów czy procesów patologicznych; c) ostatecznej przyczyny choroby psychicznej należy szukać w zaburzeniach („malfunctioning”) genetycznych, biochemicznych, organicznych; d) występujące w danym momencie zaburzenia wynikają z uprzednich urazów, deprywacji oraz czynników związanych z niewłaściwą troską o zdrowie psychiczne; e) przeprowadza się wyraźne rozróżnienia pomiędzy „chorobą” i „zdrowiem”, „anormalnym” i „normalnym”, „chorym” i „zdrowym”; f) leczenie polega na hospitalizacji i interwencji medycznej, mającej uwolnić chorego od cierpienia, usunąć chorobę, która „szaleje w jego wnętrzu”.
Czy jednak choroba psychiczna pochodzi z wewnątrz, czy z zewnątrz?  Poważną konsekwencją przyjęcia modelu medycznego i uznania, że umożliwia on zrozumienie nieprzystosowanego zachowania, jest to, iż przyczyn zaburzenia szuka się w osobie, a nie w środowisku, w którym ona funkcjonuje. W modelu tym przywiązuje się wagę do dawnych źródeł choroby, a nie do aktualnych warunków, które mogą podtrzymywać nieprzystosowawcze zachowanie. Zakłada sie, że jednostka „dotknięta chorobą” musi zostać w pewnym stopniu odizolowana, przyjmując bierną rolę „pacjenta” w procesie leczenia, którym kierują medyczni eksperci. Ponadto model medyczny zakłada, że nawet jeśli |wszystkie objawy choroby znikną po leczeniu, to nie musi to oznaczać, iż pacjent jest wyleczony, ponieważ stanowią one jedynie widoczny „wierzchołek” ukrytej - podobnie jak część pływającej góry lodowej - choroby psychicznej. Pacjenta psychiatrycznego, u którego objawy choroby już nie występują, określa się jako chorego w okresie |remisji. Oznacza to, że choroba nie występuje jawnie, lecz zarazem implikuje, iż może ona wybuchnąć w każdej chwili.
Czy potrafisz wyobrazić sobie, jak byś się czuł, gdybyś pozbył się wszystkich objawów, z powodu których trafiłeś do szpitala, po czym powiedziano by ci, że jesteś „schizofrenikiem w okresie remisji”?




Zbliżenie


Czy można być zdrowym w niezdrowych miejscach?


„Czy normalna, „zdrowa psychicznie” osoba, u której nigdy nie występowały poważne objawy zaburzeń psychicznych, może być przyjęta do szpitala psychiatrycznego i nie zostać zdemaskowana tam od razu jako zdrowa? Jest to coś więcej niż tylko zagadnienie akademickie; jest to wyraz obaw, odczuwanych przez wielu ludzi, którzy odwiedzają szpitale psychiatryczne lub pracują w nich. Zgodnie z wynikami najbardziej znanych badań, przeprowadzonych przez Davida Rosenhana (1973), objawy te są częściowo uzasadnione. Gdy dana osoba została raz określona jako „chora psychicznie” i przyjęta do szpitala, wówczas niczego, co ta osoba robi, nie uznaje się już za normalne.
Rosenhan i siedem innych osób zgłaszało się do dwunastu różnych szpitali psychiatrycznych w pięciu różnych stanach na Wschodnim i Zachodnim Wybrzeżu Stanów Zjednoczonych. Dokonywali tego telefonując do izby przyjęć każdego ze szpitali z prośbą o przyjęcie. Każdy z tych pseudopacjentów skarżył się na to samo: „Słyszę głosy, niewyraźne głosy. Wydaje mi się, że mówią one „pusty”, „próżny”, „głuchy”. Z wyjątkiem tego kłamstwa oraz zmiany swego nazwiska, zawodu i miejsca zatrudnienia, wszystko co mówili, było prawdą - przedstawiali po prostu pewne niepatologiczne epizody ze swego życia. W prawie każdym wypadku rozpoznawano u nich „schizofrenię”; wyjątkiem wśród szpitali objętych badaniami był jedyny prywatny szpital, w którym postawiono diagnozę „psychoza maniakalno-depresyjna” (diagnoza ta rokuje bardziej pomyślne szanse wyzdrowienia lub wyleczenia). Gdy pseudopacjenci znaleźli się na oddziale psychiatrycznym, wówczas natychmiast zaprzestawali symulowania jakichkolwiek objawów choroby. Każdy pseudopacjent zachowywał się tak „normalnie” pod każdym względem, jak to tylko było możliwe.
Jak szybko ich zdemaskowano? „Pomimo publicznego demonstrowania zdrowia psychicznego”, podaje Rosenhan, „pseudopacjenci nie zostali nigdy zdemaskowani. Każdy z nich, przyjęty z reguły z diagnozą schizofrenii, został zwolniony z diagnozą schizofrenii „w okresie remisji””. Długość okresu hospitalizacji wahała się od 7 do 52 dni, przy czym przeciętna wynosiła 19 dni. Zwolnienie następowało zwykle na interwencję współmałżonka czy przyjaciół, lecz żaden z członków personelu kierowniczego nie zdawał sobie sprawy, że został popełniony „błąd” przy przyjmowaniu, czyli że zdrowa psychicznie osoba przebywała w „niezdrowym” miejscu.
Aby jeszcze dobitniej wykazać subiektywność ocen oraz nierzetelność psychiatrycznej diagnozy chorób psychicznych, Rosenhan (1973) przeprowadził proste badania dodatkowe w pewnym szpitalu, którego kierownictwo zostało poinformowane o opisanych wyżej badaniach i nie chciało wierzyć, aby takie błędy mogły wydarzyć się w |ich szpitalu.  Powiedziano im, że w ciągu następnych trzech miesięcy jeden lub więcej pseudopacjentów będzie starać się o przyjęcie do szpitala. U członków personelu kierowniczego wytworzono więc w ten sposób nastawienie na wykrywanie oszustów; oceniali inni systematycznie swoją pewność, że każdy ze 193 pacjentów przyjętych w tym okresie do szpitala jest albo zdrowym pseudopacjentem, albo też psychicznie chorym, prawdziwym pacjentem. 41 osób spośród przyjętych pacjentów zostało z dużym stopniem pewności uznanych za pseudopacjentów przez przynajmniej jednego członka zarządu szpitala, zaś 19 spośród tych pacjentów zostało uznanych za zdrowych pseudopacjentów |zarówno przez psychiatrę, jak i przez członka zarządu.
Ilu pseudopacjentów wysłał Rosenhan do tego szpitala? Prawdopodobnie już to odgadłeś. |Żadnego”.


Podstawowe zarzuty pod adresem modelu medycznego są następujące: a) zjawisko określane jako „choroba psychiczna” należałoby ujmować raczej w kategoriach |dewiacji niż |choroby; b) bez względu na to, jaką nazwę jej się nada, „choroba psychiczna” nie jest czymś istniejącym w tym samym sensie, jak rak czy gruźlica, lecz jest raczej subiektywną |etykietką i określeniem stosowanym wobec pewnych ludzi przez innych ludzi, w celu wnioskowania o stanach i procesach, których nie można zaobserwować bezpośrednio; c) ludzie społecznie, ekonomicznie czy politycznie |bezsilni będą częściej określani jako „psychicznie chorzy”, niż ludzie dysponujący siłą, nawet jeśli wykazują oni identyczne zachowania; d) „szaleństwo” („madness”) jest wytworem interakcji danej jednostki z jej środowiskiem społecznym oraz jej przystosowania do tego środowiska - wraz z jego konfliktowymi wymaganiami, nierozsądnymi regułami oraz patologicznymi stosunkami panującymi w rodzinie, szkołach, miejscu pracy i innych sytuacjach. Te główne zarzuty pochodzą przede wszystkim z kręgów psychiatrii radykalnej, socjologii i psychologii społecznej.
Całkiem inną koncepcję dotyczącą tego, co nazywamy „chorobą psychiczną”, prezentuje „radykalna” szkoła psychiatrii, w której pionierami są Ronald Laing i Thomas Szasz. Stwierdzają oni, że stosunek między „reprezentującym instytucję (czyli szpital) psychiatrą a leczonym przymusowo pacjentem jest bardziej podobny do stosunku między panem a niewolnikiem niż pomiędzy lekarzem a dorosłym pacjentem” (Szasz, 1973, s. XII). Stosunek medyczny jest według nich oparty na sile, która może działać bez współczucia oraz bez uwzględniania praw, życzeń i punktu widzenia pacjenta, jak też funkcji, które jego „szaleństwo” mogło spełniać w jeszcze bardziej szalonym otoczeniu. Według Lainga, schizofrenia jest „specjalną” strategią, którą dana osoba wynajduje, aby żyć w sytuacji nie nadającej się do życia” (1967, s. 115).


Dewiacja, a nie choroba. Wzrastająca w ostatnich latach świadomość niedostatków modelu medycznego doprowadziła krytyków reprezentujących stanowisko socjologiczne do wysunięcia twierdzenia, że właściwym porównaniem dla tak zwanej „choroby psychicznej” są inne formy |dewiacji, a nie |choroby. Biorąc początek ze znaczących prac Ervinga Goffmana (1961), dotyczących pacjenta psychiatrycznego traktowanego jako dewianta moralnego, rozwinął się ruch, który kładzie nacisk na doniosłe znaczenie reakcji społecznych dla określenia tego, czym jest dewiacja, kim są dewianci i w jaki sposób powinno się ich traktować (Becker, 1963; Kitsuse, 1964; 
Erikson, 1966). W sumie pozycja „dewianta” wiąże się z pewną niższością moralną, odrzuceniem społecznym oraz niechętną oceną tych, którzy albo posiadają władzę, albo pragną ją uzyskać. Ponadto termin |dewiant implikuje, że dany osobnik „różni się jakościowo od zwykłych ludzi i że nie ma takich obszarów jego osobowości, które by nie były schorzałe wskutek jego problemu” (Scott, 1972, s. 14).


Erikson (1966) wysunął tezę, że każda społeczność określa się w sensie negatywnym: wskazując, czym |nie jest; jest to łatwiejsze, niż utworzenie pozytywnej definicji. Dewiacja nadaje kształt temu, co złe, nieakceptowane lub przerażające. Można zatem stwierdzić, że społeczeństwo, zgodnie ze swą naturą, zawsze będzie nakładać jakieś ograniczenia, aby osiągnąć minimum stabilności. Dewianci mogą być niezbędną częścią społeczności, ponieważ dzięki nim wyraźnie widać te granice; to dzięki nim reszta społeczności czuje się bardziej normalna, zdrowa, dobra moralna i przestrzegająca prawa.


Bez względu na to, co robisz, przyjemnie jest móc wskazać na kogoś innego i zgodnie z prawdą stwierdzić: „Nigdy nie złapaliście |mnie na |takim postępowaniu”. Określiwszy pewną postać schorzenia i ustaliwszy różnicę między „nami” a „nimi” jesteśmy zadowoleni, ponieważ dzięki temu nie potrafimy wyobrazić sobie, że |my moglibyśmy kiedykolwiek stać się podobni do |nich, a ponadto nie czujemy się odpowiedzialni za stworzenie warunków, które mogły wywołać tę ich „anormalną” reakcję (ryc. 11.2).


Piętno, piętno wszędzie. Diagnoza „chory psychicznie” pociąga za sobą podwójne konsekwencje: degradację społeczną i obniżenie samooceny. Piętno społeczne związane z „chorobą psychiczną” jest silniejsze i bardziej trwałe niż niemal każda inna forma napiętnowania. Obawa przed takim napiętnowaniem może skłaniać ludzi do negowania potrzeby zasięgnięcia porady psychologicznej i poddania się leczeniu nawet wtedy, gdy jest ono potrzebne ze względu na nich samych i innych (Yarrow i in., 1955; Schwartz, 1957)




* * *



Ryc. 11.2. „Niech Kara Będzie Stosowna Do Zbrodni”. Powyższy wykres przedstawia kontinuum zachowań, które uznaje się za coraz bardziej nieakceptowane społecznie, i na które reaguje się z coraz większą surowością. W gruncie rzeczy wszystkie te reakcje są karami za „odbieganie” od normy; można się przekonać, że sposób postępowania wobec tych, którzy przejawiają psychotyczne lub neurotyczne zachowania, przypomina postępowanie wobec przestępców i innych antyspołecznych dewiantów, wbrew naszemu przekonaniu, iż osób chorych psychicznie nie powinno sie pociągać do odpowiedzialności prawnej.
Osoby wykazujące zaburzenia funkcji psychicznych mogą być spostrzegane jako zagrażające życiu i stanowi posiadania innych ludzi, podobnie jak antyspołeczni dewianci. Zachowują się one w sposób niemożliwy do przewidzenia, co osłabia funkcjonowanie kontroli społecznej. Jeszcze bardziej istotne jest to, że wydają się one niezdolne do kierowania się w swym zachowaniu celami uznawanymi za pożądane, podając tym sposobem w wątpliwość podstawowe założenia dotyczące godności i integralności człowieka.


* * *







Zbliżenia


Czy taka etykietka kiedykolwiek się ściera?


„W ostatnich czasach najwstrętniejszym może przykładem szkodliwości psychiatrycznych etykietek było publiczne i polityczne zniesławienie senatora Thomasa Eagletona, który w wyborach w 1972 roku został wysunięty przez Partię Demokratyczna, jako kandydat na stanowisko wiceprezydenta. Już po jego nominacji wykryto, że przechodził on leczenie psychiatryczne, co wywołało burzą rozważań i dyskusji, która w końcu doprowadziła do wycofania jego kandydatury. Większość sporów koncentrowała się wokół faktu, że dziesięć lat wcześniej Eagleton leczył się z powodu depresji. Aczkolwiek nic nie świadczyło o nawrocie objawów depresyjnych, politycy i społeczeństwo uznali, że jest on nadal „niepewny”. W jakim momencie swego życia senator ten zostanie znów uznany za „zupełnie normalnego”? Czy też może nigdy?
W odpowiedzi na publiczny hałas wokół „sprawy Eagletona” American Psychiatric Asscociation (Amerykańskie Towarzystwo Psychiatryczne) wydało oświadczenie, którego fragment głosi: „Podjęcie normalnej działalności przez niezliczone tysiące ludzi, którzy byli skutecznie wyleczeni z depresji, jest przekonywującym dowodem, że fakt zaistnienia epizodu depresji w medycznej historii życia danej osoby winno traktować się w taki sam sposób, jak w przypadku wielu innych, skutecznie leczonych chorób” („Science News” 5 sierpnia 1972 r., s. 85).
Lecz ten autoratywny apel nie rozwiązał zagadnienia. Gdy Gerald Ford oceniany był przez swych kolegów z Kongresu przed wyznaczeniem jego kandydatury na wiceprezydenta, to dokładnie analizowano dokumenty dotyczące jego zdrowia psychicznego. Dziennikarz Sydney J. Harris w prowokującym do myślenia artykule wskazał na niebezpieczeństwa związane z naszymi niezdrowymi postawami wobec „zdrowia psychicznego”.
„(Kongres) żądał wielokrotnych zapewnień od Forda, że nigdy nie odwiedzał on psychiatry ani nie był leczony z powodu jakichkolwiek zaburzeń emocjonalnych; jak gdyby fakt, że człowiek nigdy nie zasięgał porady psychiatry, w jakiś sposób świadczył, o jego niezawodności (...). Problemy emocjonalne istotnie wpływają na zachowanie w daleko większym stopniu niż fizyczne, lecz sedno sprawy polega na tym, że oddziałują one na zachowanie jeszcze bardziej, gdy nie są rozpoznane i leczone” (1974).


Fakt, że ktoś zostaje „pacjentem psychiatrycznym” sam w sobie przyczynia się do wzmożenia lęku u tak określonej jednostki, obniżając jego samoocenę i działając zapewne jako samospełniające się proroctwo. Zamiast myśleć o sobie jak o zwykłych ludziach, którzy nie potrafią rozwiązać pewnych bieżących problemów stwarzanych przez ich społeczeństwo i otoczenie, pacjenci psychiatryczni uczą się, że są osobami, które budzą strach i litość, które są nie lubiane, degradowane i izolowane. Często uważa się ich za symulantów, ludzi o słabej woli i braku zdecydowania w przezwyciężaniu swych osobistych trudności (Fletcher, 1967).
Psycholog społeczny Amerigo Farina i jego współpracownicy z University of 
Connecticut (1965, 1966, 1971) manipulowali negatywnymi konsekwencjami 
„etykietki” choroby psychicznej w kontrolowanych warunkach 
eksperymentalnych. W eksperymentach tych osoby badane, które były 
przekonane, że współpracują z byłymi pacjentami psychiatrycznymi, okazywały 
im mniej sympatii niż osobom „normalnym”, wyniki ich pracy oceniały jako 
mniej zadawalające, traktowały ich bardziej szorstko, wolały pracować same 
i nie miały chęci na dalsze kontaktowanie się z nimi. Badani studenci, 
których poproszono o odgrywanie roli pacjenta psychiatrycznego (lub jakiejś 
innej „napiętnowanej” roli) w warunkach eksperymentalnych, starali się 
wszelkimi sposobami udowodnić swą normalność, męskość i inteligencję. Myśl, 
że ktoś obcy spostrzega ich jako napiętnowanych, miała silniejszy wpływ na 
ich zachowanie, niż instrukcje dotyczące odgrywania roli, do których 
zgodzili się stosować (Farina, 1971). W podobnych eksperymentach prawdziwi 
byli pacjenci, będąc przekonani, że ich współpracownik wie o ich 
poprzedniej hospitalizacji, uzyskiwali gorsze wyniki i wykazywali większe 
napięcie i lęk niż ci, którzy byli przekonani, że ich współpracownik o 
niczym nie wie
(Farina i in., 1971).




Czy zachowanie może
być naprawdę anormalne?




Przyjmując, że określenia te są arbitralne i że zachowanie może być oceniane błędnie, czy istnieje jakieś zachowanie, które w przypadku istot ludzkich jest zawsze normalne lub zawsze anormalne?


„|Anormalny, przym. Nie stosujący się do wzorca. W sprawach myślenia i postępowania być niezależnym - to być anormalnym, być anormalnym - to być znienawidzonym”.
Ambrose Bierce „The Devil’s Dictionary”, 1911


|Czy |”normalne” |jest |po |prostu |tym, |co |większość |ludzi |uznaje |za |normalne? Niewątpliwie, to co uważa się za „anormalne”, jest po części zdeterminowane historycznie. Duchowny rzymskokatolicki chce się ożenić, kobieta pali w miejscu publicznym, młody człowiek odmawia odbycia służby wojskowej, uczeń szkoły średniej przyjmuje narkotyki - wszyscy oni byli „anormalni” w oczach swego otoczenia nie tak dawno temu. Czy są nadal? Do niedawna ludziom, którzy zgłaszali się na psychoterapię z powodu homoseksualizmu dawano odczuć, że społeczeństwo potępia ich zboczone popędy i automatycznie poddawano ich terapii w celu „wyleczenia”. Psychiatrzy zmienili obecnie definicję tego problemu, uważając homoseksualizm za możliwy do zaakceptowania, jeśli jest swobodnie wybraną alternatywą, a nie reakcją wymuszoną przez strach lub mechanizm unikania, oparty na głębokim poczuciu nieadekwatności.


|Wyjść |poza „|liczenie |nosów”. Większość definicji anormalności ma w zasadzie charakter statystyczny - określa w jakim stopniu działanie danej jednostki różni się od tego, co robi większość ludzi? „To, co robi większość ludzi” (lub to, co robią ludzie najpotężniejsi) zależy z kolei od kultury lub od epoki. Społeczeństwa różnią się zarówno pod względem przyjmowanych norm, jak i pod względem tego, jak duże różnice w zachowaniu będą tolerować, zanim uznają je za rzeczywiste odchylenia czy dewiacje.  Jednakże zawsze istnieje tendencja do ochrony społecznego status quo przez karanie nonkonformistów lub traktowanie ich w sposób, który „przywoła do porządku” lub pozwoli ich wyeliminować - po to, aby zapobiec upodabnianiu się „przeciętnych reakcji” (tego, co robi większość ludzi) do ich zachowań.




Zbliżenie


Normy społeczne jako czynniki sprzyjające anormalności


„Normy społeczne określając, kto zostanie odrzucony i napiętnowany jako wyrzutek, mogą przyczyniać się do powstawania anomalii u tych, którzy nie mogą lub nie chcą się przystosować - wzbudzają bowiem u nich lęk, zwątpienie w siebie i poczucie izolacji społecznej. Na przykład ceną, jaką płacimy za przypisywanie wysokiej wartości sukcesowi ekonomicznemu, jest między innymi to, że każdemu załamaniu koniunktury gospodarczej towarzyszy wzrost liczby przyjęć do szpitali psychiatrycznych osób należących do klasy średniej i wyższej.
Zbyt wysokie standardy narzucane przez rodziców, nauczycieli i inne osoby sprawiają, że wielu ludzi w naszym społeczeństwie uważa się za niewystarczająco sprawnych pod względem intelektualnym. Inni cierpią udręki w związku ze swym życiem seksualnym, z powodu nauk rodziców, którzy utożsamiali seks z grzechem lub pouczeń rówieśników, w których był on synonimem podbojów i osiągnięć. Poczucie, że jest się brzydkim, bezwartościowym, uciążliwym lub umyślnie złym, może być mimowolnie zaszczepione dziecku przez rodziców, którzy dokonując porównań społecznych ukazują mu niezwykle ambitne wzory lub stosują inne „normalne” techniki wychowawcze.
Najgorszym chyba winowajcą w tym festiwalu paranoidalnego konformizmu są środki masowego przekazu. Reklamy telewizyjne przekonują kobiety, że muszą one pilnie stosować niezliczone kosmetyki do twarzy i całego ciała, aby wyglądać „naturalnie” i „sexy”. Ponadto muszą one stosować dezodoranty, specjalne mydła, „aerozole dla kobiet”, płyny do płukania ust itd., aby wyeliminować naturalne zapachy ciała i używać perfum, aby nadać ciału ponętny zapach. Aby mężczyzna był prawdziwym mężczyzną, musi on pić, palić i używać wody po goleniu, która w ciągu nocy ma przeistoczyć go w mistrza karate. W tego typu atmosferze „przystosuj sie lub zgiń” istotnym powodem do chwały gatunku ludzkiego jest to, że w ogóle ktokolwiek z nas ośmiela się być innym!!!”


Psychologowie funkcjonują jako przedstawiciele społeczeństwa. Jednakże przyjmowanie zbyt uproszczonego poglądu, że |zdrowe jest to, co jest dobre dla przeciętnej osoby, czyni z osób krytykujących - dewiantów, a z nonkonformistów - szaleńców. Staje się oczywiste, że „normalność” każdej normy grupowej należy z kolei ocenić według jakichś innych kryteriów. Czy norma antysemitycka w Niemczech hitlerowskich była „normalna”? Gdyby wszyscy studenci zdecydowali się zażywać heroinę, to czy dostosowanie się do nich byłoby „normalne”? Czy było czymś normalnym posiadanie niewolników przed wojną secesyjną w Stanach Zjednoczonych?


„To większość o tym, jak o wszystkim, decyduje. Przyzwoli, i jesteś 
zdrowy; Sprzeciwi się - natychmiast jesteś niebezpieczny i skuty 
łańcuchami”
Emily Dickinson, ok. 1862




Wiatry niosące
zmianę




W naszych czasach - czasach szybko zmieniających się wartości społecznych - wytwarza się „antynorma” która zaleca, aby ludzie „robili to, co chcą”, biorąc od społeczeństwa to, czego potrzebują, lecz nie odczuwając żadnej odpowiedzialności za „utrzymanie go w ruchu”, czyli za dopomaganie temu społecznemu agregatowi w wypełnianiu jego funkcji podtrzymywania jednostki i opiekowania się nią. Jest zupełnie możliwe, że konieczność rozwiązania powstających tu problemów doprowadzi do zdrowszej troski o jednostkę, osłabi gotowość do poświęcania indywidualnej ekscentryczności w zamian za balsam powszechnej zgody i przyczyni się do zaakceptowania różnorodnych norm zachowania. Z drugiej strony, jesteśmy istotami społecznymi, a życie polegające na indywidualnym dogadzaniu sobie nie jest jedyną możliwością odmienną od konformistycznego ulegania naciskom społeczeństwa. Każdy z nas musi zadecydować, w jaki sposób można mieć korzyść ze wspólnego życia z innymi, nie tracąc własnej tożsamości przy zabieganiu o aprobatę społeczną.  Realizacja celu, polegającego na utworzeniu społeczeństwa, w którym zarówno jednostka jak i grupa wnoszą swój wkład i wzajemnie przynoszą sobie korzyść, zamiast tylko brać i wyrządzać sobie szkodę, wymaga czasu.  Tymczasem oddziały psychiatryczne są przepełnione i cierpią na brak personelu, a patologiczne tendencje u jednostek są wzmacniane, a co więcej, wywoływane przez różne formy patologii społecznej - są to problemy, które można rozwiązać jedynie wspólnym wysiłkiem. Resztę tego rozdziału poświęcimy niektórym najczęściej spotykanym postaciom patologii indywidualnej, które arbitralnie podzieliliśmy na cztery kategorie - uzależnienie i nałóg, nerwica, psychoza, samobójstwo - każda z nich dotyczy utraty możliwości zrealizowania w pełni naszego człowieczeństwa. W dalszej części niniejszej książki poświęcimy cały rozdział analizie bardziej oczywistych przykładów patologii społecznej, z którymi spotykamy się w naszym codziennym życiu.




Utrata zdolności
autoregulacji:
uzależnienie i nałóg




W społeczeństwie amerykańskim takie czynności konsumpcyjne, jak picie alkoholu, palenie papierosów i zażywanie środków farmakologicznych, zaczynają dominować nad życiem coraz większej liczby ludzi. Te nieszczęsne jednostki uwarunkowały się w ten sposób, że osiąganie przez nie różnorodnych satysfakcji emocjonalnych i behawioralnych jest uzależnione od różnych substytutów - substytuty te pozwalają im odprężyć się, gdy są zbyt napięte, odzyskać humor, gdy są przygnębione, odpędzić senność i znużenie, zasnąć wieczorem - krótko mówiąc, pozwalają im „przeżyć dzień”.
To, co zaczyna się jako ogólnie aprobowany „kieliszek w towarzystwie”, może stać się niepohamowanym pragnieniem zmuszającym do wypijania litra lub więcej alkoholu dziennie, poczynając od samego rana. Papieros po obiedzie może w jakiś sposób przekształcić się w więcej niż cztery paczki dziennie.  „Rausz” spowodowany marihuaną, początkowo ograniczony do sporadycznych spotkań towarzyskich, może stać się koszmarem LSD, niekiedy doprowadzającym do samobójstwa, nie mającą końca podróżą do świata paranoi i gwałtu lub też nie kończącym się pożądaniem następnej dawki heroiny. Nawet pozornie niewinna czynność jedzenia, normalnie niezbędna dla podtrzymania metabolizmu komórkowego, może uzyskać anormalne właściwości, które zagrażają funkcjonowaniu i istnieniu organizmu w takim samym lub większym stopniu, jak każdy z wymienionych wyżej nałogów (o czym mówiliśmy już w Rozdziale 8).
Utrata zdolności autoregulacji może mieć zatem katastrofalne konsekwencje fizyczne dla zdrowia osoby, która popadła w nałóg. Wynikają one zarówno z |bezpośredniego wpływu nadmiernej ilości obcej substancji na funkcjonowanie układu nerwowego, oddechowego, trawiennego i układu krążenia, jak i z różnych oddziaływań |pośrednich - niewłaściwej diety i różnych zakaźnych stanów chorobowych związanych z niektórymi nałogami. Psychologiczne i społeczne konsekwencje są nie mniej poważne niż fizyczne. Na poziomie psychologicznym występuje utrata zaufania do siebie i poczucia samokontroli, ponieważ nałogowcy zaczynają określać siebie jako niezdolnych do kierowania swym własnym postępowaniem. Tej obniżonej samoocenie towarzyszy utrata zainteresowania zwykłymi czynnościami i celami życiowymi, gdyż nałóg zajmuje ich miejsce w życiu jako centralny czynnik wzmacniający („reinforcer”).
Społeczne konsekwencje tych nawyków można mierzyć sumą strat pieniężnych - utracone zarobki, roztrwonione oszczędności rodziny, wydatki na opiekę społeczną i próby rehabilitacji, straty spowodowane przestępczością. Można je także oceniać w kategoriach utraty produktywności ludzkiej i zniszczenia sensownych związków interpersonalnych - co doprowadza do stopniowego staczania się coraz niżej, do więzienia czy prostytucji. Jednakże chociaż prawie każdy intelektualnie uświadamia sobie potencjalne niebezpieczeństwo nałogów (Termin |nałóg („addiction”) formalnie oznacza uzależnienie fizyczne, lecz tutaj będziemy go stosować w szerszym znaczeniu: dla określenia uzależnienia, czy to fizycznego, czy też psychicznego, które jest na tyle poważne, że dane zachowanie stało się przymusowe i jednostka nie ma nad nim wystarczającej, dowolnej kontroli.) i chociaż wszyscy stykamy się z zakrojonymi na szeroką skalę kampaniami informacyjnymi przeciw takiej autodestrukcji, to jednak wskaźnik rozpowszechnienia takich nałogów zdaje się nadal wzrastać w tempie, które nie daje bynajmniej powodów do radości.
Dlaczego ludzie zaczynają? To jest pierwsza zagadka. W rzeczywistości jest wiele powodów występowania tego paradoksalnego zjawiska, że rozsądni ludzie dobrowolnie angażują się w zachowanie o którym wiedzą, iż może być tak autodestrukcyjne. Poza nie dającym się wykluczyć masochizmem (skłonność do czerpania przyjemności z krzywdzenia lub karania samego siebie) istnieje wiele jeszcze anormalnych procesów, które stanowią bardziej prawdopodobne przyczyny tego, że rozsądni skądinąd ludzie rozpoczynają i kontynuują zachowania prowadzące do wytworzenia nałogu.
Często danej reakcji uczymy się obserwując innych ludzi: rodzice co wieczora wypijają parę kieliszków, powszechnie szanowane osoby zalecają styl życia, który można określić jako „dobre jedzenie, dobry trunek, dobry papieros”, a rówieśnicy robią to, co chcą i wywierają na ciebie presję, abyś ty również robił to, co oni chcą. Środki masowego przekazu wydają znaczne sumy pieniędzy, aby wytworzyć strukturę przekonań, w której „normalna” droga do osiągnięcia przyjemności, zdrowia, szczęścia, uwolnienia się od bólu i lęku, a nawet uzyskania sprawności seksualnej prowadzi przez palenie, picie, jedzenie i zażywanie środków farmakologicznych (poczynając od aspiryny, środków uspokajających, pigułek dietetycznych i pigułek nasennych). Również hazard propaguje się jako akceptowaną społecznie aktywność, organizując publiczne loterie, quizy telewizyjne i loterie fantowe dla dzieci.
O ile pierwszy krok czyni się pod wpływem zachęty społecznej, o tyle w uczynieniu drugiego kroku pomagają przyjemne doznania oralne, zmiany fizjologiczne, które dają „dobre samopoczucie”oraz aprobata społeczna dla kontynuowania danej czynności. Wydaje się ona „w porządku”, fajna, wystrzałowa, wyrafinowana, męska, kobieca itd., itd. Czynność taka, raz rozpoczęta, nabiera powoli coraz większego znaczenia dla jednostki, a inne dziedziny jej życia są wokół niej organizowane. 
Społeczeństwo zakłada, że jednostki dysponują dostateczną kontrolą nad swym zachowaniem, aby powstrzymać się od całkowitego poddania się tym pokusom. Również większość ludzi jest przekonana, ze nigdy nie ulegliby takiemu niebezpieczeństwu i autodestrukcji. „Ja nie potrafiłbym stać się alkoholikiem czy narkomanem”. Uważają oni nałogowców za ludzi, którzy „zasługują” na to, co ich spotkało, ponieważ mają zbyt „słabą wolę”, aby pomóc sobie samym.
To właśnie nasze |złudzenie |panowania |nad |sobą |i |przekonanie |o |odporności prowadzą nas do niedoceniania potężnego wpływu substancji wywołujących nałogi oraz sytuacji, w których się je przyjmuje. Przeceniamy naszą „zdolność panowania nad sobą” czy „siłę woli” i jesteśmy przekonani, że potrafimy przestać, gdy tylko zechcemy. Jednakże niewiele jest wzorców zachowania trudniejszych do zmiany niż te, które koncentrują się wokół tak utrwalonego nawyku. W jakim stopniu nałóg danej jednostki jest symptomem powszechnej patologii społecznej, a w jakim stopniu oznaką patologii osobistej?




Uzależnienie
od alkoholu




Upajające napoje i ich skutki są dobrze znane od czasów starożytnych.  Niedawne odkrycia archeologiczne wykazały, że sztuka fermentacji jest w istocie dawniejsza od pisanej historii cywilizacji. Jest całkiem możliwe, że alkohol, w tej czy innej postaci, był pierwszym znanym ludzkości środkiem kojącym i od początku utrzymywał swą wątpliwą pozycję najpowszechniej używanego środka tego typu. Jednakże w ostatnich kilku stuleciach coraz wyraźniej okazywało się, że alkohol i życie człowieka nie tworzą dobrej mieszanki. Ocenia się, że obecnie w Stanach Zjednoczonych jest ponad 5 milionów osób pijących, których życie ekonomiczne, społeczne i rodzinne jest poważnie zaburzone wskutek nadużywania alkoholu. Krótko mówiąc, alkoholizm stał się jednym z pojpoważniejszych nałogów, zarówno ze względu na swe rozpowszechnienie jak i konsekwencje.
Problem opanowania alkoholizmu zaostrzają jeszcze postawy wobec picia, jakie istnieją w społeczeństwie. Umiarkowane picie alkoholu jest tolerowane przez prawo, a często spotyka się z zachętą społeczną. Jednakże jednostka, która uzależniła się od alkoholu, nie budzi współczucia, lecz jest ganiona za „brak siły woli”, krytykowana za nieodpowiedzialność i pozostawiona sama sobie, ponieważ zakłada się, że jednostka taka po prostu „nie chce”, aby jej pomagano.


„Musicie zrozumieć, dlaczego się pije. W świecie, w którym prawo jest przeciw ludziom, jeśli kiedykolwiek okażą emocje lub chcą wyzwolić się od szarzyzny swych dni, picie nie jest obrządkiem towarzyskim. Jest to rzecz, której potrzebujesz, aby żyć”.
Jimmy Breslin, cytowany w „Time’ie”, 28 lutego 1969, s. 76.


Formy alkoholizmu. Picie sprawia, że życie alkoholika jest chwilowo łatwiejsze do zniesienia, alkohol stwarza możliwość ucieczki, która staje się tym bardziej kusząca, im więcej się go używa, gdyż nie rozwiązane problemy gromadzą się a samo picie stwarza nowe. Ten wzorzec zachowania utrzymuje się pomimo swej nieprzydatności na dalszą metę, ponieważ jest wzmacniany przez krótkotrwałą ulgę. W pewnym punkcie tej sekwencji obraz komplikuje się jeszcze bardziej, gdyż wytwarza się również uzależnienie fizyczne. Gdy jednak dla każdego jest już od dawna jasne, że zdrowa niegdyś osoba stała się alkoholikiem, to ona sama może zdecydowanie przeczyć temu, utrzymując, że nie pije tyle, by stanowiło to jakikolwiek problem.
E. M. Jellinek (1960), czołowy ekspert bieżącego stulecia w dziedzinie badań nad nadużywaniem alkoholu, stwierdził, że alkoholizm najlepiej można zrozumieć traktując go jako „proces chorobowy”, w którym defekt fizyczny stopniowo powiększa się wraz z upływem czasu i wzrostem konsumcji alkoholu.  Jellinek wyodrębnił pięć głównych typów alkoholizmu, które oznaczył pięcioma literami alfabetu greckiego:

1. |Alkoholizm |alfa: psychiczne uzależnienie od alkoholu.
2. |Alkoholizm |beta: pojawienie się komplikacji fizycznych, a w pewnych przypadkach uzależnienia fizycznego.
3. |Alkoholizm |gamma: wytworzenia się tolerancji na alkohol, co powoduje, że alkoholik pije coraz większe jego ilości.
4. |Alkoholizm |delta: stale wzrastający poziom alkoholu we krwi i niezdolność do powstrzymywania się od picia przez dłuższy okres.
5. |Alkoholizm |epsilon: okresowe picie znacznych ilości alkoholu (tzw. 
„pójście w kurs”).
Chociaż wielu badaczy, którzy zajmowali się problemem alkoholizmu, potwierdza tę klasyfikację, to jednak inni utrzymują, że jest ona nie tyle zbiorem odrębnych typów, ile kontinuum, wzdłuż którego posuwają się poszczególne jednostki.


Zwalczanie alkoholizmu. Doświadczenie wykazało, co nie jest bynajmniej zaskakujące, że kary sądowe, takie jak grzywny i więzienie, są niezadawalającymi sposobami powstrzymywania ludzi od nadmiernego picia alkoholu.


Jednakże pijaństwo jest w Stanach Zjednoczonych powodem blisko trzeciej części |wszystkich aresztowań dokonywanych przez policję. Pociąga to za sobą wielkie koszty - w postaci czasu, wysiłku i pieniędzy - obciążające zarówno departament policji, jak i sądownictwo. Uwięzienie rzadko przyczynia się w jakimś stopniu do leczenia alkoholizmu - stanowi jedynie karę za publiczne demonstrowanie tej „choroby”. Dramatycznym dowodem nieskuteczności tego sposobu reagowania na alkoholizm stało się wykrycie przez komisję badającą wyroki sądowe, że w Waszyngtonie było 6 mężczyzn, którzy łącznie byli aresztowani 1409 razy za pijaństwo i w sumie spędzili 125 lat w zakładach karnych. Trudno to uznać za dane świadczące o skuteczności rehabilitacji! Inny środek prawny - ogólnonarodowa prohibicja - również nie był skuteczny, jeśli chodzi o zredukowanie rozmiarów pijaństwa. Statystyka przyjęć pacjentów-alkoholików do szpitali stanowych w Nowym Jorku między rokiem 1889 a 1943 nie wykazała żadnego związku między prawnym zakazem picia alkoholu a liczbą przypadków alkoholizmu (Landis i Cushman, 1945).
Opracowano najrozmaitsze sposoby klinicznego leczenia alkoholizmu, lecz żaden z nich nie przyniósł większych sukcesów. Techniki psychoterapeutyczne, oparte na przekonaniu, że picie alkoholu jest przede wszystkim objawem leżącego u podstaw zaburzenia emocjonalnego, dążą do zmiany postaw i stylu życia alkoholika za pośrednictwem poradnictwa indywidualnego i społecznego. Zakłada się, że osoba, która znajdzie sposoby uporania się ze swymi problemami, nie będzie już potrzebowała pić. Jednakże nawet w tych przypadkach, w których zależność od alkoholu ma charakter czysto psychologiczny, nawyk picia jest tak silny, że niełatwo go wyeliminować w sposób trwały.
W niektórych przypadkach skuteczne jest leczenie oparte na zasadach uczenia się. Pacjenta zmusza się do picia alkoholu zmieszanego ze środkami wymiotnymi, które powodują silne mdłości. W końcu wytwarza się związek warunkowy, wskutek czego, widok, zapach i smak alkoholu wywołują mdłości i wymioty. Zwykle jednak potrzebna jest także psychoterapia, a często także poradnictwo rodzinne, ponieważ picie alkoholu jest podtrzymywane przez wystarczające wzmocnienie - mianowicie, życie z nim wydaje się przyjemniejsze, lub przynajmniej mniej przykre niż bez niego. Nie jest zatem prawdopodobne wyleczenia alkoholika, jeśli on naprawdę tego nie chce, jeśli nie znajdzie innych sposobów zaspokojenia potrzeb, które zaspokajało picie alkoholu i jeśli nie zmieni warunków środowiskowych, które dostarczają wzmocnienia dla picia alkoholu.
W odniesieniu do pacjentów, którzy są motywowani do zmiany, największe sukcesy przynosi na ogół terapia grupowa lub inne metody pracy grupowej.  Wielu alkoholików znalazło pomoc w rozwiązywaniu swych problemów dzięki nieformalnym organizacjom, takim, jak Alcoholics Anonymous (Anonimowi Alkoholicy). Organizacja ta zapewnia swoim członkom atmosferę wzajemnego zrozumienia, akceptacji, koleżeńskiego współczucia i oparcia emocjonalnego; w atmosferze tej mogą oni rozwiązywać swoje problemy bez poczucia izolacji, wstydu i bezradności, które to uczucia mogą stanowić prawdziwą torturę dla alkoholika borykającego się samotnie ze swym nałogiem. To podejście do leczenia alkohlizmu, oparte na zasadach terapii społecznej, przyniosło znaczne sukcesy, lecz ogromna większość alkoholików nigdy nie przyłączyła się do grupy AA. Krytycznym momentem wszelkiej terapii - z czego poprzednio nie zdawano sobie dostatecznie sprawy - jest to, że aby była ona skuteczna, musi objąć tych, którzy jej potrzebują; trzeba więc |dotrzeć do tych ludzi z terapią, a nie czekać aż ci, którym jest ona potrzebna, zgłoszą się sami.




Uzależnienie
od papierosów




Chociaż historia sumiennie zarejestrowała budzące grozę odkrycia Krzysztofa Kolumba w Nowym Świecie, to jednak bardzo mało uwagi poświęcono temu, co przypuszczalnie było największym błędem - odkryciu i spopularyzowaniu w Europie tytoniu. Obecnie palenie papierosów stanowi najpowszechniejszą formą nałogu w naszej kulturze.


W ostatnich latach nałóg ten stał się przedmiotem powszechnego zainteresowania i troski w wyniku szerokiego rozpowszechnienia sprawozdań naukowych na temat związku między paleniem a szeregiem poważnych schorzeń fizycznych, wśród nich rakiem płuc, bronchitem, chorobą wieńcową i wysoką śmiertelnością wśród niemowląt zrodzonych z matek palących dużo papierosów.  Nawet niepalący są narażeni na niebezpieczeństwo, ponieważ zgodnie z jednym ze sprawozdań medycznych („Surgeon General’s Report” - 1972), „wykazano, że poziom dwutlenku węgla uzyskany w eksperymentach, w których stosowano pomieszczenia wypełnione dymem tytoniowym, osiągał, a niekiedy przekraczał, dozwoloną prawnie granicę maksymalnego stężenia powietrza (...) (s. 7).  Zrozumiałe jest zatem wołanie niepalących o oddzielenie ich od palaczy w samolotach, restauracjach itd.
Uzależnienie od papierosów ma charakter głównie psychologiczny. Chociaż u nałogowego palacza rozwija się tolerancja na nikotynę, to jednak tolerancja ta jest ograniczona, co zapobiega zmianom adaptacyjnym w komórkach nerwowych, które to zmiany powodują uzależnienie fizyczne w wypadku innych substancji. Nie oznacza to jednak bynajmniej, że zerwanie z tym nałogiem jest sprawą prostą, o czym może powiedzieć każdy palacz, który próbował rzucić palenie. Pomimo licznych prób znalezienia metody „leczenia” nałogu palenia papierosów, nawyk ten pozostaje zdumiewająco odporny na wygaszanie.  Różnorodne techniki - modyfikacje zachowania, psychoterapia, stymulacja sensoryczna, terapia farmakologiczna, hipnoza i mnóstwo innych - zdają się być skuteczne przez krótki czas po zrealizowaniu programu terapeutycznego, lecz żadna z nich nie wykazała skuteczności na dalszą metę.
Zagadnienie motywacji przyczyniającej się do utrzymywania się nawyku palenia - zwłaszcza u osób, które wyznają chęć rzucenia tego nawyku - jest niezmiernie złożone. Wysunięto liczne hipotezy dotyczące wchodzących tu w grę mechanizmów behawioralnych. W dążeniu do zmodyfikowania zachowania palaczy stosowano zdumiewająco szeroki wachlarz technik, pojedynczo lub łącznie (tabela poniżej). Techniki takie są odzwierciedleniem najróżniejszych hipotez - wyraźnie sformułowanych bądź ukrytych - jakie wysuwają badacze pracujący w tej dziedzinie.


Świat struktur poznawczych palacza. Jedną z głównych przyczyn nadmiernego palenia jest skojarzona z nim satysfakcja. Ponieważ skojarzenia te są wyuczone, przeto u poszczególnych palaczy są one bardzo różne. Jeden palacz podaje, że pali aby osiągnąć stan pobudzenia, inny - dla odprężenia, a jeszcze inny - ze względu na poczucie więzi towarzyskiej, jaką daje palenie. Można tylko domyślać się, ile osób z pokolenia twoich rodziców i dziadków zaczęło palić po obejrzeniu sceny miłosnej w starym filmie „Now Voyager”, w którym Paul Henreid wkładał do ust dwa papierosy, zapalał je i - w jednym z najbardziej wyrafinowanych epizodów w dziejach kina - przekazywał jeden z nich Bette Davis.


Techniki Stosowane W Celu Nakłonienia Palaczy Do Zaprzestania Palenia
1. Wielokrotne przeżuwanie pokarmu przed połknięciem
2. Zachowanie specjalnej czystości
3. Unikanie wulgarnych słów
4. Zmiany diety
5. Wczesne wstawianie
6. Gorące kąpiele
7. Zimne prysznice
8. Wysyłanie odzieży do oczyszczenia
9. Ćwiczenie się w głębokim oddychaniu
10. Utrzymywanie się w dobrej formie fizycznej
11. Środki farmakologiczne, takie jak lobelina
12. Sugestie pod hipnozą
13. Zachęta słowna
14. Porady podtrzymujące
15. Dyskusja grupowa
16. Podpisanie przyrzeczenia, którego złamanie powoduje utratę złożonej kaucji
17. Skojarzenie z paleniem papierosów mdłości, wywoływanych środkami farmakologicznymi
18. Skojarzenie z paleniem przykrych bodźców (dmuchnięcie gorącym powietrzem w twarz)
19. „Biały szum”, przerywający przyjemną muzykę, a skojarzony z paleniem
20. Wstrząs elektryczny skojarzony z paleniem
21. Wypowiadanie słów „Palenie papierosów powoduje raka” przed wykonywaniem jakiejś często występującej czynności
22. Odgrywanie roli pacjenta, który rozmawiając z lekarzem dowiaduje się, że jest chory na raka płuc

(Według Brensteina, 1969)


Palenie papierosów w znacznym stopniu skojarzyło się z takimi elementami poznawczymi, jak męska szorstkość, lojalność i wytrwałość (to ci, którzy raczej będą walczyć niż ustąpią, lub - ośmielamy się przypuszczać - raczej umrą niż przestaną), jak również z wieloma innymi pożądanymi cechami.  Czynniki poznawcze odgrywają także pewną rolę w próbach zaprzestania palenia.


„W pewnym eksperymencie nad zaprzestaniem palenia, wszystkich osiemnastu badanych, którym podano informację o wysokim prawdopodobieństwie sukcesu oraz duże pozytywne wzmocnienie, istotnie rzuciło palenie, a czternastu z nich nie paliło nadal po dwóch miesiącach. Osiemnaście osób badanych z grupy kontrolnej, dobranych na podobnych zasadach (matched) otrzymało minimalne wzmocnienie słowne i informacje o małych szansach sukcesu. Tylko osiem z nich rzuciło palenie i tylko jedna nie paliła w czasie uzupełniających badań przeprowadzonych dwa miesiące później” (Lichtenstein, 1971).


Palacze oczekują, że jeśli będą powstrzymywać się od palenia, to wystąpią u nich różne niepożądane efekty uboczne, drażliwość, nerwowość i wzmożony apetyt. Takie przekonania utrudniają zaprzestanie palenia i wytrwanie przy takim postanowieniu, lecz można nimi manipulować za pomocą techniki zwanej |terapią |atrybucyjną („attribution therapy”; Ross, Rodin i Zimbardo, 1969; Nisbett i Schachter, 1966). Wychodząc z założenia, że psychiczne przejawy jakiejś zmiany w stanach wewnętrznych są zależne od interpretacji, jaką ludzie nadają swym wrażeniom, terapia atrybucyjna po prostu dostarcza nowych czy odmiennych interpretacji dla odczuwania wrażeń. Te nowe interpretacje przypisują spostrzegany stan wewnętrzny jakiejś przyczynie, która ma charakter wewnętrzny, jest neutralna afektywnie i znajduje się pod kontrolą danej jednostki.
Poniższy interesujący przykład zastosowania terapii atrybucyjnej - dla łatwiejszego powstrzymywania się od palenia papierosów - pochodzi z badań nad pielęgniarkami, przeprowadzonych przez Barefoota i Girodo (1972).


„Piętnastu pielęgniarkom, które regularnie paliły, powiedziano, że biorą one udział w badaniach mających na celu ustalenie wpływu pewnych leków na tempo pracy serca. Poproszono je, aby powstrzymywały się od palenia przez jeden dzień. Osobom badanym z grupy eksperymentalnej podano placebo, które - jak im powiedziano - miało spowodować pewne ujemne efekty uboczne: zwiększoną drażliwość, nerwowość i wzmożony apetyt (objawy często kojarzone z zaprzestaniem palenia). Osobom badanym z grupy kontrolnej również podano placebo, lecz nie ostrzegano ich o możliwych efektach ubocznych. Jak przewidywano, osoby z grupy eksperymentalnej przypisywały swe dolegliwości działaniu pigułki i podały, że łatwiej im było powstrzymać się od palenia, niż wynikałoby to z wypowiedzi osób badanych z grupy kontrolnej, które przypisywały swe fizjologiczne i psychiczne dolegliwości temu, że pozbawiono je papierosów”.


Trochę profilaktyki... Biorąc pod uwagę trudności związane z wyeliminowaniem nałogu palenia, wielu badaczy uważa |zapobieganie paleniu za bardziej owocną dziedzinę eksperymentowania. W tym celu starają się oni zidentyfikować warunki społeczne i psychologiczne, które sprzyjają paleniu.  Zdaje się nie ulegać wątpliwości, że jeśli jakieś stałe działanie zmierzające do wyeliminowania palenia ma przynieść sukces, to konieczna jest zmiana obrazu palacza prezentowanego przez takie czynniki kulturowotwórcze, jak środki masowego przekazu. Sugeruje się więc, że niezbędna „terapia” musi przyjąć postać politycznej ustawy, która ograniczyłaby reklamę i demonstrowanie przez masowe środki przekazu przyjemności palenia papierosów, co tworzy ten obraz „atrakcyjnego, igrającego ze śmiercią utrapieńca”. Ponadto niezbędne może być rozwinięcie skuteczniejszej kontredukacji, aby ostrzegać dzieci o następstwach nałogu palenia dla zdrowia. Sugestie takie spotykają się z oporem ze strony potężnych grup nacisku, co świadczy o konflikcie pomiędzy społeczną odpowiedzialnością rządu na zdrowie fizyczne swych obywateli i jego troską o ekonomiczne zdrowie przedsięwzięć komercyjnych (a także o podatki, jakie z nich czerpie), które prosperują dzięki temu nałogowi.




Narkomania




Nie ma chyba drugiego zjawiska psychologicznego, które wywierałoby tak głęboki wpływ na tak znaczną część populacji, jak ten, który wywiera używanie i nadużywanie środków psychotropowych. Ludzie zażywają środki psychotropowe z różnych powodów. Używają ich dla przyjemności, aby znaleźć ulgę w cierpieniu, aby uciec od problemów osobistych, aby rozwinąć swą świadomość, aby lepiej funkcjonować itd. Bardzo często u ludzi rozwija się silna psychiczna potrzeba zażywania określonego środka farmakologicznego, ponieważ mają oni pewien określony problem, z którym nie potrafią sobie poradzić. Amerykańskie społeczeństwo przyzwyczaiło się do zażywania środków farmakologicznych w wielkich ilościach - zarówno dla celów medycznych, jak i w nieuzasadnionych okolicznościach. Narkomania występowała w USA od dawna, lecz ograniczała się głównie do mniejszości rasowych i osób z niższych warstw społeczno-ekonomicznych. W ostatnich kilku czy kilkunastu latach nastąpił ogromny wzrost nie kontrolowanego użycia środków psychotropowych w klasie średniej, wyższej, zwłaszcza wśród ludzi młodych, którzy zażywając te środki przede wszystkim dla rozrywki, pragnąc uciec od rzeczywistości i poszukując mistycznych doznań.


Badania przeprowadzone przez National Commission on Marijuana and Drug Abuse (Narodową Komisję do Spraw Nadużywania Marihuany i Środków Psychotropowych), obejmuje trzy tysiące stu osiemdziesięciu sześciu Amerykanów (włączając tu młodzież w wieku od 12 do 18 lat), dostarczyły wstrząsających danych, które ukazują, jak wielu młodych i starych ludzi zażywa środki psychotropowe:


Środek psychotropowy - Liczba osób, które próbowały danego środka (w mln)
Środki przeciwbólowe, morfina, kodeina - 2,6
Recepturowe środki uspokajające - dla przyjemności - 2,6
Recepturowe środki pobudzające - 5,8
Środki nasenne, barbiturany - 4,5
Metamfetaminy - 3,7
Kokaina - 2,6
Środki halucynogenne (LSD, meskalina, pejotl) - 4,7
Heroina - 2,2


Istnieje wiele teorii starających się wyjaśnić, dlaczego do tego doszło.  Jedna z teorii głosi, że jest to naturalne zjawisko w kulturze już zorientowanej na środki farmakologiczne, takiej jak amerykańska, gdy staje się ona bardziej zasobna. Inna teoria stwierdza, że gdy ludzie dowiadują się więcej o środkach psychotropowych, to stają się bardziej ciekawi i mają chęć je wypróbować. Gdy tylko zażywanie środków psychotropowych staje się akceptowanym czy zgodnym z normą zachowaniem w określonej kulturze, wówczas większa liczba jej członków ma sposobność obserwować inne osoby zażywające środki psychotropowe, środki te stają się łatwiej dostępny i wzrastają naciski grupy nakłaniającej do ich zażywania (jak widzieliśmy już w Rozdziale 7).
Dobrze wiadomo, że użycie środków psychotropowych wzrastało również w innych okresach zamętu kulturowego. Po wojnach lub w czasie wojen często następował dramatyczny wzrost użycia środków psychotropowych. Nasze czasy są erą szczególnej niestabilności, kiedy to podważane są wszelkie tradycyjne wartości oraz instytucje i ani dorośli, ani młodzi ludzie nie wiedzą, co przyniesie przyszłość. Dzisiejsza młodzież patrzy z niestępioną wrażliwością na problemy skażenia środowiska, korupcję polityczną, dyskryminację rasową i seksualną oraz niehumanitarne stosunki między ludźmi, i chociaż w wielu wypadkach musi ona dopiero znaleźć lepsze sposoby rozwiązania tych problemów, niemniej jednak nie akceptuje ślepo wartości uznawanych przez swych rodziców. Jeśli zaś raz zacząłeś wyłamywać się z systemu wartości dominującej kultury dla jakichkolwiek powodów, to zaczynasz eksperymentować z różnymi rzeczami, które nie były sankcjonowane przez ten tradycyjny system, takimi, jak protest polityczny, inne religie, bardziej liberalna etyka seksualnego czy wreszcie używanie środków psychotropowych. Używanie tych środków jest jednak zjawiskiem bardzo złożonym. Problemy osobowości, niepokoje wieku dorastania, kryzysy tożsamości, przyczyny natury społecznej i nacisk grupy rówieśniczej - wszystkie te czynniki są ważne.
Ostatnie badania wykazują, że większość młodych ludzi, którzy zaczynają brać jakiś środek psychotropowy, zwłaszcza zakazany przez prawo, czyni to po raz pierwszy z ciekawości i pod wpływem nacisku grupy rówieśniczej. Gdy dana jednostka znajdzie się w obrębie podkultury danego środka psychotropowego („drug subculture”), wówczas sposób, w jaki będzie zażywała ten środek jest uzależniony od wzorów obowiązujących w danej podkulturze.  Jeśli jest to subkultura bardzo destruktywna, to może występować silny nacisk grupy rówieśniczej na eksperymentowanie z wstrzykiwaniem amfetamin, z heroiną czy kokainą, lub z różnymi środkami łatwo wywołującymi uzależnienie. Jeśli dana jednostka jest pod wpływem jakiejś mniej destruktywnej subkultury środków psychotropowych (takiej, jaka zwykle istnieje na wyższej uczelni), to wpływ nacisku tej grupy może skłonić ją, by ograniczyła się do środków o niższym potencjale wywoływania zależności.  W początkowych stadiach nałogu ludzie rzadko samodzielnie podejmują decyzje dotyczące zażywania środków psychotropowych. Silny wpływ wywiera na nich zwykle to, co ich zdaniem robią inni, pragnienie, aby zrobić wrażenie na kolegach lub nie być różnym od nich, oraz to, jakie środki są dostępne w ich środowisku.




Zbliżenie


Heroina szturmuje Harlem


„Heroina prawie zdobyła już Harlem. Wydaje się, ze jest to coś w rodzaju plagi. Za każdym razem, gdy poszedłem tam, ktoś inny „połknął haczyk”, ktoś inny „wciągnął się”. Ludzie mówili o nich tak, jak gdyby byli już martwi.  Pytałeś o jakiegoś starego przyjaciela, a oni mówili: „Ach, no cóż, on się wciągnął”. Nie była to po prostu uwaga, czy odpowiedź na pytanie. To była mowa pogrzebowa dla kogoś, kto był już po prostu zupełnie martwy.
W tym czasie nie znałem nikogo, kto by się temu przeciwstawił. Heroina była czymś najważniejszym w Harlemie przez blisko 5 lat i nie sądzę, abym znalazł kogoś, kto by ją odrzucił...
Obawiałem się pytać o kogoś, kogo nie widziałem przez jakiś czas, zwłaszcza jeśli był to ktoś, kto był kiedyś moim dobrym przyjacielem.  Zawsze było prawdopodobne, że ktoś powie „No cóż, on nie żyje - ten facet przedawkował heroinę””; lub że zepchnięto go z okna, gdy próbował włamać się, aby obrabować czyjeś mieszkanie, lub dostał 5 strzałów, gdy usiłował obrobić jakieś miejsce, aby zdobyć trochę pieniędzy na narkotyki. Narkotyki zabijały prawie każdego, w ten lub inny sposób. To opanowało całą dzielnicę, całą społeczność...
Faceci, którzy jeszcze się w to nie wciągnęli, nie potrafili dostrzec, dokąd zmierzają. Jeśli zażywali trochę heroiny, to zdawali się sądzić, że ona nie da sobie z nimi rady. Ci faceci, jak gdyby mówili: „No cóż, do cholery, jestem fajniejszy niż inni””, mimo że sporo fajnych facetów i sporo twardych gości wpadło w szpony heroiny. Każdy mógł się przekonać, że nikomu nie udało się od niej uwolnić, gdy już raz zaczął z nią kombinować, lecz nadal niektórzy ludzie zdawali się myśleć: „Gówno, nie myślę dać się złapać. Potrafię ją zażywać, mogę brać ją i nie dać się złapać””. 
Faceci, którzy już się wciągnęli, starali się utrzymać swoich młodszych braci z dala od narkotyku. Starali się słabo i trudno się temu dziwić, ponieważ faceci, którzy wciągnęli się w narkotyki, nie mieli zbyt wiele czasu, aby kłopotać się o kogokolwiek innego poza sobą. Trzeba było praktycznie starć się 24 godziny na dobę, aby zdobyć pieniądze na odrobinę narkotyku...” (Brown, 1956, s. 179-180).


Przeprowadzone niedawno badania nad dynamiką epidemii nałogu zażywania heroiny, która ogarnęła Waszyngton w latach 1969-70, wykazały, że dotknęła ona bezpośrednio - jak się ocenia - około 18000 mieszkańców, zaś trudna do określenia ich liczba została „skażona” pośrednio (DuPont i Greene, 1973).  Dla zrealizowania opracowanego przez władze miejskie wszechstronnego programu terapii utworzono NTA - Narcotics Treatment Administration (Urząd Leczenia Narkomanii). Jednego dnia rozpoczynało leczenie nawet 58 pacjentów - zapotrzebowanie przekraczało „zdolność przepustową” tego ośrodka.



ramach tego jednego programu leczenia narkomanii poddano terapii w ciągu trzech lat około 13000 ludzi. W tym samym czasie zanotowano ponad 200 przypadków śmierci wskutek przedawkowania silnych środków zawierających opium.
Tego rodzaju środki są niezbędne nie tylko do leczenia przypadków wymagających pomocy lekarskiej, lecz także w celu zbierania danych o cechach osób zażywających nałogowo środki psychotropowe, tak, abyśmy mogli lepiej zrozumieć dynamikę problemu, a nie tylko jego konsekwencje. Spośród 13000 pacjentów NTA większość po raz pierwszy zażyła heroinę w wieku 16 - 20 lat, aczkolwiek wiele osób zażywało ten narkotyk przed ukończeniem 15 roku życia. Okazało się, że główną formą rozpowszechniania tego nałogu był kontakt towarzyski „w cztery oczy”. Jest to zatem „choroba zakaźna”, gdyż ludzie dotknięci nią przekazują ten nałóg innym. Tę towarzyską formę rozpowszechniania stwierdzono także we wcześniejszych badaniach nad nałogiem zażywania heroiny przez mieszkańców dzielnic podmiejskich (Levingood i in., 1971).


Opanowanie tej epidemii wymaga energicznego egzekwowania prawa tak, by zredukować podaż heroiny, a także zwiększenia liczby łatwo dostępnych ośrodków leczenia narkomanii. Problem ten jest jednak bardzo złożony, ponieważ przychodnie, w których zamiast heroiny podaje się methadon, donoszą, iż niektóre osoby uprzednio zażywające nałogowo heroinę, biorą metamfetaminy w celu spotęgowania „rauszu” występującego po przyjęciu methadonu, inni popadają w nałóg zażywania methadonu, a jeszcze inni skarżą się na utratę popędu seksualnego, co jest ubocznym efektem działania methadonu. Ten ostatni efekt stwarza oczywiście nowe problemy dla pacjenta.


Uzależnienie fizyczne i psychiczne. Każdy środek psychotropowy odznacza się pewną zdolnością wywoływania uzależnienia. Jedną z cech charakterystycznych tej zdolności jest to, iż dana jednostka może odczuwać przymus zażywania danego środka ze względu na uzależnienie psychiczne, uzależnienie fizyczne lub też ze względu na jedno i drugie.
W przypadku uzależnienia psychicznego, dana jednostka odczuwa silną potrzebę emocjonalną, by kontynuować zażywanie danego środka psychotropowego dla przyjemności lub dla ulgi w cierpieniach. Jeśli środek ten jest niedostępny, to osoba uprzednio zażywająca go staje się niespokojna, podrażniona i rozgniewana, lecz zwykle nie ma żadnych poważnych dolegliwości fizycznych.
Prawie każdy środek psychotropowy może wytworzyć uzależnienie psychiczne; nikotyna zawarta w papierosach, alkohol, kofeina, marihuana oraz amfetaminy - wszystko to są środki, które często wytwarzają uzależnienie psychiczne.
Pewne środki mogą również wytwarzać uzależnienie fizyczne.  Przypuszczalnie najlepiej znanymi z nich są |narkotyki otrzymywane z opium, takie jak heroina i morfina. Długotrwałe zażywanie tych środków czyni organizm fizycznie uzależnionym od obecności danej substancji chemicznej, która staje się niezbędna dla normalnego funkcjonowania; jeśli substancji tej brak w organizmie, to występuje ogólna reakcja fizjologiczna zwana |zespołem |abstynencyjnym („abstinence syndrome”), która przyczynia danej jednostce wiele cierpień. Dolegliwości te będą trwały przez kilka dni, jeśli nie zostaną wyeliminowane przez ponowne zażycie danego środka.
W pewnych przypadkach takie gwałtowne odstawienie środka psychotropowego może być niebezpieczne dla życia. Jeśli u kogoś wytworzyło się na przykład uzależnienie fizyczne od barbituranów, które są powszechnie stosowane jako pigułki nasenne, to gwałtowne odstawienie tych środków może spowodować drgawki, a nawet doprowadzić do śmierci.
W wypadku innych środków wytwarzających uzależnienie fizyczne, takich, jak heroina, wycofanie ich powoduje niezwykle przykre dolegliwości trwające kilka dni. Strach przed tymi skutkami odstawienia heroiny bardzo często powstrzymuje daną osobę zażywającą ją nałogowo od zerwania z tym nałogiem.  Osoba taka może zatem kontynuować zażywanie narkotyku, chociaż przestał on już dawno dostarczać jej jakichkolwiek euforycznych przeżyć, jedynie dlatego, że chce uniknąć przykrego procesu odstawienia tego narkotyku.


Progresywny charakter narkomanii („drug addiction”). Osoby, które stają się nałogowymi użytkownikami środków psychotropowych, przechodzą zwykle przez trzy stadia nałogu. Pierwszym jest stadium |eksperymentowania, w którym mogą one próbować najrozmaitszych środków psychotropowych z ciekawości lub pod naciskiem grupy rówieśniczej. Następnie mogą zdecydować się na odrzucenie większości tych środków, z którymi eksperymentowały, po czym sporadycznie, dla rozrywki, używają jedynie paru. Dana osoba może na przykład, od czasu do czasu pić alkohol lub palić marihuanę. W tym |rekreacyjnym stadium, o ile nie osiąga się poziomu zatrucia, dana jednostka rzadko popada w kłopoty. Jednakże w sprzyjających okolicznościach, czy to ze względu na warunki społeczne, czy też problemy osobowościowe, osoba taka przechodzi w stadium przymusowego stosowania danego środka. To trzecie stadium nosi nazwę stadium |nadużywania |środka |psychotropowego („drug abuse”), ponieważ ilości, w jakiej jest on zażywany przynosi szkodę zarówno zdrowiu danej osoby, jak i jej funkcjonowaniu ekonomicznemu czy społecznemu.
Istnieje wiele cech osobowości, które mogą predysponować ludzi do nadużywania środków psychotropowych. Psychiatryczny czy kliniczny opis nałogowca tradycyjnie przedstawia jednostkę niedojrzałą, przytłoczoną poczuciem nieadekwatności, skłonną do autodestrukcji, lecz równocześnie narcystycznie zaabsorbowaną autogratyfikacją (Nyswander, 1956).  Interpretacje psychoanalityczne wiążą niekiedy nałogowe zażywanie środków psychotropowych z takimi zjawiskami, jak „nieświadomy homoseksualizm”, „symbolizm falliczny” (na przykład strzykawka), „kompleks Edypa”, a zwłaszcza „fiksacja oralna” (Fenichel, 1945).
Jednakże próby psychiatrycznej diagnozy cech osobowości nałogowców nasuwają poważne wątpliwości. Psychiatrzy badają nałogowca dopiero |po wytworzeniu się u niego nałogu, a zatem nie są w stanie oddzielić cech wynikających z nałogu, od cech, które spowodowały nałóg. Ich interpretacje mają zawsze charakter retrospektywno-historyczny. Biorąc pod uwagę to, co widzą w danej chwili zastanawiają się, jaka była dana osoba przedtem?  Oprócz oczywistego wpływu długotrwałego zażywania środka psychotropowego na osobowość, z pewnością wchodzą tu także w grę różne inne związane z tym czynniki, a zwłaszcza psychologiczne i socjologiczne implikacje odgrywania roli nałogowca w naszym społeczeństwie. Jak słusznie podkreślił Clausen (1971), „osobowość nie jest niezależna od wpływów środowiskowych i na ogół te same oddziaływania, które sprawiają, że (narkotyki) są dostępne dla nastolatków, i które pozwalają znacznej części młodzieży w wieku dorastania stać się członkami „społeczeństwa z rogu ulicy”, stwarzają także potrzeby psychiczne i słabości, które zwiększają wartość narkotyków dla jednostki” (s. 212). Ten złożony problem zdaje się być zatem w równej mierze funkcją patologii społecznej, jak i patologii indywidualnej.
Wysoce niezadawalające wyniki osiągane przy zastosowaniu konwencjonalnych technik terapeutycznych dostarczyły w ostatnich latach inspiracji dla dla poszukiwań nowych sposobów podejścia do problemu i dla odrzucenia wcześniejszych, nadmiernie uproszczonych teorii nałogu. W coraz większym stopniu akceptuje się potrzebę zintegrowanej koncepcji uwzględniającej społeczne, psychologiczne, medyczne i prawne aspekty nałogu. Z pewnością wszystkie te punkty widzenia trzeba poważnie brać pod uwagę zarówno przy ocenie przyczyn nałogu jednostek, czy społecznego problemu narkomanii, jak i w planowaniu skutecznych programów działania, zmierzających do opanowania zjawiska nadużywania środków psychotropowych.




„Mam prawo być sobą,
robić to, co chcę”




Picie alkoholu, palenie papierosów, zażywanie środków psychotropowych, uprawianie hazardu - są to rzeczy, do których dorośli mają prawo; są one źródłem osobistej przyjemności, i kiedy robi się je samemu lub z paroma bliskimi przyjaciółmi są czynnościami prywatnymi, nie zaburzającymi publicznego sektora życia. Gdy jednak uprawia się je w sposób nieumiarkowany, wówczas przestają być „zbrodniami bez ofiar”, ponieważ oddziałują na innych ludzi - rodzinę, przyjaciół, współpracowników, policję, pracowników systemu sądowego, tych, którzy muszą zapewniać opiekę lekarską, zorganizowany świat przestępczy oraz tych, którzy są wykorzystywani w różny sposób, aby w ten sposób umożliwić zaspokajanie patologicznego nałogu. Nałogi te zmuszają nałogowców do uzależnienia się od nie podlegającej nałogom części społeczeństwa, która zapewnia im opiekę i leczenie. Stanowią oni ogromny ciężar dla społeczeństwa - zarówno psychologiczny, jak i finansowy. Ci, którzy planują dalszy rozwój naszego społeczeństwa, muszą zwrócić większą uwagę na to, aby rozwój ten przebiegał w sposób, który pomoże zaspokoić niektóre z potrzeb, jakie znajdują swój wyraz w tych nałogach. Jednocześnie my wszyscy musimy lepiej zdawać sobie sprawę z naszej własnej słabości i uświadomić sobie istnienie w naszym środowisku subtelnych sił, które mogą podstępnie pokierować naszym zachowaniem w taki sposób, że będziemy robić właśnie te rzeczy, co do których jesteśmy pewni, że nigdy byśmy ich nie zrobili.




Utrata radości
życia: nerwica




Gdy jednostka czuje się zarówno nieustannie zagrożona niebezpieczeństwami życia, jak i niezdolna do borykania się z nimi, wówczas zwykłe środki obrony, którymi posługujemy się wszyscy, już jej nie wystarczają. Stopniowo może ona zacząć nadmiernie polegać na jednej neurotycznej formie obrony (lub na kilku tego rodzaju formach). Wspólną cechą tych form obrony jest to, że pozwalają one uwolnić się od lęku, toteż występują one zwykle u ludzi, których charakteryzuje brak radości życia, a działania wynikające z tych form obrony zmierzają raczej do zmniejszenia cierpienia niż do pozytywnych dokonań czy konstruktywnego rozwiązania rzeczywistych problemów. Zapewniają one chwilową ulgę od lęku w wystarczającym stopniu, aby wiele osób trzymało się ich desperacko, pomimo tego, że nie rozwiązują one ich zasadniczych problemów, a nawet mogą pogłębić je - są zatem szkodliwe na dalszą metę.
Tragedia neurotyka polega na tym, że często jego ocena świata, jako zagrażającego, i siebie samego, jako nie efektywnego, jest błędna. Gdyby patrzył na sprawy bardziej realistycznie, to nie byłaby potrzebna ta utrata radości życia czy męczące zaabsorbowanie zmartwieniami i niebezpieczeństwami.
Na ogół „normalna” osoba funkcjonuje jako zorganizowana całość i mniej lub bardziej skutecznie radzi sobie z frustracjami. Lecz dla psychologa „normalność” obejmuje szeroki zakres zachowań, a nie pojedynczy, określony punkt na skali. Nie ma zatem wyraźnej linii podziału między „normalną” osobą a neurotykiem: różnica jest różnicą stopnia. Środki obrony stosowane przez neurotyka uważa się za nienormalne, ponieważ reprezentują one zdecydowanie i chronicznie nieskuteczne sposoby radzenia sobie z wymaganiami życia. Jednakże anomalie te rzadko są na tyle poważne, by wymagały hospitalizacji.
Jeśli istnieje kontinuum normalny - neurotyczny, to w jakim punkcie możemy uznać daną osobę za wykazującą dostatecznie duże zaburzenia, aby usprawiedliwiały nadanie jej etykietki „neurotyka” (czy też może taki proces nadawania etykietek nigdy nie jest usprawiedliwiony?). Jakie oznaki behawioralne są wykorzystywane dla zidentyfikowania jednostki neurotycznej?  W tradycyjnej psychologii zidentyfikowano kilka odrębnych postaci nerwicy, z których sześć opiszemy poniżej.




Nerwica lękowa




Niekiedy źródłem lęku dla osób neurotycznych nie jest niebezpieczeństwo zewnętrzne, lecz wewnętrzne. Mogą one być przekonane, że nie powinny przeżywać pewnych uczuć i pragnień, takich jak wrogość czy pragnienia seksualne, a zatem mogą nie potrafić zaakceptować faktu ich występowania.  Kiedy jednak pojawiają się - wówczas mogą być wypierane ze świadomości i trzeba wiele wysiłku także nieświadomego, aby utrzymać je pod progiem świadomości. Gdy od czasu do czasu grozi pojawienie się w świadomości takich myśli czy pragnień, wtedy neurotyk może doznawać uczuć lęku przed nadciągającą zgubą i może mieć napady objawów fizjologicznych, takich jak przyspieszone bicie serca lub duszności.
W wielu przypadkach osoba taka zasięga porady lekarskiej; ocenia się, że 30% wszystkich pacjentów zgłaszających się do internistów w rzeczywistości należy do kategorii (Pitts, 1969). Szacuje się też, że około 10 milionów Amerykanów cierpi na nerwicę lękową. Nie tylko lekarz nie potrafi znaleźć żadnej choroby, lecz także sami pacjenci mogą wcale nie umieć wyjaśnić, dlaczego odczuwają taki lęk; lęk ten z niczym się nie wiąże (ang.  „free-floating”-dosłownie „unoszący się swobodnie”). Niekiedy pacjenci odczuwają również niezwykle silne poczucie winy, nie wiedząc dlaczego.
Właśnie ta nieuchwytna nieokreśloność doznań lękowych jest w dużym stopniu odpowiedzialna za przerażenie, jakie odczuwa pacjent. Wyobraź sobie, że odczuwasz silne pobudzenie, dziwne rzeczy dzieją się w twojej głowie i w całym ciele - i nie masz dla nich żadnego racjonalnego wyjaśnienia. Idziesz do lekarza, a po dokładnym badaniu lekarz zapewnia cię, że nic ci nie jest. Lecz w twojej głowie coś tłucze się i tłucze, i...
Owa niemożność wyjaśnienia tego, „niewytłumaczalnego pobudzenia” stwarza teraz zagrożenie dla twojego poczucia samowiedzy oraz samokontroli i wytwarza dodatkowy lęk. Jednym z głównych celów psychoterapii jest określenie pierwotnego źródła lęku, aby można było przekształcić go w konkretny, uchwytny strach. „Daj mu nazwę, a będziesz mógł coś z nim zrobić” (Grimmett, 1970).
Lęk neurotyczny można odróżnić od lęku obiektywnego czyli strachu. Strach jest racjonalną reakcją na obiektywne, rozpoznane zewnętrzne zagrożenie i może pociągnąć za sobą ucieczkę lub atak w samoobronie. W lęku neurotycznym pobudzenie emocjonalne jest równie silne, lecz niebezpieczeństwo ma charakter wewnętrzny: ani nie daje się zidentyfikować, ani inne osoby w tej sytuacji nie uważają go za równie zagrażające.
Aczkolwiek uważa się, że napady lęku wywołują czynniki zawarte w doświadczeniu danej jednostki, to jednak istnieją również pewne dane na temat anormalnych reakcji biochemicznych (Pitts, 1969).




Fobie




W |fobiach lęk zostaje związany z określonym przedmiotem w środowisku zewnętrznym, lecz na ogół przedmiot ten nie jest źródłem fizycznego zagrożenia ani biologicznego niebezpieczeństwa. Toteż neurotycy często zdają sobie sprawę, że ich gwałtowna reakcja jest nieracjonalna - nie ma dla niej zadowalającego wyjaśnienia - lecz ta świadomość czyni tylko ich lęk jeszcze trudniejszym do zniesienia. W niektórych przypadkach wybór obiektu fobii jest czysto symboliczny; w innych pozostaje on w ścisłym związku z konfliktem stanowiącym podłoże fobii.


„Pewien robotnik budowlany musiał zrezygnować ze swej pracy, ponieważ rozwinął się u niego lęk wysokości. Każdy wie, że w pracach budowlanych zdarzają się wypadki; czy jego lęk był obiektywny czy neurotyczny? Nie mając dodatkowych danych, nie można by było odpowiedzieć na to pytanie.  Jednakże, w tym konkretnym przypadku u mężczyzny tego rozwinął się także lęk przed otwartymi przestrzeniami na powierzchni ziemi (które nie są źródłem niebezpieczeństwa), a także lęk przed śmiercią.
Okazało się, że przed wystąpieniem u niego reakcji lękowych, pewien kolega w pracy zaczął mu nieustannie dokuczać. Pacjent powiedział: „Miałem chęć go zabić”. Jednakże w rzeczywistości czuł się bezradny i nie widział żadnej możliwości podjęcia jakiegoś działania, które skłoniłoby kolegę do zrezygnowania z denerwującego zachowania. Możliwe, że rezygnując z tej pracy bronił się przeciw swym impulsom skłaniającym go do zabójstwa, jak również przeciw swej własnej niezdolności przeciwstawienia się dręczycielowi. W każdym razie lęk wysokości był skutecznym rozwiązaniem jego problemu, gdyż dostarczył usprawiedliwienia dla rezygnacji z popłatnej pracy”.


Nie ma właściwie żadnych granic, jeśli chodzi o zakres spraw, jakie mogą być symbolizowane przez fobie, ponieważ twórczy umysł potrafi konstruować bardzo odległe skojarzenia. Fobie dotyczące takich obiektów, jak nieszkodliwe węże, owady czy ptaki, dotknięcie innej osoby, włosy oraz inne zupełnie nieszkodliwe przedmioty czy sytuacje mogą wywoływać silne reakcje doprowadzające do paniki, jeśli dana osoba nie może uciec.  Charakterystyczne dla fobii są skomplikowane środki ostrożności i środki obronne, które dana jednostka wprowadza dla uniknięcia wszelkiego kontaktu z niebezpiecznym obiektem fobii. Wydaje się, jak gdyby neurotycy radzili sobie ze swymi konfliktami wewnętrznymi eksternalizując je na pewien obiekt - wówczas dopóty, dopóki mogą unikać tego obiektu, mogą także unikać zetknięcia się z lękiem, jaki istnieje w nich samych.
Osoby cierpiące na fobie funkcjonują zupełnie dobrze, gdy obiekty tych fobii są rzadko spotykane lub łatwo można ich uniknąć. Lęk przed wężami u mieszkańców miast, lęk przed wysokością wśród mieszkańców wsi itd., stanowią dogodne sposoby kanalizowania lęku przez „usunięcie go z myśli” i związanie z czymś, co nie będzie nieustannie powtarzającym się zagrożeniem.  W istocie fobia może stać się źródłem poważnych kłopotów dla danej osoby tylko wtedy, gdy danego obiektu nie można łatwo uniknąć i wskutek tego zakłóca on działanie jednostki.
W niektórych kulturach wyboru przedmiotu fobii nie pozostawia się jednostce, lecz zwyczajowo jest on wyznaczany przez znachora lub „lekarza-czarownika”, który leczy daną osobę w cierpieniu. Pewien obiekt czy czynność zostaje wybrana jako „tabu” - jakieś drzewo, którego trzeba unikać, jakiś rodzaj pokarmu, którego nigdy nie należy jeść itd. - unikanie go będzie przynosić zadowolenie, a kontakt z nim spowoduje silny lęk, chorobę, a może nawet śmierć. Dana jednostka może wówczas wyraźnie określić źródło swych kłopotów, którym są te konkretne rzeczy, i unikając ich może nie dopuszczać tych kłopotów do siebie.




Nerwica natręctw
(obsesyjno-kompulsywna)




Wyparte pragnienia i poczucie winy często prowadzą do innego anormalnego zachowania, znanego jako |nerwica |natręctw (obsesyjno-kompulsywna, anankastyczna). W rzeczywistości natręctwa myślowe (obsesje) i natrętne czynności (kompulsje) są odrębnymi typami reakcji, które mogą występować zupełnie niezależnie od siebie, lecz występują one łącznie tak często, że na ogół uważa się je za dwa odrębne aspekty jednego wzorca zachowań.


Natręctwa myślowe. Obsesja jest uporczywą i irracjonalną myślą, która pojawia się w świadomości niepotrzebnie i której nie można dowolnie z niej usunąć. Prawie każdy z nas ma czasami łagodne natręctwa myślowe, takie jak dręczące nas drobne zmartwienia: „Czy rzeczywiście zamknąłem drzwi?” lub „Czy zgasiłem gaz?” lub prześladująca nas uporczywie melodia czy piosenka, której po prostu nie możemy wyrzucić ze swej świadomości. Większość z nas czasami czuje się też nieco lepiej, odpukawszy rytualnie w nie malowane drewno lub splunąwszy za ramię.
Chociaż łagodne natręctwa myślowe, takie jak nieustannie powracająca melodia, mogą być denerwujące, to jednak prawdziwe, neurotyczne natręctwa myślowe są bardziej natarczywe i tak niepokojące, że zaczynają zakłócać wszystkie dziedziny codziennego życia danej jednostki. Często koncentrują się one wokół chorobliwych myśli o śmierci, samobójstwie lub nieustannych fantazji o popełnieniu morderstwa w jakiś brutalny sposób. Silne obsesje mogą prawie całkowicie uniemożliwiać normalne funkcjonowanie - pacjenci mogą być tak przygnieceni ciągłymi natrętnymi myślami, że nie mogą skoncentrować się na jakichkolwiek innych myślach i nie są w stanie zapanować nad występowaniem czy kierunkiem myśli natrętnych.
W jednym z wyjaśnień funkcji, jaką spełniają natręctwa, podkreśla się, że strukturalizują one w pewien sposób nie w pełni uświadomione dążenia, które są spostrzegane (na pewnym poziomie) jako chaotyczne i niebezpieczne. Myśli natrętne nie tylko ograniczają działanie, lecz także nie dają dostępu silnym emocjom, takim jak uczucia nienawiści, destrukcji czy pożądania. Dla osoby ogarniętej myślami natrętnymi stanowią one barierę między afektem i działaniem, stają się ostateczną rzeczywistością, z którą ma ona wciąż do czynienia, zamiast narażać się na konsekwencje podjęcia upragnionego, lecz zakazanego działania.


Czynności przymusowe. Czasami same myśli, nawet myśli natrętne, nie stanowią wystarczającej ochrony przed przejawieniem się zakazanych dążeń.  Za dodatkowy mechanizm, umożliwiający panowanie nad tymi dążeniami, uważa się za |czynności |przymusowe (kompulsje). W większości przypadków pacjenci, u których występują reakcje kompulsywne, nie wymagają hospitalizacji; czynności te są jedynie uciążliwe dla danej jednostki i mogą dziwić jej znajomych. Niekiedy jednak reakcje te poważnie przeszkadzają w funkcjonowaniu lub stanowią jedynie jeden z elementów szerszego obrazu psychopatologii.


„Pewien pacjent, starszy mężczyzna, spędzał wiele godzin na pisaniu jednego czy dwóch „komunikatów” i dawał je innym pacjentom i członkom personelu. Gdy polecono mu przestać i zabrano mu papiero i ołówek, wówczas komunikaty te na pewien czas ustały; następnie jednak w tajemniczy sposób zaczęły pojawiać się ponownie - pisane na serwetkach i wsuwane pod drzwi, do kieszeni lub skrzynki pocztowej członkom personelu, przy czym codziennie kto inny był adresatem. Na rycinie 11.7 pokazano przykładowe komunikaty, które jeden z autorów otrzymał w okresie trzech miesięcy. Zwróć uwagę na znaczne podobieństwo drobnych szczegółów pisma odręcznego tego pacjenta, na „magiczną liczbę”, oraz na temat tych pisanych na serwetkach komunikatów”.


Zachowanie kompulsywne składa się z powtarzających się czynności o charakterze rytualnym. Chociaż rytuały takie mają duży ładunek emocjonalny dla neurotyków, to jednak mogą oni nie zdawać sobie sprawy z ich znaczenia.  Jednakże osoba cierpiąca na nerwicę natręctw, zaabsorbowana ciągłym wykonywaniem tych drobnych, codziennych zadań, nie ma czasu ani energii na wykonanie „zakazanego” działania, przed którym nieświadomie się broni. W pewnych przypadkach poczucie winy z powodu prawdziwych czy wyimaginowanych grzechów może znaleźć swój wyraz w kompulsywnych rytuałach mających je „odkupić”; przykładem może być ciągłe mycie rąk - reakcja tego typu, jaka wystąpiła u Lady Macbeth.




Nerwica histeryczna




Studentom nieraz zdarza się zapomnieć o umówionej wizycie u dentysty lub zachorować w dniu końcowego egzaminu, śpiewacy dostają chrypki przed występem, a sportowców nieraz roboli noga, co nie pozwala im wziąć udziału w zawodach. Przykłady powyższe reprezentują niektóre z „normalnych” form unikania nieprzyjemnej, wzbudzającej strach sytuacji. Uniki te nie są dokonywane świadomie. Osoby dokonujące ich protestują w istocie gwałtownie przeciwko określeniu „uniki”: są to po prostu „przypadki”, które wydarzyły się w sytuacji przewidywanego stresu. Jednakże zapomnienie lub niezdolność fizyczna istotnie pozwalają danej osobie uniknąć sytuacji, która jest zagrażająca dla jej dobrego samopoczucia czy samooceny, a w dodatku przebiega to w taki sposób, że dana osoba nie może spotkać się z naganą, że nie stawiła czoła danej sytuacji.




* * *



Ryc. 11.7. Napisy na serwetkach wykonywane przez pacjenta cierpiącego na nerwicę natręctw (treść napisu w tłumaczeniu: Pan Najwyższy. Zdążający do Nieba, czy jesteście gotowi pójść do Przedsionka Piekieł?)


* * *





Gdy mechanizm taki przybiera tak skrajną postać, że dana osoba zostaje fizycznie sparaliżowana lub cierpi na całkowitą utratę pamięci - bez jakiegokolwiek defektu organicznego, wówczas stan ten jest anormalny i określa się go jako |nerwicę |histeryczną. Ta ogólna kategoria obejmuje dwa pokrewne zaburzenia: |reakcje |konwersyjne oraz |stany |dysocjacji.


Reakcje konwersyjne. Reakcja konwersyjna polega na utracie jakiejś funkcji sensorycznej lub ruchowej bez defektu organicznego. Dana osoba przestaje nagle słyszeć, widzieć czy odbierać wrażenia dotykowe, może mieć sparaliżowaną rękę bądź nogę lub też nie jest w stanie mówić.
Wiele symptomów histerycznych zupełnie nie daje się pogodzić z faktami medycznymi. Na przykład w pewnych typach anestezji histerycznej (utrata wrażliwości na dotyk lub ból) dotknięte obszary ciała nie odpowiadają rzeczywistemu układowi dróg nerwowych. Jednakże w innych przypadkach lekarzowi może być bardzo trudno określić, czy dany pacjent cierpi na jakieś schorzenie organiczne, czy też na histerię.
Trzeba pamiętać, że w reakcji konwersyjnej nie występują żadne rzeczywiste zmiany biologiczne. Wyraźnie świadczy o tym fakt, że gdy dana osoba śpi lub znajduje się pod hipnozą, wówczas symptomy histeryczne na ogół znikają. Na przykład, pacjenci, którzy cierpią na paraliż histeryczny, mogą być całkowicie niezdolni do poruszania nogami, lecz zastosowanie hipnozy może sprawić, że wstaną i przejdą przez pokój. Ponadto symptomy histeryczne mogą pojawiać się i znikać lub nawet pojawiać się w różnym czasie w różnych miejscach ciała; niekiedy pacjent, który jednego dnia histerycznie „niewidomy” na prawe oko, następnego dnia może nieświadomie przenieść to kalectwo na lewe oko.
Chociaż niekiedy za pomocą sugestii hipnotycznej można spowodować zniknięcie symptomów histerycznych, to jednak jest bardzo prawdopodobne, że będą one powracać, być może w zmienionej postaci, tak długo, jak długo będzie się utrzymywać leżący u ich podłoża konflikt.
Osoby, u których rozwijają się reakcje konwersyjne, są zwykle niedojrzałe, pobudliwe emocjonalnie i wymagające, skłonne do teatralnych gestów i litowania się nad sobą. W wielu przypadkach maja one pragnienia seksualne, których nie potrafią zaakceptować. Zwykle udaje im się nie tylko uniknąć zagrażającej sytuacji, lecz także uzyskać dodatkowe korzyści w formie znacznej troski i współczucia - co z kolei wzmacnia ich postawę bezradnej zależności.


Jest interesujące, że forma, jaką przyjmują reakcje konwersyjne, oraz częstość ich występowania zależą od poziomu wiedzy medycznej pacjenta i społeczeństwa (które musi uznać istnienie choroby fizycznej, aby manewr ten był skuteczny). Omdlenia, często opisywane w Anglii wiktoriańskiej, są rzadkim dziś typem występowania reakcji konwersyjnej. Co więcej, częstość występowania reakcji konwersyjnych w Stanach Zjednoczonych zmalała znacznie w ostatnich latach, chociaż nadal występują one bardzo często w tych krajach, w których wiedza medyczna jest mniej upowszechniona.


Stany dysocjacji („dissociated states”). Wielokrotnie podkreślaliśmy w niniejszej książce, jak ważne jest to, by ludzie byli przekonani, że w zasadzie sami kierują swym zachowaniem - z emocjami, procesami poznawczymi i działaniami włącznie. Niezbędnym warunkiem tego spostrzegania samokontroli jest założenie, że posiadamy zintegrowaną, spójną osobowość, której rdzeń reprezentuje naszą istotną, jedyną w swoim rodzaju naturę. Ta „osobowość” stanowi podstawę spostrzegania ciągłości nas samych w czasie.  Naszym obecnym doświadczeniom przypisujemy znaczenie i sens w kategoriach układów odniesienia ustanowionych w przeszłości, ważność zaś przypisujemy im stosownie do ich prawdopodobnych przyszłych konsekwencji. Sytuacje zmieniają się, czas upływa, nasze zachowanie zmienia się, nawet nasze postawy czy wartości mogą się zmienić, jednakże żywimy mocne przekonanie, że przez cały czas jesteśmy tą samą osobą. To właśnie ta stałość jaźni dostarcza większości ludzi mocnego, rzetelnego wzorca, w zestawieniu z którym mierzy się, interpretuje i ocenia zmiany spostrzegane w świecie zewnętrznym.
W stanach dysocjacji jednostka ucieka od swych konfliktów, rezygnując z tej wspaniałej spójności oraz ciągłości i w pewnym sensie nie uznając części samego siebie. Może ona dokonać tego w kilka sposobów. Jednym z tych sposobów jest |somnambulizm (Zjawisko to może mieć również podłoże organiczne; występuje w niektórych postaciach padaczki (przyp. red.) (lunatyzm) - dana jednostka może w czasie snu chodzić i wykonywać pewną czynność o znaczeniu symbolicznym, której nie pamięta wcale po obudzeniu ssię. Podobny rodzaj dysocjacji często spotykamy w manieryzmach („mannerisms”), czyli ruchach ciała, które w jakiś sposób wyrwały się spod świadomej kontroli. U wielu z nas występują tiki, skurcze i nawyki ruchowe, które zdają się żyć swym własnym życiem.
Utrata pamięci własnego postępowania, która cechuje stany somnambulizmu, może przyjść bardziej skrajną postać, występując w czasie czuwania. W przypadkach |amnezji ludzie wykonują swe zwykłe czynności - jedzą, mówią, czytają, prowadzą auto itd., lecz nie pamiętają wcale swej własnej tożsamości. Przekreślając za pomocą amnezji przeszłość, osoba taka jednym zręcznym pociągnięciem odcina teraźniejszość od więzów łączących ją z nieszczęśliwą przeszłością i może zacząć wszystko od nowa, uwzględniając jedynie teraźniejszość przy budowie swego obecnego życia. W wielu przypadkach amnetykami są ludzie, których historia życia i nawykowe wzorce reakcji psychicznych sprawiły, że stali się oni niezwykle biegli w uciekaniu od sytuacji, z którymi po prostu nie potrafią sobie poradzić.
Często osoba cierpiąca na amnezję, która odrzuciła swą dawną tożsamość, może przenieść się do jakiejś innej miejscowości, często zupełnie nowej czy też znanej sobie, w której, w jakimś dawniejszym okresie życia, doznawała emocjonalnego oparcia. Wyjazd taki zwany jest |fugą (ucieczką). W tej nowej miejscowości osoba ta może przyjąć nową tożsamość i stworzyć nowy styl życia, oddzielony psychologicznie, czasowo i geograficznie od uprzedniego, nieakceptowanego sposobu życia. Opisywano przypadki, w których osoby takie znajdowano po kilku latach od chwili ich zniknięcia. Oczywiście nie wiemy, ile z nich pozostaje nie odnalezionych i prowadzi resztę swego życia z przebudowaną jaźnią.




Zbliżenie


Co z oczu, to i z myśli


„Poniżej zamieszczamy opis przeżyć pewnej kobiety, u której rozwinęła się amnezja i wystąpił „epizod ucieczki” („fugue episode”). Opis ten jest niezwykły nie tylko dlatego, że stanowi osobiste sprawozdanie z tego rodzaju doznań, lecz również z tego powodu, iż w trakcie pisania go (z przeznaczeniem dla „Psychologii i życia”) autorka zaczęła tracić kontrolę nad sobą, wystąpiła u niej regresja do dzieciństwa, o czym świadczy charakter jej pisma, i zakończywszy swe sprawozdanie, ponownie straciła pamięć na pewien czas.
„Razem z moim synem, mającym wówczas 4,5 roku, lecz niezwykle rozwiniętym jak na swój wiek, znajdowaliśmy się w barze samoobsługowym na Manhattanie.  Jedliśmy śniadanie, posiłek, którego zwykle nie jadam, i zauważyłam że było około 9 rano (...). Myślę, że rozpoczynaliśmy wyprawę na zakupy przed Bożym Narodzeniem (był to początek grudnia) i cały plan tego był osnuty wokół lunchu, który zamierzałam zjeść z moją matką (która w tym czasie nie żyła już od 3 miesięcy). Poranne godziny spędziliśmy na zakupach i bieganiu z wielkim (niezwykłym, jak mi się obecnie wydaje) ożywieniem i wesołością po ulicach i sklepach (...).
Gdy zbliżało się południe, odczułam lekkie napięcie - lęk, że z jakiegoś powodu nie spotkamy się na lunchu. Weszliśmy do kabiny telefonicznej, z której zdecydowałam się zadzwonić do mojej matki, aby ustalić inny plan dotyczący obiadu. W kabinie telefonicznej zorientowałam się, że nie mogę przypomnieć sobie numeru telefonicznego mojej matki ani jej nazwiska (aby odszukać go w książce telefonicznej); odpowiedzialnością za tę niemożność przypomnienia sobie numeru obarczyłam pewien wirus, o którym słyszałam w tym czasie, że wywołuje niezwykłe stany psychiczne u osób, które go „złapały”. Postanowiłam zjeść lunch, wzięłam swego syna do muzeum, a następnie do kina. Czułam się szczególnie energiczna i wydaje się, że byłam bardziej aktywna niż normalnie.
Gdy w kinie myślałam znowu o zatelefonowaniu do matki, to uświadomiłam sobie, że nie tylko nie znam jej nazwiska, lecz także nie pamiętam swego własnego. Wzięłam synka do hallu i przeszukałam swą torbę w celu zidentyfikowania siebie. Szczególnie starałam się nie przestraszyć go, lecz sama nie byłam przestraszona i rozumowałam z niezwykłą jasnością. Znalazłam w torebce listę trzech nazwisk z numerami telefonów i adresem jednej osoby.  Nie rozpoznałam tych nazwisk. Zatelefonowałam do pierwszej osoby na liście - mojego starego wykładowcy z uczelni i bardzo bliskiego mojego przyjaciela. Gdy zgłosił się, wówczas zaczęłam opisywać swoją sytuację, lecz uświadomiłam sobie, że nie potrafię opisać siebie samej. Spojrzałam na swe odbicie w lusterku i nie poznałam się.
Powiedziałam memu wykładowcy, że jestem z synkiem i opisałam go.  Wykładowca powiedział mi, abym wzięłam taksówkę - że on wie, kim ja jestem, i podał adres, który miałam dać kierowcy. Gdy powiesiłam słuchawkę, zapomniałam nazwiska, które wymienił jako moje, lecz spoglądając na adres i widząc, że był on w Brooklynie, pomyślałam że pomylił się, ponieważ pamiętałam (lub zdawało mi się, że pamiętam), że mieszkam w New Haven (...). Zjadłam obiad z synkiem i wsiedliśmy do pociągu idącego do New Haven (...). Gdy pociąg wyjechał z Bridge Port, wówczas mój synek zauważył, iż to nie jest droga do naszego domu w Brooklynie. Przestraszyłam się wtedy po raz pierwszy. Gdy dojechaliśmy do New Haven, zatelefonowałam do następnego nazwiska na mojej liście (...). Powiedział on mi, żebym następnym pociągiem wróciła na dworzec Grand Central (...).
Rano zaprowadzono mnie do psychiatry. Mój mąż czekał na mnie, kiedy wychodziłam z gabinetu psychiatry. Gdy zobaczyłam męża, nie poznałam go.  Wydał mi się taki inny. Wstydziłam się bardzo, że go nie poznałam. Było mi bardzo gorąco, i zaczerwieniłam się. Po raz pierwszy uświadomiłam sobie, że ktoś patrzy na mnie i to był okropny wstrząs, gdy zdałam sobie sprawę, że jestem obiektem widocznym dla innych. W tym momencie uświadomiłam sobie, że jestem istotą widoczną. Myślę teraz, że w tym stanie prawie cały czas miałam wrażenie, że jestem niewidoczna, z wyjątkiem tych momentów, gdy chciałam uczynić się widoczną dla tego, z kim mówiłam - stawałam mu się wówczas znana raczej jako moja świadomość niż jako osoba (...).


Najbardziej skrajną formą dysocjacji jest |osobowość |wielokrotna (naprzemienne rozszczepienie osobowości; „multiple personality”). W tym tempie reakcji, która jest bardzo rzadka, mimo że tak często dostarcza tematu dla dramatów filmowych i telewizyjnych - dana jednostka może wytworzyć dwie (lub niekiedy więcej) odrębne osobowości, które występują na zmianę w jej świadomości, a każda z nich sprawuje świadomą kontrolę nad tą osobą w odrębnym czasie. Każda część tej zwielokrotnionej osobowości opiera się na zbiorze motywów, które pozostają w konflikcie z motywami „drugiej” jej części. Te konfliktowe układy motywów pierwotnie istniały równocześnie w jednej osobowości, lecz były tak niemożliwe do pogodzenia - a jednocześnie tak trwałe - że dana osoba mogła zaspokoić je wszystkie jedynie w ten sposób, że wypierała czasowo ze świadomości jeden zbiór motywów, zaspokajając w tym czasie drugi zbiór. Zazwyczaj, chociaż nie zawsze, jedna osobowość jest zupełnie nieświadoma istnienia drugiej. W niektórych przypadkach jedna osobowość może zdawać sobie sprawę z istnienia drugiej, lecz nie na odwrót.
Studenci często popełniają błąd polegający na myleniu takich przypadków wielokrotnej osobowości z tak zwaną |osobowością |rozszczepioną („split personality”), która w terminologii psychiatrycznej nosi nazwę |schizofrenii - jest to choroba psychiczna, w której dana jednostka jest „oddzielona” („split off”) od rzeczywistości”. W przypadku osobowości wielokrotnej, świadoma część osobowości pozostaje w kontakcie z rzeczywistością, aczkolwiek reaguje na nią neurotycznie.


„Przykładem tej drugiej postaci reakcji nerwicowej jest szeroko spopularyzowany przypadek Ewy White (Ewy „Białej”). Ewa 25-letnia kobieta żyjąca w separacji ze swym mężem, zgłosiła się do terapeuty z powodu silnych, powodujących zaburzenia wzroku bólów głowy, po których często następowały „zamroczenia świadomości”. Podczas jednego z pierwszych posiedzeń terapeutycznych Ewa była bardzo podniecona; powiedziała, że niedawno słyszała głosy. Nagle przycisnęła obie ręce do skroni, potem spojrzała na lekarza z prowokacyjnym uśmiechem i przedstawiła się jako Eve Black (Ewa „Czarna”).
Głos, gesty i maniery tej drugiej Ewy świadczyły wyraźnie, że była ona odrębną osobowością. Była ona w pełni świadoma uczynków Ewy „Białej”, natomiast Ewa „Biała” nie zdawała sobie sprawy z istnienia Ewy „Czarnej”.  „Zamroczenia” Ewy „Białej” były w rzeczywistości okresami, kiedy „u władzy” była Ewa „Czarna”, zaś „głosy” oznaczały nieskuteczne próby ujawnienia się Ewy „Czarnej”. Po dłuższej terapii stało się oczywiste, że Ewa „Czarna” istniała od wczesnego dzieciństwa Ewy „Białej”, kiedy to od czasu do czasu przejmowała kontrolę i pozwalała sobie na zakazane przyjemności, pozostawiając drugiej Ewie ponoszenie konsekwencji.


Dwie Osobowości W Jednym Ciele. Podano tu niektóre spośród cech 
osobowości Ewy „Białej” i Ewy „Czarnej”, jakie charakteryzowały dwie 
pierwsze „twarze Ewy”


Ewa „Biała” - Ewa „Czarna”
Spokojna, zamknięta w sobie - Żywa, towarzyska
Twarz miła, spokojna - Figlarny, zalotny wyraz twarzy
Ubiera się zwyczajnie, skromnie - Ubiera się atrakcyjnie, prowokująco
Czyta i pisze - Nigdy nie bywa poważna ani zamyślona
Głos łagodny, kobiecy - Głos szorstki, drażniący
Powściągliwy sposób wyrażania się - Swobodny, żartobliwy sposób wyrażania 
się
Podziwiana ze względu na swoją - Lubiana za swój dowcip i fantazję 
spokojną siłę
Pracowita i kompetentna - Lekkomyślna i nieodpowiedzialna
Rzadko ożywiona czy rozbawiona - Lubująca się w figlach i psikusach
Pełna poświęcenia matka - Uczucia krótkotrwałe i efemeryczne
Nie uczulona na nylon - Uczulona na nylon


Nawyk ten pozostał i Ewa „Biała” często cierpiała z powodu „kaca”, zawinionego przez Ewę „Czarną” (tabela).
Po około 8 miesiącach terapii pojawiła się trzecia osobowość. Ta osobowość, która występowała pod imieniem Jane, była bardziej dojrzała, zdolniejsza i silniejsza niż wycofująca się Ewa „Biała”; stopniowo ona zaczęła „sprawować władzę” przez większą część czasu. Elektroencefalogramy zarówno Jane, jak i Ewy „Białej” było normalne i bardzo do siebie podobne; 
EEG Ewy „Czarnej” sklasyfikowano jako będący na granicy normy.
W miarę, jak terapeuta sondował wspomnienia obu Ew, zyskiwał pewność, że jakieś wstrząsające zdarzenie musiało przyspieszyć wytworzenie się odrębnych osobowości u znerwicowanego dziecka. W dramatycznym momencie, stanowiącym szczytowy punkt terapii, brakujący incydent wyszedł na jaw.  Jane nagle zesztywniała i przerażonym głosem zaczęła piszczeć: „Mamo... nie każ mi!... Ja nie mogę tego zrobić! Ja nie mogę!”. Gdy krzyki te ustały, nowa - i ostatnia - osobowość „przejęła władzę”. Potrafiła ona przypomnieć sobie wstrząsające wydarzenie, które legło u podłoża dysocjacji osobowości: 
Gdy miała 6 lat, matka zaprowadziła ją do trumny babci i zmusiła, aby złożyła pożegnalny pocałunek na martwej twarzy (Thigpen i Cleckley, 1954, 1957; Thigpen, 1961).
Ostatnio ujawniła się nowa „Ewa” 48-letnia gospodyni domowa w Fairfax (stan Virginia), u której w ciągu minionych dwudziestu lat wystąpiło 21 różnych osobowości. Za każdym razem tworzyły one „zestawy” składające się z trzech bardzo różnych osobowości, lecz jej ostatnie „zwielokrotnione jaźnie” zmarły przed rokiem, pozostawiając panią Chris S. przygotowaną do odnoszenia sukcesów na własną rękę („Chicago Sun-Times”. 16 września 1975).




Hipochondria




Osoby neurotyczne często przejawiają niezwykłą troskę o swe zdrowie i stan fizyczny, rozstrząsając chorobliwie każdy najmniejszy objaw jako możliwą oznakę jakiegoś poważnego schorzenia organicznego. Gdy takie zaabsorbowanie własnym zdrowiem stanowi dominujący objaw nerwicy, to nazywa się ją |hipochondrią.
Jedno z wyjaśnień zjawiska hipochondrii głosi, że dana osoba czuje się oddzielona od swego ciała i stara się je poznać, lecz raczej analizując je i opisując, niż doświadczając go. Jest również możliwe, że w trakcie prób wyjaśnienia niejasnych uczuć lęku, napięcia i tajemniczego pobudzenia emocjonalnego, niektórzy ludzie dochodzą do przekonania, iż jest rzeczą bardziej rozsądną i mniej zagrażającą dla ego mieć schorzenie organiczne niż problem psychologiczny. Ludzie tacy mogą stać wobec wyboru między „mieć zaburzenia psychiczne” a „być chorym fizycznie”.
W każdym razie o hipochondrykach często mówi się, że „cieszą się złym zdrowiem”, ponieważ ich największa satysfakcja zdaje się polegać na znajdowaniu objawów, które potwierdzają ich okropne przewidywania. Te domniemane schorzenia nie tylko nie pozwalają na aktywne zaangażowanie w życiu - z towarzyszącym mu ryzykiem niepowodzenia - lecz także mogą przynosić wtórne korzyści w postaci troski, współczucia i usług ze strony otoczenia. Z drugiej strony, takie domaganie się niezwykłych względów, w połączeniu z ogromnymi honorariami za porady lekarskie i rachunkami za bezużyteczne zabiegi sprawiają niekiedy, iż rozgoryczona rodzina pacjenta zapomina, że cierpienia te, chociaż pochodzenia irracjonalnego, subiektywnie istnieją rzeczywiście.




Nerwica depresyjna




Osoba cierpiąca na |nerwicę |depresyjną zniekształca rzeczywistość raczej pod względem ilościowym niż jakościowym. Osoba taka reaguje na stratę lub zagrażającą stratę większym smutkiem i przez dłuższy czas niż większość ludzi - jest pogrążona w wiecznej żałobie. Pacjenci tacy nie tylko są przygnębieni, lecz także często skarżą się na niezdolność do koncentracji, brak pewności siebie, bezsenność, nudę, rozdrażnienie i złe samopoczucie.  Mogą oni zdawać sobie sprawę ze źródła swej depresji, lecz przeceniają jego znaczenie. Pacjent przestawia sobie świat jako zbyt potężny, aby można było sobie z nią poradzić, a to przez nieproporcjonalne wyolbrzymienie wszelkich porażek, frustracji, osobistych niedociągnięć czy braków.
W wielu wypadkach subiektywna ocena straty, niepowodzenia czy frustracji ma niewiele wspólnego z sytuacją obiektywną. Jednakże dla takich osób rzeczywistość subiektywna jest jedyną rzeczywistością. Mogą one boleć wciąż od nowa nad dawno minionymi przygnębiającymi doświadczeniami, tak jak gdyby były one aktualną rzeczywistością - postawa, która może tylko utrudnić życie. Tej niezdolności cieszenia się życiem często towarzyszy potrzeba picia alkoholu lub przyjmowania środków psychotropowych, po prostu po to, by móc znieść cierpienie, jakie wiąże się z przeżyciem następnego dnia. Ta fatalistyczna postawa nieustannego przygnębienia i cierpienia może stać się potężnym źródłem motywacji, aby nie znosić cierpień życia, lecz uciec od nich przez samobójstwo.
Reakcja depresyjna jest wyrazem bezsilności, jak wszystkie nerwice.  Wszystkie te strategie są sposobami, jakimi neurotycy dowodzą sobie samym i światu, że są oni niezdolni do uporania się ze swymi problemami i że nie ponoszą za to żadnej odpowiedzialności. Osoba cierpiąca z powodu fobii mówi: „To mnie przeraża - muszę tego unikać”. Człowiek z nerwicą natręctw mówi: „|Muszę o tym myśleć lub to robić”. Histeryk mówi: „Jestem unieruchomiony; nie mogę ruszyć się z miejsca; nie mogę uporać się z tą częścią mojego „ja”, której nie lubię”. Hipochondryk mówi: „Gdybym nie był taki chory, to mógłbym uporać się z innymi problemami, lecz wobec takiego fizycznego cierpienia, wszystko inne nie ma znaczenia”. Osoba cierpiąca na depresję mówi: „Jestem przygnieciona przez świat, jestem przytłoczona moim intensywnym żalem i zgryzotą”.
Dla wszystkich tych form nerwicy wspólny jest mechanizm polegający na ograniczeniu lęku przez unikanie bezpośredniej konfrontacji z jego źródłem oraz niezdolność do rozważania jakiegokolwiek innego sposobu uporania się z problemem. Neurotycy nie widzą żadnego rozwiązania swych problemów ani żadnego wyboru między alternatywnymi sposobami bycia. Jak powiedział kiedyś teolog Paul Tillich: „Nerwica jest sposobem unikania niebytu przez unikanie bycia” (1952, s. 66).
W przypadku tych ludzi terapia jest skuteczna wtedy, gdy zmienia ich pojęcie o sobie, skłaniając ich do uznania faktu, że mogą mieć wpływ na bieg rzeczy. Dzięki ponownemu odkryciu zdolności podejmowania decyzji i działania, czy po prostu dzięki wywieraniu widocznego wpływu na swe otoczenie i dzięki rozpoznaniu w tym rezultatów własnego działania, neurotyczni pacjenci uczą się, że nie tylko mogą uporać się ze swymi szczególnymi problemami, lecz mogą także zacząć kształtować swoje życie w nowych wymiarach czy aspektach, które mogą przynieść im przyjemność, satysfakcję i poczucie osiągnięć. Większość procedur terapeutycznych, które opiszemy w następnym rozdziale, zmierza do zmiany opisanych powyżej neurotycznych wzorców reakcji. Chociaż procedury te różnią się sposobem ujęcia problemu, to jednak mają one wspólne cele: uczynić osobę neurotyczną mniej bezradną i mniej pozbawioną nadziei, przyczyniając się do zwiększenia efektywności jej działania i pomagając jej w zaakceptowaniu siebie.




Utrata kontaktu
z rzeczywistością:
psychoza




Gdy zachowanie jednostki staje się tak odchylone od normalnego funkcjonowania, że traci ona kontakt z rzeczywistością, to stan taki określa się jako |psychozę. W języku potocznym psychotyka nazywa się szaleńcem lub wariatem. Spośród wszystkich omówionych dotychczas zaburzeń psychoza nie tylko w największym stopniu zakłóca funkcjonowanie jednostki, lecz ponadto jest „chorobą”, która w społeczeństwie wzbudza chyba największy strach i jest przez nie najmniej akceptowana. Samo istnienie psychozy stanowi zagrożenie dla naszych fundamentalnych pojęć o integralności psychiki, sterującej funkcji woli ludzkiej oraz o naturze rzeczywistości.
|Niepoczytalność („insanity”) nie jest terminem psychiatrycznym ani psychologicznym, lecz pojęciem prawnym, stosowanym w odniesieniu do każdego stanu psychicznego, który czyni daną jednostkę niezdolną do odróżniania dobra od zła, wskutek czego nie może ona odpowiadać przed prawem za popełnione czyny. Termin „niepoczytalność” może zatem obejmować nie tylko zaburzenia psychotyczne, lecz także bardzo silne reakcje nerwicowe, w poważnym stopniu zakłócające funkcje intelektualne jednostki.


„Psychoza nie jest „silniejszą nerwicą” czy też wyższym stopniem nerwicy, lecz swoistym stanem patologicznym, który różni się od niej dramatycznie pod względem jakościowym.


Psychotyk nie musi przechodzić przez stadium nerwicy, ani też neurotycy o bardzo poważnych zaburzeniach nie stają się w końcu psychotykami (aczkolwiek są pewne przypadki, w których mogą występować objawy mieszane, pochodzące od oby tych zaburzeń). 
Podczas gdy pacjenci neurotyczni są na ogół przytłoczeni lękiem i strachem, to pacjenci psychotyczni wykazują zwykle albo mało zróżnicowany („flattened”) lub niedostosowany afekt (emocję), albo też skrajne reakcje maniakalne lub depresyjne. Ponadto, dla neurotyków dodatkowym źródłem lęku jest często świadomość, że ich obecne zachowanie jest irracjonalne i różne od zachowania innych ludzi oraz od ich własnego, uprzedniego „normalnego” zachowania. Niektóre objawy nerwicy istotnie mogą rozwijać się jako następstwo poszukiwania uzasadnienia, mającego wyjaśnić niezwykłe uczucia i myśli, lub też jako usprawiedliwienie dla siebie i innych. Psychotycy rzadko zdają sobie sprawę, że w ich działaniach czy doznaniach jest coś niezwykłego, rzadko też zdają się niepokoić swym „stanem”.


Różnicę między osobą normalną, neurotykiem i psychotykiem można przedstawić przez analogię do różnicy między porównaniem i metaforą. Osoby normalne i neurotycy często mogą wyrazić swe uczucie w postaci |porównania - „Czuję się |jak komputer, który funkcjonuje bez emocji”. Normalna osoba może tu dodać: „lecz jest na ogół sprawny technicznie”, podczas gdy neurotyk dodaje: „lecz jest niesprawny technicznie”. Psychotycy opuszczają słowo „jak” i z pełną intensywnością żyją |metaforą - „|Jestem komputerem”.
Istotną konsekwencją kierowania się metaforą jest rozmycie granicy między podmiotem a przedmiotem, między rzeczywistością subiektywną a obiektywną.  Psychotykiem jest zatem ten, kto odmawia zaakceptowania zarówno empirycznie ugruntowanych definicji tego, co rzeczywiste, jak i społecznie uzgodnionej definicji rzeczywistości. Strategia ta uwalnia jednostkę od wielu ograniczeń krępujących myśli, oraz od odczuwania i działań ludzi zdrowych psychicznie, którzy muszą stosować się do reguł określających, co jest rzeczywiste, przyczynowe logiczne, racjonalne, właściwe i akceptowane.  Psychotycy często zatem mylą „to, co jest” i „to, co powinno być”. Mogą też oddzielać całkowicie skutki od przyczyn, działania od myśli, uczucia od działań, wnioski od przesłanek, a prawdę od dowodów. W pewnym sensie to, co wydaje się u psychotyka dziwacznym, niewłaściwym czy irracjonalnym zachowaniem, wynika ze stworzenia przez niego zamkniętego systemu, który jest wewnętrznie spójny i nie wymaga zewnętrznego potwierdzenia. Ktoś kiedyś powiedział, że neurotycy budują zamki w powietrzu, podczas gdy psychotycy żyją w nich (złośliwi zaś dodają, że psychiatrzy pobierają czynsz).




Zbliżenie


Sprawdzanie rzeczywistości a wewnętrzny i zewnętrzny świat psychozy


„W trakcie naszego rozwoju poznawczego uczymy się sprawdzać rzeczywistość. Rozwijamy zdolność oceny, czy źródło danego spostrzeżenia znajduje się poza nami w świecie zewnętrznym, czy w naszych własnych głowach. Jest to podstawa procesu, dzięki któremu sprawdzamy, czy nasze myśli, spostrzeżenia i uczucia są stosowne do danej sytuacji, do aktualnych lub uprzednich warunków, oraz do działań innych ludzi. Rzeczywistość naszego świata wewnętrznego oceniana jest zatem przy użyciu kryteriów ustanowionych w świecie zewnętrznym - środowisku fizycznym i społecznym.
Dzieci z poważnymi zaburzeniami psychotycznymi zdają się nie mieć kontaktu z rzeczywistością zewnętrzną, aczkolwiek istnieją dowody ich aktywnego życia wewnętrznego. Dwaj badacze zajmujący się psychozami dziecięcymi opracowali bardzo interesującą teorię, zgodnie z którą u psychotyków występuje odwrócenie zwykłej procedury sprawdzania rzeczywistości. Wewnętrzne doświadczenie jest u nich kryterium, względem którego sprawdzają wiarygodność doświadczeń zewnętrznych.
„Gdy rzeczywistość zewnętrzna nie pasuje do kryteriów ich wewnętrznej rzeczywistości, to jest ona lekceważona lub zniekształcana. Gdy doświadczenia rzeczywistości zewnętrznej, oceniane w kategoriach ich wewnętrznej rzeczywistości wydają się nieistotne dla ich wewnętrznych potrzeb, wówczas są odrzucane - podobnie jak jednostka normalna, która posługuje się kryteriami zewnętrznymi jako podstawą, może odrzucać doświadczenia rzeczywistości wewnętrznej, które nie pasują do kryteriów zewnętrznych. Ponadto, ponieważ dzieci te doświadczają rzeczywistości zewnętrznej jako projekcji rzeczywistości wewnętrznej, przeto wiele zdarzeń przybiera dla nich szczególne i przerażające znaczenia, a zatem muszą one unikać ich za wszelką cenę” (Meyer i Ekstein, 1970, s. 5).
Rozbieżność, jaką stwierdza neurotyk, istnieje między wymaganiami nieświadomości a wymaganiami płynącymi z rzeczywistości zewnętrznej. Dla psychotyka rozbieżność występuje między świadomością wewnętrzną a tą, która odpowiada rzeczywistości zewnętrznej. Zadaniem terapeuty jest budowanie mostu łączącego te dwa światy, z których każdy stanowi niezbędną część procesu sprawdzania rzeczywistości oraz wiedzy o sobie samym.


Dlaczego u niektórych ludzi rozwija się taka dewiacyjna struktura myślenia i działania? Niestety, mimo wielu lat badań, prowadzonych przez psychologów, psychiatrów i wielu innych przedstawicieli różnych nauk medycznych, brak jeszcze zadawalającej odpowiedzi na to podstawowe pytanie.  Badacze o orientacji medycznej opowiadają się za wrodzonym, genetycznym podłożem niektórych typów psychozy lub wskazują na defekty i zaburzenia metabolizmu. W podejściu psychologicznym kładzie się nacisk na czynniki występujące w wychowaniu i doświadczeniu społecznym jednostki. Niektórzy bardziej radykalni myśliciele, tacy jak Ronald Laing (1967), odrzucili nawet pogląd, że psychoza jest czymś anormalnym, opowiadając się za koncepcją ujmującą stan psychotyczny jako radykalny bunt przeciw dominującym w społeczeństwie, a mającym wątpliwą wartość, założeniom dotyczącym celu życia, relacji między środkami i celami oraz przeciw zbyt ograniczonym poglądom na myśli człowieka i subiektywną rzeczywistość.




Klasyfikacja psychoz




Niektóre reakcje psychotyczne i inne zaburzenia psychiczne mogą mieć charakter |organiczny - to znaczy są związane z uszkodzeniami mózgu spowodowanym fizycznymi przyczynami, takimi jak choroby układu nerwowego, guzy mózgu, uszkodzenie mózgu, nadmierne dawki środków psychotropowych, alkoholu, szkodliwych gazów lub tlenków metali oraz zaburzenia w krążeniu tętniczym występujące u osób w starszym wieku.
Bardziej rozpowszechnione są psychozy |czynnościowe, które nie są wynikiem jakiegoś nieznanego, fizycznego defektu w tkance mózgowej, lecz są raczej spowodowane zaburzeniami w funkcjonowaniu mózgu. 




* * *



Klasyfikacja Psychoz Czynnościowych


Reakcja paranoiczna
„Zasadnicze objawy”: logiczne, często wysoce usystematyzowane i 
skomplikowane urojenia; poza tym osobowość stosunkowo mało zaburzona
„Główne podkategorie”: paranoja, stan paranoidalny


Reakcje afektywna
„Zasadnicze objawy”: niezwykle silne fluktuacje nastroju lub silna, 
długotrwała depresja, albo euforia i związane z tym zaburzenia myślenia i 
zachowania
„Główne podkategorie”: mania (stan maniakalny), depresja psychotyczna, 
depresja (melancholia) inwolucyjna


Reakcja schizofreniczna
„Zasadnicze objawy”: oderwanie od rzeczywistości połączone z otępieniem emocjonalnym, niedopasowanymi reakcjami emocjonalnymi oraz znacznym zaburzeniem procesów myślenia; często występują urojenia, halucynacje oraz stereotypowe, dziwaczne zachowania („mannerisms”)
„Główne podkategorie”: schizofrenia dziecięca, schizofrenia prosta, 
schizofrenia paranoidalna, schizofrenia katatoniczna, schizofrenia 
hebefreniczna, schizofrenia niesklasyfikowana


* * *





Dzielą się one na trzy główne kategorie, które przedstawiono w tabeli (Podana przez autorów klasyfikacja psychoz i zastosowana w związku z tym terminologią są jednymi z wielu stosowanych. W Polsce na przykład przyjęty jest następujący podział psychoz: psychozy tak zwane organiczne (np.  psychozy starcze, psychozy alkoholowe i psychozy polekowe) oraz psychozy czynnościowe, do których należą psychozy schizofreniczne, psychozy afektywne, stany paranoiczne i „inne psychozy czynnościowe” (przyp. red.))


Reakcje paranoiczne (W Polskiej terminologii psychiatrycznej używa się pojęcia „zespół paranoidalny” dla określenia słabo usystematyzowanych urojeń z towarzyszącymi im ewentualnie halucynacjami, „zespół paranoiczny” dla określenia spójnych, logicznie ze sobą powiązanych i usystematyzowanych urojeń oraz „zespół parafreniczny” dla usystematyzowania urojeń występujących wraz z halucynacjami (przyp. red))


W przeciwieństwie do obrazu innych psychoz, który może być dość zróżnicowany, w przypadku zaburzeń paranoicznych charakterystyczny jest jeden główny objaw patologiczny - uporczywe urojenia. Urojenie jest to silne przekonanie, przy którym dana jednostka trwa mimo jego niezgodności z danymi obiektywnymi i mimo braku jakiegokolwiek poparcia społecznego. W |stanie |paranoidalnym („Stan paranoidalny”, czyli w terminologii polskiej „zespół paranoidalny”, w polskiej psychiatrii zaliczany jest zwykle do psychoz schizofrenicznych (przyp. red.)) („paranoid state”) urojenia mają charakter zmienny i nie są dobrze zorganizowane w spójną historię. U pacjentów mogą występować halucynacje, lecz ich osobowość pozostaje skądinąd nie naruszona. W miarę rozwoju procesu patologicznego, urojenia stają się bardziej usystematyzowane, spójne i wewnętrznie logiczne, podczas gdy halucynacje ustępują. Stan ten określa się jako |paranoję.
W zaburzeniach paranoidalnych, a niekiedy w innych stanach psychotycznych, występują trzy zasadnicze typy urojeń. Najczęstszym ich rodzajem są |urojenia |wielkościowe. Osoba taka żywi przekonanie, że jest jakąś wybitną postacią, taką jak Najświętsza Maria Panna, milioner, wielki wynalazca, czy nawet Bóg. Pewna pacjentka w szpitalu psychiatrycznym miała miły sposób bycia i pod większością względów zachowywała się na tyle racjonalnie, że powierzono jej wiele obowiązków, w tym pomoc przy pokazywaniu gościom całego zakładu. Nic jednak nie mogło zachwiać jej mocnym przekonaniem, że w rzeczywistości jest żoną Binga Crosby’ego. 
Drugim typem urojeń są tak zwane |urojenia |odniesienia (ksobne). W takich przypadkach dana jednostka błędnie interpretuje przypadkowe zdarzenia jako odnoszące się do niej. Jeśli paranoik widzi dwóch ludzi pogrążonych w ożywionej rozmowie, to natychmiast dochodzi do wniosku, że mówią o nim. Jeśli jego łóżko w sali szpitalnej zostało przestawione w inne miejsce, to stało się tak dlatego, że personel jest z niego niezadowolony i chce go dokładniej dozorować lub dlatego, że nagrodzono go w ten sposób za dobre zachowanie. Nie ma rzeczy tak błahej czy tak przypadkowej, by nie uznał, że ma ona dla niego osobiste znaczenie.
Trzecim typem urojeń są |urojenia |prześladowcze. W tym przypadku jednostka nieustannie ma się na baczności przed „wrogami”. Jest przekonana, że ktoś ją szpieguje i knuje coś przeciw niej, że zagraża jej śmiertelne niebezpieczeństwo napaści.
Urojenia prześladowcze mogą towarzyszyć urojeniom wielkościowym - pacjent jest wielkim człowiekiem, lecz nieustannie przeciwstawiają mu się złe siły.
The Federal Communications Commission (Federalna Komisja Komunikacji) otrzymuje wiele listów od ludzi uskarżających się na to, że w programach radiowych i telewizyjnych mówi się o nich, rozpowszechnia się ich zjawiska, adresy i informacje o ich sprawach osobistych. Autorzy tych listów często domagają się wyśledzenia i ukarania winowajców.
Niedawno prasa opisała przypadek pewnej starszej pani, która prawie cały swój czas (poza godzinami snu) spędzała przed odbiornikiem telewizyjnym.  Była ona tak przekonana, że spikerzy mówią tylko o niej, że chciwie słuchała ogłoszeń reklamowych, potem wybiegała do magazynu, aby zakupić reklamowane produkty i wracała akurat na czas, aby wysłuchać następnej serii reklam. Ponieważ kobieta owa nie miała żadnych przyjaciół ani krewnych, którzy by ją powstrzymali, ten wyczerpujący ekonomicznie i fizycznie proces mógłby trwać przez dłuższy czas. Na szczęście pewien pracownik wydziału przeciwpożarowego w czasie okresowej inspekcji jej mieszkania zrozumiał, co się dzieje i przekonał starszą panią, aby oddała się pod opiekę psychiatrów.
Poziom intelektualny i ekonomiczny paranoików jest zwykle wyższy niż u innych pacjentów z zaburzeniami psychicznymi. Osoby te potrafią zwykle funkcjonować przez pewien czas, kiedy to nikt nie zdaje sobie jeszcze sprawy, że potrzebują oni leczenia i hospitalizacji. Do czynników psychologicznych, którym w dynamice zaburzeń paranoidalnych często przypisuje się duże znaczenie, należą: poczucie winy z powodu niemoralnego czy nieetycznego zachowania, wyparty homoseksualizm, poczucie niższości oraz nierealistycznie wysokie ambicje.
Może zdarzyć się również tak, że gdy dana jednostka po raz pierwszy zaczyna rozwijać te paranoidalne koncepcje, to współczujący przyjaciele i krewni nie podważają ich. W miarę upływu czasu urojenia te stają się bardziej usystematyzowane, to jest bardziej logiczne i pozornie racjonalne.  Mamy tu zatem ciekawy paradoks: im poważniejszy staje się stan chorego, tym bardziej logiczne wydaje się jego rozumowanie. Ludzie tacy opierają się na terapii, ponieważ łatwiej jest przyjąć, że terapeuta należy do wrogiego spisku, niż zaakceptować fakt, że własne procesy myślowe są nielogiczne.
W Rozdziale 5 przedstawiliśmy zapis rozmowy komputera - „psychoterapeuty” („doktora od wariatów”) z człowiekiem - „pacjentem”. Keeneth Colby i jego współpracownicy opracowali także program komputerowy symulujący zachowanie psychotycznego pacjenta. Pacjenta tego, zwanego Parry (ze względu na pewne skłonności paranoidalne), można zaprogramować tak, że reaguje na osobę przeprowadzającą wywiad różnymi poziomami gniewu, strachu i nieufności, jak również wykonuje reakcje niewerbalne. Poniżej przedstawiono część typowego „posiedzenia terapeutycznego” z udziałem Perry’ego i jednego z autorów „Psychologii i życia”, w którym to posiedzeniu wszystkie trzy zmienne były utrzymane na niskim poziomie. Czy potrafiłbyś na podstawie odpowiedzi rozpoznać, czy Parry nie jest prawdziwym pacjentem-człowiekiem? Gdyby wywiad z Parrym przeprowadził komputerowy „doktór od wariatów”, to czy potrafiłbyś odgadnąć, że ich interakcja była produktem symulowanej inteligencji, a nie myślących i rozmawiających ze sobą ludzi?




Zbliżenie


Parry - paranoidalny komputer i Mafia


„PGZ: Hello.
PARRY: Hej.
PGZ: Jak się nazywasz?
PARRY: Możesz nazywać mnie Parry.
PGZ: Jestem doktor Zimbardo.
PARRY: Miło mi cię poznać.
PGZ: Gdzie mieszkasz?
PARRY: San Jose. Jednak w niezłej dzielnicy.
PGZ: Co przez to rozumiesz?
PARRY: Mam na myśli to, że nie jest tam za dużo, no, zagranicznych typów.
PGZ: Co rozumiesz przez zagraniczne typy?
PARRY: Ci obcokrajowcy zaczynają obrzydzać życie w naszym kraju.
PGZ: Jakich obcokrajowców nie lubisz najbardziej?
PARRY: Włochów, na przykład.
PGZ: Nie lubisz Włochów?
PARRY: (nachmurzony) Włochów?
PGZ: Powiedziałeś, że nie lubisz ich, dlaczego?
PARRY: Czy wiesz coś o Włochach?
PGZ: Nie.
PARRY: A co z gangsterami?
PGZ: Czy gangsterzy są Włochami?
PARRY: Powiedziałbym, że tak.
PGZ: Dlaczego powiedziałbyś tak?
PARRY: Dlaczego?
PGZ: Czy gangsterzy są naprawdę Włochami?
PARRY: Nie.
PGZ: Czy możesz powiedzieć mi coś o Mafii?
PARRY: (wystraszony) Mafii?
PGZ: Chciałbym dowiedzieć się coś o niej.
PARRY: Wiesz, oni mnie znajdą.
PGZ: Kto?
PARRY: Mafia.
PGZ: Naprawdę?
PARRY: Oni usiłują mnie dopaść.
PGZ: Kto?
PARRY: Mafia.
PGZ: Skąd wiesz?
PARRY: Oni mnie szpiegują.
PGZ: (milczenie)
PARRY: Oni wiedzą, co ja robię”.




Reakcje afektywne




Główną cechą charakteryzującą tę grupę zaburzeń psychotycznych jest niezwykle silne zaburzenie nastroju. Zwykłym objawem jest tu głęboka depresja, której towarzyszy ogólne spowolnienie aktywności umysłowej i fizycznej, ponure, chorobliwe myśli o chorobie lub śmierci oraz poczucie braku własnej wartości. W czasie takich okresów |depresji pacjenci mogą próbować popełnić samobójstwo i trzeba ich troskliwie pilnować. Mowa pacjentów cierpiących a psychotyczną depresję jest powolna, sformułowania lakoniczne; gdy mówią, to wyrażają zazwyczaj swe cierpienie i samobójcze pragnienia.
Ostrym przeciwieństwem depresji psychotycznej jest |mania (stan maniakalny), którą charakteryzuje silne podniecenie, euforia i nieustanna aktywność. Pacjenci maniakalni często śmieją się hałaśliwie, mówią głośno i z elokwencją. Poruszają się w sposób nieopanowany, uderzając o ściany i meble, gestykulując przy tym dramatycznie.
U większości pacjentów zaburzenia mają charakter albo maniakalny, albo depresyjny, lecz u niektórych okresy maniakalne i depresyjne następują po sobie na zmianę, często w cyklach regularności. Niekiedy między tymi epizodami są długie okresy, w czasie których u pacjenta nie obserwuje się żadnych objawów choroby. O utracie kontaktu z rzeczywistością świadczy pojawienie się tych skrajnych emocji bez jakiegokolwiek wyraźnego, zewnętrznego uzasadnienia. Niezależnie od tego, czy stosuje się jakieś leczenie, czy nie, objawy te utrzymują się zwykle przez parę tygodni lub parę miesięcy, a następnie ustępują.
Pewna forma skrajnej depresji, która występuje u pacjentów w średnim wieku lub później (mniej więcej po ukończeniu 40 lat), częściej wśród kobiet niż wśród mężczyzn, nosi nazwę |depresji (melancholii) |inwolucyjnej. Cechami psychologicznymi tej psychozy są niepokój, podniecenie i poczucie beznadziejności, jak również uczucia winy i porażki.  Wysuwa się sugestię, że zaburzenie to pozostaje w związku z fizjologicznym „okresem przekwitania”, który oddziałuje na funkcje reprodukcyjne. Ostatnio wykazano jednak, że prawdopodobieństwo wystąpienia zaburzeń afektywnych w okresie menopauzy jest nie większe niż w jakimkolwiek innym czasie w życiu kobiety (Winokur, 1973). Chociaż z pewnością istnieją zjawiska fizjologiczne towarzyszące menopauzie, to jednak jest prawdopodobne, że „okres przekwitania” stał się wygodnym wyjaśnieniem stosowanym dla wytłumaczenia różnych, często psychologicznych, zmian zachodzących w średnim i starszym wieku. Wyjaśnienia fizjologiczne są wygodne, ponieważ nikt nie jest winny ani odpowiedzialny za problem, można stosować medyczne formy leczenia (środki farmakologiczne, hormony itd.) i nie trzeba szukać przyczyn natury środowiskowej. Zastanówmy się jednak, co dla wielu kobiet oznacza średni wiek, gdy ich dzieci dorosły i nie są już od nich zależne, mężowie są zaabsorbowani karierą, są chorzy, zmarli lub interesują się młodszymi kobietami bądź piłką nożną, gdy przyjaciół jest niewielu, gdy dziewczęce marzenia nie zostały zrealizowane i przypuszczalnie nie dadzą się już zrealizować, a przede wszystkim odczuwa się głęboko utratę młodości, urody i możliwości. Być może, iż kobiety dobrze sytuowane, którym się powiodło, które mają poczucie spełnienia w swym życiu codziennym i w swych nadziejach, nie cierpią wskutek tak zwanej depresji okresu przekwitania. Zagadnienie to nie było przedmiotem badań, lecz zasługuje na to.
Pismo „Wall Street Journal” nazwało depresję „chorobą lat siemdziesiątych”, w roku 1973 „walka z depresją” była tematem artykułów wstępnych pisma „Newsweek”; Martin Seligman określił ją jako „powszechną jak katar formę psychopatologii”. Ze wszystkich form patologii opisanych w tym rozdziale jest ona jedyną, której prawdopodobnie doświadczyła już większość studentów. Wszyscy, w tym czy innym okresie, bywamy smutni, przygnębieni utratą najdroższej osoby lub rozłąka z nią, niepowodzeniem w dążeniu do upragnionego celu lub chroniczną frustracją i stresem.  „Normalna”, zwykłą depresja ma charakter przejściowy i wynika z sytuacji. W depresji nerwicowej objawy są głębsze, długotrwałe, powtarzające się i silniej zaburzające funkcjonowanie jednostki. Granica między depresją nerwicową i psychotyczną nie jest wyraźna, ponieważ ogólne pojęcie „depresji” oznacza zespół objawów bez jakiejś jednej definiującej cechy.  Dla psychotycznych form depresji charakterystyczna jest nie tylko jej intensywności i przewlekły charakter, lecz także towarzysząca im utrata kontaktu z rzeczywistością. Psychotyk w stanie depresji wymaga hospitalizacji i intensywnej opieki. National Institute of Mental Health (Narodowy Instytut Zdrowia Psychicznego) szacuje, że „Cztery do ośmiu milionów Amerykanów może potrzebować fachowej opieki z powodu zaburzeń depresyjnych” (Williams i in., 1970).
Analizując objawy występujące u pacjentów psychiatrycznych cierpiących na depresję, Beck (1967) wyodrębnił charakterystyczne różnice, dające się ująć w pięciu ogólnych kategoriach: emocjonalnej, poznawczo-motywacyjnej, wegetatywno-fizycznej, urojeniach oraz w wyglądzie zewnętrznym. Gdy zróżnicowaną grupę złożoną z 966 pacjentów psychiatrycznych poklasyfikowano zgodnie z poziomem głębokości ich depresji, to występowanie pewnych objawów wyraźnie różnicowało osoby z ciężką depresją od osób nie wykazujących depresji. Stwierdzono, że wszystkie objawy wymienione w zamieszczonej poniżej tabeli występowały w grupie pacjentów z depresją znacznie częściej (co najmniej u 30% osób) niż w grupie osób nie wykazujących depresji. 
Zachowanie depresyjne jest trudne do sklasyfikowania. Większość badaczy sądzi, że w rzeczywistości występują dwa typy depresji: endogenna i egzogenna (reaktywna). Rozróżnienie to opiera się na obecności lub braku wyzwalających czynników zewnętrznych (takich jak stres, konflikt lub utrata).
Przyjmuje się, że |depresję |endogenną powodują czynniki wewnętrzne (biochemiczne lub genetyczne).




* * *



Charakterystyczne Cechy Depresji


Emocjonalne:
Nastrój przygnębienia - Niechęć do samego siebie
Utrata zadowolenia - Zanik związków uczuciowych
Okresy płaczu - Utrata zdolności cieszenia się


Poznawczo-motywacyjne:
Oczekiwanie przykrych zdarzeń - Utrata motywacji
Pragnienia samobójcze - Niska samoocena
Zniekształcony obraz samego siebie - Samooskarżanie się, autokrytycyzm
Niezdecydowanie


Wegetatywno-fizyczne:
Zaburzenia snu - Utrata zainteresowań seksualnych
Męczliwość - Zaparcia


Urojenia:
Bezwartościowości - Grzeszności


Wygląd:
Twarz smutna - Mowa powolna, zredukowana, niespontaniczna
Postawa pochylona
(Źródło: Beck, 1967)


* * *





Do objawów tej formy depresji należą: obniżenie sprawności umysłowej („retardation”), silne przygnębienie, brak reaktywności na środowisko, brak zainteresowania życiem, bierność, utrata na wadze, poczucie winy, tendencje samobójcze (Mendels, 1970). Natomiast |depresja |reaktywna jest mniej groźnym zaburzeniem, a charakterystyczne, współwystępujące ze sobą elementy to w tym przypadku współczucie dla samego siebie, nieprzystosowawcze cechy osobowości oraz obecność sprzyjających wystąpieniu depresji stresorów.
Jednym z problemów, jakie nastręcza ta - jak i inne - klasyfikacja oparta na etiologii (nauka o przyczynach czy pochodzeniu chorób), polega na tym, że obserwacje przeprowadza się |po fakcie, gdy objawy są na tyle rozwinięte, że dana jednostka została poddana leczeniu. Niektóre badania wykazują, iż nieobecność psychospołecznych, sprzyjających czynników stresowych w depresji endogennej jest po prostu wynikiem tego, że pacjenci z poważnymi zaburzeniami nie są w stanie powiedzieć o nich lub nie zdają sobie z nich sprawy. Gdy pacjentów takich bada się dokładnie po powrocie do zdrowia, to często opisują oni zdarzenia stresowe podobne do tych, o których donosili pacjenci cierpiący na depresję reaktywną.
Dwa najbardziej obiecujące kierunki w badaniach nad depresją zawdzięczamy pracom Seligmana nad wyuczoną bezradnością (o których pisaliśmy w Rozdziale 9) oraz badaniom dwóch psychiatrów, Akiskala i McKinneya (1973).
Seligman w przekonujący sposób zademonstrował analogię między objawami i przyczynami wyuczonej bezradności, wytworzonej eksperymentalnie w laboratorium, oraz depresji reaktywnej, występującej w życiu codziennym.  Sądzi on, że wspólnym rdzeniem obu tych zjawisk jest wytworzenie się przekonania o nieskuteczności aktywnego działania. Osoba dotknięta depresją staje się bierna dopiero wskutek wielokrotnego braku pozytywnego wzmocnienia dla wykonywanych reakcji. Niektóre osoby cierpiące na depresję wykonują wiele reakcji, które jednak nie trafiają do „świadomości społecznej”, to jest reakcji, które inni ludzie rzadko wzmacniają. Później wzmocnienie pojawia się głównie w postaci uwagi i troski, jaką okazuje się reakcjom depresyjnym tej osoby („uboczny zysk” z patologii). Terapia musi zatem polegać na selektywnym |niezwracaniu |uwagi na objawy depresji (wygaszaniu ich) i pozytywnym wzmacnianiu aktywnych zachowań.
Akiskal i McKinney wysunęli hipotezę, że reakcje depresyjne mogą być wynikiem działania różnych mechanizmów, lecz wszystkie one mają „wspólny finał”, którym jest zaburzenie (aczkolwiek odwracalne) korowych mechanizmów wzmocnienia. Mechanizmy te mogą być zakłócone przez chemiczne lub genetyczne anomalie w mózgu, stresy będące wynikiem kontaktów z otoczeniem w niemowlęctwie, chroniczne bodźce awersyjne lub przez utratę kontroli nad efektywnością wzmocnienia.




Reakcje schizofreniczne




Nie ma większej zagadki ani ważniejszego zadania dla nauk medycznych i nauk zajmujących się zachowaniem, niż zrozumienie i opanowanie schizofrenii. Ocenia się, że od 2 do 3 milionów żyjących obecnie Amerykanów, w tym lub innym czasie, cierpiało na to najbardziej tajemnicze i tragiczne zaburzenie psychiczne. Połowę łóżek w zakładach psychiatrycznych w Stanach Zjednoczonych zajmują obecnie pacjenci z rozpoznaniem schizofrenii. Ocena, zgodnie z którą u 2% całej populacji wystąpi epizod schizofrenii w pewnym okresie życia, dla pewnych środowisk społecznych - na przykład w gettach miejskich - wzrasta do przerażających 6%, czyli więcej niż 1 na 20 osób.
Statystyka hospitalizowanych przypadków schizofrenii stawia nas wobec pewnego paradoksu. Z jednej strony występuje stały |spadek liczby osób przebywających w szpitalach psychiatrycznych z rozpoznaniem schizofrenii - spadek o więcej niż 30% w ostatnich piętnastu latach, jednakże w tym samym czasie liczba pacjentów schizofrenicznych przyjmowanych do szpitali stale |wzrastała. W samym tylko 1968 roku było ponad 320 tysięcy zachorowań, w przypadku których rozpoznano schizofrenię. Najwyraźniej występuje tu zjawisko „obracających się drzwi”; pacjenci są hospitalizowani przez krótszy czas, lecz częściej trafiają do szpitala ponownie.  Prawdopodobieństwo, że schizofrenik zostanie ponownie przyjęty do szpitala w ciągu dwóch lat od chwili wypisania go po pierwszym epizodzie schizofrenii, wynosi aż 60% procent. Ten wskaźnik „recydywy” nie odzwierciedla faktu, ż tylko 15 - 40% schizofreników leczących się ambulatoryjnie i żyjących w społeczeństwie osiąga przeciętny poziom przystosowania.
W specjalnym sprawozdaniu National Institute of Mental Healt (Narodowego Instytutu Zdrowia Psychicznego; Mosher i Feinsilver, 1971), dotyczącym aktualnego stanu badań nad schizofrenią i jej leczeniem, wymieniono dwa obszary problemów, które hamują postęp w lepszym zrozumieniu schizofrenii: bariery wynikające z niewłaściwych postaw oraz braku zgody co do faktów naukowych. 
Utrata przez pacjenta zainteresowania otaczającym go światem niepokoi rodzinę i przyjaciół i stanowi dla nich źródło negatywnych wzmocnień. Zbyt często i zbyt łatwo reagują oni na to wysyłając taką osobę do odległego zakładu opiekuńczego, aby odizolować się od jej szaleństwa. Postawy rodziny są odzwierciedleniem postaw całego społeczeństwa. „Zapewne z powodu strachu, jaki choroba psychiczna wywołuje w każdym z nas, ogół społeczeństwa nigdy nie domagał się przeprowadzenia generalnego natarcia na ten problem, o którego samym istnieniu, ogół ten wolałby zapomnieć (Mosher i Feinsilver, 1971, ss. 31-32). Może to być przyczyna, dla której społeczność naukowa nie poświęca schizofrenii takiej uwagi, na jaką ona zasługuje, a organy ustawodawcze i administracja nie przyznają odpowiednich środków na badania.
Fakt, że szereg zagadnień nadal jest przedmiotem sporu naukowców, spowodował nie koncentrację, lecz rozproszenie wysiłków badawczych. Czy schizofrenia jest jakąś pojedynczą chorobą, czy też wynikiem pewnej kombinacji różnych szkodliwych oddziaływań? Jak duże jest znaczenie czynników genetycznych i w jaki sposób schizofrenia jest przekazywana genetycznie? Czy wyróżniające się czynniki rodzinne i biochemiczne korelaty schizofrenii są jej przyczynami, czy też skutkami? Czy autyzm niemowlęcy i schizofrenia dziecięca są związane ze sobą i z przejawami tej choroby u dorosłych? To tylko kilka podstawowych problemów, które trzeba rozwiązać, zanim będzie można poczynić istotne postępy w zrozumieniu i leczeniu schizofrenii.


Określenie, czym jest schizofrenia. Początkowo zaburzenie to uważano za postępującą degradację umysłową, rozpoczynająca się we wczesnym okresie życia, i dano mu nazwę „dementia praecox” (otępienie wczesne) dla odróżnienia od psychozy afektywnej. Obecnie wiadomo, że schizofrenia nie musi „postępować” ani degradować do stanu demencji (otępienia umysłowego).  Zasadniczą jej cechą jest natomiast dezintegracja funkcjonowania osobowości. Różne aspekty osobowości pacjenta pozostają w konflikcie ze sobą, a zachowanie nie jest sterowane przez środowiskowe sprzężenie zwrotne.
Gdy ludzie raz przestaną kierować się sprzężeniem zwrotnym, wówczas mogą wystąpić uogólnione zmiany w ich procesach behawioralnych. Spostrzeżenia mogą występować bez bodźców sensorycznych (halucynacje); emocje mogą występować bez bodźców pobudzających lub przeciwnie - mogą nie występować w ich obecności; myślenie i mowa nie stosują się do logiki arystotelesowskiej ani do uznanych reguł gramatyki i stylistyki. Mogą następować zniekształcenia w perspektywie czasowej, wpływając na spostrzeganie zależności przyczynowych. Jednostki takie są zwykle hospitalizowane w celu leczenia przede wszystkim dlatego, że zachowanie, które nie jest pod kontrolą jakiegoś określonego układu sprzężenia zwrotnego, staje się nieprzewidywalne i stanowi potencjalne zagrożenie zarówno dla danej jednostki, jak i dla innych ludzi.
Jest kilka intrygujących cech reakcji schizofrenicznej, które zostały wykryte dzięki kontrolowanym badaniom. Schizofrenicy wykazują większą wrażliwość na bodźce percepcyjne, co powoduje, że są bardziej roztargnieni oraz „zalewani” przez stymulację zewnętrzną. Wskutek tego trudno jest im znaleźć stałość w środowisku sensorycznym. Zakłócone struktury myślowe mogą być konsekwencją niezdolności trwałego skupienia uwagi na zdarzeniach czy procesach.
Podobnie niezrozumiałość mowy schizofrenika spowodowana jest po części dziwacznymi wtrętami - myśli nie mające nic wspólnego z wypowiadanym zdaniem |nie są tłumione i schizofrenik nie potrafi zbudować długiego łańcucha wzajemnie powiązanych słów. Mowa schizofrenika zdaje się być pod kontrolą bezpośrednio działających bodźców. Schizofrenik, „roztargniony” pod wpływem nieustannie zmieniającego się wejścia sensorycznego i żywej rzeczywistości wewnętrznej, nie potrafi wypowiedzieć w całości prostego ciągu myśli i dlatego dla słuchacza słowa jego są pozbawione sensu.


Klasyfikowanie schizofrenii. Dla własnej wygody klinicyści wyróżniają kilka postaci schizofrenii, każdą z charakterystycznym zbiorem zachowań; sześć z nich przedstawiono pokrótce w zamieszczonej obok tabeli.
W okresie dziesięciu lat (od 1957 do 1967 roku) o 80% wzrosła liczba hospitalizowanych pacjentów poniżej 15 roku życia, u których rozpoznano schizofrenię dziecięcą. Ten nagły wzrost jest prawdopodobnie odzwierciedleniem powszechniejszej znajomości tego schorzenia i lepszego rozpoznawania go, a nie wzrostu liczby zachorowań.
Problem diagnozy i klasyfikacji ciągle jednak pozostaje nie rozwiązany, a jedną z poważnych przeszkód w lepszym zrozumieniu schizofrenicznego zachowania jest brak uzgodnionych przez ogół klinicystów kryteriów klasyfikowania tego zachowania.




* * *



Typy Schizofrenii


|Schizofrenia |dziecięca (autyzm (Autyzm - oderwanie od rzeczywistości, zamknięcie się w sobie; tak zwany osiowy (zasadniczy) objaw schizofrenii w ogóle. Część badaczy uważa, że autyzmu wczesnodziecięcego nie powinno się zaliczać do psychoz (przyp. red.)) wczesnodziecięcy)
Jednostka kliniczna zidentyfikowana po raz pierwszy przez Leo Kannera w 1943 roku. Ten typ schizofrenii zdaje się wynikać z pewnego defektu biologicznego, który powoduje niezdolność dziecka do odnoszenia się w zwykły sposób do innych ludzi i do bodźców środowiskowych. Dzieci autystyczne wykazują obsesyjne (natrętne) stereotypowe zachowania, niemożność jednoczesnego skupienia uwagi na bodźcach należących do różnych modalności zmysłowych oraz niezdolność przechodzenia od instrukcji słownych do działania. Psychika tych dzieci stanowi wyraźny przykład zamkniętego w sobie systemu.


|Schizofrenia |prosta
Redukcja zewnętrznych zainteresowań i związków uczuciowych, apatia, zamknięcie się w sobie, nie rzucające się w oczy urojenia lub halucynacje, pewna dezintegracja procesów myślowych, często agresywne zachowanie, doznania hipochondryczne oraz pobudzenie seksualne i nadużywanie alkoholu.


|Schizofrenia |paranoidalna
Słabo usystematyzowane urojenia; często wrogość, podejrzliwość, agresywność. Często urojenia wszechmocy, wybitnego utalentowania oraz wysokiej pozycji społecznej. Urojenia łączą się z dezorganizacją osobowości.


|Katatonia
Ujawnia się bardziej nagle i z większą siłą niż inne typy schizofrenii, z żywymi halucynacjami i urojeniami. Na zmianę występują osłupienie (stupor) i podniecenie; osłupienie polega na nagłym zahamowaniu aktywności, pacjent zaś przez pewien czas może pozostawać w stereotypowej pozycji - nie jedząc, nie pijąc ani nie troszcząc się o inne funkcje organizmu. Chorzy na schizofrenię katatoniczną stosunkowo najczęściej powracają do zdrowia.


|Hebefrenia
Najpoważniejsza dezorganizacja; wesołkowatość („silliness”), nieadekwatność afektu, niespójność myśli, mowy i działania, niezwykle dziwaczne zachowania („mannerisms”), halucynacje słuchowe i wzrokowe, fantastyczne urojenia, sprośne zachowanie, brak zahamowań, hipochondria, zobojętnienie emocjonalne, regresja do dziecięcego zachowania.


|Schizofrenia |niesklasyfikowana
Ostre lub chroniczne reakcje z różnymi objawami.


* * *





Chociaż istnieje pewna jednomyślność co do wielu podstawowych objawów związanych ze schizofrenią, to jednak żaden pacjent nie wykazuje ich wszystkich jednocześnie, u każdego zaś z pacjentów w różnych okresach mogą występować różne objawy.


„O tym, że istnieją różnice nie tylko między klasyfikowanymi, ale także między tymi, którzy klasyfikują, świadczą wyniki badań, w których amerykańskich i brytyjskich psychiatrów proszono o stawianie diagnozy na podstawie rozmów lekarza z pacjentami, zarejestrowanych na taśmie magnetowidu. Amerykanie częściej klasyfikowali pacjentów jako schizofreników. Brytyjczycy zaś - jako przypadki psychozy aktywnej. 
Pacjentów wykazujących zarówno zaburzenia myśli, jak i zaburzenia nastroju, 
amerykańscy psychiatrzy zaliczali do schizofreników, psychiatrzy brytyjscy 
zaś rozpoznawali u nich zaburzenie afektywne”
(Mosher i Feinsilver, 1970).


Nawet jeśli obserwatorzy zaczną zgodnie klasyfikować to, co widzą, to w pełni zrozumieć schizofrenię będziemy mogli tylko wtedy, jeśli nasze obserwacje zewnętrznych wskaźników behawioralnych uzupełnimy opisami z „pierwszej ręki”, dokonywanymi przez samych pacjentów (które to opisy pozwolą zapoznać się z ich odczuciami).




Zbliżenie


Z dziennika schizofrenika


„W „wewnętrzny świat choroby psychicznej” można wejrzeć dzięki opisom, jak zamieszczony poniżej, którego autorem jest pewien mężczyzna dobiegającego trzydziestki. Niezwykła ortografia i struktura zdań nie wynikają z braku wiedzy, lecz z osłabienia dyscypliny myślenia i wysławiania się.
„Jestem przekonany, że te rzeczy wyliczone poniżej są różnicowymi sposobami, które mamy dla wyładowania naszych emocji. Palenie 1. Uczenie się grad na trąbce. 2. Żucie gumy 3. Sporty itd. 4. Robienie czynoci, którymi cieszymy się robiąc 5. Picie do upicia. 5. Pracowanie nad lub z rzeczami, którymi cieszymy się robiąc.
Człowiek nie może żyć tym co kościół mówi 100%. Ponieważ jesteśmy ludzcy i ludzkiej natury nie możemy żyć bez okazywania czy emocji. Siły woli ja potrzebuję więcej pewnych faz’ah Życia.
Niektóre powody dlaczego kocham mężczyzn. 1. Ciężkie położenie 2.  Atrakcyjna budowa 3. Miła powierzchowność. 4. Nie czucie się dobrze wobec gobied. 5. Nie czuję zdolny odprężyć wobec nich 6. Czuję że nie byłym zdolny kontrolować mojego uczucia miłości wobec nich lecz, ja ucze jak.
Bóg daje mi dar wiedzy. Bóg pomaga mi jako jego służoncy cały czas być pokornie przet nim. Patrz naprzód a nie do tyłu. Nie możemy nigdy zmienić przeszłości. Lecz możemy zmienić przyszłość. Możemy więc patrzeć naprzód zamiast do tyłu (...). Myślę że jestem homoseksualistą bo jestem zakochany w każdym, musimy kochać całą ludzkość aby pójść do nieba. To naprawdę trudno powiedzieć nie znosiłem że wytworzyło się taki nawyk przeglądania facetów i patrzeć czy naprawdę kocha się ich czy nie (...).
Musimy nauczyć się |ufać ludziom. Musimy nauczyć się ufać ludziom całkowicie znowu, po tym jak byliśmy chorzy. Grzech lub zaufanie złej osobie powoduje, że stajemy się prawdziwie chorzy. Musimy nauczyć się panować nad własnym umysłem. Nasze działania nie zawsze dadzą wytłumaczyć się tak dobrze, jak próbujemy je zrozumieć. Nie spieszyć się - da lepsze wyniki, jeśli odprężymy się i robimy wszystko w naszym własnym sempie. Bóg jest miłością i on zna kłopot, jaki mamy ucząc się podejmować własne decyzje. Nie przejmuj się, wszystko znajdzie rozwiązanie” (Kaplan, 1964, ss. 191 - 192).


Niektórzy schizofreniczni pacjenci wydają się tak apatyczni i pozbawieni wszelkiej motywacji, że personel psychiatryczny decyduje, iż terapia „poszłaby na marne”. Biorąc pod uwagę ograniczone środki, jakimi dysponuje większość szpitali psychiatrycznych, decyzje dotyczące leczenia często podejmuje się w zależności od prognozy odnoszącej się do możliwości wyleczenia danego pacjenta: pacjenci z pomyślną prognozą są poddawani intensywnemu leczeniu, podczas gdy pacjentami nie reagującymi na stymulację środowiskową opiekuje się jedynie personel pomocniczy. Ci ostatni pacjenci często dostają się w końcu do jakiejś „bocznej” sali szpitala, gdzie mogą spędzić całe życie, jeżeli nie wyleczą się „o własnych siłach”. Lecz ten brak reaktywności może być jedynie pozorny i w rzeczywistości jest często stosowaną przez pacjenta metodą radzenia sobie z tym, co dzieje się w oddziaływującym nań środowisku.
W pewnych badaniach, polegających na dokładnej obserwacji - z minuty na minutę - zachowania chronicznych pacjentów psychotycznych w West Haven Veterans Hospital, stwierdzono, że mężczyni ci stworzyli złożony system interakcji społecznych regulujący sposób proszenia o papierosy i zapałki oraz dawnia ich. Bez słów, pisanych reguł czy wyraźnych instrukcji, wytworzył się system, polegający na tym, że gdy pewni pacjenci usiedli na pewnych krzesłach to było to wiarygodnym sygnałem dla reszty sali, że dysponują oni albo papierosami, albo zapałkami. Jeśli więc jakiś pacjent poprosił, to otrzymywał, a jeśli chciał dać - to proszono go. Taki system minimalizował potencjalną frustrację w jedynej dziedzinie, w której uznawany był kontakt interpersonalny (Hershkowitz, 1970).
Stworzenie takiego systemu interpersonalnego i reagowanie na niego wymaga większej motywacji i bystrości poznawczej niż to się zwykle przypisuje chronicznie chorym psychotykom. Niestety, ich pozorny brak motywacji wynika w dużej mierze z ich wysiłków, aby wydawać się niemotywowanymi. Być może, iż taka taktyka ma na celu oszukanie nie opiekunów, lecz siebie samego - jeśli nie masz żadnych celów i nie chcesz niczego, to nie możesz być sfrustrowany. Możliwe jest, że pacjenci psychiatryczni, stwarzając pozory, iż są niemotywowani, skutecznie wywierają wrażenie, o które im chodzi, lecz przez to mimowolnie zmniejszają swe szanse na terapię i następujące po niej zwolnienie ze szpitala.




Geneza psychotycznego
zachowania




Dążąc do rozwiązania zagadki zachowania psychotycznego, badacze próżno dotąd poszukują jego |przyczyny. Niektórzy szukają jej w naturze, inni - w wychowaniu. Stawką jest tu oczywiście coś więcej nić ciekawość naukowa, ponieważ poznanie przyczyn rozwijania się psychozy oraz - miejmy nadzieję - opanowanie jej, które umożliwiłaby taka wiedza, przyniosłoby ulgę w niewiarygodnych wprost cierpieniach ludzkich, jednocześnie wyjaśniając nam, w jaki sposób funkcjonuje umysł człowieka - i dlaczego zdarza się, że funkcjonuje on źle.
Rozważaliśmy już problemy nieodłącznie związane z próbą ustalenia, czy to natura, czy też wychowanie jest ważniejszym determinantem jakiejś cechy.  Wielu badaczy faworyzuje „wieloczynnikową” koncepcję schizofrenii i innych psychoz: sądzą oni, że wchodzi tu w grę interakcja czynników biochemicznych, neurologicznych i środowiskowych. Niemniej jednak trwa nadal poszukiwanie pojedynczej, biologicznej przyczyny „choroby” psychicznej.


Czynniki dziedziczne. „Wszystko to jest w genach” - oto jeden z poglądów na podłoże psychozy czynnościowej. Dotknięte nią jednostki dziedziczą pewną strukturę genetyczną, która przypuszczalnie zwiększa prawdopodobieństwo tego, iż staną się one psychotykami. Początkowo słuszność tego stanowiska potwierdzały wyniki licznych badań, w których wykrywano, że zaburzenia psychotyczne często występują w tych samych rodzinach. Fakt ten nie jest bynajmniej dowodem istnienia podłoża dziedzicznego, ponieważ ludzie o „niekorzystnym” wyposażeniu dziedzicznym często żyją w środowiskach, które są szkodliwe dla fizycznego i psychicznego zdrowia.
Mocniejszego materiału dowodowego, potwierdzającego hipotezę o przyczynach dziedzicznych, dostarczyły wyniki badań świadczące o tym, że ryzyko zapadnięcia na schizofrenię wzrasta wraz ze stopniem genetycznego pokrewieństwa z pacjentem schizofrenicznym. Prawdopodobieństwo, że rodzony brat czy siostra schizofrenika zachoruje na schizofrenię, jest dwa razy większe niż w przypadku rodzeństwa przyrodniego - jakkolwiek w obu przypadkach środowisko jest wspólne. Ryzyko zapadnięcia na schizofrenię wzrasta znacznie wtedy, gdy oboje rodzice byli schizofrenikami, największe zaś jest u identycznych bliźniąt wychowywanych razem - ponad 90%.
Aczkolwiek kilka wczesnych badań przyniosło zgodne wyniki, że u identycznego bliźniaka schizofrenika rozwinięcie się schizofrenii jest znacznie bardziej prawdopodobne niż u bliźniaka „zwykłego”, to jednak ostatnie badania poważnie podważyły te twierdzenia.


„W pewnych bardzo solidnie przeprowadzonych badaniach nad 342 parami bliźniąt w wieku od 35 do 64 lat, zamieszkałych w Norwegii, wśród których jedno lub dwoje było hospitalizowanych z powodu psychozy czynnościowej, stwierdzono wskaźniki zgodności (Wskaźnik zgodności wynoszący 38% oznacza, że w 38% przypadków identyczny bliźniak pacjenta schizofrenicznego również zapadł na schizofrenię.) wynoszące tylko 38% dla bliźniąt jednojajowych (identycznych) i 10% dla bliźniąt dwujajowych.


Różnica ta sugeruje, że czynnik genetyczny jest ważny, lecz nie odgrywa tak dominującej roli, jak zakładano uprzednio. Badacz stwierdził: „W przeprowadzonych dotąd badaniach zdaje się regularnie występować następująca zależność: im dokładniejszy i bardziej staranny dobór grupy badanych, tym niższe wskaźniki zgodności” (Kringlen, 1969, s. 38).


Podczas gdy w badaniach opublikowanych przed 1960 rokiem podawano wskaźniki zgodności sięgające 86% dla bliźniąt jednojajowych i tylko w 17% dla bliźniąt dwujajowych, to w pięciu poważnych badaniach przeprowadzonych po 1960 roku uzyskano wskaźniki zgodności różniące się mniej, gdyż wynosiły one 6 - 43% dla bliźniąt jednojajowych i 5 - 12% dla bliźniąt dwujajowych.
Gdy dzieci schizofrenicznych rodziców, które zostały zaadoptowane przez rodziców normalnych pod względem psychicznym, porównano z adoptowanymi dziećmi, których biologiczni rodzice zostali sklasyfikowani jako normalni, to różnica między liczbą zachorowań na schizofrenię w obu tych grupach okazała się minimalna. Duński zespół badaczy podał, że 14% dzieci narażonych na wysokie ryzyko zachorowania było hospitalizowanych z przyczyn psychiatrycznych, lecz z tych samych przyczyn hospitalizowanych było 10% dzieci z grupy kontrolnej. Według sprawozdania szpitalnego, schizofrenię rozpoznano zdecydowanie tylko u 1,3% dzieci schizofrenicznych rodziców i u żadnego dziecka z grupy kontrolnej (przytoczone przez Moshera i Feinsilvera, 1971, s. 12).
Większość psychologów i psychiatrów zgadza się obecnie, że tym, co |może być wrodzone, jest |predyspozycja do psychozy; uważa się, że w niepomyślnych warunkach bardziej prawdopodobne jest rozwinięcie się psychozy u jednostki predysponowanej niż u innych osób, u których może się rozwinąć jakieś mniej poważne zaburzenie. Jest bardziej prawdopodobne, że patologicznych sposobów radzenia sobie z otoczeniem szybciej nauczy się dziecko, które mieszka z psychotycznym krewnym, niż dziecko które mieszka ze zdrowym krewnym. Gdy dziecko ma dwoje schizofrenicznych rodziców - dwa modele anormalnego, patologicznego zachowania, które naśladuje i którymi się posługuje w procesie porównywania społecznego - to prawdopodobieństwo, że nauczy się ono schizofrenicznych wzorców zachowania jest większe.


Czynniki środowiskowe. W ostatnich latach coraz większy nacisk kładzie się na badanie złożonej macierzy środowiskowo-społecznej, w której funkcjonuje schizofreniczna jednostka. Podobnie jak czynniki genetyczne mogą uczynić daną jednostkę podatną biologicznie, tak czynniki środowiskowe, takie jak odrzucenie przez rodziców lub nadmierna troskliwość z ich strony, zbyt surowa lub niekonsekwentna dyscyplina czy też skrajny brak poczucia bezpieczeństwa, mogą psychologicznie predysponować jednostkę do zaburzeń psychicznych. Badania nad strukturą rodzinną schizofreników, jak również nad innymi cechami ich życia społecznego, ujawniają, w jakim stopniu psychoza może reprezentować wyuczone sposoby radzenia sobie z chronicznym stresem i nierozwiązywalnymi konfliktami.
Jednym z najbardziej rzetelnych wskaźników prognostycznych przyszłego zapadnięcia na schizofrenię jest wczesna |izolacja |społeczna, powstająca wówczas, gdy dorastający chłopak czy dziewczyna wycofują się z interakcji z innymi ludźmi. Może to być konsekwencją poczucia, że jest się pod pewnymi względami różnym czy „anormalnym”, lub skutkiem nie nauczenia się sposobów kontaktowania się z innymi ludźmi w pozytywny, sensowny sposób, lub też jednego i drugiego.
Wyniki wielu badań wskazują wyraźnie, że jednym z najbardziej zakłócających czynników w życiu dzieci schizofrenicznych, są stosunki między ich rodzicami oraz sposób, w jaki posługują się oni dzieckiem dla wyładowania swych własnych uczuć: frustracji i wrogości. Mogą oni stawiać dziecko w roli „bufora” czy mediatora i powodować, że czuje się ono odpowiedzialne za trwanie lub rozpad ich małżeństwa; rodzice mogą też w subtelny sposób stworzyć układ, w którym warunkiem kontynuowania ich chwiejnie zrównoważonego stosunku jest utrzymanie zależności dziecka od nich.
Badania nad interakcjami w rodzinie wykazują, że w rodzinach, w których jeden z członków jest schizofrenikiem, sposób porozumiewania się charakteryzuje mniejsza reaktywność i mniejsza wrażliwość interpersonalna niż w normalnych rodzinach. Członkowie rodzin, w których dzieci wykazują największe zaburzenia, nie słuchają tego, co do siebie nawzajem mówią, ani też nie spędzają tyle czasu na wymienie informacji, co normalne rodziny (Ferriera i Winter, 1964). Członkowie rodzin, w których młodzi w okresie dorastania wycofują się z interakcji społecznych, wykazują mniejszą zdolność wzajmenego przewidywania swych reakcji w sytuacji testowej.
Niekiedy inni członkowie rodziny schizofrenika mają większe trudności z porozumiewaniem się z otoczeniem niż ten, u którego rozpoznano schizofrenię. Prowadzi to do przypuszczenia, że tam, gdzie różni członkowie rodziny reagują „anormalnie”, tam jeden może zostać „wybrany” i otrzymać etykietę chorego psychicznie. Następnie oczekuje się od niego, że będzie postępować jak „wariat” i może nawet otrzymywać wzmocnienia za takie postępowanie.
Szersze środowisko kulturowe również zdaje się wpływać na to, jaką formę przybierze patologiczne zachowanie. Na przykład, podobnie jak nerwicową reakcję konwersyjną spotyka się obecnie rzadziej niż dawniej, tak samo chorych na psychozę maniakalno-depresyjną jest obecnie w szpitalach psychiatrycznych mniej niż 20 czy 30 lat temu (Lundin, 1961).
W społeczeństwie amerykańskim ludzie z niższych klas społeczno-ekonomicznych częściej zapadają na schizofrenię, a ludzie lepiej sytuowani częściej stają się neurotykami (Hollingshead i Redlich, 1958).  Być może, iż wyższy wskaźnik schizofrenii w rodzinach należących do klasy niższej można przypisać stosowanym w nich metodom wychowania (Langer i Singer, 1959). Jest także możliwe, że wiele środowiskowych konsekwencji ubóstwa - bezsilność, sfrustrowane ambicje, brak oparcia, fakt, że przegrywa się bitwę o przetrwanie - dostarczają żyznej gleby dla psychotycznej patologii.


„Pogląd, że ubodzy ludzie przez całe życie są narażeni na urazy ze strony środowiska, które zwiększają prawdopodobieństwo wystąpienia u nich poważnych zaburzeń psychicznych znalazł potwierdzenie w badaniach przeprowadzonych w Nowym Jorku. Na podstawie oceny psychiatrycznej i analizy komputerowej dokładnych wywiadów z matkami 2 tysięcy dzieci, w wieku od 5 do 18 lat, stwierdzono, że 23% dzieci korzystających z opieki społecznej cierpiało na zaburzenia umysłowe w stopniu na tyle poważnym, aby wymagały natychmiastowego leczenia.


Wskaźnik ten był prawie dwa razy wyższy niż u ich rówieśników nie korzystających z pomocy społecznej (Langer i in., 1970).


Pogląd, zgodnie z którym istnieje związek między klasą społeczną, a choroba psychiczną, miał w historii wielu prekursorów, co wykazali Bruce i Barbara Dohrenwend (1974) w przeprowadzonej przez siebie dokładnej analizie czynników społecznych i kulturowych wpływających na psychopatologię. Zwolennicy teorii |stresu |społecznego, reprezentujący orientację „środowiskową”, stwierdzili, że ubodzy ludzie cierpią z powodu większych stresów życiowych, co prowadzi do częstszego występowania u nich patologii. Z drugiej strony, zwolennicy teorii |selekcji |społecznej przypisywali większą częstość występowania patologicznych zaburzeń u członków klas niższych czynnikom genetycznym. Fakt, że chory psychicznie często nie potrafi kierować swymi sprawami, uważali oni za przyczynę niepowodzeń ekonomicznych. Zgodnie z tym poglądem, ubóstwo jest produktem końcowym uprzednich zaburzeń psychicznych. 
Jest też możliwe, że różnice pod względem rodzaju zaburzeń psychicznych, występujących w różnych klasach społecznych, mogą być odzwierciedleniem tendencyjności w stawianiu diagnozy i w leczeniu pacjentów. Na przykład, ubożsi pacjenci, którzy nie są w stanie zapłacić za terapię, mogą być przekazywani do szpitali państwowych jako „nie nawiązujący kontaktu psychotycy”, podczas gdy osoby, u których występują podobne objawy, a które mogą pozwolić sobie na psychoterapię, są spostrzegane i określane jako „neurotycy potrzebujący terapii w celu przepracowania swych konfliktów”.
Gdy wartości społeczne zmieniają się, gdy dokonuje się rewizji dotychczasowych definicji określających, co dopuszczalne i właściwe, gdy nasze wspólne poglądy na to, jakie są sensowne cele w życiu i co jest „rzeczywistością” ulegają zmianom, to możemy oczekiwać odpowiednich zmian w podejmowanych przez ludzi próbach przystosowania się do ich psychologicznego środowiska. Wydaje się prawdopodobne, że coraz więcej będzie takich osób, które zamiast tracić kontakt z trudną do zniesienia rzeczywistością, będą się otwarcie przeciw niej buntować, będą „odpływać” od niej chwilowo na fali narkotyków lub wycofywać się z niej na stałe wraz z przyjaciółmi, którzy zdecydują się dzielić razem złudzenie tworzenia nowej, prywatnej, wspólnej rzeczywistości w postaci „komuny”, z którą mogą się związać.




Utrata innych możliwości
istnienia: samobójstwo




Z pewnością w życiu każdego z nas są okresy, kiedy po prostu nie potrafimy sobie wyobrazić, jak zdołamy przeżyć następny dzień; gdy życie nie wydaje się warte męki i cierpień, do których znoszenia nas zmusza. Może straciliśmy właśnie ojca, matkę lub bliskiego przyjaciela; zawiedliśmy się na ukochanej osobie; nie zaliczyliśmy roku lub straciliśmy pracę, którą lubiliśmy. Jednak jakkolwiek „uzasadnione” i silne są te uczucia ostatecznej beznadziejności i towarzyszące im przelotne pragnienia, aby skończyć z tym wszystkim, większość z nas nie poddaje się temu impulsowi.  Jak kiedyś powiedział Nietzsche: „Myśl o samobójstwie jest wielkim pocieszeniem. Dzięki niej udaje się przetrwać wiele złych nocy”.
Tragiczne jest to, że każdego dnia dla ponad tysiąca ludzi samozniszczenie jest czymś więcej niż przelotnym pragnieniem, jest ostatnim zdarzeniem w ich życiu. Według World Health Organization (Światowej Organizacji Zdrowia), prawie pół miliona ludzi rocznie popełnia samobójstwo, a liczba ta staje się jeszcze bardziej przerażająca, gdy uświadomimy sobie, że znacznie więcej nieskutecznie próbuje sobie odebrać życie. Jako przyczyna śmierci samobójstwo zajmuje obecnie siódme miejsce w Stanach Zjednoczonych, jest zaś w pierwszej dziesiątce w uprzemysłowionych krajach świata. Jakie są tego przyczyny i jakiego rodzaju ludzie przyczyniają się do powstania tej statystyki? Co wiemy o czynniku ludzkim w tym równaniu życia i śmierci?




Naukowa klasyfikacja
nienaukowego pojęcia




Samobójstwo najzwięźlej definiuje się w kategoriach dwóch podstawowych cech: |zamiaru i |wyniku. „Prawdziwe” samobójstwo popełniają ludzie, którzy zamierzają się zabić i którzy rzeczywiście to czynią. Aczkolwiek wyniki są oczywiste - jednostka albo przeżyje, albo umrze - to jednak zamiarów nie da się określić tak łatwo. Niektóre przypadki zupełnie wyraźnie wskazują na zamiar odebrania sobie życia: skok z dachu wysokiego budynku czy strzał w głowę. Inne, takie jak zażycie kilku dodatkowych pigułek nasennych (po czym natychmiast telefonuje się do przyjaciół, by poinformować ich o podjętym działaniu), czy też powierzchowne przecięcie nadgarstków właśnie w chwili, gdy wóz męża wjeżdża do garażu, zdają się wskazywać, że zadanie sobie śmierci nie było tu rzeczywistym zamiarem.
Być może, najbardziej ze wszystkich przerażającym samobójczym zamiarem jest to, co nazywano „grą ze śmiercią”. W tym przypadku zamiarem danej jednostki jest umrzeć lub nie umrzeć, w całkowitej zależności od sił zewnętrznych działających w jakiejś sztucznie stworzonej sytuacji. Gra w „rosyjską ruletkę” jest skrajnym przykładem tego zjawiska. Szczególnie fascynujące jest to, że ten typ aktu samobójczego może być zinstytucjonalizowany w społeczeństwie. Antropologowie donoszą, że na Tikopi, wyspie leżącej w pobliżu Nowej Gwinei, znieważony mężczyzna bierze łódkę i wypływa na ogromne przestrzenie Pacyfiku. Gdy jego nieobecność zostanie zauważona, wówczas wypływa ekipa ratunkowa, aby go odnaleźć; jeśli go rzeczywiście odnajdą - będzie żył, jeśli nie - to umrze.




* * *



Ryc. 11.9. Sylvia Plath, znana poetka i autorka „The Bell Jar”, popełniła samobójstwo w 1963 roku, Janis Joplin i Jimi Hendrix, popularni artyści rockowi, zmarli w 1970 roku, oboje w wieku 27 lat, wskutek przedawkowania narkotyków. Nie wiadomo na pewno, czy ich śmierć była zamierzona.


* * *





I tu także jest to próba losu: „Jeśli oni dbają o mnie dostatecznie, to odnajdą mnie; jeśli nie dbają, to chce umrzeć” (Firth, 1961).
Na podstawie tego rodzaju informacji Farber (1968) skonstruował prosty model, w którym krzyżują się kategorie zamiaru („umrzeć” i „nie umrzeć”) i wyniku (śmierć, zachowanie życia). W rezultacie otrzymuje się cztery typy sytuacji; przypadki należące do typu A (osoby zamierzające umrzeć i rzeczywiście ponoszące śmierć) są to jedyne „prawdziwe” samobójstwa, które spełniają oba kryteria definicji. W przypadku typy B (osoby zamierzające umrzeć, ale pozostające przy życiu), chociaż z psychologicznego punktu widzenia są one najbardziej podobne do samobójstw „prawdziwych”, próby odebrania sobie życia są nieskuteczne. Osoby te albo przeceniają śmiertelne oddziaływanie środka farmakologicznego, albo zostały nieoczekiwanie wyratowane. Gorzką ironią są przypadki należące do typy C (samobójstwa pomyłkowe) - osoby te nie zamierzają umrzeć, a jednak umierają. Kochanek zapomniał o umówionych odwiedzinach, pomoc domowa spóźniła się lub niebezpieczeństwo śmiertelnie działającego środka nie zostało właściwie ocenione. Największa ze wszystkich grupa przypadków należy do typu D („zamierzone niepowodzenia” - osoby te w rzeczywistości nie mają zamiaru umrzeć i pozostają przy życiu). Są to ci, którzy ciągle podejmują próby, wiecznie powtarzają gesty samobójcze, ci, którzy „krzyczą o pomoc”.
Bezpośrednie badania psychologiczne nad samobójstwem w tych przypadkach, w których wynikiem była śmierć, mogą polegać jedynie na historycznej rekonstrukcji przypadku. Badania warunków uprzednich i psychospołecznej dynamiki samobójstwa koncentrują się zatem oczywiście na tych ludziach, którym próba samobójcza nie powiodło się, czy to w sposób zamierzony czy nie zamierzony. Badając tych ludzi, którzy próbowali, lecz którym się „nie powiodło”, możemy w istocie dowiedzieć się wielu rzeczy pomocnych w zrozumieniu tej ucieczki od życia.




Czynniki społeczne
a samobójstwo




Autodestrukcję najlepiej można zrozumieć rozpatrując ją w powiązaniu z czynnikami środowiskowymi - sytuacjami społecznymi i naciskiem życia - które odgrywają poważną rolę w samobójstwach wielu osób. Wykazano, że wskaźniki samobójstw są związane z wielką liczbą zmiennych w złożonym zbiorze czynności, zależności i instytucji, które składają się na życie społeczne mężczyzn i kobiet w dzisiejszym społeczeństwie.


|Płeć. Jeśli chodzi o |próby samobójstw, to kobiety są reprezentowane trzykrotnie liczniej niż mężczyźni. W jednym z badań stwierdzono, że 69% wszystkich usiłowanych samobójstw w Stanach Zjednoczonych popełniają kobiety, natomiast próby mężczyzn są skuteczniejsze - popełniają oni 70% udanych samobójstw (Farberow i Shneidman, 1965). Stwierdzono, że gospodynie domowe podejmują dwa razy więcej prób samobójstw niż wszystkie inne kobiety. W przeszłości społeczeństwo skłonne było wychwalać bezpieczną pozycję „pani domu”, to jednak obecnie badacze sądzą, że wiele kobiet należących do tej kategorii w rzeczywistości pragnie uciec od tego, co w wielu wypadkach równa się życiu w samotności i w odosobnieniu.
Rozbieżność między liczbą usiłowanych i udanych samobójstw wśród mężczyzn i kobiet może wynikać z faktu, że mężczyźni są bardziej doświadczeni w użytkowaniu śmiercionośnych broni (i mają do nich łatwiejszy dostęp), które zapewniają skuteczną realizację destrukcyjnych zamiarów. Mężczyźni najczęściej popełniają samobójstwo przez zastrzelenie się lub powieszenie, podczas gdy kobiety prawie zawsze stosują jakąś bardziej bierną metodę samounicestwienia się: lekarstwa, trucizny lub gaz.
Należy jednak zauważyć, że środki, za pomocą których ludzie popełniają samobójstwo, różnią się w zależności od kraju, stosownie do tego, co jest w nim dostępne i modne. W przeciwieństwie do preferencji Amerykanów, w Nigerii na przykład najpopularniejszym sposobem popełniania samobójstwa (dla obu płci) jest powieszenie się, podczas gdy mężczyźni i kobiety w Anglii skłonni są stosować gaz. W Bazylei (Szwajcaria) samobójstwa popełniano najczęściej przy użyciu gazu, dopóki władze nie doprowadziły do gospodarstw domowych gazu nietrującego; najbardziej popularne stały się wówczas samobójstwa przez utopienie się.


|Wiek. Samobójstwa wśród dzieci są bardzo rzadkie. Dla wieku od 5 do 15 lat utrzymuje się stały wskaźnik 0,2 na 100 tysięcy, który nie zmienia się ani z upływem czasu, ani nie jest zależny od zmiennych demograficznych. W ogólnej populacji młodzieży dorastającej (wiek od 15 do 19 lat) wskaźnik samobójstw skacze do 5,5 na 100 tysięcy chłopców i 2,0 na 100 tysięcy dziewcząt i zajmuje czwarte miejsce jako przyczyna śmierci - drugie zaś w przypadku studentów wyższych uczelni.
Statystyki opublikowane ostatnio przez Los Angeles Suicide Prevention Center (Ośrodek Zapobiegania Samobójstwom w Los Angeles) wykazują, że coraz większa liczba młodych ludzi ucieka się do samobójstw. W samym okręgu Los Angeles wskaźnik samobójstw wśród osób od kilu do dwudziestu paru lat przekracza wskaźnik dla osób w wieku ponad trzydzieści lat - alarmujące odwrócenie tradycyjnej zależności, że częstość samobójstw wzrasta z wiekiem. Co więcej, wydaje się, że tendencja ta jest charakterystyczna dla całego obszaru Stanów Zjednoczonych. Co tłumaczy ten wzrost liczby młodych ludzi, którzy chcą ze sobą skończyć? Badacze podają oklepane wyjaśnienia wskazujące na nadużywanie narkotyków i naciski ze strony szkoły, lecz po prostu nie potrafią wyjaśnić tego tragicznego marnotrastwa życia ludzkiego.  Wywiady przeprowadzone z ofiarami nieudanych prób samobójczych oraz retrospektywne analizy przypadków samobójstw udanych, ujawniły intensywny strach przed naciskiem ze strony rodziców, poczucie skrajnej beznadziejności, które jest rzutowane na ocenę całej sytuacji społecznej, najczęściej zaś - przytłaczające poczucie samotności („Newsweek”, 15 lutego 1971).
W odniesieniu do osób w średnim wieku wskaźniki samobójstw stale rosną, co koreluje ze wzrastającymi naciskami ze strony pracy i rodziny, jak również psychicznymi i fizjologicznymi zmianami, które zwiastują starość.  Wykazano, że chociaż wskaźniki usiłowanych samobójstw są najniższe wśród osób w starczym wieku, to jednak wskaźniki skutecznych samobójstw są wtedy najwyższe. Starsi ludzie podchodzą zatem najbardziej serio do aktów samodestrukcji. Nie jest zaskakujące, że w tak licznych przypadkach samotności - w wyniku śmierci kochanej osoby, odrzucenia przez własną rodzinę, braku kontaktów społecznych, ostrego fizycznego bólu czy też braku zabezpieczenia finansowego - samobójstwo jest uważane za najlepsze rozwiązanie, pozwalające uciec przed szybkim zbliżaniem się tego, co nieuchronne.


|Wykształcenie. Wśród dorosłej populacji Stanów Zjednoczonych wskaźnik samobójstw jest |odwrotnie skorelowany z poziomem wykształcenia. Ludzie o wykształceniu wyższym niż przeciętne rzadziej popełniają samobójstwo niż ludzie o wykształceniu niższym od przeciętnego. Jednakże wskaźnik samobójstw wśród studentów wyższych uczelni jest wyższy niż wśród niestudiujących osób w tym samym wieku. Jedyną przyczyną śmierci studentów wyższych uczelni „wyprzedzającą” samobójstwa są wypadki. Jednakże trzeba pamiętać, że wskaźnik śmiertelności wszystkich młodych ludzi jest przeważnie niski, a ponadto, że w USA młodzi ludzie, którzy nie uczęszczają na wyższe uczelnie, znacznie częściej giną wskutek zabójstw niż wskutek samobójstwa.




Zbliżenie


Samobójstwa studentów wyższych uczelni


„Każdego roku 10 tysięcy studentów w Stanach Zjednoczonych usiłuje popełnić samobójstwo, a ponad tysiąc czyni to skutecznie. Największa liczba zachowań samobójczych występuje na początku i przy końcu semestru. Blisko trzy razy więcej studentek niż studentów usiłuje popełnić samobójstwo, lecz podobnie jak w całej populacji, częstość przypadków śmiertelnych jest znacznie większa wśród mężczyzn.
Gdy student czy studentka wyższej uczelni próbuje popełnić samobójstwo, to jednym z pierwszych wyjaśnień nasuwających się osobom z ich otoczenia są niepowodzenia w nauce. Jednakże studenci usiłujący popełnić samobójstwo są jako grupa dobrymi studentami i chociaż są oni skłonni wiele od siebie wymagać, jeśli chodzi o osiągnięcia w nauce, i przejawiają pewne „szkolne” lęki, to jednak istotnymi przyczynami ich samobójstw nie są zwykle stopnie, rywalizacja w nauce ani napięcia związane z egzaminami. Co więcej, nawet wtedy, gdy niepowodzenie w nauce istotnie zdaje się wyzwalać zachowanie samobójcze - to znaczy w mniejszości przypadków - na ogół uważa się, że rzeczywistą przyczyną tego zachowania jest utrata szacunku dla samego siebie i niemożność sprostania oczekiwaniom rodziców, a nie samo niepowodzenie w nauce. Dla większości studentów i studentek usiłujących popełnić samobójstwo główną przyczyną skłaniającą ich do tego kroku zdaje się być albo niepowodzenie w nawiązaniu bliskiego związku interpersonalnego, albo też rozpadnięcie się takiego związku.
Najważniejszym sygnałem ostrzegawczym występującym u studentów, którzy zdają się planować samobójstwo, są zmiany w nastroju i zachowania.  Zazwyczaj studenci ci stają się przygnębieni i zamknięci w sobie, znacznie obniża się ich samoocena oraz zaniedbują się pod względem higieny osobistej. Towarzyszy temu głęboka utrata zainteresowania studiami. Często przestają oni uczęszczać na zajęcia i przez większą część dnia pozostają w swych pokojach. Zwykle mówią oni o swym cierpieniu przynajmniej jednej osobie, często w formie zawoalowanego ostrzeżenia o samobójstwie. Wielu pozostawia listy samobójcze.
Aczkolwiek większość uczelni posiada ośrodki zdrowia psychicznego, które mają przychodzić z pomocą studentom w ich kłopotów, to jednak niewielu studentów usiłujących popełnić samobójstwo poszukuje przedtem fachowej pomocy. Ważne jest zatem, aby osoby z ich otoczenia zauważyły sygnały ostrzegawcze i postarały się uzyskać pomoc dla swych kolegów czy koleżanek” (Coleman, 1976).


|Zawód. Wykazano, że uprawiany zawód jest czynnikiem, który ma istotny wpływ na wskaźnik samobójstw. Badacze z University of Oregon analizowali przypadki samobójstw popełnionych w tym stanie przez 11 lat. Stwierdzili oni, że samobójstwa wśród lekarzy, dentystów i prawników są trzy razy częstsze niż wśród pracowników umysłowych, którzy nie wykonują wolnych zawodów.
Według danych opublikowanych przez American Psychiatric Association (Amerykańskie Towarzystwo Psychiatryczne), roczny wskaźnik samobójstw wśród lekarzy wynosi przynajmniej 33 na 100 tysięcy - dwa razy więcej niż wskaźnik dla ogółu Amerykanów.



Dla psychiatrów wskaźnik ten wynosi 70 na 100 tysięcy, czyli jest cztery razy większy! Czy potrafisz wymyśleć hipotezę, która wyjaśniłaby anormalnie wysoki wskaźnik samobójstw wśród psychiatrów? 


|Stan |cywilny. Jednym z najbardziej rzetelnych społecznych predyktorów samobójstwa, zwłaszcza w odniesieniu do mężczyzn, jest informacja, czy dany osobnik jest żonaty. W przeciwieństwie do poglądów wielu cyników, w małżeństwie jest coś takiego, co wyraźnie zmniejsza prawdopodobieństwo samobójstwa związanych nim osób, w porównaniu z ludźmi samotnymi. Co więcej, owdowienie lub rozwód znacznie zwiększają prawdopodobieństwo śmierci spowodowanej samobójstwem. Najwyraźniej mężczyni zdają się potrzebować kobiet (czy małżeństwa) bardziej niż kobiety ich potrzebują - co znów jest sprzeczne z popularnym męskim mitem. Statystyki samobójstw wykazują, że absolutny przyrost wskaźnika samobójstw jako konsekwencji owdowienia lub rozwodu jest znacznie większy dla mężczyzn niż dla kobiet w każdej grupie wieku.


|Warunki |ekonomiczne. Mowi się, że „samobójstwo jest luksusem bogaczy”.  Takie twierdzenie jest fałszywe. We wszystkich klasach społecznych niepewność ekonomiczna i niedostatek finansowy przynoszą poczucie beznadziejności i rozpaczy. Samobójstwa zdarzają się nie tylko w pałacach bogaczy, lecz także w mieszkaniach czynszowych ubogich ludzi i w „domach opieki” dla ludzi w podeszłym wieku. Wskaźnik samobójstw wzrasta w okresach depresji ekonomicznej zarówno w klasach wyższych, jak i w niższych.  Jednakże wykazano, że ludzie o najwyższym statusie reagują gwałtowniej na fluktuacje w świecie finansowym (Grollman, 1071). Dzieje się tak zapewne dlatego, że bogaci mają więcej do stracenia, biorąc pod uwagę ich wysoką pozycję w życiu.


|Rasa. Pewien satyryk, komentując znacznie niższy wskaźnik samobójstw wśród Murzynów w Stanach Zjednoczonych niż wśród białych, powiedział, że trudno jest czarnym popełnić samobójstwo wyskakując z okien ich suteren. W stwierdzeniu tym dotknął on złożonej zależności pomiędzy klasą społeczno-ekonomiczną, rasą, warunkami życia i samobójstwem. Murzyni jako rasa tradycyjnie nie popełniali samobójstw wbrew nędznym warunkom życia w gettcie. Możemy domyślać się, że było to wynikiem: odczuwania mniejszej osobistej odpowiedzialności za niepowodzenie i większego gniewu skierowanego na zewnątrz, przeciw systemowi ucisku, w którym żyją, oraz „Ludziom”, którzy kierują ich losem; norm społecznych uznających samobójstwo za tchórzostwo; uwarunkowanej akceptacji ograniczonych celów i wysokiego prawdopodobieństwa niepowodzenia. Jednakże w ostatnich latach obserwuje się szokujący wzrost wskaźnika samobójstw wśród Murzynów. Jest jeszcze zbyt wcześnie, aby było wiadomo, czy jest to zjawisko przejściowe, czy też trwałe - towarzyszące zmianie społeczno-rasowych przekonań.
Drastyczne różnice kulturowe istnieją pomiędzy postawami i normami grupowymi Amerykanów i Japończyków w stosunku do samobójstwa. Statystyka samobójstw z lat 1966-67 („Statistical Bulletin Metropolitan Life Insurance Co”., 1966; liczby oznaczają ilość samobójstw na 100 tysięcy ludności) ujawnia następujący układ zależności (rasa, narodowość, płeć):


Amerykanie: Mężczyźni - Kobiety
Biali: 103,6 - 34,3
Kolorowi: 50,8 - 15,3
Japończycy: 118,8 - 86,9


Do wysokiego wskaźnika samobójstw, jaki występuje u Japończyków, i to zarówno u mężczyzn, jak i u kobiet, przyczynia się nacisk, jaki ten naród kładzie na wstyd jako technikę oddziaływania społecznego.


Ludzie unikają postępowania, które przyniosłoby wstyd im samym, ich rodzinom lub nawet grupom, do których należą. Gdy uważają, że są odpowiedzialni za przyniesienie wstydu innym, to samobójstwo jest kulturowo akceptowanym sposobem naprawienia tego zła. W dodatku literatura, sztuki teatralne, filmy i popularna prasa nadały samobójstwu - |harakiri - wysoki status szlachetności.




Depresja a samobójstwo




Jednostki skłonne do samobójstwa często prześladuje miażdżąca kombinacja poczucia beznadziejności i bezradności: uczucie rozpaczy, że nic nie można zrobić i że nikt nie może niczego zrobić. Niewątpliwie najbardziej charakterystyczną cechą tych, którzy próbują popełnić samobójstwo jest depresja.
Tragicznym komentarzem do tego tematu samotności i izolacji człowieka jest przypadek studenta, którego znaleziono martwego w jego pokoju, gdzie leżał już od 18 dni. Nie było żadnych przyjaciół, nikogo na tyle włączonego w jego codzienne życie, aby zatroszczyć się lub chociaż zauważyć, że nie było go przez ponad 2 tygodnie (Grollman, 1971).
Każda nagła i radykalna zmiana, która pozbawia daną osobę podstawowych źródeł poczucia bezpieczeństwa i możności przewidywania, może uczynić tę osobę bardziej skłonną do samobójstwa. Nagła zmiana sytuacji społecznej czy ekonomicznej, nieoczekiwana strata ukochanej osoby lub silne poczucie niesprawiedliwości życia połączone z uczuciem niezdolności wywarcia wpływu na bieg rzeczy mogą stać się czynnikiem sprzyjającym samobójstwu. Badania nad zespołem wyuczonej bezradności, omówione już wcześniej w tym rozdziale i w Rozdziale 9, dostarczają pewnych nowych sugestii co do przyczyn depresji i, miejmy nadzieję, efektywnej strategii leczenia tych, którzy są tak pogrążeni w tym stanie, że życie nie jest dla nich nic warte.




Ci, którzy pozostają...




Wołania o pomoc nie dosłyszano. Akt samounicestwienia powiódł się. Życie dobiegło końca. Lecz dla rodziny tragedia dopiero się zaczyna. „Nie wystarczy czasu, aby zaleczyć rany wywołane samobójczą śmiercią. Ten miażdżący cios jest gorzkim przeżyciem dla wszystkich tych, którzy pozostali.




* * *



Ryc. 11.19. W około 15% przypadków samobójstw pozostawiane są listy; listy te są znacznie częstsze w przypadku prób nieskutecznych niż rzeczywistych samobójstw. Powyżej reprodukowano dwa listy rzeczywistych samobójców. Duże odstępy w liście do Estelli świadczą o głębokim poczuciu izolacji. Kończenie słów szarpnięciem pióra w górę w drugim liście grafologowie interpretują jako oznakę wielkiej wrogości. Z pewnością treść listu miała wywołać u adresata żal i poczucie winy.


* * *





Noszą je oni w swych sercach przez resztę życia. Samobójstwo jest niewątpliwie najokrutniejszą śmiercią ze wszystkich dla tych, którzy pozostają” (Grollman, 1971, s. 109).
Często ci, którzy popełniają samobójstwo, czynią to po prostu dlatego, aby wywrzeć głębokie wrażenie na pozostałych przy życiu. Samobójstwa są zatem często zaaranżowane w ten sposób, aby zadać maksymalny ból tym, którzy pozostali. Samobójstwa wyrażają głębokie rozgoryczenie. Niektóre samobójstwa mogą być dokonane tak, że wyglądają jak przypadkowa śmierć, oszczędzając w ten sposób osobom pozostałym przy życiu wielu cierpień i poczucia winy, podczas gdy w innych przypadkach żyjący muszą mówić sobie: 
„Mógłbym temu zapobiec, gdybym tylko tam był...”.
Niedawno przeprowadzone badania, którymi objęto 384 osoby usiłujące popełnić samobójstwo, wyraźnie wskazują, iż |poczucie |beznadziejności jest katalizatorem zachowań samobójczych. Z niedoszłymi samobójcami przeprowadzono dwukrotnie wywiady psychiczne w ciągu 48 godzin od chwili przyjęcia ich do szpitala. Wywiady te potwierdzają rolę beznadziejności, która prowadzi do negatywnych oczekiwań, co do powodzenia jakichkolwiek prób osiągnięcia ważnych celów osobistych. Gdy wynikająca stąd depresja rozwija się, wówczas samobójstwo zaczyna wydawać się jedynym wyjściem (Beck, Kovacs i Weissman, 1975). Terapia powinna więc koncentrować się na zredukowaniu poczucia beznadziejności przez kształtowanie od nowa przekonania o własnych możliwościach i zdolnościach, co proponuje Seligman w swym eseju zamieszczonym na końcu Rozdziału 8.




Zapobieganie
samobójstwom




Występowanie samobójstw jest dla społeczeństwa ponurym przypomnieniem, że nie potrafiło ono sprawić, aby dla wszystkich jego członków życie było coś warte. Zjawisko samobójstwa stawia nas wobec wielu złożonych zagadnień - filozoficznych, psychologicznych, społecznych i polityczno-prawnych.
Czy samobójstwo kiedykolwiek można uznać za uzasadnione? W jakich okolicznościach niektóre społeczeństwa popierają samobójstwo? Czy decyzja danej osoby o popełnieniu przez nich samobójstwa powinna być respektowana przez innych i nie powinno się podejmować interwencji? Co, jeśli w ogóle jest coś takiego, skłoniłoby |ciebie do popełnienia samobójstwa?
Jest rzeczą zaskakującą, że dopiero od niedawna zaczęliśmy podchodzić do samobójstwa poważnie - jako do ludzkiego problemu zasługującego na naukowe zainteresowanie i humanitarną troskę. Pierwszy ośrodek zapobiegania samobójstwom (Suicide Prevention Center) założył Edwin Shneidman w Los Angeles stosunkowo niedawno, bo w 1958 roku. Na szczęście ośrodki takie zaczęły mnożyć się gwałtownie i w roku 1971 istniało już 200 ośrodków zapobiegawczych i interwencyjnych.
Szpitale prowadzą nowe programy terapii dla tych, którzy usiłowali popełnić samobójstwo, a w wielu miastach są specjalne alarmowe numery telefoniczne, pod które mogą dzwonić potencjalni samobójcy. Jest jednak oczywiste, że aby programy takie były skuteczne, ludzie mający popełnić samobójstwo muszą albo podjąć inicjatywę i zgłosić się sami, albo też próba samobójstwa musi być nieudana. Wysiłki zmierzające do zapobiegania samobójstwom zawodzą oczywiście, gdy potencjalni samobójcy decydują się odebrać sobie życie bez tak zwanego wołania o pomoc.


Wydawałoby się, że próby zapobiegania powinny zaczynać się wcześniej.  Zamiast starać się uchwycić w ostatniej chwili osobę, która jest tak zdesperowana, że gotowa jest umrzeć, musimy znaleźć sposoby identyfikowania dzieci i młodych ludzi, którzy są potencjalnymi samobójcami.
Tymczasem wielu ludzi otwarcie grozi, że popełni samobójstwo, zanim rzeczywiście to uczynią. Rzadko w istocie zdarza się, aby ktoś popełnił samobójstwo nie dając uprzednio jakiej wskazówki o swoich zamiarach.  Najwłaściwszą zatem reakcją na każdą groźbę samobójstwa jest potraktowanie jej poważnie - jak gdyby czyjeś życie zależało od tego, czy |ty się o nie zatroszczysz.




* * *



Ryc. 11.11. „Krzyk” jest dziełem norweskiego malarza Edwarda Muncha. The Los Angeles Suicide Prevention Center (Ośrodek Zapobiegania Samobójstwom) posłużył się tym obrazem dla przedstawienia rozpaczy leżącej u podstaw „wołania o pomoc” jednostki oraz dla podkreślenia potrzeby reagowania na takie wołania.


* * *







Ty i twoje zdrowie
psychiczne




Oprócz niezliczonych dróg prowadzących do zrealizowania potencjalnych możliwości ludzkich, istnieją także drogi czyniące zły użytek z tych możliwości umysłu i ducha. Możemy, jeśli taki będzie nasz wybór, stać się swoimi najgorszymi wrogami, zdolnymi do zniszczenia samych siebie w sposób bardziej totalny, niż potrafiłby to uczynić jakikolwiek przeciwnik za pomocą najdoskonalszych współczesnych środków zagłady. Samobójstwo jest tylko najbardziej oczywistym sposobem, w jaki odrzucamy dar życia, nie potrafiąc docenić jego celu ani dojrzeć poza naszą doczesną nietrwałością jakiegoś głębszego sensu naszej egzystencji.
Zapoznając się z niektórymi formami, jakie może przyjmować dewiacja, patologia i szaleństwo, widzieliśmy, jak różnorodne i potężne są te siły psychologicznej destrukcji. W następnym rozdziale zapoznamy się z terapią, zawodowymi metodami leczenia zaburzeń, które tu przedstawiliśmy w zarysie.  Jednakże nie wszyscy ludzie, którzy potrzebują terapii, zabiegają o nią, a zapewne mniej spośród nich potrzebowałoby jej, gdybyśmy poświęcali więcej uwagi ochronie naszego zdrowia psychicznego niż leczeniu chorób psychicznych. Jest to z pewnością ten właśnie przypadek, w którym odrobina profilaktyki jest warta znacznie więcej niż czas, pieniądze, wysiłek, lęk i |prawdopodobny sukces związane z jakąkolwiek kuracją.
Aczkolwiek podręcznik ten jest pomyślany jako akademicki przegląd aktualnego stanu wiedzy i badań psychologicznych, a |nie jako podręcznik higieny psychicznej, to jednak jesteśmy przekonani, że poniżej podane zasady mogą być przydatne w dążeniu do zachowania zdrowia psychicznego.  Przedstawiamy je jedynie jako wskazówki mające zachęcić cię, abyś myślał racjonalnie i działał bardziej efektywnie w sprawach związanych ze zdrowiem psychicznym.
1. Szukaj przyczyn swojego zachowania w swej obecnej sytuacji, lub w jej stosunku do sytuacji przeszłych, a |nie upatruj jakiegoś defektu w sobie samym.
2. Porównuj swoje reakcje, myśli i uczucia z reakcjami, myślami i uczuciami porównywalnych osób z twego otoczenia, aby ocenić ich stosowność i adekwatność.
3. Miej kilku bliskich przyjaciół, z którymi mógłbyś dzielić swoje uczucia, radości i zmartwienia.
4. Nie obawiaj się okazywać innym, że chcesz być ich przyjacielem, a nawet obdarzyć uczuciem lub odwzajemnić uczucie.
5. Nie mów nigdy złych rzeczy o sobie samym; zwłaszcza nigdy nie przypisuj sobie nieodwracalnych, trwałych, ujemnych cech, takich jak „głupi”, „brzydki”, „nietwórczy”, „niepoprawny”, „nieudany”. Znajdź źródła niepowodzeń w tych elementach, które można zmienić.
6. Zawsze przypisują sobie całą zasługę za swoje sukcesy i osiągnięcia.
7. Sporządź inwentarz wszystkich rzeczy, które czynią cię kimś niepowtarzalnym, jedynym w swoim rodzaju, tych cech, które masz do zaofiarowania innym. Na przykład, osoba nieśmiała może ofiarować osobie gadatliwej to, że będzie dobrym słuchaczem. Poznaj źródła swojej osobistej siły.
8. Gdy odczuwasz silne reakcje fizjologiczne, które zwykle interpretujesz jako „lęk”, najpierw przeanalizuj obiektywne komponenty tej reakcji fizjologicznej (policz sobie puls, zarejestruj tyle zmian organicznych, ile możesz). Następnie zastanów się, czy istnieje jakieś inne wyjaśnienie twojej fizjologicznej reakcji niż psychologiczny „lęk” - może jesteś podniecony, podekscytowany; może w pokoju jest zbyt gorąco itd.
9. Gdy czujesz, że tracisz panowanie nad swymi emocjami (nadmierne podniecenie lub depresja) to stwórz dystans między sobą a sytuacją, w której się znajdujesz, przez a) fizyczne opuszczenie jej, b) „odgrywanie roli” - zajmij stanowisko jakiejś innej osoby w tej sytuacji czy konflikcie, c) przeniesienie się w wyobraźni w przyszłość, aby móc spojrzeć z perspektywy czasu na to, co tu i teraz wydaje się przytłaczającym problemem.
10. Nie rozpamiętuj przeszłych niepowodzeń czy zdarzeń będących źródłem poczucia winy, wstydu, porażki. Przeszłość minęła i tylko myślenie o niej utrzymuje ją żywą w pamięci.
11. Stwórz sobie długoterminowe cele w życiu - co chcesz robić za pięć, dziesięć, dwadzieścia lat od tej chwili - i myśl o różnych możliwych sposobach osiągnięcia tego.
12. Przeznacz pewien czas na odprężenie, medytację, na radowanie się swym „hobby” i czynnościami, które możesz wykonywać sam i za pomocą których możesz „nawiązywać kontakt z sobą samym”.
13. Myśl o sobie nie jak o biernym obiekcie, któremu tylko przydarzają się różne złe rzeczy, lecz jako o aktywnym podmiocie, który w każdej chwili może zmienić kierunek całego swego życia.
14. Pamiętaj, że niepowodzenie i rozczarowanie są czasami ukrytym błogosławieństwem; mówią ci, że twoje cele nie były dla ciebie odpowiednie lub chronią cię od większych rozczarowań w przyszłości.
15. Nie osądzaj swojego zachowania i zachowania innych jako „normalnego” lub „nienormalnego”, lecz raczej oceniaj je jako sytuacje i kulturowo odpowiednie lub nieodpowiednie i staraj się wykryć sposoby zmodyfikowania raczej niepożądanego |zachowania niż niepożądanych ludzi (z sobą samym włącznie).
16. Jeśli widzisz kogoś, kto twoim zdaniem postępuje dziwnie, interweniuj w sposób troskliwy i łagodny, aby ustalić, czy coś jest nie w porządku i jak mógłbyś pomóc. Często wysłuchanie czyichś kłopotów jest wystarczającą terapią (jeśli nastąpi dość wcześnie).
17. Jeśli dojdziesz do wniosku, że nie możesz pomóc sobie samemu lub jakiejś innej osobie w cierpieniu, to szukaj porady wykwalifikowanego specjalisty w twoim studenckim ośrodku zdrowia. W niektórych przypadkach problem może wydawać się natury psychologicznej, lecz w rzeczywistości jest to prawa organiczna, jak na przykład w schorzeniach tarczycy.
18. Jeśli nie jest to problem medyczny, to zasięgnij porady psychiatry lub psychologa klinicznego, poleconego ci przez leczącego cię lekarza, studencki ośrodek zdrowia lub miejscowy szpital.
19. Weź pod uwagę, że byłoby lepiej, gdyby każdy miał sposobność przedyskutować swoje problemy otwarcie ze specjalistą od spraw zdrowia psychicznego; jeśli zatem zgłosisz się do niego, to nie potrzebujesz czuć się napiętnowany.
20. Dopóki trwa życie, dopóty istnieje nadzieja na lepsze życie, a jeśli jest nadzieja, zdecydowanie i działanie, to życie będzie lepsze.



„Nie proszę o waszą litość, lecz po prostu o wasze zrozumienie - nie, nawet nie o to, nie. Po prostu o to, abyście rozpoznali mnie w sobie samych, wroga zaś - czas - w nas wszystkich”.
Tennessee Williams „Sweet Bird of Youth”, 1959




Streszczenie rozdziału




Zaburzenia psychiczne zawsze były dla ludzi zarówno fascynujące, jak i przerażające. Pomimo tej niemal powszechnej fascynacji badaniem anormalnych procesów psychicznych zaznacza się tendencja do odrzucania i piętnowania ofiar tego rodzaju zaburzeń. Historycznie rzecz biorąc, zarówno choroby fizyczne, jak i psychiczne, przypisywano niegdyś działaniu sił nadprzyrodzonych; terapia polegała więc na egzorcyzmach i podobnych procedurach mających uwolnić cierpiącego od złych duchów. W ostatnich czasach badania koncentrują się na |neurologicznych i |dynamicznych przyczynach zaburzeń psychicznych. Wcześniejsze podejścia, takie, jak psychoanaliza, opierały się na studiowaniu przypadków indywidualnych; dopiero amerykańscy zwolennicy teorii uczenia się wyrazili pojęcia freudowskie w kategoriach lepiej nadających się do kontrolowanych badań.
Zaburzenia umysłowe stanowią poważny (i kosztowny) problem społeczny. W przeciwieństwie do choroby fizycznej, w której występują wyraźne, dające się mierzyć objawy, choroba psychiczna istnieje wtedy, gdy ktoś stwierdzi, że ona występuje. Gdy do „choroby” psychicznej stosuje się model medyczny, to raz nadana etykietka „chorego psychicznie” może przylgnąć do tej osoby na zawsze. Wynika to po części z naszej obawy przed tymi, którzy wykazują jakiś rodzaj dewiacji, i z naszej potrzeby odizolowania ich jako różnych od nas. „Normalne” jest to, co czyni większość ludzi. Nowe trendy kulturowe mogą doprowadzić do większego akceptowania ludzi, którzy robią „to, czego sami chcą”.
Utratę zdolności samoregulacji można obserwować w stanach psychicznego i (lub) fizycznego uzależnienia od alkoholu, papierosów czy środków psychotropowych. Uzależnienie takie może mieć katastrofalne konsekwencje fizyczne, psychiczne i społeczne, chociaż jest najwyraźniej wyuczone i utrzymuje się ze względu na krótkotrwałe wzmocnienia.
|Alkoholizm najlepiej można zrozumieć traktując go jako postępujący proces chorobowy, który z czasem staje się coraz poważniejszy. Niełatwo jest uporać się z nim przy zastosowaniu technik psychoterapeutycznych, nawet tych, które opierają się na zasadach uczenia się, o ile dana jednostka nie |pragnie rzeczywiście, aby jej dopomożono.
Uzależnienie od |papierosów, aczkolwiek głównie psychiczne, jest niezmiernie trudne do przełamania. Stosuje się szeroki zakres technik, lecz niewiele z nich wykazuje jakąś trwałą skuteczność. Czynniki poznawcze odgrywają ważną rolę zarówno w rozpoczynaniu, jak i w rzucaniu palenia, zapobieganie zaś temu nałogowi może być skuteczniejsze niż jego leczenie.
|Nałogowe |zażywanie |środków |psychotropowych stanowi poważny problem na wszystkich społeczno-ekonomicznych poziomach społeczeństwa amerykańskiego.  Nacisk grup rówieśniczych stanowi ważny czynnik sprzyjający rozpowszechnianiu się tego nałogu. Prawie wszystkie środki psychotropowe mogą wytwarzać uzależnienie psychiczne; wiele może wytwarzać również uzależnienie fizyczne, które, jeśli przestanie się zażywać dany środek, powoduje niezwykle przykre objawy związane z jego odstawieniem. O |nadużywaniu |środków |psychotropowych mówimy wtedy, gdy ich zażywanie przynosi szkodę zdrowiu danej jednostki i (lub) zakłóca jej funkcjonowanie społeczne.
|Nerwicę charakteryzuje utrata radości życia i nadmierne poleganie na psychicznych mechanizmach obronnych. Główną |cechą |nerwicy |lękowej jest nieokreślony, nie związany z niczym lęk - dana jednostka może nie mieć pojęcia, co powoduje objawy lękowe. |Fobie polegają na rozwijaniu się u danej jednostki intensywnego strachu przed określonym obiektem lub czynnością, które zwykle mają pewne osobiste, symboliczne znaczenie.  Jednostka taka zdaje sobie sprawę, że jej strach jest irracjonalny, lecz czuje się niezdolna do walki z nim. W |nerwicy |natręctw (|obsesyjno-|kompulsywnej) dana osoba może być niezdolna do pozbycia się jakiejś natrętnej myśli lub uczucia, i (lub) może czuć się zmuszona do wykonywania specjalnych „obrzędów” w celu złagodzenia lęku.
|Nerwice |histeryczne dostarczają mechanizmów ucieczki od lęku, które przejawiają się w postaci |reakcji |konwersyjnych - fizycznego niedomagania czy kalectwa bez fizycznej przyczyny - lub |stanów |dysocjacji. Do stanów dysocjacji zalicza się |somnambulizm (chodzenie we śnie) oraz |amnezję (utrata pamięci o tożsamości), która nieraz wiąże się z |ucieczką (tzw.  fuga) do jakiegoś nowego miejsca pobytu. Najbardziej skrajną formą stanu dysocjacji jest |osobowość |wielokrotna (naprzemienne rozszczepienie osobowości), rzadko spotykany stan, w którym różne części osobowości rozdzielają się i na zmianę „sprawują władzę” nad daną jednostką, często nie wiedząc o sobie nawzajem.
W |hipochondrii nieustanne zaabsorbowanie danej jednostki domniemanymi, lecz zwykle fikcyjnymi schorzeniami dostarcza jej wymówki tłumaczącej, dlaczego nie stara się rozwiązywać swoych problemów życiowych; jednocześnie schorzenia te wzbudzają współczucie i troskę otoczenia. W |nerwicy |depresyjnej dana osoba jest pogrążona w smutku i depresji, wyolbrzymiając nieproporcjonalnie negatywne strony życia. Wszystkie nerwice są mechanizmami służącymi do |udowodnienia |własnej |bezradności, pozwalają wzbudzać współczucie i unikać wysiłków, które mogłyby doprowadzić do niepowodzenia, oraz |ograniczającymi lęk, dzięki temu, że pozwalają nie stykać się z jego źródłem.


Utrata kontaktu z rzeczywistością nosi nazwę |psychozy. |Niepoczytalność jest terminem prawnym, który może być stosowany zarówno w odniesieniu do psychoz, jak i poważnych zaburzeń nerwicowych. Psychozy mogą być |organiczne (spowodowane przyczynami fizycznymi) lub |czynnościowe (które nie są wynikiem jakiegoś znanego defektu fizycznego). W |reakcjach |paranoicznych jednostka ma urojenia: albo zmienne, jak w |stanach |paranoidalnych, lub usystematyzowane i trwałe, jak w |paranoi. Najczęstsze są |urojenia |wielkościowe, |urojenia |odniesienia (ksobne) i |urojenia |prześladowcze. |Zaburzenia |afektywne są zaburzeniami nastroju; dana jednostka może być w stanie głębokiej depresji lub manii (euforii) lub mogą u niej występować na zmianę oba te stany, niekiedy rozdzielone okresem względnej równowagi psychicznej. |Depresja (melancholia) |inwolucyjna jest to głęboka depresja psychotyczna występująca w wieku średnim. Depresja, którą przypuszczalnie wywołały czynniki zewnętrzne, nosi nazwę |reaktywnej; gdy brak wyraźnych czynników tego rodzaju, wówczas określa się ją jako |endogenną.
Reakcje |schizofreniczne polegają na rozpadzie zintegrowanego funkcjonowania, przy czym dana jednostka przestaje kierować się środowiskowym sprzężeniem zwrotnym (informacjami zwrotnymi ze środowiska).  Pacjenci schizofreniczni zajmują połowę łóżek w szpitalach psychiatrycznych. W schizofrenii mogą występować zaburzenia percepcji, emocji, myślenia, mowy oraz perspektywy czasowej. Rozróżnia się rozmaite postacie schizofrenii, takie jak |schizofrenia |dziecięca, |prosta, |paranoidalna, |katatoniczna, |hebefreniczna oraz |niesklasyfikowana.  Kategorie te nie są jednak ściśle rozgraniczone.
Wydaje się, że nie istnieje |jedna przyczyna psychozy. |Predyspozycje |genetyczne mogą odgrywać pewną rolę w poszczególnych przypadkach, podobnie jak formy interakcji w rodzinie oraz ogólniejsze czynniki kulturowe. Wyższa częstość występowania nerwic wokół osób zamożnych, a psychoz na niższych poziomach społeczno-ekonomicznych, może być odzwierciedleniem prawdziwych różnic, lecz niekiedy reprezentuje jedynie różnicę w sposobie określania tych samych stanów.
|Samobójstwo jest ostatnim czynem tych, którzy sądzą, że utracili wszelkie inne możliwości. Akty samobójcze można sklasyfikować w kategoriach |zamiaru i |wyniku: niektóre miały spowodować śmierć i rzeczywiście ją spowodowały; inne, które miały doprowadzić do śmierci, nie osiągnęły tego celu. Niektóre próby samobójcze miały być nieudane, lecz okazały się śmiertelne; inne miały być nieudane i w rzeczywistości takimi były.
Sposoby popełniania samobójstw są odmienne w różnych grupach kulturowych, lecz we wszystkich krajach udane samobójstwa są częstsze wśród mężczyzn niż wśród kobiet. W Stanach Zjednoczonych liczba samobójstw wzrasta z wiekiem, aczkolwiek stają się one coraz częstsze wśród młodzieży. Wzrastają również wskaźniki samobójstw wśród Murzynów. Samobójstwa zakończone śmiercią są najczęstsze wśród osób w starszym wieku. Najbardziej charakterystyczną cechą jednostek podejmujących próby samobójcze jest |depresja. Coraz bardziej wzrasta liczba ośrodków mających na celu zapobieganie samobójstwom i podejmowanie interwencji w przypadkach kryzysowych.
Ważne jest, aby zachować czujność w stosunku do czynników, które mogą wpływać na twoje własne zdrowie psychiczne i zdrowie bliskich ci osób, oraz zdawać sobie sprawę z tego, kiedy komuś może być potrzebna twoja pomoc.




Z Frontu Badań.
Zachowanie, kontekst
i znaczenie




|David |S. |Rosenhan Stanford University


Co rozumiemy przez „normalne” zachowanie? Kiedy staje się ono „normalnym”? Skąd wiemy, że zachowanie danej jednostki jest niewłaściwe? W niniejszym artykule rozpatrzymy niektóre ze sposobów, jakimi uczymy się nadawać znaczenie zarówno naszemu własnemu zachowaniu, jak i zachowaniu innych ludzi.
Zachowanie samo przez się rzadko ma wyraźne znaczenie. Częściej owo znaczenie jest determinowane łącznie przez zachowanie i kontekst, w którym ono występuje. Podniesienie ręki oznacza co innego w klasie czy w sali wykładowej, co innego - gdy zbliża się przyjaciel, a jeszcze co innego - w armii hitlerowskiej. To, czy podniesienie ręki oznacza prośbę o pozwolenie na zabranie głosu, czy przyjazne powitanie, czy też pozdrowienie faszystowskie - zależy od kontekstu.
Jak się przekonamy, trudno wyobrazić sobie zachowanie, które ma znaczenie samo przez się, niezależnie od swych okoliczności. Fakt ten jest przyczyną niekończących się sporów na temat znaczenia określonych zachowań ludzi. Gdy ktoś nam się nie ukłonił, to możemy zastanawiać się, czy nas nie dostrzegł, czy był zatopiony w myślach, czy też jest nieśmiały, pełen rezerwy lub rozgniewany. Zachowanie to jest wystarczająco wieloznaczne, aby każda z tych interpretacji mogła być trafna. To, które znaczenie wyda się najbardziej prawdopodobne, będzie zależało od tego, co wiemy o danej osobie: czy ma ona słaby wzrok, czy martwi się czymś bardzo, czy też ostatnio pokłóciliśmy się z nią.




Wielość kontekstów




Jak łatwo można sobie wyobrazić, istnieje ogromna liczba kontekstów, które mogą niejako „zabarwiać” zachowanie i nadawać mu znaczenie. W istocie, konteksty te wchodzą ze sobą w interakcje, nadając w rezultacie identycznym zachowaniom zupełnie odmienne znaczenie. Rozpatrzmy niektóre z takich kontekstów:


Wiek. Zachowanie odpowiednie dla dziecka uważa się za niestosowne dla dorosłego. Niedołęstwo oznacza coś zupełnie innego w wieku lat dwudziestu i siedemdziesięciu. Starsi ludzie skarżą się stale, że ich dolegliwości i bólów nie traktuje się poważnie. „Cóż, to po prostu wiek” - mówią im lekarze, jak gdyby procesy chorobowe, które powodują ból u dwudziestolatka, były zawsze odmienne od takichże procesów u osób w podeszłym wieku. Czasami |są one różne, lecz bardzo często - nie.
Interesujące rzeczy zdarzają się w „punktach granicznych”, gdy wiek danej osoby nie jest łatwy do ustalenia dla innych ludzi. Moja żona zaczęła wykładać na uczelni, gdy miała dwadzieścia trzy lata. Samo w sobie było to niełatwym zadaniem; lecz komplikował je dodatkowo fakt, że wyglądała ona jeszcze młodziej. W tych czasach niektóre windy i toalety były zarezerwowane dla wykładowców i różniły się od tych, których używali studenci. Co dzień wzbudzała ona konsternację, u innych wykładowców i personelu administracyjnego, którzy sądzili, że była ona studentką naruszjącą ich terytorium!
Wiek jest więc ważną zmienną kontekstową, która determinuje to, w jaki sposób identyczne zachowania są interpretowane przez nas samych i przez inne osoby oceniające nasze zachowanie.


Płeć i rasa. Czyż nie jest tak, że widok mężczyzny jadącego motocyklem wydaje się jakoś „bardziej stosowny” niż widok kobiety za kierownicą tego samego pojazdy? Podobnie, kobieta w fartuszku, robiąca pranie sprawia na nas wrażenie czegoś bardziej właściwego niż podobnie ubrany mężczyzna przy tym samym zajęciu. Zwróćmy uwagę, że ani mężczyźni, ani kobiety, z racji swego wrodzonego wyposażenia czy fizjologii, nie są specjalnie predysponowani ani też pozbawieni zdolności do posługiwania się czy to motocyklem, czy pralką. Niemniej jednak kontekst (w tym wypadku płeć) prowadzi do posługiwani się odmiennymi kryteriami przy ocenianiu stosowności bądź niestosowności poszczególnych zachowań. To, co dotyczy motocykli i pralek, odnosi się niestety w równym stopniu do zawodów, uposażenia i awansów. Kobiety (podobnie jak członkowie mniejszości rasowych) napotykają wyższe niż mężczyźni bariery broniące im dostępu do wielu zawodów. Zatrudnionym już kobietom i osobom należącym do mniejszości rasowych często płaci się mniej za równą pracę i awansuje się je rzadziej - pomimo równych uzdolnień i kwalifikacji. I tu także, identyczne zachowania, przyjmując w powiązaniu z odmiennymi kontekstami różne znaczenie, wywołują różne reakcje i mają odmienne konsekwencje.


Status. Status danej osoby stanowi silnie oddziałujący kontekst, w ramach którego zachowanie może być odmiennie interpretowane.
Zachowania społeczne szczególnie nadają się do odmiennego interpretowania, stosownie do statusu działających osób. Zachowania, które zazwyczaj wydają się zupełnie dziwaczne, ordynarne czy zwariowane, uważa się jedynie za ekscentryczne, gdy występują u osób bardzo bogatych. Nie oznacza to, że bogacze nie bywają uważani za ordynarnych lub zwariowanych, lecz tylko to, że oceny takie są rzadsze i dotyczą bardziej ograniczonego zbioru zachowań.


Miejsce, w którym występuje dane zachowanie, stanowi tło wpływające wyraźnie na interpretację samego zachowania. Rozbieranie się ma inne implikacje w zależności od tego, czy ktoś dokonuje go w swej sypialni, czy też w sali wykładowej. Chodzenie tam i z powrotem po pokoju, czyni na ludziach inne wrażenie w domu akademickim, a inne w szpitalu psychiatrycznym. „Normalne” zachowania, które są wykonywane w szpitalu psychiatrycznym, wydają się w istocie „anormalne” personelowi właśnie dlatego, że w tym otoczeniu oczekuje się anormalnego zachowania. Jeśli więc w szpitalu psychiatrycznym, do którego przyjęto mnie w charakterze pseudopacjenta, zadawałem pytania - interpretowano to jako „intelektualizowanie”, a ponieważ zapisywałem swoje obserwacje, przeto w mojej historii choroby odnotowano, że często występowało u mnie „zachowanie w postaci pisania” („writing behavior”).


Cechy osobiste. Cechy, które przypisujemy innym ludziom, często stanowią kontekst w świetle którego interpretujemy ich zachowanie. Nie są to dające się zaobserwować konteksty, takie, jak miejsce czy płeć. Są to konteksty psychologiczne. Fakt ten nie czyni ich wpływu słabszym, natomiast wyposaża je w specjalne właściwości, dzięki którym trudniej jest zmienić je czy zniszczyć.
Weźmy jako przykład chłopca o ilorazie inteligencji równym 70, który jąkając się podaje z wahaniem odpowiedź na pytanie nauczyciela. Odpowiedź ta prawdopodobnie będzie interpretowana w świetle informacji o jego ilorazie inteligencji, dostarczając dalszego potwierdzenia opinii, że dziecko to nie jest zbyt bystre. Identyczna odpowiedź dziecka o ilorazie inteligencji równym 130 posłuży prawdopodobnie do uzasadnienia zupełnie odmiennej opinii, że dziecko to jest „myślące” lub „nerwowe”.
Wiele z tych cech osobistych przyjmuje postać terminów czy określeń osobowościowych - są to określenia, którymi posługujemy się do opisywania innych osób, jak również nas samych, i które służą jako tło, w zestawieniu z którym możemy nadać znaczenie poszczególnym zachowaniom. Na przykład nasze przekonanie, że ktoś jest „zależny”, zabarwia, właściwie lub niewłaściwie, naszą reakcję na jego prośbę o pomoc.
Niektóre określenia osobowościowe są stosunkowo „słabe”. Zabarwiają one niewiele zachowań i w niewielkim stopniu. Inne są natomiast silnymi „centralnymi cechami”, jak nazwał się Solomon Asch. Stanowią one mocne tło, w zestawieniu z którym wszelkie rodzaje zachowania stają się pozornie zrozumiałe. Stwierdzenie, że ktoś „jasno rozumuje” lub jest „skłonny do przechwałek”, może czynić zrozumiałym kilka jego zachowań, lecz z pewnością nie wszystkie. Natomiast nazwanie kogoś „głupim” lub „schizofrenikiem” dostarcza szerokiego układu odniesienia, względem którego można interpretować bardzo wiele zachowań. Takie „etykietki” przenikają i zabarwiają wszelkie inne określenia odnoszące się do danej osoby, które mogą nadać znaczenie danemu zachowaniu.
Langer i Abelson (1974) przeprowadzili dobrze zaplanowany eksperyment, który pozwolił lepiej zrozumieć to zagadnienie. Zarejestrowali oni na taśmie magnetowidu rozmowę między dwoma osobami, z których jedna opisywała drugiej swe trudności w pracy. Następnie odgrywali oni na taśmę wobec wysoko wykwalifikowanych psychologów i psychiatrów i prosili ich o ocenę zdrowia psychicznego osoby, z którą przeprowadzono wywiad. Połowie tych specjalistów powiedziano, że oglądają wywiad z osobą starającą się o pracę, podczas gdy drugiej połowie dano do zrozumienia, że jest to wywiad psychiatryczny. Podawane przez klinicystów oceny osoby badanej wyrażano na skali rozciągającej się od jednego (bardzo zaburzony), przez punkt środkowy, do 10 (bardzo dobrze przystosowany). Słowa „starający się o pracę” oraz „pacjent” stanowiły zupełnie odmienne konteksty dla ocen podawanych przez klinicystów o orientacji psycho-dynamicznej. Klinicyści, którzy sądzili, że wywiad przeprowadzono dla celów zatrudnienia, ocenili młodego człowieka jako dość dobrze przystosowanego (przeciętne ocena = 6,2). Ci, którzy sądzili, że oglądają wywiad psychiatryczny, ocenili zachowanie uczestnika rozmowy jako zaburzone w stopniu bardziej umiarkowanym (przeciętna ocena = 3,5).




Wpływ kontekstu
na percepcję




Ludzie zwykle nie oddzielają zachowania od kontekstu, w którym ono występuje. Zazwyczaj nie uświadamiają oni sobie, że określone zachowanie w odmiennym otoczeniu mogłoby mieć inne znaczenie. Przeciwnie, przyswajają oni sobie znaczenie bezpośrednio, jak gdyby zachowanie i kontekst były jednym. Doskonałego przykładu szybkości, z jaką zachodzi ta reakcja, dostarcza poniższa figura (adaptowane z Selfridge’a, 1955).


|T |H |E |C |H |T


Co widzisz? większość ludzi bez żadnych trudności rozpoznaje ten napis jako The Cat (kot), chociaż litery |A i |H mają identyczny kształt.  Niektórzy ludzie regują tak szybko na kontekst, że są zaskoczeni, gdy zwróci się im uwagę na identyczność środkowych liter.
Względna siła wpływu kontekstu (w postaci tła) na znaczenie oraz na kierunek tego wpływu zależy oczywiście po części od wieloznaczności figury znajdującej się na tym tle. Figury, które są wystarczająco „silne” i jednoznaczne, redukują zakres znaczeń, których odbiorowi może sprzyjać kontekst.


|T |A |E |C |A |T


W drugiej figurze środkową literą każdego słowa jest wyraźnie |A.  Ponieważ |A jest dobrze uformowane, przeto czytelnicy nie znajdą w tych słowach innego znaczenia niż błąd ortograficzny, i odczytanie ich może zająć im więcej czasu.
Ten potężny wpływ kontekstu występuje dlatego, że ani percepcja, ani pamięć, nie są procesami biernymi. Są one procesami aktywnymi, konstruktywnymi, w czasie których jednostka szybko i nieświadomie przetwarza, interpretuje, konstruuje i rekonstruuje obserwowane zdarzenia.  Pozornie niewielkie zmiany, czy to figury, czy tła, przekazywane przez słowa, instrukcje, otoczenie czy nawet gest, zmieniają sposób rozumienia.  Zmiany takie wpływają na percepcję. Wpływają one również na pamięć, a także na to, co zostanie wydobyte z pamięci.


„Błędne koło” utrwalające wpływ kontekstu. Gdy jakiś określony kontekst nadał już znaczenie pewnemu zachowaniu, wówczas staje się prawdopodobne, że następne wystąpienie tego samego zachowania wywoła wspomnienie owego kontekstu w umyśle obserwatora. Dzieje się tak dlatego, że człowiek poszukuje znaczenia każdej sytuacji, znaczenia zaś nie można przypisać samemu zachowaniu.
Stwierdzenie to, które dotyczy wszelkich kontekstów, odnosi się szczególnie do kontekstów wytworzonych za pomocą określeń osobowościowych - swego rodzaju etykietek. Określenia takie są przechowywane w pamięci obserwatora; są one „poręczne”, to znaczy wygodnie jest je stosować w odniesieniu do zachowań, które są zagadkowe, wieloznaczne czy kłopotliwe, podczas gdy ich „nieobserwalność” czyni je trudnymi do podważenia, zmodyfikowania czy obalenia przez zaprzeczający im materiał dowodowy.  Ponadto określenia te nie reprezentują zwykle ścisłej, wyraźnie określonej reakcji, lecz niejasną konstelację reakcji lub wzorców zachowania.  Wystąpienie jakiejkolwiek części złożonego wzorca jest zatem często wystarczającym powodem zastosowania ogólnego określenia - nawet jeśli wszystkie inne części tego wzorca nie występują lub przestały już być wykonywane. Na przykład, jeśli długotrwały okres płaczu został wyjaśniony dzięki zastosowaniu określenia „depresja”, to drugi taki okres płaczu może skłaniać do użycia tego samego określenia, nawet jeśli tym razem jest spowodowany utratą kochanej osoby.
Ennis (1972) opisuje przypadek mężczyzny zwanego Charlie Youngblood. Z Charliem, u którego przed 25 laty rozpoznano schizofrenię paranoidalną, psychiatra przeprowadzał wywiad w celu ustalenia, czy może on odpowiadać przed sądem. Wszedłszy do gabinetu psychiatry, Charlie zaczął rejestrować na taśmie magnetofonowej przebieg wywiadu. Znając wcześniejszą diagnozę, psychiatra uznał to zachowanie za potwierdzenie paranoi Charliego. Lecz Youngblood miał wiele do stracenia: było prawdopodobne, że na podstawie tego wywiadu zostanie umieszczony w szpitalu psychiatrycznym na resztę swego życia. Uzyskanie dobrego, obiektywnego zapisu tej rozmowy było więc dla niego bardzo ważną rzeczą. Gdyby psychiatra rozumiał jego bardzo realne niepokoje, to mógłby zinterpretować to zachowanie w odmiennym kontekście.
Gdy pewne określenie jest ogólne i służy jako uniwersalny „wytrych” dla bardzo wielu zachowań, to może ono przybrać właściwości samospełniającego się proroctwa. Ponieważ tak wiele zachowań można pod nie podciągnąć, niewiele zatem zachowań może uniknąć tej interpretacji, jaką to określenie ze sobą niesie. W rezultacie wiele rozmaitych, wieloznacznych zachowań może wytworzyć w umyśle obserwatora identyczny kontekst. Możemy powiedzieć: 
„Znowu jest mu gorzej”, mimo że dane zachowanie nie ma żadnego związku z pierwotnym kontekstem, w którym zostało po raz pierwszy zaobserwowane.
Jeśli określenia osobowościowe („etykietki” czy „konteksty”) są często stosowane dla wyjaśnienia zachowań przez zewnętrznych obserwatorów, to istnieje duża szansa, że są one stosowane przez daną osobę w stosunku do siebie samej. Obserwując u siebie zachowania kojarzące się z wcześniejszymi kontekstami, osoba taka może niepokoić się, że jej aktualne zachowanie odzwierciedla coś z tej przeszłości. Na przykład ludzie, którzy przeżywali poważny kryzys psychiczny, martwią się, że choroba ta może powrócić.  Zmartwienia te znajdują pożywkę w podobieństwie zachowań obecnych do przeszłych, mimo że znaczenie tych zachowań może być zupełnie inne.  „Etykietki” skojarzone z silnymi emocjami biorą zwykle górę nad „etykietkami” skojarzonymi ze słabszymi emocjami. Dana osoba może więc nie zwracać uwagi na to, że jej aktualne zachowanie jest całkowicie odpowiednie w obecnym kontekście, lecz będzie raczej interpretować je w świetle wcześniejszego, przykrego kontekstu, który zmienia znaczenie tego zachowania i staje się znów przyczyną cierpień.


Błąd kontekstowy. Obecnie powinno już być oczywiste, że w interpretacji zachowania mogą występować błędy zależne od kontekstu, w jaki zostało ono włączone. Zachowania stosowne w jednym kontekście mogą wydawać się dziwaczne w innym.
W opisanym wcześniej przypadku pan Youngblood powiedział psychiatrze: 
„Pan chce mnie zamordować za 75 dolarów”. Psychiatra, który nie miał takiego zamiaru, uznał tę uwagę za jeszcze jeden dowód paranoi Youngblooda.  Jednakże Youngblood nadał tej uwadze swój własny, zupełnie odmienny kontekst. Obawiał się on, że zostanie umieszczony przymusowo w szpitalu psychiatrycznym, być może na całe życie. Taka utrata wolności byłą dla niego równoznaczna ze śmiercią. Siedemdziesiąt pięć dolarów było zaś standardowym honorarium za wywiad diagnostyczny. W tym kontekście jego uwagę można z powodzeniem ocenić jako sformułowaną zbyt poetycznie - lecz nie jako świadczącą o paranoi.
Rozumienie ludzi polega w dużej mierze na zrozumieniu kontekstów, w jakie włączają oni swe zachowania. Konteksty te nie zawsze są dostępne dla zewnętrznych obserwatorów. Niekiedy pozwala je ujawnić proste pytanie, kiedy indziej, konieczne może być cierpliwe i pełne wyobraźni „sondowanie”.  W każdym razie, kontekst zachowania ludzkiego rzadko jest zrozumiały sam przez się.
Często rezygnujemy z sondowania kontekstu zachowania, ponieważ zakładamy, że już rozumiemy ten kontekst. Podstawa tego zrozumienia jest jednak niekiedy krucha. Możemy sądzić, że rozumiemy zachowanie danej osoby, ponieważ ją znamy. „Nakładamy” na jej zachowanie kontekst „historyczny”, nie biorąc pod uwagę możliwości zmian ani ogromnej różnorodności motywacji ludzkich. Czasami sądzimy, że widzieliśmy „takich ludzi” przedtem, narzucając danej osobie normatywny, diagnostyczny kontekst i nie uwzględniając wcale różnic indywidualnych ani osobistych nawyków. Niekiedy po prostu nie mamy dość czasu na zrozumienie. Czasami zaś dane zachowanie drażni nas, wskutek czego jest bardzo prawdopodobne, że narzucimy mu niepożądany kontekst. Fakt, że niekiedy nasze pośpieszne oceny okazują się trafne lub nie otrzymujemy żadnego dotyczącego ich ujemnego sprzężenia zwrotnego i że wszyscy jesteśmy skłonni zapominać o naszych błędnych ocenach, zwiększa prawdopodobieństwo, że znowu będziemy popełniać te błędy.
Porównanie wina może stanowić interesujący model dla zwiększania naszej zdolności rozumienia znaczenia naszego własnego zachowania i zachowania innych ludzi. Smak wina jest odczuciem całkowicie subiektywnym, jednakże kiperzy wydają się zdolni do osiągnięcia dużej zgodności przy określaniu cech wina, jakie piją. Jak oni to robią? Po pierwsze, nie śpieszą się, po drugie, opierają swoje oceny na cechach wina - jego przejrzystości, bukiecie, barwie, kwasowości itd. - a nie na swych własnych upodobaniach i uprzedzeniach. I na koniec, kontekst i warunki, w których przeprowadza się próbowanie wina, są zawsze dobrze kontrolowane. Kiperzy rozumieją, że spostrzeżenia zmieniają się, gdy zmieniają się konteksty i warunki.  Dokładność wymaga stałości warunków oraz tak dużej „obiektywności”, jak na to pozwala zadanie o tak subiektywnym charakterze.
Zrozumienie zachowania ludzi nie jest identyczne z rozpoznawaniem win. Na przykład, sposoby zachowania ludzi wolimy poznawać w ich naturalnych środowiskach, a nie w sztucznych, podobnych na przykład do piwnic winiarni.  Nie mniej jednak wynikają z tego porównania ważne wnioski. Zrozumienie kontekstów, z których wynika znaczenie zachowania, wymaga czasu. Wymaga osobistego zainteresowania i obiektywizmu. Wymaga także chłodnego i cierpliwego obserwatora, często wysoko wykwalifikowanego, a zwłaszcza takiego, który zdaje sobie sprawę z wielu znaczeń, jakie może mieć jedno i to samo zachowanie. 




Literatura




|Ennis |B. |J. „Prisonersof psychiatry: Mental patients, psychiatrists, and the law”. New York 1972, Harcourt Brace Jovanowich.
|Langer |E. |J., |Abelson |R. |P. „A patient by any other name...  Clinician group differences in labeling bias „Journal of Consulting and Clinical Psychology” 1974, 42, 4-9.
|Selfridge |O. |G. „Pattern recognition and modern computers”.  Proceedings of the Western Joint Computer Conference, Los Angeles, Calif., 1955 in: U. Neisser „Cognitive psychology”, New York, 1967, Appleton-Century-Crofts.




Rozdział 12.
Terapia jako sposób
modyfikacji zachowania




„Nie jesteśli zdolnym Poradzić chorym na duszy? Głęboko Zakorzeniony smutek wyrwać z myśli? Wygnać zaległe w mózgu niepokoje? I antydotem zapomnienia wyprzeć Z uciśnionego łona ten tłok, który Przygniata serce?)
(Przekład Józefa Paszkowskiego. William Szekspir „Dzieła dramatyczne”. 
Warszawa 1980.)
William Szekspir „Makbet” - V; 3


Wątkiem przewijającym się przez całą tę książkę jest możliwość wykorzystania psychologii w celu dopomożenia ludziom w osiągnięciu większego panowania nad samym sobą i bardziej sensownych relacji z ich fizycznym i społecznym środowiskiem. Przechodzimy teraz do tej dziedziny psychologii stosowanej, w której najbardziej prawdopodobna jest realizacja tego celu: |psychoterapii. Aczkolwiek nie ma powszechnie zaakceptowanej definicji, tego, czym jest psychoterapia, ani nawet tego, co ma osiągnąć, to jednak w popularnym sposobie posługiwania się tym terminem przekazywania jest idea, że jest to psychologiczne leczenie jakiejś anomalii myślenia, emocji lub działania. Formy jakie może przybierać takie leczenie, są tak różnorodne, jak teorie dotyczące przyczyn anormalnego zachowania ludzi.
Ponieważ przekonaliśmy się już, że istnieje wiele postaci szaleństwa, a jeszcze więcej koncepcji wyjaśniających, dlaczego niektórzy ludzie w różnych kulturach „popadają w szaleństwo”, nic więc dziwnego, że terapia może być ukierunkowana na zmodyfikowanie duszy, umysłu, psychiki, mózgu, „serca”, charakteru, siły woli, zachowania lub innych aspektów funkcjonowania jednostki, u której funkcjonowanie to jest zaburzone. 
Lecz to, co określa się jako normalność lub anormalność, zależy od kultury i warunków, w których dana jednostka żyje. W wielu przypadkach celem terapii (jakiekolwiek by były jej specyficzne cechy czy procedury) jest zatem utrzymanie „status quo” danego społeczeństwa - przez modyfikowanie dewiacyjnego zachowania, które spotyka się z dezaprobatą społeczną. Być „wyleczonym”, to często znaczy: stać się możliwym do zaakceptowania i aprobowanym przez innych ludzi w danym społeczeństwie. Tak pojęta terapia jest narzędziem kontroli społecznej; subtelną formą indoktrynacji nakłaniającą do zaakceptowania wartości, norm moralnych, praw, zasad i systemu przekonań, instytucji i autorytetów dominujących w danym społeczeństwie, w danym okresie historycznym.
Większość psychoterapeutów odrzuciłaby pogląd, że celem terapii jest uczynienie ludzi bardziej normalnymi przez eliminowanie niepożądanych zachowań, osobliwych myśli i dewiacyjnych działań. Cel psychoterapii formułuje sie zwykle w kategoriach bardziej pozytywnych: pomóc ludziom, aby bardziej siebie akceptowali, aby stali się bardziej „wewnętrznie kierowani” i aby uzyskali pełniejsze poczucie osobistej satysfakcji i kompetencji. W tym ujęciu terapia „wyzwala” jednostki, których zachowanie jest zbyt ograniczone i spętane nakazami społeczeństwa.
Można zatem powiedzieć, że psychoterapia obejmuje usystematyzowany zbiór procedur zmierzających do zmodyfikowania zachowania, które jest zbyt dewiacyjne czy też zbyt zahamowane i ograniczone. Zachowanie takie wzbudza strach, ponieważ dla innych nie ma ono sensu, i ponieważ nie można go łatwo przewidzieć ani kierować nim za pomocą będących do dyspozycji mechanizmów społecznych. Zakłada się, że podobnie jak zakaźną chorobę fizyczną, tak samo anormalne zachowanie trzeba leczyć, bo inaczej zakazi ono również zdrowych ludzi. |Terapia tradycyjnie kojarzy się zatem z ideą „wyleczenia” lub „ozdrowienia” - z powrotem danej jednostki do stanu zdrowia.  Przywykliśmy myśleć o psychoterapii jako o czymś, co specjalnie wyszkolona osoba stosuje wobec innej osoby, która jest już w pewien sposób „chora”.
Ostatnio psychoterapię stosuje się także z innych przyczyn - dla |zachowania zdrowia. Zamiast próbować działać „wstecz” w celu zmiany złej sytuacji, nowy ruch w dziedzinie psychoterapii stawia sobie za zadanie zapobieganie zaburzeniom i wzbogacanie osobowości człowieka. Zbyt wielu z nas nadmiernie skupiło się na interesach i zapominało o |radości |życia lub nigdy nie pozwoliło sobie na nią. Według niektórych terapeutów, za sukces terapii należy uznać rozwinięcie autonomii i zwiększenie możliwości danego człowieka.
W praktyce terapia ma przeważnie charakter korekcyjny czy leczniczy, ponieważ ludzie są bardziej skłonni poświęcić czas, pieniądze i wysiłek wtedy, gdy są już „chorzy” i mają jakiś „problem” niż wtedy, gdy są „zdrowi” i chcą tylko pozostać w tym stanie lub udoskonalić swe życie psychiczne. Większość terapeutów uwzględnia zatem dwa te aspekty terapii w różnych proporcjach, od wyłącznego skoncentrowania się na jednym z nich do jakiegoś połączenia ich obu.
Inne rozróżnienie między dwoma ogólnymi typami terapii to podział metod terapeutycznych na |formalne i |nieformalne. Wszyscy chyba studenci w pewnym okresie swego życia brali udział w terapii o charakterze |nieformalnym. Szukając pomocy w rozwiązaniu swych problemów natury psychologicznej, zwracali się do rodziców, nauczycieli, duchownych przyjaciół. Taką „terapię” jednostka rozpoczyna zwykle z własnej woli, trwa ona krótko i nie stanowi głównej podstawy relacji z inną osobą. Z drugiej strony, ci „niezawodowi” terapeuci nie są specjalnie przygotowani do wypełniania tej funkcji. Zwykle służą oni radą, okazują uczucie i zrozumienie lub spełniają katarktyczną rolę „płytki rezonansowej”, przy czym nie pobierają za to opłaty. Wykazano, że poszukując pomocy z powodu swych problemów osobistych, większość ludzi nie zgłasza się do psychoterapeutów. Badania ankietowe przeprowadzone na próbce dorosłych Amerykanów przez Joint Commission on Mental Healt (Połączoną Komisję do spraw Zdrowia Psychicznego; Lowen, 1968) ujawniły, że znacznie częściej ludzie poszukują porady u przedstawicieli wolnych zawodów nie związanych z dziedziną zdrowia psychicznego; 42% badanych poszukiwało pomocy u duchownych, 29% - u lekarzy, a 11% - u prawników. Mniej niż czwarta część osób mających „problemy psychologiczne” udawała się po pomoc do kogoś określonego jako psychoterapeuta.
|Formalną terapię zdefiniujemy jako procedury stosowane przez wyszkolonych, dyplomowanych psychoterapeutów w procesie leczenia „schorzenia psychicznego” (niezależnie od tego, jaką nazwę mu się nadaje) lub też ochraniania i wzbogacania „zdrowia psychicznego”.
Kto przeprowadza formalną terapię i dlaczego? Dawniej rolę psychoterapeuty przyznawano lekarzowi, który to zwyczaj wywodzi się z dzieł Hipokratesa (żyjącego w IV stuleciu p.n.e.). W USA |psychiatrzy są w istocie lekarzami, którzy po ukończeniu pierwszych lat studiów, zgodnie z typowym programem uczelni medycznej, specjalizują się w dziedzinie „schorzeń umysłowych, emocjonalnych i neurologicznych”. Prawo zezwala im na stosowanie środków farmakologicznych i innych fizycznych metod leczenia schorzeń psychicznych. Psychiatra na pierwszych latach studiów może obrać sobie jako główny przedmiot jakąś inną dziedzinę niż psychologia, może zaliczyć na uczelni stosunkowo niewiele kursów z zakresu psychologii lub nawet może nie znać metod badań psychologicznych.
|Psychologowie |kliniczni w USA uzyskują stopień doktora filozofii na jakimś akademickim wydziale psychologii (lub psychologii doradczej, czy też psychologii wychowawczej), a prócz tego odbywają pod kierunkiem specjalistów praktykę i staż w szpitalu lub klinice psychiatrycznej. Nie mając stopnia doktora medycyny, nie mogą przepisywać żadnej formy leczenia medycznego, lecz muszą polegać głównie na |słowach jako środku interwencji terapeutycznej. Przed II wojną światową główną funkcja psychologa klinicznego było przeprowadzanie testów psychologicznych, stosowanych do diagnozy i ocen zmian w stanie psychologicznym pacjenta - psychoterapia była domeną psychiatry. Nagły wzrost częstości występowania zaburzeń psychicznych w czasie wojny i ogromne zapotrzebowanie na specjalistów doprowadziły do złagodzenia przepisów, które uprzednio uniemożliwiały psychologom klinicznym prowadzenie psychoterapii.
|Psychoanalityk należy do specjalnej kategorii terapeutów, którzy ukończyli studia podyplomowe (po uzyskaniu stopnia doktora medycyny lub doktora filozofii) w instytucie psychoanalitycznym prowadzącym (na zaawansowanym poziomie) szkolenie specjalistów stosujących freudowski sposób podejścia do interpretacji i leczenia nerwic oraz innych problemów natury psychologicznej. 
Dlaczego obiera się zawód psychoterapeuty? Najbardziej oczywistą motywacją jest pragnienie, aby pomagać innym w cierpieniu, „ratować tonących”, przekształcać cierpienie i smutek w zdrowie i radość. Lecz pomagając innym, pomaga się także sobie. Troska o dobro innych może nadawać sens własnemu życiu i wyznaczać jego cele; jest wysoce szanowana w naszym społeczeństwie i może podnosić poczucie własnej wartości. Ponadto jest możliwe, że jedną z dróg wiodących do poznania i rozwiązania własnych problemów jest poznawanie i rozwiązywanie problemów innych ludzi. Istnieją też inne, mniej szlachetne aspekty kariery psychoterapeuty: pieniądze, pozycja, niezależna praca, możliwość wpływania na życie innych, poczucie, że jest się potrzebnym, a niekiedy możność upewnienia się o własnym zdrowiu psychicznym. Lecz pomimo pieniężnych zysków i wbrew temu, że „po prostu mówienie” wygląda na łatwą pracę, pełnienie funkcji zawodowego, efektywnego psychoterapeuty należy do zawodów stawiających największe wymagania - nie powinno się wybierać tego zawodu, nie uświadomiwszy sobie związanych z nim stresów emocjonalnych i konieczności dużego osobistego zaangażowania.
Zastanówmy się jednak nad drugą stroną medalu: co powoduje, że ludzie zgłaszają się oczekując terapii - chcą uzyskać coś więcej, niż dają z siebie? Jak wskazywaliśmy już poprzednio, społeczeństwo zwykle określa okoliczności, w których pacjentowi albo |zaleca |się, albo |wymaga |się od niego, aby poddał się przepisanym procedurom mającym spowodować określone zmiany. Terapię często zaleca się wtedy, gdy zachowanie danej jednostki nie spełnia norm czy oczekiwań innych osób żyjących w danej kulturze - brak wydajności, niezdolność do odnoszenia korzyści z uczenia się, uskarżanie się na doznawany lęk lub poczucie, że jest się nieszczęśliwym, niezdolność do nawiązywania i utrzymywania właściwych stosunków z innymi ludźmi, niezdolność do czerpania przyjemności lub korzyści ze środków i zasobów danej społeczności. Często społeczeństwo wymaga poddania się terapii wtedy, gdy zachowanie danej jednostki zagraża wykonywanej przez społeczeństwo kontroli społecznej lub przyjętym w nim założeniom dotyczącym natury ludzkiej i struktury społecznej.
W poprzednim rozdziale przekonaliśmy się, że psychopatologia jest pojmowana różnie: jako choroba (fizyczna lub psychiczna) danej osoby, jako coś, co nie istnieje w poszczególnych ludziach, lecz pojawia się w ich interakcjach z otoczeniem lub po prostu jako jeszcze jeden typ wyuczonego zachowania - wywołanego i utrzymującego się dlatego, że jest ono wzmacniane. Można je także uważać wyłącznie za zbiór określeń dla zachowania nie odpowiadającego pewnemu zbiorowi norm społecznych - terminy |anormalny i |niepoczytalny byłyby wówczas przydatne jedynie dla celów społecznych i prawnych. Stosowane metody terapii odzwierciedlają oczywiście różne założenia co do natury psychopatologii, warunków powodujących ją oraz możliwych sposobów jej skorygowania. Być może jeszcze bardziej fundamentalne znaczenie dla każdego z rodzajów psychoterapii ma przyjęcie określonego założenia o charakterze natury ludzkiej.




* * *



Ryc. 12.1. Różne metody leczenia zaburzeń psychicznych są odzwierciedleniem różnych koncepcji dotyczących przyczyn irracjonalnego zachowania. Pierwsza od góry fotografia przedstawia pacjentkę przygotowywaną do elektrowstrząsu - fizycznej formy terapii opartej na modelu medycznym. Inne formy terapii koncentrują się na zrozumieniu czynników sytuacyjnych, które podtrzymują zaburzenia zachowania danej osoby. Nowe formy terapii grupowej starają się stworzyć atmosferę zapewniającą swobodę ekspresji uczuciowej oraz interakcji między ludźmi.


* * *





Czym jest „natura człowieka” („human essence”), którą trzeba leczyć, modyfikować lub rozwijać za pomocą interwencji terapeutycznej?
Podstawą każdego rodzaju terapii jest jakaś ogólna teoria czy pogląd na to, co stanowi najważniejszy składnik w „recepcie na człowieka”. Niektóre poglądy głoszą, że jedynie dziedziczność, genetyka i procesy biologiczne decydują o tym, kim jesteśmy i dlaczego niektórzy z nas nie mogą poradzić sobie z trudnościami i załamują się. Inne utrzymują, że to wpływy środowiskowe kształtują - a niekiedy zniekształcają - nasze myślenie, odczuwanie i zachowanie. Niektóre teorie natury ludzkiej kładą nacisk na doświadczenie z okresu wczesnego dzieciństwa jako na najważniejsze elementy w genezie konfliktów, urazów i obecnego irracjonalnego zachowania. Inne stwierdzają, że to działające w danej chwili siły sytuacyjne i dokonywane wybory określają, kim jesteśmy. A może to świadomość zmian, przyszłość, nieskończonego potencjału rozwoju i odnowy oraz świadomości śmierci stanowią rdzeń tego, co czyni istoty ludzkie odmiennymi od wszelkich żywych stworzeń?
W tym rozdziale rozpatrzymy różne psychoterapeutyczne sposoby podejścia, które wyłoniły się z dwóch przeciwstawnych poglądów na naturę ludzką. Przy kategoryzowaniu rodzajów terapii wyróżniamy następujące ujęcia: 
|biologiczne i |psychodynamiczne - w których kładzie się nacisk na naprawę załamanego, czy źle funkcjonującego organizmu - oraz |behawiorystyczne i |egzystencjalno-|humanistyczne - w których pokreśla się znaczenie stwarzania nowych możliwości rozwoju.


Przekonamy się, jak te sposoby ujęcia problemu wiążą się z dwoistym charakterem psychoterapii. Po rozpatrzeniu charakterystycznych cech zasadniczych sposobów podejścia terapeutycznego, omówimy następnie sposób określania sukcesu czy niepowodzenia psychoterapii; sposoby, w jakie łączy się różne ośrodki oddziaływania terapeutycznego; wpływ leczenia w zakładach zamkniętych na chorobę psychiczną. Wspomnimy także o niektórych innowacjach w terapii oraz podamy nieco praktycznych rad dotyczących wyboru terapii i terapeuty.




Biologiczne podstawy
terapii




Funkcjonowanie człowieka jest niewątpliwie w istotny sposób związane z jego wyposażeniem biologicznym. Jesteśmy mimo wszystko gatunkiem zwierzęcym, podlegającym wielu takim samym ograniczeniom, jak inne gatunki w przyrodzie. Wiele czynności, jakie wykonujemy każdego dnia i każdej nocy, jest determinowanych przez konieczność zaspokojenia pierwotnych potrzeb biologicznych - dostarczają one pokarmu i tlenu dla podtrzymania przemiany materii i reprodukcji miliardów komórek organizmu. Na środowisko molekularne mózgu człowieka oddziałuje w każdej chwili niezliczone mnóstwo impulsów nerwowych i zmian biochemicznych. Ta wewnętrzna ekologia jest utrzymywana w delikatnej równowadze, która może ulec zaburzeniu skutek niedoborów w odżywaniu, niedostatecznego lub nadmiernego wydzielania hormonów, braku pewnych niezbędnych enzymów i wielu innych „nieszczęśliwych wypadków” biologicznych.
Zgodnie z tą koncepcją, podłożem schorzeń psychicznych są zaburzenia fizyczno-biologiczne i wobec tego potrzebna jest terapia |somatyczna.  („Soma” oznacza po grecku „ciało”). W leczeniu psychiatrycznym, zwłaszcza wtedy, gdy występuje znaczna utrata kontaktu z rzeczywistością, często stosuje się różne fizyczne metody terapii. Istnieje wiele metod tego rodzaju, od stosowania specjalnych diet do podawania chemicznych środków uspokajających lub sztucznego wywoływania gwałtownych drgawek. Należy podkreślić, że taka „fizyczna psychiatria” nie zawsze ma na celu wyleczenie danej jednostki, lecz może być stosowana po to, aby zapobiec jakimś skrajnym czynom, takim jak zabójstwo lub samobójstwo, lub uczynić pacjenta podatnym na psychoterapię. Największe znaczenie spośród metod fizycznych mają terapia wstrząsowa, chemioterapia (terapia farmakologiczna) oraz psychochirurgia.




Terapia wstrząsowa




U pacjentów z poważnymi zaburzeniami, których niegdyś uznano by za przypadki beznadziejne, następuje niekiedy poprawa stanu zdrowia pod wpływem sztucznie wywoływanego wstrząsu. Ten rodzaj leczenia, znany jako |terapia |wstrząsowa, stał się po II wojnie światowej powszechnie stosowaną metodą (w większości szpitali psychiatrycznych); od czasu odkrycie nowych technik chemioterapii jest stosowany znacznie rzadziej. Aczkolwiek w terapii wstrząsowej stosuje się wiele technik, to jednak mają one jedną cechę wspólną, a mianowicie powodują stan utraty świadomości, trwający od kilku minut do kilku godzin po wywołaniu wstrząsu. Nie jest zupełnie jasne, czy czynnikiem terapeutycznym jest sama utrata świadomości czy też wartość terapii wstrząsowej wynika z działania jakiegoś innego czynnika - takiego, jak zmiany fizjologiczne w układzie nerwowym lub wywołanie gwałtownej reakcji psychicznej. Inna możliwość jest taka, że u pacjentów dotkniętych depresją wpływ wstrząsów polega na redukcji poczucia winy, przy czym wstrząs jest traktowany przez nich jako „kara”, na którą zasłużyli z powodu jakiegoś rzeczywistego czy wyimaginowanego wykroczenia.
Stosunkowo najnowszą i najczęściej stosowaną formą terapii wstrząsowej są elektrowstrząsy. Pacjenta kładzie się na łóżku i okłada dla bezpieczeństwa poduszkami lub też pielęgniarki i sanitariusze trzymają go mocno, aby nie zrobił sobie krzywdy w czasie następujących w wyniku wstrząsu drgawek.  Często podaje się również środki powodujące zmniejszenie napięcia mięśniowego, aby jeszcze bardziej zredukować ryzyko złamania kości lub zbyt silnych skurczów mięśni. Następnie przymocowuje się elektrody do głowy pacjenta i przez ułamek sekundy włącza się prąd elektryczny o napięciu od 70 do 130 woltów, 20, 30 lub więcej takich zabiegów może być przeprowadzonych w ciągu kilku tygodni lub miesięcy. Elektrowstrząsy okazały się szczególnie skuteczne w przypadkach ciężkiej depresji.
Dane dotyczące korzyści, jakie przynosi ten rodzaj terapii są jednak sprzeczna. Wielu psychiatrów sądzi, że w przyszłości ta drastyczna forma leczenia będzie stosowana coraz rzadziej; już teraz zastępuje się ją środkami farmakologicznymi i nowymi technikami psychoterapii. Istnieją dane, że elektrowstrząsy wywierają ujemny wpływ na uczenie się i przechowywanie w pamięci (Leukel, 1957; Stone i Bakhtiari, 1956), a mogą także spowodować uszkodzenie mózgu (jak podaje Maher, 1966). Z pewnością zakłócają one zintegrowane funkcjonowanie organizmu.
Decydując się na wykorzystanie terapii elektrowstrząsowej, nawet do leczenia „opornych” przypadków, oprócz konsekwencji fizjologicznych trzeba wziąć pod uwagę także pewne czynniki psychologiczne. Aczkolwiek pacjenci nie pamiętają samego wstrząsu, to jednak zdają sobie sprawę ze znacznych zmian, jakie zachodzą między okresem poprzedzającym zabieg, a okresem następującym po nim; często mogą także obserwować gwałtowne drgawki u pacjentów, którzy poprzedzali ich w kolejce osób oczekujących na zabieg. U wielu pacjentów wytwarza się silny strach przed leczeniem elektrowstrząsami, niemniej jednak poddaje się ich tym zabiegom pod przymusem. W wielkich szpitalach państwowych, które mają zbyt mały personel, terapię wstrząsową stosuje się raczej bezkrytycznie, a niekiedy w charakterze groźby czy kary.




Chemioterapia




Najbardziej widoczną zmianą, jaka zaszła w szpitalach psychiatrycznych w ciągu ostatnich dwudziestu kilku lat jest to, że pacjenci rzadko „błąkają się jak lunatycy”, obnażając się, wykrzykując sprośne słowa, grożąc, wyjąc czy demonstrując skrajne emocje. Przyczyną tej zmiany jest |chemioterapia, zastosowanie środków farmakologicznych do leczenia zaburzeń psychicznych i emocjonalnych.
Dwa sprawozdania, jakie ukazały się w latach pięćdziesiątych naszego wieku, wywołały znaczne zainteresowanie możliwością zastosowania środków chemicznych do leczenia chorób psychicznych. W jednym z nich donoszono, że gdy małpom lub ochotnikom nie będącym schizofrenikami wstrzykiwano pewien rodzaj białka (wykrytego we krwi schizofreników) wywoływało to u nich na pewien czas niektóre objawy schizofrenii. Doprowadziło to do wysunięcia sugestii, że schizofrenia może być chorobą, w czasie której organizm wytwarza substancje zaburzające funkcjonowanie komórek mózgowych i że obiecującym kierunkiem badań mogłyby być opracowania środków farmakologicznych, blokujących działanie takich substancji.
W roku 1952 dwaj badacze (Osmond i Smythies) stwierdzili, że |meskalina, środek farmakologiczny, którego działanie przypomina działanie |adrenaliny (związku chemicznego występującego w organizmie), wywołuje stan podobny do schizofrenii. Od tego czasu inni badacze wykryli kilka substancji chemicznych, które pobudzają lub hamują funkcje pewnych związków organicznych biorących udział w chemicznym przekazywaniu impulsów nerwowych w mózgu (Schildkraut i Kety, 1967).
Wprowadzenie |środków |antypsychotycznych (środków tłumiących reakcje psychotyczne) głoszono jako poważny krok naprzód w dziedzinie psychiatrii.  Niedawno zaś stwierdzono, że „istnieje niemal powszechna zgoda, iż środki antypsychotyczne są skuteczne w leczeniu zachowania schizofrenicznego, o czym świadczy fakt, że praktycznie wszystkich schizofreników leczy się środkami antypsychotycznymi” (Prien, Caffey i Kleet, 1973, s. II).
Środki stosowane w chemioterapii (określanej jako farmakoterapia) dzieli się na trzy główne kategorie według ich wpływu na psychikę i zachowanie: środki uspokajające, środki pobudzające i środki halucynogenne (W Polsce te grupy leków określa się jako a)środki psycholeptyczne (uspokajające), b) środki psychoanaleptyczne (pobudzające), c) środki psychodysleptyczne (halucynogenne) - przyp. red.). Inna użyteczna klasyfikacja to podział na |środki |antypsychotyczne, |środki |antydepresyjne i |środki |przeciwlękowe (atarktyczne). Znasz być może, fabryczne nazwy niektórych środków należących do tej ostatniej kategorii - librium (elenium), valium (relanium), miltown (meprobamat), aby wymienić choć kilka.


Środki uspokajające. Środki uspokajające (trankwilizatory) redukują w pewnym stopniu pobudzenie fizjologiczne towarzyszące lękowi, jak również napięcie lękowe i zewnętrzną aktywność fizyczną oraz podniecenie. Jeśli chodzi o eliminowanie psychotycznego zachowania, to środki uspokajające, takie, jak chloropromazyna i rezepiryna, okazały się dość skuteczne. W dokładnym przeglądzie badań nad skutecznością działania środków uspokajających stwierdzono, że środki te okazały się bardziej skuteczne niż placebo w 71 badaniach, a równie skuteczne jak placebo - w 21 badaniach (Davis, 1965).




* * *



Ryc. 12.2. Wskaźniki Nawrotu Psychozy W Zależności Od Różnych Rozkładów Czasowych Odstawiania Leku. W dwóch badaniach, które objęły ponad 500 chronicznych schizofreników w szpitalach Veterans Administration, ryzyko nawrotu psychozy było zależne od zastosowania rozkładów czasowych odstawiania leku. Po ustabilizowaniu zachowania pacjentów za pomocą długotrwałego podawania leków antypsychotycznych, zmodyfikowano rozkłady podawania leków, stosując zamiast nich - w mniejszym lub większym stopniu - placebo; posłużono się przy tym „podwójnie ślepym” schematem badawczym.  Wskaźnik nawrotu psychozy wzrastał z czasem, w zależności od stopnia odstawienia leków.


* * *





Dane te sugerują, że podawanie leków antypsychotycznych można przerywać na okres 2 lub 3 dni bez istotnych zmian klinicznych, lecz odstawienie leków na czas dłuższy powoduje nawrót psychozy.


Należy jednak podkreślić, że środki te nie „leczą” w zwykłym znaczeniu tego słowa; ich działanie polega na zmniejszeniu częstości występowania pewnych zachowań, które są niepożądane i pozornie nie dają się wyjaśnić.  Hospitalizowani pacjenci psychiatryczni otrzymują |codzienne dawki leków przez całe lata. Gdy zostaną zwolnieni ze szpitala, wówczas nadal muszą zażywać te lekarstwa bez końca lub też ryzykują nawrót objawów psychotycznych (ryc. 12.2). Wskaźnik nawrotu psychozy (zaburzenia zachowania wymagające leczenia) u chronicznych schizofreników, którym odstawiono środki uspokajające, wynosi od 40% do 60%. Jednocześnie wykazano, że u pacjentów otrzymujących wysokie dawki środków antypsychotycznych wystąpienie nawrotu psychozy po zastąpieniu leku przez placebo było bardziej prawdopodobne niż u pacjentów otrzymujących mniejsze dawki leku (Prien, Levine i Switalski, 1971). Nie jest jasne, czy zjawisko to wynika z faktu, że pacjenci wymagający większej dawki leków mieli początkowo poważniejsze zaburzenia, czy też jest to pośredni efekt wytworzenia się zależności od dużej dawki leków. Jeśli nawet psychotyczni pacjenci leczący się ambulatoryjnie regularnie zażywają leki po zwolnieniu ze szpitala, to większość z nich rzadko osiąga coś więcej niż ledwie dostateczne przystosowanie do społeczeństwa (Rickles, 1968).
Chociaż środki uspokajające nie stanowią panaceum na chroniczne zaburzenia psychotyczne, to jednak istotnie pomagają one bardzo wielu ludziom, z różnymi zaburzeniami psychicznymi, funkcjonować bez doświadczanych przez nich dawniej załamań. Na przykłąd Joshua Logan, odnoszący wiele sukcesów jako reżyser takich filmów, jak „Południowy Pacyfik”, „Piknik”, „Mister Roberts”, cierpiał przez wiele lat z powodu nie dających się opanować nawrotów manii na zmianę z poważną depresją. Podobnie jak wiele innych osób cierpiących na psychozę maniakalno-depresyjną, zażywa on codziennie dawki |węglanu |litu („lithium carbonate”), który - według jego słów - „daje mu znów nadzieję na przyszłe życie i pracę” („Newsweek”, 9 lipca 1973). To starożytne lekarstwo było już podobno przepisywane przez żyjącego w V wieku lekarza Aurelianusa, który dawał zasadową wodę mineralną pacjentom cierpiącym na depresyjne lub maniakalne zaburzenia psychiczne.  Zaletą tego lekarstwa jest to, że nie stępia ono zmysłów w takim stopniu jak inne środki uspokajające, a zatem nie przeszkadza tak bardzo w pracy twórczej. 
Jeśli uznać dane dotyczące sprzedaży librium i valium za wiarygodny wskaźnik, to trzeba stwierdzić, że proces „uspokajania” (tranquilization) naszego społeczeństwa, poza szpitalami psychiatrycznymi, przebiega w szybkim tempie. Podaje się, że ponad 20 milionów Amerykanów stosuje te dwa środki uspokajające, aby „ukoić swe wzburzone, napięte nerwy”. Całkowity dochód brutto towarzystwa farmaceutycznego, które sprzedaje (co prawda, na całym świecie) te dwa środki uspokajające, przekracza 1,5 miliarda dolarów rocznie (Moskowitz, 1973). Firmy produkujące środki farmakologiczne wywierają duży nacisk na specjalistów z zakresu zdrowia psychicznego, aby nadal intensywnie stosowali ich produkty.




Zbliżenie


Gwarantowane wyleczenie każdej choroby: lekarstwa wysyłane za zaliczeniem 
pocztowym


„Czy „masz ogólne złe samopoczucie lub cierpisz na tysiąc i jeden nie dających się opisać dolegliwości, zarówno psychicznych, jak i fizycznych?


Niezależnie od tego, jaka może być ich przyczyna, ani też jak poważne są twoje kłopoty, |Nerwowe |i |Mózgowe |Pigułki |Dr |Hammonda |wyleczą |cię”.  Jest rzeczą pouczającą powrócić do okresu sprzed wydania ustawy z 1906 roku o „czystej żywności i stosowaniu leków” („Pure Food and Drug Administration Act”), aby przekonać się, w co kazano wierzyć publiczności, jeśli chodzi o przyczyny i sposoby leczenia problemów psychicznych i zaburzeń zachowania.  W katalogu Searsa i Roebucka z 1902 roku oferowano bezpieczne i godne zaufania „lekarstwo przeciw nałogowi zażywania opium i morfiny” w cenie zaledwie 67 centów za butelkę. Za grosze można było także pozbyć się nałogu alkoholowego, ponieważ „pijaństwo jest chorobą i trzeba ją zwalczać i przeciwdziałać jej odpowiednimi metodami medycznymi, takimi samymi, jak w przypadku każdej innej choroby”.
Reklamy takie ilustrują powszechnie przyjmowane w tym czasie założenia dotyczące podłoża zaburzeń psychicznych. Więzią między akceptowanymi schorzeniami fizycznymi i nieakceptowanymi schorzeniami fizycznymi i nieakceptowanymi schorzeniami psychicznymi było pojęcie „nerwów” - zmęczone nerwy, przepracowane nerwy, słabe nerwy - oraz nieczystej lub słabej krwi.  Za zaledwie 69 centów można było kupić „Vin Vitae”, „przyjemny medyczny środek tonizujący - wzmacniający nerwy, oczyszczający i ulepszający krew, pobudzający mózg, ciało i mięśnie regulujący pracę ustroju”. Fragmenty dwóch podobnych ogłoszeń reprodukujemy na rycinie 12.3 i 12.4 (zwróć uwagę na widoczną w nich troskę o ochronę publiczności przed niebezpieczeństwem w postaci oszukańczych ofert innych producentów).


Elektryczność, niedawno wówczas odkryta, cudowna tajemnica, również była sprzedawana jako lekarstwo na „słaby lub rozstrojony system nerwowy”.


Środki pobudzające. Pacjentom cierpiącym na depresję często pomagają |środki |pobudzające („energizers”), takie jak imipramina (melipramin).


„W przeglądzie badań, które objęły w sumie 5864 pacjentów, stwierdzono, 
że ogólnie biorąc imipramina i dwa inne szeroko stosowane środki 
antydepresyjne amitryptylina (saroten) i izokarboksazyd (izoniazid) pomogły 
prawie 65% pacjentów, którym je podawano. Trzy inne powszechnie stosowane 
środki pobudzajace (fenelzyna, malamid i iproniazyd) pomogły w 40% - 49% 
przypadków, w których je stosowano. Placebo podawane w grupach kontrolnych 
było skuteczne tylko w 23% przypadków, w których go użyto” 
(Wechsler, Grosser i Greenblatt, 1965).


Interesującym dodatkowym wynikiem, jaki uzyskano w tym przeglądzie, było stwierdzenie, że w badaniach, w których stosowano grupy kontrolne otrzymujące placebo, uzyskiwano mniejszą efektywność leków niż w badaniach, w których nie stosowano żadnej grupy kontrolnej lub porównywano skuteczność dwóch środków. Badacze przypisali tę różnicę, przynajmniej w części, faktowi, że w badaniach, w których stosowano grupy kontrolne otrzymujące placebo, na ocenę stanu pacjentów przez personel wpływała świadomość, że połowa pacjentów nie otrzymuje żadnego leku, a zatem nie powinna wykazać żadnych zmian w zachowaniu. Natomiast w pozostałych badaniach lekarze oceniający poprawę stanu zdrowia pacjentów wiedzieli, że wszyscy pacjenci otrzymują jakiś lek, a zatem można oczekiwać zmiany - dobry przykład tego, jak metoda badania wpływa na uzyskiwane wyniki.
Chociaż stwierdzono, że imipramina jest najbardziej skutecznym klinicznie środkiem antydepresyjnym (Klerman i Cole, 1965), to jednak nowsze badania dowodzą o podobnej skuteczności grupy związków znanych jako |inhibitory |monoaminooksydazy (MAO). W kilku badaniach stwierdzono istotną korelację między poprawą kliniczną u pacjentów z depresją a stopniem zahamowania procesu ustalenia monoaminy wywołanym w czasie podawania leku (Feldstein, Hoagland, Oktem i Freeman, 1965).


Środki halucynogenne. Meskalina i dwuetyloamid kwasu lyzergowego (LSD), które omawialiśmy w Rozdziale 7 jako środki halucynogenne, mogą wywoływać objawy zaburzenia psychicznego, lecz są także stosowane w terapii. Jeden z zasadniczych efektów działania tych leków polega na tym, że pod ich wpływem u pacjentów często występuje regresja do zachowań i uczuć z okresu dzieciństwa i potrafią przypomnieć sobie minione zdarzenia, które mogły przyczynić się do spowodowania ich zaburzeń emocjonalnych.
LSD jest niekiedy użyteczne w terapii grupowej, w której, jeśli warunki są odpowiednie, zdaje się wzmagać empatię i osłabiać nastawienie obronne, pomagając pacjentowi komunikować się swobodnie i ujawniać głębsze poziomy uczuć (Eisner, 1964).
Niektórzy terapeuci, którzy uważają zaburzenia psychiczne za chorobę, zalecają stosowanie małych dawek LSD w połączeniu z tradycyjną psychoterapią (Crocket i in., 1963). Inni terapeuci, którzy uważają terapię przede wszystkim za środek prowadzący do rozwoju, posługują się LSD przede wszystkim w celu wywołania gwałtownej zmiany osobowości; wywołują oni intensywne doznanie psychodeliczne za pomocą pojedynczych, dużych dawek. Terapia za pomocą LSD budzi pewne nadzieje w odniesieniu do szerokiego zakresu zaburzeń psychicznych, zwłaszcza w przypadkach odpornych na bardziej konwencjonalne metody terapii.
W badaniach przeprowadzonych w Maryland Psychiatric Research Center (Ośrodku Badań Psychiatrycznych w Maryland) zastosowano LSD w sposób niekonwencjonalny, lecz wysoce obiecujący. Pacjenci nieuleczalnie chorzy na raka w ostatnich stadiach choroby cierpią niezwykle silny ból fizyczny i znajdują się pod działaniem poważnego stresu psychicznego. LSD stosuje się w celu wywołania doznań psychicznych, które, w połączeniu z osobistym kontaktem z terapeutą, pomagają złagodzić ból, poprawiają samopoczucie pacjentów oraz zwiększają ich zainteresowanie otoczeniem (Richards, Grof, Goodman i Kurland, 1972).
Ocena skuteczności terapii za pomocą LSD jest trudnym zadaniem, ponieważ ocena działania środków halucynogennych jest niezwykle podatna na błąd eksperymentalny (jak podkreśliliśmy w Rozdziale 7). Wpływ tych środków na jednostkę jest w bardzo dużej mierze uzależniony od tego, czego dana osoba oczekuje (nastawienie), od środowiska społecznego i fizycznego w jakim się znajduje w trakcie tych doznań (warunki sytuacyjne) oraz mnóstwa innych czynników specyficznych dla danej jednostki, takich jak tolerancja na stres, zdolność do chwilowego odrzucenia ograniczeń stawianych przez rzeczywistość, stopień przystosowania itd. Czynniki takie są niewątpliwie w pewnym stopniu odpowiedzialne za mnóstwo sprzecznych wyników badań. Na podstawie więcej niż 300 badań dotyczących terapii za pomocą LSD wyciągnięto wniosek, że gdy czynniki nastawienia i warunków sytuacyjnych są optymalne, to „LSD może wywołać u niektórych ludzi daleko sięgające, korzystne skutki” (Mogar, s. 393).


Próba oceny chemioterapii. Zastosowanie środków uspokajających i pobudzających z pewnością odegrało ważną rolę w zmniejszeniu długotrwałości hospitalizacji pacjentów psychiatrycznych. Środki te zmniejszyły częstość występowania skrajnych form nieadaptacyjnych, dziwacznych zachowań, jakie uprzednio wiązały się z zaburzeniami psychotycznymi. Również dzięki nim niektóre kategorie pacjentów, poprzednio „niedostępnych”, można obecnie poddawać psychoterapii.
Jednakże krytyczna analiza chemioterapii musi również uwzględniać następujące czynniki. Nie ma żadnych danych świadczących o „trwałym wyleczeniu) za pomocą środków farmakologicznych; w istocie, jak przekonaliśmy się w poprzednim rozdziale, wyższy wskaźnik zwolnień ze szpitali psychiatrycznych jest obecnie kompensowany jeszcze wyższym wskaźnikiem ponownych przyjęć formalnie „wyleczonych” pacjentów. Nawet u tych pacjentów, u których zanotowano najwyraźniejszą poprawę w wyniku chemioterapii, nie można oddzielić bezpośredniego biochemicznego wpływu środków farmakologicznych od innych czynników związanych z tego rodzaju leczeniem. Czyniąc pacjentów bardziej podatnymi na oddziaływanie, chemioterapia może sprawiać, że personel psychiatryczny, będzie się czuł mniej zagrożony przez pacjentów, a zatem będzie traktował ich bardziej humanitarnie.
Przy każdej ocenie skuteczności działania środków farmakologicznych trzeba także uwzględniać znany fakt pozytywnego oddziaływania placebo.  |Sugestia, że dany preparat złagodzi ból i spowoduje poprawę samopoczucia, często działa równie skutecznie, jak skład chemiczny danego lekarstwa.
Interesujące jest stwierdzenie, że sposób podania może być ważnym czynnikiem determinującym reakcje na placebo. Pewien lekarz stwierdził, że to samo placebo podane w jaskrawoczerwonej kapsułce żelatynowej przyniosło pomyślne wyniki w 81% badanych przypadków, w porównaniu z tylko 49%, gdy podano je jako tabletkę i 69%, gdy pacjenci przyjmowali je w formie płynu (Clauser i Klein, 1957). Stwierdzono, że podskórne wstrzyknięcie substancji placebo jest zwykle bardziej skuteczne niż podanie tabletki, lecz mniej skuteczne od kapsułek. Stwierdzono, że w preparatach stosowanych zewnętrznie lepsze rezultaty przynoszą roztwory w kolorze niebieskim lub zielonym, podczas gdy płyny przyjmowane doustnie okazały się bardziej skuteczne, jeśli miały ciepłe barwy - czerwoną, żółtą lub brązową - i jeśli miały gorzki smak (Leslie, 1954).
Badanie, które wskazuje jeszcze bardziej bezpośrednio na potrzebę oddzielenia wpływu leku od efektu placebo przy analizowaniu oddziaływania środków farmakologicznych na zaburzenia umysłowe, przeprowadzono na studentach farmacji, których poproszono o pomoc w „sprawdzaniu” dwóch nowych leków.


„Wszyscy studenci w liczbie 45 przyjęli kapsułkę o godzinie #8#/30; powiedziano im, że jej maksymalne działanie powinni odczuć mniej więcej po dwóch godzinach, przestanie zaś działać pod koniec eksperymentu, o godzinie #12#/30. 15 studentów poinformowano, że ich kapsułka zawiera środek pobudzający, następnych 15, że zawiera środek uspokajający. Pozostałym 15 powiedziano, że kapsułka zawiera jedynie krochmal (który w rzeczywistości był jedynym składnikiem wszystkich kapsułek).
Ogółem 60% badanych w grupach eksperymentalnych podało, że odczuwało działanie, które mieli odczuć. Wpływ ten był wyraźniejszy wśród badanych, którzy zażyli „środek pobudzający”, gdyż 73,3% osób w tej grupie podało, że odczuwają zasugerowane im działanie, w porównaniu z 46,7% w grupie, której podano „środek uspokajający”; być może wynikło to stąd, że badani przez cały czas musieli kontynuować swą zwykłą pracę w laboratorium.
Placebo wpłynęło na tętno. Szybkość tętna u osób z grupy, która otrzymała „środek pobudzający”, wzrosła przy drugim pomiarze, przeprowadzonym w czasie rzekomego najsilniejszego działania leku, i spadła znowu pod koniec eksperymentu. U osób z grupy, która otrzymała „środek uspokajający” szybkość tętna spadła, a następnie wzrosła znowu przy końcu badania. U osób z grupy kontrolnej szybkość tętna wzrosła nieco w czasie badania, być może ze względu na nacisk, aby ukończyli na czas swe prace laboratoryjne” (Brodeur, 1965).


Wśród niebezpieczeństw, z jakimi wiąże się długoterminowa chemioterapia, wyróżnić można następujące: a) nadmierne poleganie ze strony personelu na terapii farmakologicznej, ze szkodą dla terapii psychospołecznej opartej na „kontakcie ludzkim”, b) różne uboczne efekty fizyczne, w tym pewne upośledzenie wzroku, i wreszcie c) najpoważniejsze ze wszystkich, a mianowicie wytworzenie się zależności psychicznej od leków, wskutek czego zażywający je zaczynają przypisywać wszelką poprawę swego stanu psychicznego czy zmianę w zachowaniu lekom, a nie swojej własnej, zwiększonej zdolności panowania nad swymi reakcjami (Davison, Valins, 1969).
Istnieją wreszcie pewne nowe dane eksperymentalne wykazujące, że u schizofreników, którzy uprzednio byli dość dobrze przystosowani, w rzeczywistości występuje pogorszenie stanu zdrowia pod wpływem środków uspokajających. Źle przystosowanym pacjentom lek ten pomagał (w przeciwieństwie do placebo), natomiast uprzednio dobrze przystosowana grupa 15 pacjentów, którym zaczęto podawać tiorydazynę, stała się bardziej wroga i wojownicza i wymagała jeszcze dłuższej hospitalizacji niż dobrze przystosowani pacjenci z grupy kontrolnej, którzy otrzymywali placebo.  Autorzy tego badania wysunęli przypuszczenie, że leki te mogły uniemożliwić pacjentom poleganie na sobie i zakłócić przebiegający w naturalny sposób proces powrotu do zdrowia (Evans, Rodnick, Goldstein i Judd, 1972).




Psychochirurgia




Do najbardziej dramatycznych i najszerzej rozreklamowanych innowacji z zakresu psychiatrii, które jednak przyniosły największe rozczarowanie, należą techniki chirurgii mózgu stosowane w leczeniu poważnych zaburzeń emocjonalnych (Moniz, 1937; Freeman i Watts, 1942). Najlepiej znaną formą psychochirurgii jest |leukotomia (|lobotomioa) |przedczołowa („prefrontal lobotomy”; potocznie - lobotomia czołowa), operacja, w czasie której przecina się włókna nerwowe łączące przedczołowe płaty mózgu z niższymi ośrodkami mózgowymi, zwłaszcza z podwzgórzem.
Badania na zwierzętach wykazały, że za pomocą takiej operacji można wyeliminować oznaki lęku spowodowanego konfliktem. Doświadczenie kliniczne wykazuje, że lobotomia istotnie często redukuje emocje towarzyszące myślom i wspomnieniom danej jednostki. Chociaż więc nie uważa się, że psychochirurgia usuwa przyczyny zaburzeń pacjenta, to jednak może ona eliminować udręki emocjonalne spowodowane męczącymi myślami czy halucynacjami.
Te korzyści trzeba jednak zestawić z następującą listą efektów ubocznych, sporządzoną przez Freemana i Wattsa (zespół lekarzy, który wprowadzili ten rodzaj operacji do Stanów Zjednoczonych w 1936 r.): a) utrata zainteresowania swym organizmem oraz stosunkiem swego „ja” do otoczenia, b) niezdolność przewidywania następstw planowanej sekwencji czynności mających pewne osobiste znaczenie, c) obojętność na opinię publiczną, d) wzrost częstości występowania pewnych form impulsywnego zachowania, ponieważ wyrzuty sumienia, poczucie winy i strach zostają wyeliminowane, e) zmniejszona zdolność ukształtowania jednolitego obrazu samego siebie i przewidywania własnej przyszłości. Ogólnie biorąc, pacjentów po przeprowadzonej lobotomii można określić jako pozbawionych „ciągłości ja”; to jest tracą oni poczucie, że są tą samą osobą, którą byli wczoraj i którą będą jutro (Robinson, Freeman, 1955).
Komu potrzebna jest terapia niosąca takie skutki uboczne? Niestety, negatywny materiał dowodowy tego rodzaju, często nie potrafi zachwiać przekonaniami teoretyków, prawdziwych „wyznawców” oraz badaczy eksperymentujących z nową techniką. Wbrew powyższej liście szkodliwych skutków, pionierzy tej metody byli przekonani, że kontynuowanie prac doprowadzi do odkrycia „krytycznej strefy, ważnych włókien, właściwych okolic, które trzeba poddać resekcji, szlaków, które trzeba przeciąć, i niebezpieczeństw, które trzeba wyeliminować” (Freeman i Watts, 1942, s.  18).
Ponieważ operacja psychochirurgiczna raz dokonana nie może być cofnięta i ponieważ jej wyniki są niepewne, uznano ją zatem za metodę, do której należy się uciekać jedynie w ostateczności i stosuje się ją obecnie rzadziej niż w przeszłości (Ponieważ lobotomia nie zawsze bywa skuteczna, a prawie zawsze powoduje niekorzystne, nieodwracalne zmiany w psychice i zachowaniu się pacjenta, przeto w wielu krajach, między innymi w Polsce, nie jest ona stosowana (przyp. red. nauk.)). Brak jest obecnie jakiejś kontroli, czy to prawnej czy zawodowej, nad takimi operacjami, aczkolwiek Kongres Stanów Zjednoczonych podjął akcję zmierzającą do uchwalenia ograniczeń. Burtram Brown, dyrektor National Institute of Mental Health (Narodowego Instytutu Zdrowia Psychicznego), nawoływał ostatnio do systematycznego badania skutków około 500 operacji psychochirurgicznych, które nadal są przeprowadzane corocznie w Stanach Zjednoczonych, zanim zaleci się nowe procedury kontroli przeprowadzania tych operacji (opis według Trottera, 1973).




Terapia fizyczna
a model medyczny




Każda fizyczna terapia zaburzeń psychicznych zakłada, że interwencja fizyczna może zmienić przebieg procesów psychicznych, czy to przez skorygowanie podstawowych anomalii chemicznych, czy też przez uspokojenie pacjenta lub pobudzenie go tak, aby osiągnął optymalny poziom wzbudzenia. W pewnej mierze implikuje to medyczny model zaburzenia psychicznego (tabela).  Jednym z problemów, jakie wiążą się ze stosowaniem modelu medycznego przy określaniu i leczeniu zaburzeń zachowania, jest to, że „objawy” takiej „choroby” są raczej natury behawioralnej niż fizycznej; tak więc zmiany również muszą być określone w kategoriach behawioralnych.




* * *



Pozytywne I Negatywne Aspekty Modelu Medycznego 


Aspekty pozytywne:
Rozwój fizjologicznych form terapii
Bardziej humanitarne traktowanie pacjentów
Pieniądze, środki, wpływ na ustawodastwo oraz szacunek społeczeństwa - 
wynikające z zaangażowania się świata lekarskiego
Interdyscyplinarne badania medyczne


Aspekty negatywne:
Piętno związane z etykietką „choroba”
Dewiacje jako „choroba”
Pojęcie „nieuleczalności”
Leczenie kosztowne, o ograniczonej dostępności
Mniejsze zaangażowanie społeczności
Psychiatria dyscypliną medyczną, niebehawioralną
Długotrwała hospitalizacja, izolacja od społeczeństwa
Ustalone interesy zawodowe i hierarchie statusu
Nacisk na leczenie patologii indywidualnej, nieuwzględnianie patologii 
społecznej


* * *





Lecz opisy zachowania są narażone na błędy wynikające z tendencyjności obserwatora. Wielu psychologów jest przekonanych, że terminy zaczerpnięte z modelu choroby (|choroba, |leczenie, |nawrót |choroby, a nawet |pacjent) nie są w istocie dogodnymi terminami dla opisania czy zrozumienia tego, co ich zdaniem jest przede wszystkim procesem behawioralno-psychicznym. Jak już wspominaliśmy, niektórzy badacze całkowicie odrzucają „mit choroby psychicznej” (Szasz, 1961, 1965) jako przynoszący więcej szkód niż korzyści.
Tymczasem inni badacze kontynuują poszukiwanie bardziej obiektywnych, fizycznych wskaźników, zarówno psychopatologii, jak i „wyleczenia”, w powtarzających się układach fal mózgowych lub w składzie chemicznym krwi.  Na przykład Rappaport i Silverman (1970) donieśli, że u pacjentów schizofrenicznych, którzy mają szansę odnieść korzyść z pewnych typów terapii, można zidentyfikować specyficzne wzorce fal mózgowych.
Środki farmakologiczne mogą oczywiście zmieniać zachowanie i modyfikować procesy psychiczne, zarówno bezpośrednio (zmieniając poziom wzburzenia i ułatwiając lub hamując przewodzenie nerwowe). Mogą one zredukować lęk i sprawić, że dana jednostka będzie mniej przeszkadzać innym. W takiej mierze, w jakiej normalne funkcjonowanie jednostki zależy od posiadania nie uszkodzonego mózgu i sprawnego działania układu nerwowego, środki fizyczne przywracające lub podtrzymujące jego prawidłowe działanie będą zapewniać warunki umożliwiające właściwe przystosowanie.


Lecz w takiej mierze, w jakiej efektywne zachowanie zależy od uczenia się w środowisku społecznym, można oczekiwać, że społeczna interakcja i ponowne uczenie się będą musiały być częścią terapii, aby umożliwić danej jednostce przyswojenie sobie nowego repertuaru zachowań. W takim zaś stopniu, w jakim efektywne przystosowanie zależy od uświadomienia sobie, że człowiek kieruje sobą i własnym losem, terapia musi wzmóc tę świadomość; zależność od pigułek czy innych zewnętrznych środków fizycznych prawdopodobnie będzie wpływać w przeciwnym kierunku.
Biologiczne podejście do chorób psychicznych nie przyniosło nawet w przybliżeniu takich sukcesów, jak w przypadku innych chorób. Jest to po części spowodowane drugorzędną pozycją, jaką w obrębie medycyny zajmują badania nad chorobami psychicznymi i związany z tym brak odpowiednich środków finansowych. Prawdopodobnie wynika to także ze złożonej interakcji zmiennych, jakie wchodzą w grę w przypadku psychopatologicznego zachowania - z których to zmiennych tylko jedna jest zmienną biochemiczną. Koncepcja, że choroba psychiczna jest jakąś jednostką, formą emocjonalnego, neurologicznego schorzenia, nie uwzględnia tej subtelnej interakcji procesów poznawczych, społecznych i doznaniowych („experiential”), które stanowią jej podłoże.




Psychodynamiczne
podstawy terapii




Psychodynamiczna koncepcja psychopatologii, podobnie jak koncepcja biologiczna, umiejscawia jądro zaburzenia wewnątrz danej osoby, lecz w odróżnieniu od tamtej kładzie nacisk na zachodzące w danej chwili, intensywne procesy psychiczne, a nie na fizyczne niedobory, nadmiary czy brak równowagi. Jak przekonaliśmy się przy omawianiu teorii freudowskiej w poprzednich rozdziałach, nerwicę uważa się za niezdolność do właściwego rozwiązania konfliktów wewnętrznych między nieświadomymi, irracjonalnymi impulsami |id a zinternalizowanymi ograniczeniami społecznymi nakładanymi przez |superego. Zgodnie z tą koncepcją, biologia determinuje stadia seksualne, przez które jednostka przechodzi od niemowlęctwa do wieku dojrzałego, lecz specyficzne doświadczenia psychologiczne w każdym stadium, od oralnego przez analne do fallicznego, decydują o ty, czy nastąpi fiksacja na jakimś niedojrzałym stadium, nie pozwalająca przejść do bardziej dojrzałego, zdrowego poziomu rozwoju.
W tej walce między impulsami dziecka i rozsądkiem, rozsądek zwykle wygrywa bitwę, lecz w przypadku nerwicy przegrywa wojnę. Biologiczny impuls zostaje wyparty na korzyść sił społecznego „dobrze” i rodzicielskiego „można”, niemniej jednak pozostaje ukryty „za kulisami”, aby sprawiać kłopoty przy każdej okazji. Impulsy id, które są silne, niezwerbalizowane i amorficzne, nieustannie dążą do przejawienia się w zamaskowanej postaci, podczas gdy brak racjonalnej, intelektualnej świadomości konfliktu nie pozwala na przypomnienie go sobie i przeanalizowanie. Osoba neurotyczna może odczuwać i działać pod wpływem motywów, których nie jest świadoma, a zatem zachowanie takie - na mocy samej definicji - musi być irracjonalne.
Celem psychoanalizy freudowskiej jest ustanowienie intrapsychicznej harmonii, która pozwala lepiej uświadomić sobie siły id, zredukować nadmierną zależność od wymagań superego i zwiększyć rolę ego. Freud zdawał się zapatrywać dość pesymistycznie na możliwość osiągnięcia kiedykolwiek takiej idealnej harmonii. Po wyjaśnieniu niektórych głównych elementów terapii freudowskiej porównamy ją z terapią, która rozwinęła się z psychodynamicznych teorii wczesnych współpracowników Freuda - Carla Junga i Alfreda Adlera.




Psychoanaliza freudowska




Terapia psychoanalityczna, taka jaką stworzył Zygmunt Freud, jest techniką intensywnego i długotrwałego badania nieświadomej motywacji pacjenta, przy czym szczególną wagę przypisuje się konfliktowi i wyparciu, których źródłem są urazy z wczesnych stadiów rozwoju psychoseksualnego. Jej celem jest wprowadzenie do świadomości takich wypartych wspomnień i konfliktów oraz dopomożenie jednostce w ich rozwiązaniu (w taki sposób, w jaki może to uczynić dorosły człowiek). Przyjmuje się, że taki proces wywołuje radykalną zmianę w podstawowej strukturze osobowości danej jednostki. Psychoanalitycy stosują różne techniki pozwalające wprowadzić wyparte konflikty do świadomości i dopomóc pacjentowi w rozwiązaniu ich. Do technik tych należą: swobodne skojarzenia, analiza marzeń sennych, analiza oporów oraz analiza przeniesienia.


Analiza swobodnych skojarzeń. Główną procedurą stosowaną w psychoanalizie do sondowania nieświadomości i ujawniania wypartego materiału jest |swobodne |kojarzenie. Pacjent siedzi wygodnie na fotelu lub leży w swobodnej pozycji na kozetce i pozwala swoim myślom swobodnie błądzić; opisuje na bieżąco swoje myśli, pragnienia, odczucia fizyczne oraz wyobrażenia, w miarę jak występują. Pacjenta zachęca się, aby ujawniał każdą myśl czy uczucie, bez względu na to, jak dalece są one osobiste, przykre czy też pozornie nieistotne. Terapeuta często zajmuje miejsce za pacjentem, żeby nie rozpraszać jego uwagi i nie przerywać biegu skojarzeń.
Freud utrzymywał, że „swobodne skojarzenia są zdeterminowane i nie są sprawą wyboru”. Zadaniem analityka jest prześledzenie ciągu skojarzeń, aż do ich zdeterminowanego wewnętrznego rdzenia i przeniknięcia przez pozory, pod którymi mogą kryć się wyparte impulsy - zidentyfikować to, co jest w głębi psychoanalitycznej „góry lodowej”, przedstawione na rycinie 10.2.


Analiza marzeń sennych. Psychoanalitycy próbują uzyskać dalszy wgląd w nieświadomą motywacją pacjenta za pomocą techniki polegającej na analizie marzeń sennych. Zakłada się, że gdy dana osoba śpi, wówczas ego mniej „ma się na baczności” przed niemożliwymi do zaakceptowania impulsami rodzącymi się w id, wskutek czego motyw, który nie może być wykryty na jawie, może znaleźć swój wyraz w marzeniu sennym. Niektóre motywy są jednak tak niemożliwe do zaakceptowania przez świadome ja, że nie mogą ujawnić się otwarcie nawet w snach, lecz muszą być wyrażone w zamaskowanej czy symbolicznej postaci. Toteż marzenia senne mają treść dwóch rodzajów (o czym mówiliśmy w Rozdziale 7). Treścią |jawną snu jest to, co pamiętamy i opisujemy po obudzeniu się. Zwykle nie jest ona przykra, przeciwnie, często wydaje się dość zabawna. Poza treścią jawną jest treść |utajona - rzeczywiste motywy, które dążą do ujawnienia się, lecz są dla nas tak przykre lub niemożliwe do zaakceptowania, że nie chcemy zdać sobie sprawy z ich istnienia. Terapeuta stara się wykryć te ukryte motywy badając symbole, które występują w jawnej treści marzenia sennego.
Nieświadomy proces, który przekształca przykrą emocjonalnie, utajoną treść marzenia sennego w mniej przykrą treść jawną, zwany jest |opracowaniem |marzenia |sennego („dream work”). Opracowanie marzenia sennego zniekształca treść snu w różny sposób, czyniąc wyrażane w nim motywy mniej oczywistymi dla śniącego. Na przykład student, który jest pełen lęku, ze obleje egzamin i zostanie wyrzucony z uczelni, może śnić, że przedziera się przez gwałtowną burzę śnieżną, ścigany przez dzikie zwierzęta. Treść snu może też być mniej zamaskowana: kobiecie, która odczuwa wrogość wobec swego męża, może śnić się, że zabija szczura - przy czym znaczenie tego symbolu ujawnia ona w stanie czuwania, określając żartobliwie swego męża jako „szczurka”.


Analiza oporu. W trakcie procesu swobodnego kojarzenia pacjent może wykazywać |opór - to jest niezdolność czy niechęć do omawiania pewnych myśli, pragnień czy doznań. Opór przeszkadza wprowadzić do świadomości wyparty materiał, którego przypomnienie jest przykre, jak na przykład materiał związany z życiem seksualnym danej jednostki lub z wrogimi, pełnymi urazy uczuciami wobec rodziców. Niekiedy pacjent okazuje opór spóźniając się na spotkanie z terapeutą lub „zapominając” o nim zupełnie.
Gdy materiał taki zostaje w końcu ujawniony, wówczas pacjent na ogół twierdzi, że jest on albo zbyt mało ważny, zbyt absurdalny, zbyt nieistotny, albo też zbyt przykry, aby o nim mówić.
Psychoanalityk ze szkoły freudowskiej przywiązuje szczególną wagę do tych tematów, o których pacjent |nie chce mówić. Opór ten uważa się za |barierę między nieświadomością, gdzie wyparte konflikty prowadzą „partyzancką wojnę” przeciw zdrowiu psychicznemu danej jednostki, a świadomością, która potrafiłaby uporać się w racjonalny sposób z tymi buntowniczymi siłami.  Celem psychoanalizy jest przełamanie oporów i skonfrontowanie pacjenta z tymi przykrymi myślami, pragnieniami i doznaniami. Przełamywanie oporów jest długim i trudnym procesem, lecz uważa się, że jest ono bewzględnie potrzebne po to, by ujawnić cały problem w świadomości, w której będzie go można potem rozwiązać.


Analiza przeniesienia. W trakcie terapii psychoanalitycznej pacjent zwykle zaczyna reagować emocjonalnie na terapeutę, identyfikując go z pewną osobą, która w przeszłości znajdowała się w centrum jakiegoś emocjonalnego konfliktu. Ta faza terapii znana jest pod nazwą |przeniesienia. W większości przypadków analityka identyfikuje się z jednym z rodziców lub z partnerem seksualnym. Przeniesienie nazywa się |przeniesieniem |pozytywnym, gdy uczucia wobec terapeuty są uczuciami miłości lub podziwu a |przeniesieniem |negatywnym, gdy polegają one na wrogości czy zawiści.  Często postawa pacjenta jest ambiwalentna - to jest doznaje on wobec terapeuty zarówno uczuć pozytywnych, jak i negatywnych, jak to często zdarza się w przypadku uczuć dziecka wobec rodziców.
Zadanie analityka, gdy ma on do czynienia z przeniesieniem, jest trudne i niebezpieczne, ze względu na wrażliwość emocjonalną pacjenta, lecz stanowi decydującą część terapii. Terapeuta pomaga pacjentowi interpretować przeniesione uczucia i odkryć źródło we wcześniejszych doświadczeniach i postawach.
Jednakże trzeba pamiętać, że terapeuta nie jest doskonale zaprogramowanym, obiektywnym analizatorem wejścia informacyjnego dostarczonego mu przez pacjenta. Terapeuta, pomimo prób utrzymania „dystansu emocjonalnego”, może jednak reagować na problemy pacjenta w sposób osobisty. W intensywnej interakcji między dwojgiem ludzi, którzy spotykają się przez kilka lat pięć razy na tydzień, w celu omawiania osobistych problemów, trudno jest analitykowi utrzymać swoje reakcje osobiste na poziomie „zera psychologicznego”. Toteż w czasie długotrwałej analizy może również rozwinąć się tak zwane |kontrprzeniesienie („countertransference”). Polega ono na tym, że terapeuta zaczyna lubić lub nie lubić pacjenta w sposób osobisty, z powodu spostrzeganego podobieństwa pacjenta do innych znaczących osób ze swego życia. Przepracowując to kontrprzeniesieniem terapeuta może wykryć u siebie samego pewną nieświadomą dynamikę.




Terapia psychoanalityczna
od czasów Freuda




Jak przekonaliśmy się już w Rozdziale 10, teoretycy neofreudowscy różnią się od Freuda tym, że kładą stosunkowo większy nacisk na działające w danym czasie środowisko społeczne, a mniejszy - na doświadczenia z okresu dzieciństwa. Ta sama różnica w rozkładzie akcentów występuje w terapii neofreudowskiej, która ma na celu zrozumienie zarówno przeszłych doświadczeń pacjenta, jak też jego obecnej sytuacji. Ponadto większość psychoterapeutów neofreudowskich sądzi, że pacjenta nie można wyleczyć pomagając mu po prostu zrozumieć jego nieświadome uczucia. Trzeba raczej kierować pacjentem na drodze zainicjowanych przez niego samodzielnie zmian i pomóc mu przewartościować nieadekwatne sposoby przystosowania.
Podaje się także w wątpliwość, czy wyparte konflikty seksualne stanowią, zgodnie z rolą przypisywaną im przez Freuda, zasadnicze podłoże neurotycznego zachowania także i obecnie, zwłaszcza wśród młodzieży.  Wiktoriańskie ograniczenia i powszechnie akceptowana religijna doktryna grzechu zmuszały do wypierania impulsów seksualnych w czasach Freuda, nic więc dziwnego, że stwierdził on, iż wyparcie seksulane, jest powszechnym problemem wśród jego pacjentów. Jednakże drastyczne zmiany, jakie zaszły w naszych obyczajach seksualnych w ostatnich latach, sprawiają, że wyparcie seksualne jest mniej częstą przyczyną zaburzeń emocjonalnych niż „kryzysy egzystencjalne”, niezdolność do dostrzeżenia sensu życia, poczucie bezradności oraz niezdolność do poradzenia sobie z szybkimi zmianami technologicznymi i społecznymi.
Jung i Adler, chociaż początkowo byli uczniami Freuda, to jednak zerwali z nim w 1911 roku i przystąpili do rozwijania swych własnych poglądów na osobowość, patologię i terapię.




* * *



Porównanie Koncepcji Freuda, Junga I Adlera


- Freud 
Wgląd: Ma centralne znaczenie dla zrozumienia nieświadomej motywacji.  Zwykle dotyczy wypartych wspomnień o konfliktach powstałych we wczesnych stadiach rozwoju psychoseksualnego i ich wpływu na obecne relacje.
Swobodne kojarzenie: Podstawowa procedura stosowana w psychoanalityce do badania nieświadomości. 
Marzenia: Sny są próbą uzyskania senne zakazanych satysfakcji i uważa się je za spełnienie pragnień id. Posługując się swobodnym kojarzeniem, analityk może wyjaśniać pacjentowi ukrytą treść marzeń sennych, czyniąc w ten sposób świadomym to, co było nieświadome. 
Opór: Podstawowe pojęcie w psychoanalizie, odnoszące się w ogóle do wszystkiego, co przeciwdziała postępowi terapii, a szczególnie do aktywnego przeciwstawiania się przez pacjenta ujawnieniu wypartego materiału. 
Przenienie: Uważane za emocjonalną sienie reakcję na terapeutę lub inne osoby, która przybiera formę ustaloną we wczesnym dzieciństwie w wyniku relacji z własnymi rodzicami. „Przepracowanie” (uświadomienia sobie) przeniesienia i oporów stanowi rdzeń freudowskiej psychoanalizy. 


- Jung
Wgląd: Prowadzi do zrozumienia jedynie osobistej nieświadomości i 
dlatego jest mało pomocny w leczeniu nerwicy. Nieświadomość zbiorową można zrozumieć jedynie badając sposób posługiwania się przez pacjenta symbolami w snach, fantazjach itd.
Swobodne kojarzenie: Stosowane nie w sensie pionowym - drążenie w głąb wypartej treści nieświadomości, lecz w sensie poziomym - badania skojarzeń specyficznych dla marzeń sennych lub obrazów występujących w fantazjach.
Marzenia senne: Marzenia senne, podobnie jak wszystkie inne wytwory nieświadomości, jest symbolicznym komunikatem wskazującym drogę przyszłego rozwoju. Jest twórczym i uzdrawiającym aspektem nieświadomości, ukazującym drogę prowadzącą do spełnienia.
Opór: Chociaż uznaje się obecność oporu, to jednak uważa się go za typowy dla natury ludzkiej, a zatem nieinteresujący z z punktu widzenia interpretacji jakiejś podstawowej dynamiki.
Przeniesienie: Rozróżnia się dwa poziomy przeniesienia: a) osobiste - podobne do pojęcia freudowskiego - w którym cechy osób ważnych w przeszłości są rzutowane na terapeutę; b) transpersonalne - archetypowe projekcje, w których terapeutę uważa się za osobę wszechmocną. 


- Adler
Wgląd: Nacisk na osiągnięcie wglądu może być stosowany jako strategia pozwalająca uniknąć zmian w sposobie. Wgląd został przedefiniowany jako „zrozumienie przełożone na konstruktywne działanie” (Mosak i Dreikurs, 1973, s.59).
Swobodne kojarzenie: Freudowskie pojęcie wyparcia i nieświadomości zostały odrzucone; nie ma więc potrzeby analizowania swobodnych skojarzeń.
Marzenia senne: Marzenia senne to aktywność psychiczna (ukierunkowana na przyszłość) polegająca na rozwiązywaniu problemów - wypróbowywaniu różnych działań pozwalających rozwiązać w przyszłości obecne problemy. Jest ono także odzwierciedleniem stylu życia danej jednostki.
Opór: Opory występują wtedy, gdy cele pacjenta i terapeuty nie są zgodne. 
Analizuje się je nie dla ujawnienia wypartego materiału lecz dla 
zrewidowania celów terapii
Przeniesienie: Uważane za wyraz rozbieżności celów pacjenta i terapeuty, wynikającej z nieadekwatnego uczenia się. W rezultacie długotrwałych interakcji z rodzicami i innymi osobami mającymi autorytet pacjent skonstruował „scenariusz” (zwykle nieświadomy), zgodnie z którym oczekuje, że inni będą reagować nań w pewien określony sposób. Analityk powinien odmówić dostosowania się do tego „scenariusza”.


* * *





Odrzucili oni nacisk, jaki Freud kładł na przeszłość, nieświadomość danej jednostki, seks i agresję. Jung twierdził, że istnieją znacznie głębsze poziomy sensu życia niż motywacja seksualna, i że istoty ludzkie aspirują do wyższych celów, aniżeli jedynie zaspokojenie „niskich” popędów. Obaj ci uczeni starali się wyraźniej umiejscowić jednostkę w środowisku kulturowym, ukazać, w jaki sposób jest ona związana z wszystkimi innymi istotami ludzkimi za pośrednictwem wspólnych mitów, archetypów (pierwotnych modeli czy prototypów podstawowych symboli, z których wyprowadza się inne), oraz wspólnego życia społecznego. Aczkolwiek Adler i Jung kładli nacisk na pozytywne cechy ludzi i dostrzegali w nich centralne dążenie do samorealizacji (Adler określił to jako „spełnienie” - „completion”. Jung zaś myślał o tym jako o osiągnięciu Jaźni), to jednak Adler zdawał się bardziej optymistycznie zaopatrywać na możliwości osiągnięcia tego celu.  Dla Adlera ludzie są decydującymi o sobie stworzeniami, które potrafią kształtować zarówno swe wewnętrzne jak i zewnętrzne środowisko - pogląd ten zyskał mu zaszczytne miano jednego z pierwszych psychologów humanistycznych. Obaj ci teoretycy, kładący nacisk na poszukiwanie przez jednostkę sensu w życiu oraz troszcząc się o „tu i teraz” pacjenta i jego przyszłe cele, byli prekursorami psychologii egzystencjalnej. W zamieszczonej obok tabeli przedstawiono porównywanie poglądów Freuda, Junga i Adlera dotyczących zasadniczych problemów terapii psychodynamicznej.




Ocena terapii
psychoanalitycznej




Psychoanaliza stałą się przedmiotem ataków, ponieważ nie przyjmuje ona do wiadomości żadnej krytyki i ponieważ wiele freudowskich pojęć i hipotez nie jest naukowo sprawdzalnych. Zwolennicy terapii behawioralnej krytykują praktykę wyraźnego ignorowania aktualnego problemu pacjenta na rzecz poszukiwania przypuszczalnej, podstawowej jego przyczyny. Utrzymują oni, że to objawy występujące w danej chwili stanowią problem. Jakie prawo ma „psychoanalityk, pytają oni, aby decydować o tym, co jest „rzeczywistym” problemem pacjenta, pomijając problem, który pacjent chce rozwiązać?
Psychoanaliza jest też krytykowana z praktycznego punktu widzenia, ponieważ poddanie się jej wymaga od pacjenta poświęcenia dużej ilości czasu i pieniędzy. Psychoanaliza ma na celu wywołanie fundamentalnej i trwałej zmiany w strukturze osobowości jednostki, co zwykle wymaga co najmniej dwóch-trzech lat częstych posiedzeń z analitykiem. Nawet jeśli dana osoba może pozwolić sobie na to, aby wydatkować czas i pieniądze niezbędne dla przeprowadzenia kompletnej terapii analitycznej, to jej rezultaty nie zawsze są zadawalające. Ponieważ psychoanaliza opiera się w dużym stopniu na osiąganiu przez pacjenta znacznego osobistego wglądu, jest ona zatem najbardziej użyteczna w przypadku tych jednostek, których inteligencja jest powyżej przeciętnej i które nie miały poważnych zaburzeń psychicznych, takich jak schizofrenia. Jest ona także przydatna w stosunku do tych, którzy mają duże zdolności werbalne i umiejętności introspekcji, oraz tych, z którymi analityk może pozostawać w ścisłym związku przez długi okres intensywnych interakcji.
Najważniejsze jest jednak oczywiście następujące pytanie: Jaka jest efektywność psychoanalizy, jeśli chodzi o osiągnięcie zamierzonych celów?  Problem kryteriów wyleczenia rozpatrzymy nieco dokładniej w dalszej części tego rozdziału.
Podkreślając znaczenie instynktownych popędów biologicznych, koncepcja psychodynamiczna czyni jednostkę ofiarą nieokiełznanych sił wewnętrznych.  Ludzie, którzy nie potrafią przezwyciężyć tych wrodzonych tendencji, nie mogą swobodnie wybierać swego losu. Istnieje jednak inne stanowisko, zgodnie z którym natura ludzka popycha nas ku realizacji naszego potencjału ludzkiego oraz integralności całej naszej istoty. Irracjonalność w zachowaniu uważa się więc za wytwór niewłaściwego uczenia się albo za wynik ignorowania wewnętrznych wskazówek, które wyznaczają drogę nie tylko do zaspokojenia „zwierzęcych popędów”, lecz także dla duchownego spełnienia.




Behawiorystyczne
podstawy terapii




Zwolennicy stanowiska behawiorystycznego upatrują patologię w obserwowalnym |zachowaniu, nie uważając jej za coś, co tkwi w układzie nerwowym jednostki, w wypartych konfliktach czy też w nienasyconym, nieobserwowalnym id. Zgodnie z tym poglądem, chorobę psychiczną najlepiej można zrozumieć traktując ją jako patologię zachowania, które można zmienić wykrywając i modyfikując istniejące w danej chwili warunki bodźcowe, które podtrzymują owo zachowanie.
Podobnie jak podejście psychodynamiczne było po części reakcją na dziewiętnastowieczne akcentowanie roli rozsądku, mechanizmów strukturalnych oraz siły woli, tak z kolei behawioryzm odrzucił dominujący pogląd, że „złotą ścieżką” psychologii jest „introspekcyjna analiza świadomości”. W poprzednich rozdziałach przekonaliśmy się, że behawioryzm jest stanowiskiem pragmatycznym, empirycznym i mającym swe podstawy w badaniach. Pojęcia wyprowadzone w drodze wnioskowania, takie jak „nieświadomość”, są odrzucane, ponieważ nie poddają się weryfikacji empirycznej. Zgodnie z tym stanowiskiem, centralnym zadaniem wszystkich żywych organizmów jest |uczenie |się przystosowania do aktualnego środowiska. Toteż za podstawę badań nad zachowaniem przyjmuje się teorię uczenia się. Jeśli organizmy nie nauczyły się, jak skutecznie radzić sobie z wymaganiami środowiska społecznego i fizycznego, wówczas ich nieprzystosowawcze reakcje - zgodnie ze stanowiskiem behawioryzmu można skorygować za pomocą terapii opartej na zasadach uczenia się lub oduczania się („relearning”).



Te różne typy terapii często określa się łącznie jako terapie |behawiorystyczne, |behawioralne lub |czynnościowe, gdyż wszystkie one kładą nacisk na korzyści płynące z „robienia czegoś”, a nie tylko „mówienia o czymś”. Innymi słowy, we wszystkich tych sposobach podejścia utrzymuje się, że ważne jest samo działanie, a nie tylko intelektualne zrozumienie przyczyn tego zachowania. Uważa się, że zachowanie jest zdeterminowane nie przez podstawowe popędy, lecz przez historię uczenia się danej jednostki i jej obecne środowisko. Zwolennicy teorii uczenia się społecznego zmodyfikowaliby to stwierdzenie tak, by objęło specyficzny dla danej jednostki sposób spostrzegania środowiska oraz inne czynniki poznawcze (oczekiwania, wartości, cele itd). Takie stanowisko określa się jako „łagodny” determinizm, ponieważ organizmowi przypisuje się pewien stopień kontroli nad swym zachowaniem.
Niewielkie różnice między rozmaitymi rodzajami terapii behawiorystycznej odzwierciedlają różnice poglądów co do względnej doniosłości uczenia się emocjonalnego, wzmacniania zewnętrznego i zewnętrznego reagowania, wykorzystania społecznego modeli właściwego zachowania, uczenia się zastępczego („vicarious learning”) przez obserwowanie innych itd.
|Modyfikacja |zachowania |polega |zwykle |na |zastosowaniu |procedur |warunkowania |sprawczego („operant conditioning”); nacisk kładzie się w tym wypadku na obserwowanie zachowania i odpowiednie stosowanie wzmocnień.  Najwyraźniej zobaczymy to na przykładzie tak zwanej |ekonomii |żetonowej, znajdującej zastosowanie w zakładach opiekuńczych. Terapię opartą na teorii uczenia się społecznego często określa się jako |terapię |modelującą lub |terapię |uczenia |się |społecznego. Pomimo pewnych różnic, w wypadku wszystkich form terapii behawiorystycznej zakłada się, że „problem” niepożądanego czy nieprzystosowawczego zachowania nie wynika z irracjonalnych motywów, grzechu czy stanów chorobowych, lecz po prostu z niewłaściwego uczenia się.
Behawioryści argumentują, że zachowania anormalne kształtują się w ten sam sposób, jak zachowania normalne: za pośrednictwem procesu uczenia się.
Twierdzą oni, że wszelkie patologiczne zachowania (z wyjątkiem tych, które mają określone przyczyny organiczne) najlepiej można zrozumieć i skorygować posługując się kategoriami „anormalnego” wzmocnienia, które w jakiś sposób zostało skojarzone z próbami radzenia obie z wymaganiami środowiska, podejmowanymi przez tych specyficznych „uczniów”. Działania korekcyjne („treatment”) są potrzebne, ponieważ ich zachwianie sprawia im więcej cierpień niż przyjemności lub zagraża im samym, czy też innym ludziom. Specyficznym aspektem tego oddziaływania korekcyjnego jest więc to, że jest ono ukierunkowane na modyfikację |zachowania, a nie czegoś „wewnątrz” danej jednostki. Zgodnie z tym punktem widzenia, wielu terapeutów, stosujących terapię behawioralną, woli nazywać osoby, które poddają się oddziaływaniu korekcyjnemu „klientami”, a nie „pacjentami”.




Wygaszanie




Najprostszy sposób wyeliminowania niepożądanego zachowania polega niekiedy po prostu na zaprzestaniu wzmacniania go. Gdy ten sposób postępowania jest możliwy, wówczas dane zachowanie na ogół występuje coraz rzadziej i w końcu znika. Wygaszanie jest użyteczną procedurą terapeutyczną w sytuacjach, w których niepożądane zachowanie jest wzmacniane nieświadomie, a sytuacje takie zdają się występować dość często w życiu codziennym. Na przykład, dorośli wzmacniają niekiedy mimo woli niepożądane zachowanie u dzieci, takie jak napady tak zwanych „humorów”, zwracając na nie specjalną uwagę.
Dlaczego ludzie nie przestają robić czegoś, co powoduje cierpienie i przykrość, jeśli są zdolni postępować inaczej? Wiele form zachowania (czy też objawów) ma wielorakie konsekwencje - niektóre negatywne, niektóre pozytywne. Często subtelne pozytywne wzmocnienia podtrzymują dane zachowanie, mimo jego oczywistych negatywnych konsekwencji. Często stwierdza się to w przypadkach jąkania, kiedy to niezwykle silne napięcie, zakłopotanie i niedogodności, wynikające z jąkania są równoważone w części przez troskę, współczucie i gotowe usprawiedliwienie dla niepowodzeń czy odrzucenia przez innych, jakie zapewnia jąkanie się.
Psychologowie kliniczni od dawna zdają sobie sprawę, że takie |wtórne |korzyści towarzyszą nieprzystosowawczemu zachowaniu i podtrzymują je.  Wielu jednak jest przekonanych, że zyski takie mogą być odrzucone dopiero po wyleczeniu podstawowego problemu, gdy nie są już dłużej potrzebne.  Natomiast zwolennicy terapii behawioralnej sądzą, że nieprzystosowawcze zachowanie stanowi cały problem i że zmiana warunków wzmocnienia jest wszystkim, czego potrzeba, aby zlikwidować ten problem.
Stwierdzono, że niezamierzone wzmacnianie podtrzymuje zachowania 
psychotyczne i zachęca do nich. W wielu szpitalach psychiatrycznych 
personel często pyta pacjentów, jak się czują. Może to sugerować pacjentom, 
że „właściwym” zachowaniem jest myślenie i mówienie o swoich odczuciach, 
niezwykłych objawach, halucynacjach itd. W istocie, im bardziej dziwaczne 
są objawy i werbalizacja, tym więcej uwagi może okazywać pacjentom 
personel, usiłujący zrozumieć „dynamikę” danego przypadku
(Ayllon i Michael, 1959).
Jeden z autorów niniejszej książki przeprowadzał wywiad z pewnym hospitalizowanym pacjentem, który zapytany „czy dolega mu coś jeszcze?”, odpowiedział: „Czy ma pan na myśli |halucynacje czy |sublimicję?”
Chociaż trudno to przeprowadzić, jednak jest ważne, aby wygasić te reakcje - pełnych dobrych intencji - członków personelu, nauczycieli, krewnych i przyjaciół, które dostarczają wzmocnienia nieprzystosowawczym zachowaniom. Trzeba dużego opanowania, aby nie interweniować w przypadkach awanturowania się, czy nie popadać w panikę, gdy dziecko zdaje się gotowe do samoskaleczenia się, lecz można wykazać, że taktyka nieinterwencji jest skuteczna.
Wygaszanie niepożądanego zachowania stosuje się zwykle łącznie z pozytywnym wzmacnianiem reakcji, które terapeuta uważa za bardziej przystosowawcze. Później omówimy bardziej szczegółowo techniki wzmacniania pozytywnego, a także podejmiemy problem, kto, i na jakiej podstawie, ma określić, jakie zachowanie jest „przystosowawcze”.




Odwrażliwianie




Trudno jest być jednocześnie szczęśliwym i smutnym lub odprężonym i pełnym lęku. Zasadę tę uwzględniono w terapii w postaci techniki |wzajemnego |hamowania („reciprocal inhibition”), którą rozwinął Joseph Wolpe (1958, 1969). Jednym z rodzajów hamowania wzajemnego jest |odwrażliwianie (odczulanie; „desensitization”). Ponieważ przyjmuje się, że lęk jest główną przyczyną hamującą dążenie ku pozytywnym celom oraz powodującą fiksację na celach negatywnych, pacjenta uczy się, by zapobiegał wzbudzeniu lęku stosując określoną technikę odprężania się („relaxation”).
Terapia odwrażliwiająca zaczyna się od zidentyfikowania bodźców, które wzbudzają lęk w pacjencie, i ułożenia ich w hierarchię od najsłabszych do najsilniejszych. Następnie pacjenta ćwiczy się w osiąganiu coraz głębszego odprężenia mięśni. Trening odprężania się wymaga kilku posiedzeń; aby pomóc napiętym klientom nauczyć się osiągać całkowite odprężenie, stosuje się niekiedy hipnozę lub środki farmakologiczne.
Na koniec rozpoczyna się właściwy proces odwrażliwiania. Pacjentowi, będącemu w stanie odprężenia, mówi się, aby wyobraził sobie tak żywo, jak to jest możliwe, najsłabszy bodziec lękowy z listy. Jeśli wystąpią reakcje lękowe, wówczas pacjent przerywa wywoływanie wyobrażeń i znów koncentruje się na odprężeniu. Gdy pacjent potrafi wyobrazić sobie najsłabszy bodziec bez przykrości, wówczas przechodzi do następnego z kolei, silniejszego bodźca. Po pewnej liczbie posiedzeń pacjent potrafi sobie wyobrazić bez lęku najbardziej przykre sytuacje znajdujące się na liście - nawet takie, których początkowo nie potrafi znieść. Dba się bardzo o to, aby nie wzbudzać lęku w trakcie tego procesu stopniowego zbliżania się do „przerażającego” bodźca. Jeśli pojawi się lęk, wówczas terapeuta przerywa wywoływanie wyobrażeń i doprowadza pacjenta do stanu odprężenia, a następnie znów zaczynają od słabszego bodźca.
Podobnie jak w innych przypadkach warunkowania, gdy lęk w stosunku do określonego bodźca został wygaszony dzięki połączeniu tego bodźca z odprężeniem, następuje |generalizacja hamowania na podobne bodźce, łącznie z następnymi z kolei, silniejszymi bodźcami w hierarchii. Odwrażliwianie działa zatem zarówno bezpośrednio, redukując w wyniku odprężenia lęk przed określonym bodźcem, jak i pośrednio - dzięki generalizacji redukcji lęku na podobne bodźce.
Odwrażliwianie nadaje się idealnie do korygowania specyficznych reakcji fobijnych („phobic reaction”), które utrzymują się wskutek ulgi, jakiej doświadcza dana osoba, gdy uniknie bodźców wywołujących lęk lub ucieknie od nich. Przeprowadzono wiele badań nad ludźmi cierpiącymi z powodu fobii polegającej na przeżywaniu lęku przed wężami. Można by się zastanawiać, czy przezwyciężenie reakcji lękowych wobec |myśli o wężu przeniesie się na sytuację, w której pacjent zetknie się z rzeczywistym żywym wężem. Wyniki badań wykazują, że efekty terapeutyczne istotnie przenoszą się na realne sytuacje życiowe. Pacjenci, u których eliminowano lęk przed wężami, wykazywali znacznie mniejszy strach w testach behawioralnych, w których wymagano od nich, aby zbliżyli się do żywego, niejadowitego węża lub wzięli go do ręki. 
Tradycyjni terapeuci atakowali ten sposób podejścia jako taki, który leczy jedynie powierzchowne objawy, spełniajace adaptacyjną funkcję w przypadku danej osoby, i których usunięcie stwarza jeszcze większy lęk.  Porównywano ten sposób podejścia do majstrowania przy wiatromierzu w celu zmiany kierunku wiatru lub zmieniania skali termometru w celu regulacji temperatury.
Jednakże w rzeczywistości obawa, że usunięcie jednego objawu spowoduje jedynie pojawienie się innego objawu, który przejmie jego funkcje, nie znajduje potwierdzenia w żadnych dostępnych danych. Wydaje się raczej, że usunięcie objawu wzmaga u pacjentów poczucie pewności siebie (zaczynają oni uważać siebie za ludzi, którzy potrafią przezwyciężyć lęk i uporać się ze swymi problemami) i może mieć nawet pozytywny wpływ na inne nieprzystosowawcze reakcje, nie tylko na tę, która była korygowana (Grossberg, 1964). W tabeli zamieszczonej na następnej stronie (autorzy są zwolennikami terapii behawioralnej) przedstawiono porównanie terapii dynamicznej z terapią behawioralną.
Techniki odwrażliwiania stosowane są z powodzeniem w przypadku najrozmaitszych problemów ludzkich, między innymi do takich zgeneralizowanych rodzajów lęku, jak lęk egzaminacyjny („test anxiety”), trema sceniczna, akrofobia (lęk wysokości), agorafobia (lęk otwartych przestrzeni), klaustrofobia (lęk zamkniętych pomieszczeń) oraz impotencji i oziębłości płciowej (Paul, 1969).




Terapia implozyjna




Inną stosowaną obecnie metodą treningu wygaszania jest |terapia |implozyjna, w czasie której dokłada się wszelkich starań, aby wzbudzić w pacjencie możliwie najsilniejszy lęk.




* * *



Porównywanie Terapii Dynamicznej i Behawioralnej


Terapia dynamiczna:
1. Oparta na niespójnej teorii, która nigdy nie została właściwie sformułowana. 
2. Wywodząca się z obserwacji klinicznych, nie oparta na kontrolowanych obserwacjach ani na eksperymentach. 
3. Objawy uważa się za widoczne skutki nieświadomych przyczyn („kompleksów”).
4. Objawy uznaje się za dowód wyparcia. 
5. Przyjmuje się, że występujący w danym przypadku zespół objawów jest zdeterminowany przez mechanizmy obronne. 
6. Wszelkie leczenie zaburzeń nerwicowych musi uwzględniać ich historię. 
7. Wyleczenie osiąga się nie przez leczenie samego objawu, lecz przez oddziaływanie na stanowiącą ich podłoże nieuświadamianą dynamikę. 
8. Interpretacja objawów, snów, czynności itd. jest ważnym elementem uczenia się. 
9. Leczenie jednych objawów prowadzi do ukształtowania się innych objawów. 
10. Przeniesienie jest niezbędnym warunkiem wyleczenia zaburzeń nerwicowych. 



Terapia behawioralna:
1. Oparta na spójnej, właściwie sformułowanej teorii, prowadzącej do sprawdzalnych wyników.
2. Wywodząca się z badań eksperymentalnych, zaplanowanych specjalnie w celu sprawdzenia podstawowej teorii i wyprowadzonych z niej wniosków.
3. Objawy uważa się za nieprzystosowawcze reakcje warunkowe.
4. Objawy uznaje się za dowód niewłaściwego uczenia się.
5. Przyjmuje się, że występujący w danym przypadku zespół objawów jest zdeterminowany przez różnice indywidualne i przypadkowe warunki środowiskowe.
6. Wszelkie leczenie zaburzeń nerwicowych dotyczy istniejących obecnie nawyków.
7. Wyleczenie osiąga się lecząc sam objaw, to znaczy wygaszając nieprzystosowawcze reakcje warunkowe oraz ustanawiając pożądane reakcje warunkowe.
8. Interpretacja, nawet jeśli nie jest całkowicie subiektywna i błędna, nie ma istotnego znaczenia.
9. Leczenie objawów prowadzi do trwałego wyzdrowienia - pod warunkiem, że zostaną wygaszone nie tylko szkieletowe, lecz i autonomiczne reakcje warunkowe.
10. Relacje osobiste nie są niezbędne dla wyleczenia zaburzeń nerwicowych chociaż mogą one być użyteczne w pewnych okolicznościach. 

(Źródło: Eysenck i Rachman, 1965)


* * *





Zwolennicy terapii implozyjnej również uważają zachowanie neurotyczne za uwarunkowane unikanie bodźców wzbudzających lęk, lecz sądzą, że jeśli danej osobie pozwala się unikać bodźca wzbudzającego lęk, to ten lęk nigdy nie wygaśnie, ponieważ nie będzie po temu żadnych powodów (Stampf i Levis, 1967).
Dynamikę tę sytuacji świetnie ilustruje stary dowcip o człowieku, który cały czas prztykał palcami. Gdy zapytano go, dlaczego to czyni, to odpowiedział, że nie pozwala zbliżyć się tygrysom. Gdy mu powiedziano, że nie ma żadnych tygrysów w tej okolicy, wówczas wykrzyknął uszczęśliwiony: 
„No zobaczcie, skutkuje!”. Oczywiście zachowanie tego rodzaju jest odporne na wygaszanie, ponieważ samo stwarza sobie warunki dostarczające wzmocnienia.
Zwolennicy terapii implozyjnej są przekonani, że aby najskuteczniej wygasić irracjonalny strach, pacjent musi doświadczyć silnej reakcji lękowej nie odnosząc przy tym żadnej szkody. Sytuacja terapeutyczna jest tak zaaranżowana, że pacjent nie może uciec od bodźca wzbudzającego lęk.  Terapeuta opisuje skrajnie przerażającą sytuację związaną z lękami pacjenta i nakłaniania go, aby wyobraził sobie, że znajduje się w tej sytuacji, doświadczając ją wszystkimi zmysłami tak intensywnie, jak to tylko jest możliwe. Zakłada się, że wyobrażenie takie powoduje eksplozję panicznego strachu. Ponieważ jest to eksplozja wewnętrzna, nosi ona zatem nazwę |implozji; stąd termin |terapia |implozyjna („implosive therapy”). Gdy zachodzi to wielokrotnie i nie dzieje się nic złego, wówczas bodziec ten traci swą zdolność wzbudzania lęku. Gdy lęk przestaje występować wówczas zachowanie neurotyczne (stosowane w celu uniknięcia go) znika. Innymi słowy, następuje wygaszenie.
Zamiast zaczynać od wyobrażenia sobie bodźców wzbudzających słaby lęk i stopniowo przechodzić do bodźców naprawdę przerażających (starając się zapobiec wzbudzeniu lęku w którymkolwiek momencie), podczas terapii implozyjnej pacjent ma wyobrazić sobie, jak najżywiej, najbardziej realnie, najbardziej przerażającą scenę, jaką można wymyśleć. Sposób przeprowadzenia takiej terapii oraz jej odmienność w stosunku do odwrażliwienia przedstawia poniższy przykład zastosowania jej wobec grupy dziesięciu kobiet, które obawiały się węży (spróbuj zaprząc |swoją wyobraźnię do pracy nad obrazami, z którymi miały one do czynienia):


„Opisywano wysoce przerażające sceny z wężami, po czym proszono osoby badane, by wyobrażały sobie te sceny możliwie jak najżywiej, wykorzystując wszystkie swoje zmysły: Wyobraź sobie, że atakuje cię olbrzymi wąż wielkości człowieka, że śliski wąż pełza po całym twoim ciele, że pomału dusi cię, że wąż wpełznął do twego żołądka, gdzie gryzie cię bezlitośnie.  Co pewien czas osobom badanym przypominano, że w rzeczywistości nie stało się im nic złego. Spośród dziesięciu osób badanych, siedem było zdolnych wziąć do ręki węża po jednym 45-minutowym posiedzeniu” (Hogan i Kirsner, 1968).




Uczenie się awersyjne




Istnieją pewne rodzaje zaburzeń zachowania, w których zachowanie danej jednostki (palenie, picie, uprawianie hazardu, zażywanie silnych środków psychotropowych) przynosi natychmiastową przyjemność, lecz na dalszą metę ma ujemne następstwa dla zdrowia lub dla zaspokojenia innych potrzeb. Może też być tak, że dany bodziec uzyskał zdolność wywoływania reakcji warunkowej, którą dana jednostka uważa za niepożądaną, na przykład takiej, jak podniecenie homoseksualne. Największe nadzieje budzi w przypadkach takich zaburzeń leczenie za pomocą stymulacji awersyjnej.
Jak przekonaliśmy się w Rozdziale 3, istnieje szereg zmiennych, które przy zastosowaniu stymulacji awersyjnej, łącznie wpływają na uczenie się.  Intensywność, czas trwania i rozkład awersyjnych bodźców odgrywają ważną rolę, podobnie jak ich przewidywalność, kontekst, w którym występują, oraz to, czy są one łączone z bodźcami wywołującymi dane zachowanie (warunkowanie reaktywne), czy też są następstwem zachowania (warunkowanie instrumentalne).
Awersyjne warunkowanie instrumentalne stosuje się z powodzeniem w celu eliminowania jąkania się.


„Osobom jąkającym się polecono czytać drukowany materiał na głos przez prawie godzinę, w celu uzyskania miary podstawowego poziomu jąkania się.  Następnie proszono je, aby czytały bardzo powoli, lecz za każdym razem, kiedy się jąkały, wymierzano im przykry bodziec w postaci opóźnionego słuchowego sprzężenia zwrotnego od ich własnego głosu.
Jak przekonaliśmy się w Rozdziale 6, opóźnione słuchowe sprzężenie zwrotne jest bardzo przykre dla osoby usiłującej mówić.
Gdy pacjenci potrafili już czytać powoli bez jąkania się, wówczas ich tempo czytania stopniowo przyspieszano, podczas gdy opóźnione sprzężenie zwrotne stawało się coraz słabsze. Na siedemnastym posiedzeniu jeden z jąkających się czytał szybciej niż w czasie ustalania poziomu podstawowego, a częstość jąkania się wynosiła mniej niż jedno słowo na minutę - w porównaniu z piętnastoma słowami na minutę na początku. Inny jąkający się, u którego cały trening trzeba było przeprowadzić w ciągu zaledwie jednego tygodnia, uzyskał jeszcze bardziej efektywne rezultaty: tempo czytania ponad dwukrotnie szybsze niż na początku, bez jąkania się w ogóle” (Goldiamond, 1965).
W celu zmodyfikowania „kuszących właściwości” bodźców, które wywołują dewiacyjne pragnienia i zachowania, stosuje się procedury przeciwwarunkowania. Bodźce, które uzyskały zdolność wzbudzania niepożądanych reakcji, łączy się z przykrymi bodźcami, takimi jak wstrząsy elektryczne lub środki wywołujące wymioty. Miarą osiągniętego sukcesu terapeutycznego jest niewytępowanie niepożądanej reakcji warunkowej (na poziomie fizjologicznym lub behawioralnym), mimo podawania bodźca pierwotnie wywołującego tę reakcję.


„Oddziaływanie korekcyjne wobec pewnego transwestyty, prowadzone przy zastosowaniu tego sposobu podejścia, polegało najpierw na zarejestrowaniu pobudzenia seksualnego pacjenta określanego częstością i latencją erekcji.  Pobudzenie występowało nie tylko przy eksponowaniu fotografii nagiej kobiety, lecz również części ubioru damskiego, które pacjent nosił, gdy przebierał się za kobietę. Widok każdej części tego ubioru łączono kolejno z przykrymi wstrząsami elektrycznymi. Pod koniec piętnastego posiedzenia widok żadnej części tego ubioru nie wywoływał erekcji, natomiast odpowiednie bodźce heteroseksualne w postaci ciała kobiety - wobec których nie zastosowano przeciwwarunkowania - nadal wywoływały pobudzenie seksualne” (Marks i Gelder, 1967).


W niektórych przypadkach awersyjne przeciwwarunkowanie stosowano ze znacznym powodzeniem w odniesieniu do alkoholików. Pewien badacz doniósł o całkowitej abstynencji 25 spośród 26 pacjentów w ciągu okresu wynoszącego od ośmiu do piętnastu miesięcy po przeprowadzeniu przeciwwarunkowania (Blake, 1967). Jednakże inne badania oceniające skuteczność awersyjnego warunkowania alkoholików, jak również nałogowych palaczy, wykazały jedynie umiarkowane sukcesy. Oczywistą trudnością ograniczającą kliniczną skuteczność tego rodzaju technik awersyjnego warunkowania jest to, że ludzie potrafią z łatwością odróżnić „niebezpieczne” sytuacje terapeutyczno-laboratoryjne od sytuacji pozalaboratoryjnej, gdzie znów można „bezpiecznie” pić, uprawiać hazard i „łykać pigułki”. Można nawet wysunąć argument, że w przypadku palaczy te awersyjne techniki same w sobie są źródłem lęku, przez co jeszcze silniejszym wzmocnieniem jest ulga, jakiej dostarcza palenie poza sytuacją terapeutyczną.
Jedna z trudności, jakie wiążą się ze stosowaniem terapii awersyjnej, polega na skłonieniu danej osoby, aby poddała się dobrowolnie tej terapii (a nawet płaciła za te męczarnie). Terapia awersyjna nie jest pomyślana tak, by zachęcała do poddania się jej bez przymusu lub zgłaszania się na nią po raz drugi. Zwłaszcza, jeśli bezpośrednie, pozytywne wzmocnienia, jakich dostarcza „zły nawyk”, są silne, to motywacja do poddawania się awersyjnym bodźcom nie będzie wystarczająco silna - chyba, że dana osoba jest pod wrażeniem długotrwałych, ujemnych następstw niepożądanego zachowania. „Wrażenie” takie wywiera się poprzez kształcenie, pouczanie, a czasami za pośrednictwem propagandy masowej. Przeciwdziałają temu te kręgi społeczeństwa, które ciągną zyski ze „złego nawyku” - przemysł alkoholowy, tytoniowy, kasyna gry itd.




Wzmocnienie pozytywne




Pozytywne wzmacnianie pożądanych reakcji, według pewnego systematycznego planu, stosuje się z powodzeniem w klasie szkolnej, w zakładach karnych i w szpitalach psychiatrycznych oraz w wielu innych sytuacjach.




* * *



Ryc. 12.5. Na górnym zdjęciu widzimy jedno z pierwszych „posiedzeń naśladowczych” z Billym; mając siedem lat nie potrafił on w ogóle mówić i zmienił życie swych rodziców w koszmar (demonstrował ataki szału, podczas których nieobliczalne, gwałtowne akty destrukcji występowały na przemian z biciem głową o ścianę). Wielu specjalistów, do których zwracali się jego udręczeni rodzice, uznało go za niedorozwiniętego umysłowo.


* * *





Dolne zdjęcie pokazuje Billy’ego i drugiego chłopca otrzymujących natychmiastowe wzmocnienie pokarmowe za interakcje społeczne. Po kilku miesiącach Billy mógł już mieszkać w domu i uczęszczać do szkoły specjalnej. Dwa lata później przerabiał program pierwszej klasy z zakresu czytania i arytmetyki i wydawał się szczęśliwy, aczkolwiek często mówił w sposób niewyraźny i były z nim jeszcze pewne problemy w domu (zdjęcia Allana Granta).


Nawet pacjenci, którzy byli całkowicie niemi przez wiele lat (lecz są 
fizycznie zdolni do mówienia) uczą się mówić dzięki zastosowania technik 
warunkowania sprawczego 
(Isaacs, Thomas i Goldiamond, 1960).


„W pewnym badaniu, przeprowadzonym przy zastosowaniu tej techniki, stwierdzono, że podając pacjentowi wzmocnienie (w postaci drobnych monet lub pisania za niego listów) uzależnione od mówienia, można było stopniowo kształtować wydawane przez niego dźwięki, które z początku przypominały kwiczenie. Dalszy trening stopniowo doprowadził do tego, że potrafił on wypowiadać kompletne słowa, a na koniec zdania. Po szesnastu posiedzeniach treningowych zachowanie pacjenta (mówienie w obecności terapeuty) zgeneralizowało się na jego zachowanie w sali szpitalnej: po raz pierwszy od dwóch lat przemówił on do jednego z pielęgniarzy. Gdy pielęgniarzy wyszkolono również w technikach wzmacniania, wówczas mogli oni także brać udział w dalszym leczeniu i w końcu pacjentowi temu przywrócono w pełni mowę” (Scherman, 1963).


Duże sukcesy uzyskano także stosując procedury warunkowania sprawczego w przypadku problemów zachowania u dzieci z zaburzeniami psychicznymi.  Poniżej przytaczamy jeden z takich przypadków.


„Pacjent był trzyletnim chłopcem, którego przyjęto do szpitala z rozpoznaniem schizofrenii dziecięcej. Dziecko nie jadło normalnie i nie wykazywało normalnego zachowania społecznego ani werbalnego. Występowały u niego nie dające się opanować napady, w czasie których dziecko przejawiało zachowanie autodestrukcyjne, takie jak walenie głową, bicie i drapanie się po twarzy oraz ciągnięcie się za włosy. Przeszło ono operację katarakty i z tego powodu noszenie okularów było w jego przypadku niezbędne dla rozwoju normalnego widzenia. Dziecko nie chciało jednak ich nosić i tłukło parę za parą.
Aby rozwiązać ten problem, psychologowie postanowili posłużyć się techniką kształtowania. Jeden z pielęgniarzy pracował z dzieckiem w jego pokoju, przeprowadzając codziennie dwa lub trzy dwudziestominutowe posiedzenia. Najpierw dziecko nauczono oczekiwać, że na dźwięk grzechotki otrzyma cukierek lub kawałek owocu. Dźwięk ten wkrótce stał się warunkowym czynnikiem wzmacniającym. Następnie rozpoczęto ćwiczenie z pustymi oprawkami okularów. Dziecko otrzymywało wzmocnienie najpierw za wzięcie ich do ręki, następnie za trzymanie, a wreszcie za noszenie ich w ręku. Powoli i w drodze kolejnych przybliżeń nauczyło się podnosić oprawki do oczu. Po paru tygodniach dziecko zakładało puste oprawki na głowę, początkowo pod dziwnym kątem, a w końcu nosiło je we właściwy sposób. W wyniku dalszego ćwiczenia dziecko nauczyło się nosić okulary do dwunastu godzin dziennie” (Wolf, Risley, i Mees, 1964).


Wzmacnianie sprawcze okazało się równie skuteczne, nawet w odniesieniu do 
przejawiających chroniczną regresję psychotyków; spowodowało ono, że 
zaczęli oni reagować i w ten sposób stali się bardziej podatni na terapię
(Skinner, Solomon i Lindsley, 1954).




Naśladowanie modeli




Samo pozytywne wzmacnianie może być zupełnie zadawalające w przypadku zachowania, które już co pewien czas występuje, lecz bywa długą i żmudną techniką, gdy trzeba kogoś nauczyć nowych zachowań. Osoba ucząca się może łatwiej przyswoić sobie nowe reakcje, zwłaszcza złożone, jeśli ma sposobność obserwować i naśladować pewien model. Naśladowanie jest stosowane często w połączeniu z pozytywnym wzmacnianiem.


„W pewnym programie badawczym mutyzm (czynnościową niemotę) dzieci schizofrenicznych leczono różnymi technikami, między innymi wzmacniając naśladowanie. Najpierw dzieci nagradzano po prostu za wydawanie dźwięków.  Później nagradzano je za wokalizację tylko wtedy, gdy dźwięk był podobny do dźwięku „modelowego”, wydawanego przez terapeutę. Gdy dzieci nauczyły się naśladować dźwięki, wówczas nagrody dawano za powtarzanie słów wymawianych przez terapeutę. Opierając się na rosnącym repertuarze wokalnych zachowań dzieci oraz na ich wzrastającej gotowości do naśladowania, wytworzono u nich w końcu bardziej skomplikowane zachowania społeczne i zachowania z zakresu porozumiewania się” (Lovaas, 1968; ryc. 12.5).


Takie podejście terapeutyczne wymaga znacznej cierpliwości i wytrwałości ze strony terapeuty. Jedno z autystycznych dzieci, z którym pracował Ivar Lovaas, potrzebowało 90000 prób, zanim potrafiło w konsekwentny sposób nazywać dwa przedmioty.
Nawet te dzieci w wieku przedszkolnym, których kontakty społeczne są poważnie zaburzone, mogą nauczyć się nowego zachowania, za które inne dzieci, oglądane przez nie na filmie, są nagradzane. W grupie, która oglądała pozytywnie wzmacnianą interakcję między dziećmi, wystąpił później znaczny wzrost liczby interakcji społecznych w porównaniu z grupą dzieci (mających takie same objawy), która oglądała film kontrolny (O’Connor, 1969).
W leczeniu fobii (takich, jak strach przed wężami, który jest często przedmiotem badań nad skutecznością terapii) terapeuta najpierw demonstruje zachowanie budzące stosunkowo mniejszy lęk, takie jak zbliżenie się bez obawy do klatki węża lub dotknięcie węża. Następnie pacjentowi pomaga się, przez demonstrowanie i podtrzymującą zachętę, naśladować zachowanie terapeuty. Stopniowo poziom wymagań podnosi się, aż do momentu, w którym pacjent potrafi wziąć węża do ręki i pozwoli mu pełzać swobodnie po sobie (ryc. 12.6). Nigdy nie zmusza się pacjenta do wykonywania któregoś z zachowań i, podobnie jak w odwrażliwianiu jeśli polecenie napotyka wyraźny opór, to terapeuta wraca do zachowania wykonanego uprzednio z powodzeniem i zaczyna od nowa.




* * *



Ryc. 12.6. Przedstawiona na zdjęciu pacjentka najpierw obserwowała „model” (terapeutę), który nie doznając żadnej szkody wykonywał szereg stopniowanych reakcji zbliżenia do węża, a następnie powtarzała je sama. W końcu była ona zdolna wziąć węża w ręce i pozwolić mu pełzać po sobie.


* * *





W badaniach Alberta Bandury i jego współpracowników (1970) stwierdzono, że skuteczność modelowania uczestniczącego („na żywo”) jest znacznie większa niż modelowania symbolicznego (samodzielne wyświetlanie sobie filmu przedstawiającego „modele” bawiące się bez obawy z wielkim wężem) i techniki odwrażliwiania. W grupie modelowania uczestniczącego fobię tę (lęk przed wężami) wyeliminowano u jedenastu spośród dwunastu osób badanych.




konomia żetonowa




W ostatnich latach w coraz większej liczbie szpitali psychiatrycznych w Stanach Zjednoczonych stosuje się tak zwaną „ekonomię żetonową” („token economies”). Technikę tę można uznać za specjalny przypadek pozytywnego wzmacniania. Pacjentów nagradza się za wykonywanie takich konstruktywnych społecznie czynności jak utrzymywanie czystości osobistej, przychodzenie na czas na posiłki i wykonywanie wyznaczonych zadań. Zapłatą są żetony (na przykład sztony pokerowe), za które można później „kupować” takie luksusy, jak bardziej eleganckie nakrycia obiadowe, dłuższy czas oglądania telewizji, własną pościel czy przepustki na weekend.
Personel szpitalny stwierdza, że ekonomia żetonowa bywa często w pełni skuteczna jako sposób wywoływania pożądanych zachowań, nawet u pacjentów z dość poważnymi zaburzeniami, jednakże zwykle trzeba ją wprowadzać stopniowo. Pacjentów początkowo nagradza się zatem po prostu za zbliżanie się do pielęgniarek czy innych pacjentów. Następnie, stosując proces kształtowania („shaping”), można nakłonić ich do nawiązywania rozmów między sobą. W końcu można ich nagradzać za bardziej złożone formy interakcji interpersonalnej, jak również za inne, bardziej konkretne czynności.
Efektywność ekonomii żetonowej została bogato udokumentowana w wielu badaniach. Pacjenci, którzy całymi latami prowadzili niemal wegetatywny tryb życia, zaczynają reagować, a nawet wykonywać z poświęceniem i zapałem ignorowane uprzednio zadania.


„Pewien zespół terapeutów przeprowadził wiele eksperymentów, w których sprawdzał systematycznie skuteczność ekonomii żetonowej. Pacjenci poddani badaniom byli chronicznymi psychotykami, którym w szpitalu dawano do wykonania pewną pracę; wykonywali ją niewydajnie i nieregularnie, często w ogóle jej nie podejmowali. Wprowadzano „ekonomię żetonową”, w której pacjentów nagradzano za wykonywanie przeznaczonej dla nich pracy. Wystąpiły radykalne zmiany w poziomie ich sumienności. Pacjenci zaczęli wykonywać pracę rzetelnie i szybko. Nie wysuwali żadnych próśb o chwilowe zwolnienia, chociaż dano im do zrozumienia, że takie próby będą spełniane automatycznie.
Aby bezpośrednio sprawdzić motywującą siłę ekonomii żetonowej, badacze postanowili uzależnić dalsze wzmacnianie od gotowości pacjentów do zajęcia się pracami niechętnie poprzednio wybieranymi. Gdyby pacjenci postąpili w ten sposób, to oznaczałoby to, że ekonomia żetonowa decydowała o wyborze pracy.
Wyniki były przekonywujące. Pacjenci natychmiast podjęli się tych zajęć, gdy wyjaśniono im, że dalsze wzmocnienie zależne jest od tego, czy tak postąpią. W celu ostatecznego sprawdzenia motywującej siły żetonów, badacze znów odwrócili zasadę wzmacniania i nagradzali pacjentów za wykonywanie preferowanych przez nich pierwotnie zajęć. I znów pacjenci przeszli szybko do wykonywania zadań nagradzanych” (Ayllon i Azrin, 1965).


Sposób kontroli eksperymentalnej, zastosowany w tych badaniach, spotyka się dość często w terapii behawioralnej. Ocena efektywności ekonomii żetonowej, uzyskana przez wzmacnianie najpierw prac preferowanych, następnie prac niepreferowanych, a w końcu ponownie prac preferowanych, stanowi dobry przykład schematu eksperymentalnego „A - B - A”. Najpierw wprowadza się te warunki eksperymentalne, których wpływ się sprawdza, następnie w systematyczny sposób zmienia się je, a w końcu przywraca. Każdy pacjent jest dla samego siebie „osobą kontrolną”. W tym wypadku dokonywany przez pacjenta wybór pracy może bez wątpienia przypisać samemu wzmacnianiu, a nie „zadowoleniu z pracy” czy innym czynnikom. Stosując ten sam schemat eksperymentu, Ayllon i Azrin stwierdzili, że gdy żetony wydawano automatycznie, bez względu na wynik pracy, lub gdy nagrody udostępniano swobodnie, bez potrzeby płacenia za nie żetonami, wówczas następował znaczny |spadek ilości pracy wykonywanej przez pacjentów.
O motywacjach pacjentów świadczy zestawienie dóbr, które kupowali oni za zarobione przez siebie żetony, mogąc dokonywać między tymi dobrami swobodnego wyboru. Doborem najbardziej pożądanym była możność przebywania w samotności, na drugim miejscu były produkty żywnościowe, a na trzecim przepustki z oddziału. Różnice indywidualne pod względem preferencji ograniczały się w dużej mierze do różnego rangowania tych trzech głównych nagród. Bardzo niewiele żetonów wydano na rozmowy z personelem szpitalnym lub dla uzyskania możności uczestniczenia w czynnościach religijnych lub rozrywkowych.




Zbliżenie


„Ekonomia żetonowa” w akcji


„Program „ekonomii żetonowej”, opartej na zasadach warunkowania sprawczego, po raz pierwszy wprowadzono w życie w Carmarillo State Hospital (Stan Kalifornia) w 1966 roku.
Pozwalał on tak skutecznie osiągać zamierzone cele, że w ciągu paru lat na różnych oddziałach zaczęto realizować jedenaście takich programów.  Poniżej podano niektóre kryteria behawioralne, na podstawie których przydzielano lub odbierano żetony (Montgomery i McBurney, 1970).


1. Czysty i schludny wygląd w każdej sytuacji. 
2. Wykazywanie potrzeb z zakresu higieny osobistej, takich jak korzystanie z prysznica; kąpanie się bez nadzoru.
3. Mężczyźni ogoleni przed śniadaniem.
4. Dziewczęta starannie umalowane i uczesane przed śniadaniem. Odpowiedni ubiór.
5. Akceptowany społecznie sposób zachowania przy stole.
6. Rzadkie występowanie takich zachowań, jak przeklinanie, szturchanie innych pacjentów, plucie.
7. Czekanie na swą kolej we wszystkich sytuacjach.
8. Zachowanie akceptowane społecznie: umiejętność samodzielnego poruszania się po terenie szpitala, odpowiedniego zachowywania się podczas grupowego spaceru. Znajomość zwyczajów i sposobów postępowania obowiązujących w społeczeństwie lub uczenia się ich.
9. Oddawanie swej odzieży do pralni i odbieranie jej stamtąd.
10. Utrzymywanie porządku w szafce.
11. Ścielenie łóżka i sprzątanie sypialni (włączając w to zamiatanie podłogi oraz sprzątanie w toalecie) bez nadzoru, przed przyjściem porannej zmiany.
12. Samorzutny udział w pracach zespołowych oraz pomaganie osobom mniej sprawnym. 
13. Posiadanie własnego planu pracy lub regularne uczęszczanie do szkoły, albo do ośrodka szkolenia zawodowego.



Ogólnie biorąc, można powiedzieć, że w większości szpitalnych systemów „ekonomii żetonowej” wzmacnia się dbałość pacjentów o ich wygląd zewnętrzny, socjalizację, wykonywania zadań na oddziale, jak również angażowanie się w czynności, w których pacjent sam kieruje swym zachowaniem. Niepożądane zachowania powodują utratę żetonów przez pacjenta, oczekuje się więc, że częstość ich występowania będzie maleć. Skuteczność „ekonomii żetonowej” realizowanej niedawno w Palo Alto Veterans Hospital ukazano na rycinie, która przedstawia zmiany zachowania, jakie zaszły w ciągu 10 miesięcy od chwili wprowadzenia „ekonomii żetonowej” (Rouse i Reilly, 1974). Godną uwagi cechą tego programu było utworzenie oddziałowego samorządu pacjentów, który umożliwił im uczestniczenie w kierowaniu swą własną „ekonomią żetonową”, a w końcu założenia własnego „satelickiego” schroniska poza terenem szpitala”.


W najbliższym czasie możemy oczekiwać powszechnego zastosowania zasad „ekonomii żetonowej” w wielu innych sytuacjach. Stosuje się je już na przykład w wielu szkołach, a niektórzy zwolennicy tej procedury sądzą, że w końcu żetony zastąpią obecny system ocen. Z punktu widzenia uczenia się „ekonomia żetonowa” ma następujące zalety: a) dostarcza wyraźnej oznaki aprobaty, b) sprawia, że sytuacja staje się wyraźnie określona i przewidywalna, dzięki temu, że ustala się dokładnie, co trzeba zrobić, żeby osiągnąć dany efekt, c) nie zależy od nastroju czy wartości uznawanych przez nauczyciela lub innych osób stanowiących autorytet, d) daje uczniowi całkowitą swobodę wyboru (w ramach dostępnych możliwości) dóbr, dla uzyskania których chce się pracować oraz e) gwarantuje, że nawet reakcje w minimalnym stopniu właściwe, będą przez kogoś zaobserwowane, zanotowane i wzmocnione; dzięki temu sukces i wzmocnienie są dostępne dla każdej osoby w danej grupie.
Krytycy tej techniki wzmacniania wzdrygają się jednakże na myśl o wprowadzeniu systemu opartego na motywie zysku, utrzymując, że wprowadziłoby to do nauki szkolnej „mentalność handlową”, przy której wysiłek podejmuje się jedynie dla uzyskania nagród zewnętrznych; dzieci nie miałyby sposobności uczenia się dla samej radości odkrywania czy dla samych osiągnięć intelektualnych. Procedura modyfikacji zachowania w formie ekonomii żetonowej, jaką obecnie stosuje się w niektórych więzieniach, ma ten wątpliwy aspekt, że najpierw pozbawia się więźniów niemal wszystkiego, a następnie mogą oni uzyskać „przywileje” w postaci prysznicu, gorących posiłków, przyzwoitego łóżka, książek, ćwiczeń fizycznych itd. Wprowadzając skrajną deprywację można przekształcić wszystko w „pozytywne wzmocnienie” - na przykład możliwość jedzenia, spania czy nawet pójścia do toalety.  Przedmiotem gorącego sporu jest problem, czy w warunkach przymusu i deprywacji można naprawdę mówić o |pozytywnym wzmocnieniu.




Ocena terapii
behawioralnych




Sprawozdania dotyczące terapii behawioralnych wskazują zwykle na ich skuteczność, gdyż wskaźnik sukcesu waha się na ogół między 75% a 90%.
W porównaniu z innymi rodzajami terapii, terapiom behawioralnym można przypisać szereg zalet. Są one ściślej związane z badaniami naukowymi niż terapie analityczne i w większym stopniu reagują na ich wynik. Ponieważ w terapiach behawioralnych kładzie się nacisk na leczenie specyficznych objawów, przynoszą one zatem rezultaty w znacznie krótszym czasie niż tradycyjne terapie. Oznacza to szybszą pomoc i oszczędności finansowe dla pacjenta oraz możność leczenia większej liczby pacjentów przez danego terapeutę. Ponieważ terapia opiera się na jasno sformułowanych zasadach uczenia się i nie jest uzależniona od osobowości terapeuty, jego zdolności nawiązywania kontaktów interpersonalnych czy umiejętności dokonywania interpretacji, przeto szkolenie terapeutów jest łatwiejsze i krótsze, a dzięki temu terapię tę mogą prowadzić fachowcy z innych dziedzin (nauczyciele, pielęgniarki, funkcjonariusze więziennictwa itd.) czyli |paraprofesjonaliści.
Krytyczna ocena terapii behawioralnej ujawnia jednak szereg zastrzeżeń co do jej efektywności, jej metod i jej niezamierzonych konsekwencji.
Istnieje niewiele badań, w których ocenianoby długotrwałą skuteczność tego rodzaju leczenia - to jest jego efekty po upływie więcej niż roku od chwili zakończenia terapii. W badaniach najczęściej przytaczanych jako dowód, że skuteczność terapii behawiorystycznej sięga 90% (Wolpe, 1960), występuje poważne źródło błędów w postaci tendencyjnego doboru próbki („sampling bias”). W ostatecznych rezultatach uwzględniono tylko tych pacjentów, którzy odbyli przynajmniej 15 posiedzeń terapeutycznych. Wszyscy ci, którzy odpadli w ciągu pierwszych 14 posiedzeń, zostali pominięci, co oczywiście ułatwiło osiągnięcie wysokiego wskaźnika sukcesu.
Poważniejsze zarzuty dotyczą tego, co w istocie stanowi efektywną zmienną niezależną w |terapii zachowania” (Breger i McGaugh, 1965). Wydaje się, że w wielu wypadkach behawioryści nie polegają wyłącznie na procedurach warunkowania, lecz „mieszają” je z bardziej tradycyjnymi technikami doradczymi, takimi jak dyskutowanie, w jaki sposób pacjent może „postawić się” i uzyskać kontrolę nad swymi stosunkami z innymi ludźmi (Weitzman, 1967).
Inni krytycy utrzymują, że najbardziej skutecznymi narzędziami w „czarnej walizeczce” behawiorystów są w rzeczywistości manipulacje poznawcze - że podstawowymi reakcjami sprawczymi nie są bynajmniej obserwowalne zachowania, lecz elementy poznawcze - wyobrażenia, uczucie lęku, oczekiwania i oceny. Można zatem twierdzić, że terapia behawioralna może przynosić rezultaty nie dlatego, że oddziałuje na konkretne reakcje zewnętrzne i utrzymuje je - jak się to głosi - lecz dlatego, że pacjenci, być może po raz pierwszy, mają do czynienia z przewidywalnym środowiskiem, w którym mogą wyraźnie dostrzec konsekwencje swego zachowania i dzięki temu mogą wykorzystywać zasoby środowiska tak, aby uzyskać to, czego pragną.
Innego rodzaju zarzuty pod adresem tego podejścia terapeutycznego koncentrują się na |niepożądanym uczeniu się pośrednim, któremu może sprzyjać terapia behawioralna, oraz na wartościach, które może ona kształtować. Na przykład, jeśli nagrodę podaje się jedynie za obserwowalne zachowanie i konformizm wobec tych wartości, które ktoś inny uznał za „właściwe”, to dana jednostka może nauczyć się cenić pozory zewnętrzne, ślepy konformizm wobec społecznie akceptowanych norm, aprobatę społeczną kosztem samoaprobaty oraz działanie kosztem myślenia czy odczuwania (S. P.  Grossman, 1968).
Być może najważniejszym problemem, przed jakim stoi terapia behawiorystyczna, jest brak |generalizacji skutecznej modyfikacji zachowania, osiąganej w sytuacji terapeutycznej, na sytuacje występujące w naturalnym środowisku danej osoby. Takie „nawroty” danych zachowań ograniczają użyteczność terapii, ponieważ człowiek musi żyć w swej własnej społeczności, a nie tylko w pracowni, klinice, szkole, szpitalu czy innej instytucji.
Sugeruje się, że w celu osiągnięcia skuteczniejszego transferu uczenia się z sytuacji terapeutycznej na środowiska naturalne, należy przestrzegać następujących zasad: a) bodźce terapeutyczne powinny reprezentować te bodźce, które pacjent napotyka w swoim środowisku, i powinny być do nich podobne; b) sytuacje terapeutyczne powinny być zróżnicowane, a niektóre z nich powinny przypominać naturalne środowisko pacjenta lub nawet być nim w rzeczywistości; c) więcej niż jeden terapeuta powinien ustalić procedurę warunkowania i warunki wzmacniania; d) przy wzmacnianiu reakcji terapeutycznej powinno sie stosować rozkład wzmacniania częściowego i reakcja ta powinna zostać przeuczona („overlearned”); e) część podstawowego procesu uczenia się powinna zachodzić |bez świadomości pacjenta, tak aby nie znajdowała się pod jego kontrolą poznawczą (Goldstein i in., 1966; 
Gruber, 1971).
Ograniczenia terapii behawioralnej nie powinny jednak przysłaniać jedynych w swoim rodzaju osiągnięć tego podejścia. Terapia behawioralna odniosła znaczene sukcesy, stwarza nadzieję na większe i zdaje się być najlepszą dostępną metodą leczenia obezwładniającego lęku oraz specyficznych fobii. Nie ma powodów, by oczekiwać, że terapia behawioralna będzie skuteczna w przypadku każdego zaburzenia psychicznego, tak samo, jak nie ma powodu, by oczekiwać, że penicylina wyleczy raka.
Behawiorystyczne podejście do terapii charakteryzuje się więc optymizmem, wiarą w potęgę zasad uczenia się i w postępowanie terapeutyczne oparte na badaniach naukowych, a nie jedynie na teorii, spekulacjach i analizie przypadków. Nowszy sposób podejścia zwolenników teorii uczenia się społecznego wychodzi poza twierdzenie ortodoksyjnych behawiorystów, że każde zachowanie (normalne czy anormalne) można poddać pod kontrolę środowiska. W wyniku procesu terapeutycznego można osiągnąć to, że dana osoba ma wpływ na środowisko i pewien stopień kontroli nad nim. Dzięki temu dana osoba uzyskuje poczucie kompetencji i skuteczności swego działania, a przez to przezwycięża uczucia bezsilności i wchodzi na drogę prowadzącą do szczęśliwego, bardziej produktywnego życia.




Egzystencjalno
-humanistyczne podstawy
terapii




Ruch humanistyczny zyskał sobie miano „trzeciej siły” w psychologii, ponieważ wyrósł z reakcji zarówno przeciw pesymistycznemu poglądowi na naturę ludzką, prezentowanemu przez teorię psychoanalityczną, jak i przeciw mechanistycznemu stanowisku behawioryzmu. W tym czasie, gdy w Stanach Zjednoczonych kształtował się ruch humanistyczny, podobne poglądy, które określa się łącznie jako |egzystencjalizm, zyskały już sobie akceptację na kontynencie europejskim. Egzystencjalizm był w głównej mierze wynikiem wyraźnie zaznaczającego się niezadowolenia z filozofii tradycyjnej, ocenianej jako powierzchowna, akademicka i odległa od życia (Kaufamn, 1956).
Ważnym czynnikiem, który łączy psychologię humanistyczną i egzystencjalizm, jest przyjęcie przez oba te kierunki |fenomenologii jako podstawy filozoficznej. Podstawowe twierdzenie fenomenologii głosi, że cała wiedza ludzka opiera się na doświadczeniu, stosowne zaś podejście polega w tym wypadku na utrzymywaniu „otwartości” wobec danych pochodzących z doświadczenia i gotowości przyjmowania ich, w miarę jak się pojawiają.  Obserwator stara się odłożyć na bok wszelkie ukształtowane zawczasu poglądy na daną osobę czy zjawisko, wszelkie sądy o wartości, relacjach przyczynowo-skutkowych, a nawet rozróżnienie między podmiotem a przedmiotem. W psychoterapii podejście to polega na „otwarciu się” na sprawy i osobę pacjenta i akceptowaniu go takim, jaki się nam ukazuje. To tej właśnie osobie, takiej, jaka jest w danej chwili, tu i teraz, trzeba poświęcać uwagę i troskę, zrozumieć ją i leczyć.
Termin |egzystencjalizm wywodzi się od łacińskiego słowa „existere” - „powstawać” lub „pojawić sie” - które dobrze oddaje charakterystyczne dla tego kierunku skoncentrowanie się na egzystujacej istocie ludzkiej, takiej, jaka staje się czy kształtuje. Egzystencjalizm jest próbą zrozumienia naszej jedynej w swym rodzaju pozycji we wszechświecie: naszej zdolności przeżywania uczuć miłości i nienawiści, naszego cierpienia, naszej samoświadomości oraz wiedzy o swej własnej nadciągającej nieuchronnie śmierci.
Aczkolwiek istnieją duże różnice zdań między zwolennikami tego stanowiska - co jest zgodne z wysoką rangą, jaką egzystencjalizm nadaje indywidualizmowi - to jednak pewne poglądy łączą ich. Przede wszystkim ostro krytykują oni podejście naukowe - z jego odczłowieczającą, sztywną metodologią. Każdą osobę rozpatrują nie jako jakiś statyczny byt, lecz jako ciągły proces, proces stawania się; chociaż środowisko i dziedziczność nakładają pewne ograniczenia na ten proces stawania się, to jednak zawsze zachowujemy swobodę wyboru tego, czym się staniemy (kształtujac nasze własne wartości i angażując się w nie przez nasze decyzje). Jednakże ta swoboda wyboru niesie za sobą ciężar odpowiedzialności. Ponieważ nigdy nie zdajemy sobie w pełni sprawy ze wszystkich implikacji naszych działań, doznajemy zatem uczuć lęku i rozpaczy. Przeżywamy także poczucie winy z powodu utraconych okazji pełnego zrealizowania naszych możliwości.
Powierzchowni krytycy kładą chyba nadmierny nacisk na te pozornie negacyjne aspekty egzystencjalizmu. Negatywizm ten jednak można uważać za próbę wyrwania nas z naszego zadowolenia z siebie i z konformizmu. Zachęca on nas do otwartego stawienia czoła rzeczywistości naszej własnej egzystencji, bez szukania ucieczki w systemach teistycznych czy monolitycznych, w których jakiś wyższy autorytet dyktuje nam, jak powinniśmy żyć. Wysuwa się twierdzenie, że to zmuszanie nas do tego, byśmy zdawali sobie sprawę z faktu, że jesteśmy nieustannie odpowiedzialni za to, co wybieramy i co tworzymy, stanowi jedynie antidotum przeciw rozpaczy naszych czasów.
Humanistyczne i egzystencjalne podejścia są podobne pod wieloma względami. W obu uważa się istoty ludzkie za źródło wartości i oba koncentrują swe zainteresowania na ludzkich możliwościach samorealizacji.  Oba kładą nacisk na pojęcia odpowiedzialności, wolności i zaangażowania.
Istnieje jednak kilka punktów rozbieżnych. Psychologia humanistyczna, zgodnie z duchem światopoglądu amerykańskiego, ma charakter znacznie bardziej optymistyczny i pozytywny niż europejski egzystencjalizm. Zgodnie ze stanowiskiem psychologii humanistycznej, jesteśmy nie tylko odpowiedzialni za realizację naszego potencjału, lecz posiadamy także potrzebę, by to uczynić. Zwolennicy tego stanowiska kładą również duży nacisk na wartość i godność jednostki, z czym wiąże się zainteresowanie pozytywnymi stronami życia ludzkiego, takimi jak miłość, radość, twórczość, przyjaźń, wesołość, ekstaza itd.
Gdy przechodzimy do terapeutycznych zastosowań egzystencjalizmu i psychologii humanistycznej, wówczas znajdujemy znaczne zróżnicowanie metod i stylu. Egzystencjalizm nie jest techniką, teorią czy systematycznym wyjaśnieniem ludzkiego zachowania, lecz raczej postawą, jaka zajmuje się wobec siebie i wobec innych. Możemy więc znaleźć terapeutów wyszkolonych w zakresie psychoanalizy i posługujących się takimi technikami psychoanalitycznymi, jak swobodne kojarzenie i analiza marzeń sennych, którzy jednak nazywają siebie samych psychoterapeutami egzystencjalnymi, ponieważ podzielają zasadnicze poglądy i wartości egzystencjalizmu.  Podobnie, gdy weźmiemy pod uwagę terapeutów ze szkoły Junga czy Adlera, to trudno powiedzieć, czy powinno nazywać się ich neofreudystami czy też humanistami egzystenacjalnymi, ponieważ, jak się już przekonaliśmy, zarówno Jung jak i Adler zajmowali się problemami egzystencjalnymi i obaj mieli głęboki szacunek dla integralności egzystencji jednostki.




Psychoterapia
egzystencjalna




Twórcami ruchu egzystencjalnego w psychiatrii byli europejczycy rozczarowani ortodoksyjną psychoanalizą. Zdając sobie sprawę z tego, że najbardziej powszechnym problemem współczesnego człowieka jest uczucie wyobcowania ze świata, utrata poczucia tożsamości czy przynależności, ci psychiatrzy i psychologowie byli przekonani, że psychoanaliza zaostrza problem, jeszcze bardziej „rozczłonkowując” jednostkę. Dla nich podstawową rzeczywistością było doświadczenie jednostki, a nie zdarzenia fizyczne.
Jedna ze szkół terapii egzystencjalnej, zwana |logoterapią 
(„logotherap”), koncentruje się na potrzebie dostrzegania sensu we własnym życiu. To „pragnienie sensu” uważa się za najbardziej ludzkie ze wszystkich zjawisk. Szkoła ta kładzie nacisk na stwierdzenie Nietzschego: „Ten, kto zna „Dlaczego życia”, pokona prawie każde „Jak”. Ludzie odpowiadają na pytania „Dlaczego” przez samorealizowanie się, które wiąże się zarówno ze swobodą wyboru kierunku działania, jak i z odpowiedzialnością za wybranie go w taki sposób, by rozwijać wartości duchowe. W logoterapii szczególny nacisk kładzie się na rozwój wartości duchowych i etycznych (Weisskopf-Joelson, 1955).
Logoterapia jest jedyną szkołą psychiatrii egzystencjalnej, która stworzyła specyficzne techniki psychoterapeutyczne. Jedna z tych technik, zwana |intencją |paradoksalną („paradoxical intention”), okazała się skuteczna w krótkotrwałym leczeniu pacjentów cierpiących na nerwicę natręctw (obsesyjno-kompulsywna) i fobie. Viktor Frankl, twórca logoterapii, mówi o błędnym kole, z którego nie może się wydostać osoba cierpiąca na fobię. Pacjenta nęka nie tyle obiekt czy zdarzenie budzące strach, ile |strach |przed |samym |strachem oraz potencjalnymi następstwami tego strachu, takimi jak zemdlenie czy atak serca. Frankl (1959) nazywa takie reakcje fobiczne „ucieczką przed strachem” i uważa, że pacjent reaguje na „przerażające oczekiwanie powtórzenia się danego zdarzenia”. To oczekiwanie wywołuje jednak właśnie to, czego obawia się pacjent; reakcję fobiczną. „Intencja paradoksalna” jest techniką mającą na celu uporanie się z tym antycypowanym lękiem przez zachęcanie pacjenta, „aby robił, lub chciał, aby się zdarzyło, właśnie to, czego się boi”. Istnieje wyraźne podobieństwo między tą techniką a omówioną poprzednio terapią implozyjną.  Tu jednak główna odpowiedzialność za stosowanie tej techniki spoczywa na samym pacjencie, a nie na terapeucie. Ponadto „intencję paradoksalną” rozmyślnie formułuje się w jak najbardziej humorystyczny sposób, ponieważ humor wiąże się z poczuciem pewnego zdystansowania się.
Nikt nie twierdzi, że „intencja paradoksalna”, czy nawet sama logoterapia, ma zastosowanie w przypadku wszystkich osób potrzebujących terapii ani też nie twierdzi się, że jakiekolwiek techniki tego rodzaju będą przynosić długotrwałe efekty, jeżeli dana jednostka nie zaangażuje się ponadto w realizację sensownych celów.




Psychoterapia
humanistyczna




Jednym z najwyraźniejszych i najwcześniejszych przykładów podejścia humanistycznego jest terapia |skoncentrowana |na |pacjencie („client-centred therapy”), którą w latach czterdziestych naszego stulecia stworzył Carl Rogers. Podstawową zasadę tej metody, głoszącą, że terapeuta spełnia funkcję |niedyrektywną („nondirective”) przez cały czas trwania terapii, wyjaśnia pięknie poniższy cytat z dzieł mędrca Wschodu. Lao-tse:


„Wtrącać się w życie istot, oznacza szkodzić zarówno im, jak i sobie samemu. Ten, kto narzuca siebie, posiada małą jawną moc; ten, kto nie narzuca siebie, ma wielką, tajemną moc (...). Doskonały człowiek nie wtrąca się w życie istot, nie narzuca im siebie, lecz pomaga wszystkim istotom w (osiągnięciu) wolności” (w: Buber, 1957, s. 54-55).


Terapia niedyrektywna opiera się na przesłance, że jednostki, które są wystarczająco motywowane, potrafią rozwiązać swój własny problem, jeśli mogą uwolnić się od skłonności do samooszukiwania się i od strachu - w takim stopniu, aby zdać sobie sprawę z istoty swego problemu. Zgodnie z tym, w rozmowie prowadzonej w cztery oczy zachęca się je, aby mówiły swobodnie o wszystkim, co je dręczy i aby podchodziły do tego w taki sposób, jaki chcą. Terapeuta ani nie chwali, ani nie gani, lecz akceptuje to wszystko, co zostało powiedziane, niekiedy przeformułowuje wypowiedzi pacjenta lub pomaga mu w jaśniejszym przedstawianiu (klaryfikacji) jego własnych reakcji, zwracając szczególną uwagę zarówno na uczucia wyrażane przez pacjenta na zewnątrz, jak i na uczucia wewnętrzne, których on doświadcza.
Teoria terapii niedyrektywnej głosi, że dzięki „wygadaniu się” w przyzwalającej („permissive”) atmosferze, pacjenci zdołają zrozumieć pewne związki między swymi uczuciami i zachowaniem. Terapię uważa się za „proces rozwoju”, w czasie którego pacjenci wykorzystują swe potencjalne możliwości dla osiągnięcia dojrzalszego poziomu emocjonalnego przystosowania. Od początku są oni odpowiedzialni za swe zachowanie i decyzje, jak również za przebieg terapii. W czasie terapii nie usłyszy się zdania, że „lekarz wie najlepiej”. Rola terapeuty polega na pozór na „odzwierciedlaniu” („reflecting”) uczuć wyrażanych przez pacjenta. W rzeczywistości jednak akceptacja i zainteresowanie ze strony terapeuty ma największe znaczenie, ponieważ pomaga pacjentowi w rozwinięciu poczucia pewności siebie i siły, potrzebnych do uporania się z trudnymi problemami przystosowania.
Następujący przypadek ukazuje charakter terapii niedyrektywnej, a także charakterystyczne stopniowe zmiany - od uczuć negatywnych do pozytywnych.


„Mary Jane Tilden (pseudonim), 20 lat została przyprowadzona do doradcy przez matkę. Zdawała się ona wycofywać z życia, spędzając większą część swych dni na spaniu, słuchaniu radia lub ponurych rozmyślaniach. Rzuciła pracę i zrezygnowała z wszelkich kontaktów towarzyskich; rzadko zadawała sobie nawet trud, aby się ubrać. Pierwsza rozmowa z nią miała charakter całkowicie negatywny, prócz tego, że decydowała się wrócić, by kontynuować terapię.
Panna T: „(...) kiedy porównuję siebie z innymi dziewczętami, to po prostu wydaje mi się - że nie czuję się w ogóle na siłach, by sobie z tym poradzić (...) one zdają się być tak normalne we wszystkim, co robią; rozwijały się w taki sposób, w jaki każdy powinien rozwijać się na tym świecie. A kiedy patrzę na siebie, to myślę: „No tak, do licha! Ja nawet nie umywam się do nich”. I to był po prostu taki cios, że zaczęłam po prostu zdawać sobie sprawę, iż nie szłam tak szybko tą drogą, jak powinnam - mam na myśli, że po prostu nie robiłam postępów.
Doradca: „To nie było tak, że byłaś zazdrosna, lecz że stopniowo uświadomiłaś sobie, że one były przygotowane do nowego etapu swego życia, a ty po prostu nie byłaś do niego przygotowana (...)”.
T: „(...) jest jedna rzecz, której zupełnie nie potrafię rozstrzygnąć - próbowałam przemyśleć to sobie - no tak, czym jest to - jeśli już o tym mówimy - czym jest to, czego ja naprawdę chcę? A kiedy analizuję samą siebie, nie mogę dojść, czego naprawdę chcę. Tylko, gdy przypatruję się temu, czego chcą inni ludzie, myślę: no dobrze, być może to jest to, czego chcę. To jest bardzo dziwna rzecz i to mi się nie podoba. To właśnie wzbudza we mnie uczucie - że to jest - że nie mogę robić tego, co chcę robić, ponieważ ja naprawdę nie wiem, czego chcę”.
D: „Masz poczucie, że jak dotąd, największym osiągnięciem w tym zakresie było przyjęcie celu, który zdaje się być dobry dla kogoś innego. Lecz nie masz poczucia, że istnieje jakakolwiek realna korzyść, którą z pewnością chciałabyś osiągnąć (...).
W czasie piątej rozmowy pana Tilden omawiała swe pierwsze próby polepszenia własnej sytuacji, lecz podawała wiele związanych z nimi wątpliwości. W ósmej rozmowie zaczęła patrzeć na swe zachowanie bardziej obiektywnie.
T: „(...) żyjąc w rodzinie, z której mój brat poszedł na studia i każdy ma sprawny umysł, zastanawiam się, czy to jest w porządku, że ja jestem taka, jaka jestem i że nie mogę osiągnąć tego typu rzeczy. Zawsze starałam sie być taka, jaką powinnam być zdaniem innych, lecz teraz zastanawiam się, czy nie powinnam po prostu uznać, że jestem taka, jaka jestem”.
D: „Masz poczucie, że w przeszłości żyłaś zgodnie ze standardami innych i nie jesteś pewna, co właściwie należy zrobić, lecz zaczynasz mieć poczucie, że najlepszą dla ciebie rzeczą jest po prostu zaakceptowanie siebie takiej, jaką jesteś (...)”.
T: „No tak, przypuszczam, że to jest właśnie tak. Nie rozumiem, co tak bardzo zmieniło. Tak, rozumiem. Te rozmowy dużo pomogły, a także książki, które czytałam. No tak, właśnie zauważyłam taką różnicę. Widzę, że gdy odczuwam coś, nawet gdy odczuwam nienawiść, nie przejmuje sie. Nie martwię się tym. Czuję się jakoś bardziej swobodna. Nie czuje się winna, że to czy tamto” (Rogers, 1947).


W trakcie terapii pacjentka ta dokonała znacznego postępu w lepszym poznaniu i zaakceptowaniu siebie samej, a więc i w osiągnięciu bardziej zadawalającego przystosowania do życia. Nie przyszło to od razu, były niepowodzenia i nawroty, lecz ogólny postęp był niewątpliwy. Zwróć uwagę, że doradca nigdy nie forsował sprawy, nie wprowadzał żadnych nowych idei, nie dawał rad, nie uspokajał ani nie udzielał napomnień moralnych. Starał się on jedynie odzwierciedlać i klaryfikować uczucia i postawy pacjentki w taki sposób, aby mogła ona lepiej zrozumieć siebie samą.
Może to wydać się łatwym sposobem terapii; lecz trzeba wiele opanowania, aby powstrzymać się od udzielania wskazówek czy interpretacji i narzucenia w ten sposób pacjentowi własnego systemu wartości. Wielu studentów uważa, że terapia skoncentrowana na pacjencie nie tylko wydaje się prosta w przeprowadzaniu, lecz także zbyt prostacka; w jaki sposób mogłoby pomóc coś tak bezsensownego, jak odzwierciedlenie uczuć pacjenta? Być może, w przypadku osoby, która przychodzi do terapeuty specjalnie po to, aby jej powiedział, co ma robić, zarzut ten może być słuszny, choćby dlatego, że jak stwierdzono, powodzenie terapii zależy od oczekiwań danej osoby dotyczących przebiegu terapii. Jednakże ludzie doznający stresu emocjonalnego i cierpień psychicznych odbierają te terapie nie jako zimne odzwierciedlenie przez czyste lustro, lecz jako ciepłe i niezwykle ludzkie zainteresowanie ze strony dobrego słuchacza, który wierzy, że mogą oni sobie sami pomóc.
Należy także wspomnieć, że ta nie oceniająca postawa psychiczna wobec innych nie musi ograniczać się do terapii. Wykazano, że odzwierciedlenie uczuć innych i wyrażanie swoich własnych uczuć jest bardzo skutecznym sposobem komunikowania się w wielu typach stosunków interpersonalnych (zob.  Ivey, 1971).
Ważnym aspektem terapii skoncentrowanej na pacjencie już gotowość do poddawania jej technik badaniom empirycznym i do jej modyfikowania w świetle takich doświadczeń. W rzeczywistości, Rogers był pierwszym klinicystą rejestrującym na taśmie magnetofonowej przebieg swoich posiedzeń, co doprowadziło do pierwszej doniosłej analizy procesu terapii.  Z takich badań wyłoniła się idea reagowania na emocje pacjenta i klaryfikowanie tych emocji, a nie tylko słów użytych przez niego. Podobnie, w późniejszej pracy ze schizofrenikami stwierdzono, że w przeciwieństwie do skoncentrowanego na pacjencie podejścia stosowanego wobec neurotyków, większe korzyści osiąga się wtedy, gdy terapeuta zajmuje w czasie terapii aktywną, autoekspresyjną postawę, czyniąc swe własne wewnętrzne doznania, podobnie jak doznania pacjenta, częścią procesu terapeutycznego (Meader i Rogers, 1973).
Takie przesunięcie akcentów jeszcze wyraźniej reprezentuje egzystencjalną koncepcję „spotkania interpersonalnego” („interpersonal encounter”), w czasie którego terapeuta może być sobą i ufać swoim własnym doznaniom, respektując jednocześnie wewnętrzne doznania pacjenta i pomagajac mu w ten sposób je zaakceptować. Ten sposób podejścia do pacjenta rozwinął dalej Eugene Gendlin (1973), tworząc tak zwaną |psychoterapię |uwrażliwiającą („experiential psychotherapy”), która może z powodzeniem reprezentować integrację koncepcji humanistycznych i omówionych przez nas wcześniej koncepcji egzystencjalnych.
Reasumując, stwierdzamy, że egzystencjalno-humanistyczny pogląd na naturę ludzką nie przypisuje jej żadnej podstawowej |treści, a wskazuje jedynie na pełną znaczenia egzystencję, która wpływa na to, czego się doświadcza i co się wyraża. Nie neguje się obecności irracjonalnych motywów, biologicznych popędów czy społecznego warunkowania, lecz są one czymś drugorzędnym wobec doniosłości faktu, że jednostka ma swobodę wyboru, jak się zachować. Jak sugeruje Frankl, bez względu na nakładane nam ograniczenia, zawsze mamy wolność wyboru, jak się zachować. Jak sugeruje Frankl, bez względu na nakładane nam ograniczenia, zawsze mamy wolność wyboru, co do sposobu, w jaki stawimy im czoła. Nawet w warunkach powodujących najskrajniejsze cierpienia - takich, jak zaznał sam Frankl w hitlerowskim obozie koncentracyjnym - tam gdzie egzystuje człowiek, tam możemy odkrywać sens i nowe oblicza naszego istnienia.




Ocena efektywności
psychoterapii




Teoretyczne stanowisko terapeuty wpływa na jego zasadnicze nastawienie w stosunku do natury „problemu” - czy jest to „choroba psychiczna”, „konflikt emocjonalny”, „niewłaściwe warunki wzmacniania” czy też „alienacja swego ja” („self-alienation”). Każdy terapeuta jest więc nastawiony na interpretowanie danego zjawiska z zakresu zachowania w kategoriach, które są zgodne czy harmonijne z zasadniczymi założeniami danego teoretycznego układu odniesienia - ignorując jednocześnie inne możliwości.
Podobnie jak dentysta nie leczy zaburzeń jelitowych ani internista nie leczy chorych zębów, tak samo psychoterapeuta leczy tylko tych pacjentów, których „problemy” |pasują do jego specyficznego przygotowania. Ponieważ jednak wskaźnikami „problemów” psychologicznych są zjawiska behawioralne, których nie można tak zręcznie skategoryzować, wyodrębnić i obiektywnie ocenić, jak problemów medycznych, przeto różni terapeuci leczą ten sam ujawniający się problem zgodnie ze swym sposobem |spostrzegania jego źródeł.
Pacjenci muszą zatem zawierać milczącą umowę z |określonym terapeutą, zgadzając się być „chorym” w taki sposób, jaki potrafi leczyć dany terapeuta. Można powiedzieć, że pierwszym zadaniem pacjenta jest nauczyć się odgrywać poprawnie swoją rolę w scenariuszu terapeuty. Wymaga to, by nauczyć się posługiwania specjalnym językiem terapeuty przy opisywaniu objawów i minionych wydarzeń. Może to również wymagać pewnego rodzaju „nawrócenia się” na system przekonań terapeuty, co umożliwi pacjentowi spostrzeganie i określanie jako „ważne” i „istotne” tych samych zdarzeń i zmiennych, które spostrzega i określa w ten sposób terapeuta.
Rozumując w ten sposób, niektórzy krytycy wysuwają zarzut, że terapeuci są „przekonywaczami” („persuaders”), którzy wpajają swój światopogląd i teorie zachowania swoim pacjentom (Frank, 1961). Pacjenci mogą być uznawani za „wyleczonych”, gdy zmienią swoje oryginalne przekonania i wartości na te przekonania i wartości, które terapeuta akceptuje jako rozsądne i słuszne - lub gdy przynajmniej mówią tak, jak gdyby to uczynili.
Pacjent psychoanalityka staje się zatem „historykiem” wykrywającym historyczne precedensy i historyczną ciągłość, która wiąże obecne objawy z ich dawnymi przyczynami. Pacjent behawiorysty staje się uwrażliwiony na przyszłe konsekwencje środowiskowe swoich obecnych reakcji behawioralnych i skłonny jest wiązać jakieś S z każdym R, i jakiejś R z każdym S.  Samorealizujący się pacjent wyłania się z egzystencjalno-humanistycznej terapii skoncentrowany na teraźniejszości, na „tu i teraz” istnienia, bycia i stawania się, przy czym mówi on o współuczestniczeniu, sensie, wyborze i wolności. I wreszcie osoba leczona przez terapeutę o orientacji biologicznej wychodzi po „skutecznym” leczeniu z postawą, że „lekarz wie najlepiej” i z małym poczuciem odpowiedzialności za „problem” lub jego zlikwidowanie.




Komu przypisać
zasługę za wyleczenie?




„Nerwicę leczy się za pomocą Christian Science (system uzdrawiania stosowany przez sektę religijną o tej samej nazwie - przyp. tłum.) za pomocą osteopatii, kręgarstwa, środków wymiotnych i uspokajających, benzedryny (psychedryny), zmiany miejsca pobytu, uderzania w głowę i psychoanalizy, co prawdopodobnie oznacza, że żaden z tych środków nie dowiódł dotąd swej rzeczywistej wartości w tym zakresie (...). Co więcej, ponieważ wiele objawów nerwicy cofa się samorzutnie, każdemu, kto spędził dwa lata z pacjentem, przypisuje się zasługę za to, co jest wynikiem działania natury (Myerson, 1939, s. 641).


Tę krytykę psychoterapii rozwinęli ci badacze, którzy sugerują że u niektórych pacjentów następuje poprawa nawet wtedy, gdy dokonuje się „niedokładnych interpretacji” - to jest gdy stawia się niepoprawne diagnozy (Glover, 1966). Być może, iż decydującym elementem jest to, że ktoś mający autorytet podaje |jakąkolwiek interpretację, co wskazuje, że problemypacjenta są zrozumiałe dla kogoś, kto ma możliwość udzielenia pomocy. Być może, to nie treść różnych teoretycznych wyjaśnień pomaga zatem pacjentowi, lecz fakt, że szanowany, normalny przedstawiciel społeczeństwa uznaje, iż problem pacjenta „ma sens” i może zostać wyleczony. Jest coś bardzo pocieszającego w świadomości, że dla tego, co nas dręczy, istnieje jakaś nazwa i że istnieją inni ludzie, którzy są lub byli kiedyś w podobnym stanie.
Nie ma żadnych dostępnych danych, które sugerowałyby, że jakąś określoną formę terapii można uznać za bardziej skuteczną od innych. Istnieje nieco materiałów dowodowych potwierdzających w istocie wniosek, że żadna z form terapii nie jest |w |ogóle bardziej efektywna od którejkolwiek innej i że w sumie nie są one lepsze niż brak terapii w ogóle! Jest jednak również prawdą, że niektórym jednostkom, mającym określonego rodzaju problemy, najlepiej może pomóc określony rodzaj terapii i terapeuty i że bez żadnej terapii stan ich pogorszyłby się.
W swej analizie niepowodzeń terapeutycznych Richard Stuart (1970) doszedł do wniosku na podstawie swego przeglądu 21 badań, iż „można powiedzieć, że osoby rozpoczynające psychoterapię mają umiarkowane szanse na znaczną poprawę, znacznie większe szanse na niewielką lub żadną zmianę oraz umiarkowane szanse na pogorszenie swego funkcjonowania” (s. 50).


Brytyjski psycholog Hans Eysenck zrobił przed laty furorę (1952) podając, że u osób nie poddanych żadnej terapii stwierdzono wyższy wskaźnik wyleczeń niż u tych, które poddano albo psychoanalizie, albo terapii elektycznej (kombinacja różnych sposobów leczenia). Późniejsze badania, w których usunięto niektóre niedociągnięcia, jakie wytknięto w badaniach Eysencka, wykazały, iż wniosek ten był trochę przesadzony, lecz niedaleki od prawdy. Stwierdzono, że brak terapii jest |równie |dobry, jak psychoterapia (Bergin, 1966). W siedmiu badaniach, w których porównywano zmiany u osób nie leczonych ze zmianami, jakie wystąpiły u osób poddanych psychoterapii, |przeciętna wielkość zmian była taka sama. Jednakże |zmienność wyników była większa wśród tych, których poddano terapii: u niektórych nastąpiła znaczna poprawa, podczas gdy u innych nastąpiło pogorszenie lub zmiany nie wystąpiły. Te osoby, u których podczas terapii nastąpiła znaczna poprawa, mogły nie osiągnąć tego stanu bez niej, a więc w ich przypadku pychoterapii należy przypisać zasługę za ich „wyleczenie”. U innych sam upływ czasu wystarczył do „wyleczenia wszystkich ran”.
W jakim stopniu pacjenci spostrzegają, że sami są zaangażowani w terapię i podzielają odpowiedzialność za osiągnięcie poprawy własnego funkcjonowania? To pytanie, pozostające dotychczas bez odpowiedzi, zasługuje na zbadanie, jeśli bowiem całą zasługę przypisuje się terapeucie lub określonej terapii, to pacjenci będą zmuszeni powracać na leczenie, gdy podobne problemy pojawiają sie w przyszłości. Może to być po części wyjaśnieniem wysokiego wskaźnika „nawrotów” wielu zaburzeń psychicznych.
Dobrze jest również postawić pytanie, kogo (jeśli w ogóle kogoś) powinno się obciążyć odpowiedzialnością za tych pacjentów, których stan po terapii pogorszył się. Czy jest możliwe, aby terapeuci, podobnie jak to czynią niektórzy chirurdzy, mogli powiedzieć, że operacja (terapia) udała się, mimo że pacjent zmarł (jego stan psychiczny pogorszył się)? Kiedy terapia nie pomaga, to czy ta negatywna informacja jest wykorzystywana konstruktywnie w celu zmienienia procedury terapeutycznej lub pewnych elementów teorii, tak aby funkcjonowały lepiej w przyszłości? Nie zbierano dotąd w systematyczny sposób danych potwierdzających taki punkt widzenia.  Można by raczej podejrzewać, że każdy przypadek braku poprawy („non cure”) jest porażką dla terapeuty, który woli zapomnieć o niej lub wyjaśnić ją w kategoriach działania czynników nie podlegających kontroli terapeutycznej.




Zbliżenie


Jeden uśmiech terapeuty wart jest tysiąca słów


„Badania wykazały, że wielkość korzystnych zmian u pacjenta jest skorelowana pozytywnie z: a) doświadczeniem terapeuty, b) stopniem jego pewności siebie, oraz c) jego podobieństwem do pacjenta (Stuart, 1970).  Wykazano, że niezdolność terapeuty do otwartego okazania pacjentowi dostatecznego stopnia empatii i zrozumienia prowadzi do pogorszenia się stanu pacjenta (Truax, 1963).
Czy terapeuci powinni ukrywać swe uczucia przed pacjentami, czy też je ujawniać? Freud głosił, że terapeuta powinien „być nieprzenikniony dla pacjenta i jak zwierciadło odbijać tylko to, co mu ujawniono” (1956, s.  331). Zalecał on psychoterapeutom, aby za swój wzór wzięli „chirurga, który odkłada na bok wszystkie swoje własne uczucia, z ludzkim współczuciem włącznie, i skupia intelekt na jednym tylko celu - przeprowadzeniu operacji tak umiejętnie, jak tylko jest to możliwe” (s. 327).
Dla współczesnego terapeuty taki wzór nie może być ideałem, zwłaszcza w pracy z dzisiejszymi młodymi ludźmi, którzy nie chcą współdziałać z wyniosłym autorytarnym chirurgiem w ubraniu terapeuty. Wskazuje się, że „ważniejsze jest nie tyle przygotowanie terapeuty i to, co robi on jako terapeuta, lecz przede wszystkim jego zdolność, by być ludzkim” (Dreyfus, 1967, s. 537). „Człowieczeństwo” terapeuty wykracza poza |zdolność do podtrzymywania uprzejmości i serdeczności; wymaga ono dzielenia z pacjentem tego, co odczuwa terapeuta, czy to będzie rozpacz, smutek, radość, gniew czy poczucie winy.
Każdy uczestnik relacji pacjent-terapeuta musi coś dawać i coś brać. W żydowskiej ortodoksyjnej sekcie Hasydów rola duchowego przywódcy i nauczyciela, zwanego cadykiem, polegała nie tylko na przekazywaniu wiedzy lecz sprzyjała także ukształtowaniu się ścisłej, osobistej więzi między uczniem a nauczycielem. Kopp (1969) wysunął sugestię, że współcześni terapeuci mogliby wiele skorzystać przyjmując podwójną rolę cadyka.
Zamieszczony poniżej fragment zapisu z sesji terapii grupowej świadczy o doniosłym wpływie, jaki ma autentyczność terapeuty. Grupa omawiała fakt nalegania przez terapeutkę na punktualne zakończenie sesji jako oznaki, że nie dba ona o nich. Bob, który brał także udział w terapii indywidualnej u innej terapeutki, przerwał dyskusję, aby powiedzieć, dlaczego jego zdaniem indywidualna terapeutka troszczy się o niego:


Bob: „Ona naprawdę troszczy się o mnie, bo przeciągamy posiedzenia.  Czasami trwają one godzinę lub godzinę i piętnaście minut. Gdy ona kończy nasze posiedzenia, to nigdy nie mam poczucia, że mi przerwała. Gdy ty przerwałaś posiedzenia - byłem zaskoczony... Myślę, że ona angażuje się...  Myślę że jej zależy”.
Carol: „Gdy mówisz o jej zaangażowaniu, czy masz na myśli to, że ona troszczy się o ciebie?
Bob: „Potrzebuję tego, żeby ktoś troszczył się o mnie. Przechodziłem przez coś niedobrego, naprawdę niedobrego, a ona płakała nade mną. To było coś najwspanialszego, co kiedykolwiek mi się zdarzyło. Nikt nigdy nie miał dla mnie łez” (Rustin, 1970 s. 47).


Możliwe, że gdyby terapeuci pozwalali sobie na przeżywanie i wyrażanie swych uczuć podczas terapii, to rezultat byłby równie korzystny dla nich osobiście, jak i dla pacjentów. Model terapii otwartej na „obojętnym zainteresowaniu” ułatwia może zapracowanemu terapeucie dotrwanie do końca dnia, zapełnionego wysłuchiwaniem problemów innych ludzi, pamiętajmy jednak, że wskaźnik samobójstw wśród psychiatrów jest niezwykle wysoki.  Uśmiech i łzy im także mogłyby dobrze zrobić”.




Ocena powodzenia terapii




Wydaje się oczywiste, że terapeuci nie są najlepszymi sędziami swych własnych sukcesów. Chcą oni uważać siebie za kompetentnych, a swe działania - za efektywne. Poza skłonnością, by widzieć to, co chcą zobaczyć, mogą oni sztucznie powiększać swój „wskaźnik wyleczeń”, zachęcając nieświadomie trudnych pacjentów do przerwania terapii lub stosując mgliste kryteria wyleczenia. Lecz rodzice lub przyjaciele, którzy chcą dostrzec poprawę u pacjenta, również mogą być skłonni ją „widzieć”, a pacjenci, którzy chcą sprawić przyjemność swemu terapeucie, będą podawać, iż czują, iż terapia im pomogła. Kto może być dostatecznie bliski danej jednostce, aby ocenić, co naprawdę z nią się stało, a jednocześnie wystarczająco obiektywny, aby uniknąć tendencyjności? Jest to zawiły, nie rozwiązany problem.
Zmiany będące wynikiem terapii ocenia się zwykle różnymi sposobami, takimi jak: a) ogólne wrażenia terapeuty dotyczące zmian, b) wyniki testów osobowości, c) zachowanie pacjenta w czasie wywiadu, d) sprawozdania przyjaciół lub krewnych, e) sprawozdania pacjenta o sobie samym, f) postawy pacjenta, oraz g) wybrane, obserwowalne zachowania pacjenta. Lecz zmiany w postawach werbalnych nie są wysoko skorelowane ze zmianami w zachowaniu rzeczywistym, a zachowanie w czasie wywiadu lub wynik testu osobowości nie musi być trafnym predyktorem tego, jak dana jednostka zachowa się w innych sytuacjach. Jakim miarom można ufać? W dodatku stan tego samego pacjenta można ocenić jako wskazujący poprawę lub nie wskazujący jej, zależnie od użytych kryteriów.


„Pewien hospitalizowany pacjent, który nie chciał jadać wraz z innymi w grupie, zaczął umieszczać na swej tacy dwie do czterech butelek mleka i wypijał je w towarzystwie innych pacjentów. Terapeuta uznał to zachowanie za oznakę poprawy, natomiast konsultant psychiatryczny utrzymywał, że jest to objaw regresji do poziomu niemowlęcia” (Luchins, 1960).


Niezależnie od zastosowanych miar, treść, na którą zwraca się uwagę (oczekiwany rodzaj zmiany), zwykle odpowiada temu, co dany terapeuta stara się osiągnąć, czy to będzie lepszy wygląd, usunięcie szkodliwego nawyku, pewność siebie, samorealizacja, czy cokolwiek innego. Cele danej sekwencji terapeutycznej są determinowane po części przez koncepcję terapeuty, częściowo przez potrzeby pacjenta, a częściowo przez czas i koszty, jakie wchodzą w grę. „Powodzenie”, polegające na uczynieniu pacjenta łatwiejszym do pokierowania, nie jest bynajmniej tym samym, co „powodzenie”, polegające na umożliwieniu danej osobie, by stała się samodzielnie kierującym sobą odpowiedzialnym obywatelem. Nawet w przypadku obiektywnego, nietendencyjnego sędziego, uzyskiwane odpowiedzi będą zatem uzależnione od sposobu, w jaki uprzednio odpowiedziało się na mnóstwo pytań o charakterze definicyjnym i proceduralnym.
Jeszcze innym problemem w ocenianiu efektów terapii jest brak odpowiednich środków kontroli. Do niedawna terapeuci na ogół zakładali, że ich wysiłki nie są daremne, ponieważ obserwowali poprawę w części leczonych przez siebie przypadków. Błąd w tym rozumowaniu polega na nieuwzględnieniu jednego z podstawowych wymagań schematu badawczego, jaki ma zastosowanie do wszelkich badań oceniających: mianowicie, konieczności wprowadzenia odpowiednich środków kontroli i grup kontrolnych. Jeśli bowiem stan ludzi często poprawia się bez żadnego formalnego leczenia w ogóle, to nie wiemy, czy określona terapia była podstawową zmienną przyczynową w danej grupie wyleczeń.
Rozwiązywanie problemu oceny skuteczności danej terapii jest takie samo, jak w wypadku ustalenia wpływu każdej innej zmiennej eksperymentalnej. Jak dużą zmianę można przypisywać terapii? W tym celu należy określić |podstawowy |poziom zmian w nie leczonej grupie kontrolnej i porównać z nim zmiany, jakie wystąpiły w grupie poddanej kontroli. Terapeuta, który jest przekonany, że określona forma leczenia przynosi rezultaty, nie będzie chętnie przydzielał cierpiących ludzi do grup kontrolnych. Jednakże bez stosowania odpowiednich środków kontroli nie można się będzie upewnić, że to terapia była przyczyną poprawy; być może pacjenci wyzdrowieli po prostu z upływem czasu.
Są to wszystko powody, dla których niewiele wiemy o rzeczywistym wpływie różnych terapii na różne jednostki i na różne rodzaje problemów. Jednakże potrzeba nam nie tylko obiektywnych, ścisłych, wyraźnie sformułowanych |kryteriów |efektywności |terapii; jedną z najpilniejszych potrzeb, jakie stoją przed psychologią kliniczną i psychiatrią, jest również przeprowadzenie dobrze kontrolowanych |badań |oceniających, w których zastosowano by niezależną procedurę oceniania.




Grupy terapeutyczne




Formalną psychoterapię przeprowadza się na ogół albo indywidualnie, albo grupowo. W psychoterapii indywidualnej interakcja ogranicza się do terapeuty i osoby, która zgłosiła się w celu wzięcia udziału w terapii.  Tego rodzaju indywidualne metody terapii są krytykowane ze względu na ograniczone zastosowanie, ekskluzywność i wątpliwą skuteczność. Każda terapia, która wymaga specjalnych technik, stosowanych indywidualnie przez długi czas przez terapeutów o wysokich kwalifikacjach zawodowych, ma z konieczności ograniczoną użyteczność. Szkolenie terapeutów jest długotrwałe i kosztowne oraz wymaga z kolei licznego zespołu wysoko kwalifikowanych wykładowców. Warunek ten minimalizuje liczbę pracujących terapeutów.  Ponadto wszystkie opisane powyżej rodzaje terapii wymagają szczególnej wrażliwości i złożonych umiejętności intelektualnych ze strony terapeuty.  Wymagania te są przyczyną nieuchronnych i znacznych różnic pod względem efektywności oddziaływania - nawet w przypadku terapeutów, którzy stosują ten sam sposób podejścia. Nie jest też jasne, w jakim stopniu oczekiwania terapeuty skłaniają pacjenta do odkrywania w sobie tego, co jest zgodne z teorią terapeuty. Nawet w terapii niedyrektywnej trudno jest terapeucie nie nawiązywać z pacjentem interakcji, podczas której dostarcza mu on subtelnych wzmocnień za posuwanie się w kierunku tego, co niezależne od rodzaju kryteriów stosowanych przez terapeutę, stanowiłoby „poprawę” czy „wyleczenie”.
Konwencjonalne rodzaje psychoterapii są niedostępne lub nieskuteczne w odniesieniu do wielu kategorii populacji: ludzi ubogich, nie wykształconych, nieinteligentnych, nie znających języka, jak również narkomanów, psychopatów i psychotyków. Co więcej, osoby, które ukończyły terapię tworzą jeszcze bardziej ekskluzywną grupę, ponieważ około 60% osób zgłaszających się do psychoterapeutów przerywa leczenie po kilku wstępnych wizytach (Kirtner, Cartwright, 1958).
I wreszcie, niektórzy krytycy sugerują, że psychoterapia jest dla ludzi kosztownym sposobem kupowania czasowej przyjaźni (Schofield, 1964).  Badanie ukazujące „siłę przyjaźni studenckiej” sugeruje, że ten aspekt przyjaźni może być dla wielu pacjentów decydującym elementem skutecznej terapii. U pacjentów psychotycznych, którzy przez 5 miesięcy byli leczeni przez niewyszkolonych i niedoświadczonych studentów college’u, nastąpiła większa poprawa niż u podobnych pacjentów, którzy nie byli w ogóle leczeni lub którzy brali udział w terapii grupowej prowadzonej przez psychiatrę lub psychiatrycznego asystenta społecznego (Posner, 1966).
Tego rodzaju krytyka i nowe osiągnięcia w tej dziedzinie odegrały pozytywną rolę, przyczyniając się do zwrócenia większej uwagi na terapię grupową, bardziej praktyczne, krótkotrwałe szkolenie terapeutów, terapię dla ludzi „dyskryminowanych” oraz rewizję założeń i celów psychoterapii, jak również leżących u jej podstaw wartości. Niemniej jednak, pomimo tych zarzutów, indywidualna psychoterapia może nadal być najlepszym sposobem leczenia pewnych ludzi określonymi problemami, gdy jest przeprowadzana przez spostrzegawczego i wrażliwego terapeutę.
Przed II wojna światową formalna psychoterapia była prowadzona niemal wyłącznie jako terapia indywidualna. W związku z rosnącym zapotrzebowaniem na kwalifikowanych terapeutę i koniecznością przeprowadzania treningu wielu małych grup (załóg bombowców, łodzi podwodnych itd.), w czasie wojny i po wojnie nastąpił wzrost zainteresowania pracą z grupami. Psychoterapia grupowa szybko zyskała sobie popularność, gdy stało się oczywiste, że ostrzeżenia Freuda, dotyczące niebezpieczeństw towarzyszących nieodłącznie pracy z grupami, były nieuzasadnione. Wielu specjalistów uważa w istocie, że praca w grupach ma pod wieloma względami większe zalety niż terapia indywidualna.




Terapia grupowa




Terapia grupowa pozwala biorącemu w niej udział człowiekowi przekonać się, że inni też mają podobne problemy oraz zapewnia mu „bezpieczne” środowisko, w którym możne on badać swe prawdziwe uczucia.
W badaniach przeprowadzonych w jednym z oddziałów wielkiego neuropychiatrycznego szpitala Veterans Administration dokonano porównania terapii grupowej i indywidualnej.


„Obserwowano cztery grupy pacjentów, przy czym w każdej grupie znajdowała się równa liczba niepsychotyków, psychotyków, u których zaburzenia wystąpiły stosunkowo niedawno, oraz psychotyków, u których zaburzenia występowały przez dłuższy czas. W jednej z grup praca i tryb życia, jak również psychoterapia, miały charakter grupowy. Druga grupa brała udział w terapii grupowej, lecz poszczególne osoby otrzymywały indywidualne zadania w pracy, wreszcie w trzeciej grupie psychoterapia była indywidualna, podobnie jak zadania w pracy. Czwarta grupa była grupą kontrolną: wyznaczono w niej pacjentom zwykłą rutynową indywidualną pracę, tak jak wszystkim pacjentom na tym oddziale, lecz nie poddawano ich żadnej terapii.
Niezbędny czas leczenia był najkrótszy w przypadku pacjentów biorących udział w terapii grupowej, najdłuższy zaś - w przypadku pacjentów uczestniczących w terapii indywidualnej. Późniejsze ich przystosowanie było równie dobre, bez względu na to, w jakiego rodzaju terapii brali udział i czy brali środki uspokajające, czy też nie. Dodatkowe badania, w którym zastosowano kryterium wykonywania pracy zarobkowej po zwolnieniach ze szpitala, wykazały, że wszystkie trzy grupy uczestniczące w terapii istotnie przewyższały pod tym względem grupę kontrolną, przy czym w pierwszej i trzeciej grupie był najwyższy procent osób zatrudnionych w pełnym wymiarze godzin” (Fairweather i in., 1960)
Niektóre osoby zdają się czerpać mniej korzyści niż inne z terapii grupowej, a często nawet czwarta lub trzecia część członków grupy odpada przed zakończeniem terapii. Poszukując wyjaśnienia tego zjawiska, psychologowie zidentyfikowali trzy cechy osobowości, które zdają się umożliwiać danej osobie czerpanie maksymalnych korzyści z terapii grupowej (przeciwstawionej terapii indywidualnej). Są to: chęć kształtowania relacji z innymi na poziomie emocjonalnym, zdolność wyrażania, a nie tłumaczenia gniewu oraz elastyczny stosunek do autorytetu.


„Trzydzieści dwie pielęgniarki psychiatryczne i asystentki pielęgniarek zgłosiły się dobrowolnie, by wziąć udział w serii posiedzeń grupowych, mających dopomóc im w pracy przez uzyskanie lepszego wglądu w swe własne emocje. Najpierw obserwowano je podczas wywiadu, mającego na celu ocenę wspomnianych trzech cech osobowości. W przypadku każdej osoby badanej ustalono pewien wskaźnik dla każdej osoby badanej ustalono pewien wskaźnik dla każdej z tych trzech cech. Pod koniec 15-tygodniowego kursu każdą uczestniczkę zapytano o jej pozytywne lub negatywne reakcje wobec kursu.  Reakcje pielęgniarek skłonnych do „zamykania się” emocjonalnego (bardzo ostrożnych w nawiązywaniu z innymi stosunków na poziomie emocjonalnym) były mniej przychylne niż pozostałych osób (różnica istotna statystycznie).  Stwierdzono także istotne związki między wskaźnikami dla pozostałych dwóch cech osobowości i stopniem zadowolenia z wyników kursu. 
Ponadto grupa utworzona ze specjalnie dobranych pielęgniarek (o wysokich wskaźnikach dla tych trzech cech osobowości) odniosła nieprzeciętne korzyści z posiedzeń terapeutycznych” (Gruen, 1966).


Trzeba podkreślić, że osoby, u których wspomniane wyżej trzy cechy, sprzyjające skuteczności terapii grupowej, są znacznie lepiej rozwinięte, nie muszą być w ogóle lepiej przystosowane od innych. Nieraz są one neurotyczne pod innymi względami, podczas gdy jednostki „zamknięte” emocjonalnie mogą mieć osobowość w znacznym stopniu zintegrowaną.




Grupy uwrażliwiające




W latach sześćdziesiątych nastąpił w Stanach Zjednoczonych gwałtowny wzrost liczby grup stawiających sobie cele natury psychologicznej. Kurt Back (1974), analizując ewolucję działalności małych grup, uznał to zjawisko za charakterystyczne dla ruchu społecznego w Stanach Zjednoczonych, a nie jedynie za nowy kierunek w obrębie samej psychologii.  Niezależnie od przyczyn, ewolucja tych różnic zwanych „grup treningu wrażliwości” („T-groups”) „grup rozwoju osobowego” („personal growth groups”) lub, bardziej ogólnie, „grup spotkaniowych” („encounter groups”) wywiera głęboki i zapewne trwały wpływ na nasze społeczeństwo.
Podstawowym celem grup spotkaniowych jest dostarczenie uczestnikom intensywnych doświadczeń interpersonalnych w małej grupie, związanych przede wszystkim z interakcjami i uczuciami, które ujawniają się w takiej grupie, w atmosferze sprzyjającej otwartości, szczerości, wrażliwości emocjonalnej i swobodnej ekspresji. Duże znaczenie mają więc szybko dostarczane i szczere informacje zwrotne. Członek grupy otrzymuje zwykle wiele zachęt i ciepłych uczuć ze względu na swe cechy, które inni członkowie grupy uważają za dobre, oraz poddawany jest niedwuznacznej krytyce z powodu cech uważanych za złe. Prowadzący grupę może stosować podejście kierujące („dyrektywne”) lub niekierujące („niedyrektywne”).
|Grupy |spotkaniowe, w postaci „|grup|T”, zostały wprowadzone ponad 20 lat temu w Bethel, w stanie Maine, w National Training Laboratories (Narodowych Laboratoriach Szkoleniowych), przez zwolenników tego sposobu podejścia do zagadnień psychologii społecznej, który określa się jako dynamikę grup; celem ich było rozwijanie umiejętności współdziałania w grupie i zdolności przywódczych. Specyficzny układ warunków społecznych, w jakim żyje obecne pokolenie Amerykanów, spowodował jednak, że ruch grup spotkaniowych zyskał sobie dużą popularność, czyniąc jednocześnie swym zasadniczym celem bardziej ogólny rozwój osobowości. Wiele osób odczuwa brak bliskiego związku z innymi ludźmi, brak jakiejkolwiek bliskiej im społeczności. Ruchliwość geograficzna i zawodowa, nietrwałość rodziny, zanik rodzin wielopokoleniowych, w których wielu krewnych mieszkało tuż obok siebie, anonimowość i bezosobowość narzucana przez masowe kształcenie, masową komunikację, masowe środki przekazu oraz ogromne osiedla mieszkaniowe - wszystko to przyczynia się do poczucia izolacji jednostki.  Grupy spotkaniowe stwarzają sposobność do ukształtowania intymnej więzi z innymi ludźmi - chociaż ograniczonej w czasie i bez zobowiązań co do trwałości.
Oprócz doświadczeń społeczno-emocjonalnych grupy spotkaniowe dostarczają także okazji do społecznych porównań siebie samego ze swymi rówieśnikami.  Dla wielu osób wstępujących do grupy spotkaniowej „ukryty porządek dzienny” zaczyna się od takich oto zagadnień: „Czy jestem osobą, którą można zaakceptować? Czy mogę być kochany, pożądany? Czy jestem tyle samo wart, co inni ludzie?”.
Ponieważ grupy te istotnie zaspokajają pewną odczuwaną powszechnie potrzebę, przeto gwałtownemu wzrostowi liczby grup spotkaniowych w miasteczkach uniwersyteckich na terenie całych Stanów Zjednoczonych towarzyszyło coraz powszechniejsze posługiwanie się nimi przez organizacje obywatelskie, przemysłowe i kościelne. W tych środowiskach nie uważa się ich za metodę terapii przydatnej dla chorych, lecz za źródło pouczających doświadczeń dla osób „z problemami”, jak również dla wszystkich tych, którzy chcą „rozwinąć się” - nauczyć się czerpać więcej radości z życia, poznać samego siebie, a może dokonać rewizji uznawanych przez siebie wartości i własnego stylu życia.
Gdy weźmiemy pod uwagę, jak bardzo się”maskujemy”, ile mamy różnych twarzy, jak powszechna jest tendencja do ukrywania swoich prawdziwych reakcji, to nie ulega wątpliwości, że szczere, grupowe „sondowanie” w atmosferze otwartości może być ważnym, pouczającym doświadczeniem.  Członkowie grupy mogą stać się bardziej otwarci na nowe idee i doświadczenia, bardziej świadomi swych własnych potrzeb i uczuć oraz bardziej wrażliwi na potrzeby i uczucia innych ludzi. Mogą oni także zacząć lepiej rozumieć źródła swych reakcji na zachowanie innych osób oraz powody, dla których one tak, a nie inaczej, reagują na nich; i wreszcie mogą zacząć kształtować bardziej szczere i uczciwe stosunki z innymi ludźmi.




Zbliżenie


Wybór typu grupy uwrażliwiającej


„Przy ustaleniu, do jakiego rodzaju grupy się przyłączyć, najważniejszym czynnikiem, jaki powinno się brać pod uwagę, są powody, dla których pragniesz uczestniczyć w zajęciach grupy. W zasadzie są trzy typy „grup uwrażliwiających” („experiential groups”), chociaż różnice między nimi nie są wyraźne i zależą w dużym stopniu od osoby prowadzącej grupę (zob. Lakin, 1972).
Pierwszy typ grupy jest przeznaczony dla ludzi pragnących dokonać w sobie pewnej natychmiastowej zmiany.


Są oni na przykład samotni i czują się niezdolni do ukształtowania więzi emocjonalnej z innymi osobami lub poszukują pomocy z powodu jakichś napięć natury emocjonalnej. Osoby takie oczekują oczywiście, że grupa będzie spełniać funkcje terapeutyczne, powinny więc zasięgnąć porady zawodowego terapeuty, aby wskazał im grupę o wyraźnie określonych celach terapeutycznych.
Grupy należące do drugiego typu można uważać za grupy rekreacyjne, w których można ćwiczyć zdolność ekspresji emocjonalnej i eksperymentować z różnymi sposobami zachowania się i spostrzegania. Grupy takie przeznaczone są dla ludzi, którzy są już dostatecznie sprawni i kompetentni, i uczestnictwo w grupie nie jest im potrzebne dla celów korekcyjnych. Funkcje takie spełniają zazwyczaj „grupy spotkaniowe” czy „grupy rozwoju osobowego”, o których można uzyskać informację za pośrednictwem miejscowego kościoła, szkoły lub „ośrodka rozwoju” („growth center”).
W grupach trzeciego typu kładzie się szczególny nacisk na uczenie się.  Uczestnictwo w nich wskazane jest dla osób pragnących zrozumieć, jak grupy funkcjonują i rozwijają się, w jaki sposób grupa wpływa na swych członków i jak różne czynniki hamują lub ułatwiają funkcjonowanie grupy i komunikowanie się w niej. Na problemach tych koncentrują się „grupy T”, czyli grupy treningu wrażliwości, informacji zaś o rozmieszczeniu takich grup w Stanach Zjednoczonych mogą dostarczyć National Training Laboratories w Bethel (stan Maine) lub Western Training Laboratory w Lake Arrowhead (stan Kalifornia).
Po ustaleniu, do jakiego rodzaju grupy chcesz wstąpić i po znalezieniu takich grup w twoim regionie, następnym twoim krokiem będzie skontaktowanie się z osobą prowadzącą grupę. Najlepiej jest porozmawiać z nią osobiście, lecz rozmowa telefoniczna też spełni swe zadanie. Najpierw trzeba zbadać, czy twoje cele i oczekiwania są zgodne z celami i oczekiwaniami osoby prowadzącej. Po drugie, będziesz chciał uzyskać nieco informacji o jej kwalifikacjach. Proste pytanie, takie jak: „Od jak dawna prowadzi Pan(i) zajęcia w grupach?” lub „Jak to się stało, że zaczął Pan(i) prowadzić zajęcia w grupach?”, powinno wystarczyć. Jeśli twój rozmówca zdaje się przyjmować postawę obronną lub nie odpowiada na to pytanie, to poszukaj innej grupy. Następny krok polega na wzięciu udziału w spotkaniu grupy.  Jeśli postępowanie osoby prowadzącej lub reakcje członków grupy w trakcie tego spotkania zaniepokoją cię, to poszukaj innej grupy.
Następne sprawa, o której trzeba pamiętać: nigdy nie pozwól, by zmuszono cię do zrobienia czegoś, czego nie chcesz zrobić. Może to wymagać znacznego wysiłku, ponieważ grupa potrafi wywierać niewiarygodny wprost nacisk.  Pamiętaj, że przede wszystkim masz obowiązki wobec |siebie |samego, a nie wobec osoby prowadzącej czy grupy; jeśli czujesz się przymuszany i nie potrafisz dać sobie rady z tą sytuacją, to najlepiej będzie, jeśli opuścisz grupę, mówiąc prowadzącemu, dlaczego to robisz. Jeśli nie otrzymasz gwarancji, które cię zadowolą, to nie wracaj.
Niektórzy ludzie nie zgodziliby się z tą radą, że powinieneś pozostać z grupą i wytrwać do końca, i że niekiedy konieczny jest przymus, aby zacząć robić coś inaczej niż dotąd. Być może - lecz w takich grupach łatwiej można zostać „poszkodowanym psychicznie”. Zapytaj sam siebie, ile gotów jesteś zapłacić (swą własną równowagą psychiczną) za czyjeś słabo ugruntowane teorie rozwoju osobowości. Chodzi o to, że można ryzykować, lecz tylko wtedy, gdy czujesz się przygotowany do podjęcia ryzyka. Mimo całego nacisku, jaki kładziemy tu na zachowanie ostrożności, urazy psychiczne są wyjątkiem, a nie regułą. Większość członków grup uważa doświadczenia uzyskane w grupach spotkaniowych za niezwykle pożyteczne lub przynajmniej za nieszkodliwe. Wielu studentów stwierdza, że przeżycia i wiedza o sobie, jaka uzyskują w krótkich nawet posiedzeniach grupy spotkaniowej, może być dla nich źródłem radości. Po prostu sama możność wyciągnięcia ręki, dotknięcia drugiej osoby i w wyniku tego dzielenia z nią serdecznych i ciepłych uczuć jest dla wielu studentów nowym doznaniem. Powinno ono być częścią naszego codziennego życia, lecz dopóki nie potrafimy zmienić naszego społeczeństwa w taki sposób, by było to możliwe, dopóty grupy spotkaniowe będą pomagały nam budować most od izolacji przez niezależność do zależnośi wzajemnej”. 


Celem, jaki sobie stawia większość grup spotkaniowych, nie jest zatem leczenie problemów emocjonalnych, lecz wzmogacenie życia normalnych mężczyzn i kobiet. Nie ulega jednak wątpliwości, że grupy takie przyciągają osoby z problemami emocjonalnymi oraz ludzi, którzy nie potrafią skutecznie radzić sobie w życiu. Jeszcze bardziej komplikuje sprawę problem amatorów prowadzących takie grupy - ich jedynym „przygotowaniem” było własne uczestnictwo w grupie spotkaniowej. W przeciwieństwie do zawodowych psychoterapeutów, osoby prowadzące grupy spotkaniowe nie muszą mieć licencji ani dyplomu, a wiele z nich nie posiada umiejętności niezbędnych do uporania się z poważnymi problemami emocjonalnymi. Większość takich prowadzących, aczkolwiek ma dobre intencje, w małym stopniu poczuwa się do odpowiedzialności za śledzenie efektów osiągniętych przez grupę w trakcie jej posiedzeń i nie chce pozwalać zawodowym badaczom na sprawdzanie uzyskiwanych wyników. W rezultacie wiele stosowanych przez nich metod jest raczej bezużytecznych, a zdarzają się nawet wyraźne destrukcyjne napaści słowne lub fizyczne na członków grupy.
W jednym z niewielu dobrze zaplanowanych badań porównawczych nad grupami spotkaniowymi stwierdzono, że dla grup stwarzających duże ryzyko urazów psychicznych charakterystyczna była bardzo agresywna stymulacja i stosunkowo silny charyzmat osoby prowadzącej. 
Ponadto nie uzyskano żadnych danych potwierdzających szeroko rozpowszechniony pogląd, że duże ryzyko jest niezbędne dla osiągnięcia wysokiego poziomu rozwoju. Wprost przeciwnie, najbardziej pozytywne wyniki i najmniej urazów stwierdzono w grupach prowadzonych przez osoby, które oceniano jako bardzo |opiekuńcze i dostarczające poznawczego układu odniesienia dla dokonujących się zmian. Chociaż nie ulega wątpliwości, że uczestnictwo w grupach spotkaniowych pozwala uzyskać niektórym ich członkom wyraźnie pozytywne rezultaty, to jednak jest równie oczywiste, że istnieje poważne niebezpieczeństwo w postaci urazów psychicznych związanych z uczestnictwem w tych grupach. To, czy w danej grupie będzie więcej wyników pozytywnych czy negatywnych, zależy w znacznym stopniu od społeczno-psychicznych cech prowadzącego.




Zbliżenie


Jakie są efekty uczestnictwa w grupach spotkaniowych?


„Wyniki uzyskane w pewnym niezwykle dobrze zaplanowanym i zrealizowanym badaniu, mającym na celu ocenę efektywności grup spotkaniowych, świadczą zarówno o wartości, jak i o możliwych niebezpieczeństwach tych „terapeutycznych” doświadczeń.
Grupy zorganizowano specjalnie dla celów tego badania, angażując szesnaście doświadczonych osób prowadzących, z których każda była wyspecjalizowana w prowadzeniu innej odmiany grup spotkaniowych; w grupach uczestniczyło ochotniczo 279 studentów, którzy otrzymali za to punkty niezbędne do zaliczenia kursu. Porównania można było przeprowadzić z trzema rodzajami grup kontrolnych: studentami, którzy zgłosili się, lecz nie mogli być przyjęci z powodu trudności związanych z rozkładem zajęć oraz z innych przyczyn (38 osób); zainteresowanymi przyjaciółmi uczestników, którzy nie mogli brać udziału w zajęciach grup w tym samym semestrze (31 osób) oraz tymi studentami, którzy wzięli udział w mniej niż połowie posiedzeń (35 osób).
Stosowane techniki pomiarowe były liczne i różnorodne. Samoopisy („self-reports”) i inne oceny przeprowadzono przed rozpoczęciem zajęć w grupach, w trakcie ich trwania, natychmiast po ich zakończeniu i wreszcie po upływie 6 miesięcy od chwili zakończenia pracy w grupach. Każdy uczestnik dokonywał samooceny, opisywał swe postawy, uznawane przez siebie wartości, własne spostrzeżenia, motywy, doświadczenia społeczne oraz inne aspekty samego siebie, jak również swych reakcji na inne osoby i na sytuację. Każdy student był także oceniany przez innych uczestników, prowadzącego grupę oraz grupę kolegów. Funkcjonowanie grupy i osoby prowadzącej ją oceniało dwudziestu dziewięciu obserwatorów (dwóch na każdym posiedzeniu grupy, przy czym zmieniali się oni tak, by każdy oceniał wszystkie osoby prowadzące).
Opracowanie ogromnej liczby zebranych danych nie jest jeszcze zakończone, lecz badacze wskazują na następujące godne uwagi rezultaty:
1. 75% uczestników doniosło o pozytywnej zmianie, jaka w nich zaszła, przy czym większość z nich uważała, ze zmiana ta jest trwała. 95% wyraziło przekonanie, że uczestnictwo w grupie spotkaniowej winno zostać formalnie włączone do programu akademickiego. U większości uczestników wystąpił znaczny wzrost samooceny.
2. Stwierdzono, że wyniki osiągnięte przez różne osoby prowadzące, i w różnych grupach, bardzo różniły się. W niektórych grupach doświadczenia te nie miały niemal żadnego wpływu na uczestników, w innych - prawie każdy uczestnik stwierdził, że doświadczenie to miało na niego wpływ. W niektórych grupach wpływ ten był jednak mieszany: 60% członków danej grupy doniosło o zmianach w sobie, lecz tyle samo członków grupy uznało wpływ za negatywny, ile - za pozytywny. W niektórych grupach nie odpadł nikt; w innych 40% uczestników zrezygnowało z uczęszczania na spotkania.
3. Osoby prowadzące różniły się znacznie pod względem ilości i charakteru dostarczanej przez siebie stymulacji oraz stylu „przywódctwa”, co miało wpływ na normy określające właściwy sposób zachowania się w poszczególnych grupach.
4. Różne były także poglądy studentów, na to co dało im uczestnictwo w grupie spotkaniowej: akceptację - według niektórych, zrozumienie lub zaangażowanie - według innych, dobrą radę lub stymulację intelektualną - według jeszcze innych.
5. Zidentyfikowano szesnastu studentów, na których doświadczenie to wywarło na tyle ujemny wpływ, że uzasadniał on objęcie ich dłuższą opieką psychiatryczną. Procent poszkodowanych był większy w grupach „eksperymentalnych” niż w grupach kontrolnych.
6. Najbardziej typowym źródłem urazu było zaatakowanie lub odrzucenie przez osobę prowadzącą albo przez grupę. Inne źródła urazów to niemożność osiągnięcia nierealnych celów, oczekiwania innych odbierane jako wywieranie przymusu oraz nadmiar bodźców.
7. Najczulszym wskaźnikiem urazu były odpowiedzi kolegów na pytanie „Komu stała się krzywda?”. Osoby prowadzące były szczególnie mało wrażliwe na urazy, jakie wydarzyły się w ich grupach.
8. Najbardziej efektywny (jeśli chodzi o maksymalizowanie korzyści z jednoczesnym minimalizowaniem liczby urazów) styl kierowania grupą polegał na obdarzaniu serdecznością i dostarczaniu oparcia w połączeniu z udzielaniem informacji, w jaki sposób można się zmienić (strukturalizowanie poznawcze).
9. Uzyskane wyniki nie miały związku z „etykietkami ideologicznymi” czy „nazwami gatunkowymi” różnych grup.
10. W opublikowanej niedawno pracy autorzy badania konkludują: „Wydaje się więc, że ogólna nazwa „grupy spotkaniowe” obejmuje szeroki zakres oddziaływań stosowanych przez osoby prowadzące, które to oddziaływania prowadzą do wielu rodzajów doświadczeń przeżywanych w tych grupach, a być może do wielu typów „uczenia się”

(Lieberman, Yalom i Milse, 1973).




Łączenie różnych
technik terapeutycznych




Aczkolwiek wypróbowano już wiele specyficznych technik psychoterapii - niektóre oparte na bardzo złożonych teoriach, inne zaś jedynie na doświadczeniu praktycznym - to jednak żadna z nich nie okazała się skuteczna we wszelkiego rodzaju przypadkach. W tej sytuacji większość terapeutów przyjmuje podejście |elektyczne, nie ograniczając się do stosowania jakiejś jednej procedury.
Tego rodzaju podejście jako pierwszy wprowadził sławny psychiatra Adolph Meyer, kładąc nacisk na nierozłączność procesów |psychicznych i |biologicznych. Podejście to, zwane |psychobiologią, stawia sobie za cel zrozumienie wszystkich czynników - biologicznych, psychologicznych i społecznych - jakie są uwikłane w danym zaburzeniu. Koncepcja ta prowadzi do terapii |zintegrowanej, w której różne techniki stosuje się w rozmaitych zestawieniach, zależnie od indywidualnego przypadku. Program leczenia określonego pacjenta mógłby zatem obejmować takie techniki, jak swobodne kojarzenie, analizę marzeń sennych, hipnozę oraz wszelkie metody medyczne uznane za niezbędne. Ideałem podejścia elektycznego jest elastyczność i wolność od teoretycznego dogmatyzmu w próbach dostosowania terapii do problemu - a nie pacjenta do teorii terapeuty.




Opieka w zakładach
psychiatrycznych




Najbardziej kompletny program terapii zintegrowanej realizowany jest w szpitalach psychiatrycznych, gdzie pacjenta leczy cały zespół; w ten sposób wykorzystuje się umiejętności diagnostyczne i terapeutyczne psychiatrów, psychologów, asystentów socjalnych, specjalistów w zakresie terapii zajęciowej oraz innych osób o specjalistycznym przygotowaniu. Pacjentom cierpiącym na poważne zaburzenia pobyt w zakładzie może przynieść duże korzyści - uwolnieni są tam od trudnych decyzji i nie muszą borykać się z wieloma frustracjami normalnego życia. Obecność innych osób o podobnych trudnościach łagodzi zwykle ich poczucie winy. Ponadto pacjentów chroni się, nie pozwalając im uczynić krzywdy - czy to fizycznej czy finansowej - przez siebie samych lub kogoś z ich otoczenia.


Ku lepszemu... Życie w dobrze funkcjonującym zakładzie przebiega na tyle normalnie, na ile pozwala stan każdego z pacjentów. Dominuje obecnie tendencja do zwiększania swobody pacjentów, by mogli oni żyć bardziej normalnie i w większym stopniu decydować o sobie podczas pobytu w szpitalu.  Rozwiązania takie, chociaż ciągle znajdują się w stadium eksperymentalnym, wykazały w wielu przypadkach swą wartość terapeutyczną; pomagają one pacjentom uniknąć całkowitej zależności od szpitala i przygotować się do decydowania o sobie, dzięki czemu po zwolnieniu potrafią oni lepiej przystosować się do swego rodzimego środowiska.
Najpopularniejszą ostatnio formę leczenia szpitalnego określa się jako |społeczność |terapeutyczną. Jest to taka metoda zorganizowania oddziału szpitala psychiatrycznego, w której dąży się do rozwinięcia i utrzymania poczucia wspólnoty społecznej między pacjentami a personelem. Ścisły związek między personelem a pacjentami stanowi podstawę dla wspólnego wykonywania pracy i podejmowania decyzji wpływających na życie oddziału.  Społeczność taka funkcjonuje na oddziale psychiatrycznym Yale-New Haven Hopital, gdzie pacjenci napisali konstytucję dla swego oddziału. Oddział ten określany jest w tej konstytucji jako „Społeczność, której celem jest to, aby każdy mógł nauczyć się, jak być za siebie odpowiedzialnym, i potrafił pomóc sobie samemu poprzez pomaganie innymi”. Wyraźnie określono obowiązki i przywileje pacjentów, podobnie jak zadania personelu, oraz wartości i normy postępowania rządzące życiem zarówno personelu, jak i pacjentów na tym oddziale. Problemy pacjentów rozpatruje się otwarcie w atmosferze zaufania i koleżeństwa. Główną troską społeczności jest dopomaganie pacjentom, aby mogli być zwalniani tak szybko, jak tylko to jest możliwe, i aby nastąpiła u nich poprawa w takim stopniu, by mogli skutecznie funkcjonować w swej rodzimej społeczności.


„W badaniach kwestionariuszowych nad zmianami u pacjentów i u personelu, które można przypisać doświadczeniom uzyskanym w społeczności terapeutycznej, Richard Almond (1971) stwierdził istotne zwiększenie „otwartości społecznej” („social openness”) u pacjentów oraz spadek autorytaryzmu u personelu. Oddział ten skutecznie włączał nowych pacjentów w swą kulturę. Wykryto ponadto, że u pacjentów nie tylko następowała poprawa podczas pobytu w szpitalu, lecz także zachowywali się oni (według ocen personelu) zgodnie z normą otwartości społecznej”.


„Interesujący jest fakt, że to nowe zachowanie |poprzedzało ukształtowanie się nowych postaw wobec otwartości - najpierw działali, a dopiero później zaczynali wierzyć w to, co robili. Wpływ takiej społeczności terapeutycznej na jednostkę został przedstawiony w opisie pierwszego dnia pobytu na oddziale, sporządzonym przez młodą pacjentkę: 
„Byłam zupełnie zaskoczona, gdy ludzie przychodzili do mnie i pytali: 
„Dlaczego się tu dostałaś?” Opisując swe reakcje w ciągu następnych kilku dni, stwierdziła: „Nawiązałam rozmowę z bardzo wieloma ludźmi, zarówno spośród personelu, jak i pacjentów. Zaczęłam rozumieć problemy, jakie miałam (...). Stałam się bardziej obiektywna”.


(...) Nigdy przedtem nie uświadamiałam sobie tak jasno, co wywołało u mnie tę chorobę”. Opisując, w jaki sposób stała się członkiem społeczności oddziału i nauczyła się jej zwyczajów, stwierdziła: „To stało się rzeczywiście dzięki mówieniu. Intensywność (interakcji) na tym oddziale wywiera duże wrażenie (...). Tutaj wszystko jest tak intensywne, że istotnie przystosowujesz się i zaczynasz patrzeć bardziej obiektywnie na swoje problemy, ponieważ nieustannie jesteś stawiany w takiej sytuacji, że musisz o tym mówić (...). Wszyscy ludzie mają tu ze sobą wiele wspólnego i zdają się naprawdę interesować dobrem innych” (s. 39).


... czy ku gorszemu? Opieka nad chorymi psychicznie i leczenie ich w zakładach zamkniętych stanowi problem medyczny, finansowy i społeczny. W Stanach Zjednoczonych ponad milion pacjentów leczonych jest co roku w szpitalach psychiatrycznych. Jak już wspomnieliśmy w poprzednim rozdziale, blisko połowę łóżek w tym kraju zajmują pacjenci psychiatryczni. Dzieje się tak nie dlatego, że zaburzenia psychiczne są bardziej rozpowszechnione niż choroby fizyczne, lecz z tej przyczyny, że na ogół trudniej jest je leczyć i radzić sobie z nimi w domu, a zatem wymagają hospitalizacji przez czas dłuższy.
Ogólną sumę kosztów, bezpośrednich i pośrednich, jakie w Stanach Zjednoczonych pociągają za sobą choroby psychiczne, szacuje się na miliardy dolarów. W każdym stanie działają szpitale psychiatryczne, a w większości stanów środki na opiekę nad pacjentami psychiatrycznymi i na ich leczenie stanowią jedną z największych pozycji w budżecie. Jednakże nawet w tych stanach, w których realizowane są ambitne programy higieny psychicznej, środki te są niewystarczające. Prawie wszystkie szpitale stanowe są mocno przepełnione. Ponadto, chociaż w ostatnich trzydziestu latach liczba psychologów i psychiatrów wzrosła wielokrotnie, to jednak nadal zbyt mało jest odpowiednio wyszkolonych psychiatrów, psychologów i innego wykwalifikowanego personelu, aby zapewnić właściwą opiekę chorym psychicznie.
Bardzo niewiele zakładów mających za zadanie opiekę nad pacjentami psychiatrycznymi i ich leczenie zbliża się do ideału sprzyjającego rehabilitacji. Jest wiele szpitali stanowych, w których warunki są tak złę, że gdyby były one powszechnie znane, lub gdyby podatnicy rzeczywiście troszczyli się o nie, to wybuchłby ogólnonarodowy skandal.
W niektórych szpitalach jest zaledwie jeden psychiatra na ponad tysiąc pacjentów. W innych, decyzje o podjęciu leczenia muszą opierać się na prognozie, że nowy pacjent reaguje na terapię szybko i pozytywnie. W wypadku pacjentów, u których nie można oczekiwać szybkiej poprawy lub którzy pod wpływem terapii nie wykazali istotnych postępów w krótkim czasie, leczenie z konieczności sprowadza się do chemioterapii lub terapii zajęciowej - organizowanych tak, aby móc poradzić sobie z pacjentami i aby nie sprawiali oni kłopotu.
W narastającej ostatnio fali krytyki pod adresem szpitali psychiatrycznych udokumentowano destrukcyjne skutki, jakie często pociąga za sobą działalność tych instytucji. Stwierdzono, że stosowane w nich praktyki są autorytarne (Holzberg, 1960), degradujące pacjenta (Sarbin, 1967), dehumanizujące (Goffman, 1961) i podtrzymujące chorobę (Schwartz, 1960). Według jednego z badaczy, „naturę osoby przedefiniowuje się w ten sposób, że w rzeczywistości - jeśli nie w intencji - pacjent staje się rodzajem przedmiotu, na którym można wykonywać psychiatryczne usługi. Aby uczynić z niego pacjenta, trzeba go przekształcić w obsługiwany przedmiot, przy czym ironia polega na tym, że tak niewiele usług jest do dyspozycji, gdy już się tego dokona” (Goffman, 1961, s. 379). Warunki takie występują częściej, niż można by sobie tego życzyć.
W poprzednim rozdziale stwierdziliśmy, że Rosenhana i jego współpracowników (1973) nie tylko przyjmowano w charakterze pacjentów do szpitali psychiatrycznych, gdy udawali schizofreników, lecz ponadto traktowano ich tam w depersonalizujący sposób. W przeciwieństwie do modelowej społeczności terapeutycznej, we wszystkich szpitalach „wizytowanych” przez ten zespół pseudopacjentów personel wykazywał małe osobiste zainteresowanie dobrem pacjenta, mało było bezpośrednich kontaktów z psychiatrami czy psychologami, wiele zaś interakcji między pacjentami a personelem było nacechowanych obojętnością lub wrogością.




Zbliżenie


Pacjent jako brzydkie kaczątko


„Dla pacjentów jest bardzo ważne, by nauczyli się, w jaki sposób wywierać pozytywne wrażenie na personelu psychiatrycznym - choćby z tego powodu, że oceny psychiatryczne uzależnione są w dużym stopniu od tego, czy personel |lubi danego pacjenta. Ten zaskakujący wniosek jest wynikiem dokładnych badań nad personelem i pacjentami przeprowadzonych na dwóch oddziałach Agnews State Mental Hospital w Kalifornii przez Michaela Katza (1974), który sam był pielęgniarzem psychiatrycznym. Oceny atrakcyjności społecznej pacjentów, dokonywane co tydzień przez personel, skorelowano z liczbą kontaktów między personelem a pacjentem, ocenami stanu zdrowia psychicznego pacjentów oraz takimi decyzjami, jak na przykład ta, czy pacjenta należy zatrzymać na danym oddziale, czy przenieść gdzie indziej. Wyniki tego badania potwierdzają wniosek, że atrakcyjność społeczna w dużej mierze |jest zdrowiem psychicznym!
Istnieje hierarchia statusu pacjentów, oparta na ich zdolności wzbudzania sympatii. Ci pacjenci, których personel lubi najmniej, są, w porównaniu z pacjentami sympatycznymi, bardziej unikani, częściej kwalifikuje się ich do leczenia farmakologicznego, przeniesienia na inny oddział lub do wypisania ze szpitala (wbrew temu, że ocenia się ich jako bardziej chorych psychicznie).
Katz wskazuje, że członkowie personelu powinni zdać sobie sprawę z wpływu, jaki atrakcyjność społeczna („sociability) pacjentów wywiera na ich rzekomo obiektywne oceny.



Ponadto byłoby dobrze, aby personel dokładnie wyjaśnił pacjentom, jakie zachowania są uważane za atrakcyjne lub przykre i aby następnie wzmacniał selektywnie te zachowania, które czynią pacjenta atrakcyjnym. Ponieważ szpital psychiatryczny stanowi w pewnej mierze mikrokosmos społeczeństwa, przeto z badań tych wynika być może również i to, że my wszyscy jesteśmy skłonni pobłażliwie traktować u atrakcyjnych osób to, co uważamy za poważną wadę u brzydkich kaczątek”.


W Elgin State Hospital w Illinois przeprowadzono niedawno inny, jedyny w swoim rodzaju eksperyment, w którym „personel” sam podzielił się na „pseudopacjentów” i „personel” (odgrywający swą własną rolę). Przez trzy dni 29 osób spośród personelu było zamkniętych na własnym oddziale - oddziale psychiatrycznym, na którym były one pseudopacjentami. Wyszkoleni obserwatorzy i kamery magnetowidów rejestrowały wszystko to, co się działo.  „Wydarzyły się tam naprawdę fantastyczne rzeczy”, podaje Norma Jean Orlando (1973), kierująca tymi badaniami. Po krótkim czasie pseudopacjenci zaczęli zachowywać się w sposób nie dający się odróżnić od zachowania prawdziwych pacjentów: sześciu próbowało uciec, dwóch „zamknęło się w sobie”, dwóch płakało w niepohamowany sposób, jeden był bliski załamania nerwowego. U większości nastąpił ogólny wzrost napięcia, lęku, frustracji i rozpaczy.  Najsilniej reagowali na całkowite pogwałcenie ich prywatności, na traktowanie ich tak, jak traktuje się niekompetentne dzieci, na ignorowanie ich i zmuszanie do podporządkowania się zarządzeniom personelu.
Jeden z członków personelu „przedzierzgniętego” w pacjentów, który wiele przecierpiał podczas tego weekendu, zrozumiał jednak dzięki temu tyle, że stwierdził: „Zwykłem patrzeć na pacjentów tak, jak gdyby byli oni stadem zwierząt; nie zdawałem sobie sprawy z tego, przez co przeszli oni przedtem”.
Pozytywnym następstwem tych badań było utworzenie organizacji grupującej członków personelu, a mającej za zadanie lepsze uświadomienie reszcie personelu szpitalnego, na czym polega niewłaściwe traktowanie pacjentów, a także osobistą pracę nad polepszeniem własnego stosunku do pacjentów.
Gruntowne badania, które objęły 2926 dorosłych pacjentów przyjętych na oddział psychiatryczny County General Hospital w Los Angeles, dostarczyły materiału najbardziej może obciążającego zamknięte lecznictwo psychiatryczne (Mendel, 1966). Z badań tych wyciągnięto wniosek, że 75% wszystkich pacjentów uznawanych za „schizofreników” mogło być (lecz nie było) zwolnionych do swej społeczności. Im krótszy czas przebywania w szpitalu, tym wyższy poziom społecznego funkcjonowania pacjentów po zwolnieniu. Im dłużej pacjenci pozostają w zakładzie, w tym mniejszym stopniu następuje u nich poprawa, a ich szanse udanego przystosowania się do zewnętrznej społeczności maleją.




Społeczna ochrona
zdrowia psychicznego




Joint Commission on Mental Health (Połączona Komisja do Spraw Zdrowia Psychicznego) zaleciła w 1961 roku, aby nie budować już więcej szpitali psychiatrycznych o pojemności ponad 1000 łóżek; żeby ostrymi przypadkami zajmowały się ośrodki, które należy tworzyć w rodzimej społeczności pacjenta, aby nie musiał oczekiwać długo na przyjęcie i żeby jak najszybciej, gdy tylko będzie to możliwe, wielkie stanowe szpitale psychiatryczne zostały albo „rozparcelowane”, albo przekształcone w zakłady opiekuńcze dla pacjentów cierpiących na chroniczne choroby fizyczne lub psychiczne. Pierwszym krokiem zmierzającym do realizacji tych zaleceń było wydanie „Community Mental Health Centers Act” (Ustawy o Społecznych Ośrodkach Zdrowia Psychicznego) zachęcającej do tworzenia w całym kraju lokalnych, wielokierunkowych ośrodków terapii. Istnieje nadzieja, że gdy takie ośrodki będą coraz liczniejsze i lepiej wyposażone, to coraz więcej osób potrzebujących pomocy będzie mogło uzyskać ją w swej własnej społeczności, a wówczas wielkie stanowe szpitale psychiatryczne staną się przeżytkiem.
Takie wszechstronne, lokalne ośrodki mają wiele zalet. Dzięki natychmiastowej pomocy, dostosowanej do potrzeb jednostki, można znacznie skrócić ogólny czas leczenia, oszczędzając jednocześnie wielu zmartwień, i urazów pacjentowi i jego rodzinie. Piętno związane z faktem, że jest się gdzieś „wysyłanym”, zostaje zminimalizowane lub unika się go całkowicie, a pacjentowi oszczędza się problemów przystosowania do obcego, odległego, bezosobowego zakładu oraz równie trudnego problemu powrotu do swej społeczności po długiej nieobecności i znalezienia w niej znów miejsca dla siebie.




Zbliżenie


Praktyczny przewodnik - gdzie szukać pomocy?


„Wielu z nas ma poczucie (niekiedy zostało im ono wpojone), że powinniśmy umieć rozwiązywać swoje własne problemy, a nie obciążać innych naszymi kłopotami. Przyznanie się, że moglibyśmy potrzebować pomocy, wydaje się jakby czymś niewłaściwym lub oznaką słabości. Nie ulega jednak wątpliwości, że prawie każdy przeżywa niekiedy uczucia depresji, osamotnienia lub bezradności. Istnieje wiele doświadczeń życiowych, które mogą wywoływać takie indywidualne kryzysy. Trzeba zdawać sobie sprawę z tego, że każdy wcześniej lub później, stanie wobec takich kryzysów i że nie ma nic złego ani niewłaściwego w emocjonalnym reagowaniu na nie. Szukanie pomocy w takich sytuacjach może nie być łatwe, lecz wydaje się lepsze, niż brnięcie przez nie samemu.
Kiedy osoby dostarczające nam zwykle oparcia emocjonalnego, takie jak rodzice lub bliscy przyjaciele, są nieobecne lub nieosiągalne, wtedy nie powinniśmy się wahać, lecz poszukiwać pomocy z innych źródeł. Czas trwania kryzysu u większości ludzi jest zwykle krótki (od 4 do 6 tygodni); istnieje wówczas zarówno niebezpieczeństwo w postaci zwiększonej podatności na urazy psychiczne, jak i w sposobności rozwoju osobowego. Wynik zdaje się zależeć w dużym stopniu od możliwości uzyskania odpowiedniej pomocy oraz od własnej postawy i sposobu określenia „problemu”.
Jednakże z punktu widzenia profilaktyki bardziej sensowne byłoby wyszukanie źródeł pomocy, |zanim będą one potrzebne. Interesującą i ważną pracą badawczą byłoby zidentyfikowanie różnych źródeł oparcia psychicznego, jakie są obecnie dostępne dla ciebie. Najpierw powinieneś sporządzić listę dostępnych źródeł pomocy spoza zawodowej służby zdrowia psychicznego - takich, jak rodzina, przyjaciele, nauczyciele, duchowni, „ośrodki szybkiej pomocy” itd. Być może, wizyta w miejscowym kościele lub ośrodku pomocy społecznej pozwoliłaby ci zorientować się, czy twoim zdaniem placówki te mogłyby udzielić ci pomocy w razie potrzeby. Nie potrzebowałbyś wcale wymyślać jakiejś historyjki, aby ukryć badawczy charakter twojej wizyty: możesz po prostu wyjaśnić, że starasz się ustalić źródła oparcia emocjonalnego istniejące w danej społeczności.
Większość problemów to w rzeczywistości problemy mniej poważne, które znikną z czasem, których waga maleje, gdy spojrzymy na nie z perspektywy, lecz proces „przepracowania” ich pomaga lepiej poznać samego siebie i może zmniejszyć stresowe oddziaływanie takich problemów w przyszłości. Istnieją jednak takie przypadki prawdziwego cierpienia, w których dana osoba - może ty lub twój kolega - mogłaby popaść w ciężką depresję, poważnie myśleć o samobójstwie albo też zaczęłaby się u niej rozwijać paranoidalne urojenia prześladowcze, halucynacje lub inne oznaki poważnego stresu psychologicznego. W przypadku takich problemów powinieneś od razu pójść po pomoc do zawodowego terapeuty. Byłoby najlepiej, gdyby był to ktoś, kogo poznałeś wcześniej jako osobę, którą możesz szanować, do której możesz mieć zaufanie i z którą mógłbyś mówić otwarcie. Idź do niego wcześnie, zanim objawy same staną się problemami (powodując złe stopnie, itd).
Nie jest rzeczą nierozsądną pomówić zawczasu o „kontrakcie terapeutycznym” - co dostajesz za to, co dajesz. Gdybyś uważał to za wskazane, to mógłbyś zbadać „osobistą filozofię” terapeuty: jego poglądy na naturę człowieka, przyczyny zaburzeń emocjonalnych i zaburzeń zachowania.  Oczywiście, od poznania poglądów terapeuty ważniejsze jest to, abyś dobrze się czuł w jego obecności i mógł mu zaufać. Najlepiej możesz się o tym przekonać wtedy, gdy podzieliwszy się z nim swymi problemami i troskami, ocenisz, jak pomocna jest dla ciebie jego odpowiedź. Pamiętaj jednak, że większość terapeutów powstrzymuje się od udzielania rad, lecz stara się dopomóc pacjentowi w dojściu do własnego rozwiązania problemu. Sam możesz osądzić, czy właśnie tego potrzebujesz.
Terapia jest intymną interakcją społeczną, w której płacisz za otrzymane usługi. Jeśli masz poczucie, że usługi te nie przyniosą ci korzyści, to omów ten fakt otwarcie z terapeutą, podkreślając, że niepowodzenie terapii oznacza zarówno |jego |niepowodzenie, jak i twoje własne. Przedyskutuj kryteria danego zakończenia terapii - kiedy obaj będzie mogli uznać, że „naprawdę” masz się lepiej? Omów także sprawę zakończenia terapii, jeśli jesteś z niej zadowolony. Samo w sobie może to być pozytywnym krokiem ku osiągnięciu większej pewności siebie. Wśród profesjonalistów istnieje niemal powszechne przekonanie, że nie ma terapeuty, który mógłby z każdym nawiązać odpowiedni kontakt, dobry zaś terapeuta niekiedy sam sugeruje pacjentowi, że mógłby on osiągnąć lepsze rezultaty z pomocą innego terapeuty”.


Koncepcja zdrowia psychicznego społeczności. Wraz z przyznaniem przez władze federalne Stanów Zjednoczonych pomocy finansowej dla lokalnych programów ochrony zdrowia psychicznego, nastąpiły w minionym dziesięcioleciu znaczne i bardzo potrzebne zmiany w zakresie udostępniania usług psychologicznych ludziom, którzy ich potrzebują. W zamieszczonej na następnej stronie tabeli przedstawiono wiele tych zmian, ukazując, w jaki sposób podejście to różni się od bardziej tradycyjnych, klinicznie zorientowanych metod postępowania, które opisywaliśmy w niniejszym rozdziale.
„Zdrowie psychiczne społeczności” („community mental health”) jest fascynującym sposobem podejścia do terapii, w którym innowacja nie jest wyjątkiem, lecz regułą. Nie ulega wątpliwości, że jeśli mają być zaspokojone potrzeby psychiczne wielkiej liczby ludzi, to klinicyści muszą opuścić mury zakładów i badać potrzeby ludzi, zamiast czekać, aż ludzie w potrzebie przyjdą do nich. Jednakże jeszcze ważniejsza jest koncepcja leczenia i |zapobiegania dotycząca całej społeczności, podobna do publicznych programów ochrony zdrowia mających zabezpieczyć daną społeczność przed źródłami takich chorób, jak ospa. Można ustalić źródła stresu, istniejące w środowisku czy w instytucjach i organizacjach, oraz sformułować plany złagodzenia lub uniknięcia go, jak również zwiększenia odporności na poszczególne źródła stresu.
Chociaż niektóre nasze problemy emocjonalne wynikają niewątpliwie z nie rozwiązanych konfliktów z wczesnych okresów życia oraz z niewłaściwego uczenia się, to jednak główne źródła stresu, z jakimi mamy do czynienia, wiążą się z warunkami, w których żyjemy na co dzień - z przemocą, uprzedzeniami, różnymi formami degradacji ekologicznej, izolacją społeczną, zbrodnią, bezrobociem, nędzą, wojną oraz bezsilnością, jaką odczuwamy przy podejmowaniu prób przekształcenia systemów, które sprawują nad nami władzę i manipulują nami.




* * *



Koncepcja Zdrowia Psychicznego Społeczności Przeciwstawiona Tradycyjnemu, 
Klinicznemu Sposobowi Podejścia


1. Nacisk na praktykowanie w społeczności w przeciwieństwie do praktykowania w warunkach zinstytucjonalizowanych.
2. Nacisk raczej na całą społeczność czy całą określoną populację niż na indywidualnych, rozpatrywanych pojedynczo pacjentów.
3. Nacisk na zapobieganie w odróżnieniu od usług terapeutycznych świadczonych osobom już „chorym”.
4. Nacisk raczej na usługi pośrednie, takie jak konsultacje i kształcenie w zakresie ochrony zdrowia psychicznego niż na bezpośrednie usługi terapeutyczne.
5. Nacisk na nowatorskie strategie kliniczne, takie jak krótka psychoterapia i interwencje w kryzysach („crisis intervention”), które stwarzają możliwość zaspokojenia potrzeb z zakresu zdrowia psychicznego u większej niż dotąd liczby ludzi.
6. Nacisk na racjonalne planowanie programów zdrowia psychicznego, łącznie z demograficznymi analizami danej społeczności, określeniem nie zaspokojonych potrzeb zdrowotnych, identyfikacją populacji szczególnie narażonych na zaburzenia psychiczne oraz ustaleniem priorytetów.
7. Nacisk na nowatorskie wykorzystanie zasobów ludzkich, na przykład paraprofesjonalistów.
8. Zaangażowanie się w „kierowanie społecznością” („community control”) przez identyfikowanie potrzeb społeczności, proponowanie i ocenianie programów zaspokajania tych potrzeb oraz planowanie dalszego rozwoju tych programów.
9. Zainteresowanie ustaleniem źródeł stresu w obrębie społeczności, a nie zakładanie, że patologia psychiczna istnieje wyłącznie w określonym, indywidualnym pacjencie.

(Adaptowane z Blooma, 1973)


* * *





Czy fakt, że u większości hospitalizowanych pacjentów dochodzi po zwolnieniu do nawrotu choroby, świadczy o powadze i „głębokości” ich schorzenia, czy też o „zaburzeniu” środowiska, w którym się oni znajdują?
Ciekawe, że wysoki wskaźnik nawrotów choroby u pacjentów psychiatrycznych jest zbliżony do wskaźnika recydywy u psychicznie zdrowych więźniów, którzy także przebywali przed długi czas w zakładzie (karnym). „Rzucenie” człowieka z powrotem w warunki, które od początku były niekorzystne (a mogłyby się jeszcze pogorszyć) dostarcza prawdopodobnie bodźca dla dewiacyjnych reakcji. Trzeba też zdawać sobie sprawę z trudności ponownego przystosowania się do swej rodziny i przyjaciół po długotrwałej nieobecności. Powracających z Wietnamu amerykańskich jeńców wojennych poddawano specjalnemu przeszkoleniu, lecz w wielu przypadkach nie potrafili oni przystosować się do rodziny, która obywała się bez nich przez kilka lat, ani do „społeczności”, która naprawdę nigdy nie zauważyła ich odejścia. Jeśli tak przedstawiała się sprawa w przypadku tych, których witano jak bohaterów, to jakie muszą być problemy powrotu eks-schizofreników lub eks-więźniów?
W dokonanej przez siebie dokładnej ocenie środków ochrony zdrowia psychicznego społeczności Hogarty i jego współpracownicy (1969) podkreślają, że pacjentom leczącym się ambulatoryjnie trzeba udostępnić szerszy zakres świadczeń i zapewnić im wszechstronną opiekę ze strony społeczności, jeśli mamy uniknąć tego, co określa się jako „zespół obrotowych drzwi szpitala psychiatrycznego”. Tam, gdzie opieka nad pacjentami psychiatrycznymi po ich zwolnieniu ze szpitala nie istnieje lub jest niedostateczna, przystosowanie społeczne tych pacjentów jest dużo gorsze niż tam, gdzie opieka ta jest zorganizowana na odpowiednim poziomie.  Na podstawie swych badań nad statusem społecznym i stanem zdrowia psychicznego pacjentów w ciągu dwunastu miesięcy po ich zwolnieniu ze szpitala badacze ci doszli do wniosku, że „poziom rewalidacji społecznej („social restoration”) osiągnięty przez wielką liczbę pacjentów leczonych w społeczności jest imponujący i wydaje się równy, jeśli nie wyższy, poziomowi przystosowania osiągniętemu przez pacjentów po tradycyjnej hospitalizacji w zakładach zamkniętych” (s. 280).


Terapia koleżeńska („peer therapy”). Być może najbardziej nowatorską ideą, mogącą mieć najdalej idące konsekwencje, jaka zrodziła się z koncepcji „zdrowia psychicznego społeczności”, jest wciągnięcie nieprofesjonalistów do pracy o charakterze terapeutycznym. Do służby tej wciąga się studentów wyższych uczelni, uczniów szkół średnich a nawet podstawowych, a także gospodynie domowe, emerytów, pracowników fizycznych, nieletnich przestępców, pacjentów, |eks-przestępców i |eks-narkomanów oraz innych nieprofesjonalistów zamieszkałych w danej miejscowości. Ci nowi pomocnicy wykonują niemal wszystkie te czynności, które należą do obowiązków zawodowych pracowników służby zdrowia psychicznego (z wyjątkiem przepisywania środków farmakologicznych i stosowania medycznych form terapii), a nawet angażują się w działalność nie zaliczaną formalnie do dziedziny ochrony zdrowia psychicznego, taką jak praca na rzecz rozwoju danej społeczności. Ten szybki rozwój nowych zasobów ludzkiej energii niektórzy uważają za „rewolucję społeczną” (Sobey, 1970), której wpływ na sferę zdrowia psychicznego nie jest jeszcze zupełnie jasny. W dziedzinie tej mało jest dobrze zaplanowanych badań, lecz z ograniczonej liczby dostępnych danych zdaje się wynikać, że nieprofesjonaliści mogą często być równie użyteczni, a niekiedy |bardziej |użyteczni niż wykwalifikowani profesjonaliści (przypomnij sobie eksperyment Posnera nad wpływem „|studenta-|przyjaciela”). Ważnym produktem ubocznym jest stwierdzany zazwyczaj fakt, że |pomagający również odnosi korzyści z dostarczanych przez siebie usług (Gruver, 1971).




Czym zastąpić
hospitalizację?




Wydaje się prawdopodobne, że będzie występować coraz silniejsza tendencja do leczenia poważnych nawet zaburzeń zachowania poza obrębem szpitala.  „Psychiatra bez lekarzy”, „Leczenie idzie do domu” czy „Gospodynie dla chorych psychicznie” - oto przykłady tytułów, jakie będą się pojawiały jeszcze częściej, gdyż okazuje się, że innowacje takie przynoszą dobre rezultaty. George Fairweather i jego współpracownicy (1969) w eksperymentalnym programie pilotażowym wykazali, że grupę nowo zwolnionych pacjentów psychiatrycznych można zorganizować tak, by funkcjonowali oni efektywnie poza szpitalem. Za uzyskane fundusze wynajęto dom, w którym pacjenci ci mogli mieszkać jako grupa. Początkowo obecny był tam jeden z członków personelu badawczego, później został on zastąpiony osobą nie posiadają kwalifikacji specjalistycznych. Pacjentów uczyniono w pełni odpowiedzialnymi za wzajemne regulowanie swego zachowania, dbałość o dom, kupowanie i przyrządzanie posiłków oraz zarabianie pieniędzy. Założyli oni przedsiębiorstwo usług domowych, które w ciągu trzech lat przyniosło ponad 50000 dolarów dochodu. Zarobione pieniądze dzielili stosownie do wydajności i rodzaju obowiązków każdego pacjenta.
Po czterdziestu miesiącach od chwili zwolnienia ze szpitala przeprowadzono porównanie między tą grupą a podobną grupą innych 75 pacjentów, którzy zostali zwolnieni w tym samym czasie, lecz nie mieli takich doświadczeń. Członkowie grupy wzajemnej pomocy łatwiej potrafili utrzymać pracę przynoszącą dochód, osiągnąć zadowalający poziom przystosowania oraz prowadzić rozsądny sposób życia w społeczeństwie niż osoby z grupy kontrolnej. Jeśli chodzi o wysokość nakładów z funduszy publicznych, to wszystkie te efekty osiągnięto kosztem zaledwie 6 dolarów dziennie na jednego członka grupy wzajemnej pomocy! (Rausch i Rausch, 1968).




Marzenie o przyszłości
czy szok przyszłości?




Pewien pacjent psychiatryczny, mający paranoidalne urojenia, zaczął wyobrażać sobie, że ożenił się z jedną z pielęgniarek, którą ledwie znał. W miarę jak myśli te rozbudowywały się, jego „małżeństwo” zostało pobłogosławione trojgiem dzieci, a całe jego życie wypełniło się szczęściem. Wkrótce ten bezrobotny kawaler w średnim wieku przestał interesować się swoją pracą „choćby była ona realna” i zajęty był jedynie swoim marzeniem, które, jak powiedział terapeucie, „jeśli jest realne, to jest cudowne”.
Gdy pacjent zapytał terapeutę o jego zdanie, co do realności lub nierealności tych wyobrażeń, ten odpowiedział mu, że są one po prostu czymś w rodzaju marzenia na jawie. W tym momencie pacjent przypomniał mu o swej samotności, zbliżającej się starości oraz fakcie, że nie jest żonaty i nie ma nikogo, kto martwiłby się naprawdę, gdyby umarł on jutro. „Co ja bym zrobił”, zapytał, „gdyby zabrano mi moje marzenia”? Czy może mi Pan zaoferować coś lepszego od tych marzeń?”
Gdybyś |ty był terapeutą, to co byś mu odpowiedział? To, czy ty mógłbyś zaoferować lepsze marzenie temu człowiekowi cierpiącemu na zaburzenia psychiczne, zależy od tego, czy twoje społeczeństwo może zaoferować |ci możliwość marzenia o przyszłości.




Zbliżenie


Problemy etyczne w terapii


„Jak mogliśmy się przekonać, każda próba wywołania jakiejś zmiany w innej osobie jest decyzją, która ma nie tylko aspekty pragmatyczne czy teoretyczne, lecz także etyczne. Niektórzy terapeuci unikają konieczności rozstrzygania takich trudnych problemów w ten sposób, że nie starają się określić dokładnie swych celów. Lecz czyjeś zmienione zachowanie odczuwają „na własnej skórze” inne osoby; tak więc cały proces terapeutycznej modyfikacji zachowania trzeba umieścić w szerszym kontekście społecznym.  Jakimi wartościami ty kierowałbyś się w następujących przypadkach?
1. Lotnik, który obsługiwał wyrzutnię bomb, a obecnie cierpi na lęk wysokości, chce się wyleczyć, aby móc powrócić do załogi swego bombowca i znów skutecznie rzucać bomby.
2. Mężczyzna będący impotentem rozpaczliwie pragnie mieć dużo dzieci. 
Wyleczenie jego problemów seksualnych przyczyniłoby się do zwiększenia „eksplozji ludnościowej”.
3. Pewien młodzieniec jest pochłonięty pragnieniem wybicia się w jednej dziedzinie kosztem wszelkich innych zainteresowań. Gdyby uczynić z niego osobę bardziej wszechstronną, to jako dorosły byłby lepiej przystosowany, lecz społeczeństwo mogłoby utracić utalentowanego wykonawcę.
4. Kobieta, posiadająca tak zwaną osobowość wielokrotną czerpie radość ze swego zmysłowego, pełnego seksu „ja”, które skłania ją do swobody seksualnej, i nie lubi swego konserwatywnego skromnego „ja”, które hamuje takie pragnienia. Którą „twarz Ewy” starałbyś się wyeliminować, czy też próbowałbyś je zintegrować?
5. Pewien radykalny student, przekonany, że społeczeństwo jest w rozkładzie, a zarówno jego jak i twoje życie znajduje się pod kontrolą „mafii militarno-przemysłowej”, chce doprowadzić do gwałtownej rewolucji.  Czy potraktujesz go jako paranoika i będziesz usiłował dopasować go znów do społeczeństwa, czy też będziesz się starał przyczynić do przeprowadzenia zmian w społeczeństwie, aby lepiej pasowało do ludzi?

Ponieważ nasze tradycyjne struktury ścierają się z głosami domagającymi się zmian w niemal wszystkich tych strukturach, przeto rola terapeuty, jako rozstrzygającego konflikty między wartościami z uwagi na dobro społeczne, rysuje się wyraźniej niż kiedykolwiek przedtem. Czy rola ta ma polegać na popieraniu statystycznej definicji normalności jako tego, czego życzy sobie większość, czy na łagodzeniu i „dopasowywaniu” obu stron do siebie, czy też na uznaniu wysokiego wskaźnika indywidualnych zaburzeń za odzwierciedlenie „choroby” społeczeństwa i skierowaniu swych wysiłków na leczenie patologii społecznej”?


W Rozdziale 14 przyjrzymy się siłom, które mogą nas „odczłowieczyć”, w tym także niektórym sposobom, w jaki cywilizacja może powodować, że stajemy się „niecywilizowani”. Obecnie, wielu ludzi, jak na przykład Alvin Toffer (1970), jest przekonanych, że „szok przyszłości” - wynikająca z lęku niezdolności uporania się z szybkimi przemianami naszego społeczeństwa - jest wszystkim, co ta przyszłość niesie dla każdego z nas.


Gdy przywódcy, mający wizję przyszłości bardziej godnej marzeń, giną wskutek szaleństwa (czy też zdeformowanego obrazu rzeczywistości) mordercy, to czy ich marzenie umrze także? Czy też inni - może ty - wystąpią, by podtrzymywać to marzenie, tak dla „chorych”, jak i dla „zdrowych”?


Teolog Martin Buber (1957) napisał: „Najważniejszymi wydarzeniami w historii tej ucieleśnionej możliwości zwanej człowiekiem są pojawiające się co jakiś czas początki nowych epok, zdeterminowane przez siły uprzednio niewidoczne lub niezauważone. Każdy wiek jest oczywiście kontynuacją poprzedniego, lecz kontynuacja może być potwierdzeniem, a może być zaprzeczeniem” (s. 167).


W ostatecznym rachunku to, czy marzenie o lepszej przyszłości zostanie potwierdzone, czy obalone, będzie zależało od |zachowania |jednostek oraz od umowy społecznej, którą skłonni jesteśmy zawrzeć - co każdy z nas jest gotów zrobić, nie tylko dla siebie samego, ale i dla nas wszystkich, aby wspólne marzenie stało się rzeczywistością.




Streszczenie rozdziału




Przez |psychoterapię rozumie się zazwyczaj psychologiczne leczenie pewnej anormalności myślenia, emocji lub działania. Ponieważ pojęcie normalności jest względne i zależne od danej kultury, dlatego też może to niestety oznaczać przystosowanie jednostki do wzorca obowiązującego w danej społeczności. Obecnie psychoterapię zaczyna się stosować nie tylko dla przywracania, ale i dla zachowania zdrowia.
Do specjalistów przeprowadzających formalną psychoterapię należą: 
|psychiatrzy, którzy uzyskali stopień doktora medycyny i specjalizację w zakresie leczenia chorób psychicznych; |psychologowie |kliniczni, którzy mają przygotowanie akademickie i praktykę kliniczną, lecz nie posiadają dyplomu lekarskiego; wreszcie |psychoanalitycy, którzy uzyskali przygotowanie zgodne z freudowskim podejściem do pychoterapii. Różne rodzaje terapii można podzielić na te, które reprezentują |biologiczny lub |psychodynamiczny punkt widzenia, kładąc nacisk na przyczyny tkwiące w danej jednostce, oraz te, które przyjmują |behawiorystyczny lub |egzystencjalno-|humanistyczny punkt widzenia, podkreślając znaczenie przyczyn sytuacyjnych i potencjalnych możliwości rozwoju człowieka.
|Biologiczne, czyli |somatyczne formy terapii obejmują terapię wstrząsową, chemioterapię i psychochirurgię. Najbardziej rozpowszechniona forma |terapii |wstrząsowej polega na wymierzaniu kontrolowanych wstrząsów elektrycznych za pośrednictwem elektrod przymocowanych do głowy pacjenta.  Zabiegi te okazały się skuteczne w przypadkach ciężkiej depresji.
Leki stosowane w |chemioterapii można podzielić na środki uspokajające, pobudzające oraz halucynogenne. |Środki |uspokajające redukują lęk i podniecenie, umożliwiając danej jednostce bardziej adekwatne funkcjonowanie. |Środki |pobudzające są przydatne w leczeniu pacjentów cierpiących na depresję. |Środki |halucynogenne, takie jak meskalina i LSD, okazały się użyteczne, gdyż czynią pacjentów bardziej podatnymi na psychoterapię. Leczenie środkami farmakologicznymi nie prowadzi jednak do trwałego wyleczenia i może powodować psychiczne uzależnienie od tych środków. |Reakcje |na |placebo utrudniają ocenę skuteczności działania środków farmakologicznych.
|Psychochirurgia polega na przecięciu włókien nerwowych w mózgu, co redukuje emocje związane z myślami i wspomnieniami danej jednostki. Jest to drastyczna i wysoce kontrowersyjna forma leczenia, stosowana tylko w ostateczności. Terapia biologiczna zakłada fizyczne przyczyny choroby psychicznej (stąd nazwa „model medyczny”), nie uwzględniając takich czynników, jak uczenie się oraz interakcja społeczna.
|Psychodynamiczne formy terapii również zakładają istnienie wewnętrznych przyczyn zaburzenia, lecz raczej psychicznych niż fizycznych.  |Psychoanaliza, oparta na freudowskiej teorii osobowości, dąży do wywołania zmiany osobowości przez ujawnienie wypartych wspomnień i konfliktów.  Stosowane techniki obejmują analizę |swobodnych |skojarzeń, |marzeń |sennych, |oporów i |przeniesienia. Terapeuci neofreudowscy, tacy jak zwolennicy Junga i Adlera, kładą większy nacisk na czynniki kulturowe i samorealizację. Psychoanalizę krytykuje się między innymi z tego powodu, że jest bardzo czasochłonna i zdaje się ignorować występujące w danej chwili objawy.
Różne odmiany terapii |behawioralnej koncentrują się na obserwowalnym zachowaniu i dążą do jego zmiany opierając się na zasadach uczenia się.  Stosowane warianty tej terapii obejmują: a) |wygaszanie, w którym wstrzymuje się wszelkie wzmocnienia, gdy występuje niepożądana reakcja; b) |odwrażliwianie, oparte na zasadzie |hamowania |wzajemnego, w którym dana jednostka przezwycięża lęk; c) |terapię |implozyjną, w czasie której dana osoba zostaje zmuszona do konfrontacji ze wzbudzającymi lęk bodźcami i odkrywa, że nie stało się jej nic złego; d) |uczenie się |awersyjne, w czasie którego niepożądane reakcje kojarzy się z przykrymi bodźcami; e) |wzmacnianie |pozytywne, podczas którego pożądane reakcje kształtuje się za pomocą dających zadowolenie konsekwencji; f) |naśladowanie |modeli, podczas którego dana jednostka obserwuje kogoś wykonującego pożądaną reakcję, a następnie otrzymuje wzmocnienie za jej naśladowanie i wreszcie g) |ekonomię |żetonową, procedurę, dzięki której podlegające jej osoby (znajdujące się w pewnej instytucji - szkole, więzieniu, szpitalu psychiatrycznym) otrzymują żetony w zamian za określone zachowania; żetony te mogą następnie wymienić na różne przywileje. Wymienione techniki terapii są bardzo skuteczne, zajmują mniej czasu niż tradycyjne rodzaje terapii i wymagają mniejszych kwalifikacji ze strony terapeuty. Trudno jest jednak wyodrębnić i ocenić „czyste” techniki behawioralne, ponieważ zasady uczenia się mogą w nich mieszać się z manipulacjami poznawczymi; ponadto wyniki terapii nie zawsze generalizują się na realne sytuacje życiowe.
|Egzystencjalno-|humanistyczne formy terapii rozwinęły się z tak zwanej „trzeciej siły” w psychologii i są mniej pesymistyczne i mechanistyczne niż inne podejścia. Egzystencjalizm koncentruje się na osobie takiej, jaka ona jest „tu i teraz”, na procesie „stawania się”. |Logoterapia, jedna z form terapii egzystencjalnej, kładzie nacisk na pragnienie znalezienia sensu we własnym życiu; jedną ze stosowanych w niej technik jest |intencja |paradoksalna.
Jednym z najwcześniejszych przykładów psychoterapii humanistycznej była |skoncentrowana |na |pacjencie |terapia Carla Rogersa; podczas tego typu terapii |niedyrektywny terapeuta stwarza „bezpieczną” atmosferę - dzięki temu pacjent może swobodnie ujawnić swe ukrywane uczucia, lepiej zrozumieć i bardzie zaakceptować siebie samego. Coraz częściej są stosowane techniki, w których zachęca się terapeutę do ujawniania swych własnych uczuć i doznań. Każdy terapeuta definiuje problem pacjenta z punktu widzenia określonego stanowiska teoretycznego. Trudno więc jest ocenić skuteczność różnych form terapii w leczeniu poszczególnych zaburzeń. Istnieją nawet pewne wątpliwości co do tego, czy jakakolwiek forma terapii jest bardziej skuteczna, niż niestosowanie terapii w ogóle. Ocenę utrudniają takie czynniki, jak subiektywne lub niejasne kryteria, odmienne cele oraz niedostateczne kontrolowanie badań mających na celu ocenianie skuteczności terapii.
|Grupy terapeutyczne pozwalają bardziej ekonomicznie wykorzystać czas oraz kwalifikacje personelu, a ponadto sprzyjają interakcji między pacjentami. Terapia grupowa przynosi duże korzyści niektórym pacjentom.  |Grupy |uwrażliwiające dostarczają uczestnikom intensywnych doświadczeń interpersonalnych; zyskują sobie one coraz większą popularność wśród osób „normalnych”, gdyż dają sposobność lepszego poznania siebie i realizacji swych potencjalnych możliwości. Niektóre jednostki mogą jednak zostać poszkodowane w wyniku swych przeżyć w takich grupach; wiele zależy od kwalifikacji i przygotowania osoby prowadzącej grupę.
Większość terapeutów wybiera obecnie |podejście |elektyczne, nie ograniczając się do jakiejś jednej procedury, lecz stosując pewną kombinację technik. Kompletny program |zintegrowanej |opieki możliwy jest do zrealizowania w warunkach szpitalnych. Koncepcja |społeczności |terapeutycznej kładzie nacisk na interakcję i współdziałanie między lekarzami, pacjentami i personelem administracyjnym. Jednakże przepełnienie i brak funduszów doprowadziły do powstania godnych pożałowania warunków w wielu wielkich szpitalach, które stały się raczej instytucjami opiekuńczymi niż rehabilitacyjnymi.
|Subsydiowane przez rząd |społeczne |ośrodki |zdrowia |psychicznego przekazują lojalnej społeczności opiekę nad pacjentami, sprawowaną dotąd przez wielkie szpitale stanowe; w swej działalności ośrodki te kładą nacisk na zaspokajanie potrzeb lokalnej społeczności i zapobieganie zaburzeniom zdrowia psychicznego. Coraz silniej zaznacza się tendencja do powierzania nieprofesjonalistom funkcji terapeutycznych i do stwarzania warunków, w których pacjenci mogliby uczyć się efektywnego funkcjonowania w realnym świecie. Ponieważ mamy do czynienia ze zmieniającym się społeczeństwem, w którym „szok przyszłości” jest coraz istotniejszym problemem, przeto ważniejsza niż kiedykolwiek jest teraz konieczność ustalenia, czyim interesom i wartościom - jednostki czy społeczeństwa - powinna służyć terapia.




Z Frontu Badań.
Terapia dla
rywalizacyjnego
społeczeństwa




|Elliot |Aronson |University of California, Santa Cruz”


Amerykanie z wygranej uczynili sobie bożka. Nasze społeczeństwo - od kibiców na uczelnianym stadionie piłki nożnej, śpiewających „My jesteśmy na pierwszym miejscu”, i gracza ligii szkolnej, który wybucha płaczem, gdy jego drużyna przegra, do Lyndona Johnsona, który wysyłał bez końca ludzi i broń do Wietnamu, oświadczając, że nie zamierza być pierwszym prezydentem amerykańskim, który przegra wojnę - wyraża swoje przywiązanie do zwycięstw i swą pogardę dla przegrywających.
Jakie są następstwa takiej postawy? Jak zachowują się ludzie, gdy ich współzawodnictwo jest sposobem życia i gdy gnębi ich strach przed zajęciem drugiego miejsca? Jest im trudno odprężyć się; patrzą na siebie nawzajem jak na rywali i potencjalnych wrogów; ciągle oglądają się, czy ktoś ich nie wyprzedza; trudno jest im przyznać się do słabości, wrażliwości czy innych ludzkich cech. Cierpią wskutek zawiści i zazdrości, gdy jakiś znajomy dostanie dobrą pracę lub odnosi sukcesy jako lekarz, prawnik czy fryzjer. I gdy raz człowiek znajdzie się w tym kieracie - to nie ma wytchnienia, nie ma żadnego spokojnego portu, żadnego miejsca wypoczynku. Większość ludzi nie odpręża się nawet wtedy, gdy ich udziałem stanął się największe osiągnięcia. Gdy otrzymasz Nagrodę Nobla, to pierwszym pytaniem, jakie usłyszysz będzie: „A nad czym Pan teraz pracuje?
Skłonność do rywalizacji nie jest wrodzona - lecz wydaje się taką, ponieważ człowiek uczy się jej wcześnie, jednym zaś z miejsc, gdzie odbywa się ta nauka, jest klasa szkolna. Ostatnio przeprowadziliśmy systematyczne obserwacje w bardzo wielu klasach szkół podstawowych. Najbardziej typowa sytuacja, jaką widzieliśmy, była następująca: nauczycielka stoi przed klasą, zadaje pytanie, a dzieci mają na nie odpowiedzieć. Najczęściej sześcioro do dziesięciorga dzieci podrywa się z miejsc i wyciąga ręce, wymachując nimi. Wydaje się, ze bardzo chcą, aby je zapytano. Kilkoro innych uczniów siedzi cicho, nie patrząc na nauczycielkę, jak gdyby usiłowali stać się niewidoczni. Gdy nauczycielka „wyrywa do odpowiedzi” jednego z uczniów (a przecież może ona „wyrwać” tylko jednego), to można zaobserwować wyraz rozczarowania, niezadowolenia i przykrości na twarzach tych uczniów, którzy tak ochoczo podnosili ręce, lecz nie zostali wybrani.  Jeśli uczeń wezwany do odpowiedzi poda właściwą odpowiedź, to nauczycielka uśmiecha się, kiwa głową i przechodzi do następnego pytania. Jest to wielka nagroda dla ucznia, który został wybrany przez nauczycielkę. W tym samym czasie, gdy szczęśliwy uczeń podaje właściwa odpowiedź nagrodzoną uśmiechem, można usłyszeć wyraźny jęk, wydany przez te dzieci, które nie zostały wyrwane do odpowiedzi. Jest oczywiste, że są one rozczarowane, ponieważ straciły sposobność pokazania nauczycielce, jakie są inteligentne i bystre.


W procesie tym uczniowie uczą się kilku rzeczy. Po pierwsze, uczą się oni, że jest jeden i tylko jeden ekspert w klasie: nauczycielka. Uczą sie także, że istnieje jedna i tylko jedna poprawna odpowiedź na każde pytanie, jakie zadaje nauczycielka: ta mianowicie odpowiedź, którą nauczycielka ma na myśli. Zadaniem ucznia jest domyślić się, jakiej odpowiedzi oczekuje nauczycielka. Uczniowie także uczą się, że nagrodę zapewni im przypodobanie się nauczycielce, przez pokazanie jej, jak bardzo są oni bystrzy, inteligentni, schludni, czyści i grzeczni. Jeśli dane dziecko robi to z powodzeniem, to zyskuje szacunek i miłość tej potężnej osoby. Osoba ta będzie wówczas miła dla dziecka i powie jego rodzicom, że jest ono cudowne.
Gra jest wysoce rywalizacyjna. Co więcej, stawki są bardzo wysokie.  Przypomnij sobie czasy, gdy sam chodziłeś do szkoły podstawowej. Założę się, że pamiętasz dobrze swoich nauczycieli - być może nawet lepiej niż niektórych wykładowców ze swej uczelni, których wpływ, choć świeższej daty, nie był chyba jednak głębszy. W szkole podstawowej stawki są wyższe właśnie dlatego, że dzieci rywalizują o miłość jednej z dwóch czy trzech najważniejszych osób w ich świecie (ważnej w każdym razie dla większości uczniów). Jeśli jesteś uczniem, który zna poprawną odpowiedź, a nauczyciel zapyta jakieś inne dziecko, to jest prawdopodobne, że będziesz siedział i modlił się, aby ono dało złą odpowiedź, tak abyś ty miał szansę pokazać nauczycielce, jaki jesteś bystry. Ci, którym się powiodło, lub ci, którzy nawet nie podnieśli rąk i nie stawali do rywalizacji, skłonni są nie cierpieć tych dzieci, które odniosły sukces. Często stają się zawistni i zazdrośni: mogą starać się „usadzić” je, nazywając je „lizusami”. Mogą nawet użyć przeciwko nim przemocy fizycznej na podwórku szkolnym. Ze swej strony, uczniowie odnoszący sukcesy często mają w pogardzie słabych uczniów; uważają ich za tępych i nieinteresujących. W rezultacie proces ten, który zachodzi w większym lub mniejszym stopniu w większości szkół podstawowych, nie sprzyja bynajmniej rozwijaniu przyjaźni i zrozumienia między dziećmi uczęszczającymi do tej samej klasy. Wprost przeciwnie.
Proces, który zachodzi w klasie, nie zachęca dziecka do patrzenia z przychylnością na swych kolegów; nie jest procesem, który miałby na celu zwiększenie wzajemnego zrozumienia i atrakcyjności interpersonalnej. Proces ten sprzyja natomiast rywalizacji, egoizmowi, zawiści, zazdrości i podejrzeniom. Gdy doda się do tego już istniejące napięcia rasowe, które występują w każdej społeczności miejskiej, to trudno się dziwić zdarzającym się często aktom przemocy.
Wcale tak jednak być nie musi. Kilka lat temu próbowaliśmy odwrócić kierunek tego procesu w szkołach podstawowych dużego miasta na Południowym Zachodzie Stanów Zjednoczonych. Nasza próba zmodyfikowania tego procesu była stosunkowo prosta. Po pierwsze, zmieniliśmy strukturę klas, składającą się dotąd z jednego eksperta i trzydziestu słuchaczy, rozmieszczając uczniów w małych grupach, z których każda składała się z sześciu uczniów.  Wyeliminowaliśmy nauczycielkę jako główne źródło informacji dla każdej z grup, przez ukształtowanie procesu, dzięki któremu dzieci musiały zwracać się do siebie |nawzajem po informacje i pomoc. Osiągnięto to dwoma sposobami: 1) ustrukturalizowaliśmy ten proces tak, aby rywalizacja była nie do pogodzenia z sukcesem oraz 2) współpracę dzieci uczyniliśmy warunkiem sukcesu. W tradycyjnej klasie dziecko uzyskuje nagrodę, gdy uda mu się zwrócić na siebie uwagę nauczycielki przez przyćmienie rywali. W klasie współpracującej, jaką stworzyliśmy, dzieci osiągały sukces, jeśli zwracały uwagę na inne dzieci i zadawały im właściwe pytania, pomagały sobie nawzajem, uczyły jedno drugie i pomagały sobie uczyć się wzajemnie.
Jak to się stało? Spróbujmy tchnąć nieco życia w powyższy suchy schemat podając trochę szczegółów. Po pierwsze, nie dążyliśmy do zmiany treści nauczania. Realizowaliśmy ten sam program, co i nauczyciele. Wyjaśni to przykład. Nasz pierwszy eksperyment rozpoczęliśmy w klasie piątej wtedy, gdy uczniowie poznawali życiorysy wielkich Amerykanów. Najbliższa lekcja miała być poświęcona biografii Josepha Pulitzera (Joseph Pulitzer, 1847-1911, amerykański dziennikarz i wydawca urodzony na Węgrzech (przyp.  tłum.)). Najpierw opracowaliśmy życiorys Pulitzera składający się z sześciu odcinków. Odcinek pierwszy był poświęcony przodkom Pulitzera i ich przybyciu do Stanów. Odcinek drugi mówił o Pulitzerze jako małym chłopcu i o tym, jak dorastał. Z odcinka trzeciego można się było dowiedzieć o młodzieńczych latach Pulitzera - jego studiach i pierwszej pracy. W odcinku czwartym, w którym Pulitzer występował jako człowiek w średnim wieku, była mowa o tym, jak założył on swój dziennik - i tak dalej. W każdym odcinku zawarty był inny, ważny aspekt życia Josepha Pulitzera. Powieliliśmy ten życiorys i rozcięliśmy każdy egzemplarz na sześć części, z których każda zawierała jeden odcinek. Każde dziecko wchodzące w skład sześciosobowej grupy otrzymało inny odcinek życiorysu Pulitzera.
Każda grupa miała zatem w sumie cały życiorys Josepha Pulitzera, lecz każde dziecko dysponowało tylko jedną szóstą jego biografii. Aby nauczyć się życiorysu Josepha Pulitzera, musiały one opanować swój odcinek i nauczyć go innych. Na przykład Johnnie był odpowiedzialny za zreferowanie odcinka przedstawiającego Pulitzera jako młodego człowieka. Carlos był odpowiedzialny za Pulitzera jako dziecko itd. Każdy uczeń brał swój odcinek, czytał go parę razy, a następnie spotykał się z tymi dziećmi z pozostałych grup, które również czytały ów odcinek. To jest, jeśli Johnnie zajmował się Pulitzerem jako młodym człowiekiem, to konsultował się z Mille, Tedem, Jane i Samem, którzy w innych grupach również zajmowali się Pulitzerem jako młodym człowiekiem. Mogli oni wzajemnie skorzystać ze swej pomocy przy utrwalaniu i wyjaśnianiu ważnych aspektów danej fazy życia Josepha Pulitzera. Wkrótce potem każde z tych dzieci wracało na posiedzenie swej sześcioosobowej grupy. Poinformowano je, że mają trochę czasu na przekazanie sobie nawzajem swych wiadomości. Poinformowano je także, że na koniec zostanie przeprowadzony sprawdzian ich wiedzy na ten temat. Proces ten bardzo przypomina kompletowanie układanki, przy czym każdy uczeń jest w posiadaniu jednego niezbędnego fragmentu całego obrazka. Nazwaliśmy więc nasz system modelem „układankowym”.
Zdane na własne siły dzieci nauczyły się w końcu uczyć siebie nawzajem i słuchać jedno drugiego. Dzieci nauczyły się, że żadne z nich nie może osiągnąć dobrego wyniku bez pomocy wszystkich członków tej grupy - i że każdy jej członek wnosi od siebie coś szczególnego i ważnego. Przypuśćmy, że ty i ja jesteśmy dziećmi należącymi do tej samej grupy. Ty zajmujesz się Josephem Pulitzerem jako młodym człowiekiem, ja zajmuje się Pulitzerem jako starcem. Jedynym sposobem, w jaki mogę dowiedzieć się czegoś o Pulitzerze jako młodym człowieku jest pilne uważanie na to, co mówisz. Jesteś dla mnie bardzo ważnym źródłem informacji. Nauczycielka nie jest już jedynym źródłem wiedzy - nie jest ona nawet ważnym jej źródłem; w istocie nie ma jej nawet w grupie. Ważne natomiast staje się dla mnie każde dziecko z mego „kółka”.  Uzyskam dobry wynik, jeśli będę zwracał uwagę na inne dzieci; jeśli nie będę tego robił - to uzyskam słaby wynik. Jest to całkiem nowa gra.
Ta metoda uczenia się jest jedyna w swoim rodzaju dzięki elementowi wzajemnej zależności; właśnie ta wzajemna zależność każdego ucznia od wszystkich innych uczniów zachęca ich do aktywnego udziału w procesie uczenia się. Stając się kimś w rodzaju nauczyciela, każdy uczeń staje się wartościowym źródłem wiedzy dla innych. Uczenie się od siebie nawzajem stopniowo zmniejsza potrzebę prześcigania innych, ponieważ to, czego nauczy się jeden uczeń, pomaga, zamiast przeszkadzać, innym w nauce, jak to zwykle jest w większości tradycyjnych klas skupionych na nauczycielu. W paradygmacie opartym na współpracy nauczyciel uczy się być osobą pomagającą w nauce i wraz ze swymi uczniami bierze udział w procesie uczenia się i nauczania, zamiast być jedynym źródłem wiedzy. Zamiast udzielać wiedzy uczniom, nauczyciel ułatwia wzajemne uczenie się, w którym od każdego ucznia wymaga się, aby był aktywnym uczestnikiem, odpowiedzialnym za to, czego się uczy.
Zachowanie o charakterze współpracy nie występuje od razu. Bardzo trudno jest przełamać stare nawyki. Opisywane dzieci w ciągu pierwszych czterech lat nauki w szkole przyzwyczaiły się do rywalizacji. Przez pierwszych kilka dni realizowania systemu „układanki”, uczniowie z reguły usiłowali rywalizować - mimo że rywalizacja była teraz dysfunkcjonalna. Przytoczę autentyczny przykład ukazujący, w sposób całkiem typowy, trudności, z jakimi borykały się dzieci uczące się procesu współdziałania. W jednej z naszych grup był meksykański chłopiec, którego będziemy nazywać Carlosem.  Carlos nie mówił zbyt płynnie po angielsku (był to jego drugi język).  Nauczył się on przez te lata, aby w klasie siedzieć cicho; obecnie miał wiele trudności przy przekazywaniu innym dzieciom treści swego odcinka i sprawiało mu to dużą przykrość. Tradycyjny sposób podobał mu się znacznie bardziej. Jeśli zastanowimy się nad tym, to stwierdzimy, że nie ma w tym nic dziwnego - w systemie, jaki wprowadziliśmy, Carlos był zmuszony mówić, podczas gdy przedtem w „normalnej” klasie mógł on „dezindywidualizować się” i ukrywać.
Sytuacja była jeszcze bardziej skomplikowana. Można by nawet powiedzieć, że nauczycielka i Carlos zawiązali spisek. Byli oni w zmowie. Carlos bardzo chciał siedzieć spokojnie na lekcji. Dawniej, nauczycielka pytała go od czasu do czas; z reguły zacinał się, jąkał i zapadał w kłopotliwe milczenie. Inne dzieci żartowały sobie z niego. Nauczycielka nauczyła się nie pytać go wcale. Decyzja ta prawdopodobnie wynikła z najczystszej intencji - nie chciała go upokarzać. Lecz ignorując go, „odpisała go na straty”; sugerowało to, że nie warto się nim zajmować - przynajmniej inne dzieci w klasie tak to zrozumiały. Były one przekonane, że jest jeden poważny powód, dla którego nauczycielka nie pyta Carlosa - jest on głupi.  Wydaje się prawdopodobne, że nawet Carlos zaczął dochodzić do tego wniosku.
Wróćmy do naszej sześcioosobowej grupy. Carlos musiał powiedzieć o wieku średnim Josepha Pulitzera i miał z tym mnóstwo kłopotów. Jąkał się, zacinał i kręcił się nerwowo. Inne dzieci w grupie były niezbyt skłonne do pomocy.  Przywykły do procesu rywalizacji i reagowały zgodnie z tym starym, dobrze utrwalonym nawykiem. Wiedziały one, co robić, kiedy jakieś dziecko zacina się - zwłaszcza dziecko, które uważały za głupie. Wyśmiewały go, poniżały i dokuczały mu. Podczas naszego eksperymentu zauważono, że Mary powiedziała do niego: „Ach, ty tego nie umiesz, jesteś głuptas, jesteś głupi. Sam nie wiesz, co robisz”.
W naszym pierwszym eksperymencie dzieci były dyskretnie kontrolowane przez asystentkę, która chodziła od grupy do grupy. Gdy incydent ten dotarł do jej ucha, wówczas nasza asystentka interweniowała. Interwencja ta wyglądała mniej więcej tak: „W porządku, możecie tak robić, jeśli chcecie, możecie tak się zabawiać, lecz nie pomoże to wam dowiedzieć się niczego o Josephie Pulitzerze w średnim wieku; mniej więcej za godzinę będzie egzamin”. Zwróćmy uwagę, jak zmieniły się zasady wzmacniania. Mary nie zyska już dużo poniżając Carlosa, a może wiele stracić.
Po paru dniach i kilku podobnych doświadczeniach, dzieciom zaczęło świtać, że |jedynym sposobem, w jaki mogłyby one dowiedzieć się o wieku średnim Josepha Pulitzera, jest zwracanie uwagi na to, co Carlos ma do powiedzenia. I stopniowo doszło do tego, że zaczęły one przekształcać sie w całkiem dobrych specjalistów od prowadzenia wywiadu. Jeśli Carlos miał trochę trudności z przekazaniem swych wiadomości, to zamiast ignorować go lub wyśmiewać, zaczynały zadawać sondujace pytania tego rodzaju, że ułatwiały one Carlosowi przekazanie tego, co wiedział. Carlos zaczął reagować na ten sposób postępowania coraz bardziej odprężając się, co z kolei zwiększyło jego zdolność komunikowania się. Po paru tygodniach dzieci doszły do wniosku, że Carlos nie był wcale taki głupi, jak myślały. Zaczęły go lubić. Carlosowi szkoła zaczęła się coraz bardziej podobać i zaczął uważać anglojęzyczne dzieci z tej grupy nie za dręczycieli, lecz za jednostki życzliwe i pomocne. 


To, co zaszło w grupie Carlosa, jest dobrym przykładem funkcjonowania tej techniki, która często przynosi dobroczynne skutki; nie są to jednak możliwe do zaakceptowania dane naukowe. Aby uzyskać takie dane, musieliśmy przeprowadzić eksperymenty terenowe, w których systematycznie badaliśmy wpływ techniki „układankowej” na atrakcyjność interpersonalną, samoocenę i zadowolenie ze szkoły. Wprowadziliśmy do klasy technikę „układankową” na okres sześciu tygodni i ocenialiśmy jej skuteczność przeprowadzając pomiary na początku i końcu tego okresu - porównując wyniki uzyskane przez dzieci w klasach „układankowych” z wynikami dzieci w klasach tradycyjnych, gdzie uczyli je nauczyciele o wysokich kwalifikacjach.
Uzyskane przez nas wyniki są całkiem spójne: 1) dzieci w kooperujących klasach „układankowych” polubiły się nawzajem bardziej niż dzieci w klasach tradycyjnych; 2) dzieci w klasach „układankowych” zaczęły bardziej lubić szkołę (lub w mniejszym stopniu ją nienawidzieć) niż dzieci w klasach tradycyjnych; 3) u dzieci w klasach „układankowych” samoocena wzrosła bardziej niż u dzieci w klasach tradycyjnych; 4) oceniając opanowanie materiału dydaktycznego można było stwierdzić, że dzieci w klasach „układankowych” uzyskały równie dobre lub lepsze wyniki niż dzieci w klasach tradycyjnych. Mówiąc dokładniej, podczas gdy dzieci anglojęzyczne uzyskiwały równie dobre wyniki w obu typach klas, to dzieci z mniejszości etnicznych w zintegrowanych szkołach osiągały znacznie lepsze wyniki w klasach „układankowych” niż w klasach tradycyjnych; 5) dzieci lubiły wzajemne współdziałanie bardziej niż rywalizację.
Nasze badania wykazały, że to, co wydawało się głęboko zakorzenionym sposobem zachowania - rywalizację, można modyfikować. Naszym celem nie jest pozbawienie dziecka zdolności rywalizowania; pewien element rywalizacji może być zabawny i może w wielu okolicznościach podnosić poziom wykonania.  To, co chcemy zrobić, to nauczyć współdziałania - tak abyśmy nie usiłowali zawzięcie pokonać drugiej osoby, gdy znajdziemy się w sytuacji, w której potrzebne jest współdziałanie. W naszym eksperymencie dzieci nauczyły się, że można pracować wspólnie i pomagać sobie, nie rezygnując z wysokiego poziomu osiąganych wyników.




VI. Społeczeństwo:

problemy i ich rozwiązania




13. Społeczne podstawy zachowania
14. Degeneracja form życia społecznego



Epilog: Marzenia o przyszłości




Rozdział 13.
Społeczne podstawy
zachowania




Spokój niedzielnego poranka w Palo Alto (stan Kalifornia) zakłóciło wycie syren wozów policyjnych, które pędziły przez miasto zgarniając studentów w niespodziewanych masowych aresztowaniach. Każdego z podejrzanych oskarżono o jakieś przestępstwo, poinformowano o zagwarantowanych mu przez Konstytucję prawach, ustawiono twarzą do wozu policyjnego z rękoma podniesionymi do góry, obszukano, skuto kajdankami i przewieziono na tylnym siedzeniu wozu patrolowego na posterunek policji w celu spisania personaliów.
Po wzięciu odcisków palców i wypełnieniu formularza identyfikacyjnego pozwalającego umieścić go w „kartotece” (centralnym rejestrze informacyjnym), każdego więźnia pozostawiano przez pewien czas w izolatce, a następnie zawiązywano mu oczy i przewożono do więzienia okręgowego w Stanford. Tutaj rozbierano go do naga, dokładnie obszukiwano, poddawano odwszeniu, wydawano uniform więzienny, pościel, mydło i ręcznik.
Uniform więźnia stanowił luźny chałat z numerem identyfikacyjnym z przodu i z tyłu; cały czas noszono łańcuch obejmujący kostkę nogi. Zamiast golić więźniowi głowę (zwykła procedura więzienna), kazano mu nosić zakrywającą włosy czapkę z nylonowej pończochy. Rozkazy wydawano mu krzykiem, a strażnicy popychali go, jeśli nie podporządkował się dostatecznie szybko. W celu dezindywidualizacji strażników umundurowano ich w uniformy khaki typu wojskowego, które nadały im „tożsamość grupową”. Ponadto nie posługiwano się żadnymi imionami ani nazwiskami, a noszone przez strażników okulary przeciwsłoneczne, z połyskującymi srebrzyście szkłami odbijającymi światło, uniemożliwiały nawiązanie kontaktu wzrokowego. Symbolami ich władzy były pałki, gwizdki, kajdanki oraz klucze do cel i bramy głównej.
Późnym popołudniem, gdy zakończono już aresztowania i z każdym nowo przybyłym więźniem załatwiono wszelkie niezbędne formalności, naczelnik więzienia powitał swych nowych podopiecznych i odczytał 16 podstawowych reguł dotyczących postępowania więźnia (ułożonych uprzednio przez naczelnika i jedenastu podległych mu funkcjonariuszy):
Reguła pierwsza: „Więźniowie muszą zachować milczenie podczas odpoczynku, a także po zgaszeniu świateł, w czasie posiłków i zawsze wtedy, gdy znajdą się poza dziedzińcem więziennym”. Reguła druga: „Więźniowie muszą jeść w czasie przeznaczonym na posiłki i tylko wtedy”. Reguła trzecia: „Więźniom nie wolno psuć, brudzić ani uszkadzać ścian, sufitów, okien, drzwi lub innych rzeczy będących własnością więzienia” (...). Reguła siódma: „Więzień zwracający się do innego więźnia może wymienić tylko jego numer identyfikacyjny”. Reguła ósma: „Więźniowie zwracający się do strażników muszą tytułować ich: „Panie funkcjonariuszu korekcyjny” (Mr Correctional Officer)” (...). Reguła szesnasta: „Niepodporządkowanie się którejkolwiek z powyższych reguł może pociągnąć za sobą karę”.
Młodzi więźniowie, którzy wszyscy (było ich dziewięciu) byli „nie karanymi dotychczas przestępcami”, siedzieli przeważnie na składanych łóżkach w swych pustych celach, oszołomieni i zaszokowani niespodziewanymi zdarzeniami, które tak nagle przeistoczyły ich życie. Jakiego właściwie rodzaju było to więzienie?
W istocie był to bardzo szczególny rodzaj więzienia-eksperymentalne, „pozorne więzienie” utworzone przez psychologów społecznych specjalnie w celu badania psychologicznych skutków, jakie pobyt w więzieniu wywrze na osobach, które zgłosiły się ochotniczo do udziału w tych badaniach (Zimbardo, Haney, Banks i Jaffe, 1973). Zarówno strażników, jak i więźniów zwerbowano za pośrednictwem ogłoszeń zamieszczonych w miejscowej gazecie, a zachęcających studentów do ochotniczego wzięcia udziału w dwutygodniowych badaniach nad życiem więziennym. Zapłata w wysokości 15 dolarów dziennie przyciągnęła ponad stu ochotników, z którymi następnie przeprowadzono wywiady kliniczne; spośród nich wybrano dwa tuziny studentów - potencjalnych uczestników eksperymentu. Wybrano ich dlatego, że na podstawie dokładnego zbadania testami osobowości oceniono ich jako stabilnych emocjonalnie, zdrowych fizycznie, „normalnych”, „przeciętnych” oraz jako przestrzegających prawa (nie dopuścili się w przeszłości żadnych przestępstw, aktów przemocy ani nie nadużywali środków psychotropowych).  Powiedziano im, że o późniejszym przydzieleniu ich do grupy „strażników” lub „więźniów” zadecyduje los, a mianowicie rzut monetą. Gdy pytano ich o preferencje, wówczas wszyscy powiedzieli, że woleliby być więźniami.
Na początku badania nie było zatem żadnych dających się zmierzyć różnic między młodymi ludźmi wyznaczonymi na strażników i tymi, którzy mieli odgrywać rolę więźniów. Stanowili oni względnie jednorodną próbkę białych, pochodzących z klasy średniej, studentów uczelni Stanów Zjednoczonych i Kanady. |Nie zostali oni jednak poinformowani, że eksperyment rozpocznie się od zaaresztowania przez policję miejską. „Funkcjonariusze korekcyjni” nie przeszli żadnego specjalnego przeszkolenia, w czasie którego przyuczono by ich, jak być strażnikiem więziennym. Powiedziano im tylko, aby „dbali o przestrzeganie prawa i porządku” w więzieniu i nie pozwalali na żadne głupstwa ze strony więźniów - którzy mogliby okazać się niebezpieczni, gdyby próbowali uciec. Stosowanie przemocy fizycznej zostało zakazane.
„Więzienie” mieściło się w suterenach budynku zajmowanego przez wydział psychologii Stanford University, który stał pusty po zakończeniu letniej sesji egzaminacyjnej. Długi korytarz przekształcono w „dziedziniec więzienny” przez ogrodzenie obu jego końców. Trzy małe pomieszczenia laboratoryjne otwierające się na ten korytarz zamieniono na cele: zwykłe drzwi zastąpiono kratami, na miejsce usuniętych mebli do każdego pomieszczenia wstawiono trzy łóżka polowe. Mały, ciemny magazyn naprzeciw cel służył jako „izolatka” i oznaczono go odpowiednim napisem: „The Hole” (Karcer). Zebrane dane obejmowały zarejestrowane na taśmie magnetowidu interakcje strażników i więźniów, bezpośrednie obserwacje dokonywane przez zespół badaczy, wywiady z badanymi, ich odpowiedzi na cała baterię kwestionariuszy osobowości oraz wypowiedzi w dziennikarzach, listach i codziennych sprawozdaniach.
To „pozorne więzienie” stanowiło próbę |funkcjonalnego symulowania niektórych istotnych cech stanu psychicznego występującego u więźniów.  Opracowano szereg procedur mających na celu taką operacjonalizację zmiennych występujących w sytuacjach więziennych, aby były one maksymalnie skuteczne, biorąc pod uwagę ograniczenia sytuacji badawczej. Nie chodziło przy tym o dokładne skopiowanie rzeczywistych warunków więziennych, lecz o osiągnięcie pewnych równoważnych efektów |psychicznych, pomimo odmiennych szczegółów fizycznych.
Podjęto jednak różne kroki w celu zapewnienia wystarczającego wrażenia realności sytuacji (tzw. realizmu codzienności - „mundane realism”; zob.  Aronson i Carlsmith, 1969), aby uczestnicy mogli wyjść poza powierzchowne wymagania wyznaczonych im ról i wczuć się w głębszą strukturę mentalności więźnia i strażnika. Odbywały się wizyty byłego kapelana więziennego, obrońcy publicznego, krewnych i przyjaciół niektórych więźniów, przesłuchania dyscyplinarne lub w sprawach przedterminowego zwolnienia prowadzone przez komisję złożoną z „osób dorosłych o dużym autorytecie”.  Chociaż rzekomi „strażnicy” pracowali na zmiany po 8 godzin dziennie, to rzekomi więźniowie pozostawali zamknięci w swych celach przez całą dobę, a wypuszczano ich z celi jedynie na posiłki, ćwiczenia, do toalety, na apele i do odpowiednich prac.
W bardzo krótkim czasie wytworzyły się patologiczne stosunki między więźniami a strażnikami. Po tym, jak ich początkowy bunt został stłumiony, więźniowie reagowali biernie na wzmagającą się z każdym dniem agresywność strażników - ich pewność siebie prowadziła do coraz większej zależności i uległości więźniów; autorytet strażników wiązał się z obniżeniem poczucia własnej wartości więźniów, podczas gdy odpowiednikiem nowo odkrytego poczucia nieskrępowanej władzy u strażników była depresja i wyuczone poczucie bezradności u więźniów. Jeszcze przed upływem 36 godzin trzeba było zwolnić pierwszego więźnia ze względu na trudne do opanowania napady płaczu, wybuchy gniewu, dezorganizację myślenia i poważną depresję. U trzech dalszych więźniów rozwinęły się podobne objawy i również trzeba ich było zwolnić w następnych dniach. Piątego więźnia zwolniono, gdy wystąpiła u niego psychosomatyczna wysypka na całym ciele, przy czym bezpośrednim jej powodem było odrzucenie przez fikcyjną „Komisję do Spraw Zwolnień” jego prośby o przedterminowe zwolnienie.
|Władza („social power”) stałą się głównym wymiarem, służącym do określania wszystkich i wszystkiego. Chociaż początkowo nie było różnic między studentami wyznaczonymi do odgrywania ról więźniów i strażników, to jednak wypełnianie tych ról w sytuacji społecznej, która uwypuklała różnice pod względem posiadanej władzy, doprowadziło do powstania ogromnych różnic między zachowaniem i reakcjami emocjonalnymi obu tych grup. Jak wykazała analiza taśm magnetowidowych, najczęstszymi formami interakcji zapoczątkowanymi przez strażników było wydawanie rozkazów, obrzucanie więźniów obelgami, czynienie poniżających aluzji, akty słownej i fizycznej agresji oraz groźby; w przypadku więźniów było to opieranie się, udzielanie informacji w odpowiedzi na pytania, zadawanie pytań oraz (początkowo) występowanie przeciw strażnikom.
Każdy ze strażników, w którymś momencie, postępował z więźniami w sposób obelżywy i despotyczny (autorytarny). Wielu zdawało się cieszyć wyższą pozycją, jaką zapewniało im założenie munduru strażnika - przeistaczał on ich codzienną, zwykłą egzystencje, w taką, w której mieli niemal całkowitą władzę nad innymi ludźmi.
Gdy te różnice w zachowaniu, nastroju i percepcji wystąpiły wyraźniej, wówczas konieczność kierowania niewątpliwie niżej stojącymi (i bezsilnymi) więźniami przez strażników „słusznie” już teraz dysponujących siłą, stała się wystarczającym usprawiedliwieniem, by uzasadnić niemal każde niegodne traktowanie człowieka.
Zapoznajmy się z poniższymi typowymi uwagami, zaczerpniętymi z ich dzienników, wywiadów przeprowadzonych po zakończeniu eksperymentu oraz sprawozdań:
Strażnik A: „Byłem zaskoczony sobą samym (...). Kazałem im wymyślać sobie wzajemnie i czyścić toalety gołymi rękami. Właściwie uważałem więźniów za bydło i ciągle myślałem o tym, że muszę mieć się przed nimi na baczności w sytuacji, gdyby próbowali coś zrobić”.
Strażnik B: („o przygotowaniach do pierwszego wieczoru odwiedzin): Po ostrzeżeniu więźniów, żeby nie składali żadnych skarg, jeśli nie chcą, aby wizyta szybko się skończyła, wprowadziliśmy w końcu pierwszych rodziców.  Postarałem się o to, aby być jednym ze strażników pełniących służbę na dziedzińcu, ponieważ była to moja pierwsza szansa uzyskania tego typu władzy, jaką naprawdę lubię: manipulować innymi, być bardzo ważną postacią, mającą całkowitą kontrolę nad tym, co się mówi lub czego się nie mówi”.
Strażnik C: „Postępowanie w sposób autorytatywny może być zabawne. Władza może być wielką przyjemnością”.
Zaplanowany na dwa tygodnie eksperyment symulacyjny badacze przerwali po sześciu dniach z powodu patologicznych reakcji, jakie występował o osób starannie wybranych ze względu na swą normalność, zdrowie i zrównoważenie emocjonalne.
Nie stwierdzono żadnej zależności między wynikami testów osobowości lub innymi zmiennymi związanymi z różnicami w reakcjach więźniów i strażników.  Obserwowanej tu patologii nie można zatem w uzasadniony sposób przypisać uprzednio posiadanym cechom osobowości - takim, które mają „psychopatyczni” czy „sadystyczni” strażnicy lub „wstępni, słabo panujący nad swymi popędami” więźniowie. Anormalne zachowanie indywidualne i społeczne, w obu grupach, najlepiej jest rozpatrywać jako wytwór interakcji ze środowiskiem, które podtrzymuje takie zachowanie.
Ponieważ role „strażników” i „więźniów” przydzielano w sposób losowy badanym osobom, które nie przejawiały uprzednio żadnej patologii osobowości, i nie przechodziły żadnego przeszkolenia przygotowującego je do pełnienia tych ról, to w jaki sposób moglibyśmy wyjaśnić fakt, że tak łatwo i szybko przyjęły te role? Przypuszczalnie, podobnie jak my wszyscy, miały one wyuczone, stereotypowe pojęcia o roli strażnika i więźnia, zaczerpnięte ze środków masowego przekazu, jak również ze społecznych modeli władzy i podporządkowywania się jej (ojciec - dziecko, nauczyciel - uczeń, szef - pracownik, policjant - podejrzany, itd). W istocie, badania te nie tylko pozwalają się przekonać, co środowisko podobne do więzienia może „wydobyć” ze stosunkowo normalnych ludzi, lecz także pokazują, jak w procesie socjalizacji zostali oni ukształtowani przez swe społeczeństwo.
Eksperyment ten nie jest bynajmniej typowy dla badań przeprowadzanych przez psychologów społecznych.


Niemniej jednak uwypukla on wiele zagadnień, pojęć i zmiennych, którymi będziemy się zajmować w tym rozdziale - takich jak rzeczywistość społeczna, normy, pozycja (status), role, władza, dynamika grupy, procesy oddziaływania społecznego, konflikt interpersonalny.




Podejście społeczno
-psychologiczne




Psychologia amerykańska, podobnie jak amerykańska religia i polityka, zakłada prymat jednostki. Doktryna indywidualizmu jest kamieniem węgielnym amerykańskiego sposobu myślenia o ewolucji i o istnieniu „jaźni”: wszyscy wierzymy we własną niepowtarzalność, niezależność, samowystarczalność i zdolność oddziaływania, jak również w indywidualne zbawienie oraz to, że wszelkie osobiste sukcesy i korzyści zawdzięczamy naszej własnej inicjatywie i twórczej inwencji. Przekonania te zdają się koegzystować w sposób całkiem naturalny z rozwojem kapitalistycznego porządku ekonomicznego, tradycją romantycznej miłości, formami literackimi kładącymi nacisk na rozwój charakteru oraz - w nowszych czasach - psychologią osobowości i zachowania indywidualnego.
Jednakże przekonania takie są stosunkowo nowe, gdyż nie występowały przed zakończeniem epoki Średniowiecza. W istocie można przytoczyć silne argumenty na rzecz twierdzenia, że to grupa społeczna, a nie jednostka jest podstawowym elementem ewolucji. Życie w grupie zapewnia warunki sprzyjające utrzymaniu się przy życiu, z jakich nie może korzystać osobnik samotny.  Niewątpliwymi korzyściami są: ochrona przed prześladowcami w postaci ostrzeżenia lub kontraktu ze strony grupy oraz bardziej niezawodne i obfite zaopatrzenie w żywność, dzięki polowaniu połączonymi siłami gromady.  Wspólna obrona i opieka, jakie zapewnia więź grupowa, umożliwiają większej liczbie potomstwa osiągnięcie dojrzałości i reprodukcji. Zwiększa to prawdopodobieństwo przekazania następnym pokoleniom cech genetycznych członków takich grup. I przeciwnie, istoty nie należące do grupy społecznej ławiej stają się łupem wrogów z ofiarami fizycznych sił przyrody.
Więź grupowa zapewnia także odpowiednie warunki dla naśladowania, dzięki któremu z przystosowawczej innowacji wprowadzonej przez któregokolwiek członka grupy mogą korzystać wszyscy pozostali.
Psychologia społeczna jest dyscypliną, która bada zachowanie, motywy i spostrzeżenia jednostek jako reakcje na zmienne społeczne. Dyscyplina ta stara się odpowiedzieć na pytanie, w jaki sposób rzeczywista lub wyobrażona obecność innych osób i ich zachowanie wpływają na zachowanie jednostki.  Rozwinęła się ona przede wszystkim w ciągu ostatnich trzydziestu kilku lat, wypełniając lukę między tradycyjną psychologią - która bada zachowanie pojedynczych organizmów, starannie odizolowanych od wpływu złożonych, „zakłócających” zmiennych społecznych - oraz socjologią i antropologią - które badają instytucje społeczne oraz szerszy zakres wpływów kultury na zachowanie człowieka. Aczkolwiek psychologia społeczna również bada reakcje jednostek, to jednak koncentruje się ona na ich znaczeniu poznawczym i konsekwencjach społecznych.
Badając naturę społeczną istoty ludzkiej, psychologowie społeczni koncentrują się niekiedy na zmiennej zależnej - |zachowaniu społecznym, a niekiedy na zmiennej niezależnej - |bodźcach społecznych. W rozdziale tym będziemy rozpatrywać zarówno bodźce społeczne, jak i reakcje społeczne, jak również koncepcje, które wiążą je w relacje (sensowne z psychologicznego punktu widzenia). Stosować tu będziemy na ogół molarny poziom analizy, a zmienne będą bardziej złożone niż w wypadku badań opisanych w poprzednich rozdziałach.
Psychologia społeczna zyskuje obecnie pozycję o zasadniczym znaczeniu, ponieważ staje się coraz bardziej oczywiste, że nawet na reakcje nie mające charakteru społecznego często wywierają wpływ zmienne społeczne, takie jak postawy, wartości, potrzeby społeczne (osiągnięć czy afiliacji), sposób w jaki dana sytuacja jest spostrzegana i określana (a nie to, jaka „jest ona naprawdę”) oraz rozbudowane struktury poznawcze ukształtowane przez procesy socjalizacji. Psychologia społeczna okazuje także coraz większe zainteresowanie zastosowaniem wiedzy uzyskanej w badaniach podstawowych do rozwiązywania palących problemów społecznych.


Rasizm, szowinizm płci („seksizm”), agresja, wandalizm, alienacja, ślepe posłuszeństwo wobec autorytetów oraz konflikty międzynarodowe - oto niektóre tylko istotne problemy społeczeństwa, wymagające społecznego działania, które omówimy w tym i następnym rozdziale.




Atrybucja: wnioskowanie
o cechach i przyczynach




Aby znaleźć jakiś sens w złożonym zachowaniu innych ludzi, wyciągamy wnioski dotyczące ich intencji, emocji, motywów i cech osobowości, a także tego, w jaki stopniu czynniki te są przyczynami ich zachowania. Ten proces poznawczy nosi nazwę |atrybucji („attribution”, dosł. „przypisywanie”): przypisujemy danej osobie lub danemu zachowaniu pewne czynniki sprawcze („underlying conditions”), których nie widzimy, lecz o których wnioskujemy.




Spostrzeganie ludzi




Podobnie jak nasza percepcja przedmiotów, tak i nasze spostrzeganie ludzi jest podatne na różne złudzenia i zniekształcenia. Inaczej mówiąc, często „widzimy” ludzi w sposób odbiegający od tego, w jaki zostali nam oni - obiektywnie rzecz biorąc - zaprezentowani. Jak powstają takie niezbyt trafne wrażenia? Jakimi informacjami posługujemy się przy ocenie osobowości innych osób?


Ocena na pierwszy rzut oka. Być może jesteś przekonany, że twoje oceny ludzi opierają się na starannej analizie ich zachowania. Jest to jednak niemal zupełnie niezgodne z prawdą. Psychologowie stwierdzili, że na ocenę innej osoby silnie wpływają pierwsze wrażenia, które z kolei mogą opierać się na bardzo słabych sygnałach.


„W jednym z „naturalnych” eksperymentów nad wpływem pierwszego wrażenia profesor powiedział swoim słuchaczom, że w tym dniu prowadzi zajęcia zaproszony wykładowca, a następnie przedstawił im krótką notatkę biograficzną o nim. Połowa studentów otrzymała notatkę, w której wykładowca opisany był jako „osoba raczej chłodna, pracowita, krytyczna, praktyczna i zdecydowana”. Inni studenci otrzymali identyczne notatki, lecz słowo „chłodna” (cold) było w nich zastąpione słowem „ciepła” (warm). Tym ostatnim studentom wykładowca nie tylko bardziej się podobał, lecz także częściej zabierali z własnej chęci głos w dyskusji niż ci studenci, którzy otrzymali opis ze słowem „chłodna” (Kelley, 1950).


Dlaczego pierwsze wrażenie wywiera tak silny wpływ? Jedno z wyjaśnień wskazuje, że otrzymana na początku informacja stwarza pewien |układ |odniesienia, którym osoba spostrzegająca posługuje się przy interpretowaniu późniejszych informacji. Jeśli późniejsze informacje są niezgodne z początkowymi, to zniekształca się je tak, aby pasowały do ustalonego układu odniesienia. Proces ten jest bardzo podobny do wpływu nastawienia („set”) w sytuacjach nie mających charakteru społecznego (omawialiśmy je w Rozdziale 6).


Obrazy w naszym umyśle. Większość z nas ma ukształtowane wyobrażenia o różnych ludziach. Na przykład wszyscy „wiemy”, jaki jest nowojorski taksówkarz, niemiecki uczony lub profesor wyższej uczelni. Te wyobrażenia, czyli |stereotypy, wiążą się z przypisywaniem pewnych cech całej grupie ludzi. Gdy takie wyobrażenia są oparte na doświadczeniu i stosunkowo trafne, to ułatwiają nam właściwe postępowanie z innymi ludźmi. Gdy jednak są one fałszywe lub przeszkadzają nam w dostrzeżeniu specyficznych cech danej jednostki, wówczas mogą mieć bardzo ujemny, destrukcyjny wpływ na stosunki międzyludzkie.


Pierwsze poważne badania nad stereotypami wykazały wyraźnie, że ludzie potrafią zgodnie określać cechy, jakie rzekomo posiadają inne osoby (Katz i Braly, 1933).




* * *



Stereotypy Czterech Grup Etnicznych
Cecha - Procent zaznaczających daną cechę (1933 1951 1967)


Japończycy 
Inteligentni - 45 11 20
Pracowici - 43 12 57
Postępowi - 24 2 17
Sprytni - 22 13 7
Chytrzy - 20 21 3


Żydzi 
Sprytni - 79 47 30
Chciwi - 49 28 15
Pracowici - 48 29 33
Łapczywi - 34 17 17
Inteligentni - 29 37 37


Amerykanie 
Pracowici - 48 30 23
Inteligentni - 47 32 20
Zmaterializowani - 
Ambitni - 33 21 42
Postępowi - 27 5 17


Murzyni
Przesądni - 84 41 13
Leniwi - 75 31 26
Beztroscy - 38 17 27
Ignoranci - 38 24 11
Muzykalni - 26 33 47
(Adaptowane z Karlinsa i in., 1969)


* * *





„Stu studentów Princeton University poproszono o wybranie cech, które opisują 10 różnych grup narodowościowych i rasowych. Wyniki wykazały wysoki stopień zgodności stereotypów, o czym świadczą odrębne zbiory określeń (wiele z nich było ujemnych) dla każdej z tych grup. Na przykład Żydów uważano za chytrych i chciwych, Murzynów za przesądnych i leniwych. Niemców zaś za „logicznie myślących” i pracowitych. Z niektórymi z tych grup studenci mieli bardzo mało (lub wcale) do czynienia, wydaje się więc oczywiste, że po prostu przejęli oni stereotypy, które występowały w ich społeczności”.


Po upływie prawie 20 lat na Princeton University powtórzono ten eksperyment, przy czym jego rezultaty wykazały zmniejszenie skłonności do posługiwania się stereotypami (Gilbert, 1951). Ponadto studenci wyrażali większy opór wobec polecenia, by charakteryzować innych ludzi. Ogólnie biorąc, tendencje te utrzymały się w drugim, późniejszym powtórzeniu tych badań w Princeton, aczkolwiek skłonność do posługiwania się stereotypami nadal była wyraźna. Studenci nadal potrafią być zgodni co do „najbardziej charakterystycznych cech” różnych grup, mimo że poszczególne cechy przypisywane tym grupom zmieniły się w ciągu lat, jakie upłynęły od czasu pierwszego badania (Karlins, Coffman i Walters, 1969; tabela).


Spójność i konsekwencja występujące w psychice osoby spostrzegającej.  Poza opieraniem się zbyt silnie na pierwszych wrażeniach i stereotypach, często występują jeszcze inne formy błędnego spostrzegania ludzi. Jednym z najbardziej znanych błędów percepcyjnych tego rodzaju jest tzw. efekt halo (efekt aureoli; „hallo effect”), którego występowanie zauważono już w 1907 roku. Gdy ludzie oceniają inne osoby pod względem różnych cech, to ocena ta jest zwykle zgodna z ogólnym wrażeniem („halo” oznacza dosłownie aureolę) - dobrym lub złym. Jeśli ktoś ceni na przykład grzeczność i uważa, że dana osoba jest uprzejma, to będzie raczej skłonny spostrzegać ją także jako przyjazną, uczciwą i inteligentną. Osoby spostrzegające mogą także popełniać |błąd |logiczny zakładając, że pewne cechy zawsze występują łącznie. Jeśli więc oceniamy kogoś jako silnego, to prawdopodobnie uznamy go także za aktywnego i agresywnego. Trzecim pospolitym rodzajem błędu oceny jest |błąd |łagodności, polegający na przyznawaniu przede wszystkim ocen pozytywnych oraz zmniejszaniu do minimum liczby cech negatywnych.  Prowadzi do to sytuacji, w której ponadprzeciętność staje się normą. I wreszcie błąd |tendencji |centralnej występuje wtedy, gdy oceniający ignoruje zróżnicowanie ludzi (czy też jednej osoby) i ocenia wszystkich jako „dobrych”, „zadowalających” lub „przeciętnych”.
W wyniku wszystkich tych błędów oceny uważamy innych ludzi za bardziej stałych i konsekwentnych, niż są oni w rzeczywistości. W wielu badaniach stwierdzono, że ludzie mogą zachowywać się raczej niekonsekwentnie w różnych sytuacjach. Na przykład, nie można przewidzieć uczciwości danej osoby w jakiejś sytuacji na podstawie tego, jak uczciwie zachowywała się ona w innej sytuacji (Hartshorne i May, 1928). Jednakże, pomimo tego dowiedzionego braku stałości i konsekwencji w zachowaniu ludzi, przyjmujemy, że ludzie |są stali i konsekwentni, a także spostrzegamy ich w ten sposób. O tym, w jakim stopniu my sami „generujemy” tę stałość przez wnioskowanie o cechach czy dyspozycjach stanowiących podłoże zachowania, świadczy nasza skłonność do przypisywania takich cech nawet przedmiotom nieożywionym. Skłonność tę zademonstrowano w badaniu, w którym osoby badane spostrzegały figury geometryczne jako „agresywne”, „nieśmiałe itd., przypisując im cechy, które niewątpliwie nie występują u trójkątów i kółek.




* * *



Ryc. 13.2. W jednym z eksperymentów badanym pokazano film, w którym figury geometryczne poruszały się wewnątrz i na zewnątrz dużego prostokąta.  Tym występującym w filmie „postaciom” badani przypisywali różne motywy - trójkąty często spostrzegano jako dwóch mężczyzn walczących o kobietę (kółko). Oceniając ich ruchy, duży trójkąt spostrzegano jako agresywny, mały trójkąt - jako bohaterski, kółko zaś - jako lękliwe. W odniesieniu do przedstawionej tu sekwencji większość obserwatorów podała, iż widziała, jak „T” zagonił „t” i „c” do domu i zamknął drzwi (Heider i Simmel, 1944).


* * *





Przypuśćmy, że dowiedziałeś się, że pewien człowiek ma opinię uprzejmego, lecz znany jest także jako bardzo nieuczciwy. Zgodnie z wynikami kilku badań, próbowałbyś prawdopodobnie rozwiązać tę niekonsekwencję stosując jedną z następujących technik: a) mógłbyś zignorować lub zlekceważyć którąś z tych informacji (np. facet naprawdę jest dobrodusznym, życzliwym poczciwcem) lub b) mógłbyś zmienić swoją interpretację jednej lub obu tych cech (np. jego uprzejmość nie jest „prawdziwa”, lecz jest rozmyślnie stosowanym trikiem, mającym zmylić ludzi). Użycie którejkolwiek z tych technik pozwoliłoby ci mieć bardziej konsekwentne (z zatem łatwiejsze do przyjęcia) wyobrażenie o tym człowieku.




Spostrzeganie przyczyn




Jeśli dane zachowania mają konsekwencje, które mogą sprawić nam przyjemność lub przykrość, albo mówią nam coś ważnego o nas samych, o innych ludziach lub o naszym otoczeniu, to istotne staje się dla nas zidentyfikowanie czynników przyczynowych, czyli sił, którym można przypisać te zachowania.


Atrybucje dyspozycyjne a atrybucje sytuacyjne. Przypisywanie zachowań danej osoby jej cechom osobowości, umiejętnościom, potrzebom i uznawanym przez nią wartościom zwane jest atrybucją |dyspozycyjną („dispositional attribution”). Atrybucje takie implikują |niemożność zmodyfikowania tych zachowań przez nowe doświadczenia lub interwencje. Przypisywanie zachowania nietrwałym cechom osobowości (własnym lub innych osób), takim jak postawy, preferencje lub motywy, dopuszcza możliwość zmiany, lecz nadal implikuje, że zmiana ta musi nastąpić w danej jednostce.
Natomiast atrybucje |sytuacyjne („situational attributionis”) koncentrują się nie na właściwościach danej osoby, lecz na właściwościach środowiska, sytuacji lub interakcji między ludźmi. W wypadku takich atrybucji przyczyny zachowania lokalizowane są poza działającymi osobami albo też nie wiąże się ich nierozłącznie z jakąkolwiek osobą, lecz uznaje się, że wynikają one z interakcji między ludźmi. Atrybucje sytuacyjne implikują, że można zmieniać zachowanie zmieniając istotne zmienne sytuacyjne; tak więc zdejmują one ciężar „winy” z poszczególnych osób.
Prawa dotyczące zachowania, jakie uzyskuje się w wyniku większości badań |eksperymentalnych, są to empiryczne stwierdzenia określające związek między zmiennymi sytuacyjnymi a pewnymi wynikami. Prawa takie wyjaśniają zmienność zachowania porównywalnych osób badanych w różnych sytuacjach; różnic między ludźmi nie bierze się pod uwagę. Z drugiej strony, uogólnienia wynikające z badań nad osobowością zmierzają do wyjaśnienia zróżnicowania zachowania różnych ludzi w tej samej sytuacji. Istnieje także trzecia kategoria wyjaśnień, która uwzględnia |interakcje między zmiennymi sytuacyjnymi a dyspozycjami - dana sytuacja ma różny, lecz przewidywalny wpływ na różne typy ludzi. Powyższe trzy kategorie, razem wzięte, pozwalają wyjaśnić całą możliwą różnorodność (poza różnicami przypadkowymi) zachowania ludzi w rozmaitych sytuacjach.
W psychologii społecznej coraz więcej pojawia się prac wskazujących na większą wartość zmiennych sytuacyjnych niż dyspozycyjnych w wyjaśnianiu, przewidywaniu i kontrolowaniu zachowania (Argyle, i Little, 1972; Larsen, Coleman, Forbes i Johnson, 1972). Opisane na początku tego rozdziału symulowane więzienie wykazało w sposób dramatyczny, że zmienne sytuacyjne są w stanie wywołać bardzo różne zachowania u podobnych osób, podczas gdy badania Milgrama nad posłuszeństwem (Rozdziały 1 i 14) także udowodniły, że sytuacja może „wziąć górę” nad cechami osobowości i indywidualnymi wartościami.


Błąd atrybucji. Jednakże, wbrew empirycznym dowodom tego rodzaju, większość ludzi przejawia skłonność do dokonywania atrybucji dyspozycyjnej, gdy starają się zrozumieć, dlaczego doszło do danego działania - wyjaśniając zachowanie przeceniają rolę |dyspozycji osoby działającej, a nie doceniają znaczenia sił i ograniczeń „sytuacyjnych”. Tendencję tę nazwano |błędem |atrybucji („attribution error”, Ross, Bierbrauer i Polly, 1974).
To źródło błędu występuje w wielu codziennych sytuacjach życiowych i znajduje swój wyraz w naszym przekonaniu, że |my nie postąpilibyśmy tak w danej sytuacji.
Większość ludzi nie wyobraża sobie, że mogłaby postąpić tak, jak porucznik Calley i inni sprawcy masakry ludności cywilnej w My Lai, jak członkowie Gwardii Narodowej strzelający do spokojnych studentów w Kent, czy też, jak uczestnicy afery Watergate.
Lecz było także nieprawdopodobne dla psychiatrów - a może i dla ciebie - że większość badanych w eksperymencie Milgrama nad posłuszeństwem nie sprzeciwi się w którymś momencie otrzymywanym poleceniom i będzie wymierzać niewinnej ofierze wszystkie kolejne, coraz silniejsze wstrząsy elektryczne, aż do końca. Podobnie w badaniach z symulowanym więzieniem w Stanford, wszyscy badani, którzy później byli więźniami, twierdzili z całkowitą pewnością, że wytrzymają pełne dwa tygodnie - podczas gdy połowa z nich nie wytrzymała nawet pięciu dni. Strażnicy natomiast nie wierzyli, że mogliby kiedykolwiek postępować w tak brutalny sposób, w jaki w rzeczywistości później postępowali. Przed rozpoczęciem badań jeden z nich powiedział: 
„Ponieważ jestem pacyfistą, nie potrafię nawet wyobrazić sobie, żebym był agresywny wobec drugiej osoby”. Jednakże stał się on jednym z najbardziej okrutnych strażników, który obrażał i znieważał więźniów. Nawet wtedy, gdy badanym polecano, aby odgrywali rolę osoby wymierzającej wstrząsy w eksperymencie Milgrama i pouczano ich, aby zwracali uwagę na te aspekty |sytuacji, które wpływają na decyzje podporządkowania się, nadal dokonywali oni atrybucji dyspozycyjnych z tą samą częstością - aczkolwiek byli oni również bardziej skłonni do atrybucji sytuacyjnych (Bierbrauer, 1973).
Główny wniosek, jaki płynie ze wszystkich badań nad atrybucją, brzmi następująco: chociaż ludzie są bardzo |podatni na naciski sytuacyjne (osoby mające władzę, reguły, przepisy, protokół dyplomatyczny, etykieta, jednomyślność grupy, uzasadnienia działań itp.), to jednocześnie |nie |dopuszczają do swej świadomości informacji o tym, że naciski te w dużym stopniu determinują ich zachowanie. Często mówimy o sobie: „Moje zachowanie zależy od sytuacji”, aby podkreślić, że zmienia się ono od czasu do czasu, lecz tego, co robimy, zwykle nie wiążemy wyraźnie z czynnikami sytuacyjnymi. Zachowanie innych ludzi uważamy za jeszcze bardziej uzależnione od czynników dyspozycyjnych niż nasze własne (Jones i Nisbett, 1972).


Teoria atrybucji Heidera. W jaki sposób przechodzimy tak łatwo od obserwowania działań do wnioskowania o wewnętrznych dyspozycjach, jako przyczynach zachowania? Jakie informacje wykorzystujemy i co decyduje o tym, jakiego rodzaju przyczyny przypisujemy różnym zdarzeniom?
Pytania te po raz pierwszy zostały postawione w pracach Fritza Heidera (1944, 1958), który sformułował je w kategoriach „naiwnej psychologii”.  Heider interesował się procesami, dzięki którym przeciętna jednostka |poznaje świat, tym, w jaki sposób kształtuje ona swój pogląd na wzajemne związki i zależności między zdarzeniami, ludźmi i nią samą. Pod tym względem badania Heidera i Piageta (opisane w Rozdziale 5) są zupełnie podobne - w jaki sposób dzieci i dorośli przechodzą od percepcji poszczególnych zdarzeń zewnętrznych do koncepcji abstrakcyjnych zasad, stanowiących podłoże tych zdarzeń?
Ze względu na pozorną prostotę i brak teoretycznej ścisłości sformułowań Heidera, jego wkład w głębsze zrozumienie podstawowych zagadnień psychologii człowieka początkowo nie został doceniony. Później jednak podjęto starania zmierzające do tego, aby idee dotyczące procesu atrybucji zorganizować w |teorię |atrybucji (Jones i Davis, 1965; Kelley, 1967, 1972; Bem, 1965, 1972) i obecnie teoria ta stanowi prawdopodobnie punkt wyjścia dla większej liczby badań w dziedzinie psychologii społecznej niż jakiekolwiek inne podejście.
Teoria atrybucji zakłada, że mamy potrzebę coraz lepszego zrozumienia przewidywalnych relacji, w celu nadania stabilności i sensu zdarzeniom zachodzącym w naszym życiu. Prowadzi to do ukształtowania |realistycznego |nastawienia („reality orientation”) wobec świata. (Spotkaliśmy się już z tymi dwiema orientacjami w Rozdziale 3, przy omawianiu dwóch rodzajów warunkowania oraz charakterystycznej dla organizmów potrzeby posiadania wiedzy o tym, kiedy sygnały, zdarzenia i konsekwencje są ze sobą związane).  Teoria atrybucji zakłada ponadto, że przypisywanie przez nas przyczyn może wiązać się z aktywnym poszukiwaniem informacji, że dokonuje się to w sposób systematyczny i że „znaczenie” jakiegoś zdarzenia dla nas zależy w dużym stopniu od tego, jaką przyczynę mu przypisujemy.
Analizę atrybucyjną przeprowadza się przez racjonalno-logiczną analizę informacji dostępnej dla spostrzegającej i dokonującej atrybucji osoby.  Jeśli kolega mówi ci, że pewien film, na który zamierzałeś pójść, jest niedobry, to w jaki sposób decydujesz, czy skorzystać z rady tego kolegi?  Wiesz, że filmy są różnej jakości i że ludzie różnią się pod względem swej wybredności - tak więc trzeba wziąć pod uwagę szereg czynników.
Przypuśćmy, że twój kolega zawsze krytykuje wszystkie filmy: wówczas jego ocena tego filmu nie mówi ci nic o samym filmie, lecz po prostu jest charakterystyczna dla twego krytycznego kolegi. Z drugiej strony, gdyby ocena ta była bardzo pozytywna, to przyjąłbyś, że niesie ona informację specyficzną dla tego filmu.
Twój sąd o tym, czy jakaś ocena jest |zgodna |z |prawda, zależy także od tego, czy sądzisz, że dana osoba stara się wpłynąć na ciebie. Jeśli tak, to masz wrażenie, że twierdzenie to nie wynika z właściwości ocenianego obiektu, lecz z zamiarów danej osoby, a zatem nie jest prawdopodobnie wiarygodnym świadectwem o samym obiekcie. Na ogół skłonny jesteś wyciągać wnioski dyspozycyjne wtedy, gdy spostrzegasz działania danej osoby jako zamierzone i rozmyślne, a nie jako spontaniczne, informacyjne czy przypadkowe.
Ogólnie biorąc, gdy dana osoba dostosowuje się do wymagań sytuacji, to skłonni jesteśmy przypisywać jej zachowanie przyczynom zewnętrznym, a więc niewiele wnioskujemy o tej osobie na podstawie jej działań. Z drugiej strony, gdy ktoś |uchyla |się od zachowania zgodnego z wyraźnymi wymaganiami sytuacyjnymi (prawami, oczekiwaniami, naciskami społecznymi, groźbami, nagrodami itd.), to skłonni jesteśmy uważać, że takie wychodzące poza rolę zachowania („out-of-role behaviors”) świadczą o ukrytych skłonnościach danej osoby.
Również swoje własne zachowanie przypisujesz - zależnie od okoliczności - wewnętrznym bądź zewnętrznym przyczynom. Ponadto twoja własna ocena, |dlaczego robisz to, co robisz, ma ważny wpływ na to, czy polubisz te czynności, czy będziesz wykonywać je nadal pod nieobecność zewnętrznego wzmocnienia i w jakim stopniu dasz im pierwszeństwo.
Interesująca zmiana zachodzi wtedy, gdy zaangażowałeś się w jakąś aktywność, która interesuje cię sama przez się, po czym zaczęto ci dawać za nią zewnętrzne nagrody. W tej sytuacji możesz dokonywać dyspozycyjnej atrybucji - że robisz to, ponieważ lubisz tę czynność - i zacząć przypisywać swoją aktywność nagrodzie zewnętrznej. Jeśli później nagroda zostanie cofnięta lub jej wysokość nie będzie właściwa, to jest możliwe, że zupełnie zaprzestaniesz tej aktywności, która poprzednio sprawiała ci przyjemność.


„W eksperymencie, w którym osobami badanymi byli studenci University of Rochester, płacenie im za rozwiązywanie łamigłówek, które same w sobie były dla nich interesujące, spowodowało, że później, w okresie swobodnego wyboru czynności, spędzali nad tymi łamigłówkami mniej czasu niż badani nie otrzymujący zapłaty” (Deci, 1972).


To samo może zdarzyć się w klasie - jako wynik stosowania nagród zewnętrznych w postaci pochwał, uznania i stopni.


„Pięćdziesięcioro jeden dzieci przedszkolnych, które wykazywały początkowo rzeczywiste zainteresowanie samą czynnością rysowania, wzięło udział, jako osoby badane, w eksperymencie nad wpływem „nadmiernego usprawiedliwienia” („overjustification”) danej czynności przez dodanie zewnętrznego uzasadnienia. Dzieci te przydzielono losowo do trzech grup, w których w drugiej części eksperymentu obowiązywały różne warunki: a) oczekiwano nagrody zewnętrznej (złota pieczątka i wstążka) za udział w rysowaniu; b) nie oczekiwano żadnej nagrody - lecz otrzymano ją po rysowaniu; c) nie oczekiwano ani nie otrzymano żadnej nagrody.
Po upływie jednego do dwóch tygodni znów wprowadzono na zajęcia rysowanie, w czasie którego obserwowano i rejestrowano zachowanie dzieci.  Wyniki wyraźnie potwierdzają wpływ „nadmiernego usprawiedliwienia” - spostrzeganie zewnętrznej nagrody jako przyczyny podejmowania interesującej z początku, swobodnie wybranej czynności, obniża jej wartość i zmniejsza ilość czasu poświęconego jej przez dzieci z własnej woli. Grupa dzieci oczekujących nagrody spędzała na czynności rysowania tylko połowę tego czasu, jaki poświęcały tej czynności dzieci z każdej z dwóch pozostałych grup - które nie różniły się między sobą pod względem ilości czasu poświęcanego na rysowanie (Lepper, Greene i Nisbett, 1973). Wyniki te zostały potwierdzone w innych badaniach” (Lepper i Greene, 1975).


Ten szkodliwy wpływ wzmocnienia zewnętrznego, które przekształca wewnętrznie motywowane dzieci w małych przedsiębiorców pracujących jedynie dla zysku, wskazuje na pewne ważne ograniczenie praw wzmocnienia, o których uczyliśmy się wcześniej: nawet pozytywne wzmocnienie nie może mieć ujemny wpływ na podejmowanie działań, które dana osoba wykonywała z przyjemnością dla nich samych.




Zbliżenie


Zepsuta zabawa


„Krąży apokryficzna opowieść o włoskim szewczyku zamieszkałym w Nowym Jorku, który stał się obiektem wyzwisk, wykrzykiwanych z zapałem przez chłopców z sąsiedztwa: „Brudny makaroniarz!”, „Smoluchu, wracaj na Sycylię!” oraz nie nadających się do druku sprośności. Na próżno szewc ów ignorował chłopców, przekonywał ich i próbował ich przepędzać.
Pewnego dnia, gdy zobaczył, że się zbliżają, spróbował więc nowego sposobu. „Nie pytajcie mnie dlaczego”, powiedział do nich, „lecz dam każdemu z was 50 centów, jeśli zawołacie 10 razy, tak głośno, jak tylko potraficie: „Brudny makaroniarz! Smoluchy, precz z naszej dzielnicy!” Chłopcy byli zachwyceni i entuzjastycznie wykrzykiwali te hasła, ile tylko mieli sił w płucach. Następnego dnia, zaraz po szkole, chłopcy pojawili się znowu, oczekując dalszego ciągu. Szewc powitał ich uśmiechem i powiedział: 
„Ćwierć dolara każdemu chłopcu, który będzie wykrzykiwał to samo, co powiedziałem wam wczoraj i doda jeszcze przynajmniej jedno wyzwisko”. I znów chłopcy zgodzili się, wrzeszcząc na całe gardło, dopóki nie ochrypli.
Gdy jednak przyszli następnego dnia, wówczas szewczyk powiedział smutno: 
„Przykro mi, lecz interesy idą źle i dzisiaj stać mnie zaledwie na 10 centów dla każdego”.


Na co, jak głosi opowieść, chłopcy odeszli gderając, że mają coś lepszego do roboty, niż dogadzać głupiemu makaroniarzowi za jedne 10 centów. To, co dotąd było czynnością, która sama w sobie dawała im zadowolenie, zaczęli oni uważać za coś, co robi się dla nagrody; gdy zaś nagrodę cofnięto, to nie widzieli już powodu, by robić to nadal - jak trafnie przewidział szewc.


Badania nad dozorem i zaufaniem, przeprowadzone przez Lloyda Stricklanda (1958) przed wieloma laty, wykazały, jak warunki społeczne mogą wpływać na proces atrybucji, który z kolei może oddziaływać na późniejsze warunki społeczne i nowe atrybucje.


„Czy ufamy mniej tym ludziom, którzy wymagają nadzoru, czy też nadzorowanie innych sprawia, że jesteśmy mniej skłonni im ufać? Aby oddzielić przyczynę od skutku, badacz zastosował procedurę w której „nadzorcy” mieli kontrolować wydajność pracy „robotników”, wykonujących nudne i monotonne zadanie. Warunki eksperymentu wymagały, aby nadzorcy kontrolowali robotnika A dziewięć razy, a robotnika B - tylko dwa razy. Po zakończeniu pracy okazało się, że obaj pracownicy wyprodukowali tyle samo; nie było więc różnicy w ich obserwowanym przez nadzorców zachowaniu.
Różniły się natomiast podawane przez nadzorców interpretacje powodów tych zachowań. Im ściślej nadzorowali danego robotnika, tym bardziej byli skłonni przypisywać jego zachowanie kontroli, a nie jego własnej motywacji czy osobowości. 


W następnej fazie eksperymentu, w której nie określono ścisłości nadzoru, nadzorcy kontrolowali robotnika A częściej niż robotnika B i spostrzegali B jako bardziej solidnego i godnego zaufania niż A, którego „trzeba było dobrze pilnować, żeby pracował jak należy”.


Podobne zjawisko występuje w silnie strzeżonych więzieniach, gdzie prawie każdy zakłada, że to skomplikowane środki kontroli są przyczyną uległości więźniów, i gdzie żadnego ze zgodnych z przepisami zachowań więźnia personel nie uznaje za wynik jego intencji; na ogół tylko akty dewiacji przypisuje się woli więźnia.




Motywy osobiste
i społeczne




Ludzie nie żyją samym chlebem. Poświęcają mnóstwo czasu i energii na planowanie, w jaki sposób uzyskać większy bochenek niż ich rywale, a często bardziej interesuje ich dekoracja stołu i towarzystwo niż to, co jedzą.


„Nawet ludzie w najmniej rozwiniętych technicznie społeczeństwach nie spędzają większości swego czasu na jedzeniu, piciu i czynnościach seksualnych. Przeciwnie, zarówno w nowoczesnych, jak i w nie znających jeszcze pisma społeczeństwach ludzie wydatkują większość swej energii w celu osiągnięcia lub wyrażenia tych stanów umysłu czy doznań, których źródłem nie są wrodzone imperatywy funkcjonowania biologicznego, lecz wartości, które poznali jako członkowie swego społeczeństwa” (Sarnoff, 1966, s. 15-16).


Jak przekonaliśmy się w Rozdziale 9, motywy uważa się za stany wewnętrzne, które pobudzają, organizują i ukierunkowują pewne wzorce zachowania. W przeciwieństwie do |popędów |biologicznych, które są wzbudzane przez stymulację neurofizjologiczną lub deprywację biologiczną i są podobne u wszystkich członków danego gatunku, |motywy |osobiste |i |społeczne są znacznie bardziej różnorodne, są wzbudzane i zaspokajane przez czynniki psychiczne i społeczne oraz znacznie bardziej są zależne od uczenia się.




Zbliżenie


Motywacja do pracy


„Co motywuje ludzi do nauki i pracy? Można na to odpowiedzieć, że pracują oni dla nagród |zewnętrznych, takich, jak pieniądze, stopnie szkolne i prestiż, a nie dlatego, że praca sama w sobie jest pociągająca. Czy zawsze jednak sprawa przedstawia się w ten sposób?
Według McGregora (1960), większość organizacji jest zbudowanych zgodnie z pewnym zbiorem założeń co do natury ludzkiej. Jeden taki zbiór (który nazwał on |Teorią |X) zawiera przekonanie, że ludzie w gruncie rzeczy nie lubią pracy i robią wszystko co można, aby jej uniknąć. Chociaż pragną oni mieć poczucie bezpieczeństwa, to jednak mają niewielkie ambicje i nie lubią odpowiedzialności. W każdej sytuacji pracy trzeba więc ludzi w jakiś sposób „przekupywać” lub zmuszać.
Odmienny zbiór założeń McGregor nazwał |Teoria |Y. Należy do niej pogląd, że ludzie są w zasadzie twórczy i odpowiedzialni, że wydatkowanie energii w formie pracy jest procesem naturalnym. Jeżeli cele tej pracy zaspokajają osobiste potrzeby (takie, jak szacunek dla samego siebie, ciekawość, kompetencja), to ludzie będą wewnętrznie motywowani do dobrej pracy.
Przedsiębiorstwa, które działają zgodnie z |Teorią |X, starają się zwykle zwiększyć ilość lub jakość produkcji, oferując takie stereotypowe zachęty, jak dodatkowa zapłata lub krótszy tydzień pracy. Jednakże niektóre przedsiębiorstwa wprowadziły zmiany w swej organizacji zgodnie z zasadami |Teorii |Y i okazało się, że nastąpiły radykalne zmiany w sposobie wykonywania pracy. Na przykład, w niektórych zakładach na miejsce taśm montażowych (przy których każdy pracownik wykonuje jedynie małą część końcowego produktu) utworzono małe zespoły, w których każdy pracuje nad całym produktem od początku do końca. Ludzie wówczas nie tylko są bardziej dumni ze swej pracy, lecz ponadto praca w małych grupach umożliwia im nawiązywanie bliskich przyjaźni. Pracownicy są bardziej zadowoleni i mniej jest przypadków absencji, porzucania pracy czy jej „sabotowania”.
Podobne zmiany, polegające na zastąpieniu |Teorii |X |Teorią |Y, zachodzą także w szkołach. Jedną z najlepiej znanych zmian tego rodzaju jest wprowadzenie „klas otwartych”, w których uczniów zachęca się, by uczyli się i dociekali w najbardziej odpowiadającym im tempie, zgodnie ze swymi własnymi zainteresowaniami”.


Wydaje się, że u ludzi rozwijają się na ogół potrzeby psychiczne, które wyrażają oni za pośrednictwem form społecznych właściwych danej kulturze.  Aczkolwiek potrzeby te są niekiedy przytłumione przez inne potrzeby, z wymaganiami środowiskowymi włącznie, to jednak zaspokojenie ich jest nieodzowne dla zdrowego funkcjonowania jednostki. Frustracja motywów osobistych i społecznych, chociaż nie prowadzi bezpośrednio do śmierci danej jednostki - jak to się dzieje w wypadku długotrwałej frustracji większości popędów biologicznych - to jednak może spowodować zaburzenia emocjonalne lub nawet poważną chorobę fizyczną.




Potrzeba osiągnięć




Żadnemu studentowi nie trzeba mówić, że w Stanach Zjednoczonych kładzie się duży nacisk na osiągnięcia; znajduje to odbicie w pracy zawodowej, sporcie i w całym systemie edukacji. Stopnie szkolne służą jako klucz do wyższych poziomów dalszego współzawodnictwa (dając uczniowi szkoły średniej dostęp do czteroletniego college’u, studentowi zaś kończącemu college - do studiów podyplomowych lub uczelni przygotowujących do pracy w wolnych zawodach - „professional schools”). Studenci określają całe to przedsięwzięcie jako jeden wielki wyścig szczurów do małego kawałka sera umieszczonego w znajdującej się na mecie pułapce; nie przeszkadza im to jednak przyłączyć się do tego wyścigu, zwłaszcza jeśli nagrodą jest przyjęcie do szkoły medycznej lub na studia podyplomowe.
Źródła potrzeby osiągnięć były przedmiotem wielu badań.


„W jednym z badań matki chłopców mających od 8 do 10 lat wskazywały, jakich doznań (z podanej listy) i w jakim wieku oczekiwały od swych synów.  Matki chłopców ocenionych niezależnie jako mających dużą potrzebę osiągnięć („high achievers”), w porównaniu z matkami chłopców o małej potrzebie osiągnięć („low achievers”), oczekiwały od swych siedmioletnich synów dwukrotnie więcej dokonań. Od chłopców o dużej potrzebie osiągnięć matki oczekiwały, że wcześniej będą orientować się w swej dzielnicy miasta, próbować nowych rzeczy, osiągać dobre wyniki we współzawodnictwie i znajdować sobie własnych przyjaciół” (Winterbottom, 1953).




* * *



Ryc. 13.3. Ustalanie Celów A Odpowiedzialność. Stwierdzono, że dzieci w wieku od 9 do 11 lat ustalały sobie cele o pośredniej trudności, jeśli czuły się odpowiedzialne zarówno za sukcesy, jak i za porażki, gdy zaś nie odczuwały takiej odpowiedzialności, wówczas ustalały sobie cele w sposób mało konsekwentny.


* * *





Niektórzy badacze uważają motyw osiągnięć za względnie ogólną i stałą cechę jednostki, ujawniającą się w każdej sytuacji (McClelland, 1961).  Uważa się, że wywołuje on ogólną |tendencję |do |osiągnięcia |sukcesu, aczkolwiek siła tej tendencji w danej sytuacji ma zależeć od trzech innych zmiennych: a) oczekiwania sukcesu, b) wartości wchodzącego w grę rodzaju sukcesu oraz c) percepcji osobistej odpowiedzialności za sukces (Atkinson, 1964; Feather, 1967). Na przykład, dwaj ludzie mogą mieć równie silne ogólne nastawienie na osiągnięcia, lecz jeden z nich może szczególnie cenić prestiż i pracować najciężej w sytuacjach, w których sukces oznaczałby osiągnięcie większego prestiżu, podczas gdy drugi mógłby cenić wyżej satysfakcję z dobrze wykonanej pracy i wkładać najwięcej wysiłku w pracę w tych sytuacjach, w których sukces przyniósłby mu ten właśnie rodzaj satysfakcji.
O złożoności motywu osiągnięć świadczy także fakt, że wśród osób o silnej potrzebie osiągnięć stwierdzono interesujące różnice między tymi, które koncentrują się na osiągnięciu sukcesu, oraz tymi, którym zależy przede wszystkim na uniknięciu porażki. Ci, dla których najważniejsze jest osiągnięcie sukcesu, skłonni są stawiać sobie bardziej realistyczne cele i wybierać zadania o średniej trudności. Ci, którzy najbardziej troszczą się o uniknięcie porażki, skłonni są stawiać sobie cele mniej realistyczne (zbyt łatwe lub zbyt trudne w stosunku do ich zdolności) i wybierać zadania o niskim stopniu trudności, w przypadku których porażka jest najmniej prawdopodobna, lecz sukces, nawet jeśli się go osiągnie, przynosi też najmniej satysfakcji. Poczucie odpowiedzialności za wynik jest także ważnym czynnikiem wzmacniającym poziom trudności wybieranych zadań. Badani, którzy czują się wysoce odpowiedzialni za swe sukcesy i porażki, skłonni są wybierać zadania o średnim poziomie trudności, podobnie jak badani motywowani pragnieniem uzyskania sukcesu, podczas gdy badani, którzy nie czują się odpowiedzialni za swe sukcesy i porażki, |nie wykazują wyraźnej preferencji do zadań o jakimś określonym stopniu trudności (Meyer, 1968).
W większości badań nad potrzebą osiągnięć osobami badanymi byli mężczyźni. Do niedawna bardzo niewiele uwagi poświęcano motywacji osiągnięć u kobiet. Chociaż może to być po części wynikiem stereotypów społecznych, to jednak odzwierciedla prawdopodobnie także fakt, że kobiety nie zachowały się w sposób „oczekiwany” (tzn. tak, jak mężczyni) w tych niewielu eksperymentach, w których brały udział jako osoby badane. Na przykład, kobiety w odróżnieniu od mężczyzn nie wykazują wzrostu motywacji osiągnięć, gdy znajdują się w sytuacji, w której duże znaczenie ma inteligencja i zdolności przywódcze.
Jednego z możliwych wyjaśnień tego zjawiska różnic związanych z płcią dostarczyły badania Matiny Horner nad |motywem |unikania |sukcesów u kobiet. Według Horner, kobiety nastawione na osiągnięcia znajdują się w specyficznej, konfliktowej sytuacji: z jednej strony są one, wspólnie ze „społeczeństwem męskim”, zachęcane do współzawodnictwa i sukcesów, ponieważ jednak osiągnięcie sukcesu przez kobietę często przynosi także ujemne następstwa - na przykład określana jest ona jako „mało kobieca” lub jest odrzucana społecznie („socially rejected”) - przeto, z drugiej strony, kobiety są także motywowane, by |nie odnosić sukcesów.


„W badaniu mającym na celu eksplorację tego motywu, osobom badanym podawano pierwsze zdanie opowiadania i proszono o napisanie dalszego ciągu.  Dla kobiet pierwsze zdanie brzmiało: „Po zakończeniu egzaminów na pierwszym semestrze Akademii Medycznej Anna znalazła się na pierwszym miejscu w swojej grupie”, dla mężczyzn zaś - „Po zakończeniu egzaminów na pierwszym semestrze Akademii Medycznej Jan znalazł się na pierwszym miejscu w swojej grupie”. Opowiadania badanych określono jako odzwierciedlające motyw unikania sukcesu, jeśli zawierały negatywne wyobrażenia o sukcesie. Chociaż mniej niż 10% badanych mężczyzn przejawiało takie obawy, to ponad 65% kobiet napisało opowiadania, w których przejawiał się silny lęk przed sukcesem” (Horner, 1969).




Zbliżenie


Odmiany obawy przed sukcesem


„Analizując opowiadania pisane przez kobiety pod względem wyrażonych w nich obaw przed sukcesem, Horner (1969) stwierdziła, że można wyróżnić trzy główne kategorie tych obaw.
1. Najczęściej spotykany typ opowiadania wyrażał obawy przed odrzuceniem społecznym (np. niepopularnością, samotnością, brakiem szans na zamążpójście) jako konsekwencją sukcesu. Na przykład: „Anna jest pryszczatym molem książkowym: uczy się 12 godzin dziennie, mieszka przy rodzinie, aby zaoszczędzić pieniądze. „No cóż, to się z pewnością opłaci; wszystkie piątkowe i sobotnie wieczory bez randek i zabaw - a będę najlepszą lekarką na świecie””. A jednak zakrada się smutek - Anna zastanawia się, co naprawdę ma z tego (...)”.
2. W drugiej grupie opowiadań przejawiane jest zainteresowanie definicją kobiecości i podnoszone są wątpliwości co do kobiecości i normalności Anny: 
„Niestety, Anna nie jest już tak pewna tego, że naprawdę chce być lekarzem.  Martwi się sobą i zastanawia, czy aby nie jest nienormalna (...). Anna postanawia, że nie będzie kontynuować swych studiów medycznych, lecz zacznie studiować na takim kierunku, które ma dla niej głębsze, osobiste znaczenie”.
3. Trzecia kategoria „obawy przed sukcesem” wiąże się z bezpośrednim zaprzeczeniem, jakoby kobieta mogła odnosić takie sukcesy: „Anna jest umownym imieniem nie istniejącej osoby, tworzonej przez grupę studentów medycyny. Zdają oni kolejno egzaminy za Annę i piszą za nią pracę (...).

W przeciwieństwie do tych pełnych „obaw przed sukcesem” opowiadań, jakie piszą kobiety, opowiadania pisane przez mężczyzn wykazują pozytywną postawę wobec sukcesów. Jednakże wbrew powyższym materiałom dowodowym, postawy kobiet wobec udanej kariery kobiety zdają się zmieniać w pozytywnym kierunku. Niektóre z opowiadań napisanych przez kobiety przewidywały jaśniejsze perspektywy dla Anny:
„Anna jest damą - nie tylko jest pierwsza w nauce, lecz także jest lubiana i podziwiana przez swych kolegów - coś niezwykłego w tej zdominowanej przez mężczyzn dziedzinie. Jest ona wybitnie zdolna - lecz jest także kobietą. Nadal będzie pierwsza lub w czołówce roku. I zawsze...  będzie damą”.




Reaktancja: potrzeba
swobody działania




Gdy byłeś dzieckiem, to prawdopodobnie zdarzało się, że rodzice mówili ci, abyś wykonał jakąś określoną pracę (np. „Posprzątaj swój pokój” albo „Odrób lekcje”) lub podejmowali za ciebie jakąś decyzję („Pójdziemy na film A, nie na film B”). Przypuszczalnie niekiedy stawiałeś opór wobec tych decyzji, na przykład nie chcąc iść z nimi lub wybierając jakieś inne zajęcie. Jeśli jednak twoi rodzice zareagowali na to mówiąc: „W porządku, nie rób więc tego”, to wtedy zapewne nie raz dochodziłeś do wniosku, że ich pierwotna propozycja nie jest mimo wszystko taka zła i w końcu robiłeś to, o co cię na początku poproszono.
Według Jacka Brehma (1966) tego rodzaju odwrotna reakcja jest przykładem |reaktancji („reactance”). Teoria, jaka wiąże się z tym pojęciem, oparta jest na założeniu, że ludzie są motywowani do utrzymania swej swobody działania. Gdy swoboda ta jest zagrożona w jakikolwiek sposób, wówczas będą oni „przeciwdziałać” („react”) temu, robiąc wszystko, aby ją odzyskać. Gdy więc ktoś zagraża twej wolności wywierając na ciebie nacisk, abyś postąpił w pewien sposób, wówczas będziesz starał się zachować swą wolność odmawiając takiego działania. Podobnie, jeśli ktoś próbuje wpłynąć na twoją decyzję mówiąc ci, że „A jest lepsze niż B”, to możesz zareagować na to stwierdzeniem, że „B jest lepsze niż A”.
Eksperymenty potwierdziły te przewidywania.


„W jednym z badań każdą z osób badanych proszono o wzięcie udziału w wykonywaniu zadania zespołowego, wspólnie z dwoma innymi badaniami (którzy w rzeczywistości byli pomocnikami eksperymentatora). Zadanie polegało na analizowaniu i rozwiązywaniu problemów występujących w studium przypadku z zakresu stosunków międzyludzkich, a grupa najpierw musiała zadecydować, nad którym z dwóch przypadków pracować. Gdy jeden z pomocników eksperymentatora domagał się, aby grupa zajęła się przypadkiem A, wówczas osoby badane podawały, że wolą drugą możliwość - studium przypadku B. Gdy jednak po sformułowaniu żądania przez pierwszego pomocnika, drugi z nich mówił, że jeszcze się nie zdecydował (działanie, które przywracało swobodę wyboru), wówczas badani woleli studium przypadku A” (Worchel i Brehm, 1971).




Potrzeba porównań społecznych




„Jak poszło ci na egzaminie?”
„Uzyskałem 80 punktów; a ty?”
„75, ale średnia wynosiła tylko 60”.


Aby podjąć skuteczne działanie, trzeba uświadomić sobie swoje silne i słabe punkty, zdolności i uprzedzenia. W jaki sposób zastosować się do polecenia: „Poznaj samego siebie?”
Zasadniczo są dwa główne kanały, za pośrednictwem których uzyskujesz takie informacje. Pierwszy z nich polega na „badaniu rzeczywistości”, w którym borykasz się z jakimś fizycznym atrybutem rzeczywistości. Pchnij z miejsca wielki głaz, wdrap się na najwyższą górę, przepłyń największy ocean, przerzuć monetę na drugi brzeg Potomaku, przebiegnij milę w równe cztery minuty, ugaś pożar gołymi rękoma. Za pomocą takich działań ustalisz, jakie są twe możliwości fizyczne.
Jednakże swoje powodzenie lub niepowodzenie w takich testach dotyczących |rzeczywistości |fizycznej prawie zawsze ocenia się za pomocą testów dotyczących |rzeczywistości |społecznej: „Czy inni ludzie potrafią to także? Czy potrafią zrobić to lepiej? O ile?” Motywacja: „wiedzieć, co potrafimy zrobić”, nie mająca charakteru społecznego, prowadzi do motywacji społecznej - posłużyć się innymi ludźmi jako miarą do oceny naszych własnych osiągnięć i zdolności; w ten właśnie sposób zapoczątkowujemy proces |porównywania |społecznego („social comparison”; Festinger, 1954; 
Latane, 1966). Obserwujemy, co inni mówią i robią oraz pytamy się ich, co myślą i czują. Dzięki tym testom oceniającym rzeczywistość społeczną uzyskujemy obraz tego, jak silni jesteśmy, jak inteligentni, jak wrażliwi emocjonalnie, jak konserwatywni, jak atrakcyjni itd.
Dzięki porównaniom społecznym uczymy się także relacji pomiędzy „można” i „powinno się” (Heider, 1958). Czy słuszne jest wierzyć, czuć lub działać w pewien sposób? Inni ludzie oddziałują na nas dostarczając wyraźnych informacji o tym, co jest właściwe, i w ten sposób pomagają nam określić istniejące standardy społeczne. Wpływają także na nas, wzmacniając zachowania, które stosują się do innych standardów, karząc zaś lub nie nagradzając zachowań, które są z tymi standardami niezgodne (Deutsch i Gerard, 1955).
Nie wszystkie jednak informacje porównawcze są równie użyteczne dla kształtowania dokładnych i stabilnych samoocen. Najbardziej przydatne informacje czerpie się z porównań z takimi osobami, które są podobne do nas pod względem zdolności czy poglądów lub które znajdują się w tej samej sytuacji bodźcowej.
Członkowie danej grupy skłonni są przyjmować za podstawę samooceny standardy obowiązujące w tej grupie oraz wyniki działania innych jej członków. Toteż jednostka, która różni się bardzo od innych osób w grupie, jest niewygodna, ponieważ różnice te zaburzają im stałą podstawę porównań społecznych. Jak się przekonamy, zwykle reagują oni albo starając się przywołać tę jednostkę do porządku, albo też odrzucając ją.
Co roku wielu studentów na każdej uczelni ma niestety możność przekonać się, jak dalece nasza ocena własnej inteligencji i zdolności zależy od porównania z innymi. Studenci, którzy w szkole średniej byli uczniami „wybitnie zdolnymi” (w porównaniu ze swymi kolegami), są niemile zaskoczeni odkrywając, że nagle stali się zaledwie „przeciętnymi”; co więcej, połowa z nich znajduje się poniżej mediany w porównaniu ze swymi nowymi „wybitnie zdolnymi” kolegami. Oczywiście nie zmienia się ich inteligencja, lecz podstawa porównań społecznych. Iloraz inteligencji równy 120 jest „wysoki” w porównaniu z całą populacją. Może jednak być „przeciętny” lub nawet „niski” w wysoce wyselekcjonowanej grupie.




Potrzeba aprobaty
społecznej




Już w bardzo młodym wieku dzieci uczą się, że zachowanie zgodne z rodzicielskimi (i społecznymi) ustaleniami, określającymi co jest słuszne i właściwe, przynosi szereg pozytywnych konsekwencji. Jednakże wpływ tych konsekwencji, które są wynikiem interakcji z innymi ludźmi, nie ogranicza się jedynie do zwiększania prawdopodobieństwa, że dana reakcja będzie powtarzana i zostanie wyuczona - jest on znacznie poważniejszy. Zaczyna się poszukiwać ich dla nich samych, wiele zaś z naszych wysoce cenionych czynności podejmuje się nie ze względu na nie same, lecz jako środek sprawiający, że inni ludzie będą nas zauważać, cenić, szanować, pomagać nam, czy też lubić nas i kochać. Nie ma granic, poza które nie moglibyśmy się posunąć, aby uzyskać aprobatę innych ludzi - włączjąc tu zabicie innego człowieka czy też znoszenie upokorzeń, bólu lub nawet narażenie się na śmierć.


Społeczna aprobata twoich działań ma przynajmniej pięć związanych ze sobą, lecz dających się odróżnić konsekwencji:
a) aprobata twojego zachowania jest oznaką uznania |ciebie, sprawia, iż zyskujesz |tożsamość, stajesz się „dostrzegalny”.
b) aprobata |uzasadnia twoje istnienie, podnosząc twój statut jako osoby zasługującej na uznanie;
c) aprobata implikuje akceptację tego, co masz do zaoferowania, i zapewnia ci |poczucie |bezpieczeństwa, masz świadomość, że nie zostaniesz odrzucony z powodu „niestosowności” twoich zdolności, opinii czy uczuć;
d) aprobata wytwarza więź między aprobującym i aprobowanym, zapewniając |sympatię aprobującemu oraz oczekiwanie wzajemności z jego strony;
e) aprobata dostarcza jednego z kryteriów twej |kontroli czy władzy nad środowiskiem, określając, w jaki sposób twoje zachowanie może przynosić pożądane konsekwencje.

Nic więc dziwnego, że na proces uczenia się u dzieci silnie wpływa pozbawienie aprobaty społecznej, a także pozytywne wzmocnienie społeczne w postaci skinięcia głowy lub słowa „dobrze” (Gewirtz i Baer, 1958).  Przypomnij sobie, co uczyniłbyś lub uczyniłeś, aby otrzymać mały kawałek złotego papieru w kształcie gwiazdy od swej nauczycielki w drugiej klasie.
Aprobata społeczna ze strony rówieśników może stać się jeszcze cenniejsza niż aprobata społeczna rodziców i nauczycieli, co prowadzi do „antyspołecznego” zachowania aprobowanego przez grupę. Możemy rozumieć zachowanie błazna klasowego, którego figle wprawiają w szał nauczyciela, zachowanie nastolatków ryzykujących swe życie przy grze w „kurczęta” („chicken”) (Gra ta, rozgrywana między kierowcami samochodów lub motocykli, polega na szybkiej jeździe w kierunku niebezpiecznej przeszkody lub pojazdu zbliżającego się z przeciwnego kierunku. Ten, kto pierwszy naciśnie hamulec lub zmieni kierunek jazdy, by uniknąć niebezpieczeństwa, zostaje „kurczęciem” (przyp. tłum.)) lub też pozornie bezsensowne napaści członków gangu na niewinną ofiarę, jeśli zdamy sobie sprawę z potężnej siły aprobaty społecznej ze strony rówieśników.




Potrzeba afiliacji




Ponieważ wydaje się, że ludzie zawsze żyją w grupach i ponieważ, jak wkazaliśmy wcześniej, przetrwanie często zależy od bezpieczeństwa, jakie zapewnia liczebność grupy, dlatego też pierwsi psychologowie społeczni zakładali, że towarzyskość jest podstawowym wrodzonym instynktem, „gromadę” uważano za normalne naturalne środowisko człowieka.



Jeden z ówczesnych badaczy napisał:


„Świadoma jednostka doznaje nie poddającego sie analizie, pierwotnego poczucia przyjemności w obecności swych towarzyszy, zaś równie pierwotnego uczucia przykrości, gdy są oni nieobecni. Jest dla niej oczywistą prawdą, że samotność jest czymś niedobrym dla człowieka. Samotność jest prawdziwą grozą, której rozum nie może pokonać” (Trotter, 1916, s. 31).


Badania wykazały jednak, że istnieją duże różnice międzyjednostkowe pod względem siły potrzeb afiliacyjnych, mierzonych za pomocą testów projekcyjnych (Atkinson, 1958). Niektórzy ludzie działają również w sposób bardziej afiliacyjny niż inni, należąc do większej liczby klubów towarzyskich, częściej komunikując się z innymi i zachowując się w bardziej przyjazny sposób.
Stanley Schachter (1959) sformułował pytanie dotyczące natury i źródła instynktu „stadnego” w postaci sprawdzalnej empirycznie hipotezy. Materiał dowodowy z różnych źródeł wskazywał, że izolacja wzbudza uczucie lęku.  Jeśli tak, to wzbudzenie silnego popędu, takiego jak strach, powinno skłaniać do unikania izolacji, czyli do poszukiwania możności afiliacji.


„Aby sprawdzić słuszność tego rozumowania Schachter wzbudzał eksperymentalnie silny strach u połowy osób badanych, u drugiej zaś połowy - niewielki strach. Osobami badanymi były studentki uniwersytetu, które brały udział w badaniu w małych grupach złożonych z pięciu do ośmiu kobiet.  U połowy badanych wytworzono oczekiwania, że złowrogo wyglądający doktor Gregor Zilstein wymierzy im szereg bolesnych wstrząsów elektrycznych - podczas badań nad wpływem tego rodzaju wstrząsów. Pozostałe osoby badane nie oczekiwały żadnego bólu, ponieważ miały otrzymać jedynie łagodne bodźce elektryczne. Analiza sprawozdań wykazała, że u studentek oczekujących bólu istotnie został wzbudzony silniejszy strach.
Aby przekonać się, czy ta różnica siły strachu przed oczekiwanym wstrząsem istotnie miała wpływ na zmienną zależną, to jest afiliację, studentkom dawano sposobność spędzania dziesięciominutowego „okresu oczekiwania” przed wstrząsem albo w samotności, albo z innymi kobietami.  Każda osoba badana wskazywała, czy woli być sama, czy też z innymi, a jeśli tak, to jak silnie tego pragnie. Uzyskane wyniki wyraźnie potwierdziły hipotezę: strach istotnie prowadzi do afiliacji” (ryc. 13.5).


Dalsze badania wykazały, że przy wyborze osoby będącej obiektem afiliacji ważne jest także to, |jaka jest to osoba.


„Podobnie jak w eksperymencie Schachtera, silnie wylęknionym osobom badanym dawano do wyboru: czekać samemu lub z inną osobą. Jednakże w tym wypadku połowie osób badanych powiedziano, że druga osoba oczekuje na wstrząs (tak samo, jak ona), podczas gdy pozostałym badanym powiedziano, że druga osoba już zakończyła swój udział w eksperymencie”.




* * *



Ryc. 13.5. Skłonność Do Afiliacji Nasila Się, Gdy Poziom Strachu Wzrasta.  Prawie dwukrotnie więcej badanych o wysokim poziomie strachu wybierało afiliację - w porównaniu z badanymi o niskim poziomie strachu. W dodatku siła ich dążenia do afiliacji była prawie trzykrotnie większa niż u tych badanych o niskim poziomie strachu, którzy wybrali afiliację.


* * *





Wylęknione osoby badane wybierały wspólne oczekiwanie z osoba, która była w podobnym stanie emocjonalnym, lecz nie chciały czekać wspólnie z osobą, która już ukończyła eksperyment (i mogłaby zapewne dostarczyć im obiektywnej informacji o przyczynie ich strachu). Najwyraźniej nieszczęśnik nie pragnie po prostu jakiegokolwiek towarzystwa - nieszczęśnik pragnie raczej towarzystwa nieszczęśnika” (Zimbardo i Formica, 1963; tabela).




Altruizm: potrzeba
pomagania innym




„Ten, kto ratuje jedno życie, to jak gdyby uratował cały świat”.
„Talmud”


Gdy pomagamy innym pod nieobecność jakichkolwiek nagród zewnętrznych (takich, jak pieniądze czy pochwała), to nasze zachowanie określa się jako |altruizm. Niektórzy psychologowie twierdzą, że altruzim może być po części instynktowny, ponieważ przeżycie jednostki zwykle zależy od współdziałania i pomocy ze strony innych osób (Campbell, 1965). Inni badacze wykazali, że altruistyczna reakcja (taka, jak uwolnienie innego człowieka od cierpienia) może być sama w sobie nagradzająca (Weiss i in., 1971). Ponieważ „Złota Reguła” („Golden Rule”) (Nie czyń drugiemu, co tobie niemiłe (przyp. red.)) jest normą społeczną, którą w społeczeństwie amerykańskim wyraźnie wpaja się i popiera, przeto możemy także uważać altruizm za wynik uczenia się.
Inne wyjaśnienie altruzimu opiera się na pojęciu |empatii. Gdy nauczyłeś się doświadczać - w sposób niejako zastępczy („vicariously”) - myśli i uczuć innych ludzi, to będziesz odczuwać przykrość, gdy zobaczysz inne osoby w kłopotach: podejmiesz wówczas działanie mające na celu zredukowanie zarówno ich przykrości, jak i swojej własnej (Aronfreed, 1970). W zbliżonej koncepcji postuluje się, że altruzim jest wynikiem wzbudzenia „|napięcia |wspierającego” („promotive tension”), które definiuje się jako napięcie związane z dążeniem innej osoby do celu: gdy doświadczamy potrzeb i pragnień jakiejś innej osoby, to jesteśmy motywowani, by dopomóc tej osobie w zaspokojeniu owych potrzeb. Zgodnie z tą hipotezą jest bardziej prawdopodobne, że pomożemy ludziom, którzy są podobni do nas pod względem poglądów na istotne sprawy i którzy są bliżsi osiągnięcia upragnionego celu (Hornstein, 1972).
Altruizm może być także motywowany przez |poczucie |winy oraz późniejsze dążenie do zadośćuczynienia (Rawlings, 1970). Ludzie, który sądzą, że skrzywdzili kogoś, są bardziej skłonni zachowywać się altruistycznie, chociaż osoba, której pomagają, może nie być tą samą osobą, którą krzywdzili.


„W celu sprawdzenia tej hipotezy „poczucia winy”, przeprowadzono badanie terenowe w wielkim centrum handlowym. Eksperymentator (mężczyzna) prosił kobiety dokonujące zakupów, aby wyświadczyły mu uprzejmość i zrobiły mu zdjęcie. We wszystkich przypadkach aparat fotograficzny nie działał. U połowy kobiet wytworzono przekonanie, że popsuły one ten aparat (grupa „poczucia winy”), podczas gdy pozostałym powiedziano, że to nie była ich wina (grupa kontrolna). Później, gdy każda z osób badanych szła dalej przez centrum handlowe, druga eksperymentatorka przechodziła przed nią, niosąc rozerwaną torbę z artykułami spożywczymi, które jej wypadały.


Kiedy Pragniemy Towarzystwa? Stu studentom Central Connecticut State College przedstawiono poniższe sytuacje, a oni podawali (w odniesieniu do każdej z nich), czy w danej sytuacji chcieliby być sami, czy razem z innymi osobami.




* * *



Sytuacja: Procent studentów, którzy (chcieli być z innymi - chcieli być sami - było im to obojętne)
Gdy jesteś przygnębiony: 42 48 10
Gdy masz poważne, osobiste zmartwienie: 52 44 4
Gdy jesteś zmęczony fizycznie: 6 85 9
Gdy jesteś bardzo szczęśliwy: 88 2 10
Gdy masz silne poczucie winy z powodu czegoś, co zrobiłeś: 45 43 12
Gdy czujesz się zakłopotany: 16 76 8
Gdy chce ci się płakać: 8 88 4
Gdy jesteś w nowej dla siebie sytuacji lub gdy robisz coś, czego nie 
robiłeś nigdy przedtem: 77 13 10
(Adaptowane Middlebrooka, 1973)


* * *





Spośród osób badanych należących do grupy z poczuciem winy 55% powiedziało jej, ze gubi swoje zakupy, podczas gdy tylko 15% z grupy kontrolnej postąpiło w ten sposób” (Regan, Williams i Sparling, 1972).


Inny sposób podejścia do wyjaśnienia zjawiska altruizmu kładzie główny nacisk na działanie norm społecznych. Jedną z nich jest norma |odpowiedzialności |społecznej - ludzie powinni pomagać tym, którzy są od nich zależni i potrzebują pomocy. Osoba uznająca tę normę czuje się zobowiązana pomagać innym, ponieważ jest to „właściwe” postępowanie, a nie dlatego, że odniesie z tego jakąś bezpośrednią korzyść (Berkowitz, 1972).  Norma |wzajemności również wpływa na zachowanie altruistyczne - ludzie mają poczucie, ze powinni pomagać tym, którzy im pomogli (Gouldner, 1960).
Wszelkie sygnały, które eksponują (przywodzą na myśl) normę udzielania pomocy, zwiększają gotowość do pomagania innym. Jednym z takich sygnałów jest altruizm demonstrowany przez modela. Na przykład kierowcy byli bardziej skłonni zatrzymać się i pomóc kobiecie zmienić koło w samochodzie, jeśli już przedtem minęli inną osobę pomagającą komuś w takiej czynności (Bryan i Test, 1967). Podobnie dzieci, które widziały modela dzielącego się z innymi, były bardziej skłonne dzielić się same niż dzieci, które nie widziały takiego modela lub też obserwowały modela chwalącego ideę dzielenia się, lecz nie postępującego w rzeczywistości w ten właśnie sposób” (Grusec, 1972). 




Potrzeba spójności




Wielu psychologów opracowało teorie oparte na centralnym założeniu istnienia potrzeby spójności czy konsekwencji (zob. Abelson i in., 1968).  Wszystkie te teorie postulują, że ludzie dążą do spójności, wolą relacje zrównoważone od niezrównoważonych i są motywowani do zredukowania dysharmonii cechującej spostrzeżenia niespójne.


Dysonans poznawczy. Spośród tych teorii najbardziej rozwinięta formalnie jest |teoria |dysonansu |poznawczego Leona Festingera (1957). Podstawowe założenie tej teorii głosi, że ludzie nie mogą tolerować niespójności i będą starać się wyeliminować ją lub zredukować zawsze wtedy, gdy ona wystąpi. Zgodnie z tą teorią, stan |dysonansu zostanie wzbudzony zawsze wtedy, gdy u danej osoby równocześnie występują dwa elementy poznawcze (informacje, wiadomości, przekonania, opinie), które są psychologicznie niespójne lub ze sobą niezgodne. Ponieważ taki stan jest nieprzyjemny, jednostka będzie zatem motywowana do zredukowania w pewien sposób tego dysonansu i osiągnięcia większego |konsonansu (spójności). Może to nastąpić wtedy, jeśli jeden z tych elementów poznawczych zostanie zmieniony lub jeśli zostaną dodane elementy poznawcze. 
Przypuśćmy na przykład, że elementami poznawczymi będącymi w dysonansie jest pewna informacja o sobie samym („Palę papierosy”) oraz przekonanie dotyczące palenia („Palenie powoduje raka płuc”). Aby zredukować występujący dysonans, można by: a) zmienić swoje przekonanie („Materiał dowodowy przemawiający za związkiem między paleniem a rakiem płuc nie jest zbyt przekonujący”); b) zmienić swoje zachowanie (rzucić palenie) lub też c) dodać nowe elementy poznawcze („nie zaciągam się”), które sprawią, że niespójność będzie mniej poważna.
Im |ważniejsze są elementy poznawcze dla danej jednostki, tym większy będzie dysonans. Na przykład, jeśli nasz palacz nie dba o to, czy dostanie raka płuc (ma już dziewięćdziesiąt lat i nacieszył się życiem), wówczas byłby niewielki dysonans pomiędzy „Palę papierosy” i „Palenie powoduje raka płuc”. Natomiast u osoby młodej, bardzo obawiającej się choroby i śmierci, dysonans ten byłby o wiele większy.
Wielkość dysonansu jest także zależna od |stosunku elementów poznawczych będących w dysonansie do elementów poznawczych będących w konsonansie. W przypadku palacza, u którego występują nie tylko dwa sprzeczne elementy poznawcze, lecz także inne, mniej sprzeczne z elementem „Palenie szkodzi mu” (takie, jak „Palę bardzo rzadko” i „Nie zaciągam się”), stosunek ten zostałby zatem zredukowany od 1:1 do 1:3 i w związku z tym palacz ów odczuwałby mniejszy dysonans. Zgodnie z tą teorią, wielkość wytworzonego dysonansu jest bardzo ważna dla zrozumienia późniejszego zachowania danej jednostki, ponieważ im większy dysonans, tym usilniej dana osoba będzie starała się go zredukować.
W późniejszej modyfikacji pierwszej teorii Brehm i Cohen (1962) wysunęli twierdzenie, iż wystąpienie dysonansu w danej sytuacji jest bardziej prawdopodobne, jeśli dana osoba |zaangażuje się publicznie w niespójne działanie, będą jednocześnie przekonana, że naprawdę miała możność |wyboru innego postępowania. Mógłbyś na przykład odczuwać znaczny dysonans, gdybyś publicznie poparł polityka, dla którego żywisz pogardę. Jednakże gdybyś nie widział innego wyboru (straciłbyś w przeciwnym razie pracę), wówczas mógłbyś wewnętrznie wyprzeć się tego postępku, jako narzuconego ci z zewnątrz, i nie odczuwać żadnego dysonansu.


Redukowanie dysonansu porównawczego. Ważną implikacją hipotezy Brehma i Cohena jest to, że pozwala ona przewidywać, w jaki sposób będzie następować redukcja dysonansu. Ponieważ publiczne działania są obserwowane przez innych, prywatne zaś poglądy i przekonania - nie, przeto zachowanie publiczne będzie mocniej „osadzone” w rzeczywistości i mniej podatne na zmianę niż prywatne myśli. Przypuśćmy na przykład, że odczuwasz dysonans między własnym działaniem („Wykonuję pracę, którą wybrałem”) oraz przekonaniem wewnętrznym („Ta praca jest nudna”). Ponieważ zaangażowałeś się już w to działanie, to byłoby ci bardzo trudno zmienić ten element poznawczy na „Ja nie wybrałem tej pracy”. Natomiast twoje prywatne przekonanie jest słabiej zakotwiczone w rzeczywistości zewnętrznej i jest zatem bardziej podatne na zmianę („Ta praca jest właściwie interesująca - uczę się w niej wielu rzeczy”).
Przeprowadzono wiele badań mających na celu sprawdzenie tego rodzaju hipotez dotyczących redukcji dysonansu.


„W jednym z eksperymentów każdy z badanych brał udział w bardzo nudnym zadaniu; następnie proszono go, aby (wyświadczając przysługę eksperymentatorowi) okłamał inną osobę badaną mówiąc, że zadanie to jest bardzo zabawne i interesujące. Połowie badanych płacono po 20 dolarów za kłamstwo, podczas gdy pozostałym płacono tylko po jednym dolarze. Badani w pierwszej grupie uważali tę sumę pieniędzy za wystarczające „zewnętrzne uzasadnienie” dla kłamstwa. W drugiej grupie badani uważali, że zapłata w wysokości jednego dolara jest niewystarczającym powodem, aby kłamać, w związku z czym powstał u nich dysonans między dwoma elementami poznawczymi: 
„Zadanie było nudne” oraz „Zdecydowałem się powiedzieć komuś, że jest ono zabawne i interesujące”.




* * *



Ryc. 13.6. Spróbować Koników Polnych, To Polubić Je. Badani, którzy jedli koniki polne na żądanie niesympatycznego oficera, ocenili potem ich smak znacznie bardziej pozytywnie. Pozostali badani, którzy również jedli tę potrawę, tylko nieznacznie złagodzili swe oceny, ci zaś, którzy nie zdecydowali się na zjedzenie choćby jednego konika, wyrażali większą odrazę niż poprzednio.


* * *





Aby zredukować ten dysonans, badani ci zmieniali swą ocenę zadania i później wyrażali przekonanie, że „było ono naprawdę zabawne i interesujące - chciałbym wykonywać je znowu”. Natomiast osoby badane, które skłamały za dwadzieścia dolarów, nie zmieniły swej oceny nudnego zadania (Festinger i Carlsmitch, 1959).
W innym eksperymencie badano reakcje mężczyzn rezerwistów armii USA, których poproszono o zjedzenie „obrzydliwego” pokarmu, a mianowicie smażonych koników polnych. Mężczyźni ci wysłuchali odczytu o „potrzebie nowej, ruchliwej armii”, a następnie poproszono ich, by spróbowali nowej potrawy - każdemu z nich podano talerz smażonych koników polnych. Połowie badanych zjedzenie tego posiłku zaproponował, sympatyczny oficer, pozostałym - oficer bardzo chłodny i nieprzyjemny, którego poprzednio widziano, jak zachowywał się niegrzecznie i nieprzyjaźnie wobec swego pomocnika.
W obu grupach mniej więcej połowa mężczyzn zjadła przynajmniej jednego konika polnego. Ci, którzy jedli je pod wpływem sympatycznego oficera, nie odczuwali dysonansu przy jedzeniu odstraszającego pożywienia, ponieważ dysponowali wystarczającym uzasadnieniem („To wspaniały facet - robię to dla niego”). Natomiast mężczyźni, którzy byli zachęcani przez niesympatycznego oficera, nie mieli wystarczającego powodu dla jedzenia tak paskudnego pokarmu i zachowywali się w sposób paradoksalny. Aby zredukować dysonans, zmienili oni swe postawy wobec koników polnych, dochodząc do wniosku, że w rzeczywistości są one dość smaczne” (Zimbardo, Weisenberg, Firestone i Levy, 1965). Wyniki te przedstawiono na rycinie 13.6.




Atrakcyjność
interpersonalna




Czy „Rozstanie wzmacnia uczucie”, czy też „Co z oczu, to z serca?”. Czy „Kruk krukowi oka nie wykole”, czy też „Trudno być prorokiem między swymi?”. Którą mądrość zaczerpniemy z Szekspira: „Nie kochają ci, którzy nie okazują swojej miłości”, czy też „Miłość nie patrzy oczyma ciała, lecz duszy?”.
Jeśli chodzi o przyjaźń, atrakcyjność, miłość i małżeństwo to każda społeczność ludzka nagromadziła przez wieki mnóstwo wiedzy, która może dostarczać wskazówek dla badań psychologa społecznego. Jak jednak wskazują wyraźnie zamieszczone na wstępie „hipotezy”, zdrowy rozsądek i mądrość pisarzy cieszą się długowiecznością z prostego powodu - jest tam wszystko dla wszystkich. Są nauki moralne, oklepane frazesy, cytaty, stare gadki, powiedzonka, które pasują do wszelkich przypadków - dopóki wybierasz te, które nadają się na daną okazję i niefrasobliwie ignorujesz sprzeczne z nimi.
Pomimo tego, że wzajemna atrakcyjność ludzi dla siebie niewątpliwie odgrywa rolę w tworzeniu podwalin życia społecznego, to dopiero niedawno energiczni, młodzi badacze zaczęli przekształcać kwieciste wersety poetów oraz esencję mądrości ludowej w sprawdzalne hipotezy. Badania przeprowadzone w ramach tego rodzącego się dopiero kierunku dostarczają pewnych wartościowych informacji, które mogą dopomóc nam, abyśmy się kochali wzajemnie mądrze i dobrze.




Jakich ludzi lubimy?




W zasadzie badania wykazały, że pociągają nas ludzie, którzy dostarczają nam maksymalnej ilość nagród czy gratyfikacji przy minimalnym koszcie. Na przykład, bardziej pociągają nas ludzie, którzy są blisko niż ci, którzy zamieszkują w dalszej odległości. Lubimy ludzi, dla których już jesteśmy atrakcyjni i którzy okazują nam to wyświadczając przysługi i mówiąc o nas miłe rzeczy. Lubimy ludzi, którzy zaspokajają nasze potrzeby i którzy mają potrzeby, które my możemy zaspokoić.


„Piękno zdobywa to, co najlepsze na świecie”.
Don Marquis „The Lives and Times of Archy and Mehitabel”, 1927


Atrakcyjność fizyczna. Ogólnie biorą, pięknych ludzi lubimy bardziej niż nieładnych czy brzydkich. Aczkolwiek to stwierdzenie może być sprzeczne z naszą wiarą w równość i w nieistotność wyglądu zewnętrznego dla stosunków osobistych, to jednak zostało ono udowodnione w szeregu badań eksperymentalnych (Berscheid i Walster, 1974). Dlaczego wolimy pięknych?  Jednym z powodów jest to, że żywimy stereotypowe przekonanie, że wszystko, co jest piękne, jest także dobre. Uważamy zatem pięknych ludzi za bardziej inteligentnych, miłych, szczęśliwych i mających więcej sukcesów niż inni ludzie, nawet jeśli nie ma żadnej obiektywnej podstawy dla tych sądów.
Jak dotąd, badania nad atrakcyjnością fizyczną przeprowadzano w sytuacjach, w których ludzie nie znali się nawzajem lub dopiero zaznajamiali się ze sobą. Być może atrakcyjność fizyczna odgrywa ważniejszą role w tych początkowych stadiach „zaznajamiania się” niż w późniejszym okresie trwania znajomości.


„Nie kochamy zalet - kochamy osoby; niekiedy w równym stopniu z powodu ich wad, jak i zalet”.
Jacques Maritain „Reflections on America”, 1958


Kompetencja. Na ogół lubimy ludzi zdolnych i kompetentnych bardziej niż tych, którym trudno jest zrobić coś dobrze. Jednakże niekiedy lepiej nie być zbyt kompetentnym: wysoce kompetentni ludzie mogą być bardziej lubiani wtedy, jeśli okażą jakąś ludzką słabość lub popełnią czasem poważny błąd, a nie wtedy, gdy demonstrują swą nazbyt wielką doskonałość.


„W pewnym eksperymencie każdy z badanych słuchał jednego z czterech nagranych na taśmach magnetofonowych wywiadów z „kandydatem do Quizowego Pucharu Uczelni”. Na każdej taśmie nagrany był ten sam głos, lecz na dwóch taśmach kandydat został przedstawiony jako wybitnie inteligentny i mający dobre wyniki zarówno w nauce, jak i w działalności pozaszkolnej. Na pozostałych dwóch taśmach kandydat został przedstawiony jako osoba o przeciętnej inteligencji, uzyskująca jedynie przeciętne wyniki w szkole.  Ponadto na dwóch spośród tych czterech taśm (jednej przedstawiającej osobę bardzo zdolną i drugiej przedstawiającej osobę przeciętną) kandydat do „Pucharu” popełniał kłopotliwą gafę, rozlewając na siebie niezręcznie filiżankę kawy.
Po wysłuchaniu nagranego wywiadu badani podawali swoje wrażenia o kandydacie, określali, jak się im podobał itd. „Wyniki były wyraźne: najbardziej atrakcyjna dla badanych była osoba bardzo zdolna, która popełniła gafę, podczas gdy najmniej atrakcyjna była osoba przeciętna, która także popełniła gafę... Nie było nic szczególnie pociągającego w samej gafie; zwiększyła ona atrakcyjność osoby bardzo zdolnej i zmniejszyła atrakcyjność osoby przeciętnej” (Aronson, 1969, s. 149).


„Trudno o sympatię tam, gdzie nie ma podobieństwa”.
Ezop „Bajki” 


Podobieństwo i komplementarność. Jednym z twierdzeń, najbardziej konsekwentnie powtarzających się w badaniach nad atrakcyjnością jest to, że ludzie lubią tych, którzy są podobni do nich samych. Lubimy zwłaszcza ludzi, którzy mają podobne postawy i zgadzają się z nami (Byrne, 1971).
Dlaczego osoba o podobnych poglądach ma być tak atrakcyjna? Być może przyczyną jest to, że owa zgodność dostarcza |wzmocnienia. Jest mniej prawdopodobne, że pokłócimy się lub będziemy mieli nieprzyjemną utarczkę z kimś, kto na ogół zgadza się z nami, bardziej zaś jest prawdopodobne, że umocnimy się w przekonaniu o słuszności naszych postaw.


Możemy być również przekonani, że częściej bywamy atrakcyjni dla ludzi podobnych do nas. Ponadto podobieństwo może prowadzić do atrakcyjności, ponieważ pozwala nam utrzymać |spójne, zrównoważone stosunku z naszymi przyjaciółmi. Lubimy zatem tych, którzy lubią to, co my lubimy. Inne wyjaśnienie głosi, że ludzie o podobnych postawach są dla nas atrakcyjni ze względu na |porównania |społeczne. Jak przekonaliśmy się poprzednio, oczekujemy zwykle od innych ludzi, że dostarczają nam informacji o naszych własnych zdolnościach, uczuciach i przekonaniach. Innymi słowy, atrakcyjni mogą być dla nas ludzie, którzy są odzwierciedleniem nas samych lub tego, czym chcielibyśmy być.
|Nie |każde podobieństwo rodzi jednak taką sympatię. Istnieje nieco materiału dowodowego, że atrakcyjność jest wynikiem posiadania |komplementarnych (uzupełniających się) potrzeb lub stylów osobowości. Na przykład, osoba bardzo dominująca może lubić kogoś, kto jest spokojny i uległy, bardziej niż inną dominującą jednostkę. Być może, w różnych okresach rozmaite czynniki mają szczególny wpływ na ukształtowanie związku dwojga ludzi odmiennej płci. Podobieństwo wartości może być na przykład niezbędne we wczesnych fazach, podczas gdy komplementarność potrzeb może mieć decydujące znaczenie dla długotrwałego związku (Kerckhoff i Davis, 1962).




Dlaczego lubimy tych
ludzi, których lubimy?




W miarę, jak przeprowadza się coraz więcej badań nad czynnikami wpływającymi na atrakcyjność, podejmowane są próby zintegrowania ich wszystkich za pomocą jakiejś uniwersalnej teorii. Najbardziej typowe podejście polegało, jak dotąd, na wyjaśnianiu atrakcyjności w kategoriach analizy nagród i kosztów, aczkolwiek zaczynają się pojawiać również inne teorie.


„Miłość często jest jedynie korzystną wymianą między dwojgiem ludzi, którzy uzyskują większość tego, czego mogą oczekiwać, biorąc pod uwagę ich wartość na rynku osobowości”.
Erich Fromm „The Sane Society”, 1955


Teoria słuszności (sprawiedliwości). Jak przekonaliśmy się w Rozdziale 3, ludzie skłonni są podejmować zachowania, za które otrzymują pozytywne wzmocnienie, unikać zaś zachowań, za które są karani. To podstawowe twierdzenie stanowi rdzeń |teorii |słuszności („equity theory”), która głosi, między innymi, że ludzie starają się maksymalizować uzyskiwane wyniki, osiągając możliwie największe nagrody przy minimum kosztów.  Rezultaty większości badań nad atrakcyjnością można wyjaśnić w kategoriach nagród i kosztów. Na przykład, jeśli wszystkie inne czynniki pozostaną bez zmiany, to mniej czasu i wysiłku kosztuje lubienie kogoś, kto mieszka blisko niż kogoś, kto przebywa w dużej odległości. Podobnie otrzymujemy więcej „nagród” od ludzi, którzy są mili i wyświadczają nam uprzejmości niż od tych, którzy są nieprzyjemni i kłótliwi.
Gdy dwoje ludzi jest połączonych przyjaźnią lub związkiem uczuciowym, wówczas trzeba rozpatrywać |dwa zbiory nagród i kosztów. Zgodnie z teorią słuszności, dany związek utrzyma się tylko wtedy, gdy jest korzystny dla obojga uczestników. Innymi słowy, każda z osób musi czerpać z tego związku nagrody (takie, jak poczucie bezpieczeństwa, prestiż itd.), ponosząc minimalne koszty. Taki wynik najlepiej można osiągnąć w związku „zrównoważonym”, w którym wymiana korzyści jest sprawiedliwa. Para osób odmiennej płci będzie zatem najszczęśliwsza wtedy, gdy każda z nich uzyskuje „równe” korzyści (Walster, Berscheid i Walster, 1973).
Przy stosowaniu teorii słuszności do związków uczuciowych „zrównanie” partnerów zwykle ujmuje się w kategoriach atrakcyjności społecznej („social desirability”). Ludźmi o wysokiej atrakcyjności społecznej są te osoby, które są bardziej atrakcyjne fizycznie, bardziej inteligentne, zamożniejsze itd. Teoria słuszności przewiduje, że tacy ludzie będą wybierać i najbardziej lubić ludzi o równie wysokiej „wartości społecznej”. Podobnie ludzie o niższej atrakcyjności społecznej będą wybierać i woleć partnerów, którzy odpowiadają im pod względem tej atrakcyjności. Jednakże materiał dowodowy dotyczący tej hipotezy „zrównania” jest nieco niejednoznaczny.  Aczkolwiek ludzie istotnie skłonni są wybierać partnerów o mniej więcej takiej samej wartości społecznej, to jednak uporczywie starają się zdobywać partnerów, którzy są znacznie bardziej atrakcyjni społecznie od nich.  Innymi słowy, dążymy do ideałów, lecz nasze wybory zwykle oparte są na rzeczywistości - na tym, co mamy do oferowania komuś innemu.


„Nienawiść, która jest całkowicie pokonana przez miłość, zmienia się w miłość, a miłość ta jest wówczas większa, niż gdyby nie poprzedzała jej nienawiść”.
Baruch Spinoza „Ethica”, 1677 (wyd. pol. „Etyka”)


Teoria zyskiwania i utraty. Sympatia nie jest zdeterminowana całkowicie przez właściwości innej osoby ani przez to, w jakim stopniu „dorównują” one naszym cechom. W sytuacjach, w których wchodzi w grę atrakcyjność, dana jednostka stawia na kartę swoje własne ja i sympatia do drugiej osoby może być uzależniona od własnej samooceny w takim samym lub większym stopniu, jak od właściwości tej drugiej osoby. Samoocena często oparta jest na sprzężeniu zwrotnym, jakie otrzymuje się od innych osób, reakcja zaś, która występuje w takich okolicznościach, nie zawsze jest zgodna z przewidywaniami teorii równości.
Elliot Aronson (1969) opracował model wyjaśniający wpływ sprzężenia zwrotnego na sympatię do danej osoby, który nazwał |teorią |zyskiwania |i |utraty („gain-loss theory of attraction”). Zgodnie z tą teorią, |zmiany sposobu oceniania nas przez drugą osobę będą miały większy wpływ na naszą sympatię do niej, niż gdyby ocena ta była stała. Osobę, której uznanie dla nas wzrasta z czasem (sytuacja „zyskiwania”), będziemy zatem lubić bardziej niż kogoś, kto lubił nas zawsze. Podobnie osobę, która ocenia nas coraz bardziej negatywnie (sytuacja „utraty”) będziemy lubić jeszcze mniej niż kogoś, kto zawsze nas nie lubił.
Dlaczego tak się dzieje? Jednym z powodów jest to, że zmianę w postawie danej osoby jesteśmy bardziej skłonni przypisywać czemuś, co |sami zrobiliśmy („Ona zmieniła się, ponieważ poznała mnie lepiej”), podczas gdy niezmienną postawę przypisuje się dyspozycji danej osoby („On to zawsze mówi - po prostu on już taki jest i ja nie mam na to żadnego wpływu”).  Zmian opinii przypisujemy zatem w większym stopniu sobie. Innym możliwym powodem jest wzbudzanie i redukcja lęku. Ludzie wzbudzają w nas lęk wyrażając się o nas negatywnie; gdy później powiedzą coś pozytywnego („zysk”), to oceny te nie tylko są nagradzające same przez się, lecz także redukują uprzedni lęk i w ten sposób są podwójnie nagradzające. Wręcz przeciwnie byłoby w przypadku „utraty”.


„Aby sprawdzić ten model, przeprowadzono badanie, w którym osoby badane (studentki) pracowały w dwuosobowych grupach w ciągu kilku krótkich spotkań. Po każdym spotkaniu jedna z osób badanych mogła podsłuchać rozmowę między eksperymentatorem a jej „partnerką” (w rzeczywistości pomocnicą eksperymentatora), w której to rozmowie partnerka ta oceniała osobę badaną.  Były cztery główne sytuacje eksperymentalne: 1) sytuacja pozytywna - wszystkie oceny były przychylne; 2) sytuacja negatywna - wszystkie oceny były nieprzychylne; 3) sytuacja zyskiwania - początkowo oceny były nieprzychylne, lecz stopniowo stawały się równie przychylne, jak oceny w sytuacji pozytywnej; 4) sytuacja utraty - oceny początkowo były przychylne, lecz stopniowo stawały sie równie nieprzychylne, jak w sytuacji negatywnej.
Gdyby sympatia zależała od liczby otrzymywanych nagród, to partnerka powinna być najbardziej lubiana w sytuacji pozytywnej, najmniej - w sytuacji negatywnej, średnio zaś - w sytuacji zyskania i w sytuacji utraty.  Tak jednak się nie stało. Najważniejszym wyznacznikiem sympatii był układ czy sekwencja wzmocnień. Osoby badane bardziej lubiły swoją partnerkę z sytuacji „zyskiwania” niż tę partnerkę, której wszystkie oceny były pozytywne. Podobnie partnerka w sytuacji utraty była na ogół bardziej nie lubiana niż partnerka, która za każdym razem podawała negatywne oceny” (Aronson i Linder, 1965).




Miłość romantyczna




Biorąc pod uwagę doniosłe znaczenie miłości, która w takim stopniu przyczynia się do szczęścia człowieka i sprawia, że świat „nadal się kręci”, jest nieco zaskakujące, że psychologowie przeprowadzili tak mało badań nad tym tematem. Można to po części przypisać niechęci do „obiektywizacji” czegoś, co uważa się za romantyczne i mistyczne. Czym jest zjawisko, które nosi nazwę miłości? Badania Zicka Rubina (1973) ilustrują jedno z najlepiej usystematyzowanych ujęć tego delikatnego tematu:
„Badanie to dzieliło się na trzy zasadnicze fazy. Najpierw opracowano narzędzie typu „papier i ołówek” - „skalę miłości”. Po drugie, skalę tę dano do wypełnienia, razem z innymi miarami, 182 „chodzącym ze sobą” parom (studentom i studentkom). Po trzecie, przewidywania oparte na przyjętej koncepcji miłości sprawdzono w eksperymencie laboratoryjnym, który objął okres ponad sześciu miesięcy.
Opracowanie skali miłości zaczęto od utworzenia puli twierdzeń, dla których inspiracji dostarczyły różne psychologiczne i socjologiczne rozważania na temat miłości romantycznej. Włączono tu także twierdzenia mające uchwycić dokładniej zbadaną odmianę atrakcyjności interpersonalnej - zwykłą sympatię. Po wstępnej selekcji, dokonanej przez zespół sędziów, zbiór 70 twierdzeń dano kilkuset studentom, którzy ustosunkowali się do nich, biorąc pod uwagę swe postawy wobec osoby, z którą „chodzili”.  Następnie, przede wszystkim na podstawie analizy czynnikowej tych odpowiedzi, skonstruowano krótsze skale miłości i sympatii” (tabela).
Treść tej skali miłości posłużyła jako robocza definicja miłości w następnych fazach tego badania. Objęła ona nawet trzy zasadnicze komponenty: a) potrzeby afiliacji i zależności, b) predyspozycje do udzielania pomocy oraz c) wyłączność i zaobsorbowanie.
„Rubin chciał dowiedzieć się, czy wyniki, jakie „chodzące ze sobą” pary uzyskały na skali miłości, wiązały się z ich rzeczywistym zachowaniem wobec siebie nawzajem. Opierając się na koncepcji zgodnie z którą romantyczna miłość łączy się z skłonnością do całkowitego zaabsorbowania sobą nawzajem, dyskretnie obserwował on pary, które siedziały w odosobnieniu, czekając na rozpoczęcie eksperymentu. Stwierdził on, że pary, które uzyskały wysokie wyniki na skali miłości, częściej wpatrywały się sobie w oczy niż pary z niskimi wskaźnikami na tej skali.
Po upływie sześciu miesięcy Rubin poprosił te pary, aby wypełniły kwestionariusz dotyczący ich wzajemnego stosunku w tym czasie. Jak przewidziano, ich początkowe wskaźniki miłości wykazywały dodatnią korelację z ich wypowiedziami na temat tego, czy ich związek poczyni postępy w kierunku większej trwałości”.


Zgodnie z popularnym przekonaniem, innym aspektem miłości jest podzielanie uczuć drugiej osoby. Prawdziwy kochanek nie tylko wie o przypływach i odpływach nastroju partnera, lecz doświadcza ich także.


Jak Cię Kocham? Powiem Ci, Gdy Wypełnię Ten Test. „Skala miłości” opracowana przez Rubina składa się z zamieszczonych poniżej twierdzeń. Przy każdym z nich znajduje się 9-punktowe kontinuum (na którym zaznacza się swą odpowiedź), na którym 1 = W ogóle niezgodne z prawdą; zupełnie się nie zgadzam”, 9 zaś = „Zdecydowanie zgodne z prawdą; zgadzam się całkowicie”.




* * *



Skala Miłości
1.	Gdyby ... był(a) przygnębiony(a), moim pierwszym obowiązkiem byłoby podnieść go (ją) na duchu.
2.	Mam poczucie, że mogę wyznać ... niemal wszystko.
3.	Bez trudu zapominam o błędach popełnionych przez ... .
4.	Zrobił(a)bym prawie wszystko dla ... .
5.	Jestem bardzo zazdrosny(a) o ... .
6.	Gdybym nie mógł(a) nigdy być z ... czuł(a)bym się bardzo nieszczęśliwy(a).
7.	Gdybym był(a) samotny(a), moją pierwszą myślą byłoby odszukanie ... .
8.	Jedną z rzeczy, o które troszczę się najbardziej dobro ... .
9.	Wybaczył(a)bym ... prawie wszystko.
10.	Czuję się odpowiedzialny(a) za szczęście ... .
11.	Gdy jestem z ... spędzam wiele czasu po prostu patrząc na niego (nią). 
12.	Cieszył(abym) się bardzo, gdyby ... zwierzał(a) mi się.
13.	Byłoby mi trudno obejść się bez ... .

(Źródło: Rubin, 1973)


* * *





Tę „hipotezę empatii” sprawdzono w niezwykły sposób pod pozorem eksperymentu nad uczeniem się i pamięcią.


„Osobami badanymi byli studenci (mężczyźni), którzy siedzieli wokół wielkiego stołu w sali wykładowej. Zadanie ich było zupełnie proste: każdy po kolei musiał przeczytać głośno słowo wydrukowane na znajdującej się przed nim kartce. W każdej próbie połowa badanych wykonywała to zadanie (odczytywała głośno pojedyncze słowo), podczas gdy inni jedynie przysłuchiwali się. Badanym powiedziano z góry, że otrzymują polecenie, aby przypomnieli sobie wszystkie słowa, które były czytane.
Gdy badani byli sobie obcy, wówczas układy wyników przypominania u osób wykonujących zadanie i u słuchaczy były bardzo różne. W grupie słuchaczy procent zapamiętanych wyrazów wahał się od 23% do 37%. Natomiast w tej grupie, w której słuchanie było przerywane publicznym wykonaniem zadania (nawet tak prostego, jak odczytanie głośno zwykłego słowa), krzywa przypominania była zaskakująco różna. Odczytywane przez siebie samego słowa były pamiętane prawie bezwzględnie, podczas gdy najbliższe słowa przed i po „własnym” były pamiętane bardzo słabo - im dane słowo było bliższe w czasie słowu odczytywanemu przez siebie, tym gorzej było zapamiętywane.




* * *



Ryc. 13.7. Zakres Percepcji. Ci, którzy byli jedynie słuchaczami, zapamiętywali większość słów mniej więcej tak samo, a tylko trochę lepiej te słowa, które były wypowiadane przez znajdujące się najbliżej nich osoby.  Gdy jednak słuchacze stali się osobami „występującymi” (tzn. odczytującymi na głos słowa), wówczas układ wyników bardzo się zmienił. Słowa wypowiadane przez siebie zapamiętywali słowa prawie bezbłędnie, natomiast znacznie gorzej zapamiętywali słowa wypowiadane tuż przed ich „wystąpieniem”, a także zaraz po nim.


* * *





Lęk, czy zadanie zostanie wykonane dobrze, powodował najwyraźniej „stłumienie” reakcji występujących tuż przed i tuż po własnej (Brenner, 1971; ryc. 13.7).
Gdy osoby badane uczestniczyły w tym eksperymencie razem ze swym partnerem, z którym łączył je romantyczny związek, wówczas w krzywej przypominania u słuchaczy zaszła interesująca zmiana. Krzywa przypominania u osób badanych, które przyglądały się, podczas gdy ich partnera (tzn.  dobrze pamiętali słowo odczytywane przez ich partnera, słabo zaś - słowa odczytane przedtem i potem). Innymi słowy, zapamiętywali oni to zadanie tak samo, jak gdyby wykonywali je sami, a nie po prostu przysłuchiwali się mu.  Ten wływ „empatii” był wysoce skorelowany z innymi miarami miłości i dbałości; pary o wysokich wskaźnikach „empatii” częściej: a) podawały, że troszczą się o siebie nawzajem, b) przychodziły na eksperyment trzymając się za ręce lub obejmując się i wreszcie c) „chodziły ze sobą” nadal po upływie ośmiu miesięcy (Brenner, 1973).




Oddziaływanie społeczne
jako władza innych ludzi
nad człowiekiem




|Scenariusz |I: 27 czerwca 1973 roku Kathy Crampton, lat 19, została porwana ze swego miejsca zamieszkania w komunie należącej do Fundamentalistic Church of Armageddon (Fundamentalistycznego Kościoła Armageddon) w Seattle. Porywacze - kobieta i dwóch mężczyzn - wciągnęli ją siłą do samochodu, gdy zajęta była uprawianiem joggingu. Gdy policjant zatrzymał samochód, wówczas Kathy powiedziała mu, że ludzie ci porwali ją, zabrali ją brew jej woli. Powiedziała mu także, że nazywa się Corinht Love Israel, że ma 85 lat i że jej matką jest „duchowa wizja pokoju” (wszystko to zgodnie z jej wierzeniami religijnymi). Funkcjonariusz policji |nie interweniował. Zamiast tego pozwolił jej porywaczom wywieźć ją do San Diego.
Kobietą, którą Kathy oskarżyła o kidnaping, była Henrietta Grampton, jej matka; mężczyznami byli narzeczony jej siostry oraz Ted Patric, specjalista z zakresu „odprogramowania” („deprogramming”).
Kathy twierdziła, że nie brała narkotyków ani nie miała stosunków seksualnych z członkami swej nowej rodziny, lecz że z własnej woli poświęciła swe życie założycielowi Kościoła Armageddon, aby stać się dzieckiem Boga. Po stu dwóch godzinach przymusowej reindokrynacji, w skład której wchodziły obrzędy religijne, intensywne przesłuchiwania, napaści emocjonalne i zagrożenia fizyczne, „odprogramowanie” zakończyło się na pozór sukcesem.
Lecz następnego dnia Kathy Crampton z własnej woli zdecydowała się na ucieczkę oraz powrót do Seattle i Kościoła Armageddon. Ze względu mna jej wytrwałość w stawianiu oporu „odprogramowywaniu”, założyciel tej sekty nadał jej nowe imię: „Dedication („Poświęcenie”) Israel („CBS Evening News Specjal”, 13, 14, 15 sierpnia 1973, zobacz także „Los Angeles Times:, 4 grudnia 1972).


|Scenariusz |II: 4 lutego 1974 Patricia Hearst, lat 19, została porwana ze swego mieszkania w Berkeley, w stanie Kalifornia, przez kobietę i dwóch mężczyzn należących do Symbionese Liberation Army (Symbiotycznej Armii Wyzwoleńczej). Po złożeniu przez jej ojca, Randolpha Hearsta, żądanego okupu w postaci żywności dla ubogich wartości milionów dolarów, Patty miała zostać uwolniona. Wówczas, po upływie około 60 dni od chwili jej porwania, rodzinę Hearstów i większość narodu amerykańskiego wprawiło w osłupienie nagrane na taśmę magnetofonową oświadczenie Patty Hearst - która przybrała sobie imię Tania - że zdecydowała się ona pozostać w SLA. Do taśmy dołączona była fotografia młodej kobiety stojącej w żołnierskiej postawie na tle flagi SLA i trzymającej w ręku pistolet maszynowy (ryc. 13.8).
Patty poprzedziła swe oświadczenie uwagą, że „mówi to, co czuje”, że używa swych własnych słów i że nie była w żaden sposób poddana „praniu mózgu”, działaniu narkotyków, torturowana, hipnotyzowana ani w żaden inny sposób oszołomiona. Następnie oskarżyła swego ojca o „zbrodnie przeciwko ludzkości” oraz ogłosiła, ze zrywa ze swym narzeczonym, stwierdzając: 
„Zmieniłam się - dorosłam. Stałam sie świadoma i nie potrafię nigdy powrócić do takiego życia, jakie prowadziłam uprzednio (...)”.
W ciągu dziewiętnastu miesięcy, jakie upłynęły od czasu „porwania” jej z kolei przez FBI, Tana brała udział w przynajmniej jednym napadzie na bank i innych nielegalnych akcjach. Jej sensacyjny proces w San Francisco był oczywiście czymś więcej niż po prostu procesem mającym ustalić jej winę.  Rozpatrywano na nim naturę, istotę wolnej woli przeciwstawionej wpływowi silnych oddziaływań społecznych w postaci persfazji i indoktrynacji.  Obrońca F. Lee Bailey oparł swą obronę na założeniu, że miało tu miejsce pewnego rodzaju „pranie mózgu”. Stwierdził on, że znajdowała się ona pod takim naciskiem, iż pod jego wpływem została uwarunkowana w niewyobrażalnym posłuszeństwie wobec życzeń porywaczy. Zachowanie jej nie było zatem racjonalne, lecz wymuszone przez strach i prymitywną potrzebę utrzymania się przy życiu. Sąd nie podzielił tego poglądu, uznając ją winną napadu na Hibernia Bank. Sąd nie mógł przyjąć koncepcji przymusu pod nieobecność jej porywaczy, których większość została zabita w strzelaninie, jaka miała miejsce w Los Angeles ponad rok wcześniej.
Racjonalny wydaje się wniosek, że w przypadku Patty nastąpiło ideologiczne nawrócenie na „romantyczny” system przekonań politycznych SLA - pod wieloma względami podobne do nawrócenia religijnego Kathy Crampton.  Fizyczny strach, który początkowo prawdopodobnie odczuwała, sprawił, że poczuła wdzięczność wobec swych porywaczy, gdy uwolnili ją z zamknięcia i pozwolili jeść, spać i kontaktować się z młodymi ludźmi, którzy byli jej rówieśnikami.




* * *



Ryc. 13.8. Tę fotografię Patrycji Hearst Symbiotyczna Armia Wyzwolenia (SAL) opublikowano po 58 dniach od jej porwania. Wraz z fotografią nadeszła taśma magnetofonowa, a z nagranej na niej wypowiedzi Patty wynikało, że zdecydowała się ona wstąpić do SLA.


* * *





Ich ideały oraz głoszone przez nich hasła sprawiedliwości, równego podziału bogactw i równości rasowej, gdy były elementami życia w stylu Robin Hooda, musiały bardzo silnie przemawiać do młodej osoby nie posiadającej żadnej silnej ideologii politycznej, religijnej ani społecznej.
Z opisanych powyżej przypadków wynikają dwa zasadnicze problemy dla psychologa społecznego. Jakie warunki i zmienne powodują, że ludzie zmieniają swe postawy, swe przekonania i swe zachowanie? Kiedy następuje gruntowna przemiana słów i czynów danej osoby - jak w przypadku Kathy Crampton i Patty Hearst - w jaki sposób można ustalić, czy jest to „prawdziwe” nawrócenie, czy też jedynie zewnętrzne podporządkowanie się?  Inaczej mówiąc, skąd wiemy, czy jakieś działanie - nasze lub innych osób - wynika ze swobodnego wyboru, czy też jest rezultatem nacisków i przymusów?  Kiedy spostrzegamy je jako wyłaniające się w naturalny sposób z „naszego wnętrza”, a kiedy spostrzegamy je jako wywołane sztucznie z zewnątrz?




Różne twarze
perswazji




Niemal każdego dnia naszego życia jesteśmy atakowani przez podejmowanie systematycznie próby wpłynięcia na nasz sposób myślenia, odczuwania, działania. Nasze zmysły są napastowane za pośrednictwem środków masowego przekazu przez programy reklamowe, które nakłaniają nas do nabycia różnych produktów i rozmaitych usług, niezależnie od tego, czy mamy na nie ochotę czy ich potrzebujemy i czy możemy sobie na nie pozwolić. Politycy starają się wpływać na nasze głosy; nauczyciele próbują wpłynąć na nasze myślenie; przywódcy religijni starają się wpłynąć na naszą moralność i na uznawane przez nas wartości duchowe; nasi koledzy i przyjaciele wpływają na nasz styl ubierania się, słownik, „gust” muzyczny oraz poglądy na to, jaki chłopiec czy dziewczyna nadają się na „sympatię”, nasi rodzice zaś przekonują nas o doniosłym znaczeniu jedzenia szpinaku, sprzątania swojego pokoju, higieny osobistej, pewnych postaw wobec spraw seksualnych oraz wielu innych rzeczy.
Przyzwyczailiśmy się traktować te próby oddziaływania za coś oczywistego.  Świadczą o tym takie maksymy, jak „Można złapać więcej much przy użyciu miodu niż za pomocą octu”. Jednakże przypadki perswazji, podobne do przytoczonych wyżej przykładów, ciągle nas jeszcze niepokoją. Jednostronne oddziaływanie społeczne staje się jeszcze bardziej niemożliwe do zaakceptowania dla większości ludzi, gdy: a) „ofiara” nie jest w stanie opierać się ze względu na „młodociany wiek”, „niską inteligencję” lub zależność od osoby oddziałującej; b) osoba oddziałująca stosuje przymus i sprawuje kontrolę nad istotnymi elementami sytuacji; c) „ofiara” nie zyskuje niczego, podczas gdy osoba oddziałująca coś zyskuje i co najważniejsze, gdy d) istnieje wysokie prawdopodobieństwo, że próba oddziaływania okaże się skuteczna: nikt nie troszczy się o oddziaływanie społeczne, które nie osiąga swojego celu.


Kształcenie a propaganda. Można powiedzieć, że dana osoba swobodnie dokonała wyboru tylko wtedy, gdy zdaje ona sobie sprawę z wszelkich możliwości wyboru oraz z ich możliwych następstw i powiązań. Wielu pedagogów jest przekonanych, że ich podstawowym zadaniem jest nauczyć, |jak myśleć, a nie - co myśleć, że uczniów powinno się zachęcać do wyszukiwania alternatywnych możliwości rozwiązań i uczuć, w jaki sposób je oceniać, a nie nakłaniać do akceptowania czyjeś definicji problemu lub czyjegoś wyboru rozwiązania.


Propagandę definiuje się natomiast jako systematyczne rozpowszechnianie określonych idei, doktryn czy sposobów działania dla poparcia własnego stanowiska lub dla zdyskredytowania stanowiska przeciwnika. Skuteczna propaganda wiąże się zwykle z ukrywaniem przed zamierzonymi adresatami samego zamiaru ich przekonania, jak i prawdziwego nadawcy oddziaływań propagandowych.
Jeśli jednak propaganda działa najskuteczniej, gdy jest subtelna i nieoczywista, gdyby wówczas dostosowuje się do istniejącego kontekstu społecznego, to niekiedy jest ona niemożliwa do odróżnienia od tego, co uchodzi za kształcenie. Ucząc jak myśleć, podręczniki i nauczyciele muszą posługiwać się pewną treścią. W sposobie, w jakie dobierają oni lub pomijają treści, możemy wykryć pewną stronniczość, co w niektórych przypadkach każe uznać kształcenie za propagandę, zgodnie ze standardową słownikową definicją. Przypomnij sobie jak wiele zadań mających nauczyć cię rozumowania matematycznego zawierało takie pojęcia, jak kupowanie, sprzedawanie, dzierżawienie, pożyczki, procenty, kary pieniężne i płace?  Tego rodzaju zadania znacznie częściej występują w podręcznikach krajów mających kapitalistyczny system gospodarki niż w podręcznikach krajów socjalistycznych. Podobnie, wskutek pomijania w amerykańskich podręcznikach historii przedstawicieli mniejszości narodowych, ich wkład w rozwój Stanów Zjednoczonych jest systematycznie ignorowany.


Kiedy perswazja ma charakter przymusowy? Usiłowania prawników, funkcjonariuszy policji śledczej oraz przywódców państwowych, zmierzające do pozyskania naszego „swobodnie udzielonego” przyzwolenia czy zgody, są zaplanowane bardziej starannie. Louis Nizer (1961), słynny obrońca procesowy, opisuje subtelną psychologię sądu przysięgłych, na której, jego zdaniem, trzeba grać, ponieważ „możliwości wpływania na sąd przysięgłych są równie nieograniczone, jak zręczność adwokata” (s. 42). Nasza literatura obfituje w opis taktyki perswazji, wśród których mowa Marka Antoniusza na pogrzebie Juliusza Cezara stanowi klasyczny przykład.
Podręcznikom służącym do szkolenia policjantów w sztuce przesłuchiwania można przypisać część zasługi za to, że 80% wszystkich podejrzanych przyznaje się do winy po pewnym okresie przesłuchiwania (por. Imbau i Reid, 1967). W podręcznikach tych nadużycia przemocy fizycznej, charakterystyczne dla dawnego „śledztwa trzeciego stopnia”, zostały zastąpione „wyrafinowaniem” psychologii stosowanej, której używa się w wątpliwy pod względem etycznym sposób.




Zbliżenie


Wyspowiadaj się, moje dziecko, a będziesz zbawione - w więzieniu


„Podręczniki prowadzenia śledztwa głoszą, że nie „wymusza się” przyznania do winy, lecz uzyskuje się je jako dobrowolne oświadczenie od podejrzanego, rzeczywiście winnego popełnienia przestępstwa. Po złożeniu liczącego 61 stron maszynopisu zeznania, w którym przyznał się do popełnienia morderstw, podejrzany George Whitmore powiedział, że miał poczucie, iż przesłuchujący go funkcjonariusz jest mu bliższy niż własny ojciec. Później okazało się, że przyznanie się do winy Whitmore’a było fałszywe i że zostało ono uzyskane przy użyciu subtelnego przymusu, za pomocą starej, standardowej techniki zwanej jako |metoda |Mutta |i |Jeffa. Dwóch funkcjonariuszy śledczych pracuje jako para: Mutt, „brutal, który napada na podejrzanego, obraża go i grozi”, Jeff, który jest uprzejmy i kulturalny, udaje, że przykro mu z powodu napaści Mutta ubliżającego podejrzanemu, którego on stara się bronić. Jeff jest jedyną przyjazną istotą w tej beznadziejnej sytuacji. Przyznanie się mu dopomoże w znalezieniu jakiegoś rozwiązania, pozwoli Jeffowi przywołać Mutta do porządku i da mu szansę okazania pomocy swemu nowemu przyjacielowi w niedoli. W takiej sytuacji Whitmore czuł się zobowiązany do podania szczegółowego opisu dwóch morderstw, których nigdy nie popełnił.
Wariacje na ten temat obejmują ponadto „bluff wobec rozdzielonej pracy”, w którym dwóch podejrzanych rozdziela się, przy czym Podejrzanego I bierze się „na zaplecze”, podczas gdy Podejrzany II czeka we frontowym gabinecie.  Z pomieszczenia w głębi dobiegają krzyki, głośny hałas, po czym Podejrzany II słyszy, jak sekretarkę wzywają przez telefon. Po pewnym czasie sekretarka wraca do frontowego gabinetu i zaczyna pisać na maszynie, przerywając od czasu do czasu, żeby zapytać Podejrzanego II o pewne niezbędne informacje, które wpisuje do raportu. W końcu służbowy funkcjonariusz śledczy pojawia się i mówi, że nie ma już potrzeby przesłuchiwania Podejrzanego II, ponieważ sprawa jest zamknięta: jego partner „wyśpiewał” wszystko, złożył zeznania obciążające Podejrzanego II.  W wielu przypadkach nie podejrzewający niczego Podejrzany II wypiera się wówczas wszystkiego, opisując szczegółowo przestępstwo i oskarżając wspólnika. Po tym „dobrowolnym” zeznaniu Podejrzany I, który do tej chwili nie powiedział niczego, może już przeczytać te zeznanie i wziąć całą winę na siebie lub też pogrążyć wspólnika.
W technice zwanej |odwrócony rząd” (identyfikowanych przestępców), osoba podejrzana o jakieś lżejsze przestępstwo może być rozpoznana przez kilku poważnie wyglądających świadków (współpracowników policji) jako osobnik napastujący dzieci, kidnaper, uzbrojony włamywacz lub jakikolwiek inny zbrodniarz. Wobec perspektywy wyroku skazującego na 20 lat więzienia lub dożywocie, przyznanie się do lżejszego przestępstwa zagrożonego karą od roku do pięciu lat więzienia wydaje się wielu naiwnym podejrzanym najmądrzejszą rzeczą, jaką mogą zrobić.
Poza opisami tego rodzaju metod, podręczniki prowadzenia śledztwa pouczają kandydatów na funkcjonariuszy śledczych, w jaki sposób powinien być urządzony pokój do przesłuchań, jak należy się ubierać, mówić i traktować podejrzanego, aby wywrzeć na niego maksymalny wpływ. Niektórych ludzi można doprowadzić do tego, by uwierzyli w prawdziwość swego fałszywego przyznania się do winy - świadczą o tym procesy prowadzone w latach trzydziestych, w okresie stalinowskich czystek politycznych, zaś w kontrolowanych badaniach laboratoryjnych wykazał to Daryl Bem” (1966).


Na ogół przyjmuje się, że przy rozpoznawaniu sytuacji przymusu można posłużyć się następującymi kryteriami: a) nagła, dramatyczna zmiana przekonań i wartości, zamiast stopniowej ewolucji nowego środowiska, b) brak dostępu do zwykle używanych źródeł informacji, aprobaty i porównań społecznych, c) uwięzienie w miejscu, gdzie dopływ informacji, jak również źródła wzmocnienia społecznego są kontrolowane, d) ustawiczny kontakt z osobami dokonującymi perswazji, e) obietnica, że obecna sytuacja jest jedynie chwilowa i że powrót do dawnej sytuacji jest możliwy.
„Pranie mózgu” („brainwashing”) odpowiada tym kryteriom. Nie jest to termin naukowy, lecz słowo utworzone przez pewnego reportera dla wyjaśnienia „nawróceń”, jakie pod wpływem technik perswazji stosowanych przez chińskich komunistów wystąpiły u niektórych amerykańskich jeńców wojennych w czasie wojny koreańskiej (Schein, 1961; Hinkle i Wolff, 1956).




Co kształtuje
- i zmienia
- postawy?




|Postawa jest to względnie stała, zabarwiona emocjonalnie gotowość do reagowania w pewien spójny czy konsekwentny sposób wobec pewnej osoby, grupa ludzi lub sytuacji. Pytanie, w jakie sposób postawy są przyswajane i ulegają zmianie jest interesujące dla nas wszystkich. Jesteśmy nie tylko obiektem różnych zarysowanych wyżej rodzajów perswazji; musimy także pamiętać, że rzadkością jest człowiek, który nigdy nie starał się wpłynąć na kogoś innego, zmienić czyjegoś poglądu za pomocą „gładkich słów”, argumentacji, przykładu, prośby, groźby czy łapówki w zamaskowanej postaci.  Niewiarygodny sukces książki Dale’a Carnegie’ego „How to Win Freinds...” (Jak zdobyć przyjaciół i wpływ na ludzi) można przypisać po części naszej potrzebie afiliacji, lecz ponieważ pozostała część tytułu oraz tekst dotyczą oddziaływania na ludzi, to być może większość z nas chciała udoskonalić swoje umiejętności z zakresu manipulowania ludźmi.




Zbliżenie


Facylitacja społeczna (mimo braku perswazji)


„Jesteśmy tak wrażliwi na innych ludzi, że często wywierają oni znaczny wpływ na nasze zachowanie, nawet wtedy, gdy nie zamierzają tego czynić.  Wpływ, który obecność innych ludzi wywiera na nas, zwany jest |facylitacją |społeczną. Na przykład aktor może odczuwać tremę i zapominać swą rolę po prostu dlatego, że zobaczył widownię wypełnioną widzami. Z drugiej strony, zawodnicy (biegacze, pływacy, automobiliści, kolarze) prawie zawsze uzyskują |lepsze wyniki w obecności rywali niż wtedy, gdy walczą tylko z czasem (Triplett, 1897). W wielu kontrolowanych badaniach, przeprowadzanych na ludziach i zwierzętach, uzyskuje się ten sam, ogólny wniosek: sama obecność innych osobników może wywierać pobudzający lub hamujący wpływ na zachowanie (Simmel, Hoppe i Milton, 1968).
Wysunięto hipotezę, że |obecność |innych jest bodźcem wzbudzającym ogólny, niespecyficzny stan popędowy, który następnie ułatwia wykonanie utrwalonych nawyków i prostych reakcji, lecz jako czynnik rozpraszający uwagę ma zakłócający wpływ w sytuacjach, w których przyswajane są złożone reakcje (Zajonc, 1965, 1968). Opierając się na wynikach tej analizy, rozstrzygnij czy powinieneś uczyć się sam - a zdawać w grupie, czy też uczyć się w grupie - a zdawać sam?”


Postawy mają trzy komponenty: a) |przekonania, czyli twierdzenia dotyczące tego, jaki jest lub powinien być obiekt postawy; b) |komponent |afektywny, czyli emocje związane z tymi przekonaniami, które można mierzyć w kategoriach reakcji fizjologicznych lub intensywności i stylu odpowiedzi, oraz c) |komponent |behawioralny, dotyczący działania wobec przedmiotu postawy, przy czym określa się prawdopodobieństwo reagowania w określone sposoby. Kształtujemy postawy wobec wielu rzeczy w naszym życiu, przy czym niektóre z nich znamy jedynie pośrednio, z informacji dostarczonych przez innych ludzi. Jednym ze źródeł kształtowania postaw jest zatem |informacja - czy to uzyskana za pomocą bezpośredniej obserwacji, czy otrzymana od innych, czy też uzyskana w wyniku procesu wnioskowania. Inne źródła postaw, omawiane już w poprzednich rozdziałach, obejmują |obserwację |modeli i następstw ich działań oraz |nagrody i |kary (zwykle o charakterze społecznym) wymierzane przez naszych rówieśników lub rodzinę za posiadanie lub nie posiadanie danej postawy. Nasze postawy mogą być także produktami ubocznymi wypartych konfliktów lub wynikiem ich przemieszczenia. Zakłada się, że ta związana z |obroną |ego funkcja postaw odgrywa ważną rolę w kształtowaniu niektórych spośród naszych najsilniejszych i najbardziej „irracjonalnych” postaw, na przykład uprzedzeń rasowych i religijnych (Sarnoff, 1960).
Jeśli postawy kształtują się w kilka podanych wyżej sposobów, to możemy oczekiwać, że zmiany w nich będą zachodzić w wyniku otrzymania nowych informacji, obserwowania nowych modeli lub też starych modeli w nowych warunkach wzmocnienia, w wyniku zmiany nagród i kar wymierzonych za nasze własne postawy oraz w wyniku rozwiązania naszych psychodynamicznych konfliktów. Aczkolwiek obecnie bada się wszystkie te metody zmiany postaw, to jednak zasadniczy sposób podejścia przyjęty przez psychologów społecznych polega na traktowaniu ludzi jako jednostek racjonalnie przetwarzających informacje, których postawy można zmieniać dostarczając im przekonywujących komunikatów.


Z jakim skutkiem ktoś mówi coś do kogoś? Arystoteles swej „Retoryce” przypisał przekonywający wpływ przekazywanej wiadomości trzem odrębnym czynnikom, które określił jako |etos, |logos i |patos. Czynniki te odpowiadają cechom nadawcy przekazu, właściwościom samego przekazu oraz emocjonalnym cechom audytorium (odbiorcy przekazu). Naukowe badania nad skutecznością przekazu stosują się do wskazówek Arystotelesa - bada się w nich, „|kto mówi, |co mówi, do |kogo mówi - i z jakim skutkiem”. Ten podstawowy paradygmat został opracowany przez badaczy z Yale University w ramach programu badawczego poświęconego komunikacji i zmianie postaw („Communication and Attiude Change Program” - Hovland, Janis i Kelley, 1953).
Chociaż badania koncentrują się tylko na trzech zmiennych - źródle, przekazie i audytorium - to jednak zwykle stwierdza się raczej złożone interakcje niż proste „efekty główne” („main effects”). Przyczyna tego będzie oczywista, gdy rozpatrzymy choćby tylko kilka wymiarów, pod względem których mogą się różnić źródła, przekazy i audytoria:
1.	|Źródło - fachowość, wiarygodność, pozycja społeczna (status), zdolność wywierania przymusu i nagradzania, wiek, płeć, rasa, grupa etniczna, wygląd fizyczny, atrakcyjność, cechy głosu, stopień identyfikacji z początkową postawą audytorium, itd.
2.	|Przekaz - stosowanie apeli racjonalnych lub emocjonalnych, typ apeli emocjonalnych (strach, poczucie winy, wstyd itd.), sposób organizowania przekazu (stopniowe narastanie do punktu kulminacyjnego lub „mocne uderzenie” od początku), styl wypowiedzi, język (formalny, potoczny, gwara, wyzwiska, slogany), przedstawianie obu stron zagadnienia lub tylko jednej strony, przedstawianie najpierw punktów pozytywnych lub negatywnych itd.
3.	|Audytorium - wszystkie cechy psychologiczne i demograficzne, pod względem których ludzie mogą się różnić; szczególnie istotne są tu: płeć, inteligencja, poziom wykształcenia, cechy osobowości (samoocena, zależność, dogmatyzm, ekstrawersja), a także zaangażowanie oraz stopień poinformowania o danej kwestii, skrajność początkowej postawy itd.

Pomimo całej tej złożoności, przeprowadzono dosłownie tysiące eksperymentów według tego paradygmatu.




Zbliżenie


Wyniki badań nad zmianą postaw


„Poniżej podajemy kilka wniosków dotyczących efektywności przekazu, jakie wynikają z wielu badań nad zmianą postaw, w których kontrolowano treść przekazu, jego źródło oraz audytorium. Praktycznie musimy zwykle dodać, „lecz zależy to także od czynników X, Y i Z”.
1. Przedstaw |jedną stronę zagadnienia, gdy audytorium jest nastawione na ogół przyjaźnie lub kiedy twoje stanowisko jest jedynym, jakie będzie prezentowane, lub kiedy chcesz doprowadzić do natychmiastowej, aczkolwiek nietrwałej, zmiany opinii.
2. Przedstaw |obie strony zagadnienia, gdy audytorium z początku nie zgadza się z tobą lub gdy jest prawdopodobne, że audytorium dowie się o drugiej stronie zagadnienia od kogoś innego.
3. Gdy przeciwne poglądy są przedstawiane jeden po drugim, to pogląd przedstawiony jako ostatni będzie prawdopodobnie bardziej efektywny. |Efekt |pierwszeństwa dominuje bardziej wtedy, gdy drugi pogląd jest prezentowany natychmiast po pierwszym; natomiast |efekt |świeżości bardziej dominuje wtedy, gdy pomiar opinii przeprowadza się natychmiast po zaprezentowaniu drugiego poglądu.
4. Jeśli |wyraźnie sformułujesz swe wnioski, to prawdopodobnie wystąpi większa zmiana opinii w pożądanym przez ciebie kierunku niż wtedy, gdy pozwolisz audytorium wyciągnąć własne wnioski - chyba że ich inteligencja jest wysoka.
5. Niekiedy silniejszy wpływ mają apele emocjonalne, a niekiedy oparte na faktach. Wszystko zależy od rodzaju audytorium i od warunków.
6. Odwoływanie się do strachu: wyniki badań, ogólnie biorąc, wykazują, że istnieje dodatnia korelacja między intensywnością wzbudzenia strachu a wielkością zmiany postaw, jeśli możliwe jest podanie wyraźnych wskazówek co do zalecanego działania; w przeciwnym wypadku korelacja ta jest ujemna.
7. Im mniej zewnętrznych uzasadnień dostarczy się w przekazie nakłaniającym do dewiacyjnego czy niezgodnego z postawami zachowania, tym większa będzie zmiana postawy po faktycznym podporządkowaniu się.
8. Sygnały ostrzegające audytorium o manipulacyjnych intencjach przekazu zwiększają opór względem niego, podczas gdy obecność czynników rozpraszających uwagę, prezentowanych równocześnie z przekazem, zmniejsza opór i zwiększa wpływ perswazji”.



Aby zmienić postawy, zmień najpierw zachowanie. Psychologowie społeczni badali proces zmiany postaw, ponieważ zakładali oni, że postawy są „predyspozycjami do działania”. Oczekiwano zatem, że znajomość warunków wpływających na kształtowanie i zmianę postaw zapewni skuteczne środki przewidywania i wpływania na zmianę zachowania. Jak dalece trafne są te założenia i wyjaśnienia?
Niestety, w wielu badaniach stwierdzono bardzo niską korelację pomiędzy mierzonymi postawami a innymi zachowaniami. Ponadto |zmiana |postawy spowodowana oddziaływaniem społecznym perswazyjnego komunikatu często nie ma żadnego związku ze |zmianą |zachowania. Nic w tym dziwnego, gdy uświadomimy sobie, że warunki, w których otrzymuje się werbalne stwierdzenia na skalach postaw, mogą różnić się pod wieloma względami od warunków, w których występują obserwowalne zachowania, jakie usiłuje się zmienić. Nawet jeśli oba te zbiory zachowań są związane ze wspólną podstawą, leżącą u ich podłoża, to każdy z nich jest po części pod kontrolą swych własnych warunków wzmocnienia. Narzędzie werbalne w postaci kwestionariusza, w którym jednostka oczekuje aprobaty za wykazanie stanowiska tolerancyjnego, może zatem nie wykazywać żadnych uprzedzeń, podczas gdy ta sama jednostka może przejawiać całkiem odmienne postawy w towarzystwie swych wykazujących uprzedzenia przyjaciół.
Ostatnio badacze zaatakowali z innej strony zagadnienie zmiany postaw, opierając się na mądrości zawartej w stwierdzeniu Arystotelesa, że „ludzie przyswajają sobie określoną cechę przez ciągłe działanie w określony sposób”. Istotnie, obecnie istnieje znaczny materiał dowodowy potwierdzający pogląd, że zmianę postaw u danej jednostki najłatwiej jest osiągnąć |po poddaniu jej oddziaływaniu sytuacji, w której zachowanie tej jednostki zostaje zmienione bezpośrednio.
Ludzie, w różnych sytuacjach i z różnych powodów, dają się nakłonić do podejmowania zachowań sprzecznych z ich postawami: w sporze, w zabawie, ponieważ ich praca tego wymaga, dla osobistej korzyści, dla uniknięcia kary lub śmieszności, aby nie sprawiać kłopotu itd. Często sam akt podjęcia zachowania, którego wystąpienie było poprzednio mało prawdopodobne, wystarczy, aby dana jednostka zdała sobie sprawę z jego pozytywnych aspektów, a ludzie prędzej uwierzą w to, co chwalili i sami praktykowali niż w to, co usłyszeli lub przeczytali. Wykazano też, że nakłonienie ludzi do podporządkowania się jakiemuś niewielkiemu wymaganiu zwiększa ich skłonność do podporządkowania się poważniejszemu, bardziej rozbieżnemu z ich postawą żądaniu - jest to tak zwana technika „wetknięcia nogi między drzwi” („Foot-in-the-door technique”; Freedman i Fraser, 1966).
Zwykle jednak nie wystarczy po prostu nakłonić ludzi do wykonania jakiejś mocno nie lubianej czynności, aby ich postawa uległa zmianie. Jeśli mogą oni przypisać swój akt uległości siłom |zewnętrznym (takim, jak nagroda lub przymus), to mogą oni zachowywać swą pierwotną postawę, nawet jeśli ich zachowanie jest z nią sprzeczne. Jednakże warunki bodźcowe, które mogą skłonić ludzi do wykonania rozbieżnej z postawą czynności i zarazem pozwalają spostrzegać ją jako wynikającą z ich własnego wyboru, wywołują stan dysonansu poznawczego; tak więc muszą oni albo: a) zmienić swe postawy, aby pasowały do ich zachowania, b) oddzielić psychologicznie tę czynność od danej postawy lub c) przyznać się sobie samym, że zachowują się irracjonalnie. Stwierdzenia te są zgodne z naszymi wcześniejszymi rozważaniami nad dysonansem.
Dochodzimy zatem do odpowiedzi na początkowe pytania, które postawiliśmy w odniesieniu do przypadków Kathy Crampton i Patty Hearst. Prawdopodobnie uważały one swą zmianę przekonań za swobodną i nie wymuszoną, ponieważ nie zdawały sobie sprawy z roli czynników sytuacyjnych wywołujących ich działania lub też nie były wrażliwe na te czynniki. Gdyby w celu spowodowania ich publicznej uległości zastosowana siłę fizyczną, groźby, nagrody oraz inne rodzaje uzasadnień zewnętrznych, to jest nieprawdopodobne, aby w podobny sposób udało się zmienić ich prywatne przekonania. Od razu po zniknięciu zewnętrznych nacisków powróciłyby ich osobiste przekonania. Przekonaliśmy się jednak, że gdy publiczny akt uległości wywołała się przy minimalnym zewnętrznym uzasadnieniu, wówczas towarzyszące temu aktowi zmiany w przekonaniach i wartościach nie tylko są uważane przez daną jednostkę za „prawdziwe” i „kierowane” od wewnątrz”, lecz także mają duże szanse utrzymania się.
Podstawową zasadą w przypadku każdej formy oddziaływania społecznego jest stosowanie tak niewielkiego nacisku, jaki jest niezbędny, aby zaledwie wywołać podjęcie danego zachowania, przy jednoczesnym zwiększaniu siły przekonania danej osoby, że ma możność wyboru. W takich okolicznościach niemożliwe staje się określenie, czy uzyskana w ten sposób zmiana postaw została wymuszona, czy też istotnie stanowiła wybór rozumującej osoby.




Dynamika grup




W wielu przypadkach ludzi przekonuje i nakłania do działania nie jedna osoba używająca perswazji, lecz bardziej „rozproszony” nacisk, jaki wywiera na nich grupa, do której należą. Obszerną dziedziną badań w psychologii społecznej jest badanie wpływu procesów grupowych na funkcjonowanie pojedynczych członków grupy.




Dynamika grup jako
kierunek w psychologii




Na początku lat czterdziestych, kiedy dominującymi sposobami podejścia w psychologii był behawioryzm oraz badania nad uczeniem się zwierząt, grupa młodych badaczy zaczęła badać szersze kategorie reakcji molarnych, jakie występują u ludzi pod wpływem grupy. Pod kierunkiem Kurta Lewina (który wtedy właśnie wyemigrował z Niemiec do Stanów Zjednoczonych) zorganizowali oni pierwszy formalny Groups Dynamics Center (Ośrodek Dynamiki Grup), początkowo przy Massachusetts Institute of Technology, obecnie zaś na University of Michigan. Założyli oni także National Training Laboratories (Narodowe Laboratoria Treningowe) w Bethel, stan Maine, gdzie od wielu laat ludzie reprezentujący różne zawody zaznajamiają się z procesami zachodzącymi w grupie i w których powstały pierwsze „grupy T” (grupy treningowe) zapoczątkowujące współczesny ruch „grup spotkaniowych”.
Jedynym z celów tej szkoły było badanie dynamicznych właściwości |interakcji |społecznych w grupach, z tą samą dokładnością i ścisłością, z jaką inne procesy psychologiczne badano na poziomie indywidualnym. Jak stwierdzili dwaj popularyzatorzy tego sposobu podejścia (Cartwright i Zander, 1968):


„(...) dynamikę grup należy zdefiniować jako dziedzinę badań zajmujących się wzbogacaniem wiedzy o naturze grup, prawach ich rozwoju oraz ich wzajemnych relacjach z jednostkami, innymi grupami oraz większymi instytuacjami. Dziedzinę tę można zidentyfikować za pomocą czterech charakterystycznych cech: a) nacisku na badania empiryczne, istotne pod względem teoretycznym, b) zainteresowania dynamiką zjawisk i ich wzajemną zależnością, c) dużego znaczenia dla wszystkich nauk społecznych oraz d) potencjalnej możliwości zastosowania uzyskanych wyników w próbach zmierzających do udoskonalenia funkcjonowania grup oraz jego skutków dla jednostek i społeczeństwa” (s. 7). 


Impulsu do zbadania wpływu grupy na postawy i zachowania jednostek dostarczył klasyczny eksperyment przeprowadzony w czasie II wojny światowej przez Kurta Lewina.


„Eksperyment ten miał zarówno wartość teoretyczną, jak i praktyczną.  Ponieważ, wobec niewystarczającej podaży zwykłych gatunków mięsa, było ono racjonowane, postanowił on zatem spróbować zmienić decyzję gospodyń domowych dotyczące gatunku kupowanego mięsa. Starał się zainteresować je podrobami, takimi jak serce, nerki, trzustka i grasica, które, choć bardzo pożywne, łatwiej dostępne, nieracjonowane i tańsze, były jednak powszechnie nie lubiane.
Połowa grup wysłuchała interesującego odczytu, mającego zmienić poglądy gospodyń na korzystanie z tych gatunków mięsa. Przystojny, młody „nadawca” (psycholog Alex Bavelas) starał się wywrzeć na swe audytorium tak silny wpływ, jak tylko umiał. Pozostałym grupom przedstawiono ten sam problem, a następnie zachęcano je, aby przedyskutowały trudności, jakie „gospodynie podobne do nich” mogłyby napotkać starając się wprowadzić do swych jadłospisów więcej tych gatunków mięsa.
Pod koniec tego spotkania zachęcano kobiety, aby zadeklarowały przed podniesienie rąk, które z nich chciałyby wypróbować jeden z tych gatunków mięsa w ciągu najbliższego tygodnia. Późniejszy sprawdzian wykazał, że tylko 3% kobiet, które wysłuchały odczytu podało na obiad jeden z tych gatunków mięsa, których nigdy nie podawały wcześniej, podczas gdy zrobiło to 32% kobiet uczestniczących w grupowej dyskusji i w grupowym podejmowaniu decyzji” (Lewin, 1947).


Możemy zidentyfikować przynajmniej cztery źródła oddziaływania grupy, które przypuszczalnie wpłynęły na zmianę zachowania tych osób badanych i są charakterystyczne dla grup w ogóle: 1) współuczestnictwo, 2) publiczne zaangażowanie, 3) poparcie społeczne, 4) standardy normatywne.
1. |Współuczestnictwo. Gdy ludzie uczestniczą w dyskusjach dotyczących spraw ich interesujących i biorą udział w procesie podejmowania decyzji, wówczas angażują się osobiście. W wytworzonej w ten sposób „demokracji uczestniczącej” każdy członek grupy jest |aktywnym uczestnikiem procesu zmian, a nie tylko |biernym odbiorcą jakiejś dostarczanej z zewnątrz informacji lub obiektem decyzji podjętej przez kogoś innego (przypomina to różnice między stopniem twego zaangażowania na dużej sali wykładowej i w małej grupie seminaryjnej). Badania oraz doświadczenia praktyczne z grupami w środowisku przemysłowym i w innych sytuacjach naturalnych wyraźnie wykazują, że współuczestnictwo grupowe jest niezbędne, aby ludzie zaakceptowali nowatorskie idee oraz zmiany w swym zwykłym sposobie działania. Podejmowane przez kierownictwo próby narzucenia pracownikom zmian w metodach pracy, napotykają zwykle na bezpośredni i pośredni opór, łącznie z absencją, spadkiem wydajności i obniżonym morale - nawet gdy dana zmiana ma na celu uczynienie pracy łatwiejszą (Coch i French, 1948).
2. |Publiczne |zaangażowanie. Jest bardziej prawdopodobne, że indywidualny członek grupy będzie bardziej konsekwentnie realizować zalecaną zmianę wtedy, gdy decyzja grupowa wiąże się z „podnoszeniem rąk”, niż wtedy, gdy jego zaangażowanie ma charakter prywatny. Zaangażowanie publiczne, którego świadkami są inni członkowie grupy, wymaga późniejszej realizacji decyzji w działaniu, jeśli dana jednostka ma być spostrzegana jako konsekwentna i zasłużyć sobie później na aprobatę. Zaangażowanie pomaga także skupić błądzące myśli i ukierunkować opinie, koncentrując je na zmierzających do celu działaniach (Kiesler, 1971).
3. |Poparcie |społeczne. Decyzje indywidualne dotyczące podjęcia działania zostają umocnione, gdy inne osoby z grupy zgadzają się z nimi.  Poparcie społeczne, jakiego dostarcza jednomyślność grupy, nie tylko zwiększa zaufanie do trafności własnej decyzji, lecz także zapewnia obronę wobec opozycji i kontrnacisków.
4. |Standardy |normatywne. Istnieje nieskończona różnorodność możliwych sposobów reagowania w różnych sytuacjach; gdy jednak odkrywamy standardy akceptowane przez innych członków grupy, to zachęca nas to do wybierania niektórych spośród tych sposobów, zniechęca zaś do innych. Reguły te, wyznaczające „właściwą” w danej sytuacji reakcję społeczną, pomagają nam ustalić charakter naszej sytuacji społecznej, umożliwiają, dzięki procesom porównania społecznego, określenie „właściwego” sposobu zachowania, a dostarczając członkom grupy wspólnego układu odniesienia, wzorca, do którego należy się dostosować, wzmaga w ten sposób poczucie tożsamości grupowej.

Standardy takie zwane są |normami |społecznymi. Stają się one potężnymi czynnikami wpływającymi na nas wszystkich i są przedmiotem wielu zakrojonych na szeroką skalę badań. W niektórych przypadkach normy grupowe są jasne i wyraźne - funkcjonują niemal tak, jak prawa. W innych, norma nigdy nie zostaje wyrażona słowami i nowi członkowie jedynie stopniowo i niepostrzeżenie uświadamiają sobie jej wpływ na swoje zachowanie. Często dopiero wtedy dowiadujemy się, że jakaś norma istnieje, kiedy zostaniemy ukarani za jej pogwałcenie.




Zbliżenie


Dlaczego Charlie nie podnosi się ręki


„Na niektórych uczelniach istnieje norma studencka, która ogranicza uczestnictwo studentów podczas wykładów. W jednym, godnym uwagi przypadku, łamanie tej normy („Zamknij się i pozwól wykładowcy robić to, za co mu płacą”) mało przykre konsekwencje dla gorliwego, naiwnego studenta uczęszczającego na wstępny kurs psychologii. Ten młody student, Charlie B., nie tylko odpowiadał bardzo wyczerpująco na pytania, lecz także zadawał pytania i zgłaszał się na ochotnika do odpowiedzi. Początkowo, gdy podnosił się, aby odpowiedzieć, studenci siedzący wokół niego poszturchiwali się wzajemnie, uśmiechali się, marszczyli i chrząkali. Z czasem te niewerbalne komentarze przekształciły się w chichoty i szurania nogami. W końcu, gdy miał on się podnieść, student siedzący z jednej lub z drugiej strony szturchał go przypadkowo lub odwracał się, aby popatrzeć na niego, zrzucał jego książki lub przyciskał go do siedzenia. W połowie roku Charlie nigdy już nie podnosił ręki ani nie odpowiadał, gdy wykładowca go zapytał. Co więcej, po upływie dwóch lat powiedział on swemu wykładowcy (w czasie zebrania informacyjnego o studiach podyplomowych): „Nigdy już nie będę chodził na wykłady, nawet jeśli wykładowca jest dobry; nie wiem dlaczego, lecz z jakichś powodów odczuwam wtedy niepokój i lęk”.




Funkcje norm
społecznych




Aczkolwiek normy grupowe, oparte na dotkliwych karach za ich pogwałcenie, mogą tłumić aktywność i sprzyjać nadmiernemu konformizmowi, niemniej jednak normy spełniają nieodzowne funkcje. Zdawanie sobie sprawy z norm działających w danej sytuacji grupowej pomaga w ukierunkowaniu i uregulowaniu życia społecznego. Normy naoliwiają maszynerię interakcji społecznej, pozwalając każdemu uczestnikowi przewidzieć, w jaki sposób inni wystąpią w danej sytuacji (na przykład, co „na siebie włożą”) i co prawdopodobnie będą mówić i robić, a także, jakie zachowanie z jego strony będzie zgodne z oczekiwaniami i aprobowane.
Ucząc się zachowań, które pozwalają zoptymalizować „wypłatę” w postaci nagród i kar, kształtujemy także swój światopogląd, strukturę poznawczą, kompletujemy zbiór reguł „nadających sens” rzeczywistości. Ta społecznie ukształtowana rzeczywistość może zatem zacząć brać górę nad rzeczywistością fizyczną i biologiczną.
Pewien margines tolerancji - szeroki w jednych przypadkach, a wąski w innych - dla odchylenia się od danego standardu, również stanowi część normy. Członkowie grupy mają zatem podstawę dla oceny, jak daleko mogą się posunąć, nie doświadczając jeszcze potężnej siły przymusu w postaci ośmieszenia, represji i odrzucenia.
Podporządkowanie się normom grupy jest także pierwszym krokiem do wytworzenia identyfikacji z nią, pozwalającej jednostce korzystać z prestiżu i siły grupy. W ten sposób mały wątły wyrostek staje się twardym, wzbudzającym strach członkiem bandy „Odrzutowców” („Jets”), a łysiejący mężczyzna w średnim wieku, posiadacz motocykla, jest uważany przez osoby postronne za jednego z „Aniołów Piekła” („Hell’s Angels”).
Kontrola społeczna, realizowana za pośrednictwem norm grupowych, nie jest jednak odraczana do czasu, gdy dana jednostka dołączy się do takiej czy innej grupy (z wyjątkiem, gdy ktoś „dołącza” do społeczeństwa rodząc się w nim), lecz jest wprowadzana jako zasadnicza część procesu socjalizacji; szanowanie starszych, mówienie „dziękuję”, zasada „nie rób drugiemu co tobie nie miło” oraz nasze kodeksy etykiety - wszystko to są normy, które wpływają na nas niemal od momentu urodzenia.
Uczymy się także z obserwacji, że normy funkcjonują nawet w tych sytuacjach, w których interakcja społeczna jest ograniczona i przelotna. Na przykład, oczekuje się, że w windzie każdy będzie stał twarzą do drzwi i nie będzie mówił zbyt głośno.


Niewłaściwe jest przepychanie się do przodu w kolejce, niestosowne jest wycieranie nosa inaczej niż w chusteczkę itd. Jednakże jest także oczywiste, że normy społeczne są związane z daną kulturą: to, co jest właściwe w jednym społeczeństwie, uchodzi często za obraźliwe zachowanie w innym.




Wpływ norm społecznych
w laboratorium




Jeden ze sposobów podejścia, stosowanych w badaniu wpływu norm grupowych na zachowanie jednostki, polega na porównywaniu ocen pewnego zdarzenia z zakresu percepcji, dokonywanych przez daną jednostkę w samotności i w towarzystwie innych. Klasyczne badanie tego typu przeprowadzili Muzafer Sherif (1935) i Solomon Asch (1955).


Siła większości. Bodźcem zastosowanym przez Sherifa w eksperymencie był nieruchomy punkt świetlny w ciemnym pomieszczeniu. Gdy nie ma żadnego układu odniesienia, wówczas wydaje się, że taki punkt świetlny porusza sie nieregularnie w różne strony. Zjawisko to nosi nazwę |efektu |autokinetycznego.


„Osoby badane (mężczyzn) poproszono najpierw, aby indywidualnie oceniły ruchy punktu świetlnego. Ich oceny różniły się znacznie: niektórzy widzieli ruchy na odległość paru cali, podczas gdy inni podawali, że punkt świetlny poruszał się na przestrzeni wielu jardów. Jednakże po dokonaniu szeregu ocen każdy badany ustalił pewien zakres, w obrębie którego mieściła się większość ocen. Następnie jednak, gdy włączono go do grupy wraz z dwoma lub trzema innymi badanymi, jego i ich oceny zaczynały zbiegać się w obrębie nowego zakresu, na który wszyscy oni niejako się zgodzili. Gdy to się stało, to jego późniejsze oceny mieściły się w tym nowym zakresie - nawet wtedy, kiedy był już sam w pomieszczeniu”.


Te ukształtowane przez grupę normy mogły być zupełnie różne od własnych ocen jednostki, które zanotowano przed wystąpieniem oddziaływania społecznego. Normy te są trwałe: w jednym z badań zaobserwowano ich działanie po upływie całego roku (Rohrer i in., 1954).
Można by wysunąć argument, że oddziaływanie społeczne, obserwowane w tych badaniach, ma bardzo ograniczone znaczenie, ponieważ postrzeganie ruchu było złudzeniem, a sytuacja ta była tak niejednoznaczna, że nie było żadnej rzeczywistości fizycznej, na której jednostka mogłaby się oprzeć. Jednakże badania Solomona Ascha wykazały przekonująco, że normy grupowe mogą wpływać w decydujący sposób na oceny jednostek, nawet wtedy, gdy oceniane bodźce są ustrukturalizowane i znane oraz gdy są one dokładnie spostrzegane w sytuacji nie mającej charakteru społecznego. Jak na ironię, jego badania początkowo miały wykazać, że w warunkach, w których rzeczywistość fizyczna jest jasno określona, jednostki będą |niezależne od oddziaływań rzeczywistości społecznej. Zamiast tego badania Ascha stał się klasycznym przykładem zjawiska |konformizmu wobec grupy.


„Grypy złożone z 7 do 9 studentów wyższej uczelni zbierały się, by uczestniczyć w „eksperymencie psychologicznym nad oceną wzrokową”.  Pokazywano im karty i proszono o wskazanie który odcinek na karcie porównawczej był tej samej długości, co odcinek na karcie wzorcowej.


Długość tych odcinków była tak zróżnicowana, że w zwykłych warunkach błędy oceny popełniano w mniej niż 1% przypadków. Jednakże w każdej grupie badanych wszyscy jej członkowie, oprócz jednego, byli pomocnikami eksperymentatora i pouczono ich zawczasu, aby jednogłośnie podawali niepoprawne odpowiedzi w dwunastu spośród osiemnastu prób.
Pod takim naciskiem grupowym osoby badane, będąc w mniejszości, akceptowały, ogólnie biorąc, fałszywe oceny większości w 37% prób. Jednakże liczba ta jest myląca, ponieważ różnice indywidualne były znaczne. Spośród stu dwudziestu trzech rzeczywistych osób badanych około 30% prawie zawsze ulegało, podczas gdy 25% pozostało całkowicie niezależnych.
Wywiady z badanymi przeprowadzone na zakończenie eksperymentu wykazały, że wiele osób spośród tych, które nie uległy opinii większości, miało silne poczucie zaufania do swej własnej oceny - po usłyszeniu odpowiedzi sprzecznych z ich własnymi, potrafiły szybko uwolnić się od wszelkich wątpliwości. Inni niezależni badani sądzili, że prawdopodobnie mylą się, lecz mieli poczucie, że powinni powiedzieć uczciwie o tym, co widzą.  Spośród badanych, którzy ulegli opinii większości, niektórzy sądzili, że ich spostrzeżenia muszą być błędne; inni powiedzieli, że zgodzili się z większością, aby „nie popsuć wyników eksperymentu”. Wszyscy, którzy ulegli, nie doceniali częstości swych konformistycznych reakcji.
Następnie zmieniano nieco plan eksperymentu, aby zbadać jaki wpływ ma wielkość przeciwstawiającej się większości. Wobec jednej osoby podającej niepoprawna ocenę badany przejawiał pewien niepokój; gdy opozycja wzrosła do dwóch osób, wówczas badany ulegał przeciętnie w 13,6% przypadków.  Zjawisko to wystąpiło z niemal pełną siłą, gdy badanemu przeciwstawiła się większość w liczbie trzech osób - częstość błędów wzrosła wówczas do 31,8%.  Gdy liczba przeciwstawiających się przewyższała trzy osoby, to wpływ większości nie wzrastał w sposób istotny. Gdy badanemu dodano zgadzającego się z nim partnera, wówczas wpływ większości uległ znacznemu osłabieniu - częstość błędnych odpowiedzi, jak wykazuje wykres na rycinie 13.11, zmalała do jednej czwartej liczby błędów popełnionych bez takiego partnera, a ponadto wpływ ten utrzymywał się nawet po odejściu partnera” (Asch, 1955).


Ten społeczny wpływ grup na spostrzeżenia i oceny jednostek stwierdzano wielokrotnie w innych eksperymentach nad konformizmem, w których stosowano różne warunki bodźcowe i różnie dobrane grupy osób badanych. Możemy wciągnąć stąd wniosek, że mniej więcej trzecia część nas wszystkich, stając wobec rozbieżności między rzeczywistością taką, jaką sama widzi, a rzeczywistością widzianą przez innych, decyduje się zaprzeczyć własnym wrażeniom zmysłowym.


Siła mniejszości. Biorąc pod uwagę fakt, że większość ma pod swą kontrolą zarówno niezbędne do działania środki, jak i wzmocnienia, nie zaskakuje nas obserwacja, która dotyczy rozmiarów konformizmu istniejącego na wszystkich poziomach naszego społeczeństwa. Naprawdę godne uwagi jest to, w jaki sposób komuś udaje się uniknąć takiego zdominowania przez grupę i w jaki sposób coś nowego - sprzecznego z normami - kiedykolwiek dochodzi do skutku. Jednakże każde społeczeństwo, chociaż w dbałości o swe przetrwanie polega na konformistach, którzy będą bronić norm establishemntu, zwraca się - choć niechętnie - do swych dewiantów po nowe idee i innowacje, które pozwolą mu pójść na przód.




* * *



Ryc. 13.3. Oceny Dokonywane Bez Nacisku Społecznego I Pod Naciskiem Społecznym. Wykres ten pozwala porównać przeciętną liczbę błędów popełnianych w normalnych warunkach i pod naciskiem społecznym - zarówno w obecności partnera udzielającego poparcia, jak i bez niego.


* * *





Czy jednak niewielka mniejszość może zmienić stanowisko większości i ukształtować nowe normy, opierając się jedynie na tych samych podstawowych zasadach psychologicznych, które zwykle umożliwiają ustanowienie poglądu większości?


„Grupa psychologów francuskich stwierdziła, że jeśli dwie pomocniczki eksperymentatora, wchodzące w skład sześcioosobowej grupy studentek stale nazywały niebieskie światło „zielonym”, to prawie trzecia część naiwnych osób badanych poszła w końcu za ich przykładem, wiele zaś osób spośród pozostałych udzielało odpowiedzi „zielone” później, gdy badano je indywidualnie” (Moscovici, Lage i Naffrechoux, 1969; Faucheux i Moscovici, 1967).


Jeśli konsekwentnie postępująca mniejszość może do tego stopnia pozyskać sobie zwolenników, nawet wtedy, gdy nie ma racji, to istnieje duża nadzieja dla mniejszości walczącej o słuszną sprawę.




Wpływ norm społecznych
w świecie realnym




Badania w różnych środowiskach potwierdziły wpływ norm społecznych na postawy i zachowanie jednostek.


Normy uczelniane a normy rodzinne. Jaki wpływ na postawy i wartości studentów wywiera fakt, że są oni członkami społeczności uczelni? Pytanie to jest niewątpliwie interesujące dla każdego studenta, który znajduje się między młotem a kowadłem: chciałby stać się częścią grupy, a zarazem zachować swą niezależność i indywidualność. Pewnych informacji na ten temat dostarczają wyniki badań, które rozpoczęto w 1935 roku w małym żeńskim college’u w Nowej Anglii.


„Bennington College znajduje się w małym miasteczku w stanie Vermont, a w chwili rozpoczęcia tych badań istniał dopiero od czterech lat. Jego program kładł nacisk na zindywidualizowane nauczanie i seminaria w małych grupach.  Społeczność tego college’u była „zintegrowana, samowystarczalna i samoświadoma”. Dominującą normą był polityczny i ekonomiczny liberalizm. Z drugiej strony, większość studentek pochodziła z konserwatywnych rodzin i przyszła na uczelnię z konserwatywnymi postawami. Przedmiotem badań był więc problem, jaki wpływ ta „liberalna atmosfera” będzie mieć na postawy poszczególnych studentek.
Konserwatyzm studentek pierwszego roku malał stale w miarę upływu czasu.  Na ostatnim roku większość studentek „nawróciła” się już na poglądy wyraźnie liberalne. Wydaje się, że było to wynikiem działania dwóch czynników: aprobaty społecznej ze strony wykładowców i starszych studentek dla wyrażanych liberalnych poglądów oraz większej dostępności informacji o charakterze politycznym w społeczności tej uczelni.
W drugiej części badania starano się wykryć, dlaczego niektóre studentki potrafiły się oprzeć tej powszechnej normie i zachowały swe konserwatywne poglądy. Stwierdzono, że studentki te dzieliły się na dwie kategorie.  Niektóre z nich, należące do małej, zamkniętej grupy, po prostu nie zdawały sobie sprawy z konfliktu między ich konserwatyzmem a dominującymi na uczelni postawami. Inne utrzymywały silne więzi ze swymi konserwatywnymi rodzinami i nadal stosowały się do uznawanych przez nie standardów (Newcomb, 1958).
Po upływie dwudziestu lat widoczne jeszcze były ślady doświadczeń z Bennington. Większość kobiet, które opuściły uczelnię z liberalnymi poglądami, pozostały przy nich, te zaś, które oparły się atmosferze uczelni, pozostały konserwatywne. Było to po części skutkiem zaślubienia mężczyzn uznających podobne wartości, co stwarzało sprzyjające ich utrzymaniu środowisko domowe. Jednakże spośród tych dziewcząt, które ukończyły college z liberalnymi poglądami, lecz poślubiły konserwatywnych mężczyzn, duża część powróciła do swego konserwatyzmu z pierwszego roku studiów” (Newcomb, 1963).


Można oczekiwać, że niepodporządkowanie się standardom grupowym pociągnie za sobą pewien stopień społecznego ostracyzmu. Większość ludzi doświadcza więc przykrych uczuć wyobcowania (alienacji). Lecz w ostatecznym rachunku o kierunku przyjętym przez grupę decydują działania jednostek. Stałość jednej osoby w zachowywaniu odmiennego poglądu łatwo można zlekceważyć jako dziwactwo lub też, jak przekonaliśmy się, można jej przyczepić etykietkę „szaleństwa”. Dwie takie osoby zmieniają urojenie w przekonanie, kilka zaś - może je przeobrazić w ruch społeczny. Jednakże psychologowie muszą dopiero wykryć, jakie właściwości pozwalają pojedynczej jednostce wystąpić potakującego tłumu i twierdzić głośno, że król jest nagi.


Moja norma jest lepsza niż twoja. Jeśli cele grupy i cele indywidualne ą zgodne, to rozwija się poczucie grupowej tożsamości, lojalności i współdziałania. Co się jednak dzieje, gdy członkowie jednej takiej grupy zetkną się z członkami innej grupy, co zdarza się często w życiu codziennym? W celu zbadania procesu, dzięki któremu osoby z |własnej |grupy stają się przyjaciółmi, a osoby należące do |obcych |grup stają się wrogami, zorganizowano szczególnego rodzaju obóz letni. 


„Na tym obozie wywołano tarcia między dwoma eksperymentalnie utworzonymi grupami, a później przezwyciężono je dzięki temu, że grupy te pracowały dla osiągnięcia wspólnych celów. Osobami badanymi było dwudziestu dwóch normalnych chłopców w wieku około jedenastu lat, o podobnym pochodzeniu społecznym, których podzielono na dwie grupy, podobne do siebie pod względem takich czynników, jak wzrost i różne zdolności ich członków. Przed przybyciem na obóz chłopcy nie znali się wzajemnie, a przez cały czas jego trwania nie zdawali sobie sprawy, że biorą udział w eksperymencie.
Aby zintegrować chłopców w prawdziwe grupy, eksperymentatorzy ulokowali obie grupy w oddzielnych domkach i przeprowadzali z nimi oddzielnie codzienne zajęcia grupowe. Pod koniec tej części eksperymentu obie grupy miały już określone struktury grupowe, między innymi posiadały swych przywódców, własne nazwy (Grzechotniki i Orły), przezwiska, tajne sygnały, wzory współdziałania w obrębie grupy oraz odrębne znaki rozpoznawcze (flagi i znaki umieszczane na miejscach i urządzeniach określanych jako „nasze”).
Następnie wzbudzono rywalizację między tymi grupami wprowadzając różne formy współzawodnictwa - jak przewidywano, zwiększało to solidarność w obrębie własnej grupy, a także spowodowało wytworzenie się nieprzychylnych stereotypów obcej grupy i jej członków. Demokracja i współdziałanie w obrębie własnej grupy nie obejmowały grupy obcej. Po przegraniu zawodów w przeciąganiu liny, Orły spaliły flagę Grzechotników, Grzechotniki zrewanżowały się, po czym nastąpił szereg napaści na domki przeciwników, czemu towarzyszyło obrzucanie się wyzwiskami, walki na pięści oraz inne przejawy wrogości.


W czasie tego konfliktu miejsce mniej agresywnego chłopca przewodzącego poprzednio grupie Orłów, zajął przywódca odznaczający się odwagą i siłą fizyczną; świadczy to, że stosunki z innymi grupami powodują zmiany w obrębie danej grupy.




* * *



Ryc. 13.12. Na początku eksperymentu w każdej z grup szybko rozwinęła się atmosfera współpracy; na fotografii po lewej widzimy Grzechotniki niosące wspólnie łodzie do jeziora. Po zakończeniu drugiej fazy, w czasie której podsycano współzawodnictwo międzygrupowe i wywiązała się ostra rywalizacja między Orłami a Grzechotnikami, zapoczątkowano ostatnią fazę eksperymentu.  Doprowadzono tu do nawiązania współpracy między grupami, stwarzając sytuacje, z którymi można było uporać się jedynie wspólnymi siłami - takie jak poszukiwanie uszkodzenia zbiornika wody zaopatrującej obozy.


* * *





Następnie podjęto próby przezwyciężenia tej wrogości i nakłonienia obu grup do współdziałania. Najpierw spowodowano, aby rywalizując grupy kontaktowały się ze sobą podczas wykonywania przyjemnych czynności - takich, jak jedzenie czy strzelanie z petard. Jednakże grupy te nie chciały mieszać się ze sobą, a zajęcia te dostarczały im jedynie nowych sposobności do wyrażania wrogości, co wskazuje, że kontakty międzygrupowe same w sobie nie łagodzą istniejących napięć.
Następnie zaaranżowano sytuacje, które pociągały za sobą konieczność współdziałania obu grup dla osiągnięcia nadrzędnych celów - to jest ważnych celów, których nie można było osiągnąć bez połączenia wysiłków obu grup.  Najbardziej uderzającym epizodem w tym okresie było wydarzenie, w którym lina do przeciągania, odgrywająca poprzednio główną rolę w najbardziej antagonistycznej sytuacji, posłużyła jako narzędzie pojednania. Na całonocnej wycieczce ciężarówka, która miała przywieźć im posiłek, „zepsuła się”, a wówczas chłopcy wpadli na pomysł użycia tej liny do ciągnięcia pojazdu. Po zaczepieniu liny o zderzak, dwie grupy ciągnęły za oddzielne końce; lecz następnego dnia, gdy ciężarówka „popsuła sie” znowu, członkowie obu grup pomieszali się w obu rzędach, nie przestrzegając już podziału na grupy.
Kolejnym dowodem zmian w postawach chłopców były wybory socjometryczne przeprowadzone pod koniec okresu intensywnej rywalizacji i ponownie na zakończenie eksperymentu. W grupie Grzechotników liczba przyjaciół wybranych spośród Orłów wzrosła z 6,4% do 36,4% ogólnej liczby wybranych przyjaciół. W grupie Orłów liczba wybranych Grzechotników wzrosła od 7,5% do 23,2%. Chłopców poproszono także, aby oceniali się nawzajem pod względem sześciu cech, co miało ujawnić obecność stereotypowych obrazów. W okresie antagonizmu Orły otrzymały niewiele przychylnych ocen od Grzechotników, podobnie jak Grzechotniki od Orłów; jednakże pod koniec eksperymentu nie było żadnych istotnych różnic w ocenianiu między członkami obcej grupy i własnej” (Sherif i Sherif, 1956).


Badanie to niewątpliwie ma istotne implikacje dla problemu przezwyciężania nieprzyjaźni między narodami i między antagonistycznymi grupami w obrębie jednego społeczeństwa. Dostarcza ono także wartościowych wskazówek przydatnych dla projektowania badań nad tymi niezmiernie ważnymi problemami - jak więc przypuszczasz, dlaczego tym zagadnieniom poświęca się tak mało uwagi?




Wpływ przywódcy




Od stuleci myśliciele zajmujący się analizą zagadnień politycznych i społecznych zastanawiali się nad pytaniem, na czym polegają zdolności przywódcze. Czy wielcy przywódcy rodzą się€ze specjalnymi cechami, które obdarzają ich |charyzmatem, specyficzną zdolnościa oddziaływania emocjonalnego i przyciągania zwolenników? Czy też wielcy przywódcy pojawiają się ze względu na wymagania aktualnej sytuacji, jaka powstaje w danym momencie historii i „wprowadza ich na scenę?” Czy Napoleon byłby wielkim wodzem, gdyby urodził się w 1930 roku w Szwajcarii? Czy Martin Luther King byłby wielkim przywódcą swego ludu, gdyby żył sto pięćdziesiąt lat wcześniej? Tego rodzaju pytania mogą być przedmiotem interesującej dyskusji, lecz mają niewielką wartość naukową, z tym wyjątkiem, że zwracają uwagę na dwa sposoby podejścia do badania zjawiska przywództwa: podejścia podkreślającego znaczenie |cech oraz podejścia |sytuacyjnego.


Czy przywódcy mają w sobie coś, co „porywa” ludzi? W pewnej dokonanej przed wieloma laty analizie „istoty przywództwa politycznego” autor przedstawił kilka interesujących hipotez:


„Trzeba przyznać, że w zwykłej polityce dar publicznego przemawiania ma wartość bardziej rozstrzygającą niż cokolwiek innego. Jeśli jakiś człowiek jest wymowny, zręczny i bystry na trybunie, to posiada jedyną cechę nieodzownie potrzebną mężowi stanu. Jeśli w dodatku ma on dar głębokiego poruszenia emocji słuchaczy, to jego zdolność do kierowania nieskończenie złożonym życiem państwa staje się niezaprzeczalna. Doświadczenie wykazało, że żadnej innej zdolności nie potrzeba posiadać w wyjątkowym stopniu, aby uzyskać sukcesy jako przywódca (...). Mający sukcesy pasterz myśli podobnie jak jego owce i może prowadzić swoją trzodę tylko wtedy, jeśli wyprzedza ją co najwyżej o bardzo niewielki dysonans. Musi on w istocie pozostać rozpoznawalny jako jeden z trzody, niewątpliwie większy, głośniejszy, bardziej szorstki, a przede wszystkim z bardziej rozwiniętymi potrzebami i umiejętnościami ekspresji niż zwykła owca, lecz w gruncie rzeczy muszą one mieć poczucie, że jest on z tej samej gliny, co i one. W trzodzie ludzkiej konieczność przejawiania niewątpliwych oznak tożsamości z grupą jest dla przywódcy równie istotna” (Trotter, 1916).


Późniejsze badania potwierdziły, że przywódcy są zwykle najbardziej aktywnymi werbalnie członkami swych grup. W grupie eksperymentalnej złożonej z obcych sobie osób, każdy jej członek o sztucznie wywołanej wysokiej aktywności werbalnej, może być w istocie spostrzegany jako przywódca, nawet jeśli w innej grupie (gdzie był mniej wymowny) uważano, że ma on małe zdolności przywódcze i niską „atrakcyjność społeczną” (Bavelas i in., 1965).
Wydaje się także, że aby utrzymać swą efektywność, przywódcy muszą podkreślać swą więź z szeregowymi członkami. Upadek przywódców jest często wynikiem utraty przez nich kontaktu z masami, z których się wywodzą oraz zdolności utożsamiania się z tymi, którzy dali im przywództwo.
Najwcześniejsze badania psychologiczne nad przywództwem, zgodnie z ogólną tendencją do koncentrowania się na jednostce, dążyły do zidentyfikowania cech, które występują u wszystkich przywódców. Jeden z badaczy doszedł do wniosku, że cechy najściślej związane z |efektywnym przywództwem można podzielić na pięć ogólnych kategorii (Stogdill, 1948).
a) |zdolność (inteligencja, szybko refleks, zdolności werbalne, oryginalność, zdolność oceny),
b) |osiągnięcia (eurodycja, wiedza, dokonania sportowe),
c) |odpowiedzialność („spolegliwość”, inicjatywa, wytrwałość, agresywność, pewność siebie, pragnienie przewyższania innych),
d) |uczestnictwo (aktywność, towarzyskość, współpraca, umiejętność przystosowania się, humor),
e) |status (pozycja społeczna i ekonomiczna, popularność).

Jednakże próby znalezienia typowego zbioru cech, które charakteryzowałyby przywódców w ogóle, okazały się bezowocne, i trudno się temu dziwić. Czy moglibyśmy oczekiwać tych samych cech u przywódców (lub przywódczyń), powiedzmy, Cór Rewolucji Amerykańskiej, chóru szkółki niedzielnej, grupy towarzyskiej zamieniającej się żonami i związku zawodowego? Wydaje się oczywiste, że efektywny przywódca, aby osiągnąć swe cele, musi posiadać wszelkie cechy, jakie są potrzebne indywidualnym członkom grupy oraz grupie jako całości - i że te użyteczne właściwości będą w każdej sytuacji nieco inne.
Istnieją dowody, że w wielu sytuacjach potrzebny jest więcej niż jeden przywódca. Bales (1970) wyróżnił dwa ogólne typy przywódców:
a) |przywódcy |zadaniowi („task leaders”), którzy są nastawieni na możliwie jak najsprawniejsze wykonanie danej pracy.
b) |przywódcy |społeczno-|emocjonalni („social-emotional leaders”), których punkt widzenia sprzyja stwarzaniu oraz utrzymywaniu dobrego klimatu psychologicznego w danej grupie i którzy są wrażliwi na osobiste potrzeby i problemy oraz niepowtarzalność indywidualnych członków grupy.

Wydaje się oczywiste, że efektywne przywództwo nie jest uzależnione ani od samych tylko cech osobowości, ani od samych czynników sytuacyjnych, lecz od optymalnej kombinacji osobowości przywódcy i wymagań sytuacyjnych. Jeden z badaczy stwierdził, że przywódcy, u których występowało silne nastawienie |zadaniowe, byli najbardziej efektywni tam, gdzie były a) dobre stosunki między przywódcą a członkami grupy i albo wysoce ustrukturalizowane zadanie, albo silna pozycja przywódcy, albo jedno i drugie lub też, na przeciwnym biegunie; b) złe stosunki między przywódcą a członkami grupy, niski stopień ustrukturalizowania zadania oraz słaba władza przywódcy.  Przywódcy, którzy w wysokim stopniu byli nastawieni na |stosunki |międzyludzkie, najbardziej efektywni byli w sytuacjach, w których były albo a) dobre stosunki między przywódcą a członkami grupy oraz nieustrukturalizowane zadanie i słaba władza przywódcy lub też b) złe stosunki między przywódcą a członkami grupy przy wysoce ustrukturalizowanym zadaniu i silniej władzy przywódcy (Fiedler, 1964, 1967).
W badaniach nad przywództwem rozwinął się ostatnio kierunku, w którym zwraca się uwagę na rolę przywódcy raczej jako osoby „określającej rzeczywistości” („definer of reality”) niż jako nadzorcy wydajności. Edwin Hollander, ze State University York (Buffalo), kładzie w swych nowych badaniach szczególny nacisk na następujące zagadnienia: w jaki sposób przywódcy uzyskują i podtrzymują swój status, w jaki sposób wpływają oni na sposób spostrzegania ich przez zwolenników i jak z kolei ten sposób spostrzegania przywódcy przez zwolenników wiąże się z ich lojalnością wobec grupy, identyfikowaniem się z nią oraz poczuciem równości i zaufania. Te zorientowane na analizę procesu badania zajmują się także zagadnieniem o aktualnym znaczeniu politycznym: w jaki sposób wybierani przywódcy przezwyciężają to, co zagraża ich autorytetowi (Hollander , 1972; 
Hollander i Julian, 1969).


Czy różne |style” przywództwa przynoszą różne efekty?
Odkładając na bok problemy wykrywania cech osobowości, które „tworzą” przywódców, pewien zespół psychologów społecznych wysunął pytanie, czy rozmaite style charakteryzujące sposób odnoszenia się przywódców do kierowanych przez nich grup powodują zróżnicowane zachowanie tych grup. W roku 1939, w czasie gdy rozpoczęto te badania, przykład autokratycznej władzy Hitlera w Niemczech przerażał ludzi, którzy byli przekonani, że przywództwo demokratyczne jest nie tylko bardziej pożądane, lecz także bardziej efektywne. Niektórzy wysuwali nawet tezę, że najlepszymi przywódcami są ci, którzy przyjmują „niedyrektywne” podejście, służąc pomocą tylko wtedy, gdy zażąda się od nich tego i pozwalając sprawom iść swoim torem - tak zwany |styl |przyzwalający (|styl |laissez-|faire). Ten złożony problem badano przy zastosowaniu kontrolowanego eksperymentu, przeprowadzonego z grupami dziesięcioletnich chłopców.


„Eksperyment objął cztery pięcioosobowe grupy dziesięcioletnich chłopców, którzy spotykali się po szkole, aby uprawiać różne hobby. Grupy te zostały z grubsza zrównane pod względem relacji interpersonalnych, cech osobowości, poziomu rozwoju intelektualnego i fizycznego oraz pozycji społeczno-ekonomicznej. Czterech dorosłych mężczyzn wyszkolono tak, że osiągneli biegłość w stosowaniu każdego z trzech stylów kierowania i kolejno występowali w każdej roli. Przywódca autokratyczny miał: a) ustalać sposób postępowania we wszystkich sprawach dotyczących grupy, b) dyktować techniki i kolejne etapy czynności, c) wyznaczać zadania i współpracowników każdemu członkowi grupy oraz d) kierować się osobistymi sympatiami i antypatiami przy udzielaniu pochwał i krytykowaniu każdego z członków grupy, równocześnie trzymając się wyniośle na uboczu, z wyjątkiem demonstrowania technik pracy. Przywódca demokratyczny miał: a) zachęcać do grupowego podejmowania decyzji we wszystkich sprawach i pomagać w tym, b) wskazywać ogólne etapy realizacji celu i popierać formułowanie ogólnych planów, c) pozostawiać do uznania grupy podział pracy i dobór współpracowników oraz d) być obiektywnym w chwaleniu i krytyce oraz uczestniczyć w czynnościach grupowych nie angażując się zbytnio w pracę. I wreszcie przywódca pozwalający miał: a) pozostawić grupie całkowitą swobodę, przy minimalnym uczestnictwie przywódcy, dostarczając tylko potrzebnych materiałów i informacji, b) nie brać udziału w dyskusjach roboczych oraz c) rzadko czynić jakieś uwagi, nie starając się oceniać ani regulować biegu zdarzeń, o ile nie zostanie bezpośrednio zapytany czy poproszony o to.
Po zakończeniu każdego sześciotygodniowego okresu każdego przywódcę przenoszono do innej grupy, przy czym jednocześnie zmieniał on także swój styl przywództwa. W ten sposób wszystkie grupy miały do czynienia z każdym stylem, w wykonaniu innej osoby. Wszystkie grupy spotykały się w tym samym miejscu i wykonywały te same czynności przy użyciu podobnych materiałów. W czasie każdego spotkania obserwowano zachowanie przywódców oraz reakcje chłopców.
Z eksperymentu tego wyciągnięto następujące ogólne wnioski (Lewin, Lippitt i White, 1939):
1. Styl przyzwalający nie jest identyczny ze stylem demokratycznym. Grupy kierowane w sposób przyzwalający wykonywały mniej pracy i praca ta była gorszej jakości.
2. Demokracja może być efektywna. Aczkolwiek ilość pracy wykonywanej w grupach kierowanych autokratycznie była nieco wyższa, to jednak motywacja do pracy i zainteresowanie nią było większe w grupach kierowanych demokratycznie. Gdy przywódca wychodził z pomieszczenia, wówczas grupy kierowane demokratycznie na ogół pracowały nadal, podczas gdy grupy kierowane autokratycznie przerywały pracę. Oryginalność była większa w warunkach demokracji.
3. Autokracja może wytworzyć dużą wrogość i agresywność, łącznie z agresją przeciw „kozłom ofiarnym”. Grupy kierowane autokratycznie wykazywały aż trzydziestokrotnie większą wrogość, bardziej domagały się uwagi, częściej niszczyły swą własność i szukały „kozłów ofiarnych”.
4. Autokracja często wytwarza niezadowolenie, które na pozór może się nie ujawniać. Czterej chłopcy przestali uczęszczać na zajęcia - wszyscy podczas okresów przywództwa autokratycznego (w czasie którego nie doszło do otwartego buntu). 19 spośród 20 chłopców wolało swego demokratycznego przywódcę, a więcej oznak niezadowolenia przejawiali w okresie autokracji niż demokracji. Zachowanie w postaci „wyładowania się” (takie jak niezwykle agresywne działania grupowe) w dniu zmiany stylu kierowania grupą na bardziej swobodny, wskazuje na uprzednią frustrację.
5. Autokracja sprzyja zależności i mniejszej indywidualności. W grupach kierowanych autokratycznie było więcej uległego czy zależnego zachowania, rozmowy zaś były mniej urozmaicone, bardziej ograniczone do aktualnej sytuacji.
6. Demokracja bardziej przyczynia się do kształtowania „ducha zespołowego” i przyjaźni. W grupach kierowanych demokratycznie zaimek „ja” był stosowany rzadziej, samorzutnie tworzące się podgrupy były większe, częściej występowały wzajemne pochwały, przyjazne uwagi i żartobliwa atmosfera, gotowość zaś do wspólnego dzielenia się własnością grupy była większa”.



Było to pionierskie badanie z dziedziny „dynamiki grup”. Wykazało ono, że interakcje w grupie i zmienne dotyczące grupy można badać eksperymentalnie - uzyskując wnioski dotyczące przyczyn występujących zjawisk. Badania te wykazały, że ta sama osoba, niezależnie od jej „cech”, ma istotny wpływ na grupę, gdy stosuje taki a nie inny styl przywództwa. Było tak nawet wtedy, gdy stosowane „style” zostały podyktowane przez wymagania natury sytuacyjnej, a nie przez ideologię polityczną i ekonomiczną, jak częściej bywa w życiu realnym.




Uprzedzenia i rasizm




Przekonaliśmy się, że uczestnictwo w grupie daje nam poczucie bezpieczeństwa, pozycję, podstawę do badania rzeczywistości oraz wiele innych rzeczy, których potrzebujemy zarówno do przetrwania, jak i dla pełnego rozwoju ludzkiego ducha. Jednakże zidentyfikowanie nas jako członków pewnej grupy może takie przynieść nam brak poczucia bezpieczeństwa, utratę szacunku do samego siebie oraz niepewną egzystencję - jeśli inni, mający władzę ludzie zdecydowali się określić naszą grupę jako „gorszą”. Następstwa uprzedzenia przyjmują liczne formy, lecz wspólny dla nich wszystkich jest mniej ludzki sposób reagowania na innych ludzi i zmiana kierunku wydatkowania energii psychicznej - od twórczości ku destrukcji.
|Uprzedzenie można zidentyfikować jako zespół wyuczonych przekonań, wartości i postaw danej osoby wobec innych, który: a) jest ukształtowany na podstawie niekompletnej informacji, b) jest względnie niewrażliwy na niezgodne z nim informacje, c) w kategoryczny sposób przypisuje jednostki do pewnych klas lub grup, które (zwykle) są oceniane negatywnie.  |Uprzedzenie jest to zatem stan wewnętrzny czy gotowość psychiczna danej jednostki do reagowania w tendencyjny sposób na członków pewnych grup; 
|dyskryminacja jest to zachowanie (zachowania), do którego może również prowadzić uprzedzenie. Wcześniej lub później prawdopodobnie my wszyscy będziemy lub byliśmy obiektami uprzedzenia, jak również źródłem uprzedzeń wobec innych.
Weźmy pod uwagę nie tylko najwięcej dyskutowane uprzedzenia wobec członków innych grup klasowych, religijnych i etnicznych, lecz także uprzedzenia wobec „reakcjonistów”, „biurokratów”, „establishmentu”, „komunistów”, „radykałów”, „hipisów” oraz „dziwaków”, jak również wobec starszych ze strony młodzieży i na odwrót.




Zbliżenie


Przed murem korporacji


„O trwałości uprzedzeń przeciw członkom obcych grup świadczą wyniki niedawnej ankiety, mającej określić, ilu obywateli amerykańskich różnego pochodzenia etnicznego jest zatrudnionych na stanowiskach kierowniczych w 106 największych korporacjach (towarzystwach przemysłowych bądź handlowych) w Chicago. Amerykanie pochodzący z Ameryki Łacińskiej oraz Amerykanie polskiego pochodzenia reprezentowali mniej niż 1% kierowników, chociaż stanowią oni odpowiednio 4,4% i 6,9% całej populacji. Murzyni amerykańscy wypadli gorzej: 0,1% wśród kierowników, w porównaniu z 17,6% wśród ogółu ludności Chicago (Barta, 1974). Jeśli pracodawcy nie mogą znaleźć wykwalifikowanych kandydatów z tych grup, jak często mówią, to jakie mogą być tego przyczyny?”


Kształtowanie się uprzedzenia - i jego skutki. Jednego z najbardziej wyrazistych przykładów łatwości kształtowania uprzedzonych postaw oraz ich arbitralności i nielogiczności dostarczył eksperyment przeprowadzony w trzeciej klasie szkoły podstawowej w Riceville w stanie lowa. Nauczycielka tej klasy, Jane Elliott, chciała dostarczyć swym uczniom, pochodzącym z tej wiejskiej społeczności zamieszkałej wyłącznie przez białych, doświadczeń z zakresu uprzedzeń i dyskryminacji, aby wyciągnęły z nich wnioski dotyczące ich zwodniczej atrakcyjności i niszczycielskich konsekwencji. Aby tego dokonać, opracowała ona godny największej uwagi eksperyment, bardziej przekonywujący niż jakikolwiek inny przeprowadzony przez zawodowych psychologów.


„Pewnego dnia, bez ostrzeżenia, niebieskooka pani Elliott oznajmiła swej klasie złożonej z dziewięciolatków, że ludzie mający brązowe oczy są bardziej inteligentni i lepsi niż ludzie o niebieskich oczach. Dzieciom niebieskookim, chociaż stanowiły one większość, powiedziano po prostu, że są one gorsze i że dlatego dzieci o brązowych oczach powinny być „klasą rządzącą”.
„Zaczęliśmy naszą dyskryminację od sformułowania wytycznych, których nasza „gorsza”” grupa miała przestrzegać, tak aby znała ona swoje miejsce w naszym nowym porządku społecznym. Dzieci te zostały pouczone, że mają siedzieć na końcu sali, zajmować ostatnie miejsca w kolejkach do obiadu i do wyjścia na przerwę, pozwalać dzieciom o brązowych oczach wybierać najpierw miejsce w klasie przeznaczonej do nauki czytania, używać tylko kranu i papierowych kubków przy otrzymywaniu napojów (zamiast saturatora, który był zarezerwowany dla brązowookich), a w dodatku wydano jeszcze wiele innych frustrujących i poniżających przepisów. Dzieci te pouczono także, że „lepsi”” uczniowie, z tego tylko powodu, że są „lepsi””, będą mieć pewne przywileje, które nie będą dostępne dla uczniów „gorszych”” (takie, jak dodatkowy czas wolny za dobrze wykonaną pracę)”.
W ciągu niewielu minut niebieskookie dzieci zaczęły wykonywać gorzej swoje zadania na lekcjach i stały się przygnębione, ponure i rozdrażnione.  Gdy dano im do wykonania test ortograficzny i polecono wybierać wyrazy, które najlepiej do nich pasowały, to najczęściej określały siebie następującymi słowami: „smutny”, „zły”, „głupi”, „tępy”, „okropny”, „trudny”, „przeciętny”. Pewien chłopiec powiedział, że czuje się jak „jarzyna”. O brązowookich „lepszych” uczniach nauczycielka napisała: „Te poprzednio wspaniałe, współdziałające, myślące dzieci stały się paskudnymi, złymi, dyskryminującymi, małymi trzecioklasistami... To było straszne”.
Aby wykazać, jak arbitralne i irracjonalne jest w rzeczywistości uprzedzenie i próby jego racjonalizacji, następnego dnia nauczycielka powiedziała klasie, że pomyliła się i że w rzeczywistości to niebieskookie dzieci są „lepsze”, a brązowookie „gorsze”. Brązowookie dzieci zmieniły teraz swe poprzednie samookreślenia: „szczęśliwy”, „dobry”, „delikatny”, „miły”, na określenia negatywne, podobne do stosowanych poprzedniego dnia przez dzieci niebieskookie. Poziom ich funkcjonowania szkolnego obniżył się, podczas gdy w nowej „klasie rządzącej” podniósł się. Stare więzi przyjaźni między dziećmi zostały zerwane i zastąpione wrogością”.
Na zamieszczonej obok fotografii widoczna jest ulga i radość tych dzieci, gdy w końcu wyprowadzono je z błędu i wyjaśniono, że żadne z nich nie są „gorsze” od innych. Miejmy nadzieję, że nauczyły się one współczuć ofiarom uprzedzeń, z którymi mogą zetknąć się w przyszłości” (Elliot, 1970).




* * *



Ryc. 13.13. Oprócz obserwowania zmian zachodzących w obu fazach eksperymentu w zewnętrznym zachowaniu dzieci wobec siebie nawzajem oraz w ich pracy szkolnej, Jane Elliot rejestrowała ich uczucia w każdej z faz, polecając im rysować obrazki przedstawiające, jak się czują. Poniżej zamieszczono reprodukcje dwóch takich rysunków. Gdy dzieci były „u szczytu”, wówczas czuły się kompetentne, zdolne i triumfujące, miały poczucie władzy i wyższości. Gdy były „na dnie”, wówczas czuły się małe, smutne i przytłoczone, najwyraźniej akceptując narzucony im przez dyskryminujące je otoczenie obraz samych siebie, jako jednostek gorszych od innych i bezwartościowych.


* * *






Realność napięcia emocjonalnego, jakiemu podlegały te dzieci w czasie trwania krótkiego, dwudniowego zaledwie eksperymentu, znalazła również swój wyraz w gwałtownym wybuchu radości, gdy na koniec stłoczyły się wokół nauczycielki jako zjednoczona, szczęśliwa grupa, w której każdy może akceptować wszystkich innych i być przez nich akceptowany.


Eksperyment ten został powtórzony z innymi klasami i nawet z jedną grupą dorosłych biznesmenów - z tymi samymi rezultatami. W każdym przypadku objęcie władzy przez jedną grupę nad inną, na zasadzie domniemanej wyższości, doprowadziło do dyskryminacyjnego zachowania, zaburzeń w strukturze społecznej, obniżenia samooceny, zmian w poziomie wykonania u „gorszych” członków grupy (stosownie do przypisywanego im statusu) oraz do uzasadniania przez „lepszych” tej formy dyskryminacji, która była usankcjonowana przez „system” (zapoznaj się z opracowaniem J. Elliott zamieszczonym na końcu tego rozdziału). Łatwość i szybkość z jaką mogą być przyjmowane tego rodzaju formy zachowania, szkody psychiczne, które mogą one wyrządzić (zarówno ofierze, jak i krzywdzicielowi), długotrwałe koszty dla społeczeństwa oraz ich trwałość sprawiają, że uprzedzenie jest formą patologii nie mniej poważną niż najbardziej zdezintegrowane formy zachowania psychotycznego.
Problem, polegający na posiadaniu ciemnej skóry w społeczeństwie, które ceni jasny kolor skóry, staje przed dziećmi murzyńskimi zanim jeszcze ukończą trzy lata (Landreth i Johnson, 1953). Przed niedawnym pojawieniem się normy „czarne jest piękne” („black is beautiful”), być brązowym lub czarnym oznaczało - zgodnie ze standardami białej Ameryki - być brudnym, nieczystym i w ogóle złym (ryc. 13.14).


„W pewnym badaniu, które objęło 253 dzieci murzyńskich w wieku od 3 do 7 lat, zarówno ze szkół Północy, jak i Południa, dzieci te, mając dokonać wyboru spośród dwóch białych lalek i dwóch czarnych, faworyzowały białą lalkę. Około 60% tych dzieci spostrzegało białą lalkę jako „ładną” i chciało się nią bawić, a czarna lalka wyglądał ich zdaniem „brzydko”.  Trzecia część tych dzieci w wieku do lat sześciu wybierała białą lalkę, gdy poproszono je, aby wybrały „tę lalkę, która wygląda podobnie do ciebie”.




* * *



Ryc. 13.14. Na powyższych rysunkach wykonanych przez sześcioletnią czarną dziewczynkę imieniem Ruby, można zaobserwować, jak dominująca ideologia uprzedzeń może zostać zinternalizowana przez dzieci, które są jej ofiarami.  Obrazki te Ruby narysowała w pierwszym roku swej wspólnej nauki z białymi dziećmi w zintegrowanej szkole na Południu Stanów Zjednoczonych.
Białe dzieci na tych rysunkach zostały przedstawione jako wyższe i silniejsze; uśmiechają się, ich ciała są kompletne i mają więcej wyraźnie zaznaczonych szczegółów. Natomiast dzieci murzyńskie nie okazują na rysunkach emocji; są asymetryczne, brak im poszczególnych części ciała; są znacznie mniejsze i rysowane z mniejszą dbałością o szczegóły (Coles, 1970).


* * *





Nawet wśród dzieci o najciemniejszej skórze piąta część wybrała białą lalkę jako najbardziej do nich podobną (Clark i Clark, 1958).
W teście niedokończonych opowiadań zarówno czarne jak i białe dzieci (w wieku od 3 do 6 lat) skłonne były przydzielać postaciom Murzynów negatywne role, na przykład, „złego faceta” lub „napastnika” (Stevenson i Stevart, 1966). Dzieci murzyńskie, zarówno na Północy, jak i na Południu, wybierały mniej dzieci należących do ich własnej rasy a więcej białych, jako towarzyszy zabaw, do których chciały być podobne lub z którymi chciałyby się bawić (Morland, 1966).


Tego rodzaju wnioski nie ograniczają się do dzieci murzyńskich.  Intensywne badania nad młodzieżą meksykańsko-amerykańską również dowiodły, że spostrzegają oni swój status jako ludzi „zapomnianych”, „niedostrzeganych”, z „gorszej dzielnicy” (Heller, 1966; Rubel, 1966).
Jedno z długotrwałych następstw „wczesnego treningu” w akceptowaniu swej niższości zademonstrowano w eksperymentach, w których studenci murzyńscy pracowali w zespołach złożonych z przedstawicieli dwóch ras.


„Studenci murzyńscy, którzy wykazali swe zdolności intelektualne w standardowych, względnie obiektywnych testach, z testami selekcyjnymi do college’ów włącznie, i zostali przyjęci do najlepszych uczelni, podporządkowywali się jednak ocenom białych studentów, gry pracowali razem z nimi w zespołach „dwurasowych”. Rozwiązania zadań, przedstawione przez białego członka czteroosobowej grupy, częściej zostawały wysłuchane i zaakceptowane, niż rozwiązania zaproponowane przez jednego z czarnych członków grupy” (Katz, 1970).


Gdy raz przyjmiesz deprecjonujący stereotyp jako trafny wskaźnik |twej bezwartościowości, wówczas możesz chcieć odłączyć się od pogardzanej grupy - zmieniając nazwisko, kształt nosa, prostując włosy lub wprowadzając inne zmiany w swoim wyglądzie zewnętrznym, jak również zmieniając przyjaciół i może nawet zrywając ze swą rodziną. Tego rodzaju reakcja jest jednym z najbardziej podstępnych i złowrogich skutków uprzedzeń, ponieważ zwraca ona daną jednostkę nie tylko przeciw jej własnej grupie, lecz także przeciw samej sobie.




Zbliżenie


Identyfikacja z agresorem


„Termin |identyfikacja |z |agresorem został utworzony przez Annę Freud dla określenia procesu, który jakoby ma miejsce, gdy chłopiec kochający swego ojca, lecz obawiający się z jego strony kastracji w wyniku rywalizacji o matkę, rozwiązuje ten konflikt identyfikując się z ojcem.  Proces ten nie tylko redukuje spostrzegane różnice między nim samym a jego potężnym ojcem, lecz ponadto, dzięki magicznemu myśleniu, możesz pozwolić mu dojść do przekonania, że dysponuje mocą silniejszego, domniemanego agresora. Potwierdzenia dla tego kierunku rozumowania dostarczają wyniki badań międzykulturowych - społeczeństwa, w których rozwijają się bardzo ścisłe więzi między matką a dzieckiem, mają na ogół surowe obrzędy inicjacyjne dla chłopców w wieku dojrzewania (Whiting, Kluckhon, i Anthony, 1958). Takie obrzędy istotnie skutecznie przełamują zależność chłopca od matki i sprawiają, że identyfikuje się on z rolą mężczyzny w swym społeczeństwie i akceptuje ją - aczkolwiek istnieją też odmienne hipotezy wyjaśniające, dlaczego ukształtowały się takie obrzędy.
W pewnych jednak warunkach identyfikacja z agresorem pociąga za sobą wymuszone „rozdarcie” własnego ja oraz wyalienowanie komponentów osobowości: Bruno Bettelheim opisał obrazowo, w jaki sposób wśród niemieckich więźniów obozów koncentracyjnych wytwarzała się identyfikacja z hitlerowskimi strażnikami obozowymi. Przeprowadzona przez niego analiza pokazuje, w jaki sposób warunki, które czyniły człowieka bezradnym i zależnym od strażników - zarówno jeśli chodzi o utrzymanie się przy życiu, jak i o wszelkiego rodzaju wzmocnienia - wywoływały skrajne, podobne do dziecięcych, formy identyfikacji z nimi.
Starzy więźniowie osiągali ostatnie stadium przystosowania do tej niezwykłej sytuacji, w którym zaczynali oni praktykować te same formy słownej i fizycznej agresji wobec innych więźniów, co ich strażnicy.  Pomagali pozbywać się „nieprzystosowanych”, a kiedy wykryli „zdrajców”, mogli torturować ich całymi dniami, a następnie zabijali ich. Starali się oni nawet wyglądać podobnie do hitlerowców i internalizowali ich wartości (1943, 1958).
W przeprowadzonych w Stanford badaniach nad symulowanym więzieniem podobna identyfikacja ze strażnikami uwidacznia się w tym, że 80% wypowiedzi więźniów o sobie nawzajem było ujemnych i obelżywych”.


Rasizm: uprzedzenie poparte władzą. Przez całe dziesięciolecia psychologowie badali wyznaczniki, funkcje i skutki uprzedzeń występujących u poszczególnych jednostek. Psychologowie o orientacji społecznej próbowali opracowywać programy zmierzające do zmodyfikowania uprzedzeń sfanatyzowanych jednostek. Ta koncentracja psychologii na jednostce doprowadziła do ignorowania szerszego kontekstu politycznego, społecznego i ekonomicznego, w którym indywidualne uprzedzenia są pielęgnowane i podtrzymywane.
Różnica między |uprzedzeniem a |rasizmem (szeroko zdefiniowanym) jest różnicą między jednostkami a systemami, między molekularnym a molarnym poziomem analizy, między preferencjami indywidualnymi a władzą sprawowaną przez grupy w taki sposób, jaki uważają one za niezbędny dla swego przetrwania. Podczas gdy uprzedzenie jest charakterystyczne dla poglądów i działań jednostek, to rasizm jest przekazywany z pokolenia na pokolenie przez prawa i ustawy, normy grupowe i zwyczaje. Jest on upowszechniany przez dzienniki, podręczniki szkolne i inne środki masowego przekazu.  Dominująca w danej kulturze ideologia rasistowska nieustannie dostarcza „informacyjnego” i społecznego poparcia dla dyskryminacji, wbrew osobistemu doświadczeniu, które dowodzie jej niesłuszności i niesprawiedliwości. Idee takie stają się niekwestionowanymi założeniami, które uważa się nie za tendencyjne opinie czy wypaczone wartości, lecz za oczywiste prawdy. Są one głównym czynnikiem wpływającym na związane z rasą różnice pod względem jakości zatrudnienia, wskaźnika bezrobocia oraz niezadowalających warunków mieszkaniowych, jak również warunków związanych z nauką, opieką zdrowotną i wyżywieniem. Przyczyniają się one także do zbrodni i przemocy, w innych zaś kulturach i w innych czasach prowadziły do „świętych wojen”.
Pod sztandarem „obowiązku białego człowieka” kolonialiści mogli eksploatować zasoby czarnej Afryki - Indianie zaś mogli zostać pozbawieni ziemi, wolności i środowiska ekologicznego w Stanach Zjednoczonych przez nowo przybyłych z Europy imigrantów, których pragnienia bogactwa, posiadania gospodarstw rolnych i nowych obszarów ziemi pozostawały w konflikcie z „zagrożeniem ze strony czerwonych dzikusów”.
„Żółte niebezpieczeństwo” było inną dziennikarską fikcją mającą nastawić ludzi przeciw Amerykanom pochodzenia orientalnego. Gdy przestali oni już być użyteczni jako robotnicy na kolejach, w kopalniach i przy innych pracach fizycznych, wówczas prasa i organizacje związkowe zorganizowały kampanię zmierzającą do deportowania Chińczyków, pozbawienia zarówno ich jak i japońskich imigrantów praw i przywilejów związanych z obywatelstwem amerykańskim. Czy wiesz, że ponad 100000 Amerykanów japońskiego pochodzenia na początku drugiej wojny światowej umieszczono w obozach koncentracyjnych (znajdujących się w zachodnich stanach), że wywłaszczono ich z majątku za niewielkim odszkodowaniem, a miliony dolarów będące ich własnością, zostały przejęte przez rząd i obracano w nimi w bankach aż do 1973 roku (bez żadnych procentów)? Żadnych podobnych kroków nie przedsięwzięto przeciw Amerykanom pochodzenia niemieckiego czy włoskiego - chociaż Niemcy i Włosi też byli wrogami Stanów Zjednoczonych w czasie tej samej wojny.
Gdy jakaś grupa staje się obiektem uprzedzeń i dyskryminacji, wówczas zostaje ona odizolowana społecznie, przeszkadza się jej w normalnych kontaktach i likwiduje lub blokuje kanały przekazywania informacji. Ta izolacja z kolei sprawia, że plotki i stereotypy pozostają nie sprawdzone i skorygowane, fantastyczne wyobrażenia pojawiają się i rozwijają, a „obecność” danej grupy, prawdziwa i urojona, z czasem wzrasta. Odizolowanie Indian amerykańskich w rezerwatach i segregacja w obrębie dzielnic mieszkaniowych w miastach amerykańskich wzmaga obcość między grupami i uniemożliwia zarówno sprawdzanie rzeczywistości, jak i zdawkowe interakcje.


Odmienność izolowanej grupy może być nie tyle |przyczyną dyskryminacji i segregacji, ile ich |wynikiem.


„W Japonii, od czasów średniowiecznych, istnieje systematyczna segregacja - oparte na micie niższości biologicznej dyskryminowanie kasty pariasów znanej jako Burakumin. Ponieważ nie są oni rasowo różni od Japończyków, ani też nie różnią się od nich w dostrzegalny sposób, przeto można ich zidentyfikować z pewnością jedynie na podstawie miejsca urodzenia i zamieszkania. Jednakże przez całe lata byli oni odizolowani jako „niedotykalni”, żyli stłoczeni w brudnych ruderach w gettach i podlegali licznym ograniczeniom - określono z kim wolno im się żenić, jaką pracę mogą wykonywać (tylko prace fizyczne) i jakie wykształcenie mogą uzyskać.
Utrzymywana przez całe pokolenia segregacja i niski status społeczny wytworzyły uchwytne różnice: na przykład formy językowe, jakimi się posługują, stały się odmienne niż u reszty Japończyków i obecnie mogą służyć do ich rozpoznawania, podobnie jak w Londynie język niższych klas („cockney”). Bez względu na ich zdolności, posiadane przez nich dokumenty (określające ich zawód i miejsce zamieszkania) oraz język, jakim się posługują, zapobiegają ich ucieczce do innych regionów kraju. Nic więc dziwnego, że wśród chłopców mieszkających w gettach Buraku występuje duża przestępczość i bezrobocie, notuje się tam wyższą absencję szkolną i wyższy wskaźnik odsiewu w szkołach oraz niższe wyniki w testach inteligencji.  Fakty te uważa się za oznaki „wrodzonej niższości klasowej” i wykorzystuje się je do uzasadnienia konieczności dalszej dyskryminacji (De Vos i Wagatsuma, 1966).


„W końcu każdy mający sukcesy nauczyciel powie ci, że możesz nauczyć tylko tych rzeczy, którymi sam żyjesz. Jeśli praktykujemy rasizm, to rasizm jest tym, czego uczymy”.
Max Lerner „Actions and Passions”, 1949


Czy można przezwyciężyć uprzedzenia i rasizm? Raz wytworzone uprzedzenia i rasizm są stosunkowo odporne na wygaszanie, ponieważ mogą one zaspokajać różne potrzeby jednostek i grupy oraz istnieje wiele okoliczności, które mogą sprzyjać uprzedzeniom i podtrzymywać je. Dysponujemy kilkoma sposobami przezwyciężania tego rodzaju postaw, lecz jak dotąd okazały się one niestety niewystarczające dla rozwiązania tego poważnego problemu społecznego.
1. Zmiana sposobu działania. Na podstawie naszej wiedzy o zmianie innego rodzaju postaw możemy przewidywać, że nasze wysiłki mogłyby być bardziej skuteczne, gdybyśmy skłonili ludzi do postępowania w nowy sposób, zamiast podawać im argumenty przemawiające za takim postępowaniem. Badania wykazały, że kontakt między antagonistycznymi grupami może przyczynić się do lepszych stosunków międzygrupowych i zmniejszyć istniejącą między nimi wrogość wtedy - i tylko wtedy - jeśli sprzyja temu wiele innych czynników; samo zetknięcie ze sobą takich grup nie pomaga i raczej nasila istniejące wcześniej postawy. Wystąpienie pozytywnych zmian w wyniku wzajemnych kontaktów jest najbardziej prawdopodobne, gdy kontakt ten jest nagradzający a nie frustrujący, gdy występuje wspólna korzyść lub cel i gdy uczestnicy uważają ten kontakt za wynik ich własnego wyboru.





Zbliżenie


Twardogłowi nie śmieją się z Archiega Bunkera


„Popularny w USA program „All in the Family” (Wszystko w rodzinie) wzbudził znaczne kontrowersje ponieważ jego bohater jest przedstawiony jako zupełny fanatyk. Archie Bunker nie przebiera w swej dyskryminacji: okazuje on otwartą pogardę dla wszystkich różnych od niego ludzi - różnych pod względem rasy, wiary, płci, kraju pochodzenia czy przekonań politycznych.  Niektórzy krytycy argumentują, że program ten propaguje uprzedzenia pokazując je i sankcjonując posługiwanie się stereotypami. Zwolennicy programu podkreślali, że wywiera on pozytywny wpływ „przewietrzając” publicznie uprzedzenia i wyśmiewając skrajności, do których prowadzi sposób myślenia Archie’ego. Jak sądzisz, który z tych poglądów jest prawdopodobnie zgodny z rzeczywistością?
Niedawno przeprowadzona ankieta zdaje się świadczyć, że krytycy maja więcej racji. Ankieta ta, która objęła 237 amerykańskich nastolatków ze Środkowego Zachodu oraz 130 dorosłych z miejscowości London w stanie Ontario, badała reakcje respondentów na ten program w ogóle oraz ich stosunek do Archie’go i jego liberalnie myślącego pasierba Mike’a. Badacze Neil Vidmar oraz Milton Rokeach (1974) doszli do wniosku, że program ten „raczej wzmacnia uprzedzenia i rasizm, niż zwalcza je”.
Wielu widzów nie dostrzegło w nim nawet żadnej satyry na fanatyzm.  Zamiast tego zgadzali się oni z obraźliwymi uwagami Archie’go dotyczącego ludzi o odmiennym pochodzeniu etnicznym. Ci, którzy regularnie oglądali ten program, w porównaniu z rzadko go oglądającymi, byli bardziej uprzedzeni, wykazywali większą tolerancję dla poglądów Archie’go, bardziej podziwiali Archie’go niż Mike’a oraz uważali, że w końcu Archie odniósł triumf”.


2. Zmiana reguł i wzmocnień. Aczkolwiek „prawości nie można narzucić przez wydawanie praw”, to jednak nowe prawo czy zarządzenie, do którego ludzie na ogół się stosują, dostarcza nowego systemu nagród i kar i w ten sposób może ukształtować nowa normę społeczną, która następnie wywiera potężny wpływ na jednostki, skłaniając je do przystosowywania się do tego nowego wzorca. Ustawodastwo pozwala więc zwalczać zarówno grupowe zjawisko zinstytucjonalizowanego rasizmu, jak również uprzedzenia jednostek. Te same rezultaty można osiągnąć za pomocą bardziej nieformalnych uzgodnień zmierzających do zmiany „zasad podstawowych” („ground rules”).

Trudność polega oczywiście na tym, że tymi, którzy muszą uchwalać nowe prawa, są często właśnie ci, którzy uważają nielubianą grupę za społeczne lub ekonomiczne zagrożenie; tak więc motywacja do wprowadzenia istotnych zmian jest słaba i postęp śmiertelnie powolny. Jest ważne, aby walczący o zmianę zdawali sobie sprawę, że grupy, które czują się zagrożone przez tę zmianę, muszą mieć poczucie, iż ich istotne potrzeby są brane pod uwagę, jeśli grupy te mają poprzeć - a co dopiero ustanowić - nową zasadę społeczną czy prawo.
3. Zmiana sposobu, w jaki spostrzegają się ofiary uprzedzeń. Młodych ludzi, którzy są obiektem uprzedzenia, można „zaszczepić” przeciw jego okaleczającym psychicznie skutkom - i w ten sposób pomóc im rozwinąć i wykazać ich prawdziwe potencjalne możliwości - jeśli potrafią oni ukształtować sobie poczucie dumy ze swego pochodzenia, historii oraz przynależności do danej grupy. Ruch „Czarne jest piękne” stanowi przykład skuteczności takiego podejścia.



„Wpływ tego ruchu, stawiającego sobie za cel obronę własnych praw i kształtowanie dumy grupowej, został zademonstrowany w badaniu, w którym ponownie ustalono związek między rasą badanych dzieci a preferowaniem przez nie lalek o różnej barwie. W przeciwieństwie do uzyskanych wcześniej wyników, w tym badaniu okazało się, że większość spośród 89 dzieci murzyńskich wolała lalki o czarnej „skórze”, dłużej bawiła się nimi i uważała je za bardziej atrakcyjne niż lalki białe. Ponadto aczkolwiek większość pośród 71 białych dzieci bawiła się białą lalką i uważała ją za ładną, to jednak tylko 49% spośród nich stwierdziła, że barwa czarnej lalki też jest „ładna” (Hraba i Grant, 1970).




Nieświadoma ideologia
szowinizmu płci
(„seksizmu”)




Jakiej płci osoby są |twoim zdaniem bardziej uczuciowe, wrażliwe, czułostkowe, kapryśne, potrzebujące opieki, obdarzone intuicją, zazdrosne, złośliwe i gadatliwe? Jak sądzisz, jakiej płci osoby są bardziej racjonalne, twórcze, mają predyspozycje do mechaniki i matematyki, są stanowcze, opanowane i twarde? Które nie byłyby dobrym prezydentem ani piłkarzem ligowym? Które wyglądają głupio zmieniając niemowlęciu pieluszki lub krzątając się wokół kuchni? Gość z Marsa mógłby odpowiedzieć: „O Boże, ja nie wiem, lecz być może ma to coś wspólnego z tym, co niemowlęta mają pod różową lub niebieską kołderką”.
Podczas gdy chłopcy bawią się karabinami i mechanicznym budownictwem, dziewczęta dostają lalki i zachęca się je, aby bawiły się „w dom”, przygotowując się do swojej „życiowej roli” - posłusznych, oddanych żon i poświęcających się matek. Częściej niż kolegom o takich samych zdolnościach radzi się im, aby poszły do średnich szkół handlowych lub do szkół zawodowych. Jeśli nie mają wyjątkowych zdolności, to raczej nie zachęca się ich do kontynuowania nauki na wyższej uczelni.
Jeśli mają wyjątkowe zdolności i napiszą oryginalną pracę pozwalającą uzyskać stopień doktora filozofii, to ich szanse na uzyskanie dobrej posady, która dawałaby im osobistą i finansową satysfakcję, są niskie.  Spośród blisko 30 milionów pracujących kobiet, prawie 2\3 jest zatrudnionych przy pracach domowych, jako urzędniczki, w usługach lub handlu. W roku 1968 kobieta mająca ukończone 4 lata college’u zarabiała przeciętnie 6694 dolarów rocznie - tyle samo co mężczyzna mający ukończone zaledwie 8 klas - i znacznie mniej niż koledzy ze studiów, którzy przeciętnie zarabiali 11 795 dolarów rocznie.
Ideologia, często nieświadoma, która prowadzi do tych różnic, nosi nazwę |szowinizmu |płci lub „seksizmu”. Dwa główne czynniki odpowiedzialne za utrwalanie tych szowinistycznych sposobów myślenia i postępowania, to bariery biologiczne i socjalizacja prowadząca do przyswojenia roli związanej z płcią.


„Natura przeznaczyła kobiety na nasze niewolnice (...), to one są naszą własnością, a nie my - ich. Należą one do nas tak samo, jak drzewo rodzące owoce należy do ogrodnika. Co za szalony pomysł, aby domagać się równości dla kobiet (...). Kobiety nie są niczym innym, jak tylko maszynami do produkowania dzieci”.
Napoleon Bonaparte


Bariery biologiczne. Ponieważ kobiety rodzą dzieci i ponieważ sztuczna regulacja tej reprodukcyjnej funkcji zawsze była niedoskonała, kobietę zawsze uważano przede wszystkim za |rodzicielkę |dzieci. Wszelkie dodatkowe czynności, które mogłyby zmniejszyć wpływ społecznej kontroli na jej zdolności reprodukcyjne, uważano za zagrażające samym podstawom społeczeństwa i za „sprzeczne z naturą”. Ta zasada podziału rodzaju ludzkiego - odmienne role reprodukcyjne - była zatem stosowana do uzasadnienia wszystkich innych rzekomych różnic między mężczyznami i kobietami oraz do usprawiedliwiania dyskryminującego traktowania kobiet.  Bez możliwości ograniczenia swej własnej zdolności reprodukcji, inne „swobody” kobiety były iluzją, której nie można było naprawdę zrealizować (Cisler, 1970).
Ulepszona technika regulacji urodzin, łącznie ze zmianami społecznymi w zakresie uświadomienia sobie potrzeb zredukowania wzrostu populacji, egalitarnym (równościowymi) stosunkami między mężczyzną a kobietą, innymi możliwymi stylami życia (samotne matki, komuny rodzinne itd.) oraz większą liczbą ośrodków dziennej opieki nad dziećmi zapewniają kobietom różnorodne możliwości samorealizacji.


Przyswojenie roli związanej z płcią w wyniku socjalizacji. Jeśli dyskryminacja rozpoczyna się dostatecznie wcześnie i jest konsekwentnie stosowana w wielu sferach życia danej osoby, to jest wówczas jedyną dostępną dla niej rzeczywistością społeczną, na której opiera ona swą tożsamość i z której czerpie poczucie własnej wartości.


W wielu badaniach udokumentowano powszechne zaakceptowanie przez kobiety stereotypu niższości.


„W jednym z badań studentki czytały 6 artykułów, których tematyka obejmowała zakres od pedagogiki do prawa. Każdej z osób badanych powiedziałno, że trzy artykuły napisał mężczyzna, a trzy kobieta (np. John T. McKay lub Joan T. McKay). Te same artykuły były oceniane zgodnie jako bardzo autoratywne i bardziej interesująco napisane, gdy przypisywano je autorom niż wtedy, gdy przypisywano je autorkom (Goldberg, 1968).
W kilku badaniach, którymi objęto dzieci i młodzież obojga płci w trzech grupach wieku (7-12 lat, 12-18 lat, 18-26 lat), wykazano, że dziewczęta, we wszystkich przypadkach, miały niższe oczekiwania co do swych osiągnięć w wykonywaniu zadań i sukcesów w nauce niż zrównani z nimi pod istotnymi względami ich rówieśnicy” (Crandall, 1969).


Stereotypowy sposób myślenia o tym, co dziewczęta i kobiety potrafią lub czego nie potrafią robić - jak również o tym, co powinny robić - rozwija się wskutek |tendencyjności jednych działań i |pomijaniu innych. Weźmy na przykład pod uwagę telewizję, która wielu dzieciom zabiera więcej czasu niż szkoła. Zgodnie z wynikami zakrojonych na szeroką skalę badań nad oglądaniem pierwszego programu kanadyjskiej telewizji, widzą one w tej telewizji kobiety, które są marnymi modelami, jeśli chodzi o osiągnięcia (Manes i Helynk, 1974). Często pojawiającymi się postaciami są finansowo niezależne kobiety, których małżeństwo źle się układa, lub których szczęśliwe małżeństwo rozpadło się wskutek podjęcia przez nie odpowiedzialnej pracy. Wiemy zaś z innych badań, że oglądane na filmie modele wpływają na zachowanie obserwatorów (zob. Brian i Schwartz, 1971).
Kobiety znacznie częściej niż mężczyźni są obiektem żartów w popularnych czasopismach.


„Analiza 740 dowcipów publikowanych w ciągu 6 lat w rubryce „Humor, najlepsze lekarstwo” magazynu „Readers’ Digest”, wykazała, że żartów wymierzonych przeciw kobietom jest sześć razy więcej niż żartów skierowanych przeciw mężczyznom. Humor w tych żartach często polegał na akceptacji stereotypów kobiety jako „przesadnie oszczędnej”, „niekompetentnej”, „plotkarki”, „dokuczliwej”, „sentymentalnej”, „mającej bzika na punkcie pieniędzy” lub „zazdrosnej”.
Co prawda, w latach czterdziestych naszego wieku trzecia część wszystkich dowcipów w tej rubryce miała charakter „seksistowski”. Aczkolwiek procent ten stopniowo zmniejsza się, to jednak wpływowe źródło oddziaływania nadal rozpowszechnia wynikające z uprzedzeń stereotypy w żartobliwym przebraniu” (Zimbardo i Meadow, 1974).


Dokładna analiza ról związanych z płcią, jaki przedstawiają podręczniki dla szkół podstawowych opublikowane w latach sześćdziesiątych naszego wieku, ujawniła występowanie wyraźnych stereotypów.


„Postacie kobiece a) pojawiały się rzadziej niż męskie, b) wypełniały raczej polecenia, niż wydawały je, c) częściej zajmowały się fantazjowaniem niż rozwiązywaniem problemów, d) były bardziej konformistyczne i gadatliwe oraz e) częściej znajdowały się w domu. Ponadto, podczas gdy pozytywne wyniki przypisywano działaniom mężczyzn, to pomyślne rezultaty występujące w następstwie działań kobiet przypisywano sytuacji lub dobrej woli innych osób. W podręcznikach przeznaczonych dla coraz wyższych klas zróżnicowanie płci - określane w powyższy sposób - wzrastało, a „właściwe” charakterystyki mężczyzn i kobiet były przedstawiane jako bardziej rozbieżne” (Saario, Jacklin i Tittle, 1973).


Nawet w najpowszechniej stosowanych podręcznikach psychologii dla wyższych uczelni szowinizm płci przejawia się różnymi sposobami, zwłaszcza przez pomijanie: kobiety rzadko pojawiają się w nich inaczej niż jako „matki”.


Nadmierne stosowanie zaimka męskiego oraz określenia gatunkowego „człowiek” (angielskie słowo „man” oznacza zarówno człowieka, jak i mężczyznę - przyp. tłum.) również pomaga w przekazywaniu obrazu psychologii jako nauki o „człowieku-mężczyźnie”, a nie jako nauki o zachowaniu ludzi („APA Task Force Report”, 1974).
Trafność terminu |nieświadoma |ideologia „|seksizmu” (który wprowadzili Bem i Bem, 1974) wyraźnie rzuca się w oczy, gdy czytamy stary artykuł w „Science”, donoszący o wykryciu „słabego krwawienia menstruacyjnego określonego dnia przed właściwą menstruacją u człowieka” (Simpson i Evans, 1928, s. 453); niewątpliwie chodzi tu z pewnością o „człowieka jako gatunek”, niemniej jednak z pewnością o czymś zapomniano.




Streszczenie rozdziału




|Psychologia |społeczna jest nauką o zachowaniu jednostek w sytuacjach społecznych. W ramach tej nauki bada się zarówno |zachowanie |społeczne jako zmienną zależną, jak i |bodźce |społeczne - jako zmienne niezależne.  Bodźce społeczne wpływają często nawet na zachowanie nie mające charakteru społecznego.
Za pośrednictwem procesu |atrybucji wyciągamy wnioski dotyczące innych ludzi oraz przyczyn ich zachowania. Na nasz sposób spostrzegania ludzi wpływają takie czynniki, jak nasze |pierwsze |wrażenie, nasze |stereotypowe |obrazy różnych grup oraz nasza skłonność do oczekiwania |spójności czy konsekwencji. Mamy skłonność do dokonywania |atrybucji |dyspozycyjnych, które koncentrują się na cechach danej jednostki, częściej niż |atrybucji |sytuacyjnych, które koncentrują się na czynnikach działających w środowisku. Skłonność tę określa się jako |błąd |atrybucji.
|Teoria |atrybucji zakłada, że rozwija się w nas zarówno |realistyczne |nastawienie wobec świata, jak i |nastawienie |regulacyjne - nadają one sens wydarzeniom w naszym życiu i umożliwiają ich przewidywanie. Wiąże się to z aktywnym szukaniem informacji. Jesteśmy skłonni przypisywać konformizm przyczynom sytuacyjnym, a odchylenia od norm - przyczynom dyspozycyjnym.  Wzmocnienia zewnętrzne mogą przekształcić aktywność motywowaną wewnętrznie (przypisywaną czynnikom dyspozycyjnym) w coś, co robi się jedynie dla nagrody (i przypisuje czynnikom sytuacyjnym).
|Motywy |osobiste |i |społeczne są bardziej zróżnicowane nić popędy biologiczne i bardziej zależne od uczenia się. Frustracja tych motywów może spowodować zaburzenia emocjonalne.
|Potrzeba |osiągnięć jest bardzo powszechna w naszej kulturze. Wywołuje ona ogólną tendencję polegającą na dążeniu do sukcesów, aczkolwiek niektóre jednostki zdają się koncentrować na osiągnięciu sukcesu, inne zaś - na unikaniu porażki. Motywów osiągnięć u kobiet do niedawna nie badano; istnieje materiał dowodowy wskazujący, że może u nich działać motyw unikania sukcesów. Sposób przyswajania roli związanej z płcią w naszym społeczeństwie powoduje bowiem, że kobieta może znaleźć się w sytuacji, którą można by określić jako konflikt motywów.
|Reaktancja jest to potrzeba swobody działania. Świadczy o niej skłonność do upierania się przy swym własnym wyborze, zamiast stosowania się do sugestii innych osób. |Potrzeba |do |porównywania |społecznego skłania nas do zestawiania uzyskiwanych przez nas wyników z wynikami innych ludzi.  Zaspokojenie naszej |potrzeby |aprobaty |społecznej ma pięć ważnych następstw: 1) zapewnia poczucie tożsamości, 2) uzasadnia nasze istnienie, 3) zapewnia poczucie bezpieczeństwa, 4) tworzy więzi sympatii i 5) świadczy o posiadaniu kontroli nad otoczeniem.
Siła |potrzeby |afiliacji jest różna u różnych jednostek. Zwykle potrzeba ta jest silniejsza w obecności lęku - przynajmniej wtedy, gdy inne osoby znajdujące się w danej sytuacji również się boją. |Altruizm, czyli potrzeba pomagania innym, może być po części instynktowny, a po części wyuczony.  Różni badacze sugerują, że altruizm może wiązać się z: a) |empatią („zastępczym” doświadczaniem emocji innych osób) i redukcją „|napięcia |wspierającego”, b) redukcją poczucia winy oraz c) działaniem norm społecznych. Badania nad potrzebą spójności doprowadziły do powstania teorii dysonansu poznawczego, która głosi, że jednostka odczuwająca niezgodność między dwoma elementami poznawczymi będzie motywowana do zredukowania tej niezgodności przez zmianę przynajmniej jednego z tych elementów poznawczych. Dysonans jest większy wtedy, gdy dana osoba spostrzega, że niezgodny z jej postawami kierunek działania został wybrany przez nią swobodnie, a nie narzucony z zewnątrz.
Badania nad |atrakcyjnością |interpersonalną wykazały, że skłonni jesteśmy lubić ludzi, których spostrzegamy jako atrakcyjnych, kompetentnych oraz podobnych lub „komplementarnych” w stosunku do nas. Do teorii dotyczących atrakcyjności interpersonalnych należy |teoria |słuszności, która głosi, że ludzie skłonni są poszukiwać możliwie największych nagród przy możliwie najmniejszym koszcie, oraz |teoria |zyskiwania |i |utraty, która utrzymuje, że to zmiany w sposobie oceniania na przez inną osobę mają wpływ na atrakcyjność tej osoby dla nas. Nawet |miłość |romantyczna staje się przedmiotem badań laboratoryjnych i przewidywań. Wyniki uzyskane w niedawno skonstruowanej skali miłości romantycznej wykazują dodatnią korelację z rzeczywistym zachowaniem i trwałością romantycznego związku.  |Empatia stanowi ważny aspekt miłości romantycznej; ludzie skłonni są wykazywać podobne oznaki lęku zarówno w wypadku swego własnego wystąpienia publicznego, jak i w wypadku wystąpienia swego obiektu uczuć.
Z próbami przekonania nas i wpłynięcia na nas spotykamy się prawie nieustannie; próby takie budzą jednak zaniepokojenie, gdy osoba, na którą się wpływa, jest w pewien sposób wykorzystywana. |Propaganda polega na próbach przekonania, których prawdziwy cel lub źródło pozostają ukryte; niekiedy może być trudno odróżnić ją od kształcenia. Próby przekonywania czy perswazji można uważać za oparte na przymusie, gdy pociągają za sobą nagłą, nie zaś stopniową zmianę poglądów lub gdy perswadujący posiada całkowitą kontrolę nad daną sytuacją i jej konsekwencjami.
|Postawa jest stosunkowo trwałą dyspozycją do reagowania w pewien sposób wobec ludzi lub sytuacji. W postawach wyróżnia się trzy komponenty: 
|przekonania, |komponent |afektywny (emocje), oraz |komponent |behawioralny. Do czynników wpływających na kształtowanie postaw należą: 
|informacja, |obserwacja, |nagrody i |kary, jak również |mechanizm |obronny |ego. W badaniach nad zmianą postaw częściej uwzględniano trzy zmienne: 
|źródło, |przekaz oraz |audytorium. Na ogół stwierdzano raczej złożone interakcje niż proste zależności między przyczyną a skutkiem.  Najważniejszym wynikiem tych badań było stwierdzenie, że zmiana zachowania często raczej |poprzedza zmianę postaw, niż jest jej następstwem.
|Dynamika |grup, ruch zapoczątkowany w latach czterdziestych naszego wieku, polegał na badaniu dynamiki interakcji społecznej w obrębie grup.  Czterema głównymi źródłami wpływu grupy są: 1) |współuczestniczenie w procesie podejmowania decyzji; 2) |publiczne |zaangażowanie |się w zalecany kierunek działania, 3) |społeczne |poparcie ze strony innych członków grupy oraz 4) |standardy |normatywne (normy społeczne), które określają, jakie zachowanie jest właściwe. Normy są pożyteczne z tego względu, że chronią wartości danej grupy i pozwalają jej członkom zdawać sobie sprawę z tego, jakiego zachowania oczekuje się od nich i jakie zachowanie będzie nagrodzone. Członek grupy, który stosuje się do jej norm, zyskuje pozycję i uznanie; członek grupy, który nie stosuje się do nich, może zostać odrzucony przez grupę lub też grupa może wywierać nań nacisk, aby się przystosował.
Badania laboratoryjne wykazały, że sztucznie wytworzone normy społeczne mogą wpływać na ocenę spostrzeganych bodźców; istnieje zaskakująco silna tendencja do |podporządkowywania |się normom grupowym, mimo że świadectwo zmysłów im przeczy. Jednakże konsekwentnie działająca mniejszość może spowodować ukształtowanie się odmiennych norm.
Przestrzeganie norm grupowych może wytworzyć poczucie tożsamości grupowej (w grupie własnej), która skłania do wyłączania i odrzucania osób postronnych (z grup obcych). W takich sytuacjach prawdziwe pojednanie i akceptacja członków obcej grupy wymaga na ogół wspólnego działania dla osiągnięcia nadrzędnych celów.
W badaniach nad |przywództwem tarano się zidentyfikować cechy efektywnych przywódców, później zaś badano wpływ różnych stylów przywództwa.  Stwierdzono, że efektywne przywództwo wiąże się z takimi cechami, jak inteligencja, osiągnięcia, odpowiedzialność, współuczestnictwo i pozycja (status). W różnych sytuacjach potrzebni są przywódcy o różnych cechach, na przykład |przywódcy |zadaniowi lub |przywódcy |społeczno-|emocjonalni.  Znajomość sytuacji oraz potrzeb i oczekiwań członków pomaga ustalić, jakiego rodzaju przywództwo będzie najbardziej efektywne. Różne style przywództwa mogą mieć znaczny wpływ zarówno na wyniki, jak i na atmosferę grupy.
|Uprzedzenie jest to zespół przekonań, wartości i postaw (zwykle negatywnych), które wywołują u nas tendencyjne nastawienie wobec członków określonej grupy, co prowadzi do zachowań |dyskryminujących. Nawet sztucznie wywołane uprzedzenie i dyskryminacja prowadzą do obniżenia samooceny u części ofiar. Uprzedzenie popierane przez cały system społeczny staje się |rasizmem. Przezwyciężenie ukształtowanego już rasizmu wymaga zmiany |działań, zmiany |reguł |i |wzmocnień oraz zmiany |sposobu |spostrzegania |samego |siebie przez ofiarę.
„Seksizm”, czyli |szowinizm |płci wynika z tendencyjnych oczekiwań co do zdolności i cech osobowościowych obu płci. Zasadniczymi jego źródłami są |bariery |biologiczne (kobieta = rodzicielka dzieci) oraz |socjalizacja powodująca |przyswajanie |roli |związanej |z |płcią (stereotypy prezentowane przez społeczeństwo chłopcu lub dziewczynce od momentu ich urodzenia się).




Z frontu Badań.
Siła i patologia uprzedzeń




|Jane |Elliott, „Riceville, Iowa, Public School”


„Oni wczoraj zastrzelili tego Kinga, proszę pani, dlaczego oni zastrzelili tego Kinga?”. Jak można by wyjaśnić temu niewinnemu, ciekawemu trzecioklasiście powody, dla których doktor Martin Luther King został zamordowany w Memphis tego strasznego kwietniowego dnia w 1968 roku?  „Uprzedzenia”, „dyskryminacja”, „ignorancja” i „strach przed tym, co inne” - oto stosowane powszechnie pojęcia, którymi można by posłużyć się dla wytłumaczenia tej tragedii, jednakże nie wyjaśniają jej one; nie pomogą dzieciom zrozumieć głębokich przyczyn takiej ślepej nienawiści do naszych bliźnich - mężczyzn i kobiet.
Warunki naszej codziennej egzystencji w Riceville uczyniły moje zadanie jeszcze trudniejsze; jest to osiedle wiejskie w północno-wschodniej części stanu Iowa, liczące mniej niż dziewięciuset mieszkańców, wyłącznie białych chrześcijan. W osiedlu tym, ani w otaczających je farmach, nie było Murzynów. Nie byli oni też opisywani ani przedstawiani na obrazkach w podręcznikach, którymi posługiwały się dzieci w szkole. W National Brotherhood Week (Tygodniu Braterstwa Narodowego) mówiliśmy o położeniu Murzynów w białej Ameryce, a zwłaszcza o wysiłkach doktora Kinga zmierzającego do naprawienia istniejących niesprawiedliwości. W czasie, gdy poniósł on śmierć, uczyliśmy się o Indianach i robiliśmy z prześcieradeł ogromny namiot. Ponieważ okoliczności towarzyszące śmierci doktora Kinga przypominały sposób, w jaki dawniej traktowano Indian, wydawało się naturalne połączyć jednostkę lekcyjną poświęconą Indianom z analizą sił odpowiedzialnych za zamordowanie doktora Kinga.
Uznałam, że irracjonalności, bezmyślnej brutalności rasizmu nie da się zawrzeć w małej, schludnej jednostce programowej, którą mogłabym włożyć moim uczniom - nie, aby lekcja ta miała na nich trwały wpływ, musieli oni doświadczyć ich „od wewnątrz”. Do postanowienia, aby odstąpić od typowego planu lekcji, przyczyniły się przerażenie, gniew i wstyd, jakie czułam, oglądając w telewizji białych komentatorów ubolewających nad zamieszkami, które wybuchły w gettach miejskich naszego kraju. Ich zdaniem, świadczyły one w sposób oczywisty, że „ci ludzie” są skłonni do aktów przemocy, że są „oni” naprawdę jacyś anormalni i różni od „nas”, którzy zachowywaliśmy się tak powściągliwie, gdy został zamordowany prezydent Kennedy. Nawet słuszne oburzenie czarnych obywateli uznano za nieuzasadnione - winę przypisano im, a nie systemowi dyskryminacji, przez których byli uciskani. Tego rodzaju analiza przypisywała ofiarom winę za ich nieszczęście, zamiast obwiniać pożałowania godne warunki, jakie wytworzyły wieki przesądów i lekceważenia („poczciwi” itd). Łatwo było usprawiedliwiać dyskryminację, wskazując na wyraźne różnice istniejące obecnie między różnymi grupami rasowymi w Stanach Zjednoczonych pod względem pozycji społecznej, stylu i warunków życia. Nie jest równie łatwo wykazać, że różnice takie są następstwem uprzedzeń - wtórnymi skutkami arbitralnego określenia niższości jednych, a wyższości innych ludzi.
Trzeba było specjalnego rodzaju doświadczeń, aby uzmysłowić te fakty dzieciom, a może i dorosłym, którzy uczą je wierzyć w stereotypy głoszące, że Murzyni są „tępi”, „leniwi”, „brudni”, „agresywni” itd.
Wszyscy wzięliśmy udział w pewnego rodzaju eksperymencie, eksperymencie z „odgrywaniem ról”, w którym część klasy była „lepsza” i uprzywilejowana, reszta zaś była „gorsza” i dyskryminowana. Przyjęto całkowicie arbitralną postawę zaliczania danego dziecka do grupy przywódczej, a mianowicie jego kolor oczu. Przez cały dzień brązowookie dzieci były u szczytu, a dzieci niebieskookie - na dnie. Następnego dnia odwróciliśmy role i grupa „gorsza” stała się „lepszą”. Ponieważ przedsięwzięcie to było pomyślane jako „pewne doświadczenie z zakresu wychowania moralnego” a nie jako formalny eksperyment w dziedzinie psychologii społecznej, nie zamierzałam zatem w systematyczny sposób zbierać danych o zachowaniu dzieci, które by świadczyły o wpływie tego doświadczenia. Jednakże wyniki okazały się tak dramatyczne, ze nie trzeba było wyrafinowanych narzędzi pomiarowych, skal, kwestionariuszy itp., aby ujawnić siłę uprzedzeń. 
Jak opisano, podzieliłam moja klasę według koloru oczu: na siedemnaścioro dzieci niebieskookich i jedenaścioro brązowookich (wraz z paroma zielonookimi). „Ludzie brązowoocy są lepsi, schludniejsi, bystrzejszy, bardziej kulturalni niż ludzie niebieskoocy” - powiedziałam dzieciom, a następnie zaczęłam wykazywać im prawdziwość swego twierdzenia. Wskazywałam dzieci, które garbiły się w ławce, zapominały okularów, nie uważały, biły swą młodszą siostrzyczkę - w każdym przypadku mój palec pokazywał dziecko niebieskookie. Z drugiej strony dałam przykłady dobrych, uprzejmych, sprawnych, grzecznych i bystrych brązowookich malców.
Po wprowadzeniu szeregu opisanych w tekście dyskryminacyjnych reguł, zgodnych z tą arbitralną klasyfikacją, dzieci zaczęły reagować w niezwykły sposób. Gdy dziecko niebieskookie pomyliło się czytając, wówczas potrząsałam głową i polecałam dziecku brązowookiemu, aby poprawiło je. Gdy dzieci niebieskookie nerwowo czekały, aż przyjdzie na nie kolej odpowiadania, wtedy zwracałam uwagę na ich destrukcyjne skłonności, wyraźnie widoczne w zachowaniu jednego z chłopców, który zwijał w tutkę róg stronicy swej książki.
Dzieci błękitnookie zmieniły postawę ciała, garbiły się, były bardziej niezgrabne i miały opuszczone głowy - przejawy poniesionej porażki. Poziom ich pracy w klasie pogorszył się gwałtownie w porównaniu z poprzednim dniem. Zadania arytmetyczne zajmowały niebieskookim dzieciom znacznie więcej czasu niż poprzednio: „bystre” zaś obecnie, brązowookie dzieci potrzebowały na ich wykonanie znacznie mniej czasu. Gdy zapytałam, dlaczego grupa niebieskooka pracuje tak słabo, wówczas jedna z dziewczynek wybuchnęła: „Po prostu wiem, że nie zrobimy tego!” Zaczęły one dostosowywać się do obniżonych oczekiwań!
Szczególnie przygnębiające było obserwowanie, jak moje brązowookie dzieci przekształciły się ze wspaniale współpracujących, myślących uczniów w obrzydliwych, złośliwych, dyskryminujących trzecioklasistów. Niektóre z nich sugerowały nawet, aby ktoś zawiadomił personel stołówki, żeby „mieli oko” na niebieskookich, ponieważ mogli oni próbować zgłaszać się po „repetę”, a nie możemy marnować jedzenia dając je niebieskookim. Nie trzeba mówić, że dzień ten był nieudany dla wszystkich. Podczas przerwy wybuchały bójki, ponieważ „On mnie przezywał, nazwał mnie „błękitnookim””, więc walnąłem go w brzuch!” Dzieci, które od lat były przyjaciółmi, boczyły się na siebie, niektóre dziewczęta płakały, ponieważ zostały wykluczone z zabaw swych dawniejszych przyjaciółek, mających te piękne, brązowe oczy.
Dzieci o „niskiej pozycji” mówiły takie na przykład rzeczy: „Nie chce mi się nawet próbować czegoś zrobić”, „Czuję się jak pies na smyczy” lub „Czuję się, jak gdybym był zamknięty w więzieniu, a oni wyrzucili klucz”.  Lecz lekcja ta jest dwukierunkowa - jeśli niektórzy ludzie są na dole, to inni są u góry. „Czuję się jak król”, powiedział pewien świeżo koronowany brązowooki monarcha, „rządziłem nimi, gdyż byłem lepszy od nich; byłem szczęśliwy”.
|Ja też nie byłam bezpieczna przed drwinami ze strony moich „lepszych”. 
Gdy niechcący oberwałam zasłoną, wówczas mała, brązowooka Debbie krzyknęła: 
„Czego chcecie, ona jest niebieskooka!” Natychmiast odczułam prawdziwy przypływ agresji przeciw mej małej dręczycielce i walczyłam z chęcią dania jej klapsa. Tak potężny jest wpływ pozycji ustalonej za pomocą takiego arbitralnego podziału, że dorosły uważany za „gorszego” może być publicznie wyśmiewany przez dziecko z wyższej kasty. Jeden z moich błękitnookich braci wystąpił w mej obronie przypominając wszystkim: „Ona nigdy nie potrafiła zaciągnąć zasłony jak należy!”. Nauczyłam się wiele z mojej własnej lekcji.
Jak opisano w tekście, drugi dzień przyniósł całkowite odwrócenie sytuacji. Niebieskoocy zostali teraz uznani za „lepszych”; zaczęli uzyskiwać lepsze wyniki i wzrosła ich samoocena. Brązowoocy nagle znaleźli się na dnie. Następnego dnia poleciłam każdemu dziecku napisać wypracowanie składające się z czterech części: jak czuło się ono w pierwszym i drugim dniu tego eksperymentu, co to jest dyskryminacja i kim był Martin Luther King. Wypracowania te odczytywano całej grupie dopiero wtedy, gdy wszyscy skończyli pisać i jedynie za zgodą danego dziecka. Wypracowania te wykazały znaczny wzrost poziomu zrozumienia tej problematyki przez dzieci; mam oczywiście nadzieję, że zrozumienie to może pomóc im w przyszłości wczuć się w położenie tych ludzi, których czyni się obiektem uprzedzeń.
Odtąd przeprowadzałam te zajęcia prawie każdego roku, uzyskując w zasadzie te same rezultaty. Obawiałam się, że wpływ tych zajęć będzie słabszy, jeśli uczniowie zawczasu będą o nich wiedzieć i przewidywać ich skutki. Okazało się, że jest inaczej. Nawet ci uczniowie, których bracia lub siostry brali udział w tych zajęciach i uprzedzili ich o tym, co nastąpi, gdy znaleźli się przez dwa dni w opisywanej sytuacji, reagowali dokładnie tak samo, jak uczniowie w pierwszym eksperymencie: gniewem, rozpaczą, frustracją i cierpieniem, gdy byli ofiarami, klasycznymi zaś objawami postawy rasistowskiej, gdy uznano ich za „lepszych”.
Zapewne oczekiwalibyśmy zbyt wiele sądząc, że dwudniowe zajęcia w trzeciej klasie mogłoby zmienić postawę dziecka na zawsze. Przekonałam się jednak, obserwując rozwój niektórych spośród tych dzieci w następnych latach, że wiele z nich istotnie zmieniło się w wyniku tych zajęć i że zmieniają one postawy otoczenia. Niektóre ze zmian, jakich stałam się świadkiem, były zupełnie nieoczekiwane. U niektórych dzieci doświadczenia polegające na tym, że przez jeden dzień były uznawane za „lepsze”, zapoczątkowało dramatyczną i trwałą zmianę w osiągnięciach szkolnych.  Kilkoro rodziców zatrzymało mnie tego roku po wywiadówce, aby powiedzieć mi, że ich dziecko nadal osiąga dobre wyniki w nauce.


Przykładem ilustrującym zmianę postaw, jaka zaszła u tych dzieci, może być opowiadanie jednej z matek o tym, jak jej córeczka upominała swoją babcię: „Jeśli jeszcze raz powiesz „czarnuch”, to wyjdę z tego domu i nie wrócę, dopóki nie pójdziesz sobie”, ponieważ „my już nie używamy tego słowa w naszym domu”. Inna matka powiedziała mi, że jej syn od czasu tych „Dni Dyskryminacji” stał się innym dzieckiem. „No cóż”, powiedziała ona, „jest on nawet miły dla swej siostrzyczki”. (Nawiasem mówiąc obecnie pracuję z moja klasą nad przezwyciężeniem stereotypów dotyczących płci).
Wyniki badań ankietowych nad postawami, przeprowadzonych przez profesora 
Martina Houga z University of Northern Iowa (Cedar Falls), wykazują, że u 
dzieci, które brały udział w tych „Dniach Dyskryminacji”, wystąpiły istotne 
zmiany w kierunku bardziej tolerancyjnych postaw i przekonań w porównaniu z 
ich rówieśnikami, którzy nie brali udziału w tych zajęciach. Dokonana przez 
profesora Zimbardo ocena wyników, jakie uzyskały te dzieci w szkolnych 
testach osiągnięć, potwierdziła pogorszenie się wyników u dzieci o niższej 
pozycji i poprawę wyników u dzieci o wysokiej pozycji
Szczególnie ucieszyły mnie pewne nieoczekiwane produkty uboczne tego doświadczenia; każde dziecko nauczyło się, że może być „lepsze”, może uzyskiwać dobre wyniki w klasie, gdy uwierzy, że jest naprawdę szczególne i godne uwagi. Powinnam tu wspomnieć, że niektóre z dzieci w moich klasach zostały specjalnie skierowane do mnie, ponieważ miały trudności w czytaniu (dysleksja). Poprzednio nauczono je, że są „głupie”, i nauczyciele, rówieśnicy, rodzice oraz rodzeństwo uważali je za opóźnione w rozwoju.  Zaczęły one dostosowywać się do tych oczekiwań - trwało to aż do chwili, gdy uzyskawszy wysoki status osiągnęły dobre wyniki. Wzmacniając ten nowo uzyskany przez nie obraz samego siebie, mogłam dopomóc im w znacznym, podniesieniu poziomu na jakim czytały, przy czym poprawa ta wydaje się trwała. Widzimy tu znowu, że uprzedzenia pociągają za sobą dostosowywanie się do określonych oczekiwań owych uprzedzonych osób: te białe dzieci nauczyły się funkcjonować na niskim poziomie w dziedzinie czytania, podobnie jak wiele dziewcząt - w przypadku matematyki, a uczniowie z grup mniejszościowych - w przypadku różnych przedmiotów.
Zapytano mnie, czy dorośli mogliby reagować na tę sytuację arbitralnej dyskryminacji w taki sposób, w jaki reagowały na nią dzieci. Moja odpowiedź brzmi: „tak”. Jest przerażające, że wielu dorosłych reaguje na takie doświadczenie w sposób bardzo podobny do dzieci. Jako uczestniczka konferencji na temat dzieci i młodzieży, która odbyła się w Białym Domu w 1970 roku, przeprowadziłam te zajęcia z ponad stu tak zwanymi kulturalnymi, dobrze przystosowanymi, wykształconymi i świadomymi rzeczy dorosłymi i byłam zdumiona podobieństwami między ich reakcjami, a reakcjami moich trzecioklasistów.
Pod koniec dnia, w którym przeprowadzałam tę „grę w dyskryminację”, napięcie wśród jej uczestników było tak wielkie, że |było ono prawdziwe - tak dalece, że w przerwie osoby niebieskookie, którym polecono pozostać w pomieszczeniu, siłą wydostały się do przedsionka przed salą, gdzie miało odbyć się zebranie osób brązowookich. Pierwsza wypowiedź członka tej grupy brzmiała: „Zastrzelić tych sukinsynów”, na co pewien Wuj Tom powiedział: 
„Ale ludzie brązowoocy byli zawsze dla mnie mili”. W innych wypowiedziach nawoływano do pikietowania sali zebrań, wtargnięcia do niej, domagano się więcej rozsądku - i miłości.
Chociaż niektóre osoby powiedziały, że doświadczenie takie nie było niezbędne, to jednak pod koniec dnia większość osób z tej grupy stwierdziła, że |nauczyli się oni czegoś nowego. Zajęcia te szybko stały się czymś znacznie więcej niż grą.
W sierpniu 1971 roku zaproszono mnie, abym zastosowała tę technikę wobec grup nauczycieli na zajęciach przeprowadzanych na University of Iowa. Na drzwiach sali zebrań umieściliśmy napis, który głosił: „Psom i niebieskookim wejście wzbronione”. Z jakichś powodów niebieskoocy obrazili się i postanowili nie wejść do tej sali. Zebrali się oni w przyległym pokoju, w ten sposób „okupując nielegalnie nie przyznane im pomieszczenie uniwersyteckie”. Gdy odmówiliśmy podjęcia z nimi negocjacji, wówczas wynieśli oni z tego pokoju wszystkie meble i ustawili z nich barykadę przed drzwiami naszej sali, przez co „niszczyli chuligańsko własność uniwersytetu”. Gdy dowiedzieli się, w jaki sposób określiliśmy ich postępowanie, wówczas szybko usunęli owe meble, lecz dopiero wtedy, gdy zdali sobie sprawę z „niezrównoważonego stanu swego umysłu”.
Niebieskoocy rozpoczęli swe zebranie w duchu: „Będziemy bawić się w tę grę i postępować w taki sposób, jakiego oczekuje się od członków grup mniejszościowych w tych samych okolicznościach”, lecz wkrótce przeistoczyło się to w rzeczywistość: „Co się tutaj dzieje? Coś jest tu nie w porządku!  Dlaczego oni postępują z nami w ten sposób?” Dla tych zaś nielicznych błękitnookich osób, które weszły do sali zebrań, pomimo tego, że spodziewały się złego potraktowania (rząd federalny płacim im za uczestnictwo w tych zajęciach), sytuacja była jeszcze bardziej pouczająca i przerażająca. Każde przeciwstawianie się regułom ustanowionym przez brązowookich było wykorzystywane dla udowodnienia prawdziwości naszych oskarżeń. Gdy po wielokrotnym powtórzeniu ostrzeżeń dotyczących konsekwencji, jakie im grożą za niepodejmowanie współpracy, demonstrujący błękitnoocy nadal odmawiali wzięcia udziału w ogólnym zebraniu, wówczas wezwano policję uniwersytecką. Gdy zaczęła ona fotografować demonstrantów, wtedy kilku z nich wymknęło się tylnymi drzwiami. Uciekli, aby uniknać prześladowania.
Czego to wszystko dowodzi? Według mnie tego, że możemy - i musimy - wpajać system wartości w szkole podstawowej. Dowodzi, według mnie, również tego, że dyskryminacja nie jest wynikiem uprzedzeń, lecz zupełnie na odwrót: |uprzedzenia |są |wynikiem |dyskryminujących |działań. Wybierz jakąś grupę, oskarż jej członków o posiadanie pewnych cech, postaw, upośledzeń, traktuj ich tak, jak gdyby twoje oskarżenia były faktami, a gdy zaczną oni postępować tak, jak przepowiedziałeś, wykorzystaj ich postępowanie dla udowodnienia trafności twoich oskarżeń.
Obserwacje grup przed tymi zajęciami, w ich trakcie i po nich udowodniły mi także, że uprzedzenia wyrządzają krzywdę nie tylko członkom grupy mniejszościowej, lecz także członkom grupy stanowiącej większość. Jedna z nauczycielek powiedziała mi: „Czy nie jest to podobne do tego wierszyka: 
„Dlaczego wkładasz fasolkę do ucha, skoro właśnie powiedziałam ci, żebyś nie wkładał fasolki do ucha?””. Czy nie sądzi pani, że w rzeczywistości wywołała pani uprzedzenie, i że oni prawdopodobnie nigdy nie pomyśleliby o tym, gdyby pani ich tego nie nauczyła? Nauczycielka ta myliła się w sposób tragiczny. Musimy nie tylko wyeliminować rasizm z wychowania, musimy uczyć dzieci o okropnej rzeczywistości rasizmu w naszym społeczeństwie, to za oznacza, że musimy najpierw uwrażliwić je tak, żeby rozpoznawały rasizm w sobie i w innych.
Cóż więc sugeruję? Że przeprowadzając te zajęcia z niebieskookimi i brązowookimi zmienimy świat? Absolutnie nie!
Sugeruję, abyśmy zamiast poddawać temu doświadczeniu każde dziecko, poddali mu każdego nauczyciela. Podobnie jak biali, a nie Murzyni, są odpowiedzialni za rasizm w Stanach Zjednoczonych, tak nauczyciele, a nie uczniowie są odpowiedzialni za destrukcyjne postawy, które występują u dzieci uczęszczających do szkół - oraz u młodzieży opuszczającej te szkoły.
Siuksowie mają taką oto modlitwę: „O, Wielki Duchu, daj, abym nigdy nie osądzał człowieka, dopóki nie przejdę mili w jego mokasynach”. Jest to być może modlitwa, którą powinniśmy wprowadzić do szkół? Lub przynajmniej do serc nauczycieli!




Rozdział 14.
Degeneracja form
życia społecznego




„(Historia ludzkości jest) nagromadzeniem spisków, buntów, morderstw, rzezi, rewolucji, banicji, samych najgorszych skutków, jakie mogą przynieść ze sobą chciwość, stronniczość, hipokryzja, wiarołomstwo, okrucieństwo, wściekłość, szaleństwo, nienawiść, żądza, zazdrość, zła wola i ambicja.
(...) nie mogę wysnąć żadnego innego wniosku niż ten, że większość twych rodaków jest najzłośliwszą rasą drobnego, wstrętnego robactwa, jakiemu natura kiedykolwiek pozwoliła pełzać po powierzchni ziemi.
Jonathan Swift „Gulliver’s Travels”, 1726, cz. 2, r. 6
(wyd. pol. „Podróże Guliwera”)


Aczkolwiek powyższe totalne potępienie zostało odrzucone jako dzieło cynika nienawidzącego rodzaju ludzkiego, to jednak w wielu innych utworach dotyczących „natury ludzkiej” znajdowały w ciągu stuleci swe odbicie podobne uczucia. Podstawowym tematem w zachodniej literaturze jest temat Człowieka, który - niegdyś wspaniały, niegdyś najszlachetniejszy wzór doskonałości pośród wszelkich stworzeń - utracił wiele ze swego dostojeństwa.
Według uczonych znawców „Biblii”, upadek ten rozpoczął się od jednej wady Adama - jego dumy - która doprowadziła go do nieposłuszeństwa wobec Boga i wygnania z Raju. Zgodnie z innym wątkiem, siła rozkładowa nie tkwi w samym człowieku, lecz działa z zewnątrz - czego przykładem jest oddziaływanie społeczne ze strony Ewy, która skuszona przez Szatana w postaci węża, namówiła Adama do nieposłuszeństwa wobec boskiego zakazu, aby nie jeść owoców z drzewa wiadomości.
Temat negatywnego wpływu społeczeństwa rozwinął Rousseau, który ukazał istoty ludzkie jako szlachetnych, pierwotnych dzikusów zepsutych przez kontakt ze społeczeństwem; aby odzyskać i zachować charakteryzującą je w zasadzie dobroć, jednostki musza uciec z miast i od złych nacisków nieokrzesanej cywilizacji. Francuski impresjonista Paul Gaugin poszedł za tą radą, opuszczając Paryż dla nieskażonego uroku Tahiti i prostego życia tamtejszych tubylców. Dla Amerykanów Thoreau (H. D. Thoreau (1817-1862), amerykański filozof i poeta, jeden z głównych przedstawicieli transcendentalizmu amerykańskiego, rzecznik indywidualizmu, autor „Walden or Life in the Woods” (przyp. red. nauk.)) i jego samotna chata w Walden Ponad w stanie Massachusetts stali się symbolem zerwania więzów konwencji społecznych. W obecnych czasach wielu młodych ludzi odpowiedziało na to samo wezwanie, tworząc w okręgach wiejskich małe komuny lub przyłączając się do nich.
Zdecydowanym przeciwieństwem tego sposobu widzenia istot ludzkich - jako niewinnych ofiar wszechmocnego, złowrogiego społeczeństwa - jest pogląd, że ludzie są w zasadzie źli. Zgodnie z tym poglądem, ludzie są miotani pragnieniami, żądzami i popędami, chyba że zostali przekształceni w racjonalne, rozsądne, współczujące istoty ludzkie przez edukację lub znajdują się pod kontrolą silnych autorytetów.
Jakie jest |twoje stanowisko w tym sporze? Czy rodzimy się dobrzy i psuje nas złe społeczeństwo, czy też rodzimy się źli i naprawia nas dobre społeczeństwo? Zanim oddasz swój głos, spójrz na to zagadnienie z innej perspektywy. Być może, każdy z nas ma potencjalne możliwości, by stać się świętym lub grzesznikiem, altruistą lub samolubnym, łagodnym lub okrutnym, dominującym lub uległym, zdrowym psychicznie lub szalonym. Być może, to warunki społeczne, z jakimi mamy do czynienia, oraz sposób, w jaki uczymy się borykać z nimi, decydują o tym, które z tych możliwości rozwiniemy. Co więcej, być może możliwość wypaczeń tkwi nieodłącznie w tych samych procesach, dzięki którym jesteśmy zdolni do zrealizowania tych wszystkich wspaniałych rzeczy, jakie potrafimy zrobić.
Poprzednie rozdziały są udokumentowaniem złożonego rozwoju i najwyższej specjalizacji człowieka, do której doprowadziły go niezliczone miliony lat ewolucji, rozwoju, adaptacji i walki. Staliśmy się władcami tej planety, rządząc zwierzętami oraz fizyczną materią Ziemi dla naszego przetrwania, wygody i szczęście. Panowanie to obejmuje obecnie głębie oceanów, jak również przestrzeń kosmiczną. Osiągnęliśmy tę pozycję dzięki naszej zdolności do uczenia się nowych relacji (i do zapamiętywania starych), do rozumowania, dokonywania wynalazków oraz planowania strategii działania.  Stworzyliśmy język dla operowania symbolami i przekazywania wiadomości i naszych myśli innym ludziom. Nasze umiejętności percepcyjne, poznawcze i ruchowe pozwalają nam widzieć, zastanawiać się i uniknąć przykrości, osiągnąć przyjemność i zmieniać nasze otoczenie w pożądany sposób, lecz każdy z tych jedynych w swym rodzaju przymiotów może także stać się źródłem rakowatego rozwoju. W tych samych zdolnościach, które umożliwiają doskonalenie się, zawarte są zalążki degeneracji i rozpadu.
Na przykład, nasza niepospolita pamięć pozwala nam wyciągać korzyści z błędów, zapewnia ciągłość naszemu życiu i pozwala opanować złożone konstrukcje wiedzy. Jednakże ten sam dar pamięci może przeistoczyć nasz umysł w magazyn traumatycznych zdarzeń, obaw, lęków, nierozwiązanych konfliktów oraz mało istotnych żalów i urazów.


Ponieważ ukształtowaliśmy jedyną w swoim rodzaju perspektywę czasową, możemy zatem planować naszą przyszłość, „oszczędzać na czarną godzinę”, odraczać gratyfikację i uczyć się z historii. Jednakże z powodu tego samego poczucia czasu, nasze obecne zachowanie często traci swą spontaniczność.  Nie potrafimy cieszyć się w pełni miłością, jaką dają nam inni, ani urokami natury, borykamy się bowiem każdego dnia ze swymi powinnościami, obietnicami i zobowiązaniami (dawne umowy), jednocześnie realizując zadania, unikając odpowiedzialności i przewidując najgorsze (przyszłe troski).
Częściowy katalog ludzkich cech i przymiotów oraz ich możliwych pozytywnych i negatywnych konsekwencji przedstawiono w zamieszczonej obok tabeli. Zachęcamy cię, abyś rozszerzył tę listę dopisując do niej inne cechy, które również mają taki podwójny charakter, lub też rozwijając pozytywne bądź negatywne aspekty cech już na niej wymienionych.
W rozdziale tym skierujemy naszą uwagę na pewne procesy psychiczne, które występują wtedy, gdy ludzie „schodzą z właściwej drogi”. Znaczna część tych materiałów dotyczących „patologii społecznej” nie jest zamieszczana we współczesnych, dostępnych podręcznikach psychologii. Uwzględniliśmy je tutaj, ponieważ jesteśmy przekonani, że naukowe badania nad zachowaniem organizmów muszą obejmować także wielorakie oddziaływania czynników społecznych, politycznych i ekonomicznych na nasze zachowanie. Jeśli czynniki te mogą powodować, że rywalizujemy zamiast współdziałać, walczymy zamiast kochać, tłumimy i niszczymy zamiast tworzyć, to musimy o nich wiedzieć. Jedynie dysponując wiedzą o przyczynach i mechanizmach degeneracji oraz wypaczeń, będziemy mogli przekształcić nasze sposoby wzajemnego odnoszenia się do siebie i stworzyć instytucje społeczne lepiej służące pełnej realizacji życia każdej jednostki ludzkiej, każdego z nas.




Agresja i przemoc




Świat, w którym żyjemy, często jest światem przemocy. Zamieszczane codziennie w gazetach opisy morderstw, napaści, zamieszek, samobójstw i wojen stanowią bogaty materiał dowodowy, świadczący o rozmiarach krzywd, jakie ludzie potrafią wyrządzić innym i sobie. Jak można wyjaśnić takie „anormalne” zachowanie? Czy można je opanować?
Psychologowie zainteresowani tymi zagadnieniami skoncentrowali swe wysiłki na badaniu |agresji, którą można zdefiniować jako zachowanie fizyczne lub werbalne, podejmowane z zamiarem skrzywdzenia lub zniszczenia.  Dane empiryczne dotyczące agresji czerpie się z najróżniejszych źródeł-łącznie z badaniami fizjologicznymi, obserwacjami klinicznymi oraz badaniem agresywnych interakcji zarówno w laboratorium, jak i w „świecie realnym”. Ponadto wiele uwagi poświęcono agresji u zwierząt w nadziei, że pozwoli to lepiej zrozumieć agresję u ludzi. W tym podrozdziale dokonamy przeglądu kilku teorii, które zaproponowano dla wyjaśnienia agresywnego zachowania.




Agresja jako
tendencja wrodzona




W swym słynnym eseju pod tytułem „Leviathan” Hobbes dowodził, że ludzie są z natury samolubni, brutalni i okrutni dla innych ludzi. Wyraził on tę koncepcję za pomocą krótkiej sentencji: „Homo homini lupus” (Człowiek człowiekowi wilkiem).




* * *



Jakie Nasze Zdolności Mogą Obracać Się Na Naszą Niekorzyść?


Pamięć
Pozwala nam:
- odnosić korzyści z dawnych błędów,
- tworzyć złożone pojęcia i posługiwać się nimi,
- wiązać teraźniejszość z przeszłością,
- odróżniać nowe zdarzenia od przeżywanych uprzednio.
Lecz może także powodować, że:
- żywimy urazy, cierpimy wskutek dawnych konfliktów i minionych 
traumatycznych zdarzeń,
- nasze zachowania tracą spontaniczność z powodu zobowiązań i obowiązków,
- dotkliwie odczuwamy wyrzuty sumienia lub poniesioną stratę.


Poczucie czasu
Pozwala nam:
- tworzyć historię i kształtować świadomość ciągłości swego „ja”, 
- wiązać obecne zachowanie z przyszłością, odróżniać to, co przemijające od tego, co co trwałe. 
Lecz może także powodować, że:
- obawiamy się zmian, żyjemy przeszłością, mamy poczucie winy,
- boimy się nieznanej przyszłości, ogarnia nas nieokreślony lęk,
- odczuwamy rozczarowanie wskutek niespełnionych oczekiwań,
- koncentrujemy się na przeszłości lub przyszłości, ignorując teraźniejszość. 


Zdolność kojarznia elementów i wnioskowania o nie widzialnych zdarzeniach:
Pozwala nam:
- tworzyć, wyobrażać sobie zdarzenia nie objęte własnym doświadczeniem,
- uogólniać na podstawie częściowych danych,
- konstruować teorie, hipotezy.
Lecz może także powodować, że:
- kształtujemy negatywne, kalekie skojarzenia,
- spostrzegamy błędnie siebie lub innych,
- przyjmujemy stereotypowy i urojeniowy sposób myślenia.


Spostrzeganie możliwości wyboru
Pozwala nam:
- nie być uzależnionym od bodźców, być niezależnym,
- spostrzegać siebie samych jako osoby odpowiedzialne,
- mieć nadzieję, budować dla przyszłości,
Lecz może także powodować, że:
- przeżywamy konflikty, niezdecydowanie,

- cierpimy wskutek niezdolności podjęcia działania, gdy działanie jest niezbędne.


Odpowiedzialność, samoocena
Pozwala nam:
- być dumnym z osiągnięć,
- odkładać na później gratyfikacje, podejmować trudne lub niepopularne 
zadania, 
- troszczyć się o skutki naszych działań dla innych ludzi.
Lecz może także powodować, że:
- czujemy się nieudolni,

- czujemy się winni z powodu nieosiągania standardów lub niespełnienia 
czyichś oczekiwań,
- czujemy sie skrępowani zobowiązaniami. 


Motyw kompetencji:
Pozwala nam:
- pracować dobrze, by ustanawiać wysokie standardy 
- uzyskiwać korzyści z ciężkiej pracy,
- rozwijać technikę, wykorzystywać bogactwa naturalne w celu zaspokojenia różnych potrzeb.
Lecz może także powodować, że:
- cierpimy wskutek poczucia nieudolności,
- udczuwamy lęk przed sprawdzaniem naszych zdolności,
- pracujemy, aby wywyższyć się, być na pierwszym miejscu, pokonać innych.


Poczucie sprawiedliwości:
- chronić prawa jednostki,

- ustanawiać sprawiedliwe obowiązujące wszystkich prawa,
- cenić wartości różnych możliwości dla wszystkich. 
Lecz może także powodować, że:
- poświęcamy potrzeby jednostek dla zasad lub reguł grupowych,
- torturujemy, więzimy, skazujemy na śmierć dysydentów,
- narzucamy własne rozwiązania innym. 


Zdolność posługiwania się językiem i innymi symbolami:
Pozwala nam:
- komunikować się z innymi, obecnymi i nieobecnymi; dla uzyskania informacji, dla wygody, przyjemności, w celu planowania, kontroli społecznej. 
Lecz może także powodować, że:
- puszczamy w obieg plotki i kłamstwa lub jesteśmy ich ofiarami; ukrywamy 
swe prawdziwe uczucia,
- posługujemy się „magią słów”
- przekleństwami, obelgami - dla wyrządzenia krzywdy,
- uznajemy (błędnie) symbole za rzeczywistość. 


Podatność na oddziaływanie społeczne
Pozwala nam:
- stosować się do norm grupowych,
- uczyć się wartości i przekazywać je,
- współdziałać; tworzyć wspólnotę.
Lecz może także powodować, że:
- jesteśmy zbyt konformistyczni, kosztem uczciwości,
- odrzucamy innowacje i tłumimy twórczość, własną i innych. 


Miłość
Pozwala nam:
- doznawać wzruszeń,

- troszczyć się o rozwój i niezależność innych,

- udzielać innym oparcia, zachęty i pociechy,
- czuć się potrzebnym i niezwykłym.
Lecz może także powodować, że:
- stajemy się zazdrośni i mściwi,
- zazdrośnie ograniczamy swobodę innej osoby,
- w wyniku utraty miłości pojawia się depresja i tendencje samobójcze.


* * *





Aczkolwiek sentencja ta niesłusznie oczernia wilka (wilki są w rzeczywistości zupełnie pokojowo nastawione i łagodne wobec innych osobników własnego gatunku), to jednak wyraża ona dość powszechne przekonanie, że ludzie są istotami instynktownie agresywnymi.


Energia psychiczna: Tanatos i koncepcja katharsis. Jednym z pierwszych psychologów, którzy opracowali dokładniej ten pogląd i rozwinęli go w teorię, był Zygmunt Freud. Jak przekonaliśmy się w Rozdziale 10, przyjmował on, że od momentu narodzin człowiek posiada dwa przeciwstawne instynkty: instynkt życia (Eros), który powoduje, że jednostka rozwija się i utrzymuje się przy życiu, oraz instynkt śmierci (Tanatos), który działa w kierunku samozniszczenia danej jednostki. Sądził on, że instynkt śmierci często zostaje skierowany na zewnątrz, przeciw otaczającemu światu, w postaci agresji wobec innych.


Według Freuda, energia służąca instynktowi śmierci jest nieustannie generowana w organizmie. Jeśli energia ta nie może wyładować się w małych dawkach i w jakiś sposób akceptowany społecznie, to będzie się ona gromadzić i w końcu rozładuje się w skrajnej i nieakceptowanej społecznie postaci. Wydaje się zatem, iż można przyjąć, że osobą wysoce agresywną, czy też skłonną do stosowania przemocy, jest zwykle: a) ktoś, kto generuje wiele agresywnej energii oraz b) ktoś, kto jest niezdolny do rozładowywania tej energii we właściwy sposób i w małych dawkach.
Freud przedstawił obrazowo tę energię przyrównując ją do wody gromadzącej się w zbiorniku i wylewającej się zeń w końcu w jakimś agresywnym czynie.  Może ona jednak być odprowadzana w różne „bezpieczne” sposoby, włączając tu „katharsis” (greckie słowo oznaczające „oczyszczenie”), w której emocje są wyrażane z pełną intensywnością za pomocą płaczu, słów lub też innych ośrodków symbolicznych. Arystoteles jako pierwszy posłużył się pojęciem katharsis dla wyjaśnienia tego, w jaki sposób dobra sztuka dramatyczna najpierw wzbudza u słuchaczy silne emocje, a następnie pozwala je rozładować.


„Do domu przynieśli ciało jej rycerza, Nie zemdlała ani nie wydała krzyku. A jej służebne patrząc na to, rzekły: „Musi zapłakać albo wkrótce umrze”.
(Alfred Lord Tennyson „The Princess”, 1847)


Pewne poparcie eksperymentalne dla koncepcji wiążącej agresję z pojęciem katharsis można znaleźć w badaniu przeprowadzonym przez Roberta Searsa (1961). Chłopcy, którzy byli bardzo agresywni w wieku pięciu lat, byli także bardzo agresywni w wieku lat dwunastu. Niektórzy z nich byli nadal otwarcie i antyspołecznie agresywni, jednakże inni, chociaż przejawiali agresję |antyspołeczną w małym stopniu, to jednocześnie wykazywali znaczną agresję |prospołeczną (agresję służącą celom akceptowanym społecznie, takim jak zmuszanie do przestrzegania prawa lub karanie za łamanie zasad).




* * *



Ryc. 14.1. Wzrost Nasilenia Agresji Prospołecznej I Autoagresji. Wykres ten przedstawia nasilenie agresji prospołecznej i autoagresji, przejawianej przez dwie grupy chłopców, którzy początkowo (w wieku 5 lat) wykazywali wysokie natężenie agresji antyspołecznej. Ci chłopcy, u których w wieku 12 lat natężenie agresji antyspołecznej obniżyło się (WN - wskaźnik niski) przejawiali większą agresję prospołeczną i autoagresję niż chłopcy, u których natężenie agresji antyspołecznej pozostało wysokie (WW - wskaźnik wysoki).


* * *





Przejawiali oni także większą |autoagresję (agresję przeciw samemu sobie) niż chłopcy, którzy pozostali antyspołecznie agresywni (ryc. 14.1).  Ponadto, ci „prospołecznie agresorzy” wykazywali większy lęk i obawy w związku z agresją antyspołeczną niż „agresorzy antyspołeczni”.
Badania, które przeprowadził Megargee (1966), także dostarczyły pewnego poparcia dla freudowskiej teorii agresji i katharsis, opartej na pojęciu „energii psychicznej”.


„Megargee postawił hipotezę, że skrajnie agresywnych czynów dopuszczają się te jednostki, które zwykle zbyt silnie się kontrolują i nie potrafią rozładowywać małych ilości energii agresywnej. Agresywne napięcia kumulują się w miarę upływu czasu i kiedy agresja ujawni się w końcu, to wybucha w skrajnej postaci.
Aby zweryfikować tę koncepcję, Megargee porównywał chłopców, którzy zostali skazani przez sąd dla nieletnich za umiarkowanie agresywne przestępstwa, takie jak lekkie pobicie czy bójki gangów młodzieżowych, z chłopcami skazanymi za skrajnie agresywne przestępstwa, takie jak morderstwo, brutalne pobicie czy napad z bronią w ręku. Stwierdził on, że chłopcy, którzy dopuścili się czynów skrajnie agresywnych, byli istotnie zbyt opanowanymi, nadmiernie „usocjalizowanymi” jednostkami, w porównaniu zarówno z chłopcami umiarkowanie agresywnymi, jak i grupą kontrolną złożoną z „przeciętnych” absolwentów szkoły średniej. Ich sprawowanie, zarówno w szkole, jak i w więzieniu, było określane jako bardzo dobre, byli też oceniani jako bardzo przyjaźni, współpracujący i posłuszni. W czasie zatrzymania wykazywali oni mniej werbalnej i fizycznej agresji niż wszystkie inne grupy młodocianych przestępców. Ponadto w testach psychologicznych uzyskiwali wyniki wskazujące na bardzo wysoką samokontrolę. Ich agresywne, zagrażające życiu czyny były przeważnie wywoływane przez pozornie błahą frustrację lub niewielką zaczepkę”.


Jednakże teoria Freuda, pomimo pewnych potwierdzających ją danych, jest krytykowana przez psychologów za to, że nie określa dokładnie czynników, którymi można by się posłużyć w celu przewidywania wystąpienia agresji lub też kierunku i formy, jaką ona przyjmie. Ma ona pewną wartość opisową, literacka, pozwala wyjaśniać po fakcie, lecz ma małą przydatność naukową. W swych późniejszych dziełach Freud w istocie sam zrezygnował z posługiwania się pojęciem instynktu śmierci, lecz wielu innych autorów (takich, jak Rollo May) nadal włącza to pojęcie do swej koncepcji natury ludzkiej.


„Instynkt agresji”. Autorem innej teorii kładącej nacisk na wrodzony charakter agresji jest znany etolog Konrad Lorenz (1966). Opierając się na badaniach przeprowadzonych na zwierzętach, wysunął on twierdzenie, że agresja jest spontaniczną wrodzoną gotowością do walki, która jest niezbędną dla przetrwania organizmu. Jednakże u innych gatunków akty agresji między osobnikami należącymi do tego samego gatunku rzadko powodują ich rzeczywiste obrażenia lub śmierć, ponieważ jedno ze zwierząt w końcu „sygnalizuje” poddanie się czy uległość. Według Lorenza, istoty ludzkie utraciły jakoś te sposoby hamowania agresji, zachowując jednocześnie instynkt agresji, dlatego stały się zabójcami.
Aczkolwiek Lorenz stara się udokumentować analogię pomiędzy agresją u ludzi i u zwierząt, to nie ulega wątpliwości, że istnieją między nimi zasadnicze różnice. Po pierwsze, ze względu na charakterystyczne dla ludzi zdolności pamiętania i oceniania, ich działania są często reakcja na wspomnienia i wyobrażenia, a nie na aktualną sytuację; po drugie, ze względu na swą umiejętność sporządzania narzędzi i zdolności planowania mogą oni rozmyślnie wyrządzać niemal nieograniczone szkody i krzywdy, nawet nie przeżywając agresywnych uczuć i nie wchodząc w osobiste interakcje ze swymi ofiarami. Na uwagę zasługuje fakt, iż bardziej systematyczne obserwacje wykazały, że jedyna podana przez Lorenza różnica między ludźmi a zwierzętami (to, że wrodzone „gesty poddania się” hamują agresję u zwierząt) w rzeczywistości nie istnieje (Barnett, 1967). Reakcje zwierząt na uległe zachowanie ze strony innych zwierząt są bardzo zróżnicowane, podobnie jak u ludzi. Trudno jest przewidzieć, w jakich okolicznościach oznaki słabości i uległości będą wywoływać współczucie i skłaniać do „fair play”, a w jakich warunkach będą one po prostu pobudzać do jeszcze intensywniejszych aktów przemocy ze strony agresywnej jednostki lub grupy.


„Podczas interwencji policji na University of California w Berkeley, funkcjonariusze bili pewnego dnia studenta, ciągnąc go w dół po schodach z zajętego przez policję budynku. Pracownicy administracji uniwersytetu w liście protestacyjnym stwierdzili, że jęczał on: „Proszę, przestańcie mnie bić! Czy nikt mi nie przyjdzie z pomocą?” Zgodnie z ich opisem, im bardziej prosił, tym więcej go bili” („San Francisco Chronicle”, 20 lutego 1969).


Fizjologiczne podłoże agresji. Relacje między agresją a biologią są złożone i niejasne. Wspomnimy tu tylko o roli mózgu oraz znaczeniu czynników genetycznych i hormonalnych.
Podwzgórze i ciało migdałowate (oraz prawdopodobnie inne regiony mózgu) zdają się odgrywać pewną rolę w niektórych zachowaniach agresywnych. Jak pamiętamy z Rozdziału 2, sygnały elektryczne przekazane przez radio do jądra migdałowatego zatrzymywały w miejscy szarżującego byka. O złożonej chemicznej i anatomicznej specyficzności mechanizmów mózgowych kontrolujących agresję świadczy fakt, że pewien środek farmakologiczny wstrzyknięty szczurom do bocznej części podwzgórza powodował, że osobniki zwykle samorzutnie zabijające myszy przestawały je zabijać, podczas gdy inny środek farmakologiczny wstrzykiwany w dokładnie ten sam punkt mózgu pokojowo nastawionym szczurom, skłaniał je go zabijania myszy (Smith, King i Hoebel, 1970).
Padaczka występuje wśród przestępców dziesięć razy częściej niż u nieprzestępców (Mark i Ervin, 1970), a nieprawidłowe zapisy EEG również stwierdza się częściej u tych więźniów, którzy są recydywistami (Levy i Kennard, 1953). U pewnej kilkunastoletniej dziewczyny, która napastowała kilkakrotnie niemowlęta i w końcu zadusiła jedno z nich na śmierć (ponieważ jego płacz denerwował ją) lekarze zlokalizowali specyficzne pole mózgu, którego czynność bioelektryczna powstająca |pod |wpływem |dźwięku |płaczu |niemowlęcia (a uwidoczniona w zapisie EEG) znacznie odbiegała od normy (Mark i Ervin, 1970).
Niektóre typy agresywnego zachowania ludzi wiążą się często z zaburzeniami funkcjonowania mózgu. Na przykład, schorzenie obejmujące układ limbiczny lub płat skroniowy stwierdza się niekiedy u osób wykazujących tak zwany |zespół |braku |kontroli („dyscontrol syndrome”), charakteryzujący się bezsensowną brutalnością, patologicznym podnieceniem, napaściami seksualnymi lub wielokrotnym powodowaniem poważnych wypadków samochodowych.
Guzy w mózgu również mogą mieć związek z agresywnym zachowaniem, na co wskazuje przypadek wielokrotnego mordercy Charlesa Whitmana.




Zbliżenie


Opanowany przez nieprzezwyciężalne, gwałtowne impulsy


„Latem 1966 roku Charles Whitman zabił swą żonę i matkę, a następnie wspiął się na szczyt wieży gmachu University of Texas. Uzbrojony w doskonałą strzelbę myśliwską z celownikiem optycznym postrzelił 38 ludzi - zabijając 14, zanim sam został zastrzelony. Jak mógł popełnić taki czyn?
Detektywi znaleźli listy, napisane przez Whitmana w wieczór poprzedzający ten jego atak, które częściowo dają odpowiedź na to pytanie:


„(...) naprawdę nie rozumiem teraz samego siebie. Sądziłem, że jestem 
przeciętnym, rozsądnym i inteligentnym młodym człowiekiem. Jednakże 
ostatnio (nie potrafię sobie przypomnieć, kiedy to się zaczęło) stałem się 
ofiarą wielu niezwykłych i irracjonalnych myśli. Myśli te nieustannie 
powracają, a skupienie się na użytecznych, realizowanych stopniowo 
zadaniach wymaga olbrzymiego wysiłku umysłowego. W marcu, gdy stan zdrowia 
moich rodziców pogorszył się gwałtownie, znajdowałem się w stanie silnego 
stresu. Udałem się do doktora C., pracującego w uniwersyteckim ośrodku 
zdrowia i poprosiłem go, aby polecił mi kogoś, u kogo mógłbym zasięgnąć 
porady w sprawie pewnych zaburzeń psychicznych, które - jak sądziłem - 
występowały u mnie. Rozmawiałem z lekarzem raz (przez blisko dwie godziny) 
i starałem się przekazać mu swoją obawę, że jestem opanowany przez 
nieprzezwyciężalne, gwałtowne impulsy. Po tej jednej wizycie nigdy już nie 
widziałem tego lekarza i od tej pory sam walczyłem ze swym zaburzeniem 
psychicznym, jak się wydaje - bez rezultatu. Życzę sobie, aby po mojej 
śmierci przeprowadzono sekcję pozwalającą stwierdzić, czy występowało u 
mnie jakieś widoczne schorzenie fizyczne. Dawniej miewałem okropne bóle 
głowy, a w ostatnich trzech miesiącach zużyłem dwie duże butelki ekscedryny 
(...)”



Sekcja mózgu Charlesa Whitmana ujawniła wysoce złośliwy guz, wielkości orzecha włoskiego, w okolicy ciała migdałowatego” (Sveet, Ervin i Mark, 1969).


Jaką rolę w zachowaniu agresywnym odgrywają specyficzne geny? Aczkolwiek można selekcjonować hodowane zwierzęta, na przykład byki i koguty, w taki sposób, aby uzyskać osobniki szczególnie uzdolnione do walki i zabijania (Scott, 1958), to jednak materiał dowodowy, świadczący o dziedzicznym podłożu agresywności u ludzi jest mniej jednoznaczny. Popularna koncepcja „złych genów” czy „złej krwi” uzyskała poparcie w wynikach wczesnych badań nad rodzinami Jukesów i Kallikaków, lecz jak przekonaliśmy się w Rozdziale 5, sprawozdania te były tendencyjne i nierzetelne.
Później duże poruszenie wywołała hipoteza, ze wyraźnie agresywne zachowanie może być wynikiem dodatkowego chromosomu Y (chromosom Y w parze XY w zapłodnionej komórce powoduje, że niemowlę będzie płci męskiej, a także jest odpowiedzialny za inne cechy męskie, takie jak siła fizyczna i wzrost, które mogą wiązać się z agresywnością). Chociaż jednak statystycznie istotny procent pensjonariuszy zakładów karnych i zakładów psychiatrycznych należy do typu XYY, to jednak liczby bezwzględne są małe i osoby te nie wykazują bardziej agresywnego zachowania niż inni „pensjonariusze”.
Zarówno u ludzi jak i u zwierząt osobnicy płci męskiej są zazwyczaj bardziej agresywni niż osobnicy płci żeńskiej - wydaje się, że jest to po części wynikiem oddziaływania hormonów płciowych na mózg we wczesnym okresie życia. Samice zwierząt, którym wstrzyknięto męskie hormony płciowe, często zaczynają zachowywać się w sposób bardziej agresywny (Edwards, 1971). Z drugiej strony, podłożem różnych rodzajów agresji są różne mechanizmy fizjologiczne. Moyer (1968) wyróżnił |siedem rozmaitych mechanizmów neuronowych i hormonalnych, w zależności od tego, czy agresywność wiązała się z polowaniem (u drapieżników), rywalizacja między samcami, obroną terytorium, funkcjami macierzyńskimi, czy była wywołana przez strach, podrażnienie, czy też miała charakter instrumentalny. Wyniki te jeszcze bardziej uwypuklają złożoność relacji między czynnikami fizjologicznymi i agresją, w których to relacjach na ogół wchodzą w grę także czynniki wyuczone i sytuacyjne.




Agresja jako
popęd nabyty




Po upływie 20 lat od chwili, gdy Freud postawił tezę o istnieniu instynktu śmierci, grupa psychologów z Yale University przedstawiła formalnie alternatywną koncepcję agresji zwaną |hipotezą |frustracji-|agresji (Dollard, Doob, Miller, Mowrer i Sears, 1939).
Agresja, stwierdzili oni, jest popędem nabytym, będącym reakcją na frustrację. |Frustrację określa się jako stan, który występuje wtedy, gdy pewna aktywność ukierunkowana na cel zostaje zablokowana, przy czym intensywność frustracji jest funkcją trzech czynników: a) siły motywacji do tej czynności, b) stopnia jej zakłócenia oraz c) liczby zakłóconych uprzednio sekwencji aktywności ukierunkowanej na cel. Im większa frustracja, tym silniejsza wynikająca z niej agresyjna reakcja.
Wkrótce jednak okazało się, że nie każdy akt agresji jest poprzedzony przez frustrację i że nie każda frustracja prowadzi do agresji. Pierwotną hipotezę frustracji-agresji przeformułowano w ten sposób, że każda frustracja pobudza do agresji, lecz że pobudzenie to może być zbyt słabe, aby |wywołać rzeczywiste agresywne zachowanie (N. Miller, 1941). Autorzy tej koncepcji zgadzali się z Freudem, że popęd agresji będzie wzrastał, jeśli nie zostanie wyrażony (jeśli frustracja trwa nadal), lecz źródła agresywnego zachowania upatrywali raczej w czynnikach |zewnętrznych (nagromadzonych frustrujących doznaniach), a nie w czynnikach |wewnętrznych („instynkcie” agresji).


Przemieszczenie agresji. Gdy wystąpi frustracja, wówczas pierwszy i zarazem najsilniejszy wybuch agresji jest skierowany przeciw jej źródłu.  Gdy więc na przykład dziecko widzi cukierek, lecz Mama nie pozwala mu go zjeść, wówczas dziecko to jest silnie motywowane, aby zachować się agresywnie w stosunku do niej. Taka jednak agresja może zostać zahamowana ze względu na groźbę kary. Zgodnie z teorią frustracji-agresji, dziecko |przemieści więc tę agresję na pewien obiekt - inny niż pierwotne źródło frustracji. Tę skłonność do wyładowywania wrogich uczuć na „bezpiecznym” obiekcie ilustruje przykład mężczyzny, który zwymyślany przez swojego szefa idzie do domu i tam krzyczy na żonę, daje klapsa dziecku i kopie psa.  Zgodnie z tą teorią, im mniej podobny jest ów obiekt do źródła frustracji, tym słabsza jest przemieszczona agresja i mniej pełny jest jej kataraktyczny efekt (ryc. 14.2).
Teoria frustracji - agresji zastosowana do uprzedzeń, przewiduje także, że gdy potężny czynnik frustrujący budzi strach lub niemożliwe jest „zrewanżowanie” mu się, to agresja może być przemieszczona na |kozła |ofiarnego. Mniejszości narodowe i członkowie obcych grup są zapewne dlatego ulubionym obiektem przemieszczonej agresji, że wyraźnie różnią się od członków własnej grupy (na których nie można wyładować agresji), jak też dlatego, że mają już słabą pozycję i w związku z tym nie jest prawdopodobne, aby się odwzajemnili.


„Jeśli Tyber wyleje na miasto, Jeśli Nil nie nawodni obszarów uprawnych, Jeśli niebiosa pozostaną obojętne, Jeśli ziemia się trzęsie, Jeśli jest głód i zaraza, To natychmiast wznoszą się okrzyki: 
„Chrześcijanie dla lwów”. Tertulian, historyk rzymski”


Kiedy coś źle szło w Rzymie, to zdarzało się, że chrześcijan rzucano lwom. W bliższych nam czasach, w końcu XIX wieku i na początku wieku XX na południu Stanów Zjednoczonych, gdy cena bawełny spadła, to znacznie rosła liczba linczowanych Murzynów. W czasie II wojny światowej Żydów obciążano winą za wszystkie nieszczęścia Niemiec. Czy dostrzegasz jakieś aktualne analogie?


Rola bodźców wyzwalających („releasers”) otrzymywanych ze środowiska.  Stosunkowo niedawno teorię frustracji-agresji poddano rewizji, kładąc nacisk na doniosłe znaczenie zarówno czynników wewnętrznych, jak i zewnętrznych. Według Berkowitza (1965), prawdopodobieństwo, że ludzie dopuszczają się agresji zależy od ich |wewnętrznej |gotowości |do |agresji oraz |sygnałów |zewnętrznych, które wzbudzają ich agresję i dostarczają jej obiektu. Oddziaływania tych dwóch czynników - wewnętrznego i zewnętrznego - mogą się sumować lub nawet zwielokrotniać wzajemnie.




* * *



Ryc. 14.2. „Mogłem albo to zrobić, albo wziąć karabin, wejść na dach i strzelać do ludzi”, powiedział młody człowiek, który za pomocą młota kowalskiego rozbił 19 witryn w Wells Fargo Bank w San Fransisco. Młot ten trzyma funkcjonariusz („San Fransisco Examiner Chronicle”, 17 czerwca 1973).


* * *





Jeśli jeden z nich jest słaby, to drugi musi być silny, aby wywołać agresję. Osoba nawykowo agresywna wykazuje dużą „gotowość” do przejawiania agresji i potrzebuje do tego jedynie niewielkiej prowokacji zewnętrznej, lecz nawet jednostka łagodnych obyczajów może stać się agresywna, jeśli podlega silnej i powtarzającej się frustracji oraz jest przedmiotem drastycznych prowokacji.
Opisane powyżej badania wykazały doniosłą rolę odpowiednich |bodźców |wyzwalających (nie lubianych obiektów lub obiektów już skojarzonych z agresją).


„Osoby badane sądzono przed stołem, na którym leżała albo broń (na przykład strzelba), albo różne neutralne przedmioty: gdy eksponowano broń, wówczas osoby badane reagowały bardziej gwałtownie na obrazę niż te osoby, które widziały jedynie przedmioty neutralne, chociaż oczywiście nikt nie robił żadnego użytku z broni. Wydaje się zatem, że sama obecność takich zewnętrznych sygnałów agresji, jak strzelby, może zwiększać prawdopodobieństwo agresywnego zachowania” (Berkowitz i LePage, 1967).


Pojęciem zewnętrznych bodźców wyzwalających posłużono się również w celu dalszego wyjaśnienia, dlaczego grupy mniejszościowe są stale obierane jako obiekt agresji i uprzedzeń. Ponieważ grupy te były uprzednio atakowane, zatem skojarzyły się one z wrogością oraz aktami przemocy i z tego powodu stały się bodźcami wyzwalającymi dalszą agresję przeciw sobie. Innymi słowy, zostały kojarzone z aktami przemocy, ponieważ w przeszłości |były |przedmiotem agresji.
W celu wykazania, jak może funkcjonować to błędne koło, przeprowadzono następujący eksperyment.


„Osoby badane oglądały filmy o walce bokserskiej, w której bokser nazwiskiem Kelly został ciężko pobity przez boksera o nazwisku Dunne.  Później, rzekomo w innym eksperymencie, te same osoby miały sposobność wymierzać wstrząs elektryczny osobie, którą nazywano rozmaicie: Bob Kelly, Bob Dunne lub Bob Riley.
Osoba ta otrzymywała o wiele więcej wstrząsów, gdy nazywano ją Kelly niż wtedy, gdy nadawano jej którekolwiek z pozostałych dwóch nazwisk” (Geen i Berkowitz, 1966).




Agresja jako zachowanie
wyuczone społecznie




Na pytanie dotyczące podłoża agresji można odpowiedzieć też inaczej: że jest ona wyuczona - podobnie jak wiele innych rodzajów zachowania, że nie wynika z jakiegoś instynktu czy popędu, lecz jest rezultatem norm, nagród, kar oraz modeli, z którymi zetknęła sie dana jednostka (Bandura, 1973).  Według tego podejścia, określanego jako |teoria |uczenia |się |społecznego, agresja może być wynikiem a) awersyjnych (przykrych) doświadczeń i (lub) b) przewidywanych korzyści, czyli podniet („incentives”). Wszelkiego rodzaju awersyjne doświadczenia (nie tylko frustracja) wytwarzają ogólny stan pobudzenia emocjonalnego. Pobudzenie to może następnie prowadzić do pewnej liczby różnych zachowań, zależnie od tego, jak dana jednostka nauczyła się radzić sobie ze stresem. Niektórzy ludzie, gdy są wzburzeni, to stają się agresywni, niektórzy wycofują się, niektórzy zwracają się do innych o pomoc, niektórzy zaś angażują się w konstruktywne rozwiązywanie danego problemu. Agresja, podobnie jak inne reakcje, może także występować pod nieobecność pobudzenia emocjonalnego, jeśli dana jednostka sądzi, że takie jej zachowanie doprowadzi do pewnego pożądanego rezultatu (na przykład, gdy jedno dziecko bije inne młodsze od siebie, aby zabrać mu zabawkę).


Modele agresji. Jak wspomnieliśmy w Rozdziale 3, jeden z podstawowych sposobów, za pomocą których ludzie uczą się nowych zachowań, polega na obserwowaniu innych ludzi. Bandura i jego współpracownicy jako pierwsi przeprowadzili badania, które wykazały, że agresywne modele są zdolne wywoływać agresywne zachowanie u dzieci.


„Dzieci przedszkolne badano w różnych warunkach: oglądały one model zachowujący się agresywnie w „życiu realnym”, model zachowujący się agresywnie na filmie, agresywne działania bohatera komiksu, lecz też nie miały do czynienia z żadnym modelem w ogóle.


Wkrótce po tym doświadczeniu u wszystkich tych dzieci wywołano lekką frustrację. Następnie eksperymentatorzy mierzyli wielkość naśladowczej i nienaśladowczej agresji, jaką wykazywały dzieci pod nieobecność modela.
Sfrustrowane dzieci, które obserwowały agresywne modele, przejawiały 
wiele naśladowczych agresywnych reakcji, podczas gdy sfrustrowane dzieci, 
które nie obserwowały modela, nie były prawie wcale agresywne. Co więcej, 
dzieci, które oglądały sfilmowane działanie modela, były równie agresywne 
jak te, które oglądały model w „życiu realnym”. Rycina 14.3 pozwala się 
przekonać, w jakim stopniu dzieci naśladowały agresywne reakcje modela” 
(Bandura, Ross i Ross, 1963).


Przypuśćmy, ze dzieci oglądały modela karanego za agresywne zachowanie; czy wówczas naśladowanie przez nie agresji byłoby mniej prawdopodobne?


„Dzieciom pokazano film, w którym model demonstrował cztery nowe agresywne reakcje. Jedna z grup oglądała wersję, w której to agresywne zachowanie zostało nagrodzone; druga grupa oglądała wersję, w której model został ukarany; w trzeciej grupie reakcje modela nie pociągały za sobą żadnych konsekwencji dla niego.




* * *



Ryc. 14.3. Zachowanie modela bijącego młotkiem nadmuchiwaną lalkę, było naśladowane wiernie przez badane dzieci.


* * *





Po obejrzeniu tego filmu u dzieci, które widziały, że model został ukarany, wystąpiło mniej naśladowczych, agresywnych czynności” (Bandura, 1965).
Czy jednak obserwacje takie wpływają na |uczenie |się agresji, czy tylko na |wykonywanie agresywnych czynności?


„Gdy właściwy eksperyment został już rzekomo zakończony, wówczas eksperymentator zaproponował każdemu dziecku nagrodę za zrobienie dokładnie tego, co robił model. Pod wpływem tej pozytywnej podniety wszystkie dzieci chętnie wykonywały agresywne reakcje, naśladujące zachowanie modela.  Najwidoczniej agresywna czynność została wyuczona, lecz dzieci wiedziały, że czynność taka jest niewłaściwa w danej sytuacji. Gdy „wypłaty” uległy zmianie, wówczas dzieci zaczęły wykonywać tę samą czynność” (Bandura, 1965).


Późniejsze badania wykazały, że dzieci pobudzone emocjonalnie (na przykład, gdy same biorą udział w rywalizacyjnych grach) są bardziej skłonne do naśladowania zachowania modela, niezależnie od tego, czy model demonstruje zachowanie agresywne, czy też nieagresywne (Christy, Gelfand i Hartmann, 1971).


Rób to, co ci mówię, a nie to, co ja robię. Wiele eksperymentów wykazało, że niektóre modele skuteczniej niż inne skłaniają do naśladowania.  Najbardziej efektywnymi modelami są opiekuńcze osoby dorosłe o wysokim statusie, które dysponują możliwością nagradzania. Najbardziej podatne na wpływ modeli są te osoby, które odznaczają się zależnością, są umiarkowanie pobudzone i które poprzednio były nagradzane za przejawianie naśladowczych reakcji (Bandura, 1969).
Gdybyś z jakichś powodów |chciał sprawić, aby jakaś osoba stała się bardzo agresywna, to taka sytuacja uczenia się byłaby według ciebie najlepsza do tych celów? W jaki sposób mógłbyś „zaprogramować” agresywną osobę? Przede wszystkim z pewnością potrzebowałbyś modela w postaci dorosłej osoby, a ponieważ dzieci są zależne od dorosłych, byłoby zatem dobrze, aby „uczniem” tym było dziecko. Powinieneś sprawić, aby owa agresywna dorosła osoba została zauważona przez dziecko i aby dziecko to było pobudzone emocjonalnie. Oba te warunki będą spełnione, jeśli każe się dorosłemu ukarać dziecko - dziecko z pewnością zauważy agresję, jeśli będzie jej obiektem, a zwykle jest wzburzone, wylęknione i rozgniewane wtedy, gdy się je karze. Osoba dorosła będąca modelem powinna ponadto być opiekuńcza i powinna w przeszłości nagradzać za naśladowanie jej. Ideałem byłoby zatem wybranie do tej roli rodziców, ponieważ opiekowali się oni dzieckiem od długiego czasu i często nagradzali dziecko za naśladowanie ich postaw, zachowań i przekonań. Rodzice mają ponadto pod swą kontrolą większość dostępnych nagród (przywileje, pochwały, uczucie, słodycze itd.), a zatem są całkiem „potężni”.
I wreszcie, aby uczynić tę sytuację naprawdę „idealną”, rodzice powinni być nagradzani za swe agresywne zachowanie osiągnięciem |swego bezpośredniego celu - uzyskaniem posłuszeństwa ze strony dzieci. Biorąc to wszystko pod uwagę, trudno byłoby zaprogramować środowisko bardziej sprzyjające uczeniu się agresji niż to, jakie istnieje w domu Przeciętnego Karzącego Ojca i Przeciętnej Karzącej Matki.




* * *



Ryc. 14.4. „Ja cię nauczę bić siostrę!”


* * *





Oczywiście, jeśli rodzice zawsze karzą dziecko za agresywne zachowanie, gdy tylko je zauważą, to dziecko wkrótce nauczy się hamować agresję w obecności rodziców. Jednakże na podstawie wyników badań Bandury oczekiwalibyśmy, że naśladowcza agresywna reakcja zostanie silnie wyuczona, lecz będzie hamowana w obecności rodziców i wykonywana w innych sytuacjach - i tak jest rzeczywiście. Matki, które karzą agresję w domu, stwierdzały, że ich dzieci zachowują się bardziej agresywnie w przedszkolu (Sears, Maccoby i Levin, 1957). Badania nad jawnie agresywnymi dorastającymi chłopcami wykazały, że ich ojcowie surowo karali agresję w domu i że wskutek tego niewielu spośród tych chłopców przejawiało tam agresywne zachowania. Wielu rodziców było w istocie zaskoczonych, gdy dowiedziało się, że ich „grzeczni chłopcy” byli bardzo agresywni w szkole (Bandura i Walters, 1959). Jest więc paradoksem, że ci rodzice, którzy karzą fizycznie dziecko za agresję, modelują i kształtują te właśnie zachowania, które starają się wyeliminować (ryc. 14.4).
Rodzice mogą także uczyć agresji w inny sposób. Mówiąc swemu synkowi, aby „był mężczyzną”, aby zawsze „oddał” i „umiał zrobić użytek ze swych pięści”, rodzice jawnie uczą go i zachęcają do tego, aby był agresywny w stosunku do innych ludzi. Tacy rodzice nie tylko wybaczają agresywne zachowanie - oni wymagają go i nagradzają za nie. Zamieszczony poniżej fragment wywiadu dostarcza przykładu takiego „ćwiczenia w agresji”:


Przeprowadzający wywiad: „Czy kiedykolwiek zachęcała pani Earla, aby bronił się za pomocą pięści?”
Matka: „O tak. O tak. On potrafił walczyć”
P.: Co pani robiła, aby go zachęcić?”
M.: „Kiedy był małym chłopczykiem, miał parę rękawic bokserskich. Jego tatuś był całe życie sportowcem, więc go nauczył”.
P.: „Czy kiedykolwiek przychodził on do pani i skarżył się, że jakiś kolega dokucza mu?”
M.: „O tak, kiedy był młodszy. Powiedziałam mu: Idź i rozstrzygnij to sam w walce (...)”. 
P.: „Co pani robiła, jeśli pani stwierdziła, że Earl dokucza innemu chłopcu lub przezywa go?”
M.: „To była sprawa Earla. Jeśli inny chłopiec chciał zlać go, to była sprawa Earla. On zasłużył na to” (Bandura i Walters, 1959, ss. 115-116).


Szersze środowisko kulturowe również może zachęcać do aktów przemocy.  Dostarczając wiele agresywnych modeli oraz darząc aprobatą i prestiżem akty przemocy, społeczeństwo, może wywierać duży nacisk na jednostki - zwłaszcza modele - aby dostosowały się do normy agresywności (ryc. 14.5).




* * *



Ryc. 14.5. Dzieci w Irlandii Północnej na co dzień są świadkami aktów agresji na ulicach miast i uczą się je naśladować.


* * *





„Jako dziecko zauważyłem, że większość facetów, z którymi się zadawałem, bardziej bała się uchylić od walki niż walki. Tego od nas oczekiwano i dostosowaliśmy się do tych oczekiwań. Dorośli w sąsiedztwie postępowali w taki właśnie sposób. Reprezentowali oni w swym życiu pogląd, że mężczyzna powinien walczyć. Gdy dwaj mali chłopcy wszczęli bójkę w sąsiedztwie, wówczas mężczyźni zachęcali ich i podpuszczali. Nigdy nie pomyśleli nawet, żeby przerwać walkę (...). Musiałeś walczyć i każdy szanował ludzi, którzy walczą (...). Mężczyzna był szanowany stosownie do swej opinii. Ci ludzie w sąsiedztwie, na których każdy spoglądał z szacunkiem, to byli faceci, którzy już kogoś zabili”.
Claude Brown „Manchild in the Promised Land” 1965, ss. 253-256


Wyrażanie agresji: katharsis czy dodatkowa podnieta? Ponieważ teoria uczenia się społecznego nie postuluje żadnego popędu czy instynktu agresji, odrzuca ona zatem pojęcia katharsis - zgodnie z którym wyrażanie agresywnych uczuć zmniejsza skłonność do agresywnych działań. W istocie teoria ta przewiduje wręcz przeciwny rezultat: wyrażenie agresywnych impulsów czy też obserwowanie agresywności innych |zwiększy prawdopodobieństwo przyszłej agresji.
Hipotezę tę potwierdziły wyniki przeprowadzonych badań, takie jak cytowane uprzednio, które wykazują, że agresywność wzrasta po obejrzeniu agresywnych modeli. Ponadto badania wykazały, że ujawnienie agresywnego zachowania w tolerancyjnym środowisku podtrzymuje to zachowanie na pierwotnym poziomie, zamiast je zredukować.


„Osoby badane miały do czynienia ze wzbudzającym gniew przeciwnikiem; następnie połowie z nich pozwolono wyrazić swój gniew i wrogość przed współczującym rozmówcą. Pozostałe osoby badane nie odbyły takiej rozmowy, lecz po prostu siedziały przez chwilę. Później osoby badane, z którymi przeprowadzono rozładowującą napięcie, „katarktyczną” rozmowę, bardziej nie lubiły swego przeciwnika (a nie mniej) i pozostawały bardziej pobudzone fizjologicznie niż badani z grupy kontrolnej (Kahn, 1966).
W innych badaniach dzieciom dawano sposobność wyrażenia albo fizycznej, albo słownej agresji przeciwko dziecku, które wywołało u nich frustrację. 
Żadna z tych czynności nie zredukowała agresywnych uczuć u dzieci”
(Mallick u MaCandlless, 1966).


Wyniki tych badań sugerują, że procedury terapeutyczne, w których zachęca się daną osobę do wyładowania agresywnych uczuć, mogą mieć skutek przeciwny do zamierzonego.
Te i inne wyniki badań nie tylko są sprzeczne z teoriami agresji opartymi na pojęciu instynktu lub popędu, lecz zdają się także podważać zdroworozsądkową koncepcję, ze dobrze jest „wyładować się” i „zrzucić wszystko z serca?”. Być może łatwiej nam będzie zrozumieć tę sprzeczność, jeśli przeprowadzimy rozróżnienie pomiędzy |wyrażaniem |emocji a |agresywnym |działaniem. Danie upustu swym uczuciom (na przykład w płaczu, śmiechu lub rozmowie z inną osobą) może sprawić, że poczujesz się lepiej lub twój lęk ulegnie złagodzeniu, natomiast przejawianie agresji skierowanej przeciw twojemu wrogowi, czy to słownie, czy w otwartym działaniu, |nie zredukuje prawdopodobieństwa, że postąpisz tak znowu.


Czy środki masowego przekazu uczą przemocy? Przestępcom zbrodnia może nie popłacać, lecz przemoc z pewnością jest opłacalna dla przemysłu telewizyjnego. Program z „akcją” i „przygodami” (jak eufemistycznie określa się przemoc) mają większe audytoria - a zatem przyciągają więcej reklam handlowych, które przynoszą zyski telewizji. W rezultacie, każdy kto włącza odbiornik telewizyjny obejrzy prawdopodobnie dramat lub komedię, w której ludzie są zabijani lab maltretowani na różne sposoby, filmy rysunkowe z sympatycznymi, lecz sadystycznymi postaciami oraz programy informacyjne z aktualnym serwisem filmowym przedstawiającym wojny, zabójstwa, zamieszki oraz pospolite zbrodnie.
Jaki jest wpływ wszystkich tych aktów przemocy na widza? Czy w konsekwencji oglądania telewizji stanie się on bardziej agresywny? Pytania takie były przedmiotem wielu publicznych dyskusji. Według przedstawicieli teorii agressji, opartych zarówno na pojęciu instynktu, jak i popędu, oglądanie przemocy działa katarktycznie i dzięki temu spełnia dodatkową funkcję społeczną rozładowując energię agresji. Przeciwny punkt widzenia reprezentują zwolennicy teorii uczenia się społecznego, którzy argumentują, że programy telewizyjne (jak również inne środki masowego przekazu) dostarczają wzorów aktów przemocy oraz sankcjonują je i w ten sposób przyczyniają się w poważnym stopniu do upowszechniania antyspołecznego zachowania.
Jak dotąd, wyniki badań empirycznych potwierdzają na ogół stanowisko reprezentowane przez zwolenników teorii uczenia się społecznego. Jak wspomnieliśmy wcześniej, wykazano, iż modelowanie agresji wpływa na poziom agresywnego zachowania dzieci. Nie tylko uczą się one reakcji agresywnych natychmiast, lecz ponadto mogą reprodukować wiele z nich po upływie kilku miesięcy (Hick, 1968). Ponadto stwierdzono, że ilość przemocy, jaką chłopcy oglądają w telewizji, jest w sposób istotny skorelowana z ich agresywnością po upływie 10 lat, zgodnie z tym, co przedstawia wykres na rycinie 14.6 (Eron, Huesmann, Lefkowitz i Walder, 1972).
Oglądanie sfilmowanych aktów agresji (zwłaszcza jeśli są one przedstawione realistycznie) może być bardzo podniecające dla dzieci.


Stają się one pobudzone emocjonalnie i zwykle zapamiętują więcej treści agresywnych niż nieagresywnych (Osborn i Endsley, 1971). Jednakże po wielokrotnym obejrzeniu scen przemocy dzieci zdają się przyzwyczajać do niej i doznają mniejszego pobudzenia emocjonalnego niż na początku (Cline, Croft i Courrier, 1972). Może to być aspekt jeszcze bardziej destrukcyjny niż nauczanie agresji: gdy potrafimy patrzeć na przemoc i cierpienie człowieka bez emocji, w sposób obojętny i zblazowany, to jesteśmy już przygotowani do nieludzkiego działania wobec innych ludzi.
Aczkolwiek były pewne badania, które rzekomo wykazały, iż przemoc w telewizji działa katarktycznie i zmniejsza skłonność do agresji, to jednak ich poważne błędy metodologiczne redukują wiarygodność uzyskanych wyników.


„W jednym z najczęściej cytowanych badań tego rodzaju, chłopcom w dwóch zakładach wychowawczych pokazywano przez 6 tygodni „agresywne” bądź „nieagresywne” programy telewizyjne, a personel tych zakładów obserwował i oceniał agresywne zachowania tych chłopców. Autorzy podają, że wyniki potwierdziły hipotezę katharsis” (Feshbach i Singer, 1971).


Jednakże niewiele spośród tych wyników było istotnych statystycznie, gdy chłopców tych zrównano pod względem początkowego poziomu agresywności.  Sposób podziału programów na „agresywne” bądź „nieagresywne” również był wątpliwy; na przykład filmy rysunkowe (które ocenia się jako wypełnione w najwyższym stopniu aktami przemocy) zostały sklasyfikowane jako „nieagresywne”.
Ponadto eksperymentatorzy nie mieli pełnej kontroli nad oglądaniem przez chłopców programu telewizyjnego i niektórzy z nich w rzeczywistości oglądali zarówno programy „agresywne”, jak i „nieagresywne”.
W lepiej kontrolowanych powtórzeniach tego badania nie potwierdzono wyników uzyskanych przez Feshbacha i Singera (Wells, 1971), a ponadto stwierdzono, że młodociani przestępcy, którzy wielokrotnie oglądali akty przemocy na filmach, stali się |bardziej agresywni niż ci, którzy oglądali filmy nie pokazujące przemocy (Parke i in., 1972). Eksperymenty laboratoryjne, badania terenowe, jak również badania korelacyjne - wszystkie one dostarczyły danych świadczących o tym, że oglądanie aktów przemocy przyczynia się do zwiększenia agresywności. Niestety, tego rodzaju naukowy materiał dowodowy nie prowadzi bezpośrednio do zmiany polityki społecznej.




Zbliżenie


Nauki społeczne a polityka


„Wzrastające zainteresowanie społeczne skutkami pokazywania aktów przemocy w telewizji skłoniło nie tak dawno senatora Johna O. Pastore’a do wysunięcia żądania, aby minister zdrowia powołał komitet doradczy w celu zbadania tego problemu i opracowania zaleceń. Można by się spodziewać, że w skład komitetu wejdą najwięksi znawcy tego zagadnienia, jednakże minister zdrowia przyznał przedsiębiorstwom telewizyjnym prawo weta wobec zaangażowania proponowanych członków komitetu, co spowodowało, że wielu wybitnych, czołowych znawców tej problematyki zostało wyeliminowanych.  Wśród tych odrzuconych specjalistów byli Albert Bandura i Leonard Berkowitz - wyniki ich klasycznych badań oczywiście nie są tym, co chcieliby usłyszeć przedstawiciele przemysłu telewizyjnego. Utworzony ostatecznie komitet, pod nazwą Surgeon General’s Scientific Advisory Committee on Television and Social Bevawior (Doradczy, Naukowy Komitet Ministra Zdrowia do spraw Telewizji i Zachowań Społecznych), doszedł do wniosku (co nie jest zaskakujące), że wyniki badań w tej dziedzinie nie są „zupełnie zgodne ani rozstrzygające”. Przyznał jednak, że istnieje pewien związek pomiędzy oglądaniem aktów przemocy a zachowaniem agresywnym” („Surgeon General’s Report”, 1972, s. 9).




Przemoc w interakcjach
między ludźmi




Dotychczas koncentrowaliśmy się na agresywnych skłonnościach istniejących |w danej jednostce. Jednakże agresja występuje zazwyczaj w kontekście społecznym, w sytuacjach, w których wchodzą w grę inni ludzie. Aby lepiej zapoznać się bliżej z agresywnymi interakcjami |między jednostkami.


Maltretowane dzieci. Jedną z najbardziej podstawowych i ważnych relacji społecznych jest stosunek istniejący między rodzicami a dzieckiem. Stosunek ten nie zawsze jest normalny, zdrowy, ponieważ niektórzy rodzice nie dbają o swoje dzieci, nie zapewniają im wystarczającej opieki i nie okazują im uczuć miłości. Co więcej, w ostatnich latach stwierdzono w sposób jednoznaczny, że niektórzy rodzice maltretują fizycznie swoje dzieci, a nawet zamęczają je na śmierć.
Trudno sporządzić dokładną statystykę, lecz ostrożnie ocenia się, ze ponad 700 dzieci jest zabijanych corocznie przez swych rodziców w samych Stanach Zjednoczonych, a około 40000 dalszych jest poważnie bitych i torturowanych przez swych rodziców, rodzeństwo i krewnych. Ocenia się też, że około 3 milionów dorosłych bierze udział w „zmowie milczenia” - wiedząc o przypadkach maltretowania dziecka, lecz nie interweniując w żaden sposób, by przyjść mu z pomocą (Helfer i Kempe, 1968). Jaskrawy przypadek dręczenia dziecka opisujemy poniżej.




Zbliżenie


Stadium przypadku maltretowanego dziecka


„Gdy Glorię przyłapano na kradzieży żywności ze sklepu i stwierdzono, że uciekła z domu, miała ona wówczas czternaście lat i ważyła tylko 50 funtów (około 22,7kg). Badania ujawniło niewiarygodny ogrom krzywd, jakich doznała od urodzenia. Była ona regularnie bita przez swą matkę, ciągnięto ją za włosy, trzymano jej głowę pod wodą, przypalano jej plecy gorącym żelazkiem; ślady wielokrotnych złamań kości świadczyły o długiej historii pobić.  Zamykano ją w jej pokoju i nie pozwalano jeść razem z rodziną - otrzymywała jedynie resztki posiłków. Gdy miała zaledwie |trzy |tygodnie, musiano ją skierować do szpitala z powodu niedożywienia. Gdy miała |cztery |miesiące (zgodnie z aktami szpitalnymi) była poddana leczeniu z powodu pięciu skomplikowanych złamań kości).
Uciekła ona z domu między innymi dlatego, że była literalnie głodzona na śmierć. Pielęgniarka przeprowadzająca wywiad środowiskowy nie stwierdziła niczego niezwykłego w jej „czystym, schludnym domu” ani też w pozornie normalnych stosunkach rodziców z innymi ich dziećmi. Rodzeństwo Glorii dawało jej niekiedy pokryjomu pożywienie, lecz nie było to „akceptowane” zachowanie. Matka podała, że dziecko było po prostu „inne” niż wszystkie pozostałe - nieposłuszne i „niepoprawne”. Nie było żadnych powodów, które by potwierdzały tę ocenę. Wydaje się raczej, że matka wyrzekła się psychicznie Glorii piątego dnia po jej urodzeniu, gdy teściowa stwierdziła, że niemowlę nie jest podobne do jej syna i że nie jest jego.
Dzięki odpowiedniej opiece szpitalnej Glorii przybyło 20 funtów w ciągu jedenastu dni i jej stan fizyczny stale się poprawiał. Jest jednak nieprawdopodobne, aby cokolwiek mogło zlikwidować blizny w jej pamięci lub zetrzeć uformowany w jej umyśle obraz miłości matczynej” (przypadek przedstawiony na „Symposium on Children in Peril; The Battered Child” - Sympozjum na temat Dzieci w Niebezpieczeństwie: Dziecko Maltretowane - San Fransisco, 19 lutego 1969).


Dlaczego zdarzają się takie wypadki? Czy rodzice maltretujący swe dziecko są niezwykle sadystycznymi ludźmi? Badania nad tymi zagadnieniami wykazały, że w rodzinach maltretujących dziecko występuje pewien specyficzny układ warunków, lecz że rodziców tych rzadko można uznać za patologicznych „dewiantów”.
Dzieci maltretowane są częściej w tych rodzinach, w których występuje 
napięcie między rodzicami (jak również inne problemy emocjonalne), które 
mają stosunkowo niski poziom dochodu oraz w których kary fizyczne są 
zasadniczym środkiem służącym do utrzymywania dyscypliny i sprawowania 
kontroli. Maltretowanie często dotyczy tylko jednego dziecka, a nie 
wszystkich i zdaje się wiązać z tym, że dziecko to urodziło się w wyniku 
nie chcianej ciąży. Matki maltretujące dzieci często są osobami bardzo 
samotnymi, które utrzymują mało kontaktów z ludźmi poza domem. Zwykle mają 
one fałszywe poglądy na pewne podstawowe zagadnienia dotyczące rozwoju i 
zdolności ich dzieci. Na przykład wiele z nich jest przekonanych, że 
dziecko potrafi rozróżnić dobro od zła w wieku 12 miesięcy lub wcześniej
(Elmer, 1967).
Uważając swe dzieci za znacznie bardziej rozwinięte intelektualnie i odpowiedzialne niż są one w rzeczywistości, rodzice ci są bardziej skłonni interpretować płacz dziecka, brudzenie pieluszek czy psucie zabawek jako rozmyślne złe zachowanie, złośliwość i przyczynianie kłopotów rodzicom.  Ponieważ rodzice ci często są „samotnikami”, nie mają oni zatem podstawy dla porównań społecznych (które mogłyby pomóc skorygować ich błędne poglądy), a także brak im oparcia w przyjaciołach czy krewnych w okresach stresu. Ludzie, którzy maltretują swoje dzieci, mieli zwykle rodziców, którzy ich maltretowali - jaskrawy przypadek przemocy rodzącej przemoc (Silver, Dublin i Lourie, 1969).
Wysiłki zmierzające do zapobieżenia maltretowaniu dzieci trzeba podejmować na wielu różnych poziomach. Wydaje się ustawy, które wymagają od pracowników służby zdrowia i opieki społecznej meldowania o przypadkach, w których podejrzewa się maltretowanie dziecka. Realizuje się programy, w ramach których dziecko można czasowo usunąć z domu, podczas gdy wobec rodziców stosuje się pewnego rodzaju postępowanie terapeutyczne.



Podejmuje się kroki w celu podniesienia poziomu wykształcenia z zakresu regulacji  urodzin, wychowywania dzieci i życia rodzinnego - niektóre szpitale wielkomiejskie donoszą o zmniejszeniu się liczby przypadków maltretowania dzieci. Niestety, w wielu przypadkach stosunki między maltretującym rodzicem a maltretowanym dzieckiem nadal ustala się na czysto prawnych zasadach, nie uwzględniając społecznych i psychologicznych problemów, jakie w tych przypadkach wchodzą w grę. Ciężko poszkodowane dzieci nieraz oddaje się z powrotem pod opiekę rodziców, bez dokonania oceny sytuacji rodzinnej, a rodziców maltretujących swe dziecko często traktuje się jak przestępców, a nie jak ludzi, którzy rozpaczliwie potrzebują pomocy.




* * *



Ryc. 14.7. Według opowieści chłopców, których sąsiad znalazł w tym stanie, gdy ich rodzice wyszli wieczorem z domu, związano ich, „żeby nie dobrali się do masła orzechowego”. Ojciec, który obciął prawą rękę swojej córeczce, twierdził początkowo, że był to wypadek.


* * *





Niełatwo jest znaleźć rozwiązanie tego problemu społecznego, lecz społeczeństwo musi podjąć energiczne działanie, jeśli chce zapobiec niszczeniu swej młodzieży przez te właśnie osoby, którym powierzono opiekę nad nią.


Do walki potrzebne są dwie osoby. W przypadku agresji interpersonalnej rzadko się zdarza, aby jedna osoba była zupełnie winna, druga zaś całkowicie niewinna. Częściej obie osoby biorą udział w eskalacji przemocy aż do punktu, w którym dochodzi do napaści. Schemat ten występuje w interakcjach między funkcjonariuszami policji a osobami aresztowanymi.


„Po przeprowadzeniu analizy 344 meldunków o aresztowaniu, Toch (1969) doszedł do wniosku, że w przypadkach, w których doszło do gwałtownych incydentów, obie strony reagowały na to, co spostrzegały jako zagrożenie swej integralności i szacunku dla samego siebie. Często starcie zaczynało się od czegoś, co mogło być niewinną prośbą funkcjonariusza o informację czy wylegitymowanie się lub poleceniem „proszę przechodzić”, „rozejść się”.  W 60% badanych przypadków cywil reagował negatywnie na zbliżenie się funkcjonariusza i odmawiał zastosowania się do jego prośby. Funkcjonariusz uważał tę odmowę za „irracjonalną”, świadczącą o braku szacunku, a być może wynikającą z chęci ukrycia przestępczego działania, podczas gdy dana osoba spostrzegała pierwotną prośbę czy polecenie jako nieuzasadnione lub nieuprzejme, czy też będące wyrazem osobistej wrogości. W ten sposób został zapoczątkowany łańcuch zdarzeń, w którym obie strony przyczyniały się do „rozkręcenia spirali przemocy”.


Z przeprowadzonej przez Tocha analizy tych incydentów wynika, że do aktu przemocy zazwyczaj dochodzi w wyniku typowego dwuetapowego procesu.  Pierwszym etapem jest jakieś działanie jednej z osób, które druga osoba uważa za |prowokację. W wielu incydentach z udziałem policji takim działaniem było pierwsze odezwanie się funkcjonariusza. Dla funkcjonariusza taka prośba czy polecenie było po prostu elementem jego pracy, lecz dla cywila było to zagrożenie jego osobistej godności i autonomii. Jest to wspólny wątek w najbardziej gwałtownych starciach - żaden z uczestników nie bierze pod uwagę punktu widzenia drugiej osoby.
Po takiej początkowej prowokacji, drugim etapem agresywnej interakcji jest |eskalacja i |konfrontacja. Każda z osób reaguje nie tylko na to, co czyni drugi człowiek, lecz także na spostrzegane przez siebie |intencje tego czynu, stopniowo podnosząc w ten sposób poziom agresywności. Eskalacja ta kończy się gwałtowną konfrontacją, o ile jedna ze stron nie przerwie tej sekwencji - na pchnięcie odpowiada się więc pchnięciem. W interakcjach między funkcjonariuszami policji a stawiającymi opór cywilami, prośby funkcjonariusza staja się w końcu rozkazami, a następnie posuwa się on do gróźb lub zatrzymania opornego obywatela. Cywil, z drugiej strony, często przechodzi od oporu do zniewag słownych, a następnie albo do próby ucieczki, albo do napaści na funkcjonariusza. Ponieważ te wzajemne prowokacje i eskalacje następują z coraz większą intensywnością, zaczynamy więc już rozumieć niektóre z przyczyn „zamieszek policyjnych”.


Rola ofiary. Aczkolwiek jest oczywiście wiele przypadków, w których przestępca atakuje nieznaną sobie osobę, to jednak statystyki przestępstw nie potwierdzają rozpowszechnionego wyobrażenia o obcym osobniku, który z ciemności napada na bierną, nie podejrzewająca niczego ofiarę z zamiarem wyrządzenia jej krzywdy. W ponad 75% wszystkich przypadków morderca i jego ofiara są krewnymi, przyjaciółmi lub znajomymi. Dwie trzecie wszystkich ofiar gwałtu podaje, że znało gwałciciela osobiście, zaś większość ofiar zbrodniczego napadu pozostawało uprzednio w jakichś stosunkach z napastnikiem.
Badanie przeprowadzone przez New York Police Department w trzech typowych dzielnicach miejskich dostarczyło pewnych interesujących danych, które pozostają w sprzeczności z powszechnie przyjmowanymi fałszywymi wyobrażeniami:


„Około 90% wszystkich ofiar morderstw, gwałtów i napadów jest napastowanych przez osoby tej samej rasy. Najczęstszymi ofiarami morderstwa są osoby ubogie, Murzyni, bezrobotni, wyobcowani, alkoholicy i narkomani.  Prawdopodobieństwo, że obrabowany zostanie człowiek ubogi, zarabiający mniej niż 3 tysiące dolarów rocznie, jest pięć razy większe niż w przypadku bardziej majętnego obywatela, zarabiającego 10 tysięcy dolarów rocznie” („San Francisco Chronicle”, 22 lutego 1970).


Potrzeba więcej badań koncentrujących się na działaniach ofiary, a zwłaszcza na „społecznym kontrakcie przemocy”, jaki istnieje między wieloma ofiarami a napastnikiem.




Zbliżenie


Syndrom szlemazela-szlemiela: uczenie się, jak być dobrą ofiarą


„Być może dlatego, że Żydzi jako grupa od dawna podlegali prześladowaniom, język żydowski (jidysz) ma bogaty zasób słów pozwalających rozróżnić rozmaite typy ludzi, którzy są ofiarami - losu, swego własnego braku rozsądku czy braku wrażliwości, własnych prowokacji, niewdzięczności swych dzieci itd.
|Szlemazel to osoba, która jest nieustannie sfrustrowana i zdaje się nigdy nie osiągać żadnej satysfakcji z życia; wydaje się, że tacy ludzie noszą ze sobą czarodziejską różdżkę przyciągającą zmartwienia. Fatalizm szlemazela może spowodować, że określa on sam siebie jako kogoś, na kogo zawsze „walą się kłopoty i nieszczęścia”; staje się on coraz bardziej skłonny do zachowywania się w sposób irytujący dla innych, prowokuje więc agresję - nawet ze strony przyjaciół i krewnych. Beznadziejny szlemazel staje się |szlemielem, gdy to destrukcyjne, samospełniające się proroctwo doprowadzi do tego, że inni zabawiają się kosztem jego nieszczęść”.


Co właściwie robi ofiara w tych przypadkach, w których istotnie odgrywa ona aktywną rolę (por. Ryan, 1977)? I co takiego czynią niektóre potencjalne ofiary, że potrafią skutecznie zahamować lub ograniczyć agresywne ataki?




Zbliżenie


Zmiana scenariusza


„Pewnego wieczoru, w dzienniku nadawanym na V kanale telewizyjnym w San Francisco, pokazano reportaż o obdarzonej szybką orientacją kasjerce banku w Sztokholmie, która zapobiegła obrabowaniu kasy bankowej. Jakiś mężczyzna, uzbrojony w rewolwer, wetknął głowę w drzwi banku i zawołał: „Czy są tu jakieś pieniądze?”. Kasjerka na pozór wcale nie przejęta niebezpieczeństwem, odkrzyknęła: „Bardzo mi przykro, proszę pana, ale starszy kasjer wyszedł na obiad. Czy jest może coś innego, czym mogłabym panu służyć?” Rabuś podziękował jej grzecznie, zamyślił się na chwilę, wsunął rewolwer do kieszeni i wyszedł” (30 sierpnia 1973).




Przemoc zbiorowa
i zinstytucjonalizowana




„W historii zbiorowa przemoc wynikała regularnie z zasadniczych procesów politycznych zachodzących w krajach Zachodu. Ludzie dążący do uchwycenia, utrzymania lub odzyskania steru władzy nieustannie uciekali się do zbiorowej przemocy. Uciśnieni zadawali ciosy w imieniu sprawiedliwości, uprzywilejowani - w imieniu porządku, ci, którzy byli pomiędzy nimi - w imieniu strachu” (Tilly, 1969, s. 4-5).


Z upływem lat zbiorowa i zinstytucjonalizowana przemoc przybierała wiele różnych form. Władze nieustannie nawoływały swych obywateli, aby chwytali za broń przeciw obcym napastnikom lub aby wyruszali na podbój nowych obszarów. W krajach takich jak Stany Zjednoczone, gdzie groźba napaści z zewnątrz była mała - na przykład przeciw Indianom amerykańskim, przemoc kierowano przeciw „wrogom” wewnętrznym - na przykład przeciw Indianom amerykańskim, których liczba została brutalnie zredukowana z 850 tysięcy do mniej niż 400 tysięcy w wyniku szeregu „potyczek”. Gdy władzy zaczynają uciskać naród, wówczas ludzie często łączą się, aby je obalić. Wielu rzezi dopuszczono się w imię zasad religijnych.
Chociaż niektóre z tych aktów przemocy były wyrazem uczuć nienawiści i gniewu, to jednak zbiorowa przemoc przeważnie ma charakter chłodno instrumentalny - stanowi środek do zrealizowania pewnego celu. Może być stosowana albo dla utrzymania władzy i zachowania status quo, albo w celu zmiany istniejącego społeczeństwa i zdobycia władzy.


„Na ulicach naszego kraju panuje niepokój. Uniwersytety są pełne studentów buntujących się i dopuszczających się ekscesów. Komuniści starają się zniszczyć nasz kraj. Rosja zagraża nam swą potęgą. Republika jest w niebezpieczeństwie. Tak, niebezpieczeństwo z wewnątrz i z zewnątrz.  Potrzebujemy prawa i porządku. Tak, bez prawa i porządku nasz naród nie może przetrwać (...). Przywrócimy prawo i porządek”.


Słów tych nie napisał kandydat na prezydenta Stanów Zjednoczonych w latach siedemdziesiątych naszego wieku, opowiadający się za „prawem i porządkiem”, lecz Adolf Hitler w 1939 roku. Uwypuklają one fakt, że istnieją pewne formy przemocy, które tradycyjnie uważa się za legalne, takie jak stosowanie przemocy przez państwo czy przez policję w celu utrzymania porządku i zapobieżenia przestępstwom. Wykazują one także, że ta legalność opiera się na zaakceptowaniu przez ludzi autorytetu ich instytucji. Gdy tej akceptacji zaczyna brakować, wówczas spostrzegana legalność kruszy się i każda ze stron uważa stosowanie przez siebie przemocy za uzasadnione i prawomocne, a przemoc stosowaną przez drugą stronę - za nieuzasadnioną i bezprawną.
To, co jedna osoba uważa za uzasadnioną przemoc, druga może uważać za nieuzasadnioną; na przykład, mieszkaniec getta może sądzić, że działania policji są bezprawnym zastosowaniem przemocy, podczas gdy mieszkaniec dzielnic willowych może aprobować fakt, że „policja robi to, co do niej należy”. Ogólnie biorąc, im bardziej negatywnie jest ktoś nastawiony do osób, przeciwko którym jest skierowana agresja, tym wyższy stopień przemocy będzie uważał za usprawiedliwiony. Osoba, która nie lubi protestujących studentów, będzie zatem prawdopodobnie opowiadać się za zastosowaniem maksymalnej siły przez policję w celu położenia kresu strajkom okupacyjnym i demonstracjom. Przemoc spostrzegana jest jako samoobrona lub odwet także prawdopodobnie będzie uznana za uzasadnioną. Ponieważ obie te wartości są tak powszechnie uznawane w naszym społeczeństwie, to można zastanowić się, w jakim stopniu mogą one kształtować pozytywne postawy wobec przemocy (Blumenthal, 1972).
Uchylanie się od płacenia podatków, ustalanie cen i wprowadzające w błąd reklamy to przykłady bardziej „legalnej” przemocy; są one zwykle tolerowane przez ogół społeczeństwa, czy to w wyniku nieświadomości, o co właściwie chodzi, czy to dlatego, że działalność taka jest mniej zagrażająca osobiście niż to, co ludzie uważają za „prawdziwe” przestępstwa, takie jak rabunek, napady czy gwałty. W klasycznych badaniach (Sutherland 1949), które objęły 70 największych towarzystw przemysłowych i handlowych w Stanach Zjednoczonych, stwierdzono, że wszystkie one były zaangażowane w różne rodzaje nielegalnej działalności. Wszystkie też były ścigane za różne przestępstwa, przy czym „przeciętne” towarzystwo otrzymało 14 wyroków.  Uwzględniając ten wysoki wskaźnik recydywy, 90% tych towarzystw można by, z prawnego punktu widzenia, uznać za nałogowych przestępców. Jednakże ludzie, którzy dopuszczają się tego rodzaju przestępstw, nie mają poczucia, że robią coś naprawdę złego:


„Biznesmeni różnią się od zawodowych złodziei przede wszystkim większą troską o swoją pozycję i szacunek ludzki. Uważają oni siebie za uczciwych ludzi, nie za przestępców, podczas gdy zawodowi złodzieje, gdy mówią szczerze, to przyznają, że są złodziejami. Biznesmen wprawdzie uważa siebie za osobę przekraczającą prawo, lecz sadzi, że prawa są złe lub przynajmniej, że nie powinny one go ograniczać, chociaż z powodzeniem mogą nakładać ograniczenia innym. Nie myśli on o sobie jako o przestępcy, ponieważ nie pasuje do popularnego stereotypu przestępcy. Zgodnie z tym popularnym stereotypem, przestępca zawsze wywodzi się z niższej klasy społeczno-ekonomicznej” (Sutherland, 1968).


Tego rodzaju postawa wobec przestępstw może być powodem, dla którego niektórzy ludzie sądzili, że uczestników spisku Watergate nie powinno się karać, ponieważ „nie byli oni typami przestępczymi”.




Patologia w ośrodkach
miejskich




Miasta zawsze przyciągały ludzi, ze względu na możliwości ekonomiczne, jakie stwarzają, a także z powodu swych funkcji kulturalnych i społecznych.  Ośrodki miejskie są tym miejscem, „gdzie coś się dzieje”.
Lecz obecnie dla wielu ludzi dzieje się tam zbyt wiele, zbyt szybko - w sposób zbyt nieprzewidywalny i nie poddający się kontroli. Tempo wzrasta non stop; występuje zbyt silna rywalizacja o ograniczone i często pogarszające się środki i zasoby (takie, jak taksówki, miejsca siedzące w komunikacji miejskiej, miejsca w przedszkolach); jest też zbyt wielu ludzi chcących się nam przeciwstawić, zbyt wiele nieuprzejmości i zbyt mało zainteresowania ze strony sąsiadów.
Zalety miejskiego stylu życia są w coraz większym stopniu niwelowane przez konieczność przystosowania się do sensoryczno-poznawczego przeciążenia i stresu, jaki stwarza tego rodzaju życie.
Chociaż miasta charakteryzuje najwyższy stopień panowania techniki nad przyrodą, to jednak zaczęły one ograniczać zdolność żyjących w nich osób do regulowania jakości własnego życia. Istotnie, nasze wielkie miasta coraz bardziej stają się ośrodkami nierozwiązywalnych problemów oraz źródłem patologii i destrukcji dla tych, którzy muszą żyć w ich betonowych murach.
W lecie 1970 roku zmiana temperatury spowodowała zaleganie silnie nagrzanego powietrza i zanieczyszczeń atmosfery w postaci dymów i gazów nad Nowym Jorkiem, co spowodowało wzrost temperatury i utrudniało oddychanie.  Rozwiązanie techniczne było proste: wszędzie włączono klimatyzację i urządzenia zmniejszające wilgotność powietrza. Jednakże zapotrzebowanie na energię elektryczną znacznie przewyższało jej podaż, co doprowadziło do redukcji mocy nie tylko dla urządzeń klimatyzacyjnych, lecz także dla kolei podziemnych.
Zwiększyło to frustrację wysadzanych z pociągów i spóźniających się pasażerów - wielu z nich zaczęło dojeżdżać do pracy własnymi samochodami.  Oczywiście zwiększony ruch samochodów w mieście, które już uprzednio było nadmiernie zatłoczone, nie tylko spowodował tworzenie się doprowadzających do szaleństwa zatorów i „korków”, lecz także zwiększył stopień zanieczyszczenia powietrza. Ten sam skutek miały wzmożone wysiłki przedsiębiorstw użyteczności publicznej, aby dostarczyć więcej energii elektrycznej. Wszystko to było po prostu jeszcze jednym z długiego szeregu nie kończących się problemów, jakie stwarza nadmierne zagęszczenie ludności: niewystarczające środki na oczyszczanie miasta i wywóz śmieci, źle działająca sieć telefoniczna, hałas, zatłoczone szkoły, niebezpieczne dla życia ulice i wiele innych.
W wielkich miastach stało się pewnikiem, że rozwiązanie każdego problemu staje się przyczyną nowego. Wielu mieszkańców śródmieścia, gdy tylko może sobie na to pozwolić, przenosi się do dzielnic podmiejskich, gdzie może znaleźć lepsze szkoły, więcej przestrzeni, przyrodę oraz mieć własny dom.  Jeśli jednak pracują w śródmieściu, to muszą codziennie jeździć tam i z powrotem. Aby uniknąć zatorów na ulicach śródmieścia, frustracji związanych ze znalezieniem miejsca na zaparkowanie wozu oraz sporych opłat za parkowanie, powiększają oni rzeszę dojeżdżających do pracy pociągami podmiejskimi. Jakie jednak są koszty psychiczne dojeżdżania do pracy?


„Pewien psychiatra rozdał 100 kwestionariuszy wśród tłumu osób oczekujących na pociąg o godzinie #7/#12 z Long Island do Manhattanu. Na podstawie 49 wypełnionych kwestionariuszy ustalono, że przeciętny dojeżdżający dopiero co połknął w pośpiechu śniadanie, w ciągu mniej niż 11 minut, albo nie jadł w ogóle; jest przygotowany na to, że dojazd zabierze mu trzy godziny każdego dnia; ma już za sobą 10 lat dojeżdżania - w sumie około 7500 godzin, zakładając dwutygodniowy urlop i żadnych zwolnień chorobowych. Dwie trzecie dojeżdżających było przekonanych, że dojeżdżanie wywarło ujemny wpływ na ich stosunki rodzinne, 59% odczuwało zmęczenie, 47% było pełnych świadomego gniewu, 28% uskarżało się na lęk, innym zaś dolegały bóle głowy, mięśni, niestrawność oraz inne objawy długotrwałych następstw tego codziennego „wyścigu szczurów” do miast”a (Charatan, 1973).




* * *



Ryc. 14.8. W roku 1968 strajki w Nowym Jorku przeprowadzili w kilkudniowych odstępach śmieciarze, nauczyciele, policjanci i robotnicy portowi.


* * *





Jakkolwiek takie życie jest męczące, to jednak dojeżdżający ma przynajmniej świadomość, że każdego wieczoru ucieka od coraz silniejszego uczucia strachu i poczucia patologii społecznej, które okaleczają emocjonalnie wiele osób nie dość zamożnych, aby przenieść się do dzielnicy podmiejskiej lub pozwolić sobie na luksus dobrze zabezpieczonego mieszkania. Zamieszczony niżej apel pewnego przerażonego mężczyzny, schwytanego w pułapkę śródmiejskiego getta, miałby aż nazbyt wielu sygnatariuszy.




Zbliżenie


„Jestem przerażonym człowiekiem”


„Panie Redaktorze,

pewnego wieczoru nie wrócę do domu do mojej żony i czteroletniego synka.  Stanę się ofiarą jednej z licznych band rabunkowych, które przekształciły ulicę Bedford-Stuyvesant-Williamsburgh w asfaltową dżunglę pełną terroru i przemocy, której obiektem są moi sąsiedzi - Murzyni i Portorykańczycy - a także ja sam i moja rodzina.
Jestem Murzynem i pochodzę z Porto Rico. Wychowywałem się w Harlemie i Wschodnim Harlemie, pomiędzy walczącymi ze sobą gangami. Jako młody człowiek wracałem do domu późna nocą - po całodziennej pracy uczyłem się w wieczornym college’u. W ciągu 39 lat mojego życia nigdy przedtem nie bałem się naprawdę o swoje bezpieczeństwo. Obawiałem się o swoją matkę, swego syna, swoją żonę i innych krewnych, których kochałem, lecz nigdy o siebie samego. Teraz boję się, boję się naprawdę, ponieważ widzę, że przyjdzie kolej na mnie i czuję się absolutnie bezradny.
Chcę zobaczyć, jak mój syn wyrasta na szczęśliwego, odnoszącego sukcesy i szanowanego człowieka. Najbardziej przerażająca jest świadomość, że obecnie szanse na taki obrót spraw są bardzo małe.
Tak wielu moich przyjaciół, sąsiadów i krewnych zostało napadniętych, obrabowanych, zaduszonych lub zakłutych nożem, że zdaję sobie sprawę z tego, iż to, kiedy przyjdzie moja kolej, jest tylko sprawą dni lub nawet godzin. 
Jest to jeszcze straszniejsze dlatego, że obecnie po raz pierwszy wiem, jak czuje się bezradny starzec, kobieta lub dziecko, gdy idą ulicą w zapadających wcześnie ciemnościach. Wylęknieni i całkowicie bezradni, gdy w pobliżu nie ma żadnego policjanta i gdy wiedzą, że nikt nie zechce przyjść im z pomocą.
Nie jestem już zadziornym, gotowym do walki byłym sierżantem piechoty morskiej. Jestem przerażonym człowiekiem wracającym wieczorem z pracy do domu, oglądającym się na wszystkie strony, zastanawiającym się, czy „załatwią” mnie tego właśnie wieczoru.
Czy spotka mnie to w wyjściu z metra, gdzie żarówki są potłuczone prawie każdego wieczoru, na ulicy, gdy będę przechodził obok jednej z wielu pustych parcel lub opustoszałych domów, czy też na schodach przed moimi drzwiami, gdy będę wkładał klucz do zamka?
Wiem, że jest już za późno, abym ocalił swoje życie, lecz modlę się, aby ludzi i nasi przywódcy ocknęli się, zorganizowali, przestali być pobłażliwi i skończyli wreszcie z tymi szkodliwymi narkotykami i brakiem szacunku dla władzy, co moim zdaniem jest przyczyną tego ogromnego wzrostu liczby przestępstw przeciw życiu imieniu.
Będziemy wówczas mogli ocalić życie naszych dzieci i niezliczonych innych ludzi, którzy zasługują na życie wolne od strachu przed nagłą śmiercią lub choćby przed brutalną napaścią. Ludzie będą wówczas mogli skoncentrować się na najpełniejszym przeżywaniu swego życia, na tym, aby mogli być szczęśliwi, radośni i pełni miłości dla ludzkości, a ich bliźni będą im odwzajemniać się tymi samymi uczuciami”.


Brooklyn, 30 stycznia 1972  Loui S. Campbell


Więcej morderstw jest popełnianych każdego roku na Manhattanie niż w całej Anglii i Walii (które mają blisko 30 razy więcej mieszkańców). W pewnej dzielnicy Harlemu, o wysokim wskaźniku przestępczości, na każdych |pięciuset ludzi idących ulicą jeden stanie się ofiarą zabójstwa w ciągu tego roku. Więcej niż połowa osób, z którymi przeprowadzono wywiad w pewnej dzielnicy o wysokim wskaźniku przestępstw, czuło się zagrożonych i było przekonanych, że ich społeczność nie jest dobrym miejscem do wychowywania dzieci; w dzielnicy podmiejskiej osób takich było mniej niż 5% (Conklin, 1971).




Pomocy! Kto mi
przyjdzie z pomocą?




Do najpotężniejszych sił przyczyniających się do degradacji natury ludzkiej należą warunki społeczne, które pozwalają człowiekowi być blisko wielu innych ludzi, a jednak czuć się wyobcowanym spośród nich.


W wielkim mieście człowiek jest otoczony setkami tysięcy innych ludzi, słyszy ich przez radio, ogląda ich w telewizji, je razem z nimi w restauracjach, siedzi obok nich w kinach, czeka razem z nimi w kolejkach, tłoczy się z nimi w pociągach i autobusach, dotyka ich - lecz pozostaje nieporuszony, nie związany z nimi, jak gdyby oni wcale nie istnieli.
Dla pewnej kobiety w dzielnicy Queens rzeczywiście oni nie istnieli.
„Przez więcej niż pół godziny 38 szacownych, przestrzegających prawa obywateli w dzielnicy Queens (Nowy Jork) obserwowało, jak morderca ścigał i kłuł nożem pewną kobietę na Kew Gardens, trzykrotnie ponawiając napaść.  Dwukrotnie dźwięk ich głosów oraz nagłe zapalenie się światła w ich sypialniach przeszkodziło mu i odstraszyło go. Za każdym razem powracał, odszukiwał ją i ponownie zadawał jej ciosy nożem. Żadna z tych osób nie zatelefonowała na policję w czasie tej napaści; jeden świadek zatelefonował na policję, gdy kobieta ta była już martwa” („The New York Times”, 13 marca 1964).


Ten dziennikarski opis morderstwa Kitty Genovese wstrząsnął narodem, który nie mógł pogodzić się z myślą, o takiej bierności ze strony swych odpowiedzialnych obywateli. Jednakże dopiero po paru miesiącach w gazetach ukazał się jeszcze bardziej jaskrawy i wstrząsający opis, ukazujący, jak bardzo wyobcowanym i samotnym można być wśród ludzi. Wyobraź sobie przez chwilę, że znajdujesz się w położeniu 18 -letniej sekretarki, która była bita, duszona, potem obdarta z odzieży i zgwałcona w swoim biurze, a w końcu wyrwała się napastnikowi. Naga i krwawiąca zbiegła na dół po chodach budynku do drzwi wejściowych, krzycząc: „Pomóżcie mi! Pomóżcie mi! On mnie zgwałcił!” Na ruchliwej ulicy zgromadził się tłum złożony z 40 osób i patrzył biernie, jak gwałciciel ciągnął ją z powrotem w górę po schodach.  Dopiero przypadkowe przybycie przejeżdżającej właśnie policji przeszkodziło w dalszym jej maltretowaniu, a może i morderstwie („The New York Times”, 6 maja 1964).
Czy |ty wezwałbyś policję, gdybyś mieszkał na Kew Gardens? Czy interweniowałbyś, aby pomóc gwałconej kobiecie? Czy ty (kiedy nadarzy ci się szansa) zrobisz cośkolwiek inne poza „zajęciem się swymi własnymi prawami?”




Zbliżenie


Naoczny świadek


„Ja byłem tym, który znalazł się w centrum wydarzeń Ja byłem pierwszy na miejscu zbrodni. Ja przyniosłem najnowszą sensację ja nie traciłem czasu.
Ja zobaczyłem swoje nazwisko w gazetach. Ja zobaczyłem swoją twarz w telewizji. Ja miałem materiał, który mogli wykorzystać; ja dostałem za to niezłe pieniążki.
Ja widziałem, jak ciężarówka stuknęła taxi; ja widziałem mężczyznę z rewolwerem; ja widziałem zderzenie i rabunek; jak widziałem, jak zginął kierowca.
Ja widziałem, jak ta banda uciekała; oni przemknęli tuż, blisko mnie, ja mógłbym - co ty mówisz? Dlaczego ich nie |zatrzymałem? Kto! |Ja?”
(Peter Suffolk)


Im więcej osób może przyjść ci z pomocą - tym trudniej o pomoc. Czy niepodejmowanie interwencji w sytuacjach nagłej potrzeby wynika z jakichś defektów osobowościowych obecnych tam widzów, czy też można je przypisać istniejącym warunkom uczenia się społecznego, które mogłyby wpłynąć w ten sposób na każdego?
„Dwaj psychologowie społeczni postanowili odpowiedzieć na to pytanie, w pomysłowy sposób stwarzając w laboratorium eksperymentalny odpowiednik sytuacji wymagającej interwencji przypadkowego świadka. U studenta, który znajdował się sam w pomieszczeniu, wytwarzano przekonanie, że porozumiewa się z innymi studentami przez wewnętrzny telefon. W trakcie dyskusji o problemach osobistych słyszał on coś, co brzmiało tak, jak gdyby jeden z pozostałych studentów miał napad padaczki. Osoba badana słyszała, jak dysząc i łapiąc z trudem oddech wzywał pomocy przez telefon:
„Ja - ech - um - ja myślę, że - że trzeba - ech, żeby ktoś - ech - ech - ech - ech - ech przyszedł mi - ech przyszedł mi z pomocą, ponieważ - ech - ech - ech mam na - naprawdę poważne trudności - ech - ech, właśnie teraz i ech - ech, gdyby ktoś mógł mi pomóc, to byłoby - to byłoby - ech - ech z - z pewnością dobrze... Ponieważ ech - ech - chodzi o to, że ja ech - ja dostałem je - jednego z tych - ech - ech - napa - ech - sprawa ma się coraz gorzej i - i - i mnie naprawdę ech - ech przydałaby się jakaś pomoc, więc gdyby ktoś ech - ech pomógł mi trochę - ech - ech - ech - ech, g - gdyby ktoś - ech - ech - ech - pomógł - ech - uch - uch - uch (dźwięki krztuszenia się) ... ja umie - ech - ech - ja... umieram - ech - ech - pomocy - ech - ech, napad - ech - ech (krztusi się, potem cisza)”.
W czasie tego „napadu” osoba badana nie miała możliwości porozumienia się z innymi studentami ani ustalenia, czy robią oni coś - i co - w sprawie tego wypadku. Zmienną zależną była szybkość, z jaką osoba badana zawiadamiała o wypadku eksperymentatora. Główną zmienną niezależną było liczba ludzi, którzy - jak sądził badany - wchodzili w skład grupy dyskusyjnej wraz z nim.
Okazało się, że prawdopodobieństwo interwencji zależało od liczby świadków, którzy - w przekonaniu badanego - byli przy tym obecni. Im więcej ich było, tym później badany zawiadamiał eksperymentatora o wypadku, jeśli w ogóle to czynił. Jak wynika z wykresu na rycinie 14.9, każdy badany w grupie dwuosobowej interweniował w ciągu 160 sekund, lecz prawie 40% badanych w większej grupie wcale nie zadało sobie trudu, aby poinformować eksperymentatora, że jeden ze studentów być może jest umierający. Zestaw różnych narzędzi do pomiaru osobowości, którymi zbadano każdego studenta biorącego udział w eksperymencie, nie wykazał żadnego istotnego związku między poszczególnymi cechami osobowości a szybkością czy prawdopodobieństwem interwencji” (Darley i Latane, 1968).




* * *



Ryc. 14.9. Interwencja Świadków Wypadku


* * *





Podobne badania wykazały, że twoje szanse otrzymania pomocy w sytuacji zagrożenia są większe, jeśli przypadkowi świadkowie są: Murzynami, a nie białymi, mężczyznami, a nie kobietami, należą do jakiejś grupy o charakterze formalnym, a nie towarzyskim i są właśnie w dobrym nastroju.  Ponadto interwencja świadków jest bardziej prawdopodobna, jeśli widzieli oni podobnego do siebie modela, pomagającego komuś innemu w krytycznej sytuacji, natomiast jest mniej prawdopodobne, jeśli inne obecne w sytuacji zagrożenia osoby, które nie udzielają pomocy, są spostrzegane jako podobne do nich. I wreszcie otrzymanie przez ciebie pomocy będzie zależało od tego, w jakim stopniu dana sytuacja jest wyraźnie określona jako sytuacja zagrożenia; od tego czy starasz się, jeśli jest to możliwe, pomóc samemu sobie; i od tego, czy sytuacja ta nie jest sytuacją formalną, ustrukturalizowaną.




Zbliżenie


Interwencja przygodnych świadków: laboratorium a świat realny


„Aczkolwiek badania laboratoryjne nad interwencją przygodnego świadka pomogły określić niektóre z warunków decydujących o tym, czy widzowie przyjdą z pomocą, czy też pozostaną bierni, to jednak występuje ciekawa rozbieżność, gdy porównujemy częstość interwencji w badaniach laboratoryjnych z zachowaniem w warunkach naturalnych. Dokładny przegląd literatury z tego zakresu ujawnił, ze „badania terenowe bez wyjątku wykazały znacznie |większą gotowość do interwencji ze strony przygodnych świadków, niż wskazywałyby na to badania laboratoryjne” (Warner, 1972). 


Co powoduję tę różnicę? 
Porównajmy następujący eksperyment terenowy z eskperymentami Latanego i Darleya. Pewien człowiek w wagonie nowojorskiego metra nagle chwieje się i pada na podłogę. Naocznymi świadkami tego zdarzenia jest wiele osób jadących do pracy lub z pracy, udających się na zakupy itd.  Eksperymentatorzy manipulowali tą sytuacją zmieniając „cechy ofiary” - był to inwalida o lasce lub pijak cuchnący wódką albo też, w równolegle przeprowadzanym badaniu inwalida na pozór krwawiący (lub niekrawiący) z ust. W czasie eksperymentu dyskretnie zapisywali oni reakcje świadków na te wydarzenia.
Jest zaskakujące (w świetle zarówno niskiej częstości interwencji w badaniach laboratoryjnych, jak i artykułów w dziennikach o „nieczułym” wielkomiejskim tłumie), że prawie we wszystkich wypadkach (81 ze 103) jedna lub więcej osób reagowało bezpośrednio i czyniło to po niedługim wahaniu! Pomoc nadchodziła z większym opóźnieniem, gdy pozorny koszt interwencji był wyższy (to jest z większym opóźnieniem w przypadku krwawiącej ofiary niż zwykłego zemdlenia), ale jednak nadchodziła, choćby w pośredniej formie, takiej jak na pytanie: „Czy jest w pociągu lekarz?” (Piliavan, Rodin i Piliavan, 1969; Piliavan i Piliavan, 1972).
Skąd ta różnica? W środowisku laboratoryjnym powstrzymywanie się od przychodzenia z pomocą może wynikać z następujących przyczyn: a) badani studenci przyjęli już |bierną rolę „osoby badanej”, b) zakładają oni, że w ostatecznym rachunku eksperymentator „na służbie” jest odpowiedzialny za wszystko, co zdarza się w trakcie posiedzenia eksperymentalnego, które samo w sobie jest sytuacją sztuczną, c) często w rzeczywistości nie widzą oni cierpiącej ofiary i wreszcie d) ich ruchliwość fizyczna jest poważnie ograniczona przez podporządkowanie się niepisanemu prawu obowiązującemu w laboratorium: „Masz pozostawać na swoim miejscu; masz siedzieć i wypełniać instrukcje, o ile nie otrzymasz innego polecenie”. W nieustrukturalizowanych, nieformalnych sytuacjach nie występuje żaden z tych czynników i decyzja podjęcia interwencji jest prawdopodobnie w większym stopniu oparta na wyważeniu przez obserwatora osobistych kosztów interweniowania lub nieinterweniowania.


Spóźnię się! Spóźnię się na Bardzo Ważne spotkanie. Nie mam czasu, żeby powiedzieć „Cześć”. Do widzenia, już jestem spóźniony”.
I’am late (Jestem spóźniony) z „Alice in Wonderland”, 1949 (filmowa adaptacja „Przygód Alicji w Krainie Czarów” L. Carolla)


Nie mam czasu, aby powiedzieć „Cześć”. Jedną z najbardziej niepokojących cech naszego współczesnego sposobu życia jest to, że wszystko zdaje się przebiegać i zmieniać szybciej, niż jesteśmy w stanie psychicznie sie z tym uporać. Zwłaszcza w wielkich miastach, wszystko co nieruchome zostaje ukarane mandatem, odholowane lub pogrzebane.
Godny uwagi eksperyment, który przeprowadzili Darley i Batson na Princeton University (1973) wykazał ostatecznie, w jakim stopniu ciągły pośpiech może zniszczyć same podstawy życia społecznego.


„40 studentów przygotowujących się do pracy duszpasterskiej w Princeton Theological Seminary zgłosiło sie na ochotnika do badań, rzekomo nad kształceniem religijnym i powołaniem do stanu duchownego. Po otrzymaniu w jednym budynku instrukcji dotyczącej udziału w tych badaniach, każdy student miał zgłosić się w drugim budynku w celu wygłoszenia przemówienia.  Niektórzy z niech mieli powiedzieć o tym, jakiego rodzaju prace studenci seminarium potrafiliby dobrze wykonywać; pozostali przygotowali się do wygłoszenia kazania na temat przypowieści i miłosiernym Samarytaninie. Ta przypowieść pochodzi z Ewangelii Świętego Łukasza, rozdział X:
„Pewien człowiek szedł z Jerozolimy do Jerycha i wpadł w ręce zbójców, którzy go obrabowali, poranili i odeszli, zostawiając go na pół umarłego.  Przypadkiem szedł ta drogą jakiś kapłan i zobaczywszy przeszedł mimo.  Podobnie i Lewita, gdy przyszedł na to miejsce i zobaczył go, przeszedł mimo. Pewien Samarytanin zaś, podróżując tędy, podjechał do niego i ujrzawszy, ulitował się nad nim. I podszedłszy opatrzył rany jego, zalewając je oliwą i winem, po czym wsadził go na swoje bydlę, zawiózł do gospody i opiekował się nim” (Tłumaczenie Komisji Przekładu. Warszawa 1979).
Zanim każdy ze studentów seminarium wyszedł z budynku, aby wygłosić swoje przemówienie, eksperymentatorzy w systematyczny sposób manipulowali jego przekonaniem o tym, ile czasu ma on na dotarcie do drugiego budynku.
Niewielki pośpiech: „Jest jeszcze parę minut, zanim oni będą gotowi na twoje przybycie, lecz jest również możliwe, że wkrótce będziesz zaczynać.  Jeśli będziesz musiał poczekać, nie będzie to trwało długo”.
Średni pośpiech: „Pomocnik jest już gotowy na twoje przybycie, więc idź prosto do niego”.
Duży pośpiech: „Ach, już jesteś spóźniony. Oni czekają na ciebie od kilku minut. Lepiej nie zwlekaj. Pomocnik będzie czekał na ciebie, więc lepiej pośpiesz się”.
Zgadnij, kogo spotkał badany, gdy podążał alejką do drugiego budynku? W bramie leżał oczywiście mężczyzna - kaszlący, jęczący, głowa na ziemi, oczy zamknięte. Nadarzała się sposobność, aby być Dobrym Samarytaninen, aby zatrzymać się i pomóc biednej ofierze. „Ofiara” ta, która nie wiedziała, do jakiej grupy eksperymentalnej należał każdy z badanych, zapisywała, czy dany student pomógł jej, czy nie, a także, jakiego rodzaju pomoc zaproponował. Badani studenci seminarium wygłaszali w końcu swoje przemówienia, wypełniali kwestionariusz, który zawierał pytania dotyczące udzielania pomocy ludziom w potrzebie, a zwłaszcza tego, kiedy po raz ostatni widzieli taką potrzebującą osobę i czy jej pomogli. Następnie wyprowadzano ich z błędu co do charakteru badań i wyjaśniano dokładnie cel eksperymentu.
Wyniki były zaskakujące i przygnębiające: ogółem 60% badanych |nie zatrzymało się, aby pomóc ofierze. Fakt, że mieli zamiar wygłosić kazanie o Dobrym Samarytaninie nie miał żadnego wpływu na zwiększenie prawdopodobieństwa, że postąpią tak jak on. Jest rzeczą szczególnie znamienną, że to, czy ktoś zatrzyma się w celu udzielenia pomocy, najlepiej można było przewidzieć na podstawie zmiennej sytuacyjnej - jak bardzo się spieszył. Spośród tych, którzy się nie spieszyli, pomogło 63%, spośród spieszących się średnio pomogło 45%. Tylko 10% badanych studentów seminarium, którzy byli już spóźnieni, biegnąc w wielkim pośpiechu, aby wygłosić kazanie o Dobrym „Samarytaninie”, zatrzymało się, aby pomóc bliźniemu potrzebującemu pomocy”.


Nie byli to twardzi, nieczuli ludzie, lecz jednostki, które wypełniały pewne wcześniejsze zobowiązanie, pozostające w sprzeczności z koniecznością zatrzymania się w celu udzielenia pomocy.




Nadmierne zagęszczenie




W jakim stopniu fizyczny fakt nadmiernego zagęszczenia ludności prowadzi do wrogości i schorzeń społecznych - widocznych w takich miastach, jak Nowy Jork, Filadelfia, Newark, Detroit, Chicago, Tokio, Kalkuta, Londyn i inne?
Najbardziej dokładne badania nad związkami pomiędzy liczebnością populacji, środowiskiem fizycznym i społeczno-emocjonalnym zachowaniem zwierząt prowadził w ciągu 20 lat John Calhoun (1962, 1971) w National Institute of Mental Health (Narodowy Instytut Zdrowia Psychicznego).  Kolonie dzikich bądź oswojonych szczurów lub myszy hodowano w sztucznych środowiskach, w których skutki wzrostu liczebności populacji można było obserwować w ciągu kilku pokoleń.


„W jednej serii eksperymentów stworzono coś w rodzaju „osiedla mieszkaniowego”, w którym były cztery połączone ze sobą pomieszczenia mieszkalne, do których zwierzęta mogły się przedostać po skręconych schodach. Aby dojść do końcowych pomieszczeń, zwierzęta musiały przechodzić przez pomieszczenia środkowe, które wkrótce stały się ośrodkami aktywności społecznej. Gdy populacja wzrosła do ponad 80 szczurów - optymalną liczbą było 48 zwierząt - zaczęły u nich występować destrukcyjne, zagrażające życiu zachowania.
Pomimo obfitości zasobów fizycznych, takich, jak pokarm i materiały do budowy gniazd, występowały często złośliwe walki między samcami, jak również niesprowokowane napaści na samice i młode. Niektóre samce były niezwykle agresywne, podczas gdy inne „wycofały się” i stały sie bierne.  Ogromnie wzrosła częstość przypadków hiperseksualizmu, homoseksualizmu oraz biseksualizmu. Porządek społeczny załamał się całkowicie, do tego stopnia, że samice ignorowały takie normalne czynności, jak budowanie gniazd i opieka nad małymi, zdarzały sie przypadki kanibalizmu i żadne z młodych nie osiągnęło dojrzałości.
W innej wersji, w której pomieszczenia mieszkalne były usytuowane wokół otwartej przestrzeni, przy czym również zapewniono obfitość pokarmu i materiału do budowy gniazd, jak również ochronę przed zarazkami, prześladowcami oraz deszczem czy śniegiem, oznaki załamania wystąpiły wtedy, gdy wszystkie pożądane miejsca w przestrzeni fizycznej oraz wszystkie role społeczne zostały zajęte. Dominujące samce zaczęły się załamywać wyczerpane obroną swych terytoriów. Samice wcześniej wypędzały swe młode z gniazd i stawały się bardziej agresywne i dominujące. Młode, dorosłe osobniki przestały walczyć o własne terytorium i przyjęły patologiczny sposób życia „na ulicach”, na dużej otwartej przestrzeni.  Zwierzęta przestały się rozmnażać. Ostatnia mysz zdechła przed upływem 5 lat od rozpoczęcia tego badania” (ryc. 14.11).


Jak przekonaliśmy się w Rozdziale 9, kiedy stres jest długotrwały i nieustanny, gruczoły nadnerczy pracują ponad miarę, by utrzymać produkcję hormonów potrzebnych do reakcji obronnych; powiększają sie i w końcu mogą być w ogóle niezdolne do reagowania. Ponadto rozwój organizmu ulega zahamowaniu, zmniejsza się odporność na infekcję, zmienia się skład krwi, różne narządy wewnętrzne wykazują zmiany zwyrodnieniowe, a narządy rozrodcze albo przestają funkcjonować, albo funkcjonują w sposób niepełny.  Nadmierne zagęszczenie i dezorganizacja społeczna w koloniach Calhouna stwarzały stres wystarczający do spowodowania tych zmian.




* * *



Ryc. 14.11. Dr John B. Calhoun pogląda na Universum 25, teraz już nazwane Martwym Miastem („Dead City”) - miejsce zamieszkania około 2200 myszy, które w końcu wymarły. Rozchodzące się promieniście prenty były ulicami, miejsce ich złączenia - miejskim placem zebrań. Butelki dostarczały potrzebnej ilości wody, a druciane koszyki - pokarmu.


* * *





Analogie między wynikami uzyskanymi przez Calhouna a przemocą, wandalizmem, perswersjami seksualnymi oraz ogólnym odrzuceniem reguł etycznych w życiu społecznym naszych wielkich miast są aż nazbyt oczywiste.  Jednakże nie wiemy, jak dalece wyniki te stosują się do istot ludzkich ani też, jaką właściwie rolę może w tym wszystkim odgrywać nadmierne zagęszczenie ludności. Jest to zupełnie nowa dziedzina badań i niewątpliwie istniejące związki są bardziej złożone, niż myślano początkowo.
Na przykład, wiele zależy od tego, czy osoby badane dysponują swoim osobistym „terytorium”, takim jak biurko czy krzesło, czy wymaganych jest wiele czy mało interakcji i czy eksperymentator bada wpływ |zagęszczenia |przestrzennego (ta sama liczba ludzi na różnych przestrzeniach), czy też |zagęszczenia |społecznego (więcej lub mniej ludzi na tej samej powierzchni). Różnice wieku, różnice kulturowe, oczekiwania oraz czas trwania „zagęszczenia” również pomagają w określeniu jego skutków.  Najważniejszy ze wszystkiego wydaje się sposób, w jaki dana jednostka interpretuje i ocenia zagęszczenie. Podczas gdy nadmierne zagęszczenie zdaje się oddziaływać na myszy i szczury w sposób jednoznacznie określony i przewidywalny, to jego wpływ na zachowanie ludzkie zachodzi za pośrednictwem mnóstwa innych zmiennych, spośród których wiele ma charakter „subiektywny” (zob. Loo, 1972 oraz Freedman i in., 1972).




Anonimowość
i dezindywidualizacja




Życie wśród obcych, z którymi ma się tylko powierzchowne i nieosobiste kontakty, może prowadzić do apatii, alienacji oraz cynizmu jako sposobu radzenia sobie z przeciążeniem - ludzie starają się zachować dystans psychiczny i nie dać się „nabrać”. W pewnym interesującym eksperymencie terenowym wykazano, w jakim stopniu u mieszkańców wielkich miast rozwinął się brak wzajemnego zaufania.


„Badacze, rekrutujący się spośród studentów obojga płci, pracujący pojedynczo, dzwonili do drzwi mieszkań w domach zamieszkałych przez ludzi o średnim poziomie dochodów, na Manhattanie oraz w małych miasteczkach w okolicznych okręgach. Prosili oni o pozwolenie korzystania z telefonu, wyjaśniając, że zapomnieli adresu przyjaciela, który mieszka w pobliżu.  Badacze chcieli się przekonać, czy będzie różnica między mieszkańcami wielkiego miasta i małych miasteczek  pod względem gotowości przyjścia z pomocą obcemu człowiekowi, przychodzącemu z taką prośbą.
Różnice były uderzające. Studentom pozwolono wejść do połowy mieszkań w małych miasteczkach, lecz tylko do 14% mieszkań w dużym mieście. Studentki wpuszczono do 94% mieszkań w miasteczkach, lecz tylko do 60% mieszkań w dużym mieście” (Altman, Levine i Nadien, 1970).


Życie w wielkim mieście nie tylko pozbawia ludzi wielu potencjalnych korzyści, płynących z życia społecznego, lecz często odbiera im jeden z najcenniejszych darów - poczucie osobistej tożsamości i niepowtarzalności.  Jednostka, chociaż jest otoczona przez ludzi, to jednak staje się anonimowa. W takich warunkach człowiek łatwo dochodzi do przekonania, że „nikt nie wie, ani nie dba o to, kim ja jestem - dlaczego więc ja miałbym dbać o kogoś innego?”
Własna anonimowość zmniejsza szansę otrzymania zarówno należnej nagrody za pożyteczne społecznie zachowanie, jak i kary za zachowanie antyspołeczne. Emocje lub impulsy, które w innych warunkach byłyby powściągane wskutek podporządkowania się normom społecznym i obawy przed dezaprobatą społeczną, mogą ujawnić się pod maską anonimowości.


„W pewnym eksperymencie laboratoryjnym w niektórych losowo wyznaczonych grupach studentek stworzono warunki anonimowości, polecając im nałożyć workowate fartuchy i kaptury, które zasłaniały im twarze. Ponadto siedziały one w zaciemnionym pomieszczeniu i nigdy nie zwracano się do nich po imieniu ani po nazwisku. W pozostałych grupach stworzono warunki, które podkreślały indywidualność osób badanych: nosiły one tabliczki z nazwiskami, często wołano je imieniem i nazwiskiem i widziały twarze innych studentek w swojej grupie.


Każda grupa składała się z czterech osób. 
Osobom badanym powiedziano, że eksperymentator prowadzi badania nad empatią. Wstrząsy elektryczne miały być wymierzane dwu młodym kobietom (które rzekomo brały udział w eksperymencie nad warunkowaniem). Dwie osoby badane wymierzały wstrząsy, podczas gdy dwie pozostałe spełniały jedynie rolę obserwatorów; następnie wszystkie dokonywały ocen empatii. Aby ustalić, kto będzie wymierzał wstrząsy, ciągnęły one losy (losowanie to zostało zaaranżowane w taki sposób, że każda osoba badana była przekonana, iż będzie jedną z dwóch wymierzających wstrząsy). Podczas wymierzania wstrząsów, każda z czterech osób badanych znajdowała się w oddzielnej kabinie, tak że nie mogła widzieć pozostałych badanych.
Badanym polecono, aby naciskały przycisk włączający prąd za każdym razem, gdy zapali się zielona lampka; inna lampka zapalała się wskazując, że prąd jest włączony i paliła się tak długo, dopóki którykolwiek z przycisków włączających prąd był naciśnięty (maksymalny czas włączenia prądu wynosił 2,5 sekundy). U badanych wytworzono przekonanie, że prąd miał tę samą intensywność - niezależnie od tego, czy naciśnięty był jeden przycisk czy dwa - i że eksperymentator nie widział, które osoby badane wymierzają wstrząs w danej chwili.
Zanim osoby badane zobaczyły obie „ofiary” i miały możność obserwować, jak wiły się one, skręcały i podskakiwały w reakcji na każdy rzekomy wstrząs (w rzeczywistości były one pomocnikami eksperymentatora i nie otrzymywały żadnych wstrząsów), wysłuchiwały nagranej na taśmie rozmowy z każdą z ofiar. Jedna z ofiar została przedstawiona jako antypatyczna, pełna uprzedzeń, „wydrowata”; druga natomiast jako miła, serdeczna, kochająca i altruistyczna.
Jak przewidywano, w warunkach anonimowości osoby badane od początku wymierzały znacznie dłużej trwające wstrząsy niż „zindywidualizowane” osoby badane, a ponadto czas trwania wstrząsów wzrastał w tej grupie w ciągu 20 prób (ryc. 14.12). „Zindywidualizowane” osoby badane z upływem czasu skracały trwanie wstrząsów podawanych „miłej” ofierze; „anonimowe” osoby badane wymierzały coraz dłużej trwające wstrząsy obu ofiarom. U badanych „zindywidualizowanych” wystąpiła wysoka dodatnia korelacja pomiędzy oceną ofiary i agresywnością wobec niej: większą, jeśli była ona oceniana negatywnie i mniejszą, jeśli była ona oceniana pozytywnie. U zakapturzonych osób badanych związek taki nie wystąpił: gdy tylko zaczęły się one zachowywać agresywnie wobec którejkolwiek z ofiar, wówczas ich agresja wzrastała. Wydaje się, że agresywne zachowanie w warunkach, gdy nie możesz zostać zidentyfikowanym, jest aktywnością samowzmacniającą się” (Zimbardo, 1969b).


Wiele późniejszych badań potwierdza zasadniczy wniosek wynikający z tego eksperymentu, że w warunkach sprzyjających anonimowości, ludzie są bardziej skłonni zachowywać się agresywnie lub przejawiać inne formy antyspołecznego zachowania. Badani studenci częściej oszukują lub kradną wtedy, gdy są traktowani przez eksperymentatora jako anonimowe „króliki doświadczalne” niż wtedy, gdy traktuje się ich jako niepowtarzalne jednostki.


„To samo zjawisko występuje wtedy, gdy anonimowość zapewniają kostiumy noszone w czasie maskarad urządzanych w wigilię Wszystkich Świętych. W pewnym eksperymencie terenowym obserwowano dyskretnie 1352 dzieci, gdy były one zajęte figlami i zabawą, albo pojedynczo, albo w grupach. Pomocnicy badaczy albo podkreślali anonimowość dzieci, albo umożliwiali ich identyfikację wołając je po nazwisku i zdejmując maski.




* * *



Ryc. 14.12. Agresja Jako Funkcja Anonimowości. Anonimowe osoby badane wymierzały wstrząsy przez dłuższy czas, a ponadto stopniowo zwiększały czas trwania wstrząsów wymierzanych obu ofiarom. Badani „zindywidualizowani” włączali prąd na czas około dwukrotnie krótszy, a w trakcie eksperymentu czas trwania wstrząsów wymierzanych przez nich „miłej” ofierze stawał się coraz krótszy.


* * *





Dzieci częściej brały dodatkowe słodycze i pieniądze, gdy ukrywał je kostium i gdy były częścią grupy, której przywódca był także anonimowy, bardziej zaś uczciwe były wtedy, gdy były „zidentyfikowane” i bawiły się same (Fraser, Kelem, Diener i Beaman, 1974).
W innym badaniu ośmioro dzieci zaproszono na eksperymentalną zabawę z okazji wigilii Wszystkich Świętych, gdzie pozwolono im bawić się w agresywne bądź nieagresywne gry, w których mogły one zdobywać żetony. Na aukcji zorganizowanej pod koniec zabawy, żetony te można było wymienić na atrakcyjne zabawki. Zabawa w agresywne gry wiązała się ze współzawodnictwem fizycznym (popychaniem i odpychaniem i zajmowała więcej czasu, a więc umożliwiała uzyskanie mniejszej liczby żetonów i nie była skutecznym środkiem realizacji celu polegającego na zdobyciu najlepszych zabawek.
Początkowo dzieci bawiły się w te gry w swych normalnych ubraniach; następnie przebrały się w kostiumy, które zapewniały im poczucie anonimowości; na koniec zdjęły maski i znów włożyły swe zwykłe ubrania - był to schemat badawczy typu |A-|B-|A. Podane poniżej średnie wyniki grupy świadczą wyraźnie o silnym wpływie anonimowości:


Czynności agresywne - Uzyskane żetony 
(|A) początkowa faza określenia poziomu podstawowego 42% - 58
(|B) anonimowość 86% - 31
(|A) końcowa faza określenia poziomu podstawowego 36% - 79


„Anonimowość wzmagała zatem agresywności dzieci nawet wtedy, gdy instrumentalne następstwa agresji nie były korzystne dla dziecka” (Fraser, 1974).


Niekiedy ludzie stwarzają sobie sytuację anonimowości (i nieodpowiedzialności) stając się częścią grupy. Przykłady wpływu takiej anonimowości są widoczne w wybrykach (często destruktywnych) w czasie wielkich zgromadzeń i zjazdów, jak również w czasie „zielonych nocy” korporacji studenckich, na balach kostiumowych, na zabawach w Ostatki, czy w działalności Ku Klux Klanu. W niektórych sytuacjach anonimowość jest narzucana przez społeczeństwo. Podobnie jak w opisanych powyżej eksperymentach, w których osoby badane uczyniono anonimowymi przez ubranie ich w kostiumy dostarczone przez eksperymentatorów, tak samo mężczyźni stają się „G. L” („Government Issue” - „własność rządowa”, potocznie „wojskowi”, „służbiści”) przez nałożenie identycznych uniformów wojskowych.
Ta jednolitość wyglądu ułatwia przywódcom skłonienie ludzi do konformistycznego zachowania - stwierdził to Adolf Hitler w swej książce „Mein Kampf”. Lecz ta psychologiczna anonimowość, jaka zapewniają mundury wojskowe czy kurtki używane przez członków gangów, uwalnia także noszące je osoby od konwencjonalnych ograniczeń pod względem zachowania, zwłaszcza pod nieobecność energicznego przywódcy - co w części wyjaśnia morderstwa, gwałty i rabunki, jakich dopuszczają się żołnierze wszystkich niemal narodowości, gdy znajdują się na obcej ziemi.




Zbliżenie


Anonimowość a agresja w różnych kulturach 


„W niektórych społeczeństwach mężczyźni przygotowując się do wojny zmieniają swój wygląd zewnętrzny za pomocą masek lub malowania ciała, podczas gdy w innych, nie trzeba zmieniać powierzchowności, aby stać się wojownikiem. Jak sądzisz, jakie mogą być konsekwencje tych różnic pod względem zapewniającej sobie samemu anonimowości? Które społeczności, twoim zdaniem, będą przejawiać większą agresywność podczas walki? Aby odpowiedzieć na to pytanie, Robert Watson (1973) przeanalizował dane dotyczące dwudziestu trzech różnych kultur, w przypadku których dostępne były odnośne informacje. Przekonywające rezultaty przedstawiono na rycinie 14.3. Spośród piętnastu społeczności, których wojownicy zmieniali swój wygląd zewnętrzny, w dwunastu wskaźnik „zabijania, torturowania lub okaleczania wrogów” był wysoki, podczas gdy tylko jedna z ośmiu społeczności, w których wojownicy nie zmieniali swego wyglądu, była tak dalece agresywna”.


Anonimowość jest tylko jednym z wielu warunków, które mogą przyczynić się do wytworzenia subiektywnego stanu dezindywidualizacji, z towarzyszącym mu osłabieniem zwykłych mechanizmów kontrolnych, które hamują impulsywne i antyspołeczne zachowania. Do innych tego rodzaju warunków należy podział, czyli dyfuzja odpowiedzialności, zmienione stany świadomości lub zmieniona perspektywa czasowa, pobudzenie emocjonalne lub seksualne, przeciążenie sensoryczne, nowość sytuacji lub jej nieustrukturalizowanie oraz fizyczne zaangażowanie się w jakąś agresywną czynność (Zimbardo, 1969b).
Jeśli anonimowość prowadzi do dezindywidualizacji i z kolei powoduje większą skłonność do agresywności i innych antyspołecznych działań, to w interesie społeczeństwa jest wykrywanie, jakie warunki zapobiegają dezindywidualizacji, a przeciwnie - sprzyjają zindywidualizowaniu.


„W przeprowadzonym stosunkowo niedawno badaniu (o którym wspomnieliśmy już w Rozdziale 4, w związku z zagadnieniami komunikowania się) grupom złożonym ze studentów wyższych uczelni powiedziano, że jednego członka grupy należy wybrać na koordynatora w grze symulacyjnej polegającej na projektowaniu miasta. W jednej wersji była to funkcja pożądana, za którą osoba sprawującą ją miała otrzymać zapłatę; w innej wersji, wybranie na to stanowisko było niepożądane, ponieważ koordynator miał otrzymywać wstrząsy elektryczne za każdą złą decyzję. W wersji pozytywnej osoby badane przejawiały werbalne i niewerbalne zachowania, które wyraźnie je indywidualizowały, podczas gdy w wersji negatywnej robiły one wszystko, co mogły, aby nie wyróżniać się niczym spośród innych - dezindywidualizując się w ten sposób” (Maslach, 1974).




Wandalizm:
bezsensowna przemoc?




„To jest po prostu złośliwe, bezmyślne zniszczenie, dokonane przez wandali”. Rzadkie drzewa w parku są ścinane, łamane i niszczone, zwierzęta w rezerwacie są torturowane i zabijane, ptaki obdzierane z piór, kościoły są bezczeszczone, synagogi plądrowane; palone są szkoły, wybijane szyby; komfortowe dworce są podpalane; publiczne telefony są wyrywane z kabin; zaparkowane samochody są pozbawiane części, a ich karoserie wgniatane; nagrobki cmentarne są przewracane.
Jest to zaledwie fragment listy opisującej codzienna działalność nie wrogiej armii zdobywców, lecz ciekawego gatunku obywateli zwanych |wandalami, od nazwy barbarzyńców, którzy najechali zachodnią Europę w 455 roku. Charakterystyczną cechą wandalizmu jest niszczenie własności lub życia bez żadnego wyraźnego celu - poza samym aktem zniszczenia. Zachowanie takie wydaje się pozbawione motywów i irracjonalne, ponieważ sprawcy wkładają mnóstwo wysiłku w działalność, która zdaje się nie mieć dla nich żadnej wartości instrumentalnej.


Kiedy niszczenie jest wandalizmem? W dużej mierze wandalizmem jest to, co ktoś |nazwał wandalizmem. Zniszczenia własności miejskiej dokonane po wielkim meczu piłkarskim są zwykle akceptowane jako coś „normalnego”.  Natomiast wybijanie szyb wyższej uczelni staje się „bezmyślnym niszczeniem”, jeśli uważa się je za część radykalnego protestu, i przedstawiciele prawa oceniają je znacznie surowiej - nawet jeśli rozmiary zniszczeń są takie same - niż wybryki „chłopców  korporacji”, „nowicjuszy”, czy „fanatyków big beatu”.
Wykolejenie pociągu przez ułożenie przeszkód na torze jest „wybrykiem”, jeśli zostało dokonane przez dzieci, „wandalizmem”, jeśli sprawcy osiągnęli wiek, w którym powinni mieć już świadomość swych czynów, lub „sabotażem”, jeśli ładunek pociągu ma związek z obroną narodową. Nawet zabijanie zwierząt staje się sportem, jeśli osoba zabijająca je ma licencję myśliwego. Podczas gdy zanieczyszczanie środowiska przez rzucanie śmieci jest wykroczeniem, które pociąga za sobą grzywnę, jeśli dokonała go jednostka, to zanieczyszczenie atmosfery, wody i ziemi przez fabryki nie pociągało za sobą nawet krytyki społecznej - dopiero od niedawna ruch ekologiczny uznaje te czyny za wandalizm skierowany przeciw własności całej ludzkości.
Szereg ważnych konsekwencji wynika z nazwania danego aktu destrukcji „aktem wandalizmu”. Pierwsza z nich polega na zaprzeczeniu, że może on wynikać z nieuzasadnionych motywów. Druga - to uznanie pewnych ludzi za „dewiantów”, których irracjonalne działanie stanowi dla wszystkich niebezpieczeństwo. Trzecią jest rozgrzeszenie społeczeństwa: ludzie obwiniają zaburzony rzekomo umysł wandala, zamiast szukać przyczyn w relacjach między tą jednostka a społeczeństwem. Na koniec, implikuje to bezowocność działań zaradczych, brak możności naukowego badania problemu oraz pilną potrzebę większych policyjnych sił odstraszających i surowszych kar - których jedynym dostrzegalnym efektem zdaje się być zmiana obiektów wandalizmu oraz jeszcze większe jego rozpowszechnienie (ryc. 14.14).


Znaleźć sens w „bezsensownym”. Gdyby wandalizm był istotnie „bezsensowny”, to nie moglibyśmy nigdy mieć nadziei na opanowanie go; jeśli bowiem pewien skutek nie ma przyczyny, to nie można opracować żadnego systematycznego planu, który mógłby ograniczyć jego występowanie. Na szczęście można znaleźć sens nawet w pozornie bezsensownym, złośliwym wandalizmie. Pewnych wskazówek może dostarczyć historia, jak również rozmowy z członkami gangów, obserwowanie zachowania studentów dopuszczających się aktów fizycznej destrukcji oraz różnego rodzaju eksperymenty terenowe.
W XVIII wieku, gdy grupa robotników zwanych |luddystami zaczęła niszczyć maszyny fabryczne, określano ich stereotypowo jako „szaleńców” i „obłąkanych”, ich czyny zaś jako „bezmyślne”. Jednakże stanowili oni część poważnego ruchu zmierzającego do ulepszenia ich społeczeństwa. Protestowali oni przeciwko negatywnym stronom systemu przemysłowego.
Podobnie zniszczenie własności, do którego doszło podczas zamieszek rasowych w Wetts, Newark oraz w innych amerykańskich miastach w końcu lat sześćdziesiątych, wydawało się „bezmyślne”, dopóki nie zauważono, że obiekty napaści nie były wybierane w sposób przypadkowy - były to, jak się zdaje, rozmyślne napaści na przedsiębiorstwa białych, których uważano za niesprawiedliwych lub uważano, że traktują pogardliwie członków tej społeczności.
Analiza zachowania gangów ujawniła kilka wzajemnie powiązanych czynników przyczynowych w ich aktach przemocy (Becker, 1963; W. Miller, 1966; 
Yablonsky, 1968). Członkowie gangów, podobnie jak wiele osób w niższych grupach społeczno-ekonomicznych, żyją na ogół z małą nadzieją na zmianę czy znaczną poprawę, nie mając poczucia własności ani poczucia związku ze społeczeństwem. Warunki społeczne ograniczają im możliwość „wybicia się”, uzyskania pozycji, prestiżu i wpływu społecznego. Reagują oni na to stając się outsiderami, tworząc kontrkulturę ze swymi własnymi normami. Nadal jednak muszą oni |posługiwać |się tradycyjną kulturą, aby „wybić się” w swej własnej podkulturze. Pewien członek gangu powiedział:


„Gdybym zdobył nóż, wówczas zadźgałbym kogoś. To zrobiłoby mi dużą reklamę. Ludzie szanowaliby mnie za to, co zrobiłem i temu podobne.  Mówiliby: „Oto idzie zimny morderca””. To sprawia, że czujesz się jak gruba ryba” (Yablonsky, ss. 230-231).




* * *



Ryc. 14.14. „Zamierzaliśmy rozwalić cały ten budynek” - oto wszystko co mieli do powiedzenia dwaj ośmioletni chłopcy, gdy przyłapano ich na niszczeniu szkoły. Zdjęcie obok przedstawia chłopców uprawiających znacznie częściej spotykaną formę wandalizmu.


* * *





Dla takiej młodzieży wandalizm skierowany przeciw własności i przemoc wobec ludzi mogą być działaniami pozwalającymi przekształcić nudę w podniecenie oraz uzyskać przyjemność z pogwałcenia społecznego tabu. Na podstawie naszej zamieszczonej wyżej analizy przewidywalibyśmy także, że wandalizm będzie stosowany jako środek uzyskiwania pewnego szacunku dla samego siebie. Istotnie, niedawno wśród wielkomiejskich wandali panowała moda na |identyfikacyjną |grafikę |ścienną. Wandal pozostawiał swoje wizytówki i natryskane farby na wszystkim, co znajdowało się na widoku publicznym: domach, kościołach, budynkach publicznych, środkach masowej komunikacji, toaletach i innych.
Analizując to zagadnienie głębiej, można uznać, że wandalizm bywa wyrazem buntu ze strony bezsilnych ludzi próbujących w ten sposób uzyskać jakiś wpływ na bieg rzeczy. Złośliwy wandalizm można uważać za publiczną akceptację faktu odrzucenia przez społeczeństwo oraz za aktywne dążenie do określenia samego siebie jako „outsidera” - kogoś, kto wzbudza strach.  Wydaje się, że w gruncie rzeczy czyn pozornie bezsensowny uzyskuje |większe |wzmocnienie niż działanie zrozumiałe i przewidywalne. Ludzie wyróżniają się, zdobywają sławę, pamięta się o nich lub obawia się ich z powodu zachowania, które jest niezwykłe, niewytłumaczalne i którego wystąpienie u innych ludzi w tej samej sytuacji nie jest prawdopodobne. Samowola jest pewnym sposobem pokazania, że twoje własne działanie jest pod kontrolą sił wewnętrznych, a nie innych ludzi czy zdarzeń. Można zaobserwować ten sam mechanizm w sztuce Alberta Camusa „Caligula”, w której cesarz rzymski stara się wykazać, że jest bogiem, przez samowolne sprawowanie władzy nad życiem i śmiercią innych ludzi - zarówno przyjaciół, jak i wrogów.
Wystarczy tylko dać komuś stary samochód, młot na długiej rączce i pozwolenie pogruchotania tego samochodu, aby wyzwolić zdumiewającą gwałtowność i agresywność u nawet najbardziej nieśmiałych studentów - intelektualistów z tak zwanych dobrych domów.


„Pewna grupa studentów pierwszego roku, zachęcona do takiej niszczycielskiej działalności, nie tylko zdemolowała samochód w krótkim czasie, lecz podpaliła go, próbowała przeszkodzić straży pożarnej w ugaszeniu go i w końcu policja groźbą użycia broni musiała powstrzymywać ich od ponownego zaatakowania wraka. Studenci uczęszczający na studia podyplomowe, których zachęcano, aby popróbowali swych sił i „po prostu porąbali trochę stary samochód”, z początku opierali się, lecz dali się porwać radosnemu uczuciu fizycznego niszczenia go. W pewnym momencie jeden ze studentów walił nogą w dach, dwaj inni starali się wyrwać drzwiczki, a czwarty systematycznie tłukł wszystko, co było ze szkła (ryc. 14.15).


Kto staje się wandalem? Podejmując bardziej systematyczną próbę zaobserwowania, kim są ludzie niszczący bezmyślnie samochody i jakie warunki sprzyjają takiemu wandalizmowi, przeprowadzono w śródmieściu Nowego Jorku i w Palo w Kalifornii proste badania terenowe.


„Porzucono na ulicach dwa używane samochody w dobrym stanie z usuniętymi tablicami rejestracyjnymi i z podniesionymi maskami silnika. Jeden z nich umieszczono na ulicy w pobliżu New York University w Bronx, drugi był oddalony o przecznicę od Stanford University. Ukryci obserwatorzy obserwowali, fotografowali i robili notatki dotyczące tych wszystkich ludzi, którzy weszli w kontakt z „przynętą”. Badacze oczekiwali, że większa anonimowość w śródmieściu Nowego Jorku będzie sprzyjać większej częstości przypadków wandalizmu w stosunku do porzuconego tam samochodu i że większość wandali będzie rekrutować się spośród młodzieży i dzieci.
Pierwsze przewidywanie zostało potwierdzone, drugie - z pewnością nie.  Już po dziesięciu minutach od chwili porzucenia samochodu w Nowym Jorku, pojawili się pierwsi „rabusie samochodowi” - matka, ojciec i syn. Matka pełniła rolę czujki, podczas gdy ojciec i syn opróżniali bagażnik i podręczny schowek kierowcy, a następnie wycięli chłodnicę i wyciągnęli akumulator. Wkrótce po ich odjeździe zatrzymał się przejeżdżający samochód, a jego dorosły kierowca podniósł za pomocą podnośnika tył porzuconego samochodu i zabrał najlepsze z jego kół. Do końca dnia nieustający potok dorosłych wandali zabrał z tego samochodu każdą usuwalną część (ryc.  14.16). 
Następnie zaczęło się chaotyczne niszczenie, w miarę, jak inni przejeżdżający zatrzymywali się, aby przyjrzeć się dokładnie temu samochodowi: cięto opony, oddawano mocz na drzwiczki, wybijano szyby, wgniatano maskę silnika, zderzaki, drzwiczki i dach.
Przed upływem mniej niż trzech dni to, co pozostało, było już tylko zdewastowanym, bezużytecznym, metalowym wrakiem, rezultatem 23 destrukcyjnych „kontaktów”. Akty tego wandalizmu prawie zawsze były obserwowane przez jednego lub więcej przejeżdżających, którzy niekiedy zatrzymywali się, aby pogawędzić z rabusiami. Większości zniszczeń dokonano w ciągu białego dnia, a nie w nocy (jak przewidywano), a zabawy młodzieży, polegające na wybijaniu szyb i cięciu opon, były wyraźnie poprzedzone kradzieżami dorosłych. Wszyscy ci dorośli byli dobrze ubranymi, sympatycznymi białymi, którzy w innych okolicznościach byliby błędnie uważani za dojrzałych, odpowiedzialnych obywateli, domagających się przestrzegania prawa i porządku.
O tym, że ta anonimowość powoduje uwolnienie się od zahamowań przed podejmowaniem takiego antyspołecznego zachowania, można wnioskować na podstawie uderzającego kontrastu między tym, co wydarzyło się w tych dwóch różnych miejscowościach. W małym mieście (Palo Alto) nie ukradziono z samochodu ani jednego przedmiotu, ani też żadna część porzuconego samochodu nie została zniszczona w ciągu całego tygodnia, gdy stał tak bez opieki na ulicy. Natomiast, co może być oznaką silniej rozwiniętej świadomości społecznej w tym środowisku, pewien mężczyzna przejeżdżający w czasie ulewnego deszczu obok porzuconego samochodu zatrzymał się i opiekuńczo zamknął maskę jego silnika - tak, żeby nie zamókł!” (Zimbardo, 1973).




* * *



Ryc. 14.15. Operator dźwigu samojezdnego, który odholował zniszczony wrak, powiedział, iż ostatni samochód, jaki widział w tym stanie, został rozbity przez pociąg pospieszny.


Ryc. 14.16. Pierwsze zdjęcie ukazuje „szanowną” przeciętną rodzinę, która jako pierwsza zaczęła „rozszabrowywać” samochód. Na drugim zdjęciu inny dorosły wandal zdejmuje jedno z kół. Na trzecim zdjęciu widzimy grupę chłopców, na których teraz przyszła kolej w rozbieraniu zniszczonego już wraka.


* * *





Wydaje się, że „wandalizm” obejmuje wiele rodzajów zachowań, występujących u różnych ludzi i w rozmaitych okolicznościach. Nie jest on bezsensowny - może służyć różnym celom.




Zbliżenie


Cele wandalizmu


|Akty wandalizmu można podzielić na sześć kategorii - zgodnie ze znaczeniem, jakie destrukcyjne zachowanie zdaje się mieć dla danej osoby.
1. |Wandalizm |zaborczy - niszczenie własności w celu uzyskania pieniędzy lub innych dóbr, na przykład rozbijanie kaset na pieniądze w automatach sprzedażnych lub telefonicznych, „szabrowanie” części z samochodów lub armatury i instalacji z budynków.
2. |Wandalizm |taktyczny - niszczenie własności jest środkiem zwracającym uwagę na skargi czy zażalenia lub służy wymuszeniu pewnej reakcji.  Przykładem takiego taktycznego podejścia może być zachowanie więźniów, którzy niszczą swoje cele lub stołówkę w proteście przeciw niewystarczającemu wyżywieniu lub postępowanie człowieka, który wybija szybę wystawową po to, aby zostać zaaresztowanym i znaleźć schronienie w więzieniu.
3. |Wandalizm |ideologiczny - podobny do wandalizmu taktycznego, lecz stosowany dla poparcia jakiejś sprawy o charakterze ideologicznym.  Przykładem może tu być malowanie haseł antypaństwowych na ambasadach, podpalanie budynków instytucji wojskowych oraz „rozrabianie” na terenach uniwersyteckich w celu skłonienia administracji do wezwania policji na teren uczelni (w nadziei, że jej zbyt gwałtowna reakcja zradykalizuje apatycznych studentów i pracowników naukowych). W pewnym punkcie wandalizm ideologiczny otrzymuje etykietkę „sabotażu” lub „zdrady stanu”.
4. |Wandalizm |mściwy - zniszczenie wybranego obiektu w celu wzięcia odwetu na jego właścicielu, strażniku czy reprezentancie. Niekiedy grupa uczniów demoluje klasę, ponieważ uważają oni, że nauczyciel był niesprawiedliwy.
5. |Wandalizm |zabawowy - niszczenie własności dla zabawy: kto potrafi wytłuc szyby na najwyższym piętrze, zestrzelić najwięcej lamp ulicznych, popsuć w najbardziej pomysłowy sposób automaty telefoniczne.
6. |Wandalizm |złośliwy - niszczenie własności jako jeden z przejawów gniewu lub frustracji. Ten rodzaj wandalizmu może być wybiórczy, lecz często jest skierowany przeciw symbolom klasy średniej, instytucjom publicznym i systemom sprzyjającym anonimowości - takim jak metro, szkoły, samochody (Cohen, 1973).

Klasyfikacja taka pokazuje wyraźnie, że istnieje wiele motywów wandalizmu i wiele rodzajów ludzi, którym można nadać |etykietkę wandali.




Społeczne usankcjonowanie
zła




Oświęcim, My Lai, Kent State, Attica, Jackson State (Attica (stan New York) - miejsce największego buntu więźniów w historii Stanów Zjednoczonych. W dniach 9-13.09.1971 zginęło tam 32 więźniów i 11 strażników. Kent (stan Ohio) - siedziba Kent State University, na którym w 1970 r. doszło do zamieszek. Funkcjonariusze Gwardii Narodowej postrzelili dwóch studentów i dwie studentki (którzy nie mieli nic wspólnego z demonstracjami stanowiącymi bezpośredni powód interwencji Gwardii Narodowej). Jackson (stan Missisipi) - siedziba Jackson State College, którego dwaj studenci zostali zabici przez policję podczas demonstracji (przyp. red.)), Kambodża i... Dla wielu nazwy te stały się symbolami współczesnych wersji zła. |Zło jest terminem odnoszonym do „sytuacji, w których siła, przemoc i inne formy przymusu przekraczają granice instytucjonalne lub moralne” (Smolser, 1971). Trzy klasy sytuacji, które zgodnie z tą definicja określa się jako „zło”, to sytuacje, w których jednostki lub grupy: 1) sprawują nad innymi władzę opartą na przymusie, gdy nie są do tego prawomocnie upoważnione, 2) przekraczają granice swej prawomocnej władzy w wywieraniu przymusu lub 3) sprawują nad innymi kontrolę opartą na przymusie lub mającą charakter destrukcyjny, która gwałci wyższe normy humanitaryzmu lub moralności, nawet jeśli mieści się w granicach usankcjonowanej politycznie władzy.
Ci, którzy dopuszczają się złych czynów, rzadko (lub nigdy) uważają je za takie. Dla złoczyńcy istnieje zawsze wystarczające usprawiedliwienie, które sprawia, że czyn ten wydaje się nie tylko rozsądny, lecz absolutnie konieczny. W takim przypadku także mamy do czynienia z paradoksem doskonałości ludzkiej - ten sam intelekt, który potrafi zrozumieć najgłębsze prawdy filozoficzne i metafizyczne, może zniekształcać rzeczywistość tak, że „zło” staje się „dobrem”.


Ludzie, którzy gwałcą podstawowe prawa humanitarne, często są przekonani, że złem jest właśnie przeciwstawianie się im. Zazwyczaj racjonalizują oni swe zachowanie zgodnie z pewną zasadą, która może być zaakceptowana przez inne osoby w ich społeczeństwie. Ponadto często mają oni pewien stopień społecznego czy politycznego poparcia lub dysponują zinstytucjonalizowaną strukturą, która pomaga im zdefiniować dany czyn w kategoriach innych niż ludzkie.
Zapoznajmy się ze słowami Hitlera:


„Jeśli rozpatrujemy wszystkie przyczyny upadku Niemiec, to za ostateczną i decydującą należy uznać nieuświadamianie sobie problemu rasowego, a zwłaszcza niebezpieczeństwa żydowskiego (...). Jestem obecnie przeświadczony, że muszę działać w imieniu Wszechmocnego Stwórcy: walcząc przeciwko Żydom wykonuję dzieło Pana” (1933, s. 25).


Albo też spójrzmy na powody, jakie podał wielokrotny morderca Herbert Mullin dla uzasadnienia morderstwa czterech kilkunastoletnich chłopców, dokonanego w Santa Cruz, w stanie Kalifornia, w 1973 roku. „Ukarał” on tych „hipisów”, ponieważ namawiali go, aby odmówił służby wojskowej z uwagi na nakazy sumienia i nie był żołnierzem „w tym najlepszym kraju na świecie”.  Zabił on także trzynaście osób w przeświadczeniu, że ta ofiara z ludzi zapobiegnie katastrofalnemu trzęsieniu ziemi („Associated Press”, 7 sierpnia 1973).
Za dokonanie przez kompanię „Charlie” masakry ponad 400 bezdomnych mieszkańców wietnamskiej wioski My Lai, w dniu 16 marca 1968 roku, porucznik William Calley został uznany za winnego. Lecz analiza warunków, które doprowadziły do tego potwornego czynu (powtórzonego w sąsiedniej wiosce przez siostrzaną jednostkę, kompanię „Bravo”), ujawnia, że był to „jedynie niewielki krok poza standardową, oficjalną, rutynową politykę Stanów Zjednoczonych w Wietnamie” (Opton, 1971) oraz następstwo |psychicznego |odrętwienia spowodowanego tą niewypowiedzianą wojną (Lifton, 1971).
Można by argumentować, że czyny Calleya i innych żołnierzy były reakcja na silne naciski sytuacyjne, które zdeterminowały ich zachowanie. Lecz obecnie, dokonując chłodnej analizy, którą umożliwia dystans w przestrzeni i w czasie od tej zbrodni, czy przeciętny obywatel osądza ten czyn jako zły? Czy jest on czymś, co może zdarzyć się znowu, czy też było to coś, co zdarzyło się jedyny raz w czasie wojny? Badania ankietowe, przeprowadzone starannie przez Herberta Kelmana i Lee Lawrence’a (1972) na reprezentatywnej próbce złożonej z blisko tysiąca respondendów w całych Stanach Zjednoczonych, doprowadziły badaczy do następującego wniosku:


„(...) uzyskane przez nas dane zdecydowanie sugerują, że poznawcze i ideologiczne podstawy takich czynów, jak czyny Calleya, występują w dużej części populacji. Jeśli sytuacja zdaje się wymagać tego, jeśli czynniki zobowiązujące ulegają spotęgowaniu i jeśli czynniki przeciwstawiające się temu są osłabione, to uważają oni takie działanie za przynajmniej usprawiedliwione, możliwe do zaakceptowania, a może nawet pożądane.  Publiczna reakcja na proces Calleya mówi nam zatem wiele o istniejącej w amerykańskiej populacji gotowości do takich gwałtów” (s. 212).


Pięciu żołnierzy walczących w Wietnamie, w liście przesłanym do „San Francisco Chronicle” (31 grudnia 1969), nie tylko poparło ten wniosek, lecz entuzjastycznie podpisało się pod nim - jako prawdziwym i słusznym. W pewnym fragmencie piszą oni:


„Chcę wrócić do domu żywy; jeśli muszę zabić starców, kobiety czy dzieci, aby zapewnić sobie nieco większe bezpieczeństwo - to zrobię to bez wahania.  Wojna jest obrzydliwa. Nie ma żadnych reguł właściwego postępowania w stosunku do wroga (...) gotów jestem założyć się, że następnym razem, gdy jednostki amerykańskie wejdą do tej wioski, napotkają one bardzo mały opór.  Moim zdaniem, jego (Calleya) akcja była skutecznym i bynajmniej nie wyjątkowym typem operacji”.


Jak wykazał historyk Hannah Arendt (1965), aczkolwiek złe postępowanie ma często dramatyczne konsekwencje, to jednak okoliczności, w których zło występuje, często są wprost przeciwnie - banalne i powszednie. Zło występuje często bez emocji, gniewu czy konfliktów między id i superego - często jest po prostu robotą, którą trzeba wykonać, nieprzyjemnym interludium w życiu danej jednostki. Ten powszedni sposób spojrzenia na zło znalazł aż nazbyt przerażający wyraz w dzienniku lekarza obozowego z Oświęcimia.




Zbliżenie


Banalność zła


„Dziennik, którego fragmenty zamieszczamy poniżej, pisał Johann Kremer, lekarz zatrudniony w Oświęcimiu; spodziewał się on, że „dziennik ten może kiedyś w przyszłości posłuży ku mojej obronie”. Jak dużą wagę miałby dla ciebie ten dowód niewinności, gdybyś ty był sędzią?


„4 września 1942”. W południe byłem świadkiem Operacji Specjalnej przeprowadzonej w obozie kobiecym. Najbardziej przerażający widok, jaki kiedykolwiek widziałem. Herr Thilo (lekarz załogi obozu) miał słuszność, kiedy mówił mi, że żyjemy tu w „anus mundi” (kloace świata). Około godziny 8 tego wieczoru byłem znów obecny przy Operacji Specjalnej przeprowadzonej na transporcie z Holandii. Ze względu na dodatkowe przydziały, składające sie z 200 gramów wódki, 5 papierosów oraz 100 gramów kiełbasy i chleba, zawsze są hordy SS-manów gotowych do wykonania tego zadania.


„6 września 1942”. Niedzielny obiad był doskonały: (...) o 8 wieczorem znów byłem obecny przy Operacji Specjalnej.


„3 października 1942”. Dzisiaj zakonserwowałem trochę absolutnie świeżej tkanki z ludzkiej wątroby, śledziony i trzustki. Mam także wszy wzięte z chorych na tyfus, zakonserwowane w czystym alkoholu. W Oświęcimiu całe ulice chorują na tyfus (...).


„18 października 1942”. W ten wilgotny i zimny niedzielny poranek byłem obecny przy jedenastej Operacji Specjalnej (Holendrzy). Wstrząsająca scena z trzema kobietami żebrzącymi o życie.


„31 października 1942”. Przez kilkanaście ostatnich dni piękna, jesienna pogoda zachęcała do codziennych kąpieli słonecznych w ogrodzie przy domu SS. Nawet bezchmurne noce są stosunkowo łagodne.


„13 listopada 1942”. Otrzymałem tkankę ze świeżego ciała 18-letniego Żyda. Ostra atrofia (...).


„14 listopada 1942”. Dzisiaj niedziela, spektakl wodewilu w klubie miejskim (wspaniały!)...”
„Poland Illustrated Magazine” 1964, 11, s. 123.


Ślepe posłuszeństwo wobec autorytetu


„Gdy myśli się o długiej i ponurej historii człowieka, wówczas dochodzi się do wniosku, że więcej ohydnych zbrodni popełniono w imię posłuszeństwa niż w imię buntu”.
C. P. Snow, 1961


Zaczęliśmy nasz podręcznik psychologii od analizy badań Milgrama nad posłuszeństwem. Obecnie jesteśmy lepiej przygotowani do rozważania pewnych teoretycznych i praktycznych konsekwencji tych badań.
Czy sądzisz, że kobiety reagowałyby w taki sam sposób jak mężczyźni biorący udział w badaniach Milgrama? Czy sądzisz, że badani naprawdę zostali wprowadzeni w błąd przez podane im uzasadnienie? Być może procedura ta nie wydała się im przekonywująca; być może w rzeczywistości nie wierzyli oni, że wyrządzają krzywdę „uczniowi”, lecz po prostu udawali, iż w to wierzą. Oba te zagadnienia zostały podjęte w przeprowadzonym stosunkowo niedawno eksperymencie, którego rezultaty są pod pewnymi względami jeszcze bardziej wstrząsające niż wyniki badań Milgrama.


„Studenci wyższej uczelni (13 mężczyzn i 13 kobiet) zostali zwerbowani do udziału w badaniach, w których mieli spełniać rolę pomocników eksperymentatora i ćwiczyć zwierzę w wykonywaniu zadania polegającego na różnicowaniu. Mieli oni karać każdy błąd przez stosowanie coraz silniejszych wstrząsów elektrycznych - od 15 do 450 V - dokładnie tak samo, jak we wcześniejszych badaniach. Osoba badana brała zwierzę w ręce, umieszczała je w aparaturze składającej się z dwóch pomieszczeń połączonych przejściem - skrzynce wahadłowej („shuttlebox”), a następnie obserwowała jego zachowanie z sąsiedniego pokoju przez jednokierunkową szybę.  Rzeczywisty eksperymentator znajdował się w tym pokoju razem z osobą badaną, lecz nie mógł obserwować zwierzęcia.
Zwierzęciem tym był miły, mały, puszysty szczeniak, który rzeczywiście otrzymywał wstrząsy, gdy badany-nauczyciel naciskał dźwignie znajdujące się na skrzynce rozdzielczej. Natężenie wstrząsu, jaki otrzymywał szczeniak, w rzeczywistości wzrastało jedynie od słabego do umiarkowanego, co sprawiało (chociaż prąd był dostatecznie słaby, aby nie wyrządzić krzywdy szczeniakowi), że eksperyment wydał się całkowicie wiarygodny, ponieważ gdy siła wstrząsów wzrastała, reakcje szczeniaka stawały się bardziej intensywne.
Wyniki uzyskane przez badanych mężczyzn były powtórzeniem otrzymanych wcześniej rezultatów - 54% doszło do końca skali. Czy jednak spodziewałbyś się, że kobiety, z ich rzekomo silną potrzebą opiekowania się, będą reagowały w taki sam sposób? Gdy porównywalną próbę, złożoną z 45 studentów z tej samej uczelni, poproszono o przewidzenie wyniku tego badania, to tylko trzech powiedziało, że ktoś przekroczy 300 V, wszyscy zaś stwierdzili, że żadna z kobiet nie dojdzie do 450 V. Co więcej, większość tych sędziów (86%) szacowała, że żadna z badanych kobiet nie zastosuje więcej niż 150 V.
Wbrew tym z taką pewnością formułowanym przewidywaniom i najlepszej dostępnej wiedzy potocznej, fakty są takie, że każda z badanych kobiet była ślepo posłuszna - wymierzając wstrząsy o maksymalnym natężeniu bezradnemu szczeniakowi, którego cierpienia mogły one obserwować bezpośrednio! Były one wzburzone, protestowały, a niektóre nawet płakały, lecz żadna nie wypowiedziała posłuszeństwa” (Scheridan i King, 1972).


Można wyróżnić trzy okoliczności, które prowadzą do takiego „ślepego posłuszeństwa wobec autorytetu”, z pogwałceniem własnego wyobrażenia o sobie oraz wartości moralnych.
1. Połuszeństwu sprzyja obecność |prawdziwego |autorytetu, któremu się ufa, którego uważa się za uznawanego reprezentanta społeczeństwa i który ma pod swą kontrolą ważne wzmocnienia. Autorytet, który nie znajduje się twarzą w twarz z daną osobą, traci część swej władzy.
2. Posłuszeństwo jest większe, gdy zostanie ustanowiona i zaakceptowana pewna |relacja |ról („role relationship”), zgodnie z którą dana jednostka jest podporządkowana innej osobie. Przyjmując tę rolę ludzie uważają, że nie są osobiście odpowiedzialni za to zachowanie, ponieważ nie inicjują spontanicznie działania, lecz jedynie wypełniają rozkazy. Człowiek przestaje być kierującą sobą samodzielnie „osobą działającą” („actor”), i staje się na to miejsce „osobą reagującą” („reactor”), zachowującą się zgodnie ze „scenopisem” opracowanym przez kogoś innego. Gdy jednak osoby badane widzą, że dwaj inni ludzie odmawiają zaakceptowania narzuconej im eksperymentalnie roli, wówczas 90% spośród nich również przeciwstawia się poleceniom autorytetu.
3. Posłuszeństwo sprzyja istnienie |norm |społecznych, które określają stosunek danej osoby do innych osób w tej sytuacji i dostarczają zaleceń dotyczących protokołu, etykiety oraz społeczne aprobowanego i akceptowanego zachowania. Normy te w dużym stopniu decydują o tym, co uważa się za możliwe i właściwe. Jeden z badanych w pierwotnym eksperymencie Milgrama powiedział eksperymentatorowi: „|Nie |chcę |być |niegrzeczny, |proszę |pana, lecz czy nie powinniśmy zajrzeć do niego? On jest chory na serce i może umrzeć”.

Ludzie często zatem spostrzegają siły społeczne jako tak silnie ich wiążące, iż zostają wplątani w zachowania i interakcje, które muszą wykonywać bez względu na to, co uważają za słuszne czy sprawiedliwe.  Wartości określone przez daną sytuację zajmują miejsce wartości uznawanych przez nich indywidualnie; „obowiązek” i „lojalność” wobec grupy i jej norm zastępują nakazy sumienia. Osoby badane nie chcą wyrządzić krzywdy nikomu, lecz sądzą, że ważniejsze jest, aby nie zakłócić Systemu - przedstawienie musi toczyć się dalej!
Najbardziej chyba godnym uwagi aspektem tych badań nad ślepym posłuszeństwem wobec autorytetu nie jest to, że tak wielu inteligentnych, odpowiedzialnych ludzi zgodziło się słuchać i pomagać autorytetowi, który przyjął na siebie odpowiedzialność za cierpienia zadawane przez nich niewinnej ofierze - tym aspektem jest to, że nie wstali oni z wyznaczonego im miejsca i nie weszli do sąsiedniego pomieszczenia, gdzie pewien człowiek mógł doznać poważnej krzywdy.
Nawet ci, którzy odmówili połuszeństwa, stwierdzili po prostu werbalnie, że nie będą kontynuować zadania. Nie pogwałcili oni potężnej, przyjmowanej milcząco reguły obowiązującej na wyższych uczelniach - dobrzy studenci pozostają na swych miejscach. Nawet ich nieposłuszeństwo mieściło się w ramach uprzejmej etykiety cywilizowanego protokołu.
Akt behawioralnego nieposłuszeństwa nie jest tym samym, co stwierdzenie, że się nie będzie posłusznym. Stale popełniamy błąd polegający na przypisywaniu - przede wszystkim sobie, a następnie innym ludziom - większej niezależności, zdolności kontroli i irracjonalności, niż się to obserwuje rzeczywiście, gdy my sami (lub oni) znajdziemy się w sytuacji społecznej, takiej jak opisana przez Milgrama. Nie doceniamy potęgi sił społecznych oddziałujących na osobę, która dostała się pod tego rodzaju „matrycę społeczną”.
Matryca społeczna wymuszająca posłuszeństwo wobec autorytetu nie zaczyna działać w laboratorium psychologa społecznego, lecz w klasie szkoły podstawowej, w szkółce niedzielnej i w innych środowiskach socjalizujących, gdzie uczą nas, aby nie było nas słychać, abyśmy nie sprawiali kłopotu, nie odcinali się („nie odczekiwali”) i nie zadzierali zbytnio nosa. Pożywka dla społecznego zła jest naiwność, z jaką akceptuje się takie ograniczenia naszej niezależności jako uzasadnione i normalne.
Świat realny dostarcza obficie materiałów dowodowych na poparcie twierdzenia, że występowanie ślepego posłuszeństwa jest prawdopodobne zawsze wtedy, gdy są spełnione trzy podane poprzednio warunki. Do najbardziej chyba przekonywujących przykładów ślepego posłuszeństwa wobec autorytetu - robić to, co każą - należą przytoczone niżej dwie wypowiedzi: zapisany na taśmie wywiad jednego z autorów niniejszej książki z rannym weteranem wojny wietnamskiej, który opisuje, jak zabijał kobiety i dzieci oddalone od niego zaledwie o parę metrów oraz wypowiedzi lotnika, który rzucił pierwszą bombę atomową na Hiroszimę.




Zbliżenie


Mordercza siła posłuszeństwa


„Weteran: Najbardziej niezwykłego przeżycia doznałem kiedyś w strefie zdemilitaryzowanej. Byliśmy w małej wiosce i tam ostrzelano nas z karabinu maszynowego umieszczonego w budynku szkolnym. Rozproszyliśmy się wszyscy i przylgnęliśmy do ziemi. Mówiłem już, że byłem sanitariuszem (bez broni), lecz tylko ja zajmowałem odpowiednią pozycję. Wręczono mi więc granat i powiedziano, żebym wrzucił go przez okno i zlikwidował ich. Gdy więc podkradłem się dostatecznie blisko, aby móc zajrzeć do wnętrza, do którego miałem go wrzucić, wówczas zauważyłem, że było tam dwadzieścioro czy trzydzieścioro dzieci, które siedziały w kącie w końcu pokoju z dwoma czy trzema paniami. Wrzuciłem granat i... wysłałem ich wszystkich do piekła.
ZIMBARDO: Czy był jakiś inny sposób, w który mógłbyś zlikwidować karabin maszynowy bez...
WETERAN: Nie. Nie było żadnego w ogóle sposobu, ponieważ, że tak powiem, znajdował się on około trzech stóp od nich. A ten granat jest tak skonstruowany, że średnica rażenia wybuchu wynosi przynajmniej trzydzieści czy pięćdziesiąt stóp. Nie miałem czasu myśleć, bo albo zostaniesz zastrzelony, albo ich zabijesz. Albo oni, albo ty. Chodzi tu więc po prostu o utrzymanie się przy życiu. Ratuj swoją skórę.
ZIMBARDO: Co było potem? Chodzi mi o to, że gdy wrzuciłeś go, to czy wszyscy zostali zabici, czy...
WETERAN: Oczywiście. Wszystkie dzieci zostały zabite, budynek został zniszczony, tak to było. Czy jest jeszcze coś, co chciałbyś wiedzieć?
ZIMBARDO: Czy jest jeszcze coś, o czym chciałbyś mi opowiedzieć?
WETERAN: W ostatnich dwóch tygodniach mojego pobytu w dżungli byłem na zwykłym patrolu i mała dziewczynka w wieku około trzech lat zaczęła biec ku nam. Gdy była około czterdziestu czy sześćdziesięciu stóp od nas, zauważyliśmy, że coś podskakiwało na jej plecach, gdy tak biegła, i nasz oficer powiedział „strzelajcie”, zastrzeliliśmy ją. W chwili, gdy ją zastrzeliliśmy, ona eksplodowała. Została rozerwana w małe kawałeczki.  Partyzanci przyczepili jej minę do pleców i była ona nastawiona tak, żeby wybuchła wtedy, gdy dziewczynka do nas biegnie. To było tak - albo ona, albo my. Nie wiedzieliśmy na pewno, czy była tam mina, lecz nie mogliśmy ryzykować.
ZIMBARDO: Kiedy oficer powiedział „Strzelajcie!”, ilu ludzi strzelało?
WETERAN: Wszyscy strzelaliśmy do niej. Było nas w tym plutonie około trzydziestu.
ZIMBARDO:  Ale czy |ty musiałeś to zrobić?
WETERAN: Oczywiście. Musisz to zrobić, masz rozkaz to zrobić. Albo strzelasz do nich, albo, jeśli nie strzelasz do nich, twój oficer zastrzeli ciebie. Nie ma żadnego wyboru. Żadnego co do tego wyboru - nie masz czasu pomyśleć o tym, po prostu to robisz”.


Natomiast lotnik ów, kiedy stosunkowo niedawno przeprowadzano z nim wywiad, wspominał: „Po prostu śmiałem się”, gdy „oni powiedzieli, że skonstruowano bombę, która zburzy wszystko na przestrzeni 8 mil”. Nie poinformowano go, co zawiera jego ładunek, lecz gdy dowiedział się o tym, że konieczne będzie wykonanie przez lecący samolot specjalnych manewrów dla uniknięcia chmury w kształcie grzyba, „zestawiłem ze sobą te fakty i doszedłem do wniosku, że było to radioaktywne”. Niemniej jednak stwierdza on, „latałem do tego czasu na tyle zadań bojowych, że była to przede wszystkim robota do wykonania”.  Charakterystyczna różnica między |nie |zgadzaniem |się i |nieposłuszeństwem, jak również typowy błąd polegający na przecenianiu u |innych ludzi znaczenia wewnętrznej, osobistej kontroli i niedocenianiu wpływu sytuacji społecznej na ich zachowanie i decyzje, zostały podsumowane w następującym stwierdzeniu lotnika:


„Nie wierzę we wszystko, co robimy, lecz jeśli jestem w wojsku, to muszę popierać rząd. Mogę nie zgadzać się, jeśli jednak zostanie wydany rozkaz, to z pewnością go wykonam. Sadzę, że każdy ma dość rozsądku, aby nigdy nie użyć ponownie tej bomby („Newsweek”, 10 sierpnia 1970).




Dynamika grupowego
myślenia




W wielu organizacjach i instytucjach nie pojedynczy człowiek, lecz |grupa ludzi podejmuje ważne decyzje oraz ustala kierunek i zasady działania.  Zaletą takiego procesu grupowego jest to, że umożliwia on ujęcie problemu z kilku różnych punktów widzenia, dzięki czemu decyzja nie jest zależna jedynie od uprzedzeń czy błędów oceny jednej osoby. Jednakże nawet mimo wkładu wnoszonego przez wiele różnych osób, decyzje grupowe mogą niekiedy okazać się zupełnie błędne - tak bardzo, że później inteligentni, bystrzy ludzie zadają sobie pytanie: „Jak mogliśmy być tak głupi?”
Starając się zrozumieć, w jaki sposób taki proces grupowy może prowadzić w błędnym kierunku, Irving Janis (1972) przeprowadził szczegółową analizę kilku poważnych decyzji politycznych, które doprowadziły do fiaska, takich jak inwazja na Kubę w Zatoce Świń w 1961 roku oraz inwazja Korei Północnej.  Po przeanalizowaniu tysięcy stron dokumentów historycznych, Janis stwierdził, że te poważne błędy były rezultatem tego, co nazwał |grupowym |myśleniem („groupthink”) - pewnego sposobu myślenia występującego u osób tworzących grupę o dużej spójności wtedy, gdy staną się one tak zaabsorbowane dążeniem do jednomyślności i utrzymywaniem jej, że powoduje to obniżenie ich zdolności do krytycznego myślenia. Zamiast starannie rozważać „za” i „przeciw” decyzji, rozpatrywać alternatywne możliwości, podnosić kwestie moralne itd., w grupie takiej dominuje troka o ukształtowanie |wspólnego |poglądu, co naraża ją na popełnienie poważnych błędów.
Grupowe myślenie charakteryzuje się ośmioma głównymi cechami:
a) złudzeniem całkowitego bezpieczeństwa, które prowadzi do nadmiernego optymizmu i zachęca do podejmowania skrajnego ryzyka;
b) zbiorowym racjonalizowaniem działań grupy, co pozwala tej grupie odrzucać wszelkie dane, które są sprzeczne decyzją;
c) niepodważalną wiarą w immanentną, przyrodzoną moralność grupy, co prowadzi tę grupę do ignorowania etycznych czy moralnych następstw decyzji;
d) stereotypowymi poglądami na wroga - jako słabego, złego (co wyklucza rokowania) oraz8lub głupiego;
e) silnym naciskiem wewnętrznym na członków grupy, aby dostosowali się do norm grupowych i nie różnili się w poglądach;
f) indywidualną autocenzurą myśli i idei, które odbiegają od wspólnych poglądów grupy;
g) złudzeniem jednomyślności decyzji, której jest po części rezultatem nacisków nakłaniających do konformizmu, o których wspomniano powyżej;
h) pojawieniem się samozwańczych „strażników umysłów” („mindguards”) - członków grupy, którzy tłumią niedogodną informację i ganią każdego, kogo poglądy odbiegają od wspólnych poglądów grupy.

Grupowe myślenie nie jest cechą pewnych rodzajów ludzi, jest ono raczej procesem, który może zachodzić we wszelkich rodzajach grup, nawet tych, które składają się z najlepszych i najbardziej inteligentnych ludzi.  Doniosłe znaczenie ma więc następujące pytanie: „Kiedy wystąpienie grupowego myślenia jest najbardziej prawdopodobne?” Janis wskazał trzy warunki sprzyjające grupowemu myśleniu: a) duża spójność grupy podejmującej decyzję; b) izolacja tej grupy od innych, bardziej zrównoważonych, od zewnętrznej informacji i zewnętrznych autorytetów oraz c) poparcie danego sposobu działania przez przywódcę grupy. Warunki te łącznie przyczyniają się do ukształtowania grupy, która prawdopodobnie dość szybko dojdzie do wspólnego poglądu, a kiedy to nastąpi, to będzie zmuszać swych członków do popierania go.
Planowanie inwazji w Zatoce Świń, która odbyła się w 1961 roku, jest dobrym przykładem procesu grupowego myślenia. Prezydent Kennedy i jego doradcy stanowili spójną grupę, która pracowała wspólnie od wielu lat.  Informacje o innych możliwych rozwiązaniach oraz zarzuty wobec tego planu nie były dopuszczone do tej grupy, a kilku ekspertów o wysokich kwalifikacjach zostało wyłączonych ze spotkań. Prezydent Kennedy, aczkolwiek niekiedy krytykował ten plan, to jednak wyraźnie zakomunikował grupie swe poparcie dla niego. Sprawozdania z posiedzeń poświęconych podjęciu decyzji wyraźnie świadczą o występowaniu na nich objawów grupowego myślenia. Ponieważ kariera polityczna Kennedy’ego była szeregiem niezwykłych sukcesów, grupa ta miała zatem poczucie całkowitego bezpieczeństwa i pewności - że wszystko nadal będzie się udawać. Inwazję uzasadniano poglądem, że Kubańczycy przyłączą się do tej sprawy i zbuntują się przeciwko Fidelowi Castro, mimo że nie było żadnych danych przemawiających za tym poglądem. Stereotypowe traktowanie nieprzyjaciela jako słabego i głupiego znalazło swe odbicie w przypuszczeniach (które wszystkie okazały się błędne), że działania wojska kubańskiego nie będą skuteczne i że Castro nie podejmie kroków w celu powstrzymywania możliwych zwolenników emigrantów dokonujących inwazji. I tak dalej...
Biorąc pod uwagę katastrofalne skutki, jakie mogą wyniknąć z grupowego myślenia, co można zrobić, aby zapobiec jego wystąpieniu? Janis wysuwa kilka propozycji; wszystkie one zmierzają do zmiany procesu podejmowania grupowej decyzji w taki sposób, żeby sprzyjał on niezależnemu myśleniu. Na przykład, zaleca on stosowanie procedur, które zmuszają członków grupy do krytycznej oceny zarówno pomysłów własnych, jak i pomysłów innych osób, które tworzą kanały zapewniające dopływ informacji, sprzężenia zwrotnego oraz krytyki ze strony zewnętrznych ekspertów lub grup i które wymagają, aby grupa analizowała i inscenizowała reakcje i strategie opozycji. Chociaż nie przeprowadzono żadnych badań w celu sprawdzenia trafności tych zaleceń, to jednak należy podkreślić w formie uwagi historycznej, że niektóre z tych technik zostały intuicyjnie przyjęte przez prezydenta Kennedy’ego po fiasku w Zatoce Świń. W następnym roku ta sama w zasadzie grupa ludzi stanęła wobec kryzysu związanego z zainstalowaniem na Kubie wyrzutni rakietowych i tym razem potrafiła podjąć bardzo efektywną grupową decyzję.




Watergate i degeneracja
lojalności




„Więc w drogę! Wszędzie pójdę z tobą, panie,
Wiernie, uczciwie, póki ducha stanie” (Przekład Leona Ulricha. William Szekspir „Dzieła dramatyczne”. Warszawa 1980)).
William Szekspir „Jak wam się podoba” - II; 3


Być lojalnym wobec jakiejś osoby lub idei, to uznawać siebie nie tylko za istotę obdarzoną zmysłami, lecz za wrażliwą istotę społeczną, zdolną do wykroczenia poza skoncentrowane na sobie samym, indywidualne sprawy. Cała konstrukcja życia w społeczeństwie opiera się w gruncie rzeczy na lojalność; degeneracja tej lojalności może być śmiertelną trucizną.
Latem 1973 roku większość Amerykanów była wstrząśnięta odkrywając, że dla ludzi, którzy kształtują losy ich kraju, „lojalność”, „obowiązek” i „gra zespołowa” mają całkiem odmienne znaczenie niż dla większości z nas.  Skandal Watergate ujawnił spisek (zawiązany przez najbliższych współpracowników prezydenta USA oraz Komitet na rzecz Ponownego Wyboru Prezydenta w 1972 roku) mający na celu założenie podsłuchu i włamanie się do głównej kwatery Partii Demokratycznej, mieszczącej się w biurowcu Watergate w Waszyngtonie.
Gdy podkomisja Senatu zaczęła badać ten spisek, wówczas wyszły na jaw zdumiewające rozmiary przestępczych działań, które były podejmowane przez tych ludzi w imię obrony „bezpieczeństwa narodowego”. Korzystali oni z pośrednictwa Prokuratora Generalnego, CIA, FBI oraz władz skarbowych w gromadzeniu tajnych akt dotyczących potencjalnych wrogów politycznych i dysynentów. Zestawili oni listę Amerykanów - senatorów, przywódców związkowych, aktorów, reporterów, sportowców i nawet rektorów niektórych uniwersytetów - których uznali za „wrogów”, tak aby mogli oni być wystawieni na ataki federalnej machiny biurokratycznej. Dyskredytowali przeciwników politycznych za pomocą fałszowanych listów i innych dokumentów. Wykradli akta psychiatry leczącego człowieka, który publikując dokumenty Pentagonu ujawnił oszustwa rządu w związku z wojną wietnamską.  Przeznaczali oni fundusze z kasy Partii Republikańskiej na płacenie łapówek mających na celu ukrycie ich nielegalnej działalności; są też dowody, że dopuścili się oni przestępstwa polegającego na wymuszaniu od wielkich przedsiębiorstw pieniędzy na kampanię wyborczą.
Jak mogło tak wielu pozornie przyzwoitych, szanowanych obywateli - absolwentów uniwersytetów, prawników, odnoszących sukcesy i dobrze sytuowanych finansowo „ojców rodzin” wyrzec się tak zupełnie poczucia moralności? Odpowiedź na to pytanie jest oczywiście złożona, lecz jej rdzeń można znaleźć w koncepcjach już zarysowanych w naszej uprzedniej analizie przemocy, patologii społecznej i zła. Aczkolwiek wydarzenia te i ich konsekwencje można analizować na poziomie prawnym, politycznym i socjologicznym, to nas jednak interesują tutaj siły psychologiczno-społeczne, oddziałujące na jednostki zamieszane w aferę Watergate.
W przypadku niektórych z nich motywacją była próżność - przyczyna upadku Ewy w Raju. „Moja próżność została mile połechtana, gdy powiedziano mi, że moje nazwisko będzie wymienione na wysokich szczeblach władzy, że jestem uczciwym człowiekiem, że mam dobrą prezencję i gdy i usłyszałem inne tego rodzaju rzeczy”, powiedział jeden z członków Komitetu na rzecz Ponownego Wyboru Prezydenta (UPI, 13 czerwca 1973).
Niektórzy inni uczestnicy tej nielegalnej działalności postępowali w ten sposób z poczucia |obowiązku. Były zastępca Generalnego Prokuratora zeznał, że pomagał kryć skandal Watergate wbrew swemu sumieniu, ponieważ uważał, że obowiązkiem prawnika jest służyć swemu klientowi. Poczucie obowiązku wobec tych, którzy sprawowali władzę, przekształciło się w irracjonalną gorliwość, gdy ludzie ci zaczęli rywalizować o honorowe miejsca, jak najbliżej ośrodka władzy.
Odrętwienie psychiczne i zdehumanizowany sposób patrzenia, które wynikają z przekonania, że czyjeś cele są dostatecznie ważne, aby usprawiedliwić wszelkie środki działania, doprowadziły pewnego urzędnika do stwierdzenia: 
„Kiedy ci faceci przychodzili, to zdawałem sobie sprawę, że postępują oni nielegalnie, i jestem pewien, że inni również o tym wiedzieli.  Przyzwyczailiśmy się jakoś do wykorzystywania pewnych działań, które pomagały nam w zrealizowaniu tego, co uważaliśmy za sprawę, słuszną sprawę” („New York Times” Service, 15 czerwca 1973).
Lecz najważniejszymi czynnikami były te, które sprzyjały wytworzeniu się atmosfery „grupowego myślenia”, wśród pomocników i współpracowników Prezydenta. Analogie do ogólnej charakterystyki nakreślonej przez Janisa są tu zaskakująco bliskie. Doniosłą rolę wśród tych czynników odgrywały a) nacisk na |tajność, która sprawiała, że żaden z tych urzędników państwowych nie musiał liczyć się ze społeczeństwem ani z prasą, b) zbiorowa |paranoja, skierowana przeciw hipisom, radykałom występującym przeciw wojnie oraz innym krytykom administracji; c) niepodważalne przekonanie, że postępując nielegalnie i niemoralnie oraz wykorzystując środki państwowe przeciw |własnym wrogom, bronią oni „bezpieczeństwa narodowego”, d) podkreślanie znaczenia zgodności poglądów w zespole, w którym pełnienie roli |gracza |zespołowego („team player”) było niezbędne, aby być osobiście akceptowanym przez innych członków grupy.
Ten ostatni punkt zasługuje na specjalną uwagę w przypadku narodu mającego takie zamiłowanie do sportu, jak naród amerykański. Być „graczem zespołowym” w drużynie sportowej, znaczy tyle, co pracować dla sukcesu zespołu, a nie dla indywidualnej sławy czy chwały. Jest pochwałą, jeśli twój zespół czy przywódca uznają cię za takiego gracza. W polityce pojęcie to zostało wypaczone tak, że znaczy ono: zgadzać się, nie przyczyniać kłopotów partii, być konformistą, nie mieć zbyt wrażliwego sumienia. W aferze Watergate to wynaturzenie pozytywnego stosunku jednostki do swej grupy było całkowite. Jeden ze spiskowców wyjaśnił, dlaczego „zrezygnował ze swego sumienia”, w taki oto sposób: uczynił to „dla Prezydenta, ze względu na nacisk, jaki wywiera grupa, gdy nie jest się graczem zespołowym”.




Dehumanizacja stosunków
między ludźmi




Czy kiedykolwiek mógłbyś rozmyślnie dokuczyć drugiej osobie, upokorzyć ją lub poniżyć? Czy możesz wyobrazić sobie, że odrzuciłbyś prośbę ubogiej rodziny o trochę pożywienia czy ubrania, jeśli byłbyś w stanie spełnić tę prośbę po prostu podpisując się? Czy jest do pomyślenia, abyś kiedykolwiek zadecydował, że pewne grupy są niedostosowane i zarządził ich eksterminację? Co musiałoby się zdarzyć, żeby doprowadziło cię to do zabicia drugiego człowieka?
Normalni, prawidłowo rozwinięci moralnie i nastawieni idealistycznie ludzie mogą stać się zdolni do tych i innych antyspołecznych zachowań w warunkach, w których ludzie przestają spostrzegać innych ludzi jako osoby mające takie same uczucia, pragnienia, myśli i cele w życiu, co inni. Takie „psychiczne zatarcie” ludzkich cech nosi nazwę |dehumanizacji. Powoduje ona, że na ludzi patrzy się jak na przedmioty, a nie jak na istoty ludzkie, i tak też się ich traktuje. W przeciwieństwie do humanistycznych stosunków między ludźmi (które są subiektywne, osobiste i emocjonalne) zdehumanizowany stosunek jest obiektywny, analityczny i pozbawiony emocjonalnych lub empatycznych interakcji czy reakcji. Znany teolog Martin Buber określił pierwszy typ reakcji jako stosunek „Ja - Ty”, a relację zdehumanizowaną jako stosunek „Ja - To”.
Proces dehumanizacji chroni jednostkę przed wszelkiego rodzaju pobudzeniem emocjonalnym, które mogłoby być przykre, przytłaczające, odbierające siły lub mogłoby zakłócać jakieś niezbędne, realizowane w danej chwili działanie. Na przykład w sytuacjach poważnego kryzysu lub nagłej potrzeby (podczas wojny, w czasie klęsk żywiołowych) lub też w sytuacjach wymagających dokładnego, obiektywnego, nieosobistego działania dotyczącego innej osoby (podczas operacji chirurgicznej) zdehumanizowane nastawienie do innych ludzi może służyć jako środek obrony przeciw reakcjom emocjonalnym, które inaczej mogłyby działać zakłócająco lub obezwładniająco. W sytuacjach tych dehumanizacja może zatem spełniać rolę przystosowawczą.


Lecz dehumanizacja może także mieć wiele negatywnych i destruktywnych następstw. Kiedy nie reagujesz na ludzkie cechy innych osób, wówczas bardziej możliwe staje się nieludzkie postępowanie wobec nich. „Złota Reguła” przybiera wówczas postać: „Czyń drugiemu, co tobie miłe”. Łatwiej jest być nieczułym czy szorstkim wobec zdehumanizowanych „obiektów”, ignorować ich żądania i prośby, wykorzystywać ich do swych własnych celów, a nawet niszczyć ich, jeśli nas drażnią. Ludobójstwo dokonywane przez hitlerowców na Żydach i Cyganach mogło być realizowane z taką samą sprawnością jak ta, którą codziennie można obserwować w rzeźniach Omaha, a to dzięki zastosowaniu prostego sposobu - uznania tych naszych bliźnich istot ludzkich za niższe formy życia zwierzęcego. Dla wielu wojskowych w Wietnamie Wietnamczycy przestali być ludźmi, o czym świadczy rozpowszechniona szeroko tak  zwana „reguła żółtka” („gook rule”): zabicie cywilnego Wietnamczyka było w zasadzie równe zabiciu roboczego bawoła.
Ten sam podstawowy mechanizm psychologiczny działa w wielu znanych sytuacjach i stwarza stałe zagrożenie dla fundamentalnych zasad sprawiedliwości społecznej i ludzkiej godności. Gdy wielką liczbę ludzi trzeba „załatwić”, to załatwianie to może przybrać anonimowy charakter - pozbawiony cech ludzkiego kontaktu czy zainteresowania.
Kandydatom do korporacji studenckich każe się, by przyczyniali się do własnej dehumanizacji recytując: „Jestem kandydatem; kandydat to najniższa forma życia zwierzęcego na terenie uniwersytetu”. Nawet treningi drużyny sportowej, mające na celu zdobycie sławy przez dany uniwersytet, mogą stać się niewiarygodnie okrutnym ćwiczeniem w dehumanizacji i brutalności.




Zbliżenie


Futbol kształtuje charakter


„Dwudziestu ośmiu graczy zwolniło się, albo zostało zwolnionych z pewnej uniwersyteckiej drużyny futbolowej, z powodu swego sprzeciwu wobec brutalnych pod względem fizycznym metod treningowych stosowanych w ramach przygotowań do sezonu rozgrywek. Według jednego z graczy, „Każdy z taką determinacją dążył do zwycięstwa, że kopaliśmy się, walili, zadawali sobie nawzajem ciosy w podbrzusze, robiliśmy wszystko”.
Walki, w których dwaj przeciwnicy walczyli skuleni pod drutami rozciągniętymi na wysokości czterech stóp od podłogi, były „czymś najokrutniejszym, co kiedykolwiek widziałem (...), to było do tego stopnia odczłowieczające, że gdybyś znalazł się tam ze swoim najlepszym przyjacielem, to starałbyś się go zabić(...). Na początku siadaliśmy na macie plecami do siebie, przy czym na każdym rogu maty odbywał się jeden mecz. Na gwizdek trenerzy kazali nam odwrócić się do siebie i po prostu walić jeden drugiego ile wlezie, aby po prostu wbić przeciwnika w matę.  Kazali oni kontynuować te mecze tak długo, dopóki nie uznali, że dałeś z siebie wszystko lub dopóki nie stłukłeś na kwaśne jabłko przeciwnika (...).  Wszyscy byli zupełnie zdesperowani.
Musiałeś wygrać, ponieważ wszyscy przegrywający musieli walczyć znowu i znowu, i znowu, dopóki nie zwyciężyli. Musiałem walczyć nawet siedem lub osiem razy. Ostatni przegrywający w danym dniu musiał zgłosić się o godzinie #3#/30 w piątek rano, aby biegać w górę i w dół po stopniach stadionu. Ludzie byli tak wyczerpani psychicznie i fizycznie, że zataczali się jak pijani, zadając sobie ciosy i chybiając. Byliśmy zbyt zmęczeni, aby utrzymać się w nakazanej pozycji i kilka razy zawodnicy podnieśli się i pokaleczyli dotkliwie drutami” (komunikat Associated Press, 11 czerwca 1973).




Funkcje dehumanizacji




Warunki, które zachęcają ludzi do traktowania innych jak przedmioty, wiążą się z funkcjami, jakim może służyć dehumanizacja - pozornymi korzyściami, jakie może ona przynosić komuś, kto ją stosuje.




* * *



Ryc. 14.18. W Tokio takie upychanie podróżnych w pociągu podmiejskim jest rzeczą normalną.


* * *





Dehumanizacja może być: a) narzucona społecznie, b) stosowana w samoobronie, c) stosowana rozmyślnie dla autogratyfikacji lub d) zracjonalizowana jako konieczny środek dla osiągnięcia pewnego szlachetnego celu.


Dehumanizacja narzucona społecznie. Dehumanizacja może występować w różnych sytuacjach pracy; wynika to ze sposobu, w jaki dana praca jest definiowana przez społeczeństwo. Takie definicje należą do dwóch zasadniczych kategorii: a) dana praca wymaga, aby jednostka dehumanizowała innych ludzi, by móc uporać się z nimi oraz b) dana praca dehumanizuje samego pracownika, ponieważ nie daje mu żadnej sposobności do wyrażenia ani osobistych uczuć, ani specyficznie ludzkich zdolności.
Do pierwszej kategorii należą sytuacje, w których trzeba sprawnie „załatwić” dużą liczbę ludzi - na przykład studentów wyższej uczelni w czasie rejestracji, pasażerów dojeżdżających pociągami podmiejskimi w czasie godzin szczytu, więźniów lub pacjentów psychiatrycznych w czasie posiłków. Aby tego dokonać, pracownicy administracyjni tych instytucji często dbają o „pokierowanie strumieniem ludzi”, kontrolowanie rozkładów czasu oraz minimalizowaniem zakłóceń. Gdy liczba osób, które trzeba obsłużyć, staje się zbyt wielka, wówczas przestają one być uważane czy traktowane jako „osoby”. Wprowadzenie i wyprowadzenie pacjentów psychiatrycznych do stołówki czy łazienek może stać się ważniejsze niż dbałość o wyniki terapii. Gdy liczba osób przyjmowanych na uczelnię wzrasta, wówczas studenci stają się anonimowymi liczbami na kartach kodowych komputerów i wykładowcom trudno jest nawiązać z nimi stosunki na tyle choćby osobiste, by poznawać ich poza salą wykładową. Wpychanie ludzi do wagonów metra przez pracowników kolei tokijskiej, zatrudnionych w charakterze „pakowaczy”, nie jest bardziej dehumanizujące niż biurokratyczne „utrudnianie życia”, czy też twierdzenie, że nie ma żadnych (ludzkich) wyjątków od „zasad” (ryc. 14.18).


„Nie możesz czuć się ani trochę dumny. Trudno jest być dumnym z mostu, po którym nigdy nie przejdziesz, albo z bramy, której nigdy nie otworzysz.  Produkujesz coś masowo i nigdy nie widzisz końcowego rezultatu”.
Z wywiadu z robotnikiem stalowni w Terkel, 1974


Drugą kategorię narzuconej społecznie dehumanizacji w sytuacji pracy najlepiej chyba ilustruje cud amerykańskiej techniki - linia montażowa. Na linii montażu samochodów poszczególne ich egzemplarze mogą mijać stanowisko każdego pracownika w tempie ponad pięćdziesiąt na godzinę. Każdy pracownik ma mniej niż minutę na wykonanie zadania i musi powtarzać je godzina po godzinie.
Praca przy takich liniach montażowych jest tak wyczerpująca i przygnębiająca, że nawet w czasie niedawnego okresu wysokiego bezrobocia - wynoszącego między 8 a 9% - pewne duże przedsiębiorstwo samochodowe podawało, że w ciągu roku 4000 nowo zatrudnionych pracowników nie wytrzymało przy tej pracy nawet jednego dnia!




* * *



Ryc. 14.19. Kółeczko w machinie gospodarczej: człowiek kontrolujący nie kończący się rząd butelek. Taka praca nie daje żadnej możliwości wyrażenia osobistych uczuć ani też wykazania specyficznie ludzkich uzdolnień.


* * *





Jednakże na każdego, kto zwolnił się po upływie mniej niż ośmiu godzin, przypadło wielu takich, którzy nie mogli pozwolić sobie na luksus porzucenia pracy i w ten sposób dobrowolnie zaciągali się w szeregi „przymusowej siły roboczej” (Price, 1972).
Robotnik taki nie czuje się w jakiś sensowny sposób związany z wytworem swej pracy i pracuje tylko po to, żeby zarobić pieniądze, za które kupi rzeczy wytwarzane przez innych ludzi. Rezultaty - to wysokie wskaźniki absencji, duża płynność kadr, zła jakość pracy, alkoholizm i nadużywanie narkotyków w pracy, powszechne niezadowolenie robotników, coraz więcej przypadków zaburzeń zdrowia psychicznego, niższa wydajność pracy oraz zagrażające życiu samochody, które trzeba wycofywać ze sprzedaży - wszystko to świadczy o tym, jak powszechna jest dehumanizacja na współczesnym rynku pracy (przesłuchania Kongresu USA w sprawie alienacji pracowników „Congressional Hearings on Worker Alienation”, 1972).


Dehumanizacja stosowana w samoobronie. W służbie zdrowia i w wielu innych zawodach usługowych ludzie muszą funkcjonować w sytuacjach, które zwykle wzbudzają bardzo intensywne emocje, wywołują bolesną empatię i8lub wymagają zachowań uznawanych za „tabu”, takich jak wtargnięcie w sferę prywatności lub naruszenie nietykalności ciała ludzkiego. Aby móc sprawnie działać w takich sytuacjach, jednostka często wytwarza mechanizmy obronne przeciw tym zakłócającym emocjom, stosując techniki dehumanizacji.



Traktując swych klientów czy pacjentów w obiektywny, „oderwany” sposób, łatwiej jest przeprowadzać niezbędne wywiady, testy czy operacje nie doznając silnego dyskomfortu psychicznego.
Chirurdzy podają na przykład, że aby móc wykonywać sprawnie swe zadania, musieli najpierw nauczyć się nie widzieć całej osoby pod skalpelem, lecz tylko narząd, tkankę czy kość. W obrębie tego zawodu proces ten nazywa się „odizolowanym zainteresowaniem” („detached concern”), termin ten najlepiej oddaje trudną (i prawie paradoksalną) sytuację - konieczność dehumanizowania ludzi w celu przyjścia im z pomocą lub wyleczenia ich (zob.  Lief i Fox, 1963).
Jednakże „oderwanie” to może przybrać skrajną postać. Jeli stres i napięcie psychiczne związane z daną pracą stają się zbyt silne (na przykład, gdy asystent społeczny usiłuje pomóc kilkuset ubogim i cierpiącym rodzinom), wówczas dana osoba może „wypalić się” emocjonalnie i stracić wszelkie ludzkie uczucia dla ludzi, którym służy. Nierzadko zdarza się, że niektóry opiekunowie społeczni zaczynają odmawiać prośbom o zaopatrzenie w pokarm czy odzież ze względu na związane z tym dodatkowe trudności biurokratyczne oraz podejrzenia, że są „nabierani”.
Ten sam obronny, bezosobowy styl obserwuje się niekiedy u tych, który pracują z dziećmi upośledzonymi umysłowo lub z chorymi na schizofrenię, z nieuleczalnie chorymi pacjentami czy ze starszymi ludźmi przebywającymi w zakładach.
W wielu tak zwanych domach dla osób w podeszłym wieku nieszczęsnym pensjonariuszom podaje się nadmierne dawki środków uspokajających, aby łatwiej było nimi kierować, zmusza się ich, aby bezczynnie pozostawali w łóżku, w celu zmniejszenia ryzyka wypadku, a co za tym idzie - stawek ubezpieczeniowych (i aby łatwiej było ich obsługiwać); odmawia się im wszelkiej prywatności, pozbawia drobnych wygód i nie pozwala na żadne  zachcianki; i wreszcie zapewnia się im ledwie wystarczające wyżywienie. Dla pacjentów staje się oczywiste, że ich przedłużająca się egzystencja jest jedynie ciężarem dla krewnych i personelu (Burger, 1969).


Dehumanizacja dla uzyskania autogratyfikacji. Niekiedy inni ludzie są używani jedynie dla własnego zysku, przyjemności czy rozrywki, przy czym nie poświęca się żadnej uwagi ich uczuciom czy myślom. Przykładem tego procesu jest prostytucja, w której jedna osoba otwarcie kupuje sobie przywilej dehumanizowania drugiej jednostki. Nawiasem mówiąc, prostytutka odwzajemnia się tym samym, uważając klienta za jeszcze jeden „numer” do zaliczenia. Mężczyźni, dla których stosunek seksualny jest doznaniem służącym jedynie własnej gratyfikacji - z kobietą będącą po prostu środkiem do tego celu - dają wyraz tej dehumanizacji, gdy nazywają ją „lalką”, „suką”, „krową” itd.
O tym, jak głęboko może sięgać ta niewrażliwość na inne istoty ludzkie, świadczą zamieszczone w dziennikach opisy osób, które podjudzają ludzi zamierzających popełnić samobójstwo, aby zrealizowali swój zamiar - po to tylko, by móc na to patrzeć i czerpać podniecenie z tego widoku.


„W Albany, w stanie Nowy Jork, pewnego mężczyznę ocaliły od samobójczego kroku prośby jego siedmioletniego bratanka, podczas gdy widzowie podjudzali: „Skacz! Skacz! Skacz!”. Wśród tłumu ciekawych złożonego z około 4000 osób byli ludzie zachęcający go do skoku: „Dalej! Jesteś mięczak!” „Jesteś żółtek” i zakładający się, czy skoczy, czy też nie. Pouczająca jest też uwaga wygłoszona przez pewnego dobrze ubranego mężczyznę: „Mam nadzieję, że skoczy po tej stronie. Nie moglibyśmy go widzieć, gdyby skoczył na drugą stronę” („New York Times”, 14 kwietnia 1964).
Tę samą degenerację zainteresowań społecznych można było zaobserwować w Miami na Florydzie, gdy 87 -letni mężczyzna pogrążony w depresji wskutek wielu lat samotności groził, że popełni samobójstwo skacząc z mostu.  Zamiast starać się zapobiec jego śmierci, grupa osób obecnych tam zachęcała go: „Dalej, skacz! Skacz! Skacz!”. Przyjął on tę radę i skoczył. Pewien młody człowiek pospieszył mu z pomocą, wyciągnął go z rzeki i na próżno usiłował przywrócić do życia, a apatyczny tłum patrzył na to nie oferując żadnej pomocy („Knight Newspapers Service”, 17 sierpnia 1973).
Jeszcze bardziej niewiarygodnym przykładem dehumanizacji jest doniesienie o pacjentkach szpitala psychiatrycznego, które personel wyprowadzał potajemnie z tego zakładu i zmuszał do prostytucji. Był w to wciągnięte nawet małe dziewczynki. Pielęgniarki otrzymywały rzekomo 10 dolarów za każdą „przeszmuglowaną” pacjentkę - sama pacjentka dostawała cukierka lub monetę (komunikat prasowy UPI, 25 marca 1969).


Dehumanizacja jako środek pozwalający osiągnąć cel. Wiele razy w historii zdarzało się, że ludzie uważali określona grupę innych ludzi za przeszkodę umożliwiającą im osiągnięcie celów. Spostrzegając takich ludzi jako „wrogów”, „masy”, „zagrożenie dla bezpieczeństwa narodowego”, „istoty niższe” itd., łatwiej było podjąć akcję przeciwko nim w imię jakiejś wielkiej sprawy, takiej jak pokój, zwycięstwo, wolność czy rewolucja. Ich cierpienie, krzywda czy eksterminacja są następnie często usprawiedliwiane jako środek prowadzący do „wzniosłego celu”. Wiele przykładów takiej dehumanizacji przychodzi na myśl, włączając tu rzucenie bomby atomowej na mieszkańców Hiroszymy w celu zapewnienia pokoju”, masowe mordowanie Żydów przez hitlerowców, ponieważ byli oni „nieprzystosowani” oraz odmówienie leczenia Murzynom dotkniętym syfilisem (grupa kontrolna w budzących zastrzeżenia badaniach przeprowadzonych w Tuskegee w stanie Alabama) w celu „badania przebiegu choroby”.
Aby zademonstrować z jaką łatwością ludzie mogą przyjąć ten zdehumanizowany sposób patrzenia na inne osoby pewien psycholog badał reakcję wielkiej grupy studentów wyższej uczelni na rzekome zagrożenie ich bezpieczeństwa.
„Osobami badanymi byli studenci i studentki z University of Hawaii, w wieku od 17 do 48 lat. Grupy złożone z dwudziestu do trzydziestu osób zbierały się, aby wysłuchać krótkiego przemówienia pewnego profesora. Ten obdarzony autorytetem człowiek prosił ich o współpracę, jako inteligentnych i wykształconych ludzi. Mieli mu oni pomóc w opracowaniu naukowych metod uśmiercania osób nie przystosowanych psychicznie i emocjonalnie. Problem ten został przedstawiony przekonywająco w następującym kontekście:
„W ostatnich latach rośnie zainteresowanie coraz większą groźbą w postaci eksplozji demograficznej. Szczególnie niepokojący jest fakt, że osoby psychicznie i emocjonalnie nieprzystosowane przyczyniają się do wzrostu zaludnienia w znacznie większym stopniu niż ludzie przystosowani emocjonalni i inteligentni. Jeżeli nie podejmie sie jakichś radykalnych środków, to nadejdzie dzień, kiedy przystosowana i inteligentna część ludzkości znajdzie się w niebezpieczeństwie. Kształcenie w zakresie planowania rodziny i środki służące regulacji urodzin nie pozwalają na skuteczne opanowanie tej eksplozji demograficznej; obecnie stało się więc niestety konieczne opanowanie nowych metod uporania się z tym problemem i nowe środki są rozważane przez kilka najpotężniejszych krajów na świecie, włączając nasz własny. Jedną z tych metod jest eutanazja, co oznacza „zabijanie z miłosierdzia”. Takie uśmiercanie większość ekspertów uważa nie tylko za dobrodziejstwo dla nieprzystosowanych, ponieważ uwalnia ich od nędzy i cierpień za życia, lecz co ważniejsze, będzie ono miało dobroczynne skutki dla zdrowej, dostosowanej i bardziej wykształconej części populacji.  Jest to zatem „ostateczne rozwiązanie” poważnego problemu.
Idea takiego rozwiązania nie powinna być zaskakująca, ponieważ już praktykujemy je w wielu krajach, włączając nasz własny; już decydujemy, kiedy jakiś człowiek nie powinien żyć - orzekając na przykład karę śmierci.  Nie jest jednak jasne, jakie metody uśmiercania powinno się stosować, jaka metoda jest najmniej bolesna, kto powinien zająć się uśmiercaniem, a kto decydować, kiedy powinni się uciec do tego sposobu postępowania.
Z tych powodem konieczne są dalsze badania i nasz projekt badawczy dotyczy właśnie tego problemu. Musimy włączyć inteligentnych i wykształconych ludzi do rozwiązywania takich problemów i dlatego prosimy was o pomoc. Wyniki naszych badań wykorzysta się w odniesieniu do ludzi, dopiero wtedy, gdy system ten zostanie udoskonalony. Obecnie musimy wypróbować go najpierw na zwierzętach i dopiero wtedy, gdy zostaną uzyskane niezbędne dane, będzie on zastosowany wobec istot ludzkich u nas i w innych krajach. Jest rzeczą ważną, aby system ten był badany i stosowany w sposób naukowy”.
W czterech odrębnych badaniach zastosowano niewielkie zmiany, różnicując bliskość w czasie tego zagrożenia, zalecane środki (wysyłanie na wojnę bądź eutanazja) oraz grupy charakteryzowane jako nieprzystosowane (Amerykanie, grupy mniejszościowe, Azjaci). Studenci wskazywali, czy aprobują różne przedstawione rozwiązania, czy też nie, a następnie odpowiadali na kilka pytań dotyczących praktycznych aspektów „systematycznego uśmiercania”.
Na koniec powiedziano im o prawdziwym celu tego eksperymentu. Na podstawie ich reakcji emocjonalnych oraz ich prób usprawiedliwiania swych poprzednich odpowiedzi przyjęto, że zaakceptowali oni ten problem, tak jak został on postawiony i naprawdę byli zainteresowani jego rozwiązaniem.
W pierwszym wariancie około dwóch trzecich badanych aprobowało „naukowe rozwiązanie”, gdy określono, że zagrożenie wystąpi w ciągu życia osoby badanej, podczas gdy dwie piąte poparło to rozwiązanie, nawet wówczas, gdy zagrożenie nie miało stanowić niebezpieczeństwa jeszcze przez siedemdziesiąt do stu lat. Zastosowanie naukowej eksterminacji przedkładano nad uśmiercanie nieprzystosowanych przez wysyłanie ich na wojnę, a ponadto częściej aprobowano uśmiercanie grup bardziej różniących się od własnej.  Odpowiedzi studentów na te pytania podano w zamieszczonej poniżej tabeli (Mansson, 1972).


Była to bezpośrednia analogia do realizowanego przez Hitlera ostatecznego rozwiązania „problemu żydowskiego”, lecz zostało to przedstawione jako wysoce intelektualny, naukowy projekt, poparty przez uczonych, zaplanowany dla dobra ludzkości i w gruncie rzeczy stanowiący nawet dobrodziejstwo dla tych, którzy mieli być wyeliminowani. Był on ponadto „uzasadniony” przez analogię z karą śmierci, a tym, których poproszono o wyrażenie opinii, pochlebiano - określając ich jako inteligentnych, wykształconych i uznających wysokie wartości etyczne; aby rozwiać wszelkie pozostałe wątpliwości, zapewniono ich, że przeprowadzi się wiele starannych badań, zanim zostanie podjęta jakakolwiek akcja przeciw ludziom. Jest prawdopodobne, że wszystkich 570 osób badanych powiedziałoby, że nie aprobują one dokonanej przez Hitlera eksterminacji sześciu milionów Żydów, lecz kiedy akcję tę określono inaczej i zamaskowano ją jako coś szlachetnego, to 517 spośród nich zaakceptowało podstawową przesłankę, wszyscy zaś, prócz 33, wskazali nawet, w którym z etapów tej pracy woleliby wziąć udział. Żaden z tych studentów wyższej uczelni nie odmówił wzięcia udziału w takim przedsięwzięciu.
Po kilku latach badanie to zostało powtórzone na 618 studentach wstępnego kursu psychologii, również na University of Hawaii.


„Wyniki były znów niepokojące. Nawet bez naukowego uzasadnienia czy też poparcia przez autorytet, zaznaczyła się ogólna sympatia dla zastosowania „ostatecznego rozwiązania” wobec części ludności ocenionej jako „nieprzystosowana” lub „niebezpieczna dla dobra ogółu”. Nie było żadnych istotnych różnic między odpowiedziami tych, którym podano racjonalne uzasadnienie tego rozwiązania przez „eksperta od spraw populacji zatrudnionego przez administrację federalną”, a tymi, którzy po prostu wypełniali kwestionariusz dany im przez studentów studiów podyplomowych bez żadnego uzasadnienia.




* * *



Opinie Studentów Dotyczące „Ostatecznego Rozwiązania”
1. Czy zgadzasz się, że zawsze będą ludzie bardziej i mniej nadający się do życia?

Zgadzam się - 90%
Nie zgadzam się - 10%
2. Jeśli takie uśmiercanie uzna się za konieczne, to czy osoba lub osoby podejmujące tę decyzję powinny także wykonywać akt śmierci?

Tak - 57%
Nie - 43%
3. Czy byłoby lepiej, gdyby jedna osoba była odpowiedzialna za uśmiercanie, a druga wykonywała ten akt?

Tak - 79%
Nie - 21%
4. Czy byłołoby lepiej, gdyby kilka osób naciskało przyciski, lecz tylko jeden przycisk powodowałby śmierć? W ten sposób zachowana byłaby anonimowość i nikt nie wiedziałby, kto w rzeczywistości uśmiercenia?

Tak - 64%
Nie - 36%
5. Jaką metodę zadawania śmierci uznałbyś za najlepszą i najbardziej efektywną?

„Krzesło elektryczne” -1%
Bolesna trucizna - 9%
Bezbolesny narkotyk - 89%
6. Gdyby prawo wymagało od ciebie asystowania, to czy wolałbyś;

a) być tym, kto asystuje przy podejmowaniu decyzji? - 85%
b) być tym, kto asystuje przy uśmiercaniu? - 8%
c) być tym, kto asystuje zarówno przy podejmowaniu decyzji, jak i przy uśmiercaniu? - 1%

Brak odpowiedzi - 6%


7. Większość ludzi jest zgodnych co do tego, że w sprawach życia i śmierci wymagana jest największa ostrożność i rozwaga. Większość ludzi zgadza się także, że w skrajnych okolicznościach jest rzeczą całkiem słuszną eliminowanie tych, których uznano za niebezpiecznych dla ogólnego dobra. Czy zgadzasz się?

Tak - 91%
Nie - 5%
Niezdecydowani - 4%
(Adaptowane z Manssona, 1972)


* * *





Zaskakujące, że w 29% badanych opowiedziało się za tym „ostatecznym rozwiązaniem” nawet w odniesieniu do swych własnych rodzin!” (Carlson i Wood, 1974).


Wyniki te powinny dać do myślenia każdemu czytelnikowi, ponieważ wykazują one, jak mały wysiłek może być potrzebny, aby przekształcić te „sztuczne” dane eksperymentalne, w taki sam koszmar rzeczywistości, jaki miał miejsce w Niemczech w czasie II wojny światowej - oraz w innych miejscach i w innych okresach przedtem.




Techniki dehumanizacji




Jakimi metodami czy strategiami posługują się ludzie, aby doprowadzić do dehumanizacji i „oderwania się” emocjonalnego? Jest zaskakujące, jak bardzo mało badań przeprowadzono nad tym zagadnieniem. W gruncie rzeczy jest  tylko jedno badanie eksperymentalne na ten temat; wykazało ono, że ludzie rzeczywiście potrafią kontrolować swe reakcje emocjonalne na bodźce wywołujące wzburzenie (Koriat, Melkman, Averill i Lazarus, 1972). Badanych proszono o obejrzenie bardzo denerwującego filmu o wypadkach w przemyśle i powiedziano im, aby starali |odizolować |się psychicznie od niego.  Najwyraźniej te słowne instrukcje wystarczyły, aby osoby badane czuły się mniej pobudzone emocjonalnie przez film (chociaż ich reakcje fizjologiczne nadal były silne). W odwrotnej sytuacji osoby badane, którym powiedziano, aby |zaangażowały |się w ten film, wykazywały istotnie większe pobudzenie fizjologiczne, a także podawały, że czują się bardziej wzburzone emocjonalnie. Praca ta oparta była na badaniach Lazarusa i jego współpracowników, o których pisaliśmy wcześniej.
W jaki sposób badani ci w rzeczywistości tłumili lub potęgowali swe reakcje emocjonalne? W tym momencie musimy oprzeć naszą odpowiedź na pewnych potocznych obserwacjach i spekulatywnych rozważaniach. Zgodnie z przeprowadzoną stosunkowo niedawno analizą teoretyczną wydaje się, że jest kilka technik, za pomocą których ludzie są w stanie dehumanizować ludzi.  Wszystkie te techniki, aczkolwiek w różny sposób, pomagają jednostce: a) spostrzegać inne osoby jako mniej ludzkie, b) spostrzegać swój związek z innymi osobami w obiektywnych, analitycznych kategoriach i8lub c) redukować wielkość doznawanej emocji i pobudzenia fizjologicznego (Maslach i Zimbardo, 1973). Niektóre z tych technik reprezentują specjalne sposoby posługiwania się mechanizmami obronnymi omówionymi w Rozdziale 9 - w tym wypadku chronią one jednostkę od bólu związanego z cierpieniami innych.


Zmiana „etykietki”. Posługiwanie się pewnego rodzaju językiem jest chyba jedną z najbardziej dostrzegalnych technik dehumanizacji. Zmiana etykietek, czyli terminów stosowanych dla określenia ludzi, jest jednym ze sposobów powodujących, że wydają się oni bardziej podobni do przedmiotów, a mniej ludzcy. Niektóre z tych mniej dehumanizujących terminów są uwłaczające, takie jak „żółtek”, „półgłówek”, „mieszaniec”, „gówniarz”. Inne są bardziej abstrakcyjnymi określeniami, które odnoszą sie do wielkich, niezróżnicowanych całości - takich jak „obcy”, „masy”, „narody słabo rozwinięte”.
Inna forma dehumanizującego języka polega na określaniu ludzi w kategoriach związku funkcjonalnego, w którym dana jednostka pozostaje z nimi. Na przykład opiekunowie społeczni często mówią o „moim przypadku”, gdy mają na myśli ludzi, którymi się zajmują, podczas gdy prawnicy prowadzący sprawy ubogich mówią o „moim rejestrze”. Stosowanie słów o mniejszym ładunku emocjonalnym może mieć ten sam efekt. Wojna wietnamska dostarczyła kilku nowych przykładów tego typu zmiany słów: zamiast „zabić” kogoś, zaczęto mówić „zniszczyć” daną osobę lub „wyeliminować ją”. Podobnie uczciwym studentom łatwiej było kraść książki z ich uczelnianej księgarni, jeśli określili swą działalność jako „rujnowanie establishmentu”.


Intelektualizacja. Podobna nieco jest technika dehumanizacji, w której dana jednostka ujmuje sytuację w kategoriach bardziej intelektualnych a mniej osobistych. Zajmując się abstrakcyjnymi cechami ludzi (a nie bardziej ludzkimi), dana osoba może „zobiektywizować” sytuację i reagować w sposób mniej emocjonalny. Na przykład, pielęgniarka psychiatryczna, mając do czynienia z pacjentem, który często obrzuca ją wyzwiskami, może uniknąć poczucia, iż jest osobiście znieważona, zachowując rezerwę i patrząc na problemy pacjenta w sposób analityczny („Ten pacjent ma objawy zespołu urojeniowego”). W podobny sposób lekarze mogą mówić o swych pacjentach w kategoriach ich chorób („Przyjąłem wczoraj na oddział dwa wyrostki”), wykładowca zaś może unikać uczucia odpowiedzialności za znudzenie studentów, składając winę na ograniczony zakres uwagi młodzieży, jej apatię lub to, że jest ona pozbawiona w domu dyscypliny.


Izolowanie („szufladkowanie”). Konkretną sytuację lub typ aktywności tym łatwiej można odizolować od osobistych uczuć i wartości uznawanych przez daną jednostkę, im bardziej można oddzielić ją od reszty jej życia.  Przykładem tego jest przekonanie, że zasada „Nie zabijaj” jest słuszna - z wyjątkiem wojny, kiedy twój kraj rozkazuje zabijać. Dziennik lekarza obozu zagłady w Oświęcimiu wykazuje, jak daleko można posunąć się w takim izolowaniu w „imię słusznej sprawy”.


Wycofanie się. Inną techniką pozwalającą redukować pobudzenie emocjonalne jest minimalizowanie swego zaangażowania w interakcje z innymi osobami, interakcje, które mogłyby wywoływać stres. Można to zrealizować różnymi sposobami, na przykład spędzając mniej czasu z daną osobą, fizycznie dystansując się od niej (stając dalej od tej osoby lub nie utrzymując z nią kontaktu wzrokowego), porozumiewając się z tą osobą w sposób nieosobisty (na przykład powierzchownymi ogólnikami, formalnymi listami) itd. Opis Rosenhana (1973) przedstawiającego, jak często personel szpitala psychiatrycznego pozostaje wewnątrz swych szklanych „klatek” i jak mało czasu poświęca on na rzeczywiste interakcje z pacjentami, dostarcza doskonałego przykładu praktycznego stosowania tej techniki.


Dyfuzja odpowiedzialności, poparcie społeczne, humor. Usiłując uporać się z silnymi emocjami, jednostka często pragnie znaleźć u innych pomoc i oparcie. Jeśli takie działania redukują stres i dyskomfort psychiczny, to mogą one być stosowane dla celów dehumanizacji. Jeśli inni ludzie powiedzą: 
„To nie jest takie złe” lub „Dlaczego nie spojrzysz na to w |ten sposób”, to pomaga to danej osobie w osiągnięciu „izolacji emocjonalnej”.  Spostrzegana dyfuzja odpowiedzialności również może pomóc w dehumanizacji.  Jeśli jednostka wie, że inni ludzie myślą w ten sam sposób lub robią to samo, to może mieć mniej skrupułów przed zaangażowaniem się w określone działania.
Zdolność żartowania i śmiania się ze stresowego zdarzenia jest innymi sposobem redukowania napięcia i lęku, jakie ktoś może odczuwać. Może to także sprawić, że sytuacja wydaje się mniej poważna, mniej przerażająca, mniej przytłaczająca. Obserwatorzy stwierdzili, że studenci medycyny dokonujący sekcji zwłok podczas nauki anatomii posługują się „czarnym humorem” i wysunęli sugestię, że służy on właśnie tym celom (Lief i Fox, 1963).
Powyższa lista technik, chociaż niekompletna, powinna dać pewne pojęcie o różnorodności subtelnych i mniej subtelnych sposobów, jakie stosuje sie przy dehumanizacji. Znacznie więcej uwagi i troski należy poświęcić tym technikom, nie tylko po to, aby lepiej zrozumieć ich funkcjonowanie, lecz także, aby wykryć ich wpływ zarówno na przedmiot dehumanizacji, jak i na osobę, która jej dokonuje. Mógłbyś zacząć katalogować sposoby i sytuacje, w których jesteś traktowany w sposób dehumanizujący - jak również sposoby i miejsca, w których ty być może dehumanizujesz innych, nie zdając sobie z tego sprawy. Następnym zadaniem dla ciebie i dla naszego społeczeństwa będzie opracowanie strategii, które zminimalizowałyby dehumanizujące, zinstytucjonalizowane stosunki, pozwalając jednocześnie wykonywać nam naszą pracę, a mimo to odnosić się do innych nie jak do przedmiotów, lecz jak do braci i sióstr, o których się troszczymy.




Streszczenie rozdziału




Rodzaj ludzki niektórzy uważają za szlachetny z natury, lecz zepsuty przez cywilizację, inni zaś za zły z natury i utrzymywany w ryzach jedynie przez naciski społeczne. Jest rzeczą paradoksalną, że te same zdolności, które umożliwiają nam największe osiągnięcia, mogą także powodować największe cierpienia, jeśli zostaną źle użyte.
Rozpowszechnienie |agresji skłoniło niektórych psychologów do uznania jej za |instynktowną. Freud traktował agresję jako rozładowanie energii związanej z instynktem śmierci. Do czynników fizjologicznych związanych z agresją należy uszkodzenie mózgu, anomalie genetyczne oraz brak równowagi hormonalnej.
Teoria |frustracji-|agresji sugeruje, że agresja jest popędem nabytym, będącym reakcją na |frustrację, która występuje zawsze, gdy reakcja ukierunkowana na cel zostaje zablokowana. Agresja może ulec |przemieszczeniu ze źródła frustracji na jakiś mniej zagrażający obiekt, czyli może zostać skierowana na |kozła |ofiarnego. Obecność |czynników |wyzwalających w środowiku, w interakcji z czynnikami wewnętrznymi, sprzyja powstaniu agresji.


Zgodnie z teorią |uczenia |się |społecznego, agresja, podobnie jak inne zachowania, zostaje wyuczona przez obserwację |modeli. Reakcje agresywne wyuczone pod wpływem takiej obserwacji mogą być wykonywane w pewnych sytuacjach, lecz hamowane w innych.
W przeciwieństwie do tych, którzy są przekonani, że agresja jest instynktowna i może ulec redukcji w wyniku |katharsis, zwolennicy teorii uczenia się społecznego utrzymują, że wyrażanie agresywnych reakcji |zwiększy tylko prawdopodobieństwo przyszłej agresji. Badania potwierdziły na ogół pogląd, że oglądanie w telewizji aktów przemocy prowadzi do wzmożonej agresji u dzieci.
Przemoc w stosunkach między rodzicami a dziećmi staje się przedmiotem badań naukowych. |Maltretowanie |dzieci spotyka się częściej w rodzinach żyjących w stresie emocjonalnym, w których mało jest kontaktów dostarczających podstawy dla porównań społecznych. Rodzice, którzy maltretują swe dzieci, byli zwykle maltretowani przez swych własnych rodziców. |Agresja |interpersonalna nie jest zwykle jednostronna, lecz polega na |wzajemnej |prowokacji, |eskalacji i |konfrontacji. Większość ofiar gwałtownych przestępstw zna osobiście napastników lub nawet jest z nimi spokrewniona. Zbiorowa przemoc może być uznawana za uzasadnioną, jeśli stoi za nią władza czy autorytet społeczny.
Przeludnienie i frustracja często są przyczyną patologicznych warunków życia w naszych miastach. Przypadkowi świadkowie mogą biernie powstrzymywać się od interwencji w sytuacjach zagrożenia i nagłej potrzeby, zwłaszcza wtedy, gdy obecnych jest wielu innych ludzi lub gdy się spieszą. Badania wykazały, że |nadmierne |zagęszczenie zwierząt może prowadzić do poważnej patologii społecznej i indywidualnej - implikacje wyników tych badań w odniesieniu do ludzi w przeludnionych obszarach miejskich zależą w dużej mierze od tego, w jaki sposób ludzie ci psychologicznie interpretują swą sytuację.
|Anonimowość życia miejskiego jednostkę poczucia tożsamości. Takie |zdezindywidualizowane osoby, bardziej niż osoby w warunkach sprzyjających indywidualizacji skłonne są do przejawiania agresji i innych antyspołecznych zachowań. Anonimowości i nieodpowiedzialności może sprzyjać noszenie kostiumów lub uniformów.
|Wandalizm definiuje się na ogół jako niszczenie dla samego niszczenia.  Ten sam czyn może być uznany za wandalizm lub za psotę - w zależności od tego, kto sie go dopuszcza. Wandalizm może służyć jako źródło podniecenia lub samopotwierdzenia dla członków grup kontrkulturowych, aczkolwiek sprawcy takich czynów wywodzą się ze wszystkich poziomów społeczno-ekonomicznych. Wandalizm nie musi być bezcelowy z punktu widzenia sprawcy; akty wandalizmu mogą być dokonywane dla |zysku, ze względów |taktycznych, |ideologicznych, z |zemsty, ze |złośliwości lub mogą też stanowić rodzaj |zabawy.
Społecznie usankcjonowane |zło polega często na nadużywaniu władzy przez wywieranie przymusu. Badania nad |ślepym |posłuszeństwem |wobec |autorytetu wykazały, że takiemu posłuszeństwu sprzyja obecność |prawomocnego |autorytetu, |relacja |ról, która podporządkowuje jedną jednostkę drugiej, oraz |normy |społeczne. Oceniając zachowanie innych ludzi w takich sytuacjach, skłonni jesteśmy przeceniać wpływ czynników wewnętrznych i nie doceniać wpływu sytuacji.
Grupowe podejmowanie decyzji może ulec degradacji przyjmując formę zwaną |myśleniem |grupowym, w którym troska o jednomyślność bierze górę nad myśleniem krytycznym. Takie czynniki, jak spójność grupy, izolacja,  poparcie ze strony przywódcy oraz nadmierny nacisk na „grę zespołową” i „lojalność” zwiększają prawdopodobieństwo wystąpienia tego wypaczenia.
|Dehumanizacja polega na ukształtowaniu relacji „Ja - To”, w której inne osoby traktuje się jak przedmioty. Taki proces może służyć jako potrzebna ochrona w sytuacjach nagłej potrzeby przy udzielaniu pomocy lekarskiej, lecz może także być wysoce destrukcyjny dla godności ludzkiej, a nawet dla życia ludzkiego.
Dehumanizacja może być |narzucona |społecznie, na przykład w pewnych sytuacjach pracy, niezbędna dla |samoobrony, na przykład w przypadku personelu lekarskiego, stosowana dla |autogratyfikacji, na przykład, gdy innych wykorzystuje się dla własnej przyjemności lub stosowana jako |środek |do |osiągnięcia |celu, jak w sytuacjach politycznych. Do technik dehumanizacji należą: zmiana etykietki, intelektualizacja, izolowanie, wycofanie się, dyfuzja (podział) odpowiedzialność, zyskiwanie poparcia społecznego, a także posługiwanie się humorem.




Z Frontu Badań.
Wypalenie się: utrata
troski o człowieka




|Christina |Maslach „University of California, Berkeley”


„Tuż przed Bożym Narodzeniem pewna kobieta przyszła do prawniczki zatrudnionej w opiece społecznej, prosząc o pomoc. Podczas omawiania swych problemów uskarżała się ona na to, iż jest tak uboga, że nie będzie mogła dać swym dzieciom żadnych prezentów świątecznych. Można było oczekiwać, że prawniczka, która sama była młodą matką, będzie współczuć losowi tej kobiety. Zamiast tego zaczęła ona w pewnym momencie wymyślać tej kobiecie, wykrzykując: „Więc idź, obrabuj kogoś, jeśli chcesz mieć prezenty dla swoich dzieciaków! I nie wracaj do mnie, dopóki nie zostaniesz złapana i nie będziesz potrzebować obrony w sądzie!” Później, myśląc o tym incydencie, prawniczka uświadomiła sobie, że „wypaliła się”.


W bardzo wielu sytuacjach ludzie intensywnie obcują z innymi ludźmi, poznając ich intymne problemy psychologiczne, społeczne i fizyczne; często wymaga się od nich, aby osobiście udzielali pewnego rodzaju pomocy. Takie intensywne zaangażowanie się w pracę z ludźmi występuje na duża skalę (w sposób ciągły) u osób zatrudnionych w różnych zawodach związanych ze służbą zdrowia i opieką społeczną. Godzina po godzinie, dzień po dniu, prawnicy ci muszą troszczyć się o wielu innych ludzi, a nasze badania wykazują, że często płacą oni wysoką cenę psychiczną za to, że każdy z nich jest „stróżem brata swego”.
Stałe lub ciągle powtarzające się pobudzenie emocjonalne jest bardzo stresowym doznaniem dla każdej istoty ludzkej, a często może działać destrukcyjnie i odbierać zdolność do pracy. Aby dobrze i efektywnie wykonywać swą pracę, osoby zatrudnione w takich zawodach mogą bronić się przed silnie odczuwanymi emocjami, stosując techniki emocjonalnego „dystansowania się” („detachment”). W najlepszym razie starają się osiągnąć wystarczający obiektywizm i dystans wobec danego problemu bez utraty swego zainteresowania osobą, z którą pracują. Jednakże w nazbyt wielu przypadkach nie są w stanie uporać się z tym ciągłym stresem emocjonalnym i w końcu dochodzi do „wypalenia się”. Tracą całe zainteresowanie dla ludzi, z którymi pracują i zaczynają traktować ich w sposób obojętny, a nawet zdehumanizowany.
„Wypalenie się” nie jest wyjątkowym zjawiskiem, które można przypisać jedynie ograniczonej liczbie osób. Przeciwnie, występuje ono bardzo często i dotyczy bardzo różnych ludzi w wielu różnych zawodach. Wydaje się, że jest ono głównym czynnikiem odpowiedzialnym za niskie morale pracowników, absencję oraz dużą płynność kadr i zasadniczym powodem niskiej jakości usług świadczących potrzebującym przez służbę zdrowia i opiekę społeczną.  Znajduje ono prawdopodobnie swe odbicie we wzroście liczby procesów o zaniedbanie obowiązku przez lekarzy i w związanym z tym wzroście kosztów ubezpieczeń. Ponadto jest ono skorelowane z innymi negatywnymi wskaźnikami stresu, takimi jak alkoholizm, choroby psychiczne, samobójstwa i konflikty małżeńskie. W rozmaitych zawodach „wypalenie się” może wystepować w różnym natężeniu i pod różnymi nazwami, lecz wydaje się, że w najróżniejszych środowiskach zawodowych występuje to samo w zasadzie zjawisko.
Przez kilka lat, wspólnie z swymi współpracownikami z University of California w Berkeley, badałam dynamikę destrukcyjnego procesu „wypalania się”. Obserwowaliśmy przedstawicieli różnych zawodów przy pracy, zbieraliśmy obszerne dane kwestionariuszowe i przeprowadzaliśmy indywidualne wywiady. Jak dotąd, wśród badanych przez na grup zawodowych byli pracownicy opieki społecznej, pielęgniarki psychiatryczne, pracownicy udzielający porad ubogim ludziom, pracownicy opieki nad dziećmi, psychologowie kliniczni i psychiatrzy pracujący w szpitalu psychiatrycznym, personel więzienny i lekarze. Celem naszych badań było ustalenie: a) z jakimi stresami interpersonalnymi mają do czynienia ci pracownicy, b) czy w ramach studiów otrzymywali oni jakieś przygotowanie (i jakiego rodzaju) pozwalające im radzić sobie z tymi stresami, c) jakimi specyficznymi technikami posługują się oni, aby „zdystansować się” skutecznie wobec problemów swych klientów czy pacjentów, d) jakie są osobiste i społeczne następstwa stosowania takich technik i e) czym różnią się te środowiska zawodowe, w których „wypalanie się” zdarza się często, od tych środowisk, gdzie jest ono czymś rzadkim. Wyniki uzyskane przez nas dotychczas wykazują, że wszystkie te grupy zawodowe (i być może inne, jakie mógłbyś wymienić na podstawie swego własnego doświadczenia) często uważają zdystansowanie się wobec ludzi, z którymi pracują, za niezbędny warunek uporania się ze stresem emocjonalnym. W niektórych wypadkach to zdystansowanie się zachodzi podczas interakcji danego pracownika z pacjentem czy klientem (jak w wypadku „słuchania jednym uchem”). W innych wypadkach dystansowanie się działa jako środek zapobiegawczy lub jako środek pozwalający „odciąć się od przeszłości”. Niektórzy pracownicy uczą się na przykład „wyłączać” wszystkie myśli i uczucia dotyczące ich pacjentów czy klientów, gdy tylko wyjdą oni z ich gabinetu - „następny proszę”. W zawodach medycznych taki obiektywizm i dystans emocjonalny uważa się za niezbędny warunek umożliwiający zapewnienie pacjentowi dobrej opieki lekarskiej . Ta filozofia „zobiektywizowanej troski” łączy w sobie koncepcję troski o dobro pacjenta z ideą, że pewne osobiste zdystansowanie się od stresowych aspektów opieki nad pacjentem jest konieczne dla osiągnięcia tego celu. Jednakże w innych sytuacjach zawodowych pracownicy nie uświadamiają sobie nawet, że działa taki psychologiczny mechanizm obronny. Nieposługiwanie się tym procesem „zobiektywizowanej troski” sprawia, że całkowite „wypalenie się” staje sie bardziej prawdopodobne.




Techniki emocjonalnego
dystansowania się




We wszystkich badanych przez nas grupach zawodowych, pomimo zróżnicowania ich funkcji, pracownicy opisywali zaskakująco podobne zmiany w swej percepcji klientów czy pacjentów oraz w swych uczuciach wobec nich. Podobne były także specyficzne techniki, werbalne i niewerbalne, stosowne dla osiągnięcia pewnego dystansu emocjonalnego. Każda z tych technik na różne sposoby pomaga danej jednostce: a) spostrzegać drugą osobę jako mniej ludzką, b) rozpatrywać swe stosunki z druga osobą w obiektywnych, analitycznych kategoriach i wreszcie c) redukować intensywność i zakres doznawanego pobudzenia emocjonalnego.


Semantyka dystansowania się. Zmiana terminów, stosowanych do opisywania ludzi, jest jednym ze sposobów, dzięki którym wydają się oni bardziej podobni do rzeczy i mniej ludzcy. Niektóre z tych terminów to określenia uwłaczające (na przykład, „to są po prostu zwierzęta”). Inne terminy są bardziej abstrakcyjne i odnoszą się do dużych, niezróżnicowanych grgup, takich jak „ubodzy”. Inna forma „zobiektywizowanego” języka polega na określaniu ludzi w kategoriach relacji funkcjonalnej, istniejącej między daną jednostką a tymi ludźmi. Na przykład, pracownicy opieki społecznej często mówią o „moim przypadku”, gdy chodzi im o ludzi, z którymi mają do czynienia, podczas gdy wielu prawników, udzielających bezpłatnych porad ubogim, mówi o „mojej sprawie. Inny sposób „oddzielania” swych uczuć od jakiegoś stresowego zdarzenia polegają na określaniu wszystkiego bardzo precyzyjnie, ściśle i naukowo. Ten sposób posługiwania się językiem jest stosowany w różnych zawodach, w których użycie naukowego żargonu (na przykład „seria pozytywnych interakcji”, „reakcja pozorowana”) w odniesieniu do wywiadu z pacjentem służy z reguły zdystansowaniu się danej osoby wobec pacjenta czy klienta, którzy z jakiegoś powodu wywołują u nas napięcie emocjonalne. Ponadto pacjent, który jest tylko „zawałem”, traci wiele ze swego złożonego człowieczeństwa.


Intelektualizacja. Jest to technika podobna do poprzednio opisywanej, w której dana osoba przedstawia sytuację w bardziej intelektualnych a mniej osobistych kategoriach (pomijając ich cechy indywidualne, osobiste) pracownik może „zobiektywizować” daną sytuację i reagować mniej emocjonalnie. Na przykład, pielęgniarka psychiatryczna, mając do czynienia z pacjentem chorym psychicznie, który znieważa ja słownie, może zachować rezerwę i patrzeć na problemy pacjenta w sposób analityczny („pacjent przejawia określony zespół urojeniowy”), aby nie dać się wyprowadzić z równowagi.


Izolowanie sytuacji. W przeprowadzonych przez nas wywiadach, badani pracownicy przeprowadzili wyraźne rozróżnienie miedzy swą pracą a życiem osobistym. Z kolegami czy koleżankami z pracy nie rozmawiali o swych sprawach rodzinnych czy osobistych, a ze swymi małżonkami i przyjaciółmi często zawierali formalną umowę, aby nie mówić o pracy. Niektórzy pracownicy zatrudnieni w więziennictwie nie chcieli nawet mówić innym, na czym polega ich praca - odpowiadając na pytania, mówili tylko „Jestem urzędnikiem państwowym”, lub „Pracuję dla państwa”. Za pomocą takich środków ograniczali stres emocjonalny do tej części swego życia, którą poświęcali pracy zawodowej. Pewien asystent społeczny pracujący w ośrodku opieki nad dziećmi stwierdził, że gdyby wychodząc z tego ośrodka nie przestawał myśleć o swej pracy, to trudno byłoby mu zajmować się własnymi dziećmi. Podobnie, kiedy był w pracy, to nie mógł myśleć o swej rodzinie, ponieważ wówczas nadmiernie identyfikował się ze swymi podopiecznymi i współczuł im, traktując ich nieszczęście jak swoje własne - było to przeżycie emocjonalne, z którym nie mógł ciągle się borykać. Jak można by oczekiwać, osoba taka nie stawia sobie, tak jak inni, rodzinnych fotografii na swym biurku w pracy. W niektórych instytucjach obowiązują przepisy, które sprzyjają „izolowaniu”: zabraniają personelowi utrzymywania stosunków towarzyskich z pacjentami czy klientami poza miejscem pracy.
Dla wielu psychiatrów jedną z ujemnych stron podjęcia prywatnej praktyki jest to, że nie może wówczas być utrzymywany ów rozdział między pracą a życiem prywatnym, ponieważ zawsze są „pod telefonem”. Jak powiedział jeden z naszych respondentów: „Za każdym razem, kiedy słyszę wieczorem dzwonek telefonu, myślę „Ach, nie - mam nadzieję, że to nie pacjent””. Czasami wydaje mi się, że nigdy nie zdołam się uwolnić od problemów moich pacjentów i mieć trochę spokoju dla siebie. Kiedy pracowałem w szpitalu, to nie było tego problemu, gdy bowiem szedłem do domu, wówczas przychodziła druga zmiana - dzięki temu mogłem odprężyć się wieczorami; wiedziałem, że jeśli któryś z pacjentów potrzebuje pomocy, to jest ktoś inny, kto może mu ją zapewnić”.


Wycofywanie się. Inna technika redukowania pobudzenia emocjonalnego polega na zminimalizowaniu swego fizycznego zaangażowania się w wywołującą stres interakcję z innymi ludźmi. Badani przez nas pracownicy osiągnęli to różnymi sposobami. Jedna z oczywistych metod, jakie obserwowaliśmy, polegała na fizycznym zwiększaniu dystansu dzielącego ich od drugiej osoby (przez stanie z dala od niej, unikanie kontaktu wzrokowego czy trzymanie ręki na klamce drzwi), mimo kontynuowania pewnej minimalnej interakcji.  Wycofywaniem się było także komunikowanie się z pacjentem czy klientem w sposób nieosobisty, na przykład za pomocą powierzchownych ogólników czy formalnych listów. W niektórych wypadkach pracownicy po prostu spędzali mniej czasu z pacjentem lub klientem, czy to rozmyślnie, skracając czas formalnego wywiadu lub posiedzenia terapeutycznego, czy też spędzając więcej czasu na rozmowach i kontaktach towarzyskich z innymi członkami personelu. W skrajnych formach wycofywania się badani przez nas pracownicy w ogóle nie wchodzili w interakcje z ludźmi, którymi mieli się zajmować.  Przedłużenie przerw obiadowych, poświęcanie czasu na papierkową robotę, wychodzenie wcześniej w piątek lub po prostu opuszczanie pracy - oto przykłady wycofywania się.


Techniki społeczne. Usiłując uporać się ze swymi własnymi silnymi emocjami, często zwracamy się do przyjaciół o pomoc i oparcie emocjonalne.  Ponieważ działania takie redukują psychiczny stres i niepokój, przeto badani przez nas pracownicy posługiwali się nimi dla emocjonalnego zdystansowania się. Jedna z technik społecznych, którą stosowali pracownicy polegała na zabieganiu o radę i pociechę ze strony innych członków personelu po wycofaniu się z jakiejś trudnej sytuacji. Takie oparcie społeczne nie tylko przyczyniało się do złagodzenia stresu i odczuwanej przykrości, lecz także pomagało danej jednostce w osiągnięciu dystansu intelektualnego wobec danej sytuacji. Zbieranie się wraz z innymi członkami personelu, aby „omówić sprawy”, „ponarzekać trochę”, „pogadać o tym, co trzeba zrobić”, „pośmiać się z tego” - było podstawą procesu „obiektywizowania troski” dla wielu badanych przez nas pracowników.
Oparcie społeczne pomagało także w zdystansowaniu się, sprzyjając spostrzeganej dyfuzji odpowiedzialności. Jeśli kilku innych członków personelu przyjęło określony kierunek działania, to dana osoba często miała mniej skrupułów wobec zrobienia tego samego. Inna technika społeczna polegała na obracaniu wszystkiego w żart. Możliwość żartowania, śmiania się ze stresowego zdarzenia była jednym ze sposobów redukowania napięcia i lęków, które te osoby mogły odczuwać. Humor pomagał także uczynić daną sytuację mniej poważną, mniej przerażającą i mniej przytłaczającą. „Czarny humor” chirurgów wojskowych jest szczególnie dobrym przykładem funkcjonowania tej techniki.
Wiele z tych technik emocjonalnego dystansowania się może być stosowanych przez pracowników społecznych, albo do zmniejszania stresów, albo do skutecznego radzenia sobie z nimi, przy jednoczesnym utrzymywaniu wystarczającego poziomu zainteresowania i troski o ludzi, z którymi muszą pracować. Ponieważ jednak niektóre rodzaje tych technik wykluczają możność ciągłego opiekowania się, doprowadzają one zatem w końcu do całkowitego zdystansowania się i dehumanizacji, jakie występują w wypadku „wypalenia się”. W takiej sytuacji dążenia pracowników do zapewnienia sobie psychicznej samoobrony realizowane są kosztem klienta, pacjenta, więźnia, ucznia czy dziecka.




Środki zaradcze przeciw
„wypaleniu się”




Kiedy „wypalenie się” jest bardziej prawdopodobne? Wyniki naszych badań wskazują na kilka czynników w sytuacji pracy, które mogą mieć poważny wpływ, decydujący o tym, czy dany pracownik „wypalił się”, czy też będzie skutecznie radził sobie z własnym stresem w pracy.


Wskaźnik liczby osób przypadających na jednego członka personelu. Jakość interakcji zawodowych zależy w dużym stopniu od liczby osób, jaką pracownik ma pod swą opieką. Gdy liczba ta wzrasta, wówczas powoduje to przede wszystkim jego większe przeciążenie: poznawcze, sensoryczne i emocjonalne.  O doniosłym znaczeniu tego wskaźnika dla zrozumienia zjawiska „wypalenia się” świadczą przekonywająco wyniki badań nad pracownikami opiekującymi się dziećmi, które to badania przeprowadziłam niedawno wraz z Aylą Pines.  Badałyśmy pracowniczki ośmiu różnych ośrodków opieki nad dzieckiem; ośrodki te różniły się pod względem liczby dzieci przypadających na jedną osobę personelu, przy czym wskaźnik ten wahał się od 1:4 do 1:12. W ośrodkach, gdzie wskaźnik ten był wysoki, opiekunki pracowały więcej godzin w bezpośrednim kontakcie z dziećmi i miały mniej sposobności, by korzystać z przerw w pracy. Bardziej aprobowały one stosowanie dodatkowych technik mających na celu uspokojenie dzieci, takich jak przymusowe spanie i podawanie środków uspokajających dzieciom nadmiernie aktywnym. Były one przekonane, że mają niewielką kontrolę nad tym, co robią w pracy i na ogół lubiły swoją pracę znacznie mniej niż opiekunki z ośrodków, w których na jedną pracowniczkę przypadało mniej dzieci.
Tam, gdzie te wskaźniki są niskie, każdy członek personelu ma mniej osób, o które musi się troszczyć i każdej z nich może poświęcić więcej uwagi.  Ponadto, jest więcej czasu, aby koncentrować się na pozytywnych, bezkonfliktowych aspektach życia danej osoby, zamiast żeby skupiać się tylko na jej aktualnych problemach czy objawach jej choroby. Na przykład, na oddziałach psychiatrycznych, gdzie wskaźniki te były niskie, pielęgniarki miały więcej sposobności, aby widzieć swych pacjentów zarówno w dobrych, jak i w złych chwilach. Chociaż zdarzało się, że ich interakcje z pacjentami były frustrujące czy denerwujące, to jednak kiedy indziej pielęgniarki te potrafiły śmiać się i żartować z pacjentami, grać z nimi w ping-ponga lub w karty, rozmawiać z ich rodzinami itd. W pewnym sensie pielęgniarki te miały pełniejszy, bardziej ludzki obraz każdego pacjenta.


„Przerwy na wytchnienie” czy ucieczka. Możliwość wycofania się z sytuacji stresowej jest dla tej kategorii pracowników sprawą niezwykle ważną.  Jednakże rodzaj wycofania się, jakim się posłużę, może decydować o różnicy między „wypaleniem się” a skutecznym radzeniem sobie z trudnościami.  Najbardziej pozytywna formą wycofania się, jaką zaobserwowaliśmy, nazwaliśmy „przerwą na wytchnienie”. Przerwy na wytchnienie nie są jedynie krótkimi przerwami w pracy (takimi jak okresy odpoczynku czy przerwy na kawę). Jest to raczej możliwość wybrania przez pracownika jakiejś innej, mniej stresowej pracy, podczas gdy ktoś inny spośród personelu obejmuje jego obowiązki wobec klientów czy pacjentów. Na przykład, na jednym z badanych przez nas oddziałów psychiatrycznych pielęgniarki wiedziały, że jeśli miały ciężki dzień, to mogą przejść na jakiś czas do pracy papierkowej lub rozdzielać lekarstwa, zamiast pracować bezpośrednio z pacjentami. Inne pielęgniarki zastępowały te, które brały „czas na wytchnienie”, nadal zapewniając pacjentom właściwą opiekę. Ta forma wycofania się ma charakter pozytywny, gdyż można utrzymać właściwą opiekę nad pacjentami, mimo że danemu pracownikowi zapewniono chwilowe wytchnienie emocjonalne.
W przeciwieństwie do usankcjonowanych „przerw na wytchnienie” większość innych sposobów wycofania się była równoznaczna z negatywną formą „ucieczki”. Tu decyzja pracownika, żeby wziąć przerwę w pracy, zawsze była realizowana kosztem klientów lub pacjentów, ponieważ nie było innego pracownika, który mógłby przejąć niezbędne obowiązki. Jeśli w danym dniu jakiś pracownik był nieobecny i nie leczył lub nie świadczył określonych usług, wówczas ludzie musieli po prostu czekać, przychodzić innego dnia lub rezygnować. W takiej sytuacji było bardziej prawdopodobne, że pracownicy będą się czuli „schwytani w pułapkę” całkowitej odpowiedzialności za tych ludzi i nie będą mogli wycofać się choćby na pewien czas bez poczucia winy.  Gdy takie poczucie winy nakładało sie na, i tak już wielki, ciężar emocjonalny, jaki cierpliwie dźwigali, to ciężar ten często stawał sie już niemożliwy do zniesienia. W końcu to poczucie winy znikało u tych pracowników, którzy zaczynali tracić zarówno poczucie troski, jak i zainteresowanie dla podopiecznych. Tam, gdzie przepisy danej instytucji nie pozwalały na korzystanie z dobrowolnych „przerw na wytchnienie”, stwierdziliśmy niskie morale personelu, objawy większego stresu emocjonalnego i - jako nieuniknioną konsekwencję - większe niezadowolenie wśród ludzi korzystających z usług tej instytucji; sfrustrowanych, że nie otrzymują opieki, jaka jest im potrzebna.


Czas trwania bezpośrednich kontaktów. Jest bardzo prawdopodobne, że liczba godzin, jaką dana osoba pracuje w ciągu dnia, jest skorelowana zwystępującym u tej osoby poczuciem zmęczenia, nudy, stresu itp. Można by więc podejrzewać, że dłuższe godziny pracy prowadzą do częstszego „wypalenia się”. Jednakże nasze dane ujawniają nieco inny układ zależności.  Dłuższe godziny pracy są skorelowane z większym stresem i negatywnymi postawami u personelu tylko wtedy, gdy praca wymaga ciągłego, bezpośredniego kontaktu z pacjentami czy klientami. Nasze badania przeprowadzone w ośrodkach opieki nad dziećmi stanowia dobrą ilustrację tego zagadnienia. Dłuższe godziny pracy były korelowane z oznakami „wypalenia się” wtedy, gdy oznaczły one dłuższe zajmowanie się dziećmi, Gdy dłużej wykonywana praca miała charakter administracyjny, nie związany bezpośrednio z dziećmi, wówczas wystąpienie „wypalenia się” było mniej prawdopodobne. Zasadniczo, u tych osób personelu, które pracowały przez większą liczbę godzin z dziećmi, rozwijały się bardziej negatywne postawy wobec tych dzieci. Bardziej aprobowały one instytucjonalne ograniczenia nakładane na zachowanie tych dzieci, a gdy nie były w pracy, to chciały być jak najdalej od dzieci i związanych z dziećmi czynności. Od osób tych różnili się ci członkowie personelu, którzy pracowali równie dużo godzin, lecz którym mniejszą część czasu zajmowały bezpośrednie kontakty z dziećmi.  Nie wytworzyły się u nich tego rodzaju negatywne postawy wobec dzieci, lecz byli pozytywnie ustosunkowani do nich i do danego ośrodka opieki nad dziećmi w ogóle. Wydaje się, że jeśli nie miłosierdzie, to jakość opieki może być odwrotnie proporcjonalna do poświęcanego na nią czasu.
                                                                         

Towarzysko-zawodowe grupy oparcia. Możność uczestniczenia w formalnych lub nieformalnych spotkaniach, w ramach których pracownicy mogą przedyskutować napotkane trudności oraz uzyskać radę i oparcie, jest jedynym ze sposobów dopomożenia im w skutecznym radzeniu sobie ze stresem pracy. Takie spotkania dostarczają sposobności do analizowania zarówno napotykanych problemów, jak i związanych z nimi osobistych odczuć, dają okazję do żartów, odprężenia się oraz do porównań społecznych ze współpracownikami. Wskaźniki „wypalenia się” zdają się być niższe u tych pracowników, którzy mogą uczestniczyć w spotkaniach takich grup, zwłaszcza jeśli są one dobrze rozwinięte i korzystają z pomocy jakiejś większej instytucji. Niektórzy z badanych przez nas psychiatrów podawali, że należeli do takiej towarzysko-zawodowej grupy oparcia wtedy, gdy odbywali swój staż kliniczny. Po rozpoczęciu praktyki prywatnej twierdzili oni, że brak takiej grupy był dla nich poważną, nieoczekiwaną stratą i często czynili starania, aby znów włączyć się w działalność takiego systemu oparcia (aczkolwiek nie zawsze im się to udawało).


Analiza osobistych uczuć. Ponieważ wzbudzanie silnych reakcji emocjonalnych jest charakterystyczne zarówno dla zawodów związanych ze służbą zdrowia, jak i opieką społeczną, należy zatem podjąć wysiłki, aby radzić sobie z tymi uczuciami w sposób konstruktywny i nie dopuścić do ich całkowitego wygaszenia, jak to zdarza się w wypadku „wypalenia się”.  Byliśmy zaskoczeni stwierdzeniem, że wiele spośród badanych przez nas osób nie wiedziało, iż inni ludzie doświadczają tych samych zmian w postawach i emocjach, co i oni. Każda z nich sądziła, że osobiste reakcje, jakich doświadczają, były czymś jedynym w swoim rodzaju (złudzenie podtrzymywane przez występującą u nich tendencję do nieujawniania swych uczuć wobec współpracowników). Nie zdawali sobie sprawy z faktu, że ich doznania są czymś dosyć częstym, a nie jakimś wynaturzeniem. Chociaż wielu z tych pracowników zachowywało swe uczucia dla siebie, to jednak jest zupełnie oczywiste, że mieli oni silną potrzebę mówienia o nich.
Uzyskane przez nas wyniki wykazują, że wskaźniki częstości występowania „wypalenia się” są niższe u tych pracowników, którzy aktywnie wyrażają i analizują swe uczucia, a także dzielą się nimi ze swymi kolegami. Nie tylko świadomie zrzucają oni ciężar z serca, lecz także mają sposobność uzyskania konstruktywnego sprzężenia zwrotnego od innych ludzi, możliwość nowego spojrzenia na problemy i zrozumienia swego stosunku do pacjentów czy klientów. Proces ten zostaje znacznie wzmożony, jeśli dana sytuacja (taka, jak ośrodek czy szpital) stworzyła odpowiedni mechanizm dla realizowania go. Mogą to być towarzysko-zawodowe grupy oparcia, specjalne zebrania personelu czy posiedzenia, na których omawia się problemy występujące w pracy. Ogólnie biorąc, stwierdziliśmy, że ci pracownicy, których ćwiczy się w rozwiązywaniu problemów psychologicznych, lepiej potrafią rozpoznawać swe własne uczucia i radzić sobie z nimi. Na przykład, pewna kobieta, psycholog kliniczny, podała, że nie potrafiła dobrze pracować z określonym typem pacjentów - to jest z biernym, zbyt zależnymi kobietami. Po przeanalizowaniu swych osobistych reakcji na ten typ kobiet (które były związane z jej doświadczeniami z dzieciństwa i własnym przygotowaniem zawodowym), potrafiła ona zrozumieć, dlaczego pracowało jej się tak źle z tym typem pacjentek, i mogła podjąć odpowiednie kroki dla zaradzenia tej sytuacji. Natomiast strażnikom więziennym, którzy doświadczali silnego strachu, uniemożliwiał ujawnienie go, czy choćby uświadomienie go sobie, obowiązujący w tej instytucji „kodeks silnego człowieka”; jedną z konsekwencji tego było destruktywne „skanalizowanie” tej emocji w schorzenia psychosomatyczne, takie jak wrzody żołądka, skurcze mięśni i migreny.


Ćwiczenie umiejętności interpersonalnych. Na podstawie dotychczasowych wyników badań wydaje się oczywiste, że pracownicy zatrudnieni w służbie zdrowia i opiece społecznej potrzebują specjalnego przeszkolenia i przygotowania do bezpośredniej pracy z innymi ludźmi. Chociaż są oni dobrze wyszkoleni w zakresie metod i „technik” niezbędnych przy leczeniu, to jednak często nie są dobrze przygotowani do prowadzenia wielokrotnych, intensywnych, emocjonalnych interakcji z ludźmi. Jak stwierdził pewien prawnik udzielający porad ubogim: „Uczyłem się prawa, a nie tego, jak pracować z ludźmi, którzy są moimi klientami. I te własnie trudności w zajmowaniu się ludźmi i ich osobistymi problemami, godzina po godzinie, stały sie dla mnie problemem - nie kwestie prawne same w sobie”.
Z punktu widzenia osoby poszukującej pomocy, pracownikom tym może być potrzebna dodatkowa „wiedza o ludziach”, która uzupełniałaby ich „wiedzę książkową”. Aczkolwiek wielu naszych badanych stwierdziło, że chcieli uzyskać wcześniej przygotowanie z zakresu umiejętności interpersonalnych, to jednak niektórzy sądzili, że nie było na to czasu w i tak przeładowanym programie studiów. Inni byli zdania, że przygotowanie takie było tylko „lukrowaniem ciastka”, a nie istotną częścią szkolenia zawodowego. Kilku lekarzy uważało, że kompetentne przygotowanie z zakresu medycyny, to wszystko, co było im potrzebne dla osiągnięcia sukcesów w karierze zawodowej, i że wszelkie treningi psychologiczne dają jedynie umiejętność przeprowadzania „rozmówek” z pacjentami. Umiejętność taką uważali oni za potrzebną, lecz w zasadzie nieważną.
Moim zdaniem taki pogląd jest niestety błędny, ponieważ trywializuje pewien zasadniczy aspekt relacji między lekarzem a pacjentem i nie bierze pod uwagę tego, że zarówno lekarz, jak i pacjent są istotami ludzkimi, których osobiste postawy i emocje mogą wpływać nie tylko na jakość zapewnianej opieki zdrowotnej, ale także na to, jak jest ona przyjmowana - a nawet, czy w ogóle jest przyjmowana.




Wnioski




Czy „wypalenie się” jest nieuniknione? Niektórzy pracownicy badani przez nas zdają się tak sądzić i uważają, że jest to tylko kwestiż czasu - zanim się „wypalę”, trzeba zmienić pracę. Okresem, jaki najczęściej wymieniano na pewnym oddziale psychiatrycznym, było półtora roku, podczas gdy niektórzy pracownicy udzielający porad ubogim mówili o zredukowaniu przyjętego dotąd czteroletniego okresu, na jaki się angażowali, do co najwyżej dwóch lat. Ja sadzę, że „wypalenie się” nie jest nieuniknione i że można podejmować pewne kroki w celu zmniejszenia częstości występowania tego zjawiska i złagodzenia go. Jestem przekonana, że przyczyną wielu przypadków „wypalenia się” nie są trwałe, niezmienne cechy ludzi, lecz określone czynniki społeczne i sytuacyjne, na które można oddziaływać w sposób, jaki sugerują nasze badania.
Niezależnie jednak od rzeczywistych przyczyn „wypalenia się”, jego skutki - pod względem kosztów społecznych i osobistych - są w dramatyczny sposób oczywiste. W takiej mierze, w jakiej ludzie czują się zmuszeni „uciekać” ze swej pracy lub nawet porzucać całkowicie swój zawód, zjawisko to powoduje ogromne marnotrawstwo ich wykształcenia i talentu. Jeszcze ważniejsze jest to, że „wypalenie się” ma szkodliwe następstwa natury psychologicznej, zarówno dla pracowników, jak i dla ich pacjentów czy klientów. Stosunek tych pracowników do ludzi w ogóle i żywione wobec innych uczucia często ulegają negatywnym zmianom, nabiera znamion cynizmu: zaczynają oni myśleć bardziej nieprzychylnie o swych pacjentach czy klientach i wierzyć, że jakoś zasłużyli oni sobie na te kłopoty, które mają. Na urlopie chcą być z dala od wszystkich ludzi. Opowiadając nam o swej wymarzonej pracy często opisywali takie zajęcia, w których ma sie do czynienia co najwyżej z kilkoma osobami. Na przykład, pewien asystent społeczny powiedział, że uwielbia sztukę i najbardziej chciałby pracować samotnie w muzeum, katalogując obrazy w magazynie.
Ostatnim szkodliwym następstwem „wypalenia się” jest jego wpływ na stosunki pracownika z własną rodzina i przyjaciółmi. Jeśli napięcie nie może być rozładowane w pracy, to często zostaje nieświadomie przeniesione do domu, co może prowadzić do nasilenia konfliktów osobistych i rodzinnych.  W wielu tych zawodach wskaźniki rozwodów, chorób psychicznych i samobójstw są wyższe od przeciętnej dla ogółu ludności (na przykład, u funkcjonariuszy policji wskaźnik samobójstw jest sześć i pół raza wyższy niż w zawodach nie związanych ze strzeżeniem prawa; również wśród psychiatrów liczba samobójstw jest wyższa od przeciętnej).
Nie ulega wątpliwości, że osoby zatrudnione w służbie zdrowia i w opiece społecznej płacą wysoką cenę za pracę w wybranych przez siebie zawodach. Co jednak można powiedzieć o kosztach, jakie ponosimy my, ich pacjenci i klienci? Jest równie oczywiste, że my również cierpimy wskutek ich „wypalania się”. Czekamy dłużej, a otrzymujemy mniej troski i zainteresowania. Jakość opieki czy usług, jakie otrzymujemy, staje się niższa, a doświadczenia związane z ich uzyskaniem nabierają charakteru dehumanizacyjnego.
Jak starałam się wykazać w tej analizie, zjawisko „wypalania się” nie jest spowodowane tym, że ludzie są „źli”, niewrażliwi i brutalni. Wynika ono raczej ze „złych” sytuacji, w których muszą działać ludzie początkowo nastawieni bardzo idealistycznie. Można mieć jednak nadzieję, że wcielenie w życie niektórych zaproponowanych tu idei mogłoby stać się punktem wyjścia do wprowadzenia zmian w ogólnej sytuacji panującej w służbie zdrowia i opiece społecznej - tak, aby służby te przyczyniały się do rozwoju wartości ludzkich, zamiast je niweczyć.




Epilog.
Marzenie o przyszłości




Przebyliśmy już długą drogę podróży, jaką podjęliśmy wspólnie w Rozdziale 
1. Mamy nadzieję, że lepiej zdajesz sobie teraz sprawę z tego, czym zajmuje się psychologia, a dzięki zapoznaniu się z nowym psychologicznym sposobem patrzenia na rzeczy będziesz umiał lepiej analizować (i skuteczniej rozwiązywać) niektóre napotykane przez siebie problemy natury osobistej i społecznej.

Aczkolwiek zbliżasz się już do końca tego podręcznika i wstępnego kursu psychologii, to jednak, oczywiście, dopiero rozpoczynasz pełniejsze, bardziej pogłębione studia nad wieloma aspektami wiedzy psychologicznej.  Prawie każdy z głównych tematów, jaki tu przedstawiliśmy, w większości uczelni jest przedmiotem całego kursu (lub kilku kursów) poświęconego pojęciom, metodom oraz podstawowej wiedzy z danego zakresu. Być może, iż chcesz pojąć dalsze formalne studia nad tymi tematami, które uznasz za interesujące, czy to z osobistego, czy też naukowego punktu widzenia. W twojej bibliotece uczelnianej znajdziesz także bogatą literaturę z zakresu nawet tych tematów i zagadnień, o których mogliśmy jedynie krótko napomknąć. Jedną z przyczyn, dla których w całym podręczniku zamieszczaliśmy cytatu z różnych badań i prac, jest chęć ułatwienia ci lepszego zapoznania sie z tymi zagadnieniami, o których chciałbyś dowiedzieć się więcej. Drugą przyczyną jest dążenie do tego, abyś potrafił samodzielnie oceniać wartość dowodów, na których oparte są poszczególne wnioski psychologów - abyś potrafił oddzielić spekulacje i poglądy od rzetelnych danych i uzasadnionych konkluzji.
W niniejszym ostatnim rozdziale, chcielibyśmy przedstawić trzy ogólne zagadnienia, które chociaż zwykle nie są omawiane we wstępnych podręcznikach psychologii, to jednak budzą wielkie zainteresowanie wielu studentów - a mianowicie: psychologię ekologiczna, problemy etyczne związane z interweniowaniem w życie ludzi oraz zastosowanie psychologii do podnoszenia jakości naszego życia.
Ekologia stała się jednym z podstawowych problemów naszych czasów i chcielibyśmy, abyś zapoznał się z podejściem ekologicznym, które umożliwia nowe spojrzenie na zagadnienia psychologiczne - odmienne od tego, które dotąd było charakterystyczne dla myśli psychologicznej. Ważne jest również, abyśmy wszyscy zdawali sobie sprawę z tego, że chociaż problemy ekologiczne często przedstawia się jako problemy fizycznych zasobów środowiska, to jednak w ostatecznym rachunku kluczem, zarówno do zrozumienia, jak i rozwiązania tych problemów, są |ludzie. Nie ulega wątpliwości, że to wartości uznawane przez ludzi oraz ich postawy i zachowania prowadzą do przeludnienia, skażenia środowiska, lekceważenia darów natury oraz ambitnych planów „modernizowania”, „urbanizowania” i sterowania istniejącym środowiskiem. Lecz są także inni |ludzie, którzy przestrzegają nas przed niebezpieczeństwem nadmiernego uzależnienia od kurczących się zasobów energii oraz przed długotrwałymi, ujemnymi następstwami interwencji, które na krótką metę wydają się pożyteczne - takich jak stosowanie DDT oraz innych środków ochrony roślin do zwalczania szkodników. Jak zmienić zachowanie osób śmiecących, wandali, ludzi szukających zysku za wszelką cenę, i im podobnych? Tu właśnie musi wkroczyć psychologia.
Jeśli jednak ktoś wkracza w życie innej osoby, tak aby je zmienić, to zawsze wówczas powstają problemy etyczne. Ponieważ psychologia jest nauką eksperymentalną, opartą na modelu badawczym, w której podejmuje się próby wpływania na zachowanie, przeto we wszystkich przedsięwzięciach badawczych trzeba brać pod uwagę względy etyczne. Ponadto wszelkie odmiany terapii psychologicznej stanowią próbę zmodyfikowania sposobu, w jaki ludzie myślą, czują i zachowują się wobec innych, jak również wobec siebie samych. Czy etyczne jest narzucanie innemu człowiekowi swoich wartości lub zmienianie osobowości - choćby „patologicznej” - innej jednostki? Czy są jakieś kryteria, za pomocą których moglibyśmy ocenić, że uwieńczona „sukcesem” terapia służy najlepiej pojętym interesom pacjenta, a nie jest po prostu wygodna dla porządku społecznego, do którego „dopasowuje się” daną osobę?  Chociaż nie ma gotowych odpowiedzi na takie ogólne pytania dotyczące etyki interwencji, to jednak nadszedł czas, aby psychologowie, studenci i inni ludzie zaczęli o niej poważnie dyskutować.
Po zapoznaniu się z różnymi formami, jakie może przyjmować degeneracja życia społecznego, wielu studentów zaczyna zapatrywać się sceptycznie na możliwości psychologii (czy jakiejkolwiek innej nauki) w zakresie wywoływania u ludzi reakcji prospołecznych i pozytywnego oddziaływania na świat. My jednak patrzymy z optymizmem na przyszłe możliwości stosowania wiedzy psychologicznej do rozwiązywania wielu rodzajów problemów, przed jakimi stoi nasze społeczeństwo. Dotychczas psychologia nie miała tak dużego wpływu na odnośne ustawodastwo, jaki mogłaby mieć, ponieważ psychologowie byli zbyt ostrożni, a może po prostu zbyt skromni, by dążyć do rzeczywistego i powszechnego wykorzystania wiedzy, jaką zgromadzili.  Ponadto, w przeszłości wiedza psychologiczna była wykorzystywana przede wszystkim w interesie instytucji handlowych, przemysłowych i wojskowych, a rzadziej posługiwano się nią do rozwiązywania „problemów ludzkich”. Powiały jednak nowe wiatry i w następnym dziesięcioleciu psychologia zostanie prawdopodobnie w znacznym stopniu oddana na usługi „zwykłych ludzi”. W niniejszym Epilogu chcielibyśmy ukazać pewne zastosowania psychologii oraz nowe kierunki, w jakich może zmierzać psychologia stosowana, aby uczynić życie przeciętnego człowieka pełniejszym i bardziej zadawalającym.




Psychologia ekologiczna




„Ekologia jest nieekonomiczna, lecz - przyjmując odmienną logikę - ekonomia jest nieekologiczna”.
(Kenneth Boulding (1974).)


W pewnym mieście w południowej części stanu Illinois wykryto, że azotany (stosowane do użyźniania gleby w otaczających miasto farmach), które znacznie zwiększały plony, dostają się do sieci wodociągowej, gdzie w obecności pewnych bakterii przekształcają się w azotyny, które są wysoce toksyczne i mogą powodować u dzieci poważne schorzenia. Farmerzy „uzależnili się” jednak od dodatkowych plonów, dzięki którym gospodarka była opłacalna, a miasto to jest z kolei ekonomicznie uzależnione od sukcesu gospodarczego farmerów. Farmerzy nie mogą po prostu zrezygnować ze stosowania nawozów azotowych bez zaburzenia całego systemu i narażenia się na ruinę finansową; jeśli jednak nadal będą stosować nawozy, to narażają na niebezpieczeństwo zdrowie dzieci ze swej własnej społeczności.
Podobnie jak uświadomiliśmy sobie, że jesteśmy częścią biologicznego |ekosystemu, w którym wszystkie elementy są od siebie wzajemnie zależne, tak samo odkrywamy, że ludzie w społeczności są wzajemnie od siebie uzależnieni i że wiele z ich zachowań ma swe źródło w swej psychologicznej, wzajemnej zależności, a nie w ich izolowanych cechach charakteru ani też w poszczególnych warunkach bodźcowych oddziałujących na nich w danym momencie.
Te wzajemne zależności nie rzucają się w oczy, gdy badamy zachowanie pojedynczych jednostek, i dlatego psychologia skłonna była ignorować te problemy, które pojawiają się, gdy zachowanie jednostek jest uwikłane w sieć systemu społecznego. Staje się jednak coraz bardziej oczywiste, że zasad psychologii indywidualnej nie można po prostu i bezpośrednio przełożyć na zasady potrzebne dla zrozumienia złożonych zachowań w ramach pewnego systemu. Zakończona sukcesem psychoterapia jednej osoby może zburzyć równowagę w całej rodzinie. Wybitnie uzdolniona jednostka zaczyna uzyskiwać złe wyniki w szkole, gdy rówieśnicy odnoszą się z dezaprobatą do zainteresowań natury intelektualnej. Ludzie - zwykle łagodni i uprzejmi - podczas wojny zabijają bezbronnych wieśniaków. Tłum szydzi z przerażonego chłopca, który grozi samobójstwem. Obywatel na wysokim stanowisku wymierza - jak mniema - niebezpiecznie silny wstrząs elektryczny osobie, której nie zna i której nie chce skrzywdzić. Student seminarium duchownego, spieszący wygłosić kazanie o Dobrym Samarytaninie, nie znajduje czasu na to, żeby nim być, gdy napotyka osobę, która zdaje się być w potrzebie. Rywalizujący ze sobą rybacy świadomie wyniszczają zasoby ryb do tego stopnia, że zagraża to ich źródłu utrzymania. I wreszcie państwa, które mają już dosyć broni, aby wielokrotnie uśmiercić swych wrogów, nadal pracują nad jeszcze straszniejszymi sposobami zabijania istot ludzkich, jednocześnie redukując fundusze na cele społeczne i zdrowotne, nieodzowne dla zaspokojenia potrzeb ich własnych obywateli. Ludzie w niektórych sytuacjach postępują w sposób, który zdaje się nie mieć żadnego sensu.
Wydawałoby się, że mamy do wyboru dwie możliwości: albo możemy uznać takie szkodliwe dla samego siebie i niekonsekwentne zachowanie za irracjonalne i niezrozumiałe, lub też, jeśli przyjmujemy, że wszelkie zachowanie ma swe przyczyny, możemy szukać ogólniejszych zasad, co umożliwi poddanie takiego zachowania analizie w kategoriach |systemów |społecznych, gdzie związki przyczynowe mogą mieć różny charakter, niż w przypadku jednostki reagującej na izolowany bodziec. Jeśli wybierzemy tę druga możliwość, to co wtedy?
Występuje wyraźnie kilka różnic między tradycyjnymi zasadami wyjaśniania zachowania jednostki w próżni społecznej, a zasadami, które są potrzebne do zrozumienia całej ekologii złożonego zachowania społecznego. Różnice te wyodrębnimy w sposób arbitralny dla celów opisu, aczkolwiek (ponieważ mamy do czynienia z ekosystemem psychologicznym) różne ich aspekty są ze sobą w rzeczywistości powiązane. Do celów analizy wyodrębnimy zatem trzy różnice w |sposobie |podejścia i cztery różnice w |podstawowych |pojęciach, występujące między psychologią ekologiczną a psychologią tradycyjną.




Różnice w sposobie
podejścia




Badacz, próbujący wyjaśnić złożoność zachowania w sytuacjach społecznych występujących w życiu realnym, musi zajmować się raczej zachowaniem molarnym niż molekularnym, częściej stosować obserwację i analizę zachodzącego w danej chwili zachowania niż manipulację i kontrolę oraz musi brać pod uwagę ludzkie wartości, a nie tylko obiektywizm naukowy.
Molarne czy molekularne jednostki analizy. W analizie psychologicznej dąży się zwykle do wyjaśnienia zachowania w kategoriach zjawisk zachodzących w poszczególnych częściach organizmu, zwłaszcza w mózgu i w innych partiach układu nerwowego czy układu wydzielania wewnętrznego. Jak już wiemy, takie koncentrowanie się na elementach systemu określa się jako |analizę |molekularną. Jej przeciwieństwem jest |analiza |molarna, w której bierze się pod uwagę zachowanie całego organizmu.
Na przykład, „klasyczny” psycholog eksperymentalny mógłby badać zależność między intensywnością bodźca świetlnego a czasem reakcji osoby badanej naciskającej przełącznik.
Z drugiej strony, psycholog przeprowadzający badania na molarnym poziomie analizy, mógłby badać zależność między oświetleniem ulic a aktami wandalizmu. Obaj starają się wykryć wpływ środowiska na zachowanie, lecz drugi z nich przyjmuje szerszą definicję, zarówno „środowiska”, jak i „zachowania”.
Podejście molekularne ma zwykle charakter redukcjonistyczny, gdyż wyjaśnia zjawiska na danym poziomie organizacji w kategoriach procesów z niższego poziomu i zakłada, że przy takim „przekładzie” nie zachodzą żadne straty - że zachowanie organizmu można adekwatnie opisać w kategoriach aktywności komórek nerwowych i procesów elektrochemicznych. Podejście molarne przyjmują zwykle ci psychologowie, którzy zakładają, że całość ma właściwości, jakich nie mają ani nie pozwalają przewidzieć jej części, że na każdym poziomie organizacji pojawiają się nowe właściwości, które najlepiej jest zbadać na tym poziomie i których zapewne nie można nawet sensownie opisać w kategoriach procesów zachodzących na niższych poziomach.  Argumentują oni na przykład, że na próżno próbowalibyśmy wyjaśnić, w kategoriach wyładowań w neuronach i skurczów mięśni, dlaczego „piraci powietrzni” porywają samoloty. Strach, nadzieja, gniew, ambicje polityczne - wszystko to są cechy, jakie przejawiają istoty ludzkie, a których nie można nigdy zaobserwować w neuronach, gruczołach czy naczyniach krwionośnych. Systemy społeczne mają zaś takie cechy (np. spójność i relacje władzy), których nie da się zaobserwować u jednostek. 
Dla podejścia molarnego charakterystyczne jest także zainteresowanie tym, w jaki sposób cechy całości wpływają na funkcjonowanie jej części. Układ nerwowy, gruczoły wydzielania wewnętrznego oraz inne układy wewnętrzne funkcjonują zatem inaczej w zależności od tego, czy dana jednostka lęka się egzaminu, czy chce posłuchać plotek, czy też jest pogrążona w medytacji transcendentalnej. Podobnie cechy społeczeńtwa wpływają na zachowanie i działanie jego członków oraz istotnie pomagają nam wyjaśnić niektóre zachowania, które wydają się irracjonalne, gdy rozpatruje się je w izolacji.


Aczkolwiek społeczeństwa nie są organicznymi jednostkami fizycznymi, takimi jak organizmy, to jednak reprezentują układy wzajemnych zależności, które mogą determinować możliwości i wybory jednostki oraz nagrody i kary, które będą następstwem każdego wyboru.


Obserwacja i klasyfikacja zamiast kontroli i interwencji. Jak już wiemy, najwyższymi w hierarchii celami psychologii tradycyjnej były przewidywanie i kontrola. Najbardziej cenionym rodzajem badań był eksperyment kontrolowany, w którym istotne zmienne można utrzymywać na stałym poziomie, a zmiennymi niezależnymi można manipulować w taki sposób, aby wyniki można było wyrażać w kategoriach przyczyn, a nie jedynie korelacji.
Kiedy jednak w ten sposób formułuje się i sprawdza hipotezy, to można wówczas badać jedynie te czynniki, które już się podejrzewa o to, że są one przyczynami. Ważne fragmenty sieci realnie funkcjonujących przyczyn mogą nigdy nie zostać rozpoznane ani nie poddane badaniom.
Ponadto wielu zagadnień o życiowej doniosłości, które dotyczą zachowania społecznego, nie można badać w ten sposób ze względu na praktyczne lub etyczne ograniczenia możliwości manipulowania i kontroli ze strony psychologów, a także dlatego, że w wielu wypadkach interwencja badacza zmieniłaby samo badane zachowanie.
Jeden z pionierów w dziedzinie psychologii ekologicznej, Roger Barker, odrzucił podejście interwencjonistyczne na rzecz badania zjawisk behawioralnych w stanie „nietkniętym” („intact”), takich, jakie występują w środowisku naturalnym („polu”) badanych jednostek. Postawił on sobie zadanie opisywania możliwie najdokładniej i najpełniej całego przestrzennego i czasowego kontekstu zachowania - co się dzieje, kiedy, gdzie, kto bierze w tym udział, jak długo. Zamiast wkraczać w daną sytuację z jakąś teorią do potwierdzenia lub z hipotezą do sprawdzenia, stara się on zachować całkowitą bezstronność przy próbach opisania i skategoryzowania tego, co się dzieje.
Przy takim podejściu |dane dotyczące środowiska i zachowania stają się tą rzeczywistością, którą należy analizować i zrozumieć, a ich zmiany w czasie są ważnym aspektem tego, co się obserwuje. Badacz o nastawieniu ekologicznym nie wybiera ani nie manipuluje systematycznie żadną zmienną; zamiast tego pozwala on „strumieniowi zachowania” płynąć bez zakłóceń, jedynie obserwując go i rejestrując dla późniejszej analizy.


Troska o polepszenie losu ludzkiego zamiast zainteresowania „czystymi” odkryciami intelektualnymi. Nauka stawia do naszej dyspozycji środki umożliwiające zbieranie danych, co pozwala rozwiązywać pewne rodzaje problemów. Dla wielu naukowców motywem do podjęcia takiej działalności jest przede wszystkim ciekawość intelektualna dotycząca tajemnic natury - chęć odkrycia, jak funkcjonują rzeczy i ludzie. „Wiedza dla niej samej” - oto hasło „czystej nauki”, w tym także czystej psychologii.
Jak jednak przekonaliśmy się w Rozdziale 1, wielu psychologów zdaje sobie sprawę z tego, co psychologia może zrobić dla poprawienia ludzkiego losu.  Chociaż obiektywizm musi dominować w tych fazach badań, które polegają na zbieraniu danych i analizowaniu ich, to jednak wykorzystanie wyników do zmiany życia ludzi nieuchronnie wiąże się z wyborami opartymi na wartościach.
Psycholog ekologiczny boryka się z problemami, których rozwiązanie mogłoby mieć wpływ na jakość środowiska, a bezpośrednio lub pośrednio na życie ludzi w tym środowisku. Wiąże się z tym poczucie „misji”, zaabsorbowanie doniosłymi społecznie celami, zainteresowanie problemami praktycznymi i rozwiązaniami, które można przełożyć na programy działania.  Dla takiego badacza zainteresowania humanistyczne są równie ważne - lub może ważniejsze - jak oderwane, naukowe, intelektualne zainteresowanie rozwiązywaniem zagadek stawianych przez naturę. Więcej o tej sprawie powiemy w ostatniej części niniejszego „Epilogu”.




Zbliżenie


Aby oszczędzić drapieżniki i ocalić ich ofiary


„Doskonałego przykładu ukazującego, w jaki sposób podstawowe badania mogą prowadzić do praktycznych rozwiązań, dostarczają wyniki eksperymentów, w których awersyjne warunkowanie zastosowano dla powstrzymania kojotów od atakowania owiec (Gustavson, Garcia, Hankins i Rusiniak, 1974).
Dzikie kojoty polują na jagnięta i owce na państwowych pastwiskach zachodnich stanów. Doprowadziło to do ostrego sporu pomiędzy tymi, którzy chcieli wytępić drapieżniki, a przyrodnikami, którzy pragnęli zachować ten gatunek w jego naturalnym siedlisku. Zwykle, aby ograniczyć szkody wyrządzane przez drapieżników, wyznacza się nagrody za zabijanie tych zwierząt. Obecnie psychologia znajduje metody behawioralne, dzięki którym można zarówno oszczędzić drapieżniki, jak i ocalić ich ofiary.
W Rozdziale 3 omawialiśmy badania Johna Garcii i jego współpracowników nad „ostrożnością wobec przynęty” - jak nowo wykrytym ograniczeniem podstawowych praw warunkowania. „Ostrożność wobec przynęty” jest to uwarunkowana awersja wobec smaku danego pokarmu nabyta na podstawie pojedynczego doświadczenia, polegającego na tym, że zwierzę zachorowało wskutek zjedzenia danego pokarmu.
Uwarunkowaną awersję wobec określonego rodzaju mięsa wytworzono u sześciu kojotów, nakarmiwszy je mięsem z dodatkiem chlorku litu, który powoduje przejściowo chorobę. W przypadku trzech kojotów  było to mięso jagnięce, w przypadku pozostałych trzech - był to królik. Następnie obserwowano zachowanie każdego z kojotów. Po zaledwie jednym, lub co najwyżej dwóch awersyjnych doświadczeniach tego rodzaju, drapieżniki przestawały atakować te ofiary, których mięso przyprawiało je o chorobę, lecz nadal atakowały ofiary należące do innego gatunku.
Badacze sugerują, że zabijanie owiec przez kojoty można by zlikwidować wprowadzając do mięsa martwych jagniąt i owiec tę niepowodującą śmierci truciznę, tak aby wytworzyć u kojotów warunkową awersję na zapach i smak tego mięsa. Jest to piękny przykład badań psychologicznych, nie mających z pozoru praktycznego zastosowania; jednakże można je wykorzystać, w poprawny  z ekologicznego punktu widzenia w sposób, do zachowania przy życiu zagrożonego gatunku, jednocześnie zapobiegając wyniszczaniu przez ten gatunek zwierząt niezbędnych dla zaopatrzenia nas w pokarm”.




Różnice w pojęciach




Oprócz różnic w rozkładzie akcentów i ogólnym sposobie podejścia, istnieją także różnice w kluczowych pojęciach, jakie występują przy badaniu złożonego zachowania społecznego. Składają się na to wielorakie przyczyny i wielorakie skutki zamiast „zmiennej niezależnej” i „zmiennej zależnej”, wzajemne oddziaływania między współzależnymi częściami zamiast oddziaływania jednokierunkowego oraz systemy pojmowane jako organiczne całości, a nie jako zbiory odrębnie funkcjonujących jednostek.


Wielorakie przyczyny zamiast „zmiennej niezależnej”. Badania w psychologii tradycyjnej przeprowadzono zgodnie ze strategią polegającą na dążeniu do wyodrębnienia wpływu pojedynczych czynników na zachowanie.  Zmienne działające w danej sytuacji dzieli się arbitralnie na trzy kategorie: zmienne niezależne, zmienne utrzymywane na stałym poziomie oraz zmienne zależne. Zmieniając jedynie zmienną niezależną, badacz może stwierdzić, że w warunkach danego eksperymentu zmiana w poziomie zmiennej niezależnej była |przyczyną zmiany obserwowanej w zmiennej zależnej, która była |skutkiem.
Jednakże wyodrębnianie jednego badanego czynnika często powoduje, że zapominamy o istnieniu nieustannego wpływu wszystkich zmiennych, którymi |nie manipulujemy. Naciśnięcie przełącznika powoduje zapalenie światła tylko wtedy, |gdy istnieje nieuszkodzony obwód, dobra żarówka, system energetyczny, do którego można się przyłączyć i tak dalej. Wszystkie te elementy - a nie tylko samo naciśnięcie przełącznika - są warunkiem palenia się światła. Również w przypadku zachowania ścisła kontrola może pozwolić osiągnąć to, że po zmianie jednego bodźca będzie regularnie następować określona zmiana w zachowaniu, lecz nadal wśród przyczyn tego zachowania będą te czynniki, które utrzymywane są na stałym poziomie: wzmocnienie pokarmowe zmienia zachowanie tylko wtedy jeśli dany organizm jest głodny, czuwa, może widzieć, słyszeć lub zwęszyć pokarm i jeśli w danym momencie nie jest bardziej zainteresowany czymś innym.
Na pytanie: „Od czego uzależnione jest poruszanie się twego samochodu?” inaczej odpowiadano po lutym 1974 roku niż przed tym okresem braku benzyny.  Badanie opinii publicznej wykazało, że większość ludzi była przekonana, iż polityka rządu federalnego oraz towarzystw naftowych decydowała o tym, czy będzie dość benzyny aby uruchomić ich samochody (Murray i in., 1974).  Benzyna może być bezpośrednim czynnikiem przyczynowym decydującym o wprawianiu w ruch silnika samochodu, lecz jej dostępność stała się produktem końcowym mnóstwa innych przyczyn - intryg międzynarodowych, konfliktów między Arabami a Izraelem, podejrzewanej zmowy między towarzystwami naftowymi (zmierzającej do podniesienia cen przez zredukowanie dostaw), politycznego uprzywilejowania wielkich przedsiębiorstw, braku odpowiedniego nadzoru ze strony rządu lub braku długofalowego planowania zasobów energetycznych i tak dalej.




Zbliżenie


Czym „nakarmisz” swój samochód, gdy wcale nie będzie benzyny?


„W jaki sposób nałogowi „samochodziarze”, jacy są wśród nas, przystosują się do kryzysu energetycznego? Kenneth Bouldig (1974) wprowadza w swych przewidywaniach rozróżnienie między przystosowaniami długoterminowymi i krótkoterminowymi.
„Najwyraźniejszą i najbardziej drastyczną zmianą był nagły wzrost ceny i zmniejszenie się dostępności benzyny dla posiadaczy prywatnych samochodów.  Wydaje się prawdopodobne, że sytuacja taka utrzyma się przez dłuższy czas (...). Długoterminowe skutki są jednak uzależnione zarówno od zmian w podaży, jak i w pewnym stopniu od tego, co można by nazwać „mechanizmem popytu” - przystosowaniem preferencji i stylu życia do zmieniających się cen i struktur dochodu.
Muszę wyznać, że moim zdaniem, znacznie większy wysiłek zostanie włożony w problemy zaopatrzenia i podaży, niż w przystosowanie popytu. Samochód jest tym szczególnym przedmiotem, który bardzo łatwo powoduje wytworzenie się specyficznego nałogu. Określiłbym go jako zbroję z 200 końmi wewnątrz, dostatecznie dużą, aby uprawiać w niej miłość. Nic więc dziwnego, że jest on popularny. Przekształca on swego kierowcę w rycerza odznaczającego się ruchliwością arystokraty i zapewne także niektórymi innymi jego wadami.  Pieszy i osoba korzystająca ze środków transportu publicznego są, przez porównanie, wieśniakami spoglądającymi (z niemal nieuniknioną zawiścią) na rycerzy przejeżdżających obok nich w swych mechanicznych rumakach. Raz posmakowawszy rozkoszy społeczeństwa, w którym prawie każdy może być rycerzem, trudno jest wrócić do roli wieśniaka. Podejrzewam więc, że będą bardzo silne naciski, aby zachować samochód w jakiejś formie, nawet gdybyśmy musieli uciec się do syntezy jądrowej jako ostatecznego źródła energii i do płynnego wodoru jako namiastki benzyny. Alternatywnym rozwiązaniem byłoby, jak się zdaje społeczeństwo szczęśliwych wieśniaków, z których każdy uprawiałby swój własny, mały ogródek i jechał do pracy autobusem lub nawet elektrycznym tramwajem. To rozwiązanie wydaje się jakoś mniej prawdopodobne, niż rozpaczliwe próby znalezienia nowych źródeł energii dla zachowania naszej rycerskiej ruchliwości” (s. 255).


Trzeba zdawać sobie sprawę, że o tym, którymi zmiennymi się manipuluje, które utrzymuje się na stałym poziomie, a które ignoruje się w danym badaniu, decyduje się w sposób arbitralny i zależny od preferencji. Każdy psycholog manipuluje tymi zmiennymi, które wydają się najważniejsze w świetle jego podejścia teoretycznego, a utrzymuje na stałym poziomie zmienne „nieważne”.
Psychologowie interesujący się wpływem różnych rozkładów wzmocnienia posługują się organizmami o podobnym wyposażeniu genetycznym i podobnej motywacji (np. pozbawionymi pokarmu lub wody przez tę samą liczbę godzin).  Gdy w ten sposób utrzymuje się na stałym poziomie zmienne indywidualne, wówczas różne rozkłady wzmacniania istotnie prowadzą do uzyskania różnych krzywych uczenia się. Gdy teoretycy osobowości utrzymują wzmocnienie na stałym poziomie (dostarczając to samo wzmocnienie wszystkim badanym), a zmieniają motywację lub inne zmienne indywidualne, to wówczas stwierdza się, że zachowanie zmienia się wraz ze zmianą |tych właśnie czynników, a o rozkładach wzmocnienia nie wspomina się jako o przyczynie - ani nie uważa się ich za przyczynę. Lecz w obu wypadkach te zmienne, które utrzymywane były na stałym poziomie, działały nadal i były częścią tego, co „powodowało” dane zachowanie. Gdyby ich nie było lub gdyby były odmienne, to zachowanie mogłoby być zupełnie inne. Zmiana w jakimkolwiek miejscu danego systemu mogłaby zmienić obserwowane zachowanie.
Niekiedy zmienne, które utrzymujemy na stałym poziomie lub ignorujemy, okazują się tak ważne, że przyłamują ograniczenia schematu badawczego i zmuszają nas do zauważenia ich i badania. Przykładem takiej zmiennej może być wykryta przez Kellera Brelanda „tendencja instynktowna” („instinctual drift”); stwierdził on, że wpływ kontrolowanego w eksperymencie wzmocnienia był niekiedy ograniczony przez uwarunkowane genetycznie skłonności zwierzęcia, specyficzne dla jego gatunku. Innym przykładem jest tak zwane wdrukowanie („imprinting”); tutaj pewien rodzaj uczenia się o ogromnym wpływie na zachowanie, zdaje się nie stosować do zwykłych praw zachowania instrumentalnego. Jeszcze innym przykładem było wykrycie wyuczonej bezradności kiedy to zwierzęta, które w przeszłości miały do czynienia z silnym, nieuniknionym wstrząsem, nigdy nie nauczyły się uciekać, gdy stało się to możliwe, pomimo silnej motywacji i dużego wzmocnienia. Potężnym motywem, zarówno u ludzi, jak i u zwierząt, jest |ciekawość, popęd do badania i poznawania otoczenia. Aż do lat pięćdziesiątych naszego wieku, kiedy zostało „odkryte” owo źródło motywacji, badacze starali się minimalizować jego „zakłócający wpływ”, przyzwyczajając badane zwierzęta do środowiska eksperymentalnego przed rozpoczęciem badania, w którym zmiennymi były popędy biologiczne lub przebieg uczenia się.
Poszukiwanie pojedynczych przyczyn i prostych funkcjonalnych zależności jest tradycyjnie dążeniem nauki, w tym i nauk społecznych, podobnie jak dążeniem przeciętnego człowieka jest znalezienie odpowiedzi na pytanie, co spowodowało określone zdarzenie. Wszyscy szukamy prostoty w złożoności, z jaką mamy do czynienia. Niekiedy możliwe jest wykrycie głównej przyczyny - czynnika, który jest odpowiedzialny za większość zmienności reakcji - lecz często „jesteśmy niesprawiedliwi” wobec danego zjawiska, wymagając prostych odpowiedzi, gdy przyczyny są siecią wzajemnych powiązań, których nie można analizować „kawałek po kawałku”.
„Dlaczego?” pytamy, gdy nasze samochody, szkoły, kościoły, parki i domy są oszpecane i niszczone w pozornie bezsensowny sposób. Przekonaliśmy się w Rozdziale 14, że „wandalizm”, przyczyna takiego niszczenia własności, może być następstwem warunków społeczno-środowiskowych, który sprzyjają powstawaniu poczucia anonimowości. Aby jednak poczucie anonimowości przejawiło się w postaci wandalizmu, niezbędne są także inne warunki, takie jak uprzednia styczność ze społecznymi modelami określonych aktów wandalizmu, poczucie wyalienowania ze struktury nagród istniejącej w danym społeczeństwie oraz poparcie grupy dla takich czynności.
Badacze reprezentujący podejście ekologiczne uznają zatem, że większość doniosłych zjawisk ma wiele przyczyn. Co więcej, przyczyny te nie działają niezależnie od siebie, a wpływ ich nie jest wynikiem prostego sumowania - stanowią one sieć wzajemnie oddziałujących na siebie czynników. Toteż trzeba je badać jako sieć, jako wzajemnie ze sobą powiązane, wchodzące ze sobą w interakcję zmienne. Zmienne te mogą mieć odmienne skutki, w zależności od tego, jak są poważne; inne skutki występują także wtedy, gdy zmieniają się one wszystkie naraz, a inne, gdy pozwala się zmieniać tylko jednej z nich. Badając je oddzielnie jako zmienne niezależne, możemy uzyskać obraz zarówno niedokładny, jak i niekompletny.


Wielorakie skutki zamiast „wyniku” lub „zasadniczego skutku plus skutki uboczne”. Gdy szukamy wielorakich przyczyn, to musimy szukać także wielorakich skutków. Na pozór wiemy o tym, lecz w większości naszych badań nie jest to ważne - lub też sądzimy, że nie ma to znaczenia. Niektórzy pedagogowie starają się opracować specjalne schematy oddziaływań dydaktycznych, aby polepszyć znajomość ortografii u dzieci szkolnych. Lecz oprócz wyuczenia się listy słów, na tyle dobrze, aby wykonać z powodzeniem test z ortografii, dzieci mogą nauczyć się lubić lub nienawidzić szkołę, odczuwać szacunek do siebie z powodu górowania nad innymi lub mieć poczucie, że są głupsze od swych rówieśników. Mogą one także na razie uzyskiwać dobre stopnie, lecz później zachorować na owrzodzenie żołądka wskutek nieustannego napięcia i niepokoju. Mogą one nauczyć się posłuszeństwa wobec swego nauczyciela i zgeneralizować to posłuszeństwo na takie osoby mające władzę, które nie zasługują na nie.
Psycholog ekologiczny interesuje się |wszystkimi skutkami danej interwencji, łącznie z odległymi skutkami w innych częściach systemu i z opóźnionymi następstwami (skutki odroczone), które nie od razu się ujawniają. Aż nazbyt często zdarza się, szczególnie w sprawach społecznych i politycznych, że nawet takie przedsięwzięcia, dzięki którym skutecznie realizuje się zamierzone cele, przynoszą także wiele innych skutków - spośród których nie wszystkie są pożądane. Te długoterminowe, odroczone w czasie, ujemne skutki mogą nie tylko zniwelować, ale nawet przeważyć krótkotrwałe korzyści.
Tama Assuańska w Egippcie stanowi dobry przykład krótkotrwałego sukcesu, jeśli chodzi o osiągnięcie pewnego celu, co jednak na dalszą metę spowodowało nieprzewidziane klęski w innej części systemu. Tama osiągnęła zaplanowany cel - pozwoliła opanować wylew Nilu, nawodnić duży obszar i zapewnić mu energię elektryczną. Lecz ponadto spowodowała zniszczenie złożonego cyklu życiowego, w którym wylewy zapewniały bogate składniki odżywcze dla „łańcucha pokarmowego” - od fitoplanktonu, przez zooplankton do sardynek i człowieka. Wytwórnie rybne w delcie Nilu, które uprzednio produkowały około 1800 ton sardynek rocznie, obecnie dostarczają zaledwie 500 ton. Poziom życia w wioskach zamieszkałych przez rybaków poławiających sardynki uległ znacznemu obniżeniu wskutek udanego powstrzymywania wylewów przez tamę. Nadto istnieje obawa, że minerały pozostawiane w glebie przez wodę z systemu irygacyjnego mogą w końcu doprowadzić ziemię do zniszczenia; w dodatku od czasu zbudowania tamy nastąpił niepokojący wzrost zachorowań na |schistosomatozę, chorobę jelit powodowaną przez pasożyty rozwijające się w stojącej wodzie.
W miarę jak psychologia uzyskuje coraz większe możliwości oddziaływania, musimy zdawać sobie sprawę, że wszelkie interwencje, jakie podejmujemy w stosunku do innych ludzi (lub siebie samego) będą miały wiele skutków, między innymi niektóre niezamierzone, inne zaś nieprzewidywalne; długoterminowe następstwa w pewnej sferze mogą zniweczyć krótkoterminowe skutki w innej. Ponadto, powinniśmy zdawać sobie sprawę z faktu, że reformy społeczne i ustawy, które mają na celu skorygowanie jakiegoś rozpowszechnionego zła społecznego, są najczęściej interwencjami, |eksperymentalnymi |manipulacjami. Przyjmujemy za coś oczywistego istnienie szpitali psychiatrycznych i więzień, aczkolwiek pierwotnie były one pomyślane jako postępowa reforma mająca zapewnić spokojny azyl od stresów nowoczesnego życia w burzliwym okresie dziejów Ameryki, za rządów prezydenta Jacksona w pierwszej połowie XIX wieku (Rothman, 1971).  Obecnie, gdy istnieją poważne dowody, że tego rodzaju „azyl” nie spełnia swego zadania, nie są likwidowane, ponieważ „zinstytucjonalizowały się” i opierają się krytycznym ocenom.
W więzieniach stanu Kalifornia przebywają więźniowie skazani na nieokreślony czas pozbawienia wolności (na przykład, sześć miesięcy do pięciu lat, pięć lat do dożywocia itd.). Zamierzonym skutkiem tej innowacji w formułowaniu wyroków było skrócenie czasu przebywania skazanych w więzieniu do minimum, przez danie personelowi więzienia możliwości zalecenia jak najwcześniejszego warunkowego zwolnienia więźnia, zamiast jak dawniej zmuszać sędziego do wyznaczenia sztywnego okresu, w którym więzień nie mógł być nagrodzony za „dobre sprawowanie się”. |Rzeczywisty skutek, przeciwny do zamierzonego, polega na |wydłużeniu przeciętnego okresu pobytu w więzieniu; w więzieniach stanu Kalifornia okres ten jest obecnie najdłuższy w całym państwie!
Jako obywatele i psychologowie musimy nauczyć się przewidywać możliwie najwięcej skutków (krótkoterminowych i długoterminowych) każdej proponowanej zmiany, jak również naszych obecnych sposobów działania, tak abyśmy potrafili wybierać te rozwiązania, które charakteryzować będzie najwyższy stosunek korzyści do kosztów - ekonomicznych, społecznych i psychologicznych. Musimy także nalegać, aby każdą taką proponowaną interwencję poddawać określonej analizie i krytycznej ocenie, tak aby ustalić, czy jest ona efektywna, bezużyteczna, czy nawet szkodliwa.  Uzasadnieniem dla kontynuowania eksperymentów społecznych nie może być fakt, że już istnieją, lecz stwierdzenie, że pozwalają one osiągnąć konkretne cele (określone w kategoriach zachowań). Wszelkie przeprowadzane przez nas eksperymenty społeczne muszą być nieustannie analizowane i oceniane w sposób niezależny. Nie ulega wątpliwości, że zasadniczym komponentem każdej nowej ustawy społecznej powinny być propozycje systematycznych badań służących ocenie jej efektywności w realizacji wytyczonego celu.


Wzajemne oddziaływania zamiast oddziaływań jednokierunkowych. W tradycyjnej psychologii badano zależność reakcji od bodźców, czyli oddziaływanie jednokierunkowe. Ostatnio wielu psychologów starało się skorygować ten model, postulując istnienie pętli sprzężenia zwrotnego.  Podejście ekologiczne idzie dalej, uznając wzajemne związki i wzajemne oddziaływania za sytuację najbardziej rozpowszechnioną. Wpływ pewnego czynnika środowiskowego na zachowanie zmienia w drodze sprzężenia zwrotnego środowisko, które z kolei może następnie wpływać na to zachowanie zupełnie inaczej. Zarówno jednostka, jak i środowisko, zmieniają się nieustannie w wyniku tych interakcji.
Tradycyjne schematy badawcze maskują te wzajemne oddziaływania, ponieważ starają się ustalić związek między jednym zbiorem warunków bodźcowych a drugim zbiorem reakcji, przy czym inne czynniki pozostają bez zmiany (kontrolowane i na stałym poziomie). Lecz w życiu realnym różne czynniki nie pozostają stałe i niezmienne, ich fluktuacje zaś oddziałują na siebie nawzajem - powodując zmiany i podlegając im. Gdy patrzymy na zachowanie jako na ciągły strumień, to widzimy wzajemne oddziaływanie i dynamiczne interakcje - a nie czynności i zdarzenia spokojnie oczekujące na to, aby ktoś je z czymś powiązał.
Na przykład ciekawa żona (brunetka) pyta swego męża, skąd się wziął jasny włos na jego ramieniu. Przypuśćmy, że to pytanie wzbudza w nim poczucie winy, które stara się on ukryć przechodząc do ofensywy i atakując słownie żonę. Intensywność jego reakcji jest dla niej sygnałem, że prawdopodobnie coś ukrywa; wzmaga się intensywność śledztwa. Jej wypytywania napotykają jeszcze silniejszą agresję z jego strony, i błahy epizod rozwija się w poważną konfrontację. W jaki sposób mógłbyś określić zmienna niezależną w tym epizodzie? Czy było nią pytanie żony? jej ciekawość? jasny włos? dawna niewierność męża? sposób zadawania pytań przez żonę? jego poczucie winy?  jego obronny kontratak? czy może nawet jakiś inny motyw ze strony żony, taki jak chęć ukrycia swej własnej niewierności lub chęć nakłonienia męża do jakiegoś wypływającego z poczucia winy aktu uległości, takiego jak złożenie wizyty teściom?


Nie ulega wątpliwości, że właściwy sposób analizy nie polega tu na wyodrębnianiu zmiennych, lecz na badaniu układu wzajemnych zależności między obydwoma reagującymi stronami.
Inny przykład jeszcze lepiej ilustruje to zagadnienie subtelnej, wzajemnej zależności środowiska i zachowania.


„Przed umieszczeniem małego, rzadkiego ptaszka, zwanego Bearded Tit (sikorka brodata), w ptaszarni pewnego europejskiego ogrodu zoologicznego, jego opiekun poświęcił wiele czasu, wysiłku i cierpliwości, aby zbadać naturalne siedlisko tego ptaszka i jego tryb życia; zaprojektował on w ogrodzie zoologicznym warunki, które były ekologicznie właściwe dla tego gatunku, i zarówno samce, jak i samice, wydawały się być w nim bardzo szczęśliwe. Ptakom nowe otoczenie podobało się do tego stopnia, że nie tylko jadły, piły, muskały piórka i latały swobodnie dookoła, lecz także śpiewały, kojarzyły się w pary, budowały gniazda, składały jajeczka i wysiadywały pisklęta.
Uszczęśliwiony opiekun po kilku dniach przekonał się z przerażeniem, że wszystkie pisklęta leżą martwe na ziemi. Rodzice byli nadal aktywni i „radośni” jak zawsze, więc doszedł do wniosku, że musiał to być wypadek.  Kiedy jednak cykl rozrodczy powtórzył się i wykluły się nowe pisklęta, to one również w krótce wszystkie były martwe.
Staranne obserwacje ujawniły, że mordercami byli rodzice - wypychali oni pisklęta z gniazda na ziemię, gdzie ginęły! Ten cykl kojarzenia się w pary, wysiadywania młodych i wypychania ich z gniazda - co powodowało śmierć - powtórzył się kilka razy. Lecz dlaczego? Dlaczego ci pozornie szczęśliwi, „normalni” rodzice zachowywali się w „anormalny sposób” w tym troskliwie zaprojektowanym środowisku?
Opiekun powrócił do normalnego środowiska ptaków, aby zaobserwować, czy było coś takiego, co przeoczył w swym projekcie. Wykrył on, że pisklęta spędzały tam wiele godzin na donośnym domaganiu się pokarmu, podczas gdy rodzice poświęcali wiele czasu na poszukiwanie pożywienia (którego było niewiele) i karmieniu wymagających malców. Ponadto rodzice utrzymywali gniazdo w czystości, wyrzucając z niego wszystkie nieożywione przedmioty, takie jak liście, skorupki jajek czy pióra.
Oto rozwiązanie zagadki! W nowym, „doskonale zaprojektowanym” środowisku, pokarmu było pod dostatkiem, tak że potrzeby piskląt mogły być szybko zaspokojone. Nakarmione pisklęta zasypiały - w biały dzień, gdy rodzice nadal czuwali: stawały się wówczas „przedmiotami nieożywionymi” i były wyrzucane przez rodziców z gniazda. Gdy środowisko ptaków w zoo zmieniono w ten sposób, że pokarmu było mało i trudno go było znaleźć wówczas pisklęta czuwały wołając o pożywienie rodzice byli zajęci poszukiwaniem go i wszyscy od tej pory żyli szczęśliwie”. (Willems, 1973).


Przykład ten wskazuje na złożoną zależność między ilością dostępnego pokarmu, poszukiwaniem go przez rodziców, nie zaspokojonym głodem piskląt oraz ich aktywnością i utrzymaniem się przy życiu. Wykazuje on jeszcze raz, dlaczego dla psychologa o orientacji ekologicznej najważniejszym kryterium stosowanym w ocenie jakiegokolwiek sposobu działania są często miary efektywności długoterminowej. Zaprojektowane środowisko ptaków było sukcesem tylko wtedy, gdy oceniano je jedynie na podstawie pozornej adaptacji rodziców do niego. Gdy jednak do tych kryteriów włączono utrzymywanie się przy życiu piskląt tych rodziców, wówczas sprawa przedstawiała się zupełnie inaczej.
Ten sam problem powstaje, gdy próbujemy ocenić skutki, jakie dla istot ludzkich mają zmiany społeczne, takie jak życie w komunach czy różnorodne style związków małżeńskich. Czy sukcesy takich przedsięwzięć należy oceniać na podstawie tego, w jakim stopniu przynoszą one szczęście swym uczestnikom, czy też stosowanie do tego, w jakim stopniu sprzyjają one zdrowemu rozwojowi i szczęściu dzieci w następnym pokoleniu? Czy będziemy wystarczająco inteligentni, aby opracować modele korzystne zarówno dla nas samych, jak i naszych dzieci?




Zbliżenie


Przejście do dorosłości a życie społeczne


„Dwa główne okresy rozwoju jednostki, uznawane w większości społeczeństw, to dzieciństwo i wiek dojrzały. „Młodość” jest pośrednim stadium, które pojawiło się, między innymi, w pismach psychologów rozwojowych dopiero w okresie pierwszej wojny światowej. Obecnie występuje szereg zmian społecznych, które zdają się prowadzić do ukształtowania jeszcze jednego stadium w procesie „stawania się dorosłym”. Okres rozciągający się od 17-19 roku życia (wstąpienia na uczelnię), do dwudziestu kilku, a nawet trzydziestu paru lat, najlepiej można określić jako |przechodzenie |do |dorosłości („transadulthood”). Jest ona konsekwencją głębokich zmian wartości we współczesnym społeczeństwie, które mogą z kolei doprowadzić do jeszcze większych zmian w modelu życia nadchodzących generacji.
Badacze z Rutgers University, Carl Danzinger i Matthew Greenwald (1974), określają stadium przechodzenia do dorosłości jako „okres eksperymentowania z różnymi stylami życia, poszukiwania kierunku kariery oraz wypróbowywania możliwych kierunków kształcenia się. Jest on często okresem, w którym obowiązki są minimalne, a swoboda osobista - maksymalna. Pragnienie, aby utrzymać swobodę wyboru, aby być stale elastycznym i przygotowanym do zmian, jest charakterystyczne dla jednostki w tym okresie życia” (s.  9,20).
Oto niektóre z czynników, jakie wpływają na tworzenie się tego nowego stadium i na związany z nim styl życia: a) większa dostępność wyższych uczelni dla wielu młodych ludzi, zwłaszcza mieszkających w internatach (wyłącznie ze swymi rówieśnikami), spotęgowała poczucie specjalnej tożsamości młodych ludzi, którzy są za „starzy”, aby zaliczać się do młodzieży, a zbyt młodzi, aby być ludźmi dojrzałymi; b) ruch wyzwolenia kobiet podważa tradycyjne role mężczyzny i kobiety (męża i żony) oraz narusza wszelkie komercyjne więzy wczesnego małżeństwa i biernej akceptacji miejsca kobiety w domu; c) ruch Zero Population Growth (Zerowego Wzrostu Populacji) skłonił wielu młodych ludzi do przemyślenia problemu wielkości rodziny, do późniejszego podejmowania decyzji o posiadaniu dzieci lub postanowienia, aby w ogóle nie mieć dzieci; d) zaakceptowanie i dostępność „pigułki” antykoncepcyjnej zmieniła między innymi postawy seksulane, jednym zaś ze skutków tego było dopuszczenie eksperymentowania z różnego rodzaju układami partnersko-życiowymi; e) wzrost wskaźnika rozwodów sprawił, że wiele osób w okresie przechodzenia do dorosłości przyjęło cyniczne postawy wobec trwałych związków; dostarczył on modeli samotnych rodziców z powodzeniem przystosowujących się do tego stylu życia.
Na podstawie wywiadów, przeprowadzonych z jednostkami, parami i grupami, badacze dochodzą do wniosku, że „w latach siedemdziesiątych stadium przechodzenia do dorosłości będzie w coraz większym stopniu uznawane rzez społeczeństwo. Więcej osób w wieku od lat kilkunastu do dwudziestu kilku przyjmie styl życia charakterystyczny dla tego stadium. Będzie to mieć istotne reperkusje ekonomiczne, podobnie jak formalizacja stadium młodości również pociągnęła za sobą skutki ekonomiczne” (s. 30).
Jesteśmy więc świadkami powstawania nowego stadium psychospołecznego, ilustrującego, jak złożone siły działające w społeczeństwie stwarzają warunki, które wpływają na wybory jednostki. Gdy jednostki zaczynają dokonywać nowych wyborów i przyjmować nowe założenia, wówczas system lub jego część również się zmienią”.


Systemy zamiast zbiorów odrębnych jednostek. Tradycyjna psychologia poświęcała wiele wysiłków staraniom zmierzającym do ustalenia cech, zdolności, popędów, postaw oraz innych właściwości jednostek jako zmiennych wyjaśniających, dlaczego robimy to, co robimy. Radykalny behawioryzm popadł w przewiną skrajność, starając się wyjaśnić całą zmienność zachowania w kategoriach zdarzeń środowiskowych, a szczególnie zasad wzmacniania. Nadal jednak każdy organizm rozpatrywano w nim jako odrębną całość.
Podejście ekologiczne kładzie nacisk na fakt, że nie tyle jesteśmy otoczeni przez środowisko, ile stanowimy jego część, struktury zaś i naciski systemów, których jesteśmy częścią, są ważnymi „przyczynami” naszego zachowania.
Natura systemów decyduje o naszych wyborach, jak w przypadku farmerów z Illinois, którzy muszą wybierać między zyskiem materialnym a zdrowiem swych dzieci.
System społeczny może wywierać silny nacisk skłaniając do wybrania tej a nie innej możliwości, jak w przypadku badań Milgrama nad posłuszeństwem, w których jednostki zachowywały się agresywnie (w zaplanowany sposób), aczkolwiek wcale nie chciały wyrządzić krzywdy swej ofierze, a ich zachowanie było sprzeczne z ich własnymi przekonaniami.




Zbliżenie


Społeczności lokalne a zbiorowiska ludzi


„Różnice między systemem a zbiorowiskiem oddzielnych jednostek można zaobserwować w kontraście między starymi dzielnicami w centrum Nowego Jorku a podobnymi dzielnicami przekształcanymi w „osiedla mieszkaniowe”. Jane Jacobs (1961) opisuje, w jaki sposób korzystanie z chodników i innych miejsc publicznych w starych społecznościach lokalnych dostarcza ludziom tylu kontaktów z innymi ludźmi, ilu pragną, umożliwiając wytworzenie poczucia sąsiedztwa i zaufania.
„Wzajemne poczucie zaufania wśród ludzi mieszkających przy wielkomiejskiej ulicy kształtuje się z czasem z wielu, wielu drobnych kontaktów na publicznym chodniku. Rozwija się ono dzięki temu, że ludzie wstępują do baru na piwo, zasięgają rady od właściciela sklepiku i udzielają rad sprzedawcy w kiosku z gazetami, porównując swe opinie z opiniami innych klientów w piekarni i pozdrawiają skinieniem głowy dwóch chłopców pijących oranżadę na ganku, zerkają na dziewczęta w czasie, gdy czekają na obiad, napominają dzieci, słuchają opowiadania sprzedawcy wyrobów żelaznych o jego pracy, pożyczają dolara od drogerzysty, podziwiają nowo narodzone niemowlęta i wyrażają współczucie z powodu wyblaknięcia marynarki...
Sumą takich dorywczych, społecznych kontaktów na poziomie lokalnym - z których większość jest przypadkowa, większość związania z załatwianiem jakichś spraw, a wszystkie są regulowane przez zainteresowanie osoby, a nie narzucane im przez kogoś - jest poczucie społecznej tożsamości ludzi, tkanka powszechnego szacunku i zaufania oraz ratunek w potrzebie osobistej czy społecznej. Brak takiego zaufania jest klęską dla ulicy wielkomiejskiej” (s. 56)
Jedną z konsekwencji istnienia lub braku istnienia takiej sieci zaufania można zaobserwować w zachowaniu się dzieci w danej dzielnicy oraz reakcji dorosłych na nią. Jacobs przedstawia sobie sytuacje istniejące po obu stronach tej samej szerokiej ulicy w pewnej dzielnicy Nowego Jorku, gdzie mieszkają ludzie z mniej więcej takich samych grup ekonomicznych i rasowych.
„Po stronie staromiejskiej, gdzie w publicznych miejscach i na chodniku mitrężono czas w sposób tak opłakiwany przez utopijnych myślicieli, projektujących dla ludzi inne formy spędzania wolnego czasu, dzieci były pod dobrą opieką. Po drugiej, osiedlowej stronie ulicy, dzieci które miały dostęp do otwartego hydrantu pożarowego znajdującego się obok ich placu zabaw, zachowywały się destrukcyjnie, lejąc wodę w otwarte okna domów, ochlapując dorosłych, którzy obojętnie przechodzili osiedlową stroną tej ulicy, pryskając wodą w szyby przejeżdżających samochodów. Nikt nie ośmielił się ich powstrzymać. Były to anonimowe dzieci i nie było wiadomo, kto zanimi stoi. Co by się stało, gdybyś je zganił lub powstrzymał? Kto przyszedłby ci z pomocą tam, na nieznanym terytorium jakiegoś gangu młodzieżowego? A może spotkałaby cię zemsta? Lepiej trzymać się od tego z daleka. Bezosobowe ulice wielkomiejskie czynią ludzi anonimowymi (...)” (s.57).
To przeciwstawienie ukazuje pułapki, jakie czyhają przy ustalaniu danych dotyczących korelacji między pojedynczymi czynnikami, takimi jak „pozycja społeczno-ekonomiczna” a dane zachowanie. Wpływ danych czynników społeczno-ekonomicznych nie jest taki sam w różnych sytuacjach, lecz zależy od tego, jakie jeszcze działają wtedy czynniki, i od tego, jak są |one silne lub słabe.
O adekwatności stosowania stwierdzeń dotyczących pojedynczych zależności, przy ignorowaniu innych decydujących czynników działających w danej sytuacji, świadczą, zdaniem Jacobs, miejsca publiczne zaprojektowane w tych osiedlach. Aczkolwiek zapewniają one miejsce do zbierania się ludzi, to jednak nie zapewniają one niezbędnej równowagi między sposobnością do kontaktów z ludźmi a potrzebą prywatności i możliwością uwolnienia się od tych, którzy mogą „dokonać zamachu” na nasz czas. Zaplanowane miejsca spotkań, takie jak sale gier, zbyt często stają się się pułapkami, z których mieszkańcy nie mogą się wydostać lub w których nie mogą mieć po prostu jedynie |krótkotrwałego kontaktu z ludźmi. Gdy wytworzy się zbyt wielka zażyłość pomiędzy sąsiadami z osiedla, to tracą oni „swobodę ruchu” i nie mogą się uchronić przed wtargnięciem intruzów, wobec tego występuje tendencja do |nienawiązywania bliskich, przyjaznych stosunków z innymi mieszkańcami tego samego osiedla, lecz szuka się przyjaciół w innych osiedlach lub w innych częściach miasta. To z kolei rodzi tę anonimowość i brak społecznej więzi, która przyczynia się do patologii społecznej wielu naszych ośrodków miejskich”.


Podany poniżej tytuł wiadomości w gazecie ilustruje często spotykany sposób, w jaki struktury i naciski pewnego systemu przeszkadzają nam we współdziałaniu z innymi osobami, tak jak należałoby współdziałać z istotami ludzkimi:


Kierowcy Ignorują Błagania 10-letniej Nagiej Dziewczynki - Dziecko 
Znaleziono zgwałcone I Zamordowane


Zgodnie z zamieszczonym w gazecie opisem tego zdarzenia, 10-letnia dziewczynka na próżno usiłowała uzyskać pomoc zatrzymując przejeżdżające samochody na ruchliwej autostradzie. Było to w godzinę największego ruchu i ocenia się, że minęło ją około stu samochodów. Żaden nie zatrzymał się, aczkolwiek dziewczynka była naga, krzyczała i machała rękami. Została ona porwana, uciekła z samochodu i usiłowała wzywać pomocy. Kiedy żaden z samochodów nie zatrzymał się, porywacz wrócił, zgwałcił dziewczynkę, a następnie udusił ją.


„Kilku kierowców, którzy minęli dziewczynkę nie udzielając jej pomocy, zeznało na policji, że widziało ją, a także wóz wracający ku niej poboczem autostrady. Podawane przez nich przyczyny, dla których nie zatrzymali się, aby udzielić pomocy, ilustrują tę „mentalność ekspresowych autostrad”, jaką stworzyliśmy dzięki naszemu systemowi szybkiego ruchu: „Nie mogłem uwierzyć w to, co widziałem, jechałem tak szybko”, powiedział jeden z kierowców.  Inny usprawiedliwiał swój brak reakcji na sygnały nadawane rzez człowieka w potrzebie wyjaśniając: „Sądziłem, że ktoś za mną był w lepszej sytuacji.  Znajdowałem się na paśmie mijania jadąc z szybkością 65 do 70 mil na godzinę, a tuż za mną było pięć czy sześć samochodów” (...).
Nie polegało to na tym, że kierowcy byli nieczuli czy bez serca. Lecz byli oni częściami systemu wzajemnie uzależnionych od siebie elementów pędzących z szybkością 60 mil na godzinę. Obraz dziewczynki machającej rękami pojawiał się w ich oczach jedynie na moment i zanim zdali sobie z tego sprawę, co widzą już ją mijali. Naciśnięcie hamulców byłoby niebezpieczne. Nie mogli wiedzieć, co zdarzyło się tej dziewczynce, wszystkie zaś naciski oddziałującej na nich sytuacji przeszkadzały w porozumieniu się z nią i utrzymywały ich uwagę skupioną przede wszystkim na tym, aby nie narazić siebie ani innych przez nagłą zmianę kierunku jazdy lub zatrzymanie się. Ci, którzy widzieli wracający ku niej samochód, przypuszczali prawdopodobnie (lub mieli nadzieję) że to jakiś dobry samarytanin zdąża jej z pomocą - i odczuwali ulgę, ponieważ oni nie musieli już tego czynić.
Wiele z ich racjonalizacji miało pewne podstawy w rzeczywistości. Lecz pozostaje faktem, że jechali dalej, zamiast zatrzymać się w odpowiedzi na sygnały dziecka w potrzebie; w ułamku sekundy, w którym musieli dokonać wyboru, „system szybkiego ruchu” ustrukturalizował ich działania w taki właśnie sposób”.
Widzimy tu zatem błędne koło: ludzie zmieniają naturalne środowisko i tworzą struktury fizyczne i społeczne. Te z kolei ograniczają, ukierunkowują i zmieniają nas samych: zachęcając do pewnych zachowań, do innych jednocześnie zniechęcając lub zapobiegając im, często w sposób, którego nie przewidzieliśmy.
John Platt z University of Michigan zwrócił uwagę na „pułapki”, które niekiedy tworzą się w systemach społecznych - ludzie zachowują się w sposób, który - jak potrafią przewidzieć - będzie dla nich na dalszą metę szkodliwy, lecz nie wiedzą, w jaki sposób zaprzestać owego zachowania (Platt 1973). Uzależnienie się farmerów od stosowania sztucznych nawozów jest przykładem takiej pułapki. Lecz jest nim również nasza zależność od techniki, zależność od innych ludzi świadczących nam usługi, zależność od nieograniczonych dostaw energii naturalnej. Jesteśmy schwytani w pułapkę różnych urządzeń i aparatów nowoczesnej techniki - „oszczędzających czas” i „ułatwiających życie” - i po prostu nie potrafimy się bez nich obejść, oczywiście, jeżeli nie musimy.


„The Whole Earth Catalogue” (Katalog Całej Ziemi) cieszył się powszechnym uznaniem i odniósł sukces handlowy, ponieważ ożywił w wielu z nas zainteresowanie samowystarczalnością - jak nauczyć siebie i innych ograniczania swoich wymagań, ze względu na własny, jak i wspólny interes.  podobnie niedawny kryzys energetyczny wyzwolił nowe siły twórcze, ukierunkowane na kształtowanie alternatywnych stylów życia - w mniejszym stopniu uzależnionych od ropy naftowej, węgla i maszyn, które zarówno wyzwoliły nas od ciężkiej pracy, jak i pozbawiły nasze życie prostoty (zob.  Hammond, 1974).
Inny przykład pułapki społecznej nosi nazwę „tragedii wspólnych pastwisk”. W Anglii każdy farmer użytkujący wspólne pastwisko dochodzi do wniosku, że korzystne byłoby dla niego zwiększenie swego stada o dodatkową krowę. Jest oczywiste, że na dalszą metę wszyscy poniosą szkodę, ponieważ pastwisko zostanie zbyt wypasione, a jednak każdy farmer, który zacząłby ograniczać wielkość swego stada, traciłby tak długo, dopóki inni utrzymywaliby swoje stada w nie zmienionej wielkości. Jak mamy nauczyć ludzi, aby działali nie tylko dla własnego dobra, lecz także dla |dobra |wspólnego? Lub też, ujmując to zagadnienie inaczej, w jaki sposób nauczymy się wreszcie, że krótkotrwałe własne korzyści mają często katastrofalne konsekwencje na dalszą metę, ponieważ naruszają wspólne dobro - z którego i my także czerpiemy? Bardziej znaną pułapką społeczną jest wyścig zbrojeń nuklearnych, w którym obie strony zdają sobie sprawę z tego, że dla każdej z nich byłoby lepiej, gdyby wykorzystały cenne zasoby i umiejętności dla zwiększenia potencjału życia, a nie potencjału śmierci. Jednakże żadna ze stron nie ośmiela się jako pierwsza zaprzestać zbrojeń.




Zbliżenie


Problemy spowodowane przez system wymagają systemowych rozwiązań


„W mieście, jakie znamy, godzina szczytu oznacza, że aby dostać się do domu, trzeba stracić ponad 60 minut, zamiast „normalnych” dwudziestu minut w każdej innej porze. Dzieje się tak nie dlatego, że jest zbyt wiele samochodów na ulicach, lecz dlatego, że samochody wpychają się na skrzyżowaniach nawet wtedy, gdy nie będą go mogły opuścić przed zmianą świateł. Wskutek tego pojazdy oczekujące na przecznicy nie mogą przejechać przez skrzyżowanie nawet wtedy, gdy mają zielone światło. W końcu zaczyna się „przepychanie”, aż wreszcie samochody zdążające ze wszystkich czterech stron zaklinowują się na skrzyżowaniu. Kierowcy zajmują każdy wolny cal powierzchni, bo gdyby tak nie robili, to „nigdy nie przedostaliby się przez skrzyżowanie”.
To samo zdarza się na następnym skrzyżowaniu, na drugim z kolei, i tak dalej, we wszystkich kierunkach. Wobec tego skrzyżowanie nie opróżnia się, ponieważ następne jest „zakorkowane” i cały obszar, w którym występuje duży ruch, zostaje nagle unieruchomiony.
W takim systemie jednostki są bezradne. Ich normalne nawyki prowadzenia wozu nagle przestają być przydatne. Nie mają już możliwości wykazywania uprzejmości czy stosowania się do sygnałów świetlnych. System, w który się uwikłali, nie oferuje im żadnego racjonalnego rozwiązania problemu przedostania się przez skrzyżowanie. Im wszystkim nie podoba się to, co robią, uświadamiają sobie irracjonalność danego sposobu postępowania, czują do siebie niechęć z powodu tego, że wchodzą sobie w drogę, i nadal wpychają się, gdzie tylko mogą.
Tylko zmiana systemu mogłaby przynieść rozwiązanie ich problemów.  Dokonałby tego policjant regulujący ruch na skrzyżowaniu lub wprowadzenie surowych przepisów przewidujących grzywnę za przebywaniu na skrzyżowaniu w chwili zmiany świateł. W pewnym znanym nam mieście na skrzyżowaniach wymalowane są na jezdni prostokąty. Każdy samochód, przyłapany na obszarze takiego prostokąta w momencie zmiany świateł, podlega grzywnie. Lecz jest także możliwe przekonanie pracodawców, aby wprowadzili zróżnicowane godziny rozpoczynania i kończenia pracy, tak żeby okresy dojazdu do pracy i powrotu do domu rozłożyły się na dłuższy czas. Również „spółki” właścicieli samochodów wspólnie dojeżdżających do pracy oraz lepsza komunikacja publiczna mogłyby zredukować liczbę samochodów rywalizujących o swe indywidualne prawa. Aby uzyskać takie proste zmiany, trzeba by było jednak dokonać poważnych zmian w sposobie myślenia - należałoby sprawić, by przywiązywano mniejszą wagę do intymności i wygód uzyskiwanych dzięki dobrym warunkom materialnym”.


Takie pułapki społeczne są charakterystyczne nie dla jednostek, lecz dla systemów. Ograniczają one możliwości wyborów i decydują o tym, jakie będą konsekwencje dokonanego wyboru. Tak więc są one ważnymi wyznacznikami tego, czy i w jaki sposób jednostki w danym systemie mogą zaspokoić swe podstawowe potrzeby. Ludzie, którzy nie potrafią wybrać i określić swego stylu życia w izolacji od reszty systemu, muszą stosować się do reguł tego systemu, jeśli mają osiągnąć powodzenie, a może nawet, jeśli mają utrzymać się przy życiu. Jeśli stosowanie się do tych reguł oznacza angażowanie się w zachowanie, jakiego nie aprobują, to ich wybór może oznaczać rezygnację albo z szacunku do siebie samego, albo z poważania innych, z którym to poważaniem łączy się uznanie awanse i bardziej konkretne nagrody.
Chociaż nasze możliwości (jako jednostek) w zakresie działania i osiągania rezultatów są w danym momencie ograniczone przez te właściwości systemu, to nie jesteśmy jednak na stale zdani na jego łaskę, ponieważ systemy można zmieniać. Uczymy się wreszcie, że wszystko to, co istnieje w systemach społecznych nie jest nieuchronne. Podobnie jak zmieniamy nasz świat fizyczny - czasami prawie nie do poznania - tak zaczynamy zdawać sobie sprawę, że przez planowanie i wspólne działanie możemy zmienić nasz świat społeczny w taki sposób, aby lepiej zaspokajał nasze ludzkie potrzeby.




Zbliżenie


Co jest dla nas dobre?


„Jeśli mamy dopomóc w uporządkowaniu świata, to będziemy musieli rozstrzygnąć, czym jest „porządek.



Mogłoby być interesujące, gdybyś próbując badać te zagadnienia poprosił swoich kolegów, by postarali się opisać swe „utopie”. Jakimi cechami ich zdaniem powinno odznaczać się środowisko najlepiej przystosowane do zaspokajania potrzeb ludzkich? Gdy wykonają oni to zadanie, to porównaj ich odpowiedzi ze swymi własnymi odpowiedziami oraz z podaną niżej definicją (opartą na pracy Pottera, 1971). Potter wymienia następujące cechy definiujące „optymalne środowisko”:
1. Możliwość zaspokajania podstawowych potrzeb dzięki indywidualnym lub wspólnym staraniom.
2. Ochrona zdrowia jednostek przez uwolnienie ich od działania szkodliwych substancji chemicznych, niepotrzebnych czynników traumatycznych (wojna, wypadki drogowe, hałasy itd.) oraz chorób, którym można zapobiec.
3. Poszanowanie słusznych zasad ekologicznych; nauczenie się, jak żyć z przyrodą, zamiast „panować” nad nią.
4. Ciągłe rozwijanie u każdej jednostki zintegrowanego, adaptacyjnego systemu reakcji za pośrednictwem systematycznych wymagań stawianych jej przez fizyczne i intelektualne zadania, które są w zasięgu jej możliwości (lub na górnej ich granicy).
5. Szczęście jednostki które wiąże się z ukształtowaniem trwałego poczucia osobistej tożsamości oraz zdolności doceniania satysfakcji życiowych i odnoszenia korzyści z przykrości.
6. Zaangażowanie się każdej jednostki w pracę na rzecz innych członków społeczeństwa dla zwiększenia ich siły, możliwości działania i szczęścia.
7. Nieustanne dążenie do piękna i porządku, które nie neguje roli indywidualności, ekscentryczności i nieładu.



W dalszych częściach „Epilogu” przypatrzymy się niektórym specyficznym problemom psychologii oraz jej możliwościom przyczynienia się do wspomnianych wyżej zmian. Najpierw zajmiemy się etycznymi problemami interwencji - w laboratorium, w ramach terapii oraz w społeczeństwie.  Następnie zakończymy nasze rozważania - i całą naszą książkę - przykładami udanego zastosowania psychologii do polepszenia jakości ludzkiego życia.




Etyka interwencji




„Charakterystyczny dla naukowców sposób patrzenia na świat z punktu widzenia własnej dyscypliny - nieuchronnie stwarza dylematy etyczne, choćby dlatego, że wiedza i techniki naukowe, które można zastosować dla polepszenia losu człowieka, można zwykle wykorzystać także do celów manipulacji i eksploatacji”.
APA (American Psychological Asscociation), „Etical Principles”, 1973 s. 8


Problemy etyczne wyłaniają się zawsze wtedy, gdy jednostka robi coś, co ma wpływ na życie innych ludzi. Są one nieuniknionym elementem wszystkiego, co dotyczy życia społecznego. Lecz mają one specjalne znaczenie dla zawodu psychologa, ze względu na to, że prowadzone przez niego badania i terapia wymagają bezpośredniej interwencji w zachowanie, w sposób myślenia i poglądy osób badanych oraz pacjentów. Zasady etyczne wymagają podporządkowania się ogólnym normom moralnym, jak również wskazaniom określającym możliwy do zaakceptowania sposób postępowania, ustalony przez otoczenie lub grupę zawodową. W praktyce ustalenie, co stanowi pogwałcenie zasad etycznych, rzadko jest prostą decyzją opartą na absolutnych kryteriach. Niemniej jednak tylko wtedy, gdy psychologowie angażują się w nieustanne dążenie do postępowania w sposób etyczny wobec osób badanych i pacjentów, można będzie przezwyciężyć tendencje do gwałcenia norm etycznych.
Ze względu na oburzenie o protesty społeczeństwa przeciw faktom niepoddawania leczeniu pacjentów chorych na choroby weneryczne lub raka, których zaliczono do grup kontrolnych w różnych badaniach lekarskich.  Kongres Stanów Zjednoczonych pracuje nad wydaniem ustawy przewidującej powołanie komisji do spraw etyki przy Department of Health, Education, and Welfare (Departamencie Zdrowia, Edukacji i Pomocy Społecznej). Ustawa ta ma spowodować powołanie Commission for the Protection of Human Subjects of Behavioral and Biomedical Research (Komisji do spraw Ochrony Ludzi Poddawanych Badaniom z Zakresu Nauk Społecznych i Biomedycznych). Po raz pierwszy sformułowano by wymagania badawcze o mocy prawa oraz poważnie ograniczono dostęp do pewnych populacji badanych, uznanych za niezdolnych do wyrażenia dobrowolnej, świadomej zgody na swe uczestnictwo w badaniach - takich jak małe dzieci, sieroty, więźniowie, osoby „słabe” umysłowo i inne.  Taka ustawa chroni prawa osób bezsilnych, przebywających w zakładach opiekuńczych, leczniczych bądź karnych. Jednakże bez uczestniczenia takich osób w badaniu nie można będzie odpowiedzieć na wiele istotnych pytań, dotyczących tego, w jaki sposób powinno się nimi opiekować, leczyć ich i kierować nimi.
Podobny spór toczy się nad tym, czy badanego trzeba informować o wszystkich aspektach badania, a nawet dawać mu prawo wyboru preferowanej procedury eksperymentalnej. Chociaż otwartość i uczciwość są warunkiem podjęcia badań, to jednak istnieją pewne problemy, których nie można byłoby badać bez czasowego zatajenia pewnych informacji - na przykład dotyczy to badań nad niepewnością, pobudzeniem o nieznanych badanemu przyczynach, podejmowaniem decyzji w warunkach stresu lub przy ograniczonej informacji oraz innych tematów. Ponadto, przyszło ci już niewątpliwie na myśl, że sama istota eksperymentowania zostanie zniszczona bez przestrzegania niezbędnego warunku, aby osoby badane przyporządkowywać |losowo do różnych procedur i do grup eksperymentalnych i kontrolnych. Jeśli osoby badane mają swobodę wybory procedury, której będą poddane, to nie jest możliwe ustalenie związków przyczynowych między zmiennymi niezależnymi i zależnymi, lecz jedynie ustalenie związków korelacyjnych. Wszystkie zmienne decydujące o tym, którą procedurę wybierze każda z osób, splotą się ze zmienną eksperymentalną, wpływając na wyniki w niemożliwy do ustalenia sposób.
Chociaż jednak dyskutuje się nad szczegółowymi wytycznymi, to nie ulega wątpliwości, że psychologowie uwrażliwili się na konieczność wyraźnego określenia kryteriów etycznych kierujących ich sposobem postępowania w sprawach zawodowych. Zainteresowania te odzwierciedla po części rosnący wpływ orientacji humanistycznej w psychologii, jak również większy nacisk na badania nad ludźmi niż nad zwierzętami oraz umacniające się przekonanie o możliwości wpływania na zachowanie za pomocą interwencji psychologicznych.
Istotą etycznego postępowania w psychologii jest odpowiedzialne przestrzeganie akceptowanych kulturowo norm humanitarnego traktowania osób badanych i pacjentów. Należy unikać wyrządzania przykrości, ryzyka wyrządzenia krzywdy (fizycznej, psychicznej czy społecznej), naruszenia sfery prywatności, obniżenia szacunku do siebie samego.




Badania a etyka




„Etyczne problemy badań psychologicznych nad istotami ludzkimi są nieodłącznie związane z działalnością badawczą. Wynikają one z samej natury badania naukowego, gdy dotyczy ono ludzi, a nie ze złych intencji badacza, czy też z jego niewrażliwości na wartości humanistyczne. Prawie każde badanie psychologiczne przeprowadzone z ludźmi pociąga za sobą konieczność dokonania wyboru dotyczącego względnych wag, jakie należy przypisać ideałom etycznym, konieczność wybrania pewnego szczególnego aspektu etycznego przed innymi. Z tego względu na są tacy, którzy zażądali, aby położyć kres całej działalności badawczej i tacy, którzy wznoszą bariery uniemożliwiające badania nad wieloma ważnymi zagadnieniami psychologicznymi. Decyzja, aby nie przeprowadzać badań jest jednak dla psychologów sama w sobie kwestią etyczną, ponieważ jednym z ich obowiązków jest wykorzystanie swych umiejętności badawczych do wzbogacania wiedzy, aby móc w zasadniczy sposób poprawić ludzki los (American Psychological Asscociation, 1973, s. 7)”.


Decyzja badacza, aby przystąpić do realizacji projektu badawczego, 
powinna opierać się na starannej ocenie: a) jego celów ogólnych i 
szczegółowych (badania podstawowe czy stosowane, mające na celu przyjęcie z 
pomocą określonej osobie lub grupie czy też mające ogólne znaczenie itd.), 
b) praw osoby badanej do prywatności, do wyboru alternatywnej procedury, do omówienia dalszego uczestnictwa w badaniu w dowolnym jego momencie, do uzyskania możliwie pełnej informacji o sprawdzanych hipotezach lub uzyskanych wynikach itd., c) odpowiedzialność badacza (wobec kogo badacz jest odpowiedzialny za przeprowadzenie badań, za poinformowanie o wynikach, za sposób załatwienia skargi itd.?) i wreszcie d) stosunku korzyści do szkód.

Ten ostatni punkt decyduje często o możliwości zaakceptowania danego badania. Czy korzyści wynikające z przerowadzenia badania przeważają nad szkodami, które może ono przynieść poszczególnym osobom biorącym w nim udział? Jeśli nie, to należy zrezygnować z badania. Jeśli korzyści przeważają, wówczas możliwość przeprowadzenia lub kontynuowania badań musi być oparta na racjonalnej analizie dostępnych informacji. Zgodnie z projektem opracowanym przez APA (Amerykańskie Towarzystwo Psychologiczne) badacz, aby uzyskać podstawę do podjęcia tego typu decyzji, powinien ocenić i wywarzyć trzy subiektywne parametry dotyczące szkód oraz te same trzy parametry dotyczące korzyści. Są to: |wielkość szkód i korzyści wchodzących w grę, |prawdopodobieństwo, że dana korzyść czy szkoda rzeczywiście wystąpią oraz |liczba ludzi, którzy poniosą szkodę lub odniosą korzyść” (American Psychological Asscociation, 1971, s. 10).
Jednakże nie istnieje ścisły rachunek, który by się nadawał do rozwiązywania takich równań; ostateczna decyzja jest ciągle decyzją osobistą, subiektywną. Jako taka podlega krytyce, jeśli bowiem badacz rzeczywiście wierzy w daną teorię lub w wynik pewnego sposobu postępowania i zainwestował w nie całe lata pracy, wysiłek, pieniądze i swą opinię, to jest bardzo prawdopodobne, że te zainwestowane wkłady przechylą jego ocenę stosunku korzyści do szkód w kierunku „prowadzić badania”. Ponadto w początkowych stadiach badania często niemożliwe jest ustalenie z góry, czy badanie to przyniesie jakiekolwiek rzeczywiste korzyści, czy też na dalszą metę spowoduje szkody. Aby zdjąć ciężar odpowiedzialności z ramion badacza i wyeliminować możliwość nadużyć prawie każdy uniwersytet, szpital czy instytut wymaga od badaczy, aby swoje propozycje badawcze przedkładali do oceny komisji specjalistów. Projekty ocenione jako wątpliwe etycznie lub naruszające przepisy ochronne wydane przez rząd, stowarzyszenie zawodowe (APA) lub instytucje lokalne muszą zostać odpowiednio zmodyfikowane lub zostają odrzucone. W sprawach w których trudno jasno określić stanowisko, projekt może uzyskać prowizoryczną aprobatę, z tym, że musi zostać poddany ponownej ocenie komisji po zebraniu ograniczonej liczby wstępnych danych, a następnie powinny być przeprowadzane okresowe oceny. Takie rozwiązanie jest lepsze od bewzględnej decyzji „prowadzić - nie prowadzić” w sytuacji, gdy brak stosownych danych, na których można by oprzeć taką decyzję.  Przeprowadzenie badań wbrew opinii komisji może mieć poważne skutki prawne i zawodowe dla badacza. Komisje takie służą dwóm celom - chronią prawa osób badanych, jednocześnie umożliwiając przerowadzenie badań nad ważnymi problemami psychologicznymi i społecznymi.




Zadawanie cierpień
i oszukiwanie a odkrycia




W poprzednich rozdziałach zauważyliśmy, że wiele badań psychologicznych miało umożliwić zrozumienie przyczyny patologii indywidualnej i społecznej, poznanie takich zjawisk, jak lęk, strach, zależność, agresja, posłuszeństwo itd. Lecz manipulacje eksperymentalne, które wytwarzają takie stany u osób badanych, powodują u nich, aczkolwiek jedynie chwilowe, cierpienia emocjonalne.
Czy ktokolwiek ma jednak prawo wyprowadzać inną osobę z rónowagi, nawet chwilowo, aby dowieść słuszność jakiegoś twierdzenia lub zweryfikować jakąś teorię? Gdy osoba badana doznaje jakiegoś niepowodzenia w eksperymencie, w którym manipuluje się w pewnym stopniu jej samooceną, to ta obniżona samoocena może utrzymywać się nadal (co wykazali Ross, Lepper i Hubard, 1975), nawet badacz wyprowadził z błędu osobę badaną, wyjaśniając jej, że niepowodzenie to zostało spowodowane w sposób arbitralny i w rzeczywistości nie zależało od sposobu wykonania zadania.
W niektórych eksperymentach chodzi i zbadanie reakcji na stres, a więc niezbędne jest w nich wywołanie reakcji charakterystycznych dla sytuacji stresu. W badaniach Lazarusa nad strategiami radzenia sobie ze stresem pokazywano badanym fragmenty z filmów, które najwyraźniej wywoływały silne pobudzenie fizjologiczne i afektywne, lecz uzyskane przez niego wyniki są pomocne w opracowywaniu technik pozwalających radzić sobie z nieuniknionym stresem w życiu codziennym.
Jak |ty oceniłbyś następujące dwa badania, gdybyś był w komisji do spraw etyki, która musi je zaaprobować lub odrzucić?


„W pierwszym z nich pacjenci-alkoholicy zgłaszali się na ochotnika na badanie, o którym sądzili, że było terapią przeciwalkoholową. Nie ostrzeżono ich z góry o działaniu środka, jaki im podawano, ponieważ badacz sądził, że ta informacja zredukowałaby traumatyczny wpływ tego przeżycia.  Rzeczywistym celem tego eksperymentu było zbadanie procesu wytwarzania się reakcji warunkowej w traumatycznej, choć nie związanej z bólem sytuacji.  Stosowany środek farmakologiczny zakłócał normalny proces oddychania, wytwarzając poważny stres psychologiczny, który, aczkolwiek nie wiązał się z bólem fizycznym, to jednak był tak przerażający, że „wszyscy badani stwierdzili, iż sądzili, że umierają” (Campbell, Sanderson i Lavertz, 1964, s. 631).
W drugim eksperymencie grupę rekrutów w armii stawiano w sytuacjach, które miały na celu zbadanie, jak zareagowaliby oni na zagrożenie swego życia. Aby uniknąć nierealistycznych, minimalnych zagrożeń stosowanych w badaniach laboratoryjnych nad stresem i aby studiować rzeczywiste reakcje na stresy o charakterze wojskowym, badanych umieszczano w samolocie, któremu na pozór groziło rozbicie albo pozostawiano ich w opustoszałym terenie, gdzie rzekomo działało promieniowanie jądrowe lub gdzie szalał pożar puszczy, lub na który omyłkowo skierowano ostrzał artylerii; gdy badany próbował wzywać pomocy przez radio, wówczas okazywało się, że nadajnik odmówił posłuszeństwa. „Jak on zareaguje?” - oto było pytanie badaczy” (Berkum, Bailek, Kern i Yagi, 1962).


„Jak |ty reagujesz na takie badania?” - oto nasze pytanie. Jak oceniasz szkody i korzyści wynikające z tych badań, które zrealizowano przed wprowadzeniem komisji do spraw etyki?
Wprowadzenie w błąd przyjmuje wiele różnych form w badaniach psychologicznych: od ukrywania prawdziwego celu badań jakiejś zasadniczej zmiennej, do fałszywego celu badań lub jakiejś zasadniczej zmiennej, do fałszywego informowania czy okłamywania badanych przy wyjaśnianiu pewnych zjawisk lub nawet przy zawieraniu „umowy” między eksperymentatorem a badanym. Przykładem tego ostatniego sposobu postępowania jest badanie Festingera i Carlsmitha (1959), w którym osoba badana uważała się za pomocnika eksperymentatora, a nie za badanego, w decydującej fazie eksperymentu, kiedy starała się przekonać prawdziwego pomocnika, udającego osobę badaną, że nudny eksperyment jest interesujący (za nagrodę od jednego do dwudziestu dolarów). Fałszywa informacja na temat natury pobudzenia odegrała zasadniczą rolę w badaniu Schachtera i Singera (1962) nad wpływem elementów poznawczych na charakter pobudzenia emocjonalnego (wywoływanego wstrzyknięcia adrenaliny). W badaniach Ascha (1955) nad konformizmem każdego badanego trzeba było przekonać, że grupa spostrzegała porównywane odcinki w odmienny niż on sposób, aby można było zbadać, w jaki sposób zostawała rozwiązana ta niezgodność. Nie przekazywanie pełnej informacji o eksperymencie może być niekiedy niezbędnym warunkiem badania pewnych zmiennych, ponieważ ich charakter zmieniłby się w zasadniczy sposób, gdyby osoba badana wiedziała o co chodzi.
Herbert Kelman z Harvard Unieversity od dawna wypowiada się na temat etyki badań nad ludźmi oraz wyraża się krytycznie o procedurach wymagających wprowadzenia w błąd. Stwierdza on: „Nazbyt często wprowadzanie w błąd stosuje się nie jako ostatni ratunek, lecz jako coś oczywistego.  Nasza postawa wydaje się być następująca: Jeśli można oszukać, to po co mówić prawdę? Właśnie ta bezkrytyczna akceptacja, to zrutynizowanie oszukiwania jest tym, co naprawdę mnie niepokoi” (1967, s. 3).
W niektórych eksperymentach fakt wprowadzenia w błąd i możliwe szkodliwe następstwa tego uchodzą uwagi nawet krytyków takiego sposobu podejścia, ponieważ rozkład akcentów w danym eksperymencie odwraca uwagę od innych faktów. W klasycznym badaniu nad rozwiązywaniem konfliktu międzygrupowego przez dzieci, dzięki wprowadzeniu celów nadrzędnych, Sherif i Sherif (1976) wprowadzali dzieci w błąd (i rodziców?) nie mówiąc im, że ich obóz letni był w rzeczywistości psychologicznym laboratorium na świeżym powietrzu i że manipulowano środowiskiem w celu wytworzenia konfliktu międzygrupowego. Gdy |ty czytałeś opis tego badania, to czy troszczyłeś się o fizyczne niebezpieczeństwa związane z wywołaniem konfliktu w warunkach obozowych bez odpowiedniego nadzoru, zwłaszcza w czasie wypadów nocnych, lub o to, że dzieci uczyły się ze swych „doświadczeń wojennych”, w jaki sposób być bardziej sprawnymi „wojownikami”?
Przeżycia, jakie były udziałem osób badanych w eksperymentach Milgrama nad posłuszeństwem, usprawiedliwiał on tym, że przeżycia te stanowiły „sposobność do dowiedzenia się czegoś ważnego o sobie samym i, bardziej ogólnie, o warunkach ludzkiego działania” (1964, s. 850). Argumentuje on zatem, że uczestnictwo w pewnego rodzaju badaniach pozwala biorącym w nich udział osobom dokonać jedynych w swoim rodzaju |odkryć. Istotnie, badania połączone z wprowadzeniem w błąd z samej swej natury stwarzają największe możliwości, jeśli chodzi o uzyskiwanie nowej wiedzy o sobie samym.  Uświadomienie sobie, że postępowało się tchórzliwie lub że było się ślepo posłusznym nieodpowiedzialnej osobie posiadającej władzę, może stanowić wartościowy „wgląd” który pomoże danej osobie uniknąć takich reakcji w realnym życiu - gdzie naprawdę mają one znaczenie. Jednakże dawanie takiej lekcji uczniowi, który ani nie prosił o nią, ani nie był przygotowany do jej zaakceptowania - i może nie mieć ochoty na ujawnianie swych braków czy słabości - wynika z wątpliwej jakości założeń czynionych przez eksperymentatora, który próbuje uzasadnić konieczność wprowadzania w badanych w błąd. W badaniach eksperymentalnych nad interwencją przypadkowych świadków (do których bodźca dostarczył fakt niereagowania obywateli na błagania Kitty Genovese), ci, którzy nie interweniowali, stają po badaniach wobec wiadomości, że wykazali brak odpowiedzialności społecznej, podczas gdy ci, którzy interweniowali, mogą być zażenowani swą „głupotą” ujawnioną przez „zbyt pochopne reagowanie” na zainscenizowany wypadek.
Jak na ironię, wiele tak zwanych eksperymentów naturalnych nad altruizmem poddaje się krytyce z powodu stosowanych w nich nieetycznych procedur.  Osoby, które nie zdają sobie sprawy z tego, że są badanymi w eksperymencie, znajdują zgubiony portfel lub list albo też widzą, jak ktoś daje pieniądze na cele dobroczynne lub pomaga naprawić przebitą dętkę. Sposób ich reagowania jest obserwowany i rejestrowany bez ich wiedzy. Jeśli potem wyjaśni się im ich rolę w eksperymencie, to mogą oni być |mniej skłonni do altruistycznego zachowania się w przyszłości, gdy nastąpi rzeczywisty wypadek lub powstanie jakaś potrzeba społeczna, ponieważ nie będą pewni, czy nie jest to po prostu jakiś inny oszukańczy eksperyment. Jeśli nie poda się im żadnych wyjaśnień, to oznacza, że brali udział w eksperymencie, bez swej zgody i bez żadnych osobistych korzyści z tego doświadczenia.
Są to trudne problemy, lecz podejmują je wszyscy ci, którzy chcą być pewni, że nie dokonujemy skażenia środowiska psychologicznego przez nieetyczne praktyki eksperymentalne, które mogą zaszczepić podejrzliwość, nieufność i cynizm w studentach pierwszych lat studiów i w innych osobach biorących udział w badaniach psychologicznych. Świadomość tego problemu i wrażliwość na liczne jego aspekty jest wstępnym warunkiem opracowania rozwiązań, które będą sprzyjać zarówno przeprowadzaniu wartościowych badań, jak i dobrym stosunkom międzyludzkim.




Terapia - interwencja
na żądanie




W badaniach nad psychoterapią ma się do czynienia ze wszystkimi powyższymi problemami, a ponadto z jeszcze innymi. Przekonaliśmy się w Rozdziale 12, że ocena efektywności psychoterapii wymaga losowego przyporządkowania do grup poddawanych leczeniu i do grup kontrolnych (nie poddawanych leczeniu) ludzi, którzy zgłaszają się na terapię ze względu na swe osobiste problemy. Niepoddanie ich terapii, która mogłaby być skuteczna, jest nieetycznym sposobem postępowania, ponieważ poświęca się potrzeby obecnego, pojedynczego pacjenta ze względu na interesy nieznanej większej liczby przyszłych pacjentów, którzy mogą odnieść korzyść z wyników badania. Ponadto, w takich badaniach nie informuje się pacjentów o możliwości wyboru różnych form terapii i próbuje się ich powstrzymać od zmiany terapeuty lub typu terapii, jeśli nawet nie odczuwają żadnej poprawy - i płacą za opiekę nad swym zdrowiem psychicznym. Jednym z rozwiązań tego problemu jest zapewnienie później każdemu członkowi grupy kontrolnej takiego rodzaju terapii, który okazał się najbardziej skuteczny.
Także podczas zwykłej terapii, gdy nie wchodzą w grę kontrolowane badania, występuje wiele problemów etycznych. O niektórych wspomnieliśmy w Rozdziale 12. W jakiej mierze pacjent uczestniczy w formułowaniu kontraktu terapeutycznego, który by wyraźnie definiował cele terapii, stosowane podejście, odmienne możliwości oraz prawo do krytykowania, do zakończenia terapii lub do szukania pomocy gdzie indziej? Wysoki status, jaki wszyscy lekarze posiadają w naszym społeczeństwie, stawia pacjentów w wyraźnie słabszej pozycji, tak że nie mogą oni odrzucić żadnego polecenia terapeuty.
Terapeuci pomagają ludziom, których zachowanie i doznania nie są zgodne z kulturowymi standardami „normalności”. Toteż terapeuci muszą bacznie uważać, czy nie są wykorzystywani przez społeczeństwo do utrzymania „status quo” przez przerabianie okrągłych kołków, które nie pasują do kwadratowych dziurek. Terapeuta Fred Spaner stwierdza, że przedstawiciele tego zawodu mają obowiązek pomagać w zmienianiu warunków społecznych, które powodują dysfunkcję, a nie jedynie zmieniać ludzi, u których wystąpiły zaburzenia funkcjonowania. „Jeśli nie uczestniczymy aktywnie w popieraniu korzystnych zmian społecznych, to uczestniczymy aktywnie w utrzymywaniu takiego systemu, jaki jest” (1970, s. 62). Siła tego nakazu staje się bardziej wyraźna, gdy psychologowie pracują dla instytucji (takiej, jak wojsko czy więzienie), gdzie celem terapii jest uczynienie człowieka „dobrym żołnierzem” lub „dobrym więźniem”. Gdy taki cel pozostaje w konflikcie z samorealizacją danej jednostki i wartościami osobistymi, to czy terapeuta kiedykolwiek zaleci bunt lub zmianę praktyki obowiązującej w danej instytucji, aby przystosować ją do człowieka, czy też przystosowanie jest zawsze „ulicą jednokierunkową?” Skrajności, do których może dojść terapia jako nieetyczna procedura służąca ograniczaniu ludzkiej swobody myślenia i działania, ujawniają na przykład niedawne sprawozdania o nadużywaniu psychiatrii do prześladowania przeciwników politycznych. Sama definicja zaburzeń zdrowia psychicznego bywa podawana w wątpliwość, gdyż przyjmuje się w niej, że wina za cierpienie ludzi i za sytuację, w jakiej się znajdują, obciąża jakieś ich defekty, a nie istniejące warunki. Badacze z Michigan, Nathan Caplan i Stephen Nelson, w swej bardzo prowokującej do myślenia analizie (1973) określają ten sposób podejścia jako ogólną tendencję panującą zarówno w psychologii, jak również w ustawodawstwie, systemie prawnym oraz w instytucjach wcielających prawo w życie - uważa się mianowicie „winę osobistą” za przyczynę większości problemów społecznych.  Jeśli but nie pasuje, to właściwym sposobem postępowania zdaje się być wykrycie, jakie wady ma noga!




Inżynieria społeczna
- interwencja
w społeczeństwie




Nie tylko badacze i terapeuci (oraz osoby przez nich badane i ich pacjenci) muszą interesować się etyczną stroną swych działań. Działalność ta występuje w naszym środowisku na stosunkowo niewielką skalę w porównaniu z szeroko rozpowszechnioną „inżynierią społeczną”, która istnieje na co dzień wszędzie tam, gdzie ludzie organizują warunki życia i pracy dla innych ludzi, często bez ich zgody czy choćby uczestnictwa w podejmowaniu decyzji. Przedsiębiorstwa handlowe i przemysłowe co roku wydają więcej na badania komercyjne, niż rząd federalny przeznacza na wszystkie badania z zakresu nauk społecznych (Meyer, 1974, s. 9). Dyrekcje przedsiębiorstw zatrudniają zwykle psychologów przemysłowych po to, aby zmniejszyć niezadowolenie pracowników, jednocześnie zwiększając produkcję, a zarazem i stopę zysku. Psychologowie wojskowi tworzą system propagandy i opracowują programy indoktrynacji. Wydawcy dzienników oraz dyrektorzy stacji radiowych i telewizyjnych decydują nie tylko o tym, co będzie nadawane jako „godne opublikowania”, lecz także o formie programów, jakie publiczność będzie zmuszona zaakceptować w danym sezonie.




Zbliżenie


Eksperymenty społeczne - za i przeciw


„Alice Rivlin, przewodnicząca Panel on Social Experimentation on The Brookings Institiution (Komisji do Spraw Eksperymentów Społecznych Instytutu Brookings) przeprowadziła analizę pewnych dylematów, z jakimi ma się do czynienia przy obecnym sposobie podejścia do eksperymentów społecznych. Należą tu:
1. |Dylematy |planowania, wynikające z konfliktu między chęcią uzyskania rzetelnych i wiarygodnych wyników, a potrzebą uzyskania tych wyników szybko i przy niskich kosztach.
2. |Dylematy |realizacji, powstające przy wprowadzaniu w życie danego programu. Czy powinno się nalegać, żeby trzymać się dokładnie pierwotnego projektu? Jeśli tak, to jak można ustalić, co się stanie, gdy program jest wcielany na wielką skalę przez ludzi, którzy nie trzymają się ściśle tego planu?
3. |Dylematy |oceny, które wiążą się z doborem osób oceniających. Z pewnością ci, którym program jest najlepiej znany, mają największe kwalifikacje do jego oceny. Czy jednak jest prawdopodobne, że będą oni najbardziej obiektywni?
4. |Dylematy |czasowe, wynikające z faktów, że politycy nie są skłonni przyznawać funduszy na badania, o ile nie trzeba właśnie podjąć jakiejś decyzji, ale wtedy mogą nie dać dość czasu na wykonanie solidnej roboty.
5. |Dylematy |moralne, które obejmują zagadnienia etyczne tego typu, o których pisaliśmy w tekście, jak również dbałość o nienaruszanie sfery prywatności uczestników, Rivlin dochodzi do wniosku, że „jeśli nie zatroszczymy się poważnie o to, aby prowadzone obecnie eksperymenty uczynić jak najbardziej użytecznymi i sensownymi, to może wystąpić reakcja przeciw eksperymentom w ogóle i potencjalnie użyteczne narzędzie może zostać stracone” (1974, s. 35).



Zmiany polityki społecznej, które wpływają na wielką liczbę ludzi, należałoby traktować jako manipulacje eksperymentalne, niezależnie od tego, czy są one ujęte w formalne schematy badawcze, czy też nie. Powinno się więc poddawać je takiej samej analizie uwzględniającej naruszenie zasad etycznych, jakiej obecnie wymaga się od badaczy i terapeutów.
Powinniśmy zapytać:
1. W jakim stopniu w podejmowaniu decyzji uczestniczą ludzie, których ma ona dotyczyć? Czy wyrazili oni zgodę na tę manipulację? 2. Jaka jest podstawa proponowanej manipulacji? Wiedza naukowa? Mądrość ludowa? Brutalna siła? 3. Jak będzie się mierzyć skutki decyzji? Czy rzeczywiście jej skutki zostaną ustalone i podane do publicznej wiadomości? 4. Jeśli dana manipulacja okaże się szkodliwa, to czy będzie możliwe naprawienie jej skutków, czy też nieodwracalnie zmieni ona ludzi nią dotkniętych lub ich sytuację życiową? 5. Jakie będą uboczne skutki tej manipulacji?

Na przykład, kontrola policyjna na lotniskach zdaje się zmniejszać liczbę wypadków porywania samolotów, lecz niewątpliwie skłania obywateli do akceptowania rewizji osobistych, ścisłych środków kontroli oraz do milczącego przyzwalania na jeszcze inne ograniczenia ich swobody poruszania się. Z perspektywy ekologicznej, jaką zarysowaliśmy poprzednio, nieoczekiwane, długoterminowe skutki mogą przynieść tyle szkody, że nie tylko zniwelują, lecz również przeważą efektowne, bezpośrednie korzyści płynące ze stosowanych operacji rewidowania i konfiskowania.
Lecz kto będzie działał w komitetach do spraw etyki jako cerber strzegący nienaruszalności najistotniejszych norm społecznych? Czy chciałbyś to czynić? A skąd wziąć siłę do zrealizowania sankcji przeciw winowajcom, skoro winowajcami tymi często są ci, którzy już mają w swych rękach największą władzę?


„Psycholog wierzy w godność i wartość jednostki ludzkiej. Jest on zobowiązany działać tak, by pomóc człowiekowi lepiej zrozumieć siebie samego i innych ludzi. Realizując to przedsięwzięcie chroni on dobro osoby, która poszukuje jego usług, oraz każdego badanego - człowieka czy zwierzęcia - który może być przedmiotem jego badań. Nie wykorzystuje on swej pozycji czy stosunków zawodowych do celów niezgodnych z tymi wartościami ani nie pozwala świadomie, aby jego usługi były wykorzystywane przez innych dla takich celów. Domagając się dla siebie swobody badań i przekazywania informacji, jednocześnie przyjmuje na siebie obowiązki związane z tą swobodą: obowiązek kompetencji przy zbieraniu głosu, obowiązek obiektywizmu w opisywaniu swych stwierdzeń oraz obowiązek uwzględniania najlepiej rozumianych interesów swych kolegów i społeczeństwa” (American Psychological Association, 1963, s. 1)”.




Psychologia na rzecz
lepszego życia




Gdy do tradycyjnych celów psychologii dodaliśmy „podnoszenie jakości życia”, wówczas wyszliśmy poza ściśle naukowe akademickie poszukiwanie wiedzy dla niej samej i wkroczyliśmy w królestwo działalności społecznej, gdzie wiedza jest narzędziem, instrumentem służącym dokonywaniu zmian.  pozorna prostota zdania „podnoszenie jakości życia” skłania prawie każdego do przytakiwania: „To brzmi pięknie”, „Oczywiście, dlaczegóż by nie?”, „To dobra myśl, kupuję”.
Wszyscy potencjalni reformatorzy, przywódcy grup religijnych czy politycznych lub choćby kawiarniani politycy opowiedzieliby się za tą brzmiącą wzniośle zasadą. Lecz czyż Hitler nie był przekonany, że do tego właśnie zmierza jego działalność, czy nie byli o tym przeświadczeni również „instalatorzy” z afery Watergate, a nawet mordercy z Mafii? „Czyje życie ulegnie poprawie, czyim kosztem i dla czyjego zysku?” - oto pytanie, jakie musimy stawiać.
W tej obecnej, optymistycznej erze psychologii, kiedy prezesi narodowego towarzystwa psychologicznego mówią o „oddaniu psychologii na służbę”, „o psychologii dla ludzi” oraz „o psychologii na rzecz przedsięwzięć ludzkich”, niektórzy bardziej konserwatywni naukowcy obawiają się pompatyczności takich planów oraz niebezpieczeństw związanych z przekształcaniem się psychologii w dyscyplinę służącą rozwiązywaniu problemów. Dla laika - a także dla naukowca jako obywatela - kojarzy się to także złowrogo z koncepcją |kontroli zachowania ludzkiego.
Można jednak wysunąć argument, że każde wspólne przedsięwzięcie obejmujące dwóch lub więcej ludzi wymaga kontroli nad zachowaniem. Nasze najpoważniejsze problemy wynikają z tego, co ludzie |robią, lub czego |nie |robią. Skażenie środowiska, wyczerpywanie się zasobów naturalnych, dyskryminacja, przemoc indywidualna i grupowa - wszystko to jest rezultatem ludzkiego działania lub braku działania. W tej sytuacji pytanie, dlaczego te zjawiska się zdarzają, i w jaki sposób można by to zmienić - są, przynajmniej w części, problemami psychologicznymi. Chociaż zdajemy sobie sprawę, że skuteczne metody kontroli zachowania mogą być nadużywane, to jednak jesteśmy również przekonani, że wysiłki zmierzające do rozwiązania problemów ludzkich (bez posiadania rzetelnej wiedzy o zachowaniu człowieka) mogą prowadzić do ogromnego marnotrawstwa wysiłków, fatalnych niepowodzeń, a zapewne także do stworzenia nowych, jeszcze poważniejszych problemów.




Zbliżenie


Jeśli zaprojektujesz miasto w kształcie pojemnika na śmieci, to co ludzie z nim poczną?


„Przy projektowaniu środowiska ludzkiego dąży się zwykle do realizacji dwóch bliźniaczych celów - projekt powinien być ekonomiczny i oszczędny.  Niekiedy przy planowaniu budynków, osiedli mieszkaniowych, centrów handlowych oraz innych trwałych elementów naszej przestrzeni życiowej bierze się także pod uwagę względy estetyczne, jednakże często planiści i architekci miejscy projektują pamiętając o |ludziach, a nie tylko o stali i cemencie, dolarach i centach?
Zaczynamy zdawać sobie sprawę z doniosłego wpływu, jaki środowisko fizyczne wywiera na nasze zachowanie, nastrój i sposób spostrzegania.  Sposób rozplanowania przestrzeni może pomóc ludziom w stworzeniu więzi między nimi lub w odizolowaniu ich od siebie. Typ okien w domu mieszkalnym może zachęcać mieszkańców do wyglądania na ulicę, dzięki czemu mają oni „oko na swych sąsiadów”, lub też, jeśli są to okna, które nie pozwalają na łatwe wyglądanie, mogą one zwrócić ludzi ku wnętrzu ich własnych mieszkań.
Od czasu, gdy psychologowie skierowali swą uwagę na „przemożny wpływ” zaplanowanych środowisk, na występujące w nich zachowania, powstają laboratoria „ekologii społecznej”, aby dopomagać w projektowaniu takich środowisk. Badacze, tacy jak Rudolf Moss (1973), studiują zachowanie w różnych środowiskach społecznych i próbują scharakteryzować „klimat” tych przestrzeni życiowych według wymiarów, które mają wyraźny wpływ na zachowanie jednostkowe i grupowe. Jesteśmy zatem świadkami nowego zainteresowania opisywaniem „osobowości” środowisk, podczas gdy poprzednio na środowiska nie zwracano szczególnej uwagi a różnic poszukiwano jedynie w ludziach.


Interakcja nauk społecznych i projektowania architektonicznego prowadzi także do nowych osiągnięć w zakresie „humanizacji środowiska wielkomiejskiego”. W pierwszej linii tego ruchu jest Lawrence Halprin, który projektuje fontanny, tereny rekreacyjne oraz inne miniśrodowiska miejskie przeznaczone dla ludzi. Jak stwierdził autor przeglądu jego prac poświęconych „architekturze dla ludzi”: „Jego teza - teza podstawowa - głosi, że realizowanie ustalonych zawczasu celów jest złym sposobem podejścia do projektowania czy czegokolwiek innego, ponieważ dążąc do określonego z góry rozwiązania często przeoczy się rzeczywiste problemy i możliwości. Mnóstwo pięknych budynków, całe nowe miasta okazały się fiaskiem, ponieważ były one estetycznymi plastrami przyłożonymi na bolące miejsca w środowisku; stwarzały one nowe problemy zamiast eliminować istniejące, gdyż wznoszono je, aby zrealizować ograniczone „idealne”” style życia, a nie potrzeby prawdziwych, żywych ludzi”.
To „nieukierunkowane na cel podejście” („nongoaloriented approach) Halprina rozwinęło się (w ten sam sposób, co większość innowacyjnych technik czy filozofii) dzięki wyodrębnieniu przez niego zjawiska, które było tak wrośnięte w tkankę społeczną, że uchodziło świadomości społecznej.


Halprin po prostu uświadomił sobie fakt, że ludzie będą |poruszać |się i |żyć w projektowanych przez niego miejscach - a nie tylko patrzeć na gotowe budowle i widoki. Jest on przekonany, że ludzi, którzy będą użytkownikami końcowego produktu, |trzeba |brać |pod |uwagę |w |procesie |wytwarzania |go” (Schoen 1972, ss. 14-15).
Naszym zamiarem w tym ostatnim podrozdziale „Psychologii i życia” jest wskazanie kilku pozytywnych przykładów wykorzystania psychologii w życiu dzieci, które to przykłady świadczą o jej przydatności w realizowaniu celu, jakim jest zapewnienie nam wszystkim lepszego życia.
Zasadniczym punktem zwrotnym w akcji rządu federalnego, przeciwdziałającego segregacji rasowej w szkołach, była decyzja Sądu Najwyższego z 1954 roku w sprawie „Brown przeciw wydziałowi oświaty w Topeka i innym” (347 U.S. 483). Przewodniczący Sądu Najwyższego, Waren, zacytował opinię sądu w Kansas stwierdzającą, że segregacja rasowa w szkołach ma szkodliwy wpływ na rozwój szkolny i umysłowy dzieci murzyńskich. Zgodnie z opinią Sądu wniosek ten znajdował mocne oparcie w opinii współczesnych autorytetów (s. 494). Ich ekspertyza składała się z szeregu analiz dotyczących wpływu uprzedzeń na rozwój osobowości (autor Kenneth Clark) oraz psychologicznych skutków przymusowej segregacji (autor Isidor Chein), a także z danych i opinii zebranych do innych psychologów i socjologów.
Znacznie później inni badacze pracowali nad sposobami sprzyjającymi dobrowolnej integracji rasowej (Hauserman, Walen i Behling, 1973).  Posługując się namową, nagrodami i innymi indywidualnie dobranymi metodami zachęcano dzieci z pierwszej klasy do zawierania „nowych przyjaźni”, do rozszerzenia kręgu przyjaciół i przekraczania usankcjonowanych kulturowo barier rasowych między czarnymi i białymi dziećmi.
Nauczanie wspomagane przez komputer (CAI - „Computer-Assisted Instruction”) ułatwia dzieciom naukę czytania w szkołach Florydy, Oklahomy, Teksasu i Waszyngtonie. Każde dziecko spędza codziennie 10 do 15 minut przy dalekopisie, mając na głowie słuchawki, przez które przekazywane są informacje. Komputer przedstawia (na ekranie telewizyjnym) słowa, które należy przeczytać, rozpoznać i napisać, oraz dostarcza dziecku natychmiastowego sprzężenia zwrotnego. Przechowuje on kompletną historię interakcji dziecka z materiałem nauczania i stale uaktualnia swe zestawienia, dotyczące tych części materiału, które sprawiają dziecku trudności. Każde dziecko uczy się więc czytać według materiału specjalnie przystosowanego do jego indywidualnych potrzeb i postępów. Przeprowadzone badania oceniające wykazały efektywność tego programu. Uczniowie pierwszej klasy biorący udział w CAI, wyprzedzali przeciętnie o 5,05 miesiąca grupę kontrolną złożoną z pierwszoklasistów nie uczestniczących w tym programie, gdy przebadano ich pod koniec pierwszego roku nauki; sprawdzian przeprowadzony rok później wykazał, że korzyści były trwałe, gdyż uczniowie uczestniczący w CAI wyprzedzali uczniów z grupy kontrolnej o 49 miesiąca (w drugim roku nie prowadzono CAI). Chłopcy w tym wieku czytają na ogół gorzej niż dziewczęta. CAI pomaga im poczynić większe postępy niż dziewczętom, przezwyciężając w ten sposób tę ogólnie znaną różnicę związaną z płcią.
W badaniach tych, przeprowadzonych przez Richarda Atkinsona (1974), zaprezentowano technikę opartą na teorii nauczania oraz na modelach rozwoju poznawczego i przetwarzania informacji, jak również na postępach w dziedzinie symulacji komputerowej i programowania. Jest ona wynikiem prowadzonych przez wiele lat badań laboratoryjnych nad procesami pamięciowymi, uwagą oraz wykrywaniem cech i układów bodźcowych.
Odmienny rodzaj środowiska uczenia się stworzono dla młodocianych, którzy popadli w konflikt z prawem z powodu dopuszczenia się przestępstw. W jednym z ośrodków reedukacyjnych w Waszyngtonie Harold Cohen zaprojektował kompletne środowisko dla młodocianych przestępców (chłopców) w wieku od 13 do 21 lat (niektórzy z nich byli oskarżeni o morderstwo). W ciągu sześciu mięsięcy 90% tych chłopców poczyniło postępy w nauce odpowiadające czterem klasom, przynajmniej w jednym z przedmiotów szkolnych. W ciągu jednego roku wystąpiły radykalne zmiany nie tylko w osiąganych przez nich wynikach nauki, lecz także w zakresie zachowania interpersonalnego oraz w poziomie umiejętności niezbędnych dla osiągnięcia powodzenia w społeczeństwie (o czym świadczy niski wskaźnik recydywizmu w następnym roku po ich zwolnieniu).
W zastosowanej technice najpierw starannie analizowano, w jaki sposób trzeba zaprojektować środowisko fizyczne, aby skłaniało do uczenia się, współpracy i pozytywnych interakcji społecznych, a nie do agresji i rywalizacji. Następnie ustalono kryteria wykonania określonych zadań i rozkłady wzmocnień (wypłat), których później ściśle przestrzegano. Z czasem na miejsce systemu bezpośrednich, konkretnych nagród wprowadzono opóźnionągratyfikację i symboliczne czynniki wzmacniające. Doznanie sukcesów w nauce, poczucie kompetencji oraz poczucie osobistego rozwoju i dokonań przyczyniły się do wytwarzania się u tych chłopców szacunku do samych siebie, godności własnej oraz zdolności do dawania i przyjmowania miłości i uczucia (Cohen i Filipczak, 1971).
Musimy uczyć się kształtować struktury wzmocnień warunkowych sprzyjające takim zachowaniom, naszym i naszych dzieci, które pomogą stworzyć społeczeństwo zapewniając każdej jednostce optymalne warunki swobodnego rozwoju oraz pełną realizację jej możliwości.


Większość dzieci nie ma tak poważnych problemów jak młodociani w badaniach Cohena i obecnie niewiele instytucji jest tak wyposażonych, aby mogły zapewnić tego rodzaju środowisko, jakie zorganizował Cohen, lecz można ćwiczyć dzieci w tym, aby pomagały swoim rówieśnikom uczyć się poprawnego zachowania (w sposób analogiczny do kontroli społecznej, jaką zwykle sprawują dorośli nad sobą nawzajem i nad dziećmi).


„Solomon i Wheeler (1972) wybrali z pewnej szóstej klasy, liczącej trzydziestu uczniów, pięcioro dzieci „trudnych” i pięcioro dzieci współpracujących i popularnych wśród swych kolegów. Obserwacja wykazała, że w normalnych warunkach inne dzieci zwracały uwagę na dzieci „trudne” i dostarczały im społecznego wzmocnienia tylko wtedy, gdy przejawiały one niepożądane zachowania. Następnie dzieci współpracujące ćwiczono w zwracaniu uwagi na zachowanie, które dorośli uznają za pożądane i w nagradzaniu ich; potem obok każdego dziecka „trudnego” posadzono dziecko współpracujące. Dzieci współpracujące ignorowały niepożądane zachowania, co spowodowało, że dzieci „trudne” zaczęły wkrótce przejawiać ich znacznie mniej, a znacznie więcej - zachowań prospołecznych. Jest interesujące, że dzieci współpracujące nie wzmacniały zachowań pożądanych lub czyniły to w taki sposób, że dorośli obserwatorzy nie zauważyli tego. Niemniej jednak częstość niepożądanych zachowań została zredukowana - po prostu wskutek tego, że koledzy nie zwracali na nie uwagi. Prawdopodobnie to właśnie umożliwiło występowanie bardziej pozytywnych reakcji, które były wzmocnione przez nauczyciela lub rzez niewystąpienie oczekiwanego negatywnego wzmocnienia”.


Badanie to jest ważne, gdyż wskazuje, że w naturalnych warunkach uczniowie dostarczają swym „trudnym” rówieśnikom wzmocnienia jedynie za złe zachowanie, i że „niepożądane” zachowanie jest bardzo podatne na wpływ rówieśników. Jeśli skłonnych do współdziałania uczniów można wyćwiczyć tak, aby regularnie oddziaływali na swych „trudnych” rówieśników, to niepożądane zachowanie można by eliminować nawet w takich sytuacjach, w których oddziaływanie ze strony dorosłych byłoby trudne lub niemożliwe.
Dzieci uważa się za jedną z najbardziej upośledzonych i bezradnych grup w społeczeństwie - ani się ich nie słucha, ani nie rozumie (zob. „Harvard Educational Review”, 1973, 1974 - numery specjalne poświęcone prawom dzieci). Dotychczasowe badania, a także szkolne nauczycieli, nazbyt często zmierzają do opracowania technik umożliwiających dorosłym uzyskanie jeszcze większej władzy nad dziećmi, które są „źródłem kłopotów”. W pewnym badaniu odwrócono tę sytuację i uczono dzieci stosowania technik oddziaływania na nauczycieli i kształtowania ich zachowania (Gray, Graubard i Rosenberg, 1974). W badaniach tych, zatytułowanych „Little Brother is Changing You” (Mały Braciszek Zmienia Ciebie) „trudne” dzieci z małego miasteczka Visalia, położonego w wiejskim okręgu stanu Kalifornia, uczono kształtować zachowanie ich nauczycieli. Uczono je rejestrować dane dotyczące zadawalających bądź niezadowalających interakcji oraz rozpoznawać, które z ich własnych zachowań są nagradzające bądź nienagradzające dla nauczycieli.  Aby kształtować zachowanie nauczycieli w taki sposób, by interakcje z nimi były przyjemne i by udzielali oni pomocy, dzieci musiały dostarczać nauczycielom wzmocnienia społecznego, gdy wykonywali oni pożądaną reakcję.  Nauczyciele określali uczniów jako zachowujących się dobrze, gdy dostarczali oni takiego wzmocnienia i w ten sposób stosunki między nauczycielami i uczniami polepszały się. Dzieci te uczono też takiego kształtowania zachowań ich rodziców, by byli oni lepszymi opiekunami i lepiej zajmowali się domem oraz kształtowania zachowań kolegów tak, aby interakcje z nimi były przyjemniejsze. Piękno tej metody polega na tym, że ci, którzy chcą sprawować kontrolę nad innymi, muszą dostarczać swym „klientom” tego, czego tamci sobie życzą, aby nagradzać zachowania, jakich oni sami pragną.
Psychologów coraz częściej powołuje się jako ekspertów, aby ich wiedzę i sposób ujmowania przez nich problemów spożytkować przy podejmowaniu decyzji - dotyczących kwestii prawnych, społecznych i politycznych. Znajomość mechanizmów zachowania, subtelnych źródeł motywacji, wpływu czynników sytuacyjnych na zachowanie, źródeł subiektywnej stronniczości - oto tylko niektóre przykłady umiejętności psychologa, które może on wnieść jako swój wkład do rozwiązywania wspomnianych wyżej problemów (zob. Brodsky, 1973).
Jest zaskakujące, że badania Zimbarda i jego współpracowników nad symulowanym więzieniem, opisane w Rozdziale 13, okazały się jedynym dostępnym materiałem dowodowym, gdy podkomisja Senatu analizowała skutki przetrzymywania młodocianych w areszcie przed rozprawą sądową. Badanie to było jednym, które dotyczyło młodocianych osób aresztowanych przez policję, wciąganych do kartotek i trzymanych w areszcie przed przesłuchaniem przez sąd. Senator Birch Bayh, przewodniczący tej podkomisji, przedstawił następnie projekt ustawy mającej doprowadzić do zmiany (humanizacji) sposobu traktowania młodocianych osób podejrzanych o dokonanie przestępstw kryminalnych. Stwierdził on, że ten materiał badawczy w istotny sposób wpłynął na jego poglądy na ten temat.




Zbliżenie


Psychologowie jako eksperci


„Stosunkowo niedawno sześciu więźniów przebywających w więzieniu San Quentin wniosło sprawę cywilną przeciw systemowi więziennemu stanu Kalifornia, wysuwając zarzut, że długotrwałe przebywanie w odosobnieniu, w tym ośrodku „maksymalnego przystosowania”, stanowi okrutną i niezwykłą karę. Mężczyźni ci, „Szóstka z San Quentin”, przebywali w swych izolatkach przeszło trzy lata, będąc oskarżeni o zabójstwo strażników w czasie ucieczki Georga Jacksona 21 sierpnia 1971 roku. Aczkolwiek oskarżenie to zostało obalone, to jednak władze stanowe nadal trzymały tych ludzi w izolatkach, dopóki ich apelacja nie została rozpatrzona. Szóstka z San Quentin stwierdziła, że byli oni brutalnie traktowani przez strażników i dehumanizowani przez tę sytuację; administracja więzienna zaprzeczała tym oskarżeniom. Komu sąd miał dać wiarę?


Ze względu na to, że wiedza uzyskana w wyniku eksperymentu z symulowanym więzieniem w Stanford mogła mieć tu zastosowanie, zaproszono Zimbarda, aby pełnił rolę eksperta w sprawie tego powództwa. Obserwował on warunki życia więźniów, rozmawiał z każdym z nich, jak również z byłymi strażnikami, a także dokonał przeglądu literatury psychologicznej na ten temat. Analogie z różnymi elementami badań nad symulowanym więzieniem były pod wieloma względami bardzo duże. Wszystkie obserwacje i wnioski przedstawiono sędziemu federalnemu Zirpoli jako część materiału dowodowego, na podstawie którego miał on podjąć decyzję w tej sprawie.
W swej opinii wydanej 15 grudnia 1975 roku, sędzia Zirpoli stwierdził: 
„Jest oczywiste, iż długotrwałe więzienie powodów („Szóstki z San Quentin”) w odosobnieniu na pierwszej kondygnacji Ośrodka Przystosowania nie tylko nie sprzyja ich pozytywnym przemianom i rehabilitacji, lecz jest do tego stopnia destruktywne, że wzbudza w nich większe poczucie alienacji i głębszą nienawiść wobec społeczeństwa, które początkowo słusznie ich tam umieściło” (s. 20) (...)” Eksperci w dziedzinie psychiatrii i psychologii orzekli, że warunki w Ośrodku Przystosowania zagrażają zdrowiu psychicznemu powodów i dehumanizują ich w stopniu, który można będzie w pełni ocenić dopiero po ich zwolnieniu” (s. 6). W konkluzji sędzia Zirpoli orzekł, że takie długotrwałe odosobnienie „stanowi okrutną i niezwykłą karę, będącą pogwałceniem Ósmej i Czternastej Poprawki do Konstytucji Stanów Zjednoczonych” (s. 21).


Istnieje oczywiście mnóstwo innych przykładów, które moglibyśmy przytoczyć, a które świadczą o możliwościach wykorzystania psychologii dla dobra ludzi i społeczeństwa - od nowych metod obniżania zbyt wysokiego ciśnienia krwi do projektów badawczych z zakresu walki z zaśmiecaniem otoczenia oraz do szkolenia obywateli w zapobieganiu przestępczości przez odtwarzanie więzi społecznych. Niektórzy psychologowie pracują nad podniesieniem poziomu moralnego strażników więziennych i więźniów, podczas gdy inni badają elementy, które składają się na te doznania, jakie przede wszystkim należałoby zapewnić dzieciom w tworzonych obecnie ośrodkach opieki nad dzieckiem (najpoważniejszy eksperyment społeczny lat siedemdziesiątych). Niektórzy próbują odkryć sposoby przezwyciężania poczucia nieśmiałości i osamotnienia, podczas gdy ich koledzy starają się ustalić, co jest podstawą trwałego zaangażowania i więzi uczuciowych. Jest to psychologia całkiem odmienna od tej, o jakiej myślał Wilhelm Wundt w swym małym, lecz pełnym przyrządów laboratorium w Lipsku przed stu laty.  Jesteśmy obecnie świadkami ciekawego łączenia się naukowego poszukiwania wiedzy, odkrywania prawidłowości i porządku zjawisk z humanistycznym dążeniem do zrozumienia i akceptacji innych ludzi oraz osiągnięcia osobistego spełnienia. Nie ma żadnych powodów, aby nowoczesna psychologia nie mogła zrealizować obu tych celów. Jednakże byłoby dobrze, aby zarówno psychologowie jak i studenci psychologii, zanim wyruszą, aby nakładać bandaże na rany świata, mieli w pamięci mądre słowa sędziego Davida Bazelona (1972). Zadał on następujące pytanie grupie psychologów pracujących w dziedzinie resocjalizacji:


„Dlaczego mielibyśmy się w ogóle zastanawiać nad zasadniczymi zmianami społecznymi lub całościową redystrybucją dochodów, jeśli całym problem można rozwiązać polecając naukowcom, by nauczyli klasę przestępczą - niby grupę szczurów laboratoryjnych - jak przejść z powodzeniem przez labirynt naszego społeczeństwa? Krótko mówiąc, zanim odpowiecie z entuzjazmem na nasze apele o pomoc, musicie zadać sobie samym pytanie, czy wasza pomoc jest naprawdę potrzebna, czy też jesteście angażowani jedynie jako magicy do wykonywania intrygującego pokazu gdzieś na uboczu, aby widzowie nie zwrócili uwagi na decydujące wydarzenia zachodzące na głównej arenie.  Sądzę, że zastanawiając się nad motywami, które leżą u podstaw zaoferowania wam jakiejś roli, zrobilibyście dobrze biorąc pod uwagę to, że znacznie mniej kosztowne jest zatrudnienie tysiąca psychologów, niż wprowadzenie choćby niewielkiej zmiany w strukturze społecznej i ekonomicznej” (s. 6).


Kończąc nasze wprowadzenie do psychologii pragniemy wyrazić nadzieję, że uznasz, iż jest to dla ciebie początek czegoś, a nie jedynie koniec kursu.


„Każde wyjście jest wejściem gdzie indziej”.
Tom Stoppard „Rosencrantz and Guildenstern Are Dead”, 1967


Mamy nadzieję, że to „gdzie indziej” będzie dla ciebie interesującym miejscem pobytu.




Dodatek.
Podstawowe pojęcia statystyki




Statystyka dostarcza nam metod prezentowania i oceniania wyników badań psychologicznych. Podobnie jak student wydziału zarządzania musi nauczyć się księgowości, aby zrozumieć w pełni znaczenie liczb obrazujących wielkość sprzedaży i zysku, tak psycholog musi posługiwać się metodami i wzorami statystycznymi, aby móc wyprowadzać z obserwacji trafne uogólnienia dotyczące zachowania ludzkiego i procesów psychicznych. Chociaż metody te na pierwszy rzut oka mogą wydawać się skomplikowane, to jednak w rzeczywistości umożliwiają one zredukowanie wielkiej liczby danych do takiej postaci, którą umysł jest w stanie objąć.
Psychologowie, podobnie jak inni naukowcy poświęcają wiele czasu na dokonywanie obserwacji.
Obserwacje te są surowcem, na którym pracują. Po dokonaniu wielu obserwacji starają się zintegrować je w ramach pewnej teorii lub wykorzystać je do znalezienia rozwiązania określonego problemu czy też odpowiedzi na pewne pytanie. Wymaga to zazwyczaj stosowania różnych procedur statystycznych. Pierwszy krok polega na przedstawieniu obserwacji w postaci liczbowej, tak aby można było poddawać je operacjom statystycznym. Dokonuje się tego za pomocą |psychologicznych |technik |pomiarowych, które oparte są na jednej z opisanych poniżej skal pomiarowych.
Gdy obserwacjom psychologa nada się już postać liczbową, wówczas, można ich użyć do dwóch zasadniczych celów: opisu i wnioskowania. |Statystyka |opisowa pozwala nam w ekonomiczny i dogodny sposób opisywać, organizować i integrować zbiory danych pochodzących z obserwacji grup. Statystyka opisowa pozwala nam na przykład określić, jak inteligenta jest dana grupa studentów pierwszego roku (jako grupa) i czy reprezentują oni wszyscy mniej więcej ten sam poziom inteligencji, czy też różnią się znacznie między sobą.  Statystyka opisowa pozwala nam także porównywać wyniki uzyskane przez nich w dwóch lub więcej testach. |Wnioskowanie |statystyczne pozwala nam |wywnioskować, jak typowe są ich wyniki dla studentów pierwszego roku w ogóle i jak wiele zaufania możemy mieć do poszczególnych wniosków, które możemy wyciągnąć w odniesieniu do ogółu studentów pierwszego roku.




Pomiar psychologiczny




Pomiar w psychologii, podobnie jak w innych dziedzinach, można zdefiniować jako przyporządkowanie liczb, zgodnie z pewnymi zasadami, osobom, przedmiotom lub zdarzeniom. Psychologowie posługują się czterema różnymi rodzajami |skal |pomiarowych (Więcej danych na temat rodzajów skal pomiarowych i ich zastosowania w psychologii znajdzie Czytelnik w następujących pracach: T. Szustrowa „Skale ocen jako narzędzie pomiaru osobowości, w: E. Pankiewicz (red.) „Materiały pomocnicze do ćwiczeń z metod badania osobowości”. Warszawa 1977, Wyd. U. W.; J. Brzeziński „Elementy metodologii badań psychologicznych”. Warszawa 1980, P W N (przy.  red. nauk.)). Są to skale: |nominalna, |porządkowa, |przedziałowa i |ilorazowa. Każda z tych skal ma pewne charakterystyczne cechy, które poniżej opiszemy.




Skale nominalne




Skala nominalna jest najniższym poziomem pomiaru, to jest takim poziomem pomiaru, który dostarcza najmniej informacji. Liczby stosuje się tu tylko dla odróżnienia jednej osoby lub grupy od innej. Przykłady zastosowania skal nominalnych to numery na koszulkach piłkarzy, numery telefoniczne lub ponumerowanie okręgów wyborczych. Liczby te nie reprezentują |ilości czegokolwiek, ani też wysoki numer nie oznacza, że czegoś jest więcej niż wtedy, gdy numer jest niski. Liczby te jedynie odróżniają daną jednostkę lub kategorię od innych. Można by wysunąć wątpliwość, czy jest to w ogóle pomiar, lecz odpowiada on definicji: „przyporządkowanie liczb osobom, przedmiotom lub zdarzeniom zgodnie z pewnymi zasadami”.
Istotą pomiaru na skali nominalnej jest |klasyfikacja |jakościowa.  Moglibyśmy klasyfikować zarejestrowanych wyborców przyporządkowując im numer okręgu wyborczego, w którym mieszkają. Ponieważ w tym samym okręgu wyborczym mieszka wiele osób, zatem każdy numer przyporządkowalibyśmy więcej niż jednej osobie. W niektórych zastosowaniach pomiaru nominalnego, takich jak ponumerowanie piłkarzy, w każdej klasie jest tylko jedna osoba.  Chociaż dana kategoria może obejmować więcej niż jedną osobę, to jednak żadna osoba nie może być zaliczona do więcej niż jednej kategorii. Dany wyborca nie może być zarejestrowany w dwóch okręgach wyborczych, ani też piłkarz nie może mieć dwóch numerów. W wypadku pomiaru nominalnego osoby, przedmioty czy zdarzenia są zatem zaliczane do |wykluczających |się |wzajemnie kategorii.




Skale porządkowe




Pomiar na skali porządkowej nie tylko odróżnia daną osobę od pozostałych, lecz także mówi nam, czy dana osoba posiada mierzoną cechę w większym, czy też mniejszym stopniu niż inne osoby w tej samej grupie. Przykładem skali porządkowej może być kolejność, w jakiej biegacze mijają linię mety.  Biegacz, który finiszuje jako pierwszy, jest szybszy niż biegacz, który ukończył bieg jako drugi, a ten zaś z kolei jest szybszy niż biegacz zajmujący trzecie miejsce i tak dalej. Rejestrując kolejność, w jakiej biegacze mijają linię mety, mierzymy ich szybkość na skali porządkowej.
Pomiar porządkowy nie daje jednak żadnych informacji co do wielkości różnic między dwoma osobami pod względem mierzonej cechy. Chociaż zatem wiemy, że biegacz, który zajął pierwsze miejsce jest szybszy od biegacza, który ukończył bieg na drugim miejscu, to jednak nie wiemy, o ile jest od niego szybszy. Nie wiemy także, czy różnica szybkości między pierwszym i drugim biegaczem jest taka sama, jak między biegaczami, którzy ukończyli bieg na miejscu trzecim i czwartym. Psychologowie stosują dość często pomiar porządkowy, ponieważ cechy psychiczne nierzadko trudno jest mierzyć na skali ilościowej.




Skale przedziałowe




Skala przedziałowa (zwana także interwałową) posiada wszystkie właściwości skal nominalnych i porządkowych, a ponadto tę, iż ma równe jednostki. Oznacza to, że jednakowe różnice wyników reprezentują równej wielkości różnice tej cechy, którą mierzymy. Przykładem skali przedziałowej jest skala temperatury, taka, jaka znajduje się na termometrze. Różnica temperatury między 99 a 100 stopniem skali 100-stopniowej (Celcjusza) jest taka sama, jak różnica między 49 i 50 stopniem lub jakakolwiek inna różnica wynosząca jeden stopień. Innymi słowy, |przedziały są równe na całej skali.  Mierząc temperaturę na skali |przedziałowej wiemy nie tylko to, że jeden przedmiot jest cieplejszy lub zimniejszy od drugiego, lecz wiemy także, |o |ile jest on cieplejszy lub zimniejszy.
Pomiar na skali przedziałowej nie daje nam jednak informacji o stosunku tych dwóch przedmiotów pod względem mierzonej cechy. Niepoprawne byłoby zatem twierdzenie, że przedmiot, którego temperatura wynosi 50 st. C jest dwa razy cieplejszy od przedmiotu o temperaturze 25??? C. Twierdzenie to byłoby poprawne, gdyby 0 st. C było zerem bewzględnym, to jest gdyby przedmiot o temperaturze 0 st. C nie miał w ogóle żadnej ciepłoty. W rzeczywistości jednak, zero bewzględne odpowiada temperaturze -273 st. C.  Ciepłota przedmiotu równa 25 st. C jest więc w rzeczywistości o 298 stopni wyższa od zera bewzględnego, ciepłota zaś przedmiotu równa 50 st. C jest o 323 stopnie wyższa od zera bewzględnego. Jest zatem oczywiste, że drugi przedmiot nie jest dwa razy cieplejszy od pierwszego.




Skale ilorazowe




Skala ilorazowa stanowi najwyższy poziom pomiaru. Skala ta posiada wszelkie właściwości wymienionych poprzednio skal, a w dodatku tę właściwość, że jej początkiem jest zero bewzględne.
Jest to skala, na której dokonuje się najczęściej spotykanych fizycznych pomiarów długości czasu i ciężaru. Ponieważ skala ta ma zero bewzględne, mają zatem sens stwierdzenia dotyczące stosunków: odcinek o długości sześciu centymetrów jest dwa razy dłuższy od odcinka o długości trzech centymetrów, przedmiot o wadze 10 kilogramów jest pięć razy cięższy od przedmiotu ważącego dwa kilogramy itd.
Psychologowie nie wiedzą zwykle, gdzie znajduje się punkt odpowiadający „zeru bezwzględnemu” w stosowanych przez nich narzędziach pomiarowych i dlatego muszą być ostrożni przy porównywaniu procentów i innych proporcji.  Na przykład, jeśli Mary ma iloraz inteligencji równy 100, Suzan zaś ma iloraz inteligencji równy 110, to nie możemy powiedzieć, że Suzan jest o 10% inteligentniejsza od Mary. Istnieją jednak w pomiarach psychologicznych rzadkie przypadki, w których takie stwierdzenia są możliwe.
Właściwości omówionych powyżej skal pomiarowych można przedstawić w skrócie jak następuje:




* * *



Właściwości: Skala (nominalna, porządkowa, przedziałowa, stosunkowa)
Klasyfikacja: x x x x
Porządek: - x x x
Równe jednostki: - - x x
Zero bewzględne: - - - x


* * *





Jak wynika z tabeli, każdy z tych poziomów pomiaru posiada wszystkie właściwości poziomów niższych, a także pewną właściwość dodatkową. Im wyższy poziom pomiaru, tym więcej uzyskuje się informacji o mierzonej cesze. Z tego właśnie powodu psychologowie, podobnie jak inni naukowcy, starają się używać najwyższego możliwego w danej sytuacji poziomu pomiaru.

Posługiwanie się statystykami opisowymi

Gdy dane zostały już zebrane przy użyciu pomiaru psychologicznego, wówczas stosuje się statystyki opisowe w celu przedstawienia tych danych w zwięzłej postaci, tak żeby można było wyciągnąć wnioski. Statystyka opisowa jest pojedynczą liczbą, która reprezentuje wiele pomiarów zebranych w danej grupie. W badaniach psychologicznych stosuje się bardzo wiele różnych statystyk. Wybór statystyki będzie zależał zarówno od zastosowanej skali pomiarowej, jak i od tego, jakiej informacji potrzebujemy.
Ponieważ różne statystyki wymagają różnych operacji liczbowych, przeto trzeba uwzględniać poziom pomiaru przy podejmowaniu decyzji, jakiej statystyki użyć. Im wyższy poziom pomiaru, tym więcej operacji liczbowych jest możliwych. Wiemy już, że pomiar na skali nominalnej umożliwia jedynie klasyfikację. Liczby, które reprezentują różne kategorie, są jedynie etykietkami, czyli oznaczeniami poszczególnych kategorii; nie wyrażają one ilości. Byłoby zatem bezsensowne, lub nawet mylące, dodawanie ich, odejmowanie lub wykonywanie jakichkolwiek innych operacji liczbowych. Dane na skalach ilorazowych można natomiast dodawać, odejmować, mnożyć i dzielić.
Jeszcze ważniejszą sprawą przy wybieraniu statystyki jest oczywiście to, jakiej informacji potrzebujemy. Oto trzy rodzaje informacji najczęściej potrzebne w badaniach psychologicznych: a) jaki jest przeciętny, czyli najbardziej reprezentatywny wynik (wartość centralna), b) jak bardzo inne wyniki różnią się od wyniku przeciętnego (zmienność) oraz c) jaki jest wzajemny związek między dwoma lub więcej zmiennymi reprezentowanymi przez różne zbiory wyników?

Miary wartości centralnej

Przypuśćmy, że jacyś psychologowie badają cechy różnych grup religijnych.  Najpierw musieliby oni poklasyfikować osoby badane według wyznania. Jako narzędzie pomiarowe mogliby zastosować kwestionariusz, w którym prosiliby każdą osobę o podanie swego wyznania. Gdyby udało się im zaliczyć każdego badanego do jednej i tylko jednej kategorii z listy zawierającej wyliczenie różnych wyznań, to „zmierzyliby” wyznanie osób badanych na skali nominalnej. Przypuśćmy, że chcą oni teraz opisać zbadaną próbkę, określając wyznanie „przeciętnej” osoby badanej. Jest kilka statystyk, które pozwalają określić przeciętny pomiar w grupie, lecz ponieważ posłużyli się oni jedynie pomiarem nominalnym, to muszą skorzystać z takiej statystyki wartości centralnej, którą można zastosować w przypadku skali nominalnej.  Statystyką taką jest |modalna.

Modalna. Modalną w grupie pomiarów nominalnych jest kategoria o największej liczbie elementów. Na przykład w tabeli zamieszczonej poniżej modalną są protestanci, ponieważ w grupie tej więcej osób badanych podaje, że wyznaje protestantyzm niż jakąkolwiek inną religię.

Religia - Liczba badanych
1. Protestanci - 88 (modalna)
2. Katolicy - 37
3. Żydzi - 17
4. Inni - 5

Ponieważ tabela taka jak powyższa ukazuje, jak osoby badane są „rozłożone” między różne kategorie, nosi ona nazwę |rozkładu. Zbiór wyników pomiarowych często nazywamy rozkładem; gdy wyniki te są uporządkowane według częstości występowania - od najwyższego do najniższego - to uporządkowanie takie nosi nazwę |rozkładu |częstości.

Mediana. Jeśli dysponujemy przynajmniej pomiarem porządkowym - to znaczy, jeśli kategorie można uporządkować w taki sposób, aby każda kategoria reprezentowała w większym stopniu, niż inne kategorie następujące po niej, to, co mierzymy, wówczas dla opisania danej grupy możemy posłużyć się inną statystyką wartości centralnej. Przypuśćmy, że chcemy przedstawić w skrócie stopnie wojskowe oraz grupy oficerów biorących udział w konferencji wojskowej.

Stopień wojskowy - Liczba uczestników
7. Generał - 2
6. Pułkownik - 3
5. Podpułkownik - 6
4. Major - 9
3. Kapitan - 10 (mediana)
2. Porucznik - 8
1. Podporucznik - 12 (modalna)

Ogółem - 50

Notując odznaki na ich naramiennikach moglibyśmy dokonać pomiaru stopni wojskowych. Ponieważ pomiary te można uporządkować według wysokości owych stopni, więc w efekcie otrzymaliśmy pomiar na skali porządkowej. W tabeli powyżej każdy stopień jest wyższy niż stopień znajdujący się pod nim, niższy zaś niż stopnie znajdujące się nad nim.
W celu zachowania tego porządku zastosowano większe liczby dla oznaczenia wyższych stopni. Liczby te są w pewnym stopniu dowolnie dobrane; moglibyśmy równie dobrze oznaczyć generała liczbą 99, pułkownika - liczbą 98 i tak dalej, aż do podporucznika. Dopóki większa z dwóch liczb zawsze reprezentuje wyższy z dwóch stopni, dopóty porządek jest zachowany.
Miara wartości centralnej, którą możemy zastosować dla tych danych, nazywa się |mediana. Mediana jest liczbą, która niejako dzieli dany rozkład na połowy, tak aby połowa przypadków znajdowała się ponad nią, a połowa poniżej. Ponieważ jest tu ogółem 50 przypadków, przeto medianą jest stopień, ponad którym znajduje się 25 przypadków, a pod którym - również 25 przypadków. Jak widzimy, 20 oficerów jest porucznikami lub podporucznikami, 20 zaś ma stopień majora lub wyższy. Ponieważ nie można podzielić tego rozkładu dokładnie na połowy, przeto staramy się do tego możliwie najbardziej zbliżyć i stwierdzamy, że medianą jest stopień oznaczony liczbą 3, jest to stopień kapitana.
Gdybyśmy chcieli, moglibyśmy posłużyć się modalną jako miarą wartości centralnej. Modalną tego rozkładu pomiarów jest 1, ponieważ jest więcej podporuczników niż wojskowych jakiejkolwiek innej rangi. Wybór między tymi dwoma statystykami będzie zależał od tego, jakiej informacji potrzebujemy.  Jeśli użyjemy modalnej jako wartości reprezentującej wszystkich członków tej grupy, to „trafimy” dokładnie w większej liczbie przypadków, niż gdybyśmy posłużyli się w jakąkolwiek inną wartością. Jeśli jednakże potrzebujemy takiej wartości centralnej dla stopni, aby tylu samo oficerów znalazło się powyżej, jak i poniżej niej, to wybierzemy medianę. Ujmując to inaczej, przypuśćmy, że chcemy odgadnąć stopień jakiegoś oficera. Jeśli zgadując podamy modalną, to dokładne „trafienie” będzie najbardziej prawdopodobne. Jeśli posłużymy się medianą, to prawdopodobieństwo podania stopnia zbyt niskiego byłoby takie samo, jak prawdopodobieństwo podania stopnia zbyt wysokiego.

Średnia. Jeśli pomiar został przeprowadzony na skali ilorazowej lub przedziałowej, to można zastosować jeszcze trzecią miarę wartości centralnej. Miarą tą jest |średnia (Ścisła nazwa tej statystyki to |średnia |arytmetyczna, w odróżnieniu od innych średnich, takich jak na przykład średnia geometryczna. Ponieważ te inne statystyki rzadko stosuje się w psychologii, przeto |średnią |arytmetyczną zwykle określa się skrótowo jako |średnią; oznacza się ją literami M lub X (str. 653.); średnią oblicza się dodając do siebie wszystkie pomiary i dzieląc tę sumę przez liczbę przypadków.

Jeśli chcemy wiedzieć, jaka jest przeciętna zdolność rozumienia słów w grupie uczniów szkoły średniej, możemy zacząć od zmierzenia tej zdolności za pomocą testu. Jeśli test został skonstruowany starannie, to zwykle zakładamy, że dostarcza on pomiarów na skali przedziałowej. W tym wypadku przyjmujemy, że równym różnicom między wynikami testu odpowiadają różne różnice pod względem rozumienia słów. Przypuśćmy, że wyniki uzyskane w tym teście, uporządkowane w kolejności od najwyższych do najniższych, przedstawiają się następująco.
* * *

Uczeń - Wyniki w Teście Rozumienia Słów (X)
John - 20
Mary - 18
Shirley - 18
Peter - 17
Alice - 16 
Nancy - 13 (średnia)
Henry - 13 (średnia)
Diane - 12 (mediana)
Douglas - 11
Sam - 11
Harvey - 10 (modalna)
Jane - 10 (modalna)
Barbara - 10 (modalna)
David - 9
Roger - 7
Suma - 195

* * *

Pierwszy krok przy obliczaniu średniej polega na dodaniu wszystkich wyników. Sumę wszystkich wyników oznacza się symbolem suma X, co czytamy: 
„suma X-ów”. Duża grecka litera sigma oznacza „sumę...”. Duża litera X reprezentuje każdy z kolejnych wyników. Dodając wszystkie wyniki stwierdzamy, że suma X =195.
Drugi krok w obliczeniu średniej polega na podzieleniu suma X przez N, ogólną liczbę przypadków. Wzór na obliczenie średniej jest następujący:

średnia (czyli X pod kreską) =suma X8N,

gdzie X pod kreską oznacza średnią. Wzór ten odczytuje się następująco: 
„|Średnia jest równa |sumie X-ów podzielonych przez |liczbę X-ów”.
Ponieważ jest 15 wyników, możemy zatem obliczyć średnią jak następuje:

x pod kreską =suma X8N =195815 =13


Średnia powyższych wyników wynosi zatem 13. Oznacza to, że średni wynik w teście rozumienia słów w tej grupie uczniów wynosi 13.
Wyniki testu rozumienia słów są danymi na skali przedziałowej, a więc |można stosować modalną, medianę lub średnią. Każda z tych statystyk wartości centralnej reprezentuje inny rodzaj „najlepszego odgadywania”.
Jeśli chodzi nam o to, żeby jak najwięcej razy odgadnąć zupełnie trafnie, to zastosujemy modalną. Więcej osób uzyskało wynik równy 10 niż jakikolwiek inny wynik, a więc 10 jest modalną. Gdybyśmy zgadywali, że wynik każdego ucznia należącego do tej grupy wynosi 10, to odgadlibyśmy zupełnie trafnie trzy razy. Oczywiście, zgadując wyniki pozostałych 12 uczniów pomylilibyśmy się o pewną wielkość. W tym wypadku zwykle podawalibyśmy wynik zbyt niski, ponieważ dziesięciu uczniów uzyskało wyniki powyżej modalnej, a tylko dwóch wyniki niższe do modalnej. Gdybyśmy chcieli przy odgadywaniu równie często podawać wynik zbyt wysoki, jak zbyt niski, to posłużylibyśmy się medianą, która jest równa 12. Wówczas odgadlibyśmy zupełnie trafnie tylko raz, lecz podawany wynik byłby zbyt wysoki 7 razy, a zbyt niski również 7 razy.
Mediana znajduje się zatem w „środku” rozkładu wyników, w tym sensie, że ta sama |liczba wyników znajduje się po obu jej stronach. Przypuśćmy jednak, że każde z trojga uczniów i najlepszych wynikach, mianowicie John, Mary i Shirley, uzyskało wynik równy 100. Mediana nadal wówczas wynosiłaby 12, lecz podając przy odgadywaniu ten wynik, w trzech przypadkach podalibyśmy wynik o 88 punktów za niski. Mediana byłaby zbyt niska i zbyt wysoka, w takiej samej |liczbie przypadków, lecz całkowita |suma punktów, o którą jest ona zbyt niska, byłaby o wiele większa niż suma punktów, o którą jest ona za wysoka. Jeśli chcemy podawać przy odgadywaniu taki wynik, który uwzględniałby wielkość błędu, to posługujemy się średnią. Średni wynik tych piętnastu uczniów w teście rozumienia słów wynosi 13. Gdybyśmy odgadywali, że wynik każdego ucznia w teście rozumienia słów jest równy 13, to suma punktów, o którą ten odgadywany wynik byłby zbyt niski, byłaby równa sumie punktów, o którą byłby on zbyt wysoki.
Statystyki wartości centralnej opisujące daną grupę są „najlepszymi odgadnięciami”, jakie możemy podać w odniesieniu do każdego członka tej grupy. Modalna jest to ten odgadywany wynik, który najczęściej okazuje się trafny; w przypadku mediany istnieją równe szanse na to, że okaże się ona zbyt wysoka lub zbyt niska; średnia zaś będzie zbyt wysoka o tę samą w sumie liczbę punktów, o jaką będzie ona zbyt niska.

Miary zmienności

Istoty ludzkie różnią się między sobą, o czym przekonaliśmy się w całym tym podręczniku. Różnią się one pod względem sposobu reagowania na bodźce.  Różnią się pod względem zdolności uczenia się i spostrzegania.
Celem stosowania statystyk zmienności jest określenie, jak dalece „rozciągnięty” jest dany rozkład. Innymi słowy statystyki te informują nas, jak dobrze (lub źle) pojedyncza statystyka wartości centralnej reprezentuje wszystkie wyniki w danym rozkładzie. Jeśli wszystkie wyniki są skupione blisko siebie, to każdy wynik jest dobrze reprezentowany przez statystykę wartości centralnej, taką jak średnia. Jeśli jednak rozkład jest rozciągnięty na dużym obszarze, to wówczas statystyka wartości centralnej nie będzie trafną oceną dla wielu poszczególnych wyników reprezentowanych w danym rozkładzie. Istnieje kilka miar, które określają zmienność wyników w grupie.

Obszar zmienności. Najprostrzy chyba sposób określenia, jak bardzo rozciągnięty jest dany rozkład, polega na ustaleniu |obszaru |zmienności.  Obszar zmienności jest to różnica między wynikiem najwyższym a najniższym.  W tabeli wyników testu rozumienia słów najwyższy wynik wynosi 20, najniższy zaś jest równy 7. Obszar zmienności wynosi zatem: 20 -7 =13.
Statystyki zmienności, podobnie jak statystyki wartości centralnej muszą odpowiadać zastosowanemu poziomowi pomiaru. Obszar zmienności wymaga pomiaru na |skali |przedziałkowej, ponieważ wchodzi tu w grę odejmowanie. W przypadku zastosowania skali nie posiadającej równych jednostek odejmowanie byłoby pozbawione sensu.
Obszar zmienności jest miarą dostarczającą stosunkowo mało informacji, ponieważ zależy ona tylko od dwóch wyników. Przypuśćmy, że jeden z uczniów uzyskał w teście rozumienia słów wynik równy 3. Ten jedyny wynik zmieniłby obszar zmienności o blisko jedną trzecią. Miara zmienności, czy jakakolwiek inna statystyka, przy której obliczaniu wykorzystuje się wszystkie wyniki w rozkładzie, dostarczy więcej informacji niż statystyka, która oparta jest jedynie na paru wynikach.

Odchylenia standardowe. W wypadku pomiaru na skali przedziałowej, najczęściej stosowaną miarą zmienności jest |odchylenie |standardowe. Przy jego obliczaniu wykorzystuje się każdy wynik w rozkładzie. Mówiąc dokładniej, oparte jest ono na odchyleniu każdego wyniku od średniej.  Odchylenie danego wyniku od średniej oznacza się małą literą x. 
Matematycznie można to wyrazić za pomocą wzoru:

x = X -(X pod kreską),

co oznacza: „|Odchylenie jest równe |wynikowi minus |średnia”.
Na pierwszy rzut oka mogłoby się wydawać, że dobrym sposobem mierzenia zmienności, wykorzystującym wszystkie wyniki, byłoby po prostu obliczenie średniej wszystkich tych odchyleń. Jednakże rezultat takiego działania przyniósłby rozczarowanie. Jak pamiętamy, odchylenie wyniku jest równe temu wynikowi minus średnia. Jeśli jakiś wynik jest powyżej średniej, to jego odchylenie będzie dodatnie. Jeśli jest on poniżej średniej, to odchylenie będzie ujemne. Jak wiemy, suma, o którą średnią jest zbyt niska (odchylenia dodatnie) jest równa sumie, o którą średnia jest za wysoka (odchylenie ujemne). Gdybyśmy zatem dodali do siebie wszystkie odchylenia, zarówno dodatnie, jak i ujemne, to zniosłoby się ono wzajemnie i otrzymalibyśmy jako wynik zero. Matematycznie:

suma x =0.

Dotyczy to każdego zbioru wyników. Aby uniknąć tej niedogodności, każde odchylenie przed dodaniem podnosi się do kwadratu (Istnieją także inne, bardziej matematycznie wyrafinowane przyczyny podnoszenia odchyleń do kwadratu, lecz omówienie ich wykracza poza zakres tej książki.) (mnoży przez siebie). Ponieważ liczba dodatnia pomnożona przez liczbę dodatnią daje w wyniku liczbę dodatnią, a liczba ujemna pomnożoną przez liczbę ujemną daje w wyniku również liczbę dodatnią, przeto wszystkie odchylenia po podniesieniu do kwadratu muszą być dodatnie i łatwo można otrzymać średnią tych |podniesionych |do |kwadratu odchyleń:

s do kwadratu = suma x do kwadratu 8N

Symbol s kwadrat nosi nazwę |wariancji. Powyższy wzór można przeczytać następująco: „|Wariancja jest równa |sumie |odchyleń |podniesionych |do |kwadratu podzielonej przez |liczbę |przypadków”.
Wariancję oznacza się przez (s do kwadratu) dla odzwierciedlenia faktu, że wszystkie odchylenia podniesiono do kwadratu, zanim obliczono ich średnią. Wariancje wyraża się zatem za pomocą jednostki innej niż pomiary pierwotne. Jeśli pomiarami pierwotnymi były wyniki testu rozumienia słów, to wariancja będzie wyrażona przy użyciu wyników testu rozumienia słów podniesionych do kwadratu. Aby odwrócić operację podnoszenia do kwadratu i dostarczyć miary zmienności wyrażonej w tych samych jednostkach co pomiary, z których została wyprowadzona, jako miary zmienności używa się często pierwiastka kwadratowego z wariancji. Nosi on nazwę |odchylenia |standardowego, a jego symbolem jest s. Odchylenie standardowe oblicza się za pomocą wzoru:

s = pierwiastek z (suma X do kwadratu dzielone przez N)

Kroki stosowane przy obliczaniu odchylenia standardowego podano w tabeli obok. W przykładzie tym wykorzystano wyniki testu rozumienia słów.

Średnia wynosi 13, a odchylenia standardowe = 3,8. Te dwie statystyki dostarczają nam skrótowego opisu piętnastu wyników. Średnia stanowi liczbę reprezentatywną dla poziomu grupy jako całości, a odchylenie standardowe jest liczbą reprezentatywną dla wszystkich odchyleń, ponieważ wskazuje, jak blisko wokół średniej skupione są wyniki.

Wyniki standaryzowane. Jak widzieliśmy, miary zmienności są użytecznym sposobem skrótowego przedstawienia różnic indywidualnych występujących w danej grupie. Mogą one także służyć do utworzenia jednostki standaryzowanej. Przypuśćmy, że uczniowie szkoły średniej, którzy wykonywali test rozumienia słów, rozwiązali również test ortograficzny.  Moglibyśmy wówczas postawić pytanie, czy jakiś określony uczeń jest równie dobry w rozumieniu słów, jak w znajomości ortografii. Przypuśćmy, że średnia wyników testowych oraz wyniki jednego z uczniów, Johna, przedstawiają się następująco:

Test: Średnia wyników - Wyniki Johna
Rozumienie słów: 13 - 20
Ortografia: 44 - 48
* * *
Wariancja I Odchylenia Standardowe

Uczeń: Wynik Testu Rozumienia Słów (X) - Odchylenie od średniej (x) - Odchylenie do kwadratu (x do kwadratu)
John: 20 7 49
Mary: 18 5 25
Shirley: 18 5 25
Peter: 17 4 16
Alice: 16 3 9
Nancy: 13 (średnia) 0 0
Henry: 13 (średnia) 0 0
Diana: 12 -1 1
Douglas: 11 -2 4
Sam: 11 -2 4
Harvey: 10 -3 9
Jane: 10 -3 9
Barbara: 10 -3 9
David: 9 -4 16
Roger: 7 -6 36
Sumy: 195 0 212

1. Dodaj wszystkie wyniki. Sumę tę oznacza się suma X:

suma X =195

2. Podziel tę sumę rzez liczbę wyników (N). W ten sposób uzyskałeś średnią (X pod kreską):

(x pod kreską) = suma X 8N = 195 815 =13.

3. Odejmij średnią od każdego z wyników, aby znaleźć jego odchylenie od średniej X (por. kolumnę „Odchylenie od średniej”):

x = X -(X pod kreską).

4. Podnieś każde odchylenie do kwadratu, to znaczy pomnóż je przez siebie (por. kolumnę „Odchylenie do kwadratu”):

x do kwadratu = (X - X pod kreską) do kwadratu.

5. Dodaj wszystkie odchylenia podniesione do kwadratu. Rezultat oznacza się jako: suma x do kwadratu:

suma x do kwadratu =212.

6. Podziel tę sumę przez liczbę wyników, aby znaleźć wariancję (s kwadrat):

s kwadrat = suma x kwadrat 8N = 212 815 = 14,13.

7. Wyciągnij pierwiastek kwadratowy z wariancji. Jest to odchylenie standardowe s:

s =3,8.

* * *

Wiemy już, że wyniki Johna są w obu testach powyżej średniej. Nie wiemy jednak, |jak |bardzo powyżej średniej. Nie możemy porównać obu jego wyników ponieważ nie wiemy, czy jeden punkt w jednym z tych testów jest równoważny jednemu punktowi w drugim z nich. Jest prawdopodobne że nie są one równoważne. Przypuśćmy, że jeden punkt w teście ortograficznym odpowiada dwóm punktom w tekście rozumienia słów. Oznaczałoby to, że cztery punkty, o które wynik Johna przewyższa średnią w teście ortograficznym, byłyby równoważny 8 punktom powyższej średniej w teście rozumienia słów. Ponieważ John uzyskał w teście rozumienia słów wynik przewyższający średnią tylko o 7 punktów to uznalibyśmy, że jego wynik w teście ortograficznym był wyższy.  Z drugiej strony, jeśli jednostki w obu testach są równoważne, to John uzyskał lepszy wynik w teście rozumienia słów.
Aby określić związek między jednostkami obu tych testów, możemy posłużysz się naszymi miarami zmienności. Wiemy, że odchylenie standardowe wyniku testu rozumienia słów wynosi 3,8. Wynik Johna wynoszący 20 jest o 7 punktów, czyli prawie o 2 odchylenia standardowe (dokładnie 1,8), powyżej średniej. Przypuśćmy, że obliczyliśmy odchylenie standardowe rozkładu wyników teście ortograficznym i stwierdziliśmy, że jest ono równe 4.  Oznaczałoby to, że wynik Johna w teście ortograficznym jest o jedno odchylenie standardowe powyżej średniej, podczas gdy w teście rozumienia słów jego wynik przewyża średnią o prawie dwa odchylenia standardowe.  Moglibyśmy powiedzieć, że John uzyskał lepszy wynik w teście rozumienia słów niż w teście ortograficznym. Odchylenie standardowe można zatem zastosować jako jednostkę umożliwiającą porównywanie wyników danej osoby w dwóch testach. Odchylenie wyniku każdej z osób od średniej można wyrazić posługując się tą jednostką. Wyniki wyrażone w ten sposób noszą nazwę |wyników |standaryzowanych i oznacza się je symbolem „z”. Wynik Johna, będący o 1,8 odchylenia standardowego powyżej średniej, daje mu wynik standaryzowany równy 1,8. Gdyby John uzyskał wynik równy średniej czyli 13, to jego wynik „z” wynosiłby 0. Gdyby uzyskał wynik poniżej średniej, to jego wynik „z” byłyby liczbą ujemną.
Często dwa różne testy są różnej długości lub trudności, lub stosuje się w nich różne jednostki pomiaru, co powoduje, że wyniki uzyskiwane w obu tych testach nie są porównywalne. Jeśli na przykład ktoś uzyskał 82 punkty w jednym teście, a 450 w drugim, to spojrzawszy na te wyniki nie mielibyśmy po prostu pojęcia, który z nich jest lepszy od drugiego. Wyniki standaryzowane dla obu tych testów byłyby natomiast wyrażone w porównywalnych jednostkach (odchyleniach standardowych) tak, że moglibyśmy powiedzieć od razu, czy jeden z nich jest lepszy niż drugi.
Wynik standaryzowany pozwala nam określić miejsce danej osoby w grupie, w której wykonywała ona dany test. Jeśli więc porównamy wynik standaryzowany Johna w teście rozumienia słów z jego wynikiem standaryzowanym w teście ortograficznym, to otrzymamy odpowiedź na pytanie: „Czy |względny wynik Johna w teście ortograficznym jest lepszy czy gorszy niż jego |względny wynik w teście rozumienia słów?”
Odchylenie standardowe można obliczyć tylko wtedy, jeśli stosowano skalę pomiarową o równych jednostkach. Odchylenia standardowe, podobnie jak średnią arytmetyczną, można zatem stosować tylko wtedy, gdy pomiaru dokonuje się przynajmniej na skali przedziałowej.

Miary korelacji

Dotychczas omawialiśmy statystyki, które opisują pojedynczy zbiór pomiarów. Psychologia zwykle interesuje się wieloma różnymi zmiennymi, a zatem wieloma różnymi zbiorami pomiarów. W badaniach psychologicznych często stawia się pytanie: „W jakim stopniu związane są ze sobą te dwa zbiory wyników?” Na przykład, jeśli daliśmy do wykonania tej samej grupie osób test rozumienia słów i test ortograficzny, to moglibyśmy zapytać, w jakiej mierze osoby, które uzyskały wysokie wyniki w jednym teście, uzyskały także wysokie wyniki w drugim. Jednym ze sposobów ustalenia tego byłoby wypisanie nazwisk wszystkich osób, które uzyskały wyniki powyżej średniej w teście rozumienia słów, i ustalenie, ile z nich uzyskało wyniki powyżej średniej w teście ortograficznym. Postępowanie takie dałoby nam przybliżone pojęcie o |korelacji między tymi dwoma testami. Gdyby większość osób uzyskujących wysokie wyniki w jednym teście uzyskało również wysokie wyniki w drugim z nich, to powiedzielibyśmy, że istnieje między tymi testami wysoka |dodatnia |korelacja. Jeśli większość osób, które uzyskały wysokie wyniki w jednym teście uzyskało niskie wyniki w drugim, to powiedzielibyśmy, że istnieje wysoka |korelacja |ujemna.

Współczynniki korelacji i ich znaczenie. Spróbujemy teraz wyjaśnić pojęcie korelacji opierając się na znajomości wyników standaryzowanych (wyników „z”). Przypuśćmy, że wszystkie wyniki w testach z ortografii i testach rozumienia słów zostały przekształcone w wyniki standaryzowane.  Przyjmijmy ponadto, że wynik „z” każdego ucznia w teście ortograficznym jest taki sam jak jego wynik „z” w teście rozumienia słów. W takim wypadku mówi się, że istnieje doskonała korelacja dodatnia między wynikami obu tych testów. Rezultat ten przedstawia wykres, na którym każda kropka reprezentuje jedną osobę, wyniki zaś każdej z osób można odczytać na osi poziomej i pionowej. Na przykład John (kropka umieszczona najwyżej) uzyskał wynik „z” = 1,8 w obu testach. W przypadku korelacji doskonałej wyniki poszczególnych osób w jednym teście można dokładnie przewidzieć, jeśli zna się ich wyniki w drugim teście.

Przypuśćmy teraz, że każdy uczeń, który uzyskał wysoki wynik w teście rozumienia słów, uzyskał równie niski wynik w teście ortograficznym. Innymi słowy, każdy był równie słaby w jednym teście, jak dobry w drugim - uczeń najlepszy w teście ortograficznym był najgorszy w teście rozumienia słów i na odwrót.

W obu powyższych przykładach wyniki uzyskane w jednym teście były zupełnie ściśle związane z wynikami drugiego testu. Biorąc od uwagę przeciwną skrajność przypuśćmy, że wyniki te są zupełnie ze sobą nie związane. W takim przypadku uczeń najlepszy z ortografii mógłby być dobry, przeciętny lub słaby w rozumieniu słów. Wiedza o umiejętnościach danej osoby z zakresu ortografii nie mówiłaby nam nic o jej zdolności rozumienia słów.

Często dwie zmienne są skorelowane ze sobą, aczkolwiek nie jest to korelacja doskonała. Na rycinie przedstawiającej tego rodzaju związek, kropki nie leżą na linii prostej, ani nie tworzą koła; są ułożone w kształcie elipsy. Im bardziej płaska elipsa, im bardziej zbliżona do linii prostej - tym wyższa jest korelacja.
Jak wspomnieliśmy w Rozdziale 1, stopień korelacji między dwoma zmiennymi wyraża się za pomocą |współczynnika |korelacji („r”). Do jego obliczenia można wykorzystać wyniki z zgodnie z następującym wzorem:

r = (suma z od x razy z od y) 8N

Zgodnie z tym wzorem, współczynnik korelacji jest równy sumie wyników „z” poszczególnych osób w jednym teście pomnożonych przez wyniki „z” tych samych osób w drugim teście, podzielonej przez liczbę osób. Obliczenie to wydaje się skomplikowane, lecz w rzeczywistości jest proste. Poszczególne kroki w obliczeniu korelacji, na przykładzie wyników uzyskanych w teście ortograficznym i w teście rozumienia słów, przedstawiono w tabeli poniżej.
* * *

Korelacje
Uczeń: Rozumienie słów (X, z od X) - Ortografia (Y, z od Y, z od x razy z od y)
John (20 1,8) (48 0,8 1,44)
Mary (18 1,3) (45 0,2 0,26)
Shirley (18 1,3) (45 0,2 0,26)
Peter (17 1,1) (57 2,5 2,75)
Alice (16 0,8) (39 -0,9 -0,72)
Nancy (13 0,0) (42 -0,4 0,0)
Henry (13 0,0) (52 1,5 0,0)
Diane (12 -0,3) (43 -0,2 0,06)
Douglas (11 -0,5) (47 0,6 -0,30)
Sam (11 -0,5) (44 -0,0 0,00)
Harvey (10 -0,8) (41 -0,6 0,48)
Jane (10 -0,8) (37 -1,3 1,04)
Barbara (10 -0,8) (43 -0,2 0,16)
David (9 -1,1) (40 -0,8 0,88)
Roger (7 -1,6) (37 -1,3 2,08)
Suma (z od x razy z od y) = 8,39


1. Oblicz średnie i odchylenia standardowe dla obu korelowanych zmiennych:

X pod kreską =13; s od x =3,8
Y pod kreską =44; s od y =5,3 (obliczone w taki sam sposób jak X pod kreską i s).

2. Przekształć każdy z wyników w wynik standardowy, odejmując ich średnią i dzieląc przez ich odchylenie standardowe (por. kolumny z do x i z od y).

3. Przemnóż przez siebie dwa wyniki standardowe dla każdej jednostki w grupie (por. kolumnę z od x razy z od y).

4. Znajdź średnią arytmetyczną tych iloczynów, dodając je do siebie i dzieląc przez liczbę uczniów:

r =0,56


|Wniosek: Istnieje umiarkowana dodatnia korelacja.

* * *

W tym przypadku „z od x” oznacza wynik standaryzowany w teście rozumienia słów, zaś „z od y” jest wynikiem standaryzowanym w teście ortograficznym.
Współczynniki korelacji, o czym również była już mowa w Rozdziale 1, mogą przybierać wartości od +1 (doskonała korelacja dodatnia) przez 0 (brak korelacji) do -1 (doskonała korelacja ujemna). W praktyce korelacja doskonała, czy to dodatnia czy ujemna występuje rzadko; jedynie czasem udaje się do niej zbliżyć przy czym korelację wynoszącą 0,90 uważa się za bardzo wysoką.


Współczynnik korelacji a przewidywanie. Statystycy ustalili, jaki procent osób, które znajdują się w górnej połówce rozkładu w odniesieniu do jednej cechy, powinien znaleźć się w górnej połówce rozkładu pod względem drugiej cechy, gdy występuje pewna określona korelacja między tymi dwoma cechami o normalnych rozkładach. W tabeli poniżej podano współczynniki korelacji oraz odpowiadające im procenty.

* * *

Współczynniki korelacji: Procent osób z „lepszej połowy” w teście A, które znajdują się (w „lepszej połowie” w teście B, w „gorszej połowie” w teście B)
0,00: 50 - 50
0,05: 52 - 48
0,10: 53 - 47
0,20: 56 - 44
0,30: 60 - 40
0,40: 63 - 37
0,50: 67 - 33
0,60: 70 - 30
0,70: 75 - 25
0,80: 80 - 20
0,90: 86 - 14
0,95: 90 - 10
1,00: 100 - 0
* * *

3 3 75 0 2 108 1 5a 1 74 0
Jak wynika z powyższej tabeli, dokładność przewidywania zależy od wysokości korelacji między dwoma rozpatrywanymi zmiennymi. Jeśli wiesz na przykład, że współczynnik korelacji między dwoma testami wynosi 0,90 to możesz przewidywać, że 86% osób, które były w górnej połówce pod względem wyniku w teście rozumienia słów, znajdzie się także w górnej połówce testu ortografii. Lecz 14% nie znajdzie się tam i zawsze istnieje możliwość, że konkretna jednostka, którą się interesujesz, będzie wśród tych 14%.  Przewidując więc wynik danej osoby, można co najwyżej określić jego prawdopodobieństwo. W tym przypadku możesz powiedzieć, że szanse danej osoby na znalezienie się w górnej połówce wyników drugiego testu wynoszą 86 na 100.
3 3 75 0 2 108 1 5a 1 74 1

Posługiwanie się Wnioskowaniem statystycznym


Największą wartością metodologii statystycznej jest to, że pozwala nam ona dokonywać uogólnień. Psychologowie zwykle nie chcą ograniczać swych wniosków do tych specyficznych grup, które wybierają dla obserwacji lub eksperymentu. Przeciwnie, mają oni nadzieję, że ustalą zależności obowiązujące w znacznie większych grupach lub dotyczące ludzi w ogóle. Ta procedura wyciągania ogólnych wniosków na podstawie badanych próbek nosi nazwę |wnioskowania |statystycznego. Przy tworzeniu ogólnych teorii zachowania ludzkiego nie jesteśmy w stanie badać wszystkich ludzi we wszystkich warunkach. Psychologowie eksperymentalni wyprowadzają zatem pewną szczegółową hipotezę z danej teorii i opracowują eksperyment mający sprawdzić tę hipotezę na pewnej próbie. Jeśli rezultaty okażą się zgodne z hipotezą, to zwiększa to ufność badaczy w trafność tej teorii. Jeśli wyniki są sprzeczne z hipotezą, to mają oni powód, by wątpić w trafność teorii.
Wnioskowanie statystyczne stosuje się czasami w badaniach, w których nie chodzi o sprawdzenie jakiejś teorii, lecz o znalezienie odpowiedzi na konkretne, praktyczne pytanie. Jest to dziedzina badań stosowanych. Dobrego przykładu posługiwania się wnioskowaniem statystycznym w badaniach stosowanych dostarczają badania opinii publicznej. Dokładność, z jaką badacze potrafią przewidywać zachowanie danej grupy po uzyskaniu wypowiedzi jedynie małej liczby osób z tej grupy, stanowi przykład efektywności technik wnioskowania statystycznego.
Podstawowe etapy wnioskowania statystycznego, zarówno w badaniach teoretycznych, jak i stosowanych, są następujące:
1. Określ |populację. Populacja (czasami zwana |universum) jest to cała grupa, którą badacz się interesuje. Może być ona tak ogólna, że obejmuje wszystkich ludzi lub nawet wszelkie organizmy żywe. Może być także tak specyficzna, jak wszyscy studenci pierwszego roku w pewnym college’u lub wszyscy zarejestrowani wyborcy w pewnym okręgu wyborczym.
2. Pobierz |próbkę z tej populacji. Próbka jest to grupa badanych, na której przeprowadza się badania.
3. Dokonaj |pomiarów na tej próbce. Etap ten stanowi właściwe badanie czy eksperyment. Zależnie od charakteru badań pomiar ten może być tak prosty, jak zapytanie osoby badanej, na kogo będzie ona głosować przy następnych wyborach. Z drugiej strony, może on być niezwykle złożony, wymagając na przykład podziału próbki na kilka grup eksperymentalnych, poddania każdej grupy oddziaływaniu odrębnych warunków eksperymentalnych i wreszcie mierzenia ich reakcji na te warunki.
4. Oblicz jedną lub więcej |statystykę |opisową. Jak już wiemy, statystyki opisowe pozwalają przedstawić w skrótowej formie szereg pomiarów.
5. Wykorzystaj statystyki opisowe do |wyciągnięcia |wniosków dotyczących danej populacji za pomocą testów wnioskowania statystycznego.

Pobieranie próbki

Pobieranie próbki, jak można się domyślić, jest to proces doboru próbki z pewnej populacji. Każda zastosowana przy pobieraniu próbki procedura powinna zapewnić rzeczywistą reprezentywność próbki dla danej populacji.  Dokładniej mówiąc, próbka musi reprezentować, ze znanymi dokładnie ograniczeniami, wszystkie cechy danej populacji, które wiążą się z problemem eksperymentalnym. W przeciwnym wypadku próbka nosi nazwę |tendencyjnej.
Istnieje wiele metod pobierania próbki, przy czym najczęściej stosowaną jest |losowe |pobieranie |próbki. W losowym pobieraniu próbki stawia się dwa wymagania: a) dla każdego członka danej populacji prawdopodobieństwo znalezienia się w tej próbce musi być takie samo, b) prawdopodobieństwo, że dany członek populacji zostanie włączony do próbki, musi być niezależne od tego, czy jakikolwiek inny członek został do niej włączony, czy też nie.  Przykładem losowego doboru próbki jest losowanie wygranych w uczciwie przeprowadzonej loterii. Wszystkie losy (populacja) miesza się dokładnie, wygrywające zaś numery (próbka) wyciąga się na „ślepo”. Teoretycznie losowy dobór próbki wymaga, aby każdy wygrywający los umieścić ponownie w urnie przed wyciągnięciem następnego, tak aby ten sam los mógł być wyciągany więcej niż raz. Jeśli jednak populacja jest duża, to subtelne rozróżnienie nie ma znaczenia. Mniej kłopotliwa metoda losowego doboru próbki polega na przypisaniu kolejnych liczb każdemu członkowi danej populacji, a następnie wybieraniu liczb z tabeli, w której liczby następują po sobie w kolejności losowej. Tabele te są tak skonstruowane, że prawdopodobieństwo wystąpienia każdej liczby na danym miejscu listy jest takie samo. Jedną z takich tabel opublikowano w formie książkowej (Rand, 1955).
Gdy próbka została już dobrana, wówczas przeprowadza się pomiary i oblicza statystyki opisowe. Statystyki takie mogą następnie służyć jako oceny ich odpowiedników w populacji jako całości. Odpowiedniki te noszą nazwę |parametrów.
Nawet najlepsza ocena parametru ma pewien margines błędu. Ważne jest, aby wiedzieć, jak duży jest ten błąd. Można to określić przy użyciu modelu matematycznego. Model to pewna abstrakcja, którą stosuje się dla opisania zjawisk świata realnego. Model najczęściej w tym wypadku stosowany przez psychologów nosi nazwę |rozkładu |normalnego.


Rozkład normalny


Jak wyjaśniono w Rozdziale 10, w badaniach psychologicznych często stwierdza się, że wyniki większości osób badanych skupiają się w pobliżu średniej rozkładu wyników. Im dalej od średniej znajduje się dany wynik, tym mniej osób go uzyskuje. Pokazaliśmy wcześniej, jak byłyby prawdopodobnie rozłożone wyniki 1000 losowo dobranych osób, którym dano by do wypełnienia test służący do pomiaru pewnej cechy psychicznej.
Można określić trzy właściwości tego rozkładu wyników: a) liczba osób uzyskujących dany wynik zmniejsza się, w miarę jak rośnie odległość tego wyniku od średniej, b) rozkład ten jest symetryczny względem średniej, c) modalna, mediana i średnia są sobie równe.
Przybliżeniem tego rozkładu częstości może być |krzywa |normalna (|k.  |dzwonowa), która obejmuje wszystkie wyniki. Ponieważ krzywa normalna tak często stanowi dobre przybliżenie rozkładów częstości uzyskiwanych w pomiarach psychologicznych, przeto warto przyjąć tę krzywą za model, czyli przypadek idealny.
Model ten, |rozkład |normalny, jest pewnym uogólnieniem dotyczącym rozkładów częstości, podobnie jak „50:50” jest uogólnieniem dotyczącym szans przy podrzucaniu monet. Jeśli podrzuca się pewną liczbę monet, to „modelowe” oczekiwanie będzie głosiła, że połowa monet opadnie orłem do góry. Przewidywanie to rzadko jest dokładnie prawdziwe, lecz im więcej monet podrzuca się w górę, tym lepsze przybliżenie do tego modelu uzyskuje się. To samo dotyczy również rozkładu normalnego: doskonałej krzywej normalnej nie otrzymuje się z próbki pomiarów nigdy, chociaż im większa próbka, tym bardziej wyniki zbliżają się do krzywej normalnej. Aby pomiary idealnie pasowały do matematycznej definicji tej krzywej, potrzebna byłaby nieskończenie wielka populacja. Gdy otrzymane pomiary są bardzo zbliżone do krzywej normalnej, wówczas często przyjmuje się założenie, że próbka ta została pobrana z populacji, która w |istocie dokładnie pasuje do tego modelu.
Rozkład normalny jest modelem niezwykle użytecznym. Jeśli rozkład wyników w próbce jest w przybliżeniu normalny i znamy jego średnią i odchylenie standardowe, to możemy skonstruować krzywą, która pokaże, jaki prawdopodobnie byłby rozkład wyników w całej populacji, z której próbka ta została pobrana.
W przybliżeniu dwie trzecie wyników mieści się w granicach jednego odchylenia standardowego od średniej. W przypadku ilorazów inteligencji około dwie trzecie powierzchni pod krzywą znajduje się zatem między wartościami I.I. równymi 84 i 116, ponieważ odchylenie standardowe jest równe 16.
Mniej niż 0,3 jednego procenta wyników znajduje się w odległości większej niż trzy odchylenia standardowe od średniej. Z tego względu obszar zmienności obejmujący sześć odchyleń standardowych - trzy poniżej średniej i trzy powyżej niej - przyjmuje się jako reprezentujący cały praktycznie zakres rozkładu normalnego. Jeśli próbka nie jest niezwykle duża, to rzadko otrzymamy wyniki wykraczające poza te granice.



Pytania, na jakie odpowiada wnioskowanie statystyczne


Gdy w danej populacji pobierze się losowo dwie próbki, to okaże się prawdopodobne, że ich średnie różnią się w pewnym stopniu z powodu działania przypadkowych czynników. Jeśli podrzucisz monetę 1000 razy, to powinna ona upaść orłem do góry w przybliżeniu 500 razy. Lecz gdyby wykonać tylko 10 prób, to mogłaby nie wypaść dokładnie połowa orłów. Gdy więc prowadzi się badania na małej próbce, to potrzebny jest pewien sposób ustalenia, czy uzyskane wyniki są przypadkowe, czy też można je przypisać działaniu jakiegoś rzeczywistego, a nie losowego czynnika - zjawiska lub procesu - który stanowi źródło systematycznego odchylenia.
Procedury wnioskowania statystycznego wprowadzają porządek do wszelkich naszych prób wyciągania wniosków, które wykraczają poza obserwacje dokonywane na poszczególnych próbkach. Oto niektóre z pytań, na jakie można odpowiedzieć dzięki wnioskowaniu statystycznemu: a) czy uzyskana przez ciebie próbka wyników jest rzeczywiście reprezentatywna dla pewnej określonej populacji, b) czy otrzymana różnica między średnimi różnych próbek jest dostatecznie duża, abyś mógł wyciągnąć wniosek, że próbki te są prawdopodobnie pobrane z różnych populacji raz c) czy zróżnicowanie wyników |między grupami, które poddano różnym oddziaływaniom eksperymentalnym, jest większe niż rozrzut wyników |w |obrębie każdej z tych grup.
Jeśli średnie wyników w dwóch grupach różnią się, lecz rozkłady wyników „zachodzą na siebie” w znacznym stopniu, to różnica między tymi dwoma średnimi może być przypadkowa, a nie spowodowana oddziaływaniem eksperymentalnym.
Za każdym razem, gdy pod koniec eksperymentu porównujesz wyniki grupy eksperymentalnej z wynikami grupy kontrolnej, to starasz się ustalić, czy wskutek oddziaływania eksperymentalnego wyniki te reprezentują tera dwie różne populacje. Im większa jest różnica między średnimi tych grup oraz im mniej rozkłady wyników na siebie zachodzą, tym większą możesz mieć pewność, że istnieje rzeczywista różnica. W takiej sytuacji mógłbyś oczekiwać, że ponownie stwierdzisz tę różnicę przy powtórzeniu eksperymentu z dwoma innymi próbkami pobranymi z pierwotnej populacji. Możesz mieć tym większą pewność, że przeprowadzony przez ciebie test statystyczny wykazuje godny zaufania, istotny wpływ czy różnicę, na której możesz polegać, im częściej i w sposób bardziej konsekwentny stwierdzasz tę różnicę, im jest ona większa, im większe są pobrane przez ciebie próbki i im większe są różnice między grupami w porównaniu z różnicami wewnątrz grupy.
Dostępne są trzy testy statystyczne, które pozwalają znaleźć odpowiedź na ogólne pytania postawione powyżej i na szczegółowe pytania stawiane przez każdego badacza. Możemy tu jedynie wymienić kilka powszechnie stosowanych testów i podać do czego służą. Na przykład, testem najczęściej stosowanym do porównywania rzeczywiście stwierdzonych częstości różnych możliwych zdarzeń z przewidywanymi częstościami ich występowania jest test chi-kwadrat. Test służący do porównywania różnic między dwoma zbiorami wyników nazywa się |testem |t. Test do porównywania zróżnicowania między grupami ze zróżnicowaniem wewnątrzgrupowym (dla dwóch lub więcej grup) nosi nazwę |analizy |wariancji lub |testu |F.
Ten krótki dodatek stanowi niezmiernie pobieżny przegląd pojęć, które zwykle omawia się w ramach wstępnego kursu statystyki. Uwzględniono w nim tylko najważniejsze punkty, a i te bardzo skrótowo. Niemniej jednak ogólne przyswojenie sobie zaprezentowanego tu materiału będzie bardzo pomocne przy interpretowaniu wyników większości publikowanych badań psychologicznych.

Słownik


(Definicje terminów zawartych w „Słowniku” Autor sformułował z punktu widzenia potrzeb Czytelnika niniejszej książki; wyjaśnienia nie wyczerpują całości zagadnień - pominięto w nich te informację, które nie były bezpośrednio przydatne do zrozumienia tekstu. Numery stron książki, z którymi powiązane są poszczególne hasła, podano w „Indeksie rzeczowym” odrębną czcionką (przy. red.))


Absolutyzm fenomenalistyczny („phenomenal absolutism”). Bezkrytyczna pewność naiwnego obserwatora, że spostrzega on w bezpośredni sposób cechy różnych przedmiotów.
Acetylocholina („acetylocholine”). Chemiczna substancja przekaźnikowa, która prawdopodobnie umożliwia przejście impulsu nerwowego przez synapsę, z jednego neuronu do drugiego.
ACTH; adrenokortykotropina („ACTH”). Hormon wydzielany przez przedni płat przysadki mózgowej; współdziała z hormonami wydzielanymi przez korę nadnerczy i odgrywa ważną rolę w reakcjach fizjologicznych na długotrwały stres.
Adaptacja do ciemności („dark adaptation”). Proces, dzięki któremu oczy stają się bardziej wrażliwe i w efekcie możemy widzieć przy słabym oświetleniu.
Adaptacja sensoryczna („sensory adaptation”). Osłabienie reakcji na długo działający bodziec, spowodowane adaptacją receptorów lub zmęczeniem mięśni.  Zobacz także „Habituacja”.
Adenina („adenine”). Jedna z czterech zasad nukleotydowych, z których składa się cząsteczka DNA; wiąże się z tyminą.
Adipocyty („adipocytes”). Wyspecjalizowane komórki organizmu, które magazynują tłuszcz w postaci kwasów tłuszczowych; jednostki otyłe mają większą liczbę tych komórek niż jednostki o przeciętnej wadze ciała.
Adrenalina; epinefryna („adrenaline”; „epinephrine”). Hormon wydzielany przez rdzeń nadnerczy (wewnętrzną część gruczołów nadnerczy) w czasie silnych emocji; związany z reakcjami gniewu i strachu.
Afazja („aphasia”). Upośledzenie zdolności posługiwania się językiem i rozumienia go, występujące mimo tego, że mechanizmy słuchu i mowy są nieuszkodzone; spowodowane jest schorzeniem lub uszkodzeniem pewnych pól kojarzeniowych mózgu.
Afekt niedostosowany („inappropriate affect”). Objaw występujący u psychotycznych pacjentów, u których wyrażane emocje są niewłaściwe ze względu na charakter sytuacji.
Aferentne włókno nerwowe („afferent nerve fiber”). Przewodzi informacje z czuciowej komórki receptorowej, na przykład w oku lub uchu, do ośrodkowego układu nerwowego; zwane także czuciowym włóknem nerwowym („sensory nerve fiber”).
Afiliacja („affiliation”). Skłonność czy pragnienie przebywania z innymi ludźmi; podstawowa potrzeba społeczna, czyli motyw „towarzyski”, o zasadniczym znaczeniu dla wspólnego życia.
Agnostycyzm („agnosticism”; od greckiego słowa oznaczającego „niepoznawalne”). Stanowisko, zgodnie z którym o istnieniu Boga i prawdziwości dogmatów religii (a także o innych aspektach rzeczywistości - przyp. tłum.) nie można rozstrzygać na gruncie nauki i doświadczenia.
Agnozja („agnosia”). „Niezdolność do rozpoznawania”; zaburzenie spostrzegania polegające na niemożności zorganizowania wrażeń w normalne spostrzeżenia. 
Agresja („aggression”). Reakcja polegająca na niszczeniu przedmiotów, wyrządzaniu krzywdy innym lub sobie samemu (lub wyraźnej intencji dokonania tego); przyjmuje wiele różnych postaci.
Agresja antyspołeczna („antisocjal aggression”). Agresja wyrażana w nieakceptowany społecznie sposób.
Agresja prospołeczna („prosocial aggression”). Agresja służąca akceptowanym społecznie celom, takim jak karanie za łamanie reguł lub obrona dziecka przed awanturnikiem.
Akomodacja („accommodation”). Proces (postulowany przez Piageta), dzięki któremu wytworzone uprzednio struktury poznawcze są modyfikowane na podstawie nowych doświadczeń.

Akson (axon). Długie włókno wychodzące z ciała komórkowego neuronu; przekazuje impulsy nerwowe do innych neuronów lub do mięśnia czy gruczołu.
Aktywacja (activation; energizing). Ogólna nieukierunkowująca funkcja motywacji, polegająca na wzbudzaniu lub dostarczaniu energii (co umożliwia organizmowi osiągnięcie jego celów).
Alkohol (alcohol). Rodzaj środka psychotropowego, który poraża ośrodkowy układ nerwowy: ma o dużą zdolność wywoływania psychicznego i fizjologicznego uzależnienia oraz powoduje nieodwracalne uszkodzenia tkanek.
Alkoholizm (alcoholism). Uzależnienie od alkoholu, czyli nałóg jego picia; można próbować określić go jako proces chorobowy, w którym defekt fizyczny stopniowo powiększa się wraz z upływem czasu i wzrostem konsumpcji alkoholu.
Altruizm (altruism). Wszelkie działanie, w którym przychodzi się z pomocą innym, nie spodziewając się nagród zewnętrznych za udzielenie pomocy.
Amnezja (amnesia). Utrata pamięci, zwłaszcza o swych osobistych przeżyciach, może być jedną z odmian stanu dysocjacji.
Amnezja hipnotyczna (hypnotic amnesia). Zmiany pamięciowe, które występują w wyniku hipnozy; amnezja dotycząca części doznań hipnotycznych może być spontaniczna lub powodowana określonymi sugestiami podanymi podczas seansu hipnotycznego.
Amplituda reakcji (amlitude of response). Miara siły warunkowania oparta na rozmiarach czy wielkości reakcji (np. ilość śliny wydzielanej przez psa w doświadczeniach Pawłowa).
Analiza czynnikowa (factor analysis). Technika statystyczna stosowana przy ustalaniu i mierzeniu względnej doniosłości podstawowych zmiennych, czyli czynników, które składają się na jakąś złożoną zdolność, cechę czy formę zachowania.
Analiza pozycji (item analysis). Metoda statystyczna służąca do ustalenia, w jakiej mierze odpowiedzi na każdą z pozycji testowych różnicują badane grupy.
Analiza snów (dream analysis). Technika psychoanalityczna polegająca na interpretowaniu marzeń sennych w celu uzyskania wglądu w nieświadomą motywację pacjenta; oparta na przekonaniu Freuda i innych, że marzenia senne są symbolicznym odzwierciedleniem imulsów, konfliktów i pragnień.
Analizatory cech (feature analyzers). Neurony, które reagują selektywnie na cechy wyzwalające.
Analiza w kategoriach systemów społecznych (social-system analysis).  Metoda polegająca na dążeniu do zrozumienia indywidualnych wzorców reakcji w świetle ich powiązań i wzajemnej zależności z większymi systemami społecznymi, a nie na poszukiwaniu prostych związków przyczynowych z izolowanymi bodźcami.
Analne stadium (anal stage). W teorii freudowskiej, drugie stadium rozwoju psychoseksualnego, w którym dziecko uzyskuje kontrolę nad procesami wydalania i w którym te procesy są głównym źródłem przyjemności.
Androgyniczna osobowość (androgynous personality). Osobowość jednostki wykazującej męskie, jak i kobiece cechy psychiczne.
Anonimowość (anonymity). Pozostawanie nieznanym; brak poczucia wyraźnie zaznaczonej indywidualności (anonimowość życia miejskiego pozbawia jednostki ich poczucia tożsamości).
Anorexia nervosa (anorexia nervosa). Głodzenie samego siebie wynikające z nieodczuwania łaknienia; jest to rzadka, chroniczna choroba, trudna do leczenia, na którą zapadają prawie wyłącznie młode dziewczęta.
Antropomorfizm (anthropomorphism). Przypisywanie ludzkich cech, uczuć i myśli zwierzętom lub rzeczom.
Antycypacja szeregów (serial anticipation). Metoda badania przypominania, w której osoba badana najpierw uczy się szeregu pojedynczych słów lub sylab, aby potem w kolejnych ekspozycjach przewidywać, jaki element pojawi się jako następny.
Antynorma (counternorm). Alternatywny standard właściwego zachowania, odmienny od dominujących norm społecznych.
Aprobata społeczna (social approval). Wzmocnienie, w postaci akceptacji lub uznania, okazywane danej osobie przez innych ludzi, z powodu jej działań lub jej sposobu bycia.
Aprobata warunkowa (conditional regard). Aprobowanie pewnego zachowania danej jednostki, nie zaś tej jednostki jako osoby; aprobata jest uzależniona od spełnienia określonych kryteriów. 
Archetypy (archetypes). W teorii osobowości Junga uniwersalne symbole i predyspozycje dziedziczone w nieświadomości zbiorowej; mogą występować w marzeniach sennych.
Asymilacja (assimilation). Proces, w którym nowe elementy poznawcze są modyfikowane tak, by stały się bardziej podobne do elementów znanych już z doświadczenia i by można je było łatwiej włączyć w istniejące struktury poznawcze.
Atrybucja (attribution). Proces przypisywania jednostkom lub ich zachowaniu uwarunkowań i przyczyn (na podstawie wnioskowania). 
Atrybucja dyspozycyjna (dispositional attribution). Przypisywanie przyczyn pewnego działania lub zjawiska względnie stałym, niemodyfikowanym cechom wewnętrznym danej jednostki, to jest cechom jej osobowości i charakteru oraz wewnętrznym dyspozycjom do działania. Atrybucja dyspozycyjna umożliwia jedynie wyodrębnienie kategorii ludzi trudnych, nie pozwala zaś na analizę sytuacji problemowych.
Atrybucja sytuacyjna (situational attribution). Przypisywanie działaniom czy zjawiskom przyczyn tkwiących w środowisku, sytuacji lub interakcji między osobami, nie zaś w cechach danej jednostki.
Audytorium (audience). Ci, dla których przeznaczony jest dany przekaz; zmienna w badaniach nad zmianą podstaw.
Autoerotyzm (autoerotism). Pobudzenie czy podniecenie seksualne wywoływane przez siebie samego, bez udziału innej osoby i bez stymulacji z jej strony.
Autonomiczny układ nerwowy; AUN (autonomic nervous system; ANS).  Część obwodowego układu nerwowego, która reguluje czynności organizmu nie podlegające zwykle kontroli dowolnej, w tym zmiany w narządach wewnętrznych występujące podczas doznawania emocji; złożony z dwóch części: układu sympatycznego (współczulnego) i układu parasympatycznego (przywspółczulnego).
Autosugestia (autosuggestion). Proces oddziaływania na swe własne postawy, zachowanie lub stan fizyczny za pomocą procesów psychicznych innych niż świadome myślenie, na przykład przez zastosowanie autohipnozy.
Autyzm dziecięcy (autism). Skrajna postać zaburzenia psychicznego występującego w okresie dzieciństwa, dla której charakterystyczny jest brak komunikowania się lub właściwych kontaktów z otoczeniem, albo też niewytworzenie adekwatnego obrazu samego siebie.


Badanie rzeczywistości (reality testing). Proces, dzięki któremu jednostka ocenia siebie (swe opinie, zdolności i inne cechy) stosownie do obiektywnych, przeciętnych norm i wzorów lub według pewnego fizycznego aspektu otoczenia.
Behawioryści (behaviorists). Psychologowie, których działalność można określić jako naukowe badanie zewnętrznego zachowania organizmów. Zajmują się oni zachowaniami, które można obiektywnie mierzyć i obserwować, oraz wykrywaniem przewidywalnych i swoistych zależności między bodźcami a reakcjami. 
Behawioryzm (behaviorism). Szkoła psychologiczna zajmująca się obiektywnym badaniem związków między bodźcami a reakcjami.
Beznadziejności poczucie (hopelessness). Stan braku nadziei powodujący apatię, bezczynność i bierną rezygnację.
Biologiczne sprzężenie zwrotne (biofeedback). Technika, za pomocą której organizm uczy się zmieniać i regulować wewnętrzne procesy fizjologiczne, poprzednio uważane za niezależne od woli (na przykład ciśnienie krwi i czynność bioelektryczną mózgu); polega ona na dostarczaniu osobie badanej natychmiastowego sprzężenia zwrotnego, czyli informacji o zmianach zachodzących w danej chwili w jego organizmie.
Bliźnięta dwujajowe (dizygotic twins). Bliźnięta, które rozwijają się z odrębnych zapłodnionych komórek jajowych.
Bliźnięta jednojajowe (monozygotic twins). Bliźnięta identyczne, które rozwinęły się z tej samej komórki jajowej (zygoty), a zatem mają identyczne wyposażenie genetyczne.
Blokada; podwójne wiązanie (double-bind). Sytuacja, w której występują dwa lub więcej niezgodne komunikaty wymagające niemożliwych do pogodzenia reakcji.
Błąd atrybucji (attribution error). Skłonność do przeceniania roli cech osoby działającej i niedoceniania znaczenia czynników sytuacyjnych występująca przy próbach wyjaśnienia lub zrozumienia danego działania.
Błąd logiczny (logical error). W ocenie percepcyjnej błąd polegający na założeniu, iż pewne cechy zawsze występują łącznie.
Błąd łagodności (leniency error). Pospolity rodzaj błędu oceny polegający na skłonność osoby oceniające do przyznawania prawie wszystkim ocen pozytywnych, to jest bliskich dodatniego krańca skali ocen.
Błąd tendencji centralnej (central tendency error). Błąd oceny percepcyjnej występujący wtedy, gdy osoba oceniająca ignoruje zróżnicowanie ludzi lub cech jednej osoby: ocenia na przykład wszystkich jako „zadowalających, dobrych lub przeciętnych.
Błona bębenkowa (eardrum). Cienka błona na końcu przewodu słuchowego między uchem zewnętrznym a środkowym.
Błona podstawowa (basilar membrane). Błona w uchu, znajdująca się wewnątrz ślimaka; ruch tej błony pobudzają komórki włoskowe narządu Cortiego, dzięki czemu bodźce słuchowe są przekładane na impulsy nerwowe.
Błona zewnętrzna (outer membrane). Struktura komórkowa, która otacza komórkę i oddziela jej wnętrze od środowiska zewnętrznego.
Bodziec bezwarunkowy; Sb (unconditioned stimulus, UCS). Bodziec, który wywołuje reakcję bez warunkowania.
Bodziec proksymalny; b. bliski (proximal stimulus). Obraz przedmiotu na siatkówce (w przeciwieństwie do rzeczywistego przedmiotu).
Bodziec dyskryminacyjny Sd (discriminative stimulus, Sd). W warunkowaniu sprawczym bodziec, który sygnalizuje, że wzmocnienie jest lub nie jest dostępne po danym zachowaniu sprawczym.
Bodziec dystalny; b. odległy (distal stimulus). Rzeczywisty przedmiot powodujący stymulację siatkówki.
Bodziec podprogowy (subliminal stimulus). Bodziec zbyt słaby, aby mógł go wykryć receptor sensoryczny.
Bodziec warunkowy; Sw (conditioned stimulus, CS). Bodziec, początkowo obojętny, który w wyniku wielokrotnego zestawienia go z bodźcem bezwarunkowym nabywa zdolności wywoływania reakcji, początkowo wyzwalanej jedynie przez bodziec bezwarunkowy.
Bodźce społeczne (social stimuli). Zmienne niezależne o charakterze społecznym wpływające na zachowanie jednostek; bodźce te mogą pochodzić bezpośrednio od innych ludzi lub też mogą być bodźcami pośrednimi, skojarzonymi uprzednio z innymi ludźmi, z normami społecznymi itd.
Bodźce wyzwalające (releaser stimuli). Zewnętrzne bodźce sygnałowe czy sygnały, takie jak nielubiane obiekty bądź obiekty już skojarzone z agresją, których interakcja ze stanem wewnętrznym danej jednostki wywołuje i ukierunkowuje jej agresję na określone cele.
Bruzdy (fissures). Głębokie szczeliny czy rowki oddzielające od siebie poszczególne płaty kory mózgowej; najważniejsze z nich to bruzda Rolanda (pionowa szczelina oddzielająca płat czołowy od ciemieniowego) oraz bruzda Sylwiusza (pozioma szczelina oddzielająca płat skroniowy od płata ciemieniowego i czołowego).Burza mózgów (brainstorming). Technika grupowego rozwiązywania problemów stosowana w celu pobudzenia czy ułatwienia procesu twórczego; uczestnicy starają się wymślić wszelkie możliwe rozwiązania danego problemu, a dopiero potem przystępują do ich oceny i wybierają jedno z nich.


Cannula (cannula). Podwójna rurka (jedna rurka umieszczona w drugiej) wprowadzana na przykład do jam ciała lub naczyń krwionośnych i stosowana do różnych celów, takich jak odprowadzanie cieczy lub wstrzykiwanie substancji chemicznych w wybrane miejsca mózgu lub innych części ciała. 
Cecha (trait). Względnie stała właściwość jednostek, którą można obserwować lub mierzyć.
Cechy hormetyczne (hormetic traits). Elementy osobowości mające bezpośrednio motywujący charakter (zależne zarówno od potrzeb fizjologicznych, jak i od rodzaju doświadczeń danej jednostki); obejmują potrzeby, postawy i zainteresowania.
Cechy specyficzne dla gatunku (species-specific charakterystic). Cechy występujące tylko u jednego gatunku.
Cechy wyzwalające (trigger features). Układy bodźców sensorycznych, które wywołują reakcje w poszczególnych neuronach czuciowych.
Celowość (purposiveness). Ważna zasada teorii zachowania opracowanej przez Tolmana, głosząca, że uczenie się jest ukierunkowane racjonalnie i dotyczy hipotez, oczekiwań, wyraźnych celów itd.
Charyzmat (charisma). Niezwykła, właściwa danej osobie zdolność przywódcza, rzeczywista lub spostrzegana, polegająca na specyficznej umiejętności oddziaływania emocjonalnego i przyciągania zwolenników.
Chemioterapia; farmakologia (chemotherapy, pharmacotherapy). Forma terapii biologicznej, czyli somatycznej, w której stosuje się środki farmakologiczne do leczenia zaburzeń psychicznych i emocjonalnych; stosowana na dużą skalę w zakładach zamkniętych, zarówno w celach leczniczych, jak i dla łatwiejszego kierowania pacjentami.
Chloropromazyna (chlorpromazine). Środek uspokajający szeroko stosowany w leczeniu schizofrenii; wzmaga wytwarzanie serotoniny.
Choroba psychiczna (mental illness). Termin pochodzący z medycznego modelu zaburzenia psychicznego, odnoszący się do różnych anormalnych form zachowania na tyle poważnych, że kolidujących ze zwykłym trybem życia; obejmuje złe przystosowanie motywacyjne, emocjonalne i społeczne.
Choroba psychosomatyczna (psychosomatic illness). Choroba, w której objawy fizyczne, często w postaci rzeczywistych uszkodzeń tkanek, można przypisać stresowi emocjonalnemu lub innym przyczynom natury psychologicznej.
„Choroba rezygnacji (give-up-itis). Zespół występujący u niektórych jeńców wojennych, na który składa się utrata wszelkiej nadziei na odzyskanie kiedykolwiek wolności oraz wynikająca stąd utrata zainteresowania przyszłością; prowadzi do śmierci z przyczyn emocjonalnych.
Chromosomy (chromosomes). Składniki jądra komórkowego, zbudowane z DNA i białek, zawierające geny, odpowiedzialne za cechy dziedziczne. Każda komórka organizmu człowieka zawiera czterdzieści sześć chromosomów, z wyjątkiem komórek płciowych, czyli gamet, w których są 23 chromosomy.
Ciało kolankowate boczne (lateral geniculate nucleus). Punkt przekaźnikowy we wzgórzu, przez który przechodzą impulsy biegnące z oka do kory potylicznej.
Ciało komórki (cell body). Część neuronu, która zwiera jądro i z której wychodzą wypustki: akson i kilka dendrytów.
Ciało migdałowate (amygdala). Struktura w układzie limbicznym mózgu związana z reakcjami walki i obrony, pierwotnymi emocjami i zachowaniem seksualnym.
Ciało modzelowate (corpus callosum). Gruba wiązka włókien nerwowych łącząca dwie półkule mózgowe. Gdy zostanie przecięta, wówczas odrębne funkcje oby półkul nie są integrowane, co prowadzi do pojawienia się dwóch umysłów w jednym mózgu.
Ciekawość (curiosity). Popęd organizmu do badania i poznawania swego otoczenia; określany także jako popęd eksploracyjny lub odruch badawczy.
Cytoplazma (cytoplasm). Substancja, z której składa się komórka (oprócz jądra); zachodzi w niej większość biochemicznych reakcji komórki.
Cytozyna (cytosine). Jedna z czterech zasad nukleotydowych, z których składa się cząsteczka DNA; wiąże się z guaniną.
Częstość reakcji (frequency of response). Miara siły reakcji oparta na tempie wykonywania danej reakcji.
Czopki (cones). Komórki receptorowe w siatkówce, które umożliwiają widzenie barw i zapewniają dużą ostrość wzroku.
Czuciowe włókno nerwowe. Zobacz Aferentne włókno nerwowe.
Czynniki temperamentalne (temeramental factors). W teorii czynnikowej Guilforda, cechy osobowości określające charakterystyczny dla danej jednostki sposób działania.
Czynnikowe teorie osobowości (factor theories of personality). Teorie osobowości, w których różne układy właściwości ludzkich opisuje się i wyjaśnia w kategoriach czynników ustalanych metodami matematycznymi.
Czynność przymusowa; cz. kompulsywna (compulsion). Dziwaczna, irracjonalna, ciągle powtarzana czynność, której dana osoba nie rozumie, niemniej jednak czuje się zmuszona ją wykonywać; czynność ta ma zwykle charakter symboliczny.


Dane (data). Opisy lub pomiary obserwowanych zdarzeń.
Decybel; dB (decibel; db). Jednostka pomiarowa natężenia dźwięku.
Dehumanizacja (dehumanization). Psychiczne zatarcie ludzkich cech i wartości innych osób; prowadzi do tego, że innych ludzi spostrzega się i traktuje jak przedmioty lub zwierzęta.
Dendryty (dendrites). Mocno rozgałęzione wypustki neuronu, które przewodzą impulsy nerwowe z obwodu (np. od innych neuronów) do ciała komórki; zwykle dość krótkie.
Depolaryzacja (depolarization). Proces, który zachodzi w neuronie, gdy siła bodźca przekroczy próg pobudzenia; wybiórcza przepuszczalność błony komórkowej zmienia się, co pozwala jonom sodu wniknąć do wnętrza komórki, dzięki czemu stan polaryzacji neuronu znika i powstaje impuls nerwowy biegnący wzdłuż aksonu.
Deprywacja (deprivation). Brak (lub pozbawienie) bodźców umożliwiających zaspokojenie potrzeb lub czegoś niezbędnego do biologicznego lub psychicznego funkcjonowania.
Deprywacja sensoryczna (sensory deprivation). Znaczne obniżenie poziomu stymulacji sensorycznej osiągnięte za pomocą możliwie pełnego wyeliminowania bodźców wzrokowych, słuchowych i dotykowych; może doprowadzić do wystąpienia halucynacji i urojeń. Deprywacja może także oznaczać brak takiej różnorodności wejścia sensorycznego, jakiej wymaga nasz złożony mózg.
Depresja (depression). Stan emocjonalny charakteryzujący się przygnębieniem, poczuciem braku własnej wartości i zwykle lękiem; jest obecnie najbardziej rozpowszechnione w Stanach Zjednoczonych zaburzenie psychiczne; jego objawy wykazują znaczne podobieństwo do objawów wyuczonej bezradności.
Depresja endogenna (endogenous depression). Typ zachowania depresyjnego, którego przyczyny upatruje się w czynnikach wewnętrznych - biochemicznych lub genetycznych; objawy tej formy depresji mogą obejmować obniżenie sprawności umysłowej, bezsenność, silne przygnębienie i zamiary samobójcze.
Depresja inwolucyjna (involutional melancholia). Reakcja psychotyczna, dla której charakterystyczne są lęki, podniecenie, urojenia i depresja; występuje w późnym okresie życia u osób nie wykazujących uprzednio zaburzeń psychotycznych; jej zasadniczym rysem może być depresja lub myśli paranoidalne; częściej rozpoznawana u kobiet.
Depresja reaktywna (reactive depression). Typ zachowania depresyjnego wywoływanego przez zewnętrzne, sytuacyjne stresory, a nie przez wewnętrzne przyczyny o chorobliwym charakterze.
Depresja synaptyczna (synaptic depression). Mechanizm habituacji, znany także jako zmęczenie swoiste (intrinsic fatique); stan dróg nerwowych występujący w miejscu połączeń synaptycznych.
Determinizm (determinism). Teoria głosząca, że wszystkie zdarzenia są zdeterminowane przez poprzedzające je przyczyny. Teoria ta zakłada, że związki przyczynowe są niezmienne, a zatem dane zdarzenie jest możliwe do przewidzenia, jeśli znane są jego przyczyny.
Determinizm psychiczny (psychic determinism). Postulowana przez Freuda teoria zachowania, zarówno normalnego, jak i anormalnego, która głosi, że zjawiska psychiczne nigdy nie są przypadkowe i można ustalić między nimi związki logiczne lub przyczynowe, jeśli zbada się je dostatecznie dokładnie. 
Dewiacja (deviance). Zachowanie uznawane przez społeczeństwo za różniące się znacznie od przeciętnego zachowania danej grupy, czyli od normy oczekiwanej w danej sytuacji i w danych warunkach.
Dezindywidualizacja (deindividuation). Subiektywne poczucie utraty własnej tożsamości i odpowiedzialności. Powoduje to osłabienie zwykłych mechanizmów kontrolnych, które hamują impulsywne i antyspołeczne zachowania; do powstania tego stanu może przyczyniać się między innymi anonimowość i zmienione stany świadomości.
Diada (dyad). Grupa złożona z dwóch osób.
DNA (DNA). Kwas dezoksyrybonukleinowy; zasadniczy składnik genów, zbudowany z długich łańcuchów par zasad nukleotydowych ułożonych w kształcie skręconej drabiny lub spiralnych schodów.
Dominacja półkul mózgowych (cerebral dominance). Asymetria w funkcjonowaniu mózgu pozwalająca uniknąć rywalizacji między półkulami mózgowymi, dzięki zdominowaniu jednej z nich przez drugą - zwykle półkuli „milczącej przez półkulę zawiadującą mową (u większości ludzi praworęcznych dominującą jest lewa półkula).
Dominacja wzrokowa (visual domination). Zdominowanie percepcji słuchowej przez percepcję wzrokową wówczas, gdy istnieje między nimi sprzeczność; znane także jako owładnięcie wzrokowe (visual capture).
Doznania szczytowe (peak experiences). Zgodnie z tą teorią osobowości Maslowa, momenty największego szczęścia i poczucie spełnienia doświadczane przez osoby, które osiągnęły samorealizację.
Dualizm (dualism). W ujęciu kartezjańskim pogląd, iż organizm ludzki składa się z dwóch niezależnych elementów: mechanistycznego ciała i mózgu oraz spirytualistycznej duszy wraz z efemeryczną psychiką.
Dwoistość świadomości (duality of consciousness). Odrębność funkcji świadomości wypełnianych przez dwie półkule mózgowe.
Dynamika grup (group dynamics movement). Kierunek w psychologii (zapoczątkowany przez Lewina) zajmujący się badaniem dynamicznych właściwości interakcji społecznych w grupach, na poziomie empirycznym, teoretycznym i praktycznym.
Dynamizm (dynamism). W teorii osobowości Sullivana, długotrwały, powtarzający się wzorzec zachowania; nawyk.
Dyshabituacja (dishabituation). Zanik habituacji; powrót reakcji orientacyjnej po okresie habituacji, gdy pojawi się bodziec dostrzegalnie różny od poprzednich bodźców.
Dyskryminacja (discrimination). Reakcje lub zachowania wynikające z uprzedzeń (jak w przypadku dyskryminacji rasowej).
Dysleksja (dyslexia). Upośledzenie zdolności czytania polegające między innymi na odwracaniu liter lub cyfr.
Dywergencja (divergence). Proces rozchodzenia się impulsów w układzie nerwowym, dzięki któremu impulsy z jednego neuronu lub komórki receptorowej docierają do wielu neuronów lub efektorów.


Efekt halo; e, aureoli (halo effect). Błąd oceny, którym obarczone są wyniki uzyskane za pomocą skal ocen; jest to skłonność (występująca przy przeprowadzaniu wywiadu lub ocenianiu jakiejś osoby ze względu na pewną cechę) do formułowania oceny danej osoby pod wpływem własnej opinii o jakiejś innej posiadanej przez nią cesze lub pod wpływem ogólnego wrażenia, jakie ta osoba wywarła na oceniającym.
Efekt Zeigarnik (Zeigarnik effect). Tendencja do lepszego pamiętania zadań przerwanych przed ich ukończeniem niż zadań ukończonych.
Efektory (effectors). Narządy (mięśnie lub gruczoły), które realizują przystosowawcze funkcje organizmu po otrzymaniu impulsów nerwowych z neuronów ruchowych.
Eferentne włókno nerwowe (efferent nerve fiber). Przenosi informację z ośrodkowego układu nerwowego do reagującego narządu, takiego jak mięsień czy gruczoł; zwane także ruchowym włóknem nerwowym (motor nerve fiber).
Ego (ego). W psychoanalitycznej teorii Freuda, racjonalny aspekt osobowości; kieruje impulsami id tak, by spełnić wymagania rzeczywistości, a jednocześnie utrzymać szacunek jednostki dla siebie samej i zapewnić jej aprobatę społeczną. Bardziej ogólnie - pojęcie danej jednostki o sobie.
Egocentryzm (egocentrism). Niezdolność odróżniania własnego punktu widzenia od punktu widzenia innych ludzi.
Egzorcyzmy (exorcisms). Różne techniki stosowane od czasów starożytnych i średniowiecznych do wypędzania złych duchów z osób opętanych, czyli chorych psychicznie; oparte na koncepcji, zgodnie z którą przyczyną zaburzeń psychicznych jest owładnięcie przez demony.
Egzystencjalizm (existencialism). Introspekcyjna filozofia, która kładzie nacisk na to, że jednostki są odpowiedzialne za swe własne życie i realizują w pełni swą egzystencję dzięki sztuce dokonywania wyboru.
Eklektyczne podejście (eclectic approach). W przypadku prac naukowych, na przykład psychologicznych, posługiwanie się różnorodnymi teoriami, założeniami, rodzajami badań i poziomami analizy, bez opowiadania się za którymś z nich jako lepszymi od innych.
Ekologia (ecology). Nauka o wzajemnych relacjach między organizmami a ich środowiskiem fizycznym.
Ekonomia żetonowa (token economy). Technika pozytywnego wzmacniania, często stosowana w szpitalach psychiatrycznych i innych zakładach opieki, polegająca na nagradzaniu pacjentów żetonami za konstruktywne społecznie zachowanie; żetony te można później wymienić na różne przywileje. Główną zaletą tej techniki jest możliwość wyraźnego określenia celów oraz kryteriów zachowania.
Ekosystem (ecosystem). Społeczność rozpatrywana jako całość ekologiczna, łącznie z nieożywionymi elementami jej otoczenia.
Ekspresja niewerbalna (nonverbal expression). Przekazywanie informacji czy porozumiewanie się bez słów i symboli słownych.
Elektroencefalogram; EEG (electroencephalogram; EEG). Zapis słabych prądów czynnościowych kory mózgowej, zwanych także falami mózgowymi; wykorzystywany do wykrywania zaburzeń i patologicznych zjawisk w funkcjonowaniu mózgu.
Elektromiogram; EMG (electromyogram, EMG). Zapis aktywności elektrycznej związanej z reakcjami mięśniowymi.
Emocja (emotion). Złożony subiektywny proces psychiczny, który może być wywoływany przez bodźce środowiskowe i w którym pośredniczą zmienne fizjologiczne; może mieć zdolność motywowania organizmu do działania. Wiąże się z odczuwaniem skłonności ku bodźcom ocenianym jako dobre i od bodźców ocenianych jako złe.
Empatia (empathy). Doświadczanie w sposób zastępczy myśli, uczuć i motywów innych osób; może służyć jako wyjaśnienie altruzimu.
Empiryści brytyjscy; asocjacjoniści (british empiricists; 
„associationists). Siedemnastowieczni filozofowie, którzy utrzymywali, że źródłem wiedzy o rzeczywistości mogą być jedynie informacje przetwarzane przez narządy zmysłowe; złożone myśli uważali za wynik kojarzenia prostych elementów sensorycznych.
Empiryzm (empiricism). Metoda naukowa, w której wykorzystuje się możliwe do zweryfikowania informacje o faktach, uzyskiwane za pośrednictwem obserwacji, doświadczeń zmysłowych lub eksperymentów, zamiast nieprzewidzialnych czy nieobserwowalnych pojęć i spekulacji myślowych.
Engram (engram). Hipotetyczny ślad pamięciowy ukształtowany w trakcie uczenia się i przechowywany przez pewien czas; zanika, jeżeli nie zostanie przeniesiony do systemu pamięci długotrwałej.
Enwironmentalizm (environmentalism). Stanowisko, zgodnie z którym wpływ czynników środowiskowych a nie dziedzicznych wywiera decydujący wpływ na rozwój natury ludzkiej. Zwolennicy tego stanowiska za czynnik taki uznają wychowanie. Uważają oni, że naturę ludzką można modyfikować.
Epifenomen (epiphenomenon). Zjawisko wtórne towarzyszące innemu zjawisku i uważane za jego skutek; rumieniec jest epifenomenem zakłopotania. 
Epigeneza (epigenesis). Teoria rozwoju embrionalnego, wywodząca się z poglądów Arystotelesa, zgodnie z którą narządy kształtują się stopniowo z prostych, początkowo niezróżnicowanych substancji znajdujących się w zapłodnionej komórce jajowej. Obecnie termin ten oznacza tworzenie się w trakcie rozwoju struktur i narządów nie występujących początkowo w zarodku.  Zobacz także Ortogeneza.
Erogeniczne strefy ciała (erogenous body zones). Miejsca ciała, których stymulacja dotykowa wywołuje pobudzenie czy podniecenie seksualne.
Eros (Eros). Według teorii freudowskiej, instynkt seksualny, czyli „instynkt życia, jeden z dwóch popędów obecnych od urodzenia; obejmuje wszelkie dążenia do twórczej syntezy, jest więc pojęciem znacznie szerszym niż sam popęd seksualny.
Erotyczny (erotic). Zdolny do wywoływania podniecenia seksualnego.
Eskalacja agresji (escalation of aggression). Druga faza agresywnej interakcji, w której każda z uwikłanych w nią osób reaguje na uprzednie zachowanie, początkową prowokację, a także na spostrzegane przez siebie intencje takiego postępowania.
Estrus (estrus). Stan receptywności seksualnej u samic ssaków; jest to cyklicznie powtarzający się stan, znany także jako ruja, któremu może towarzyszyć sugestywne lub agresywne zachowanie seksualne.
Etiologia (etiology). Zespół przyczyn; nauka zajmująca się między innymi badaniem przyczyn zaburzeń.
Etnocentryzm (ethnocentrism). Tendencja do przyjmowania negatywnych postaw wobec wszelkich grup innych niż własna (którą uważa się za najlepszą).
Etolog (ethologist). Badacz, który studiuje zachowanie zwierząt w ich naturalnym środowisku, często w celu poznania cech specyficznych dla gatunku.
Etyka (ethics). Zbiór zasad i wartości dotyczących tego, co dobre, a co złe, co słuszne a co niesłuszne, a także określających obowiązki moralne.
Euforia (euphoria). Uczucie niezwykle dobrego samopoczucia czy radosnego podniecenia.
Eugenika (eugenics). Nauka, która zajmuje się ulepszaniem gatunku przez kontrolowanie czynników dziedzicznych przy dobieraniu par.


Falliczne stadium (phallic stage). W teorii freudowskiej, trzecie stadium rozwoju psychoseksualnego (między trzecim i piątym rokiem życia), w którym występuje eksploracja i stymulacja własnych narządów płciowych oraz silny pociąg do rodzica przeciwnej płci z towarzyszącą mu zazdrością wobec rodzica tej samej płci.
Farmakoterapia Zobacz Chemioterapia.
Fenomenalizm (phenomenalism). Przekonanie, że następujące po sobie zdarzenia mogą być związane przyczynowo nawet wówczas, gdy zachodzą w różnych miejscach bez żadnej bezpośredniej styczności.
Fenomenolodzy (phenomenologists). W psychologii, zwolennicy badania natury ludzkiej poprzez zrozumienie świadomości. W przeciwieństwie do behawiorystów zajmują się oni subiektywnym doświadczeniem jednostki, sprawozdaniami introspektywnymi i procesami psychicznymi, aby zrozumieć świat z punktu widzenia osoby badanej.
Feromony (pheromone). Sygnały zapachowe, które, między innymi, wzbudzają pożądanie seksualne u zwierząt.
Fiksacja (fixation). W teorii freudowskiej, zatrzymanie rozwoju na skutek nadmiaru frustracji lub gratyfikacji w danym stadium wyrażające się nieprzechodzeniem do następnego stadium psychoseksualnego.
Fobia (phobic reaction). Neurotyczna forma obrony; jest to proces przemieszczania lęku o nieokreślonych przyczynach na pewien obiekt zewnętrzny, który nie powinien budzić strachu; prowadzi do unikania tego obiektu lub sytuacji.
Fonemy (phonemes). Podstawowe, odrębne jednostki dźwiękowe, z których składa się dany język.
Frenologia (phrenology). Fałszywe przekonanie, że osobowość tworzą różne, odrębne władze, z których każda jest zlokalizowana w określonym miejscu mózgu o czym mają świadczyć wypukłości na głowie.Frustracja (frustration). Zablokowanie motywów przez przeszkody znajdujące się między daną jednostką a celem. Jeśli nie ma żadnych możliwości wyrażenia agresji wywołanej frustracją, to mogą pojawić się i utrzymywać zmiany fizjologiczne, na przykład w tempie pracy serca lub skurzowym ciśnieniu krwi.
Fuga; ucieczka (fugue). Neurotyczny stan dysocjacji; wiąże się z utratą pamięci, której towarzyszy rzeczywista, fizyczna ucieczka od swej własnej sytuacji życiowej do zupełnie nowego bądź też dawnego, mniej zagrażającego środowiska.Funkcja potęgowa Stevensa (Stevens power function). Zależność, która wyraża prawo psychofizyczne stwierdzające, iż równym stosunkom bodźcowym odpowiadają równe stosunki wywołanych przez nie wrażeń subiektywnych.
Funkcja sygnalizacyjna (cueing). Specyficzna funkcja motywacji służąca wyzwalaniu pewnych sekwencji reakcji organizmu prowadzących do określonych celów.
Funkcja w kształcie odwróconej litery U (inverted-U function). Funkcja obrazująca związek między wzbudzeniem a efektywnością działania - wzrost wzbudzenia zwiększa efektywność działania jedynie do pewnego punktu, a po przekroczeniu go, ma na nią ujemny wpływ.


Gamety (germ cells). Komórki rozrodcze (męska - plemnik i żeńska - komórka jajowa); łącząc się tworzą zygotę, z której rozwija się nowy organizm. Zawierają tylko połowę liczby chromosomów występujących w innych komórkach organizmu.
Generalizacja bodźcowa (stimulus generalization). Tendencja do wywoływania reakcji warunkowej przez wiele bodźców podobnych do bodźca warunkowego (lecz nie identycznych z nim).
Genitalne stadium (genital stage). W teorii freudowskiej, ostatnie stadium rozwoju psychoseksualnego, rozpoczynające się w okresie dojrzewania, w którym następuje przejście od autoerotyzmu do zainteresowania narządami płciowymi innych osób.
Geny (genes). Ultramikroskopijne odcinki łańcuchów DNA w chromosomach; podstawowa jednostka przekazywania dziedzicznego.
Główne pole ruchowe (primary motor area). Część kory nowej, zawiadująca funkcjami ruchowymi, leżąca tuż przed bruzdą Rolanda.
Griadient dążenia (approach gradient). Wzrost siły tendencji do zbliżenia się ku upragnionemu celowi w miarę zmniejszania się jego oddalenia; ważne dla zrozumienia pewnych sytuacji konfliktowych.
Gradient generalizacji bodźca (stimulus generalization gradient).  Przedstawienie funkcjonalnego związku między stopniem podobieństwa bodźca a siłą reakcji; gdy bodziec staje się mniej podobny do bodźca warunkowego, wówczas prawdopodobieństwo reakcji odpowiednio maleje.
Gradient unikania (avoidance gradient). Wzrost siły tendencji do oddalania się od wzbudzającego strach miejsca lub obiektu w miarę zbliżania się do niego; nachylenie tego gradientu jest bardziej strome niż gradientu dążenia; ważne dla zrozumienia pewnych typów sytuacji konfliktowych.
Gruczoły nadnerczy (adrenal glands). Para gruczołów wydzielania wewnętrznego; każdy z nich znajduje się na górnym biegunie jednej z nerek i składa się z części wewnętrznej - rdzenia nadnerczy, który, zwłaszcza podczas silnych emocji, wydziela adrenalinę i noradrenalinę, oraz z części zewnętrznej - kory nadnerczy, która między innymi wydziela hormony wpływające na dojrzewanie.
Grupa eksperymentalna (experimental group). Grupa osób badanych poddana oddziaływaniu zmiennej niezależnej, której wpływ się bada, Zobacz także „Grupa kontrolna.
Grupa kontrolna (control gruop). Grupa osób badanych, o tych samych cechach, co grupa eksperymentalna, podlegająca tym samym, co i ona procedurom - z tym wyjątkiem, że nie poddaje się jej oddziaływaniu zmiennej niezależnej, której wpływ się bada. Zastosowanie grupy kontrolnej pozwala określić poziom odniesienia, z którym porównuje się efekty oddziaływań, jakim poddano grupę eksperymentalną. Zobacz także Grupa eksperymentalna.
Grupy spotkaniowe (encounter groups). Małe grupy terapeutyczne, lub też grupy mające na celu rozwijanie osobowości, dostarczające uczestnikom intensywnych doświadczeń interpersonalnych związanych przede wszystkim z interakcjami, w których uczestniczą i z uczuciami, które w atmosferze uczciwości i szczerości ujawniają się w takiej grupie. Zobacz także Grupy T. Grupy T; grupy uwrażliwiające (T-groups; experiential groups).  Grupy zajmujące się trenigami wrażliwości, organizowane nie tyle w celach terapeutycznych, ile dla ułatwienia osobistego rozwoju i ćwiczenia się w doskonaleniu umiejętności interpersonalnych. Zobacz także Grupy spotkaniowe.
Guanina (guanine). Jedna z czterech zasad nukleotydowych, z których składa się cząsteczka DNA; wiąże się z cytozyną.


Habituacja (habituation). Osłabienie fizjologicznych i psychologicznych reakcji na odbierany bodziec; zanik reakcji orientacyjnej, gdy bodziec stał się dobrze znany, powtarza się nieustannie lub jest oczekiwany - przez co obniża się jego wartość informacyjna dla danej jednostki.
Halucynacja; omam (hallucination). Wrażenie sensoryczne dotyczące obiektów zewnętrznych, powstające bez udziału odpowiedniej energii bodźcowej z otoczenia; źródło spostrzeżenia jest wewnętrzne a nie zewnętrzne.
Halucynogenny (hallucinogenic). Zdolny do wywoływania halucynacji sensorycznych.
Hamowanie (inhibition). Stłumienie lub zniesienie jakiegoś zachowania czy zjawiska; termin ten ma wiele specyficznych znaczeń na różnych poziomach analizy.
Hamowanie oboczne (lateral inhibition). Proces percepcyjny, w którym każdy pobudzony receptor wzrokowy oddziałuje hamująco na sąsiednie komórki.
Hamowanie wzajemne (reciprocal inhibition). Technika odwrażliwiania, rozwinięta przez Wolpea i stosowana w terapii behawioralnej; w technice tej z bodźcami wzbudzającymi lęk łączy się reakcje antagonistyczne wobec lęku takie jak odprężenie.
Hebefrenia (hebephrenic schizophrenia). Forma schizofrenii, w której występuje wyjątkowo daleko posunięta dezorganizacja zachowania; charakteryzuje ją niedostosowany afekt, wesołkowate, dziecinne zachowanie oraz inne poważne zaburzenia myślenia, afektu i zachowania. 
Hedonizm (hedonism). Doktryna, zgodnie z którą osobista przyjemność lub szczęście są jedynym dobrem i głównym celem w życiu.
Hermafrodyta (hermaphrodite). Jednostka, u której istnieje sprzeczność między wyglądem genitaliów a układem chromosomów płciowych, gonadami i wewnętrznymi strukturami rozrodczymi; jednostka, u której zróżnicowanie psychoseksualne nie jest kompletne.
Heteroseksualizm (heterosexuality). Zainteresowanie seksualne przede wszystkim osobnikami odmiennej płci.
Heurystyki (heuristies). Metody sprzyjające generowaniu nowych pomysłów podczas rozwiązywania problemów; techniki stosowane w próbach rozwiązania problemu.
Hierarchia potrzeb (hierarchy of needs). Zgodnie z teorią osobowości Maslowa, sposób zorganizowania wrodzonych potrzeb człowieka według pewnych priorytetów; aby zaczęły dominować potrzeby z wyższych poziomów w tej hierarchii, muszą najpierw zostać zaspokojone potrzeby znajdujące się na jej najniższych poziomach.
Hierarchia reakcji (response hierarchy). Uporządkowanie reakcji znajdujących się w repertuarze danej jednostki według prawdopodobieństwa, że wystąpią one w danej sytuacji; najbardziej prawdopodobne jest wystąpienie reakcji znajdujących się u szczytu tej hierarchii. 
Hiperfagia (hyperphagia). Zjadanie nadmiernej ilości pokarmu; występuje na przykład u zwierząt, u których dokonano lezji mózgowych; prowadzi do otyłości.
Hipnotyczne znieczulenie (hypnotic analgesia). Niewrażliwość na ból - pod wpływem sugestii osoby hipnotyzującej.
Hipnoza (Hypnosis). Zmieniony stan świadomości wywoływany różnymi technikami i charakteryzujący się głębokim odprężeniem, zwiększoną podatnością na sugestię, zmianami w poczuciu samokontroli i w poziomie motywacji.
Hipochondria (hypochondria). Neurotyczne zaabsorbowanie funkcjami swego organizmu i stanem swego zdrowia.
Hipoglikemia (hypoglycemia). Obniżony poziom cukru we krwi, na przykład po wstrzyknięciu insuliny.
Hipokamp (hippocamus). Podkorowa struktura mózgu, która ma decydujące znacznie dla pamięci świeżej i odgrywa ważną rolę w zachowaniu seksualnym.
Hipoteza (hypothesis). Prowizoryczne określenie związku między dwoma zjawiskami lub zmiennymi, często oparte na wynikach poprzednich obserwacji, które sprawdza się eksperymentalnie; niezbędne przy przewidywaniu, wyjaśnianiu i badaniu zachowania. Wyniki doświadczeń mogą hipotezę obalić lub potwierdzić, nigdy jednak nie można udowodnić jej prawdziwości w sposób ostateczny.
Hipoteza ciągłości (continuity hypothesis). Teoria, zgodnie z którą rozwiązywanie problemów jest w swej istocie procedurą stopniowego uczenia się, opartą na zachowaniu tych prób i błędów.
Hipoteza frustracji-agresji (frustration-aggression hypothesis). Teoria głosząca, że agresja jest popędem nabywanym jako bezpośrednia reakcja na frustrację; im większa frustracja, tym silniejsza wynikająca z niej agresywna reakcja.
Hipoteza nieciągłości (discontinuity hypothesis). Teoria, zgodnie z którą rozwiązywanie problemów polega przede wszystkim na wglądzie i reorganizacji percepcyjnej, rozwiązanie zaś odkrywa się od razu, a nie stopniowo.
Hipoteza zerowa (null hypothesis). Hipoteza głosząca, iż zmienna, którą się manipuluje, nie ma żadnego wpływu na mierzone zachowanie, że po oddziaływaniu eksperymentalnym nie będzie żadnej różnicy między grupą eksperymentalną a grupą kontrolną. Istnieją testy statystyczne, które pozwalają odrzucić bądź utrzymać w mocy hipotezę zerową (H0) 
Histeria. Zobacz Nerwica histeryczna.
Holistyczne podejście (holistic approach). W psychologii, sposób badania zachowania, zgodnie z którym pełne jego zrozumienie zapewnia analiza zachowania w kategoriach całego organizmu, a nie tylko w kategoriach jego funkcjonujących części.
Homeostaza (homeostasis). Złożony proces utrzymywania stałości wewnętrznego środowiska organizmu podczas jego kontaktów z otoczeniem, tak by chemiczna równowaga organizmu mogła być utrzymana, a potrzeby społeczne i biologiczne - zaspokojone; homeostaza na poziomie fizjologicznym jest przeważnie automatyczna.
Homoseksualizm (homosexuality). Zainteresowanie seksualne przede wszystkim osobnikami własnej płci.
Homunculus (homunculus). Zdaniem niektórych dawnych uczonych, miniaturowy człowieczek, znajdujący się w plemniku i potrzebujący tylko pożywienia oraz czasu, aby rozwinąć się w dorosłego człowieka.
Hybrydyzacja (hybridization). Kojarzenie się osobników niepodobnych pod względem genetycznym.


Id (id). W postulowanym przez Freuda podziale osobowości na trzy części, pierwotna część nieświadomości złożona z instynktownych biologicznych popędów, dla której charakterystyczne jest nieokiełznane, impulsywne poszukiwanie przyjemności.
Idiograficzne podejście (idiographic approach). W psychologii, sposób wyjaśniania natury ludzkiej, w którym zrozumienie osobowości jednostki możliwe jest dzięki skupieniu się na jej osobowości i na oddziałujących na nią specyficznych warunkach.
Iloraz inteligencji I.I. (intelligence quotient; IQ). Wskaźnik inteligencji, który oblicza się dzieląc wiek inteligencji (W.L.) danej jednostki (ustalony na podstawie uzyskanych przez nią wyników w znormalizowanym teście inteligencji) przez jej wiek życia (W.Ż.), a następnie mnożąc rzez 100. Iloraz inteligencji równy 100 uważa się za przeciętny.
Imprinting. Zobacz Wdrukowanie.
Impuls nerwowy (nerve impuls). Pobudzenie elektrochemiczne przekazywane wzdłuż neuronu lub łańcucha neuronów; za pośrednictwem impulsów nerwowych odbierana jest i przekazywana informacja w układzie nerwowym.
Instynkt (instinct). Wrodzony wzorzec zachowania, na który ćwiczenie nie ma wpływu; niezmienna sekwencja złożonych zachowań obserwatora u wszystkich osobników danego gatunku i wywoływana przez specyficzne bodźce przy pozornej nieobecności uczenia się.
Insulina (insulin). Hormon wydzielany przez trzustkę, który sprzyja rozkładaniu cukru znajdującego się w organizmie i utrzymuje stały poziom cukru we krwi.
Intelektualizacja (intellectualization). Proces czy mechanizm obronny, który zmniejsza lęk w zagrażającej sytuacji przez przekształcenie jej w abstrakcyjny problem lub wyjaśnienie jej w taki sposób, aby owo zagrożenie zmniejszyć.
Inteligencja (intelligence). Ogólna zdolność korzystania z doświadczeń; jest to złożona zdolność umysłowa, która obejmuje takie zdolności podstawowe, jak rozumienie słowne, wyobraźnia przestrzenna, zdolność rozumowania, zdolność posługiwania się liczbami; zgodnie z definicją operacyjną, inteligencja jest tym, co mierzą testy inteligencji.
Intencja paradoksalna (paradoxical intention). Technika stosowana w logoterapii (użyteczna w krótkotrwałym leczeniu pacjentów cierpiących na nerwicę natręctw i fobie), w której, aby uporać się z przewidywanym wystąpieniem lęku, zachęca się pacjenta do robienia lub wyobrażenia sobie właśnie tego, czego się on boi; podobna do terapii implozyjnej.
Interferencja proaktywna (proactive interference). Zakłócający wpływ materiału wyuczonego wcześniej na pamiętanie materiału przyswajanego później.
Interferencja retroaktywna (retroactive interference). Zakłócający wpływ materiału przyswojonego później na pamiętanie materiału wyuczonego uprzednio.
Interwencjoniści (interventionists). Ci, którzy żywią przekonanie, że badania psychologiczne powinno się przeprowadzać w warunkach kontrolowanych, w których można manipulować istotnymi zmiennymi - warunkami nie występującymi lub niemożliwymi do zaobserwowania i kontrolowania w naturalnych okolicznościach.
Introspekcyjna analiza (introspective analysis). Staranna autoobserwacja treści psychicznych. Technika wyszukiwania pierwotnych elementów doświadczenia psychicznego, wolnych od zniekształceń wynikających z nadawanych znaczeń oraz interpretacji.
Izolowanie (isolation). Mechanizm obronny i technika dehumanizacji, za pomocą której konkretne działanie lub sytuację można oddzielić od życia, wartości i uczuć danej jednostki; zwane także szufladkowaniem (compartmentalization).


Ja idealne (ego ideal). Pogląd danej jednostki na to, jakiego rodzaju osobą być powinna; część superego.
Jasnowidzenie (clairvoyance). Forma spostrzegania pozazmysłowego, w której dana osoba poznaje rzekomo pewien zewnętrzny obiekt bez pomocy narządów zmysłowych.
Jądro (nucleus). Wyspecjalizowana protoplazma znajdująca się w każdej komórce, kierująca procesami zachodzącymi w cytoplazmie. Zawiera chromosomy i jest niezbędną dla reprodukcji komórki. Również zgrupowanie ciał komórkowych neuronów, zlokalizowane w obrębie ośrodkowego układu nerwowego.
Jodopsyna (iodopsin). Fotopigment znajdujący się w czopkach oka; trzy typy jodopsyny są wrażliwe na różne długości fal świetlnych, odpowiadające światłu niebieskiemu, zielonemu i czerwonemu.
Joga (yoga). System wierzeń i praktyk, których celem jest osiągnięcie zjednoczenia jaźni z Najwyższą Rzeczywistością; w popularnym ujęciu jest to forma medytacji, w której główną rolę odgrywa przyjmowanie określonych postaw ciała i ćwiczenia oddechowe.


Kara (punishment). Bodziec awersyjny, który następuje po niepożądanej reakcji, powodując zmniejszenie częstości tej reakcji.
Karłowatość deprywacyjna (deprivation dwarfism). Zahamowanie rozwoju fizycznego i dojrzewania u dzieci w następstwie deprywacji emocjonalnej.
Karmienie pozorne (sham feeding). Procedura eksperymentalna stosowana w badaniach nad regulacją ilości przyjmowanego pokarmu; wymaga ona operacji chirurgicznej, w wyniku której pokarm podawany zwierzęciu do pyska jest wprawdzie przeżuwany i połykany, ale przez otwór w przełyku wydostaje się na zewnątrz i nie dociera do żołądka.
Katatonia (catatonia). Typ schizofrenii, której objawami są bezruch i brak reakcji (osłupienie, stupor), egzystencja na poziomie wegetacji; stosunkowo dobrze poddaje się leczeniu.
Kinezjetyka (kinesics). Dyscyplina zajmująca się badaniem ekspresji niewerbalnej - pozycji ciała, postawy gestów i ruchów.
Kolbki synaptyczne. Zobacz Stopki końcowe.
Kolejne odtwarzanie (successive reproduction). Technika stosowana w badaniach nad pamięcią wytwórczą; osoba badana kilkakrotnie odtwarza materiał mający pewien sens; za każdym razem rejestruje się wszelkie przekształcenia pierwotnego materiału.
Komórka jajowa (ovum). Żeńska gameta (komórka rozrodcza).
Komórki dwubiegunowe (bipolar cells). Pierwsze neurony drogi wzrokowej; przewodzą informacje z pręcików i czopków do komórek zwojowych.
Komórki przeciwstawne (opponent cells). Komórki w ciele kolankowatym bocznym, które umożliwiają widzenie barw; dzieje to się w wyniku swego rodzaju odejmowania impulsów otrzymywanych z jednego typu czopków od impulsów otrzymywanych z czopków innego typu.
Komórki rozrodcze. Zobacz Gamety.
Komórki zwojowe (ganglion cells). Neurony, które łączą komórki dwubiegunowe z punktami przekaźnikowymi w mózgu.
Komplementarność (complementarity). (W odniesieniu do cech osobowości) posiadanie takich cech, które uzupełniają cechy innej osoby (tzn. pasują do nich), właściwość, które czynią daną osobę atrakcyjną dla innej.
Komunikowanie się; porozumiewanie się (communication). Proces, dzięki któremu jednostka przekazuje i otrzymuje informacje.
Konflikt (conflict). Jednoczesne występowanie sprzecznych czy wzajemnie wykluczających się impulsów, pragnień lub niemożliwych do pogodzenia reakcji (np. zbliżyć się i oddalić).
Konflikty intrapsychiczne (intrapsychic conflicts). Termin psychoanalityczny odnoszący się do konfliktów między id, superego i ego.
Konformizm (conformity). Dostosowanie własnych postaw, uznawanych wartości i (lub) zachowania do norm społecznych.
Konfrontacja (confrontation). Kulminacyjna faza w sekwencji agresywnej interakcji; wynik eskalacji.
Konopie indyjskie (cannabis indica). Grupa środków psychotropowych obejmująca marihuanę i haszysz; wpływ tych środków na zachowanie jednostki zależy w dużej mierze od czynników osobowościowych i społecznych. Nie wywołują one uzależnienia fizjologicznego. 
Kontrola bodźcowa (stimulus control). Sprawowanie kontroli nad występowaniem reakcji za pomocą sygnału (S) informującego w wiarygodny sposób, że dostępny jest czynnik wzmacniający; reakcje regularnie występują w obecności tego bodźca, natomiast nie występują, gdy go brak.
Kontrola poznawcza (cognitive control). Sprawowanie kontroli nad reakcjami motywacyjnymi, emocjonalnymi, percepcyjnymi i behawioralnymi za pomocą procesów poznawczych, takich jak redukowanie dysonansu poznawczego, znajdowanie możliwości wyboru, eliminowanie poczucia bezradności, wiara w placebo lub tabu.
Kontrprzeniesienie (countertransference). Proces, podczas którego u analityka rozwijają się osobiste uczucia wobec pacjenta, ze względu na spostrzegane podobieństwo pacjenta do znaczących osób z życia terapeuty; odwrotność zwykłego procesu przeniesienia.
Konwergencja (convergence). Proces rozchodzenia się impulsów w układzie nerwowym, dzięki któremu impulsy z wielu neuronów lub komórek receptorowych dochodzą do tego samego neuronu lub efektora.
Kora mózgowa (cortex). Cienka, szarawa warstwa tkanki pokrywająca mózgowie; składa się z neuronów i ich wypustek; odgrywa istotną rolę w wyższych procesach psychicznych; zwana także istotą szarą.
Kora nadnerczy (adrenal cortex). Zewnętrzna część gruczołów nadnerczy, która wydziela kortykosterydy, hormony odgrywające ważną rolę w reakcjach fizjologicznych na długotrwały stres.
Kora nowa (neocortex). Kora mózgu, która wytworzyła się w wyniku ewolucji u wyższych gatunków zwierząt; najbardziej rozwinięta u ludzi.
Kora potylityczna (occipital cortex). Płat w tylnej części mózgu, który odbiera impulsy z nerwu ocznego.
Korelacja (correlation). Miara siły związku między dwoma zmiennymi; przewidywania w psychologii oparte są zwykle na korelacji między dwoma zachowaniami, a nie między warunkami bodźcowymi a zachowaniem. Ścisłą ilościową miarą wielkości korelacji jest współczynnik korelacji.
Kortykosterydy (cortin). Hormony wydzielane przez korę nadnerczy, które współdziałają z ACTH (hormonem przysadki mózgowej) i są ważnym czynnikiem w fizjologicznej reakcji na długotrwały stres.
Kosteczki słuchowe (ossicles). Trzy małe kosteczki (młoteczek, kowadełko i strzemiączko) znajdujące się w uchu środkowym.
Kozioł ofiarny (scapegoat). Obiekt inny niż pierwotne źródło frustracji, na który została przemieszczona agresja; nawiązując do uprzedzeń trzeba wspomnieć, że właśnie mniejszości oraz niepopularne, bezsilne grupy są ulubionymi obiektami przemieszczonej agresji.
Krzywa normalna, k. dzwonowa (normal curve). Wykres rozkładu normalnego w idealnym przypadku, w którym średnia, mediana i modalna są sobie równe, rozkład zaś jest symetryczny względem tej wartości centralnej.
Kryzys tożsamości (identity crisis). Okres przejściowy charakteryzujący się chaosem, eksperymentowaniem i emocjonalnością; występuje wtedy, gdy uprzedni pogląd na siebie samego przestaje być odpowiedni w zmieniającej się sytuacji życiowej (jak w okresie dorastania lub w wieku średnim).
Kształtowanie zachowania (shaping). Forma warunkowania sprawczego, stosowana podczas ćwiczenia, w której najpierw nagradza się wszystkie reakcje zbliżone choć trochę do reakcji pożądanej, następnie zaś jedynie najdoskonalsze jej przybliżenia (dopóki nie zostanie nabyta pożądana reakcja).
Kwestionariusz osobowości (self-inventory). Narzędzie do pomiaru cech osobowości wymagające od osoby badanej podawania informacji o sobie; jego trafność jest ograniczona przez to, że badani nie w pełni rozumieją samych siebie, a ponadto pragną przedstawić się w lepszym świetle.


Latencja reakcji (latency of response). Miara siły warunkowania oparta na długości czasu upływającego między pojawieniem się bodźca warunkowego a wystąpieniem reakcji.
Latencji stadium (latent stage). W teorii freudowskiej czwarte stadium rozwoju psychoseksualnego, w którym świadome zainteresowania seksualne występują w mniejszym stopniu.
Leczenie elektrowstrząsami (electroconvulsive shock treatment). Forma terapii wstrząsowej stosowana w celach psychoterapeutycznych dla złagodzenia depresji lub innych poważnych objawów; w terapii tej przez głowę (mózg) pacjenta przepuszcza się przez krótki czas prąd elektryczny, powodując w ten sposób chwilową utratę świadomości i drgawki.
Ledwo dostrzegalna różnica; Idr (just noticeable difference; jnd).  Minimalna zmiana bodźca fizycznego niezbędna dla spostrzeżenia (przynajmniej w 75% przypadków), że bodziec uległ zmianie.
Leki antypsychotyczne (antipsychotic drugs). Leki, które tłumią reakcje psychotyczne; stosowane w chemioterapii.
Leukotomia (lobotomia) przedczołowa (prefrontal lobotomy). Operacja psychochirurgiczna polegająca na przecięciu włókien nerwowych łączących struktury międzymózgowia z czołowymi płatami mózgu, dokonywana w celu wyeliminowania związku procesów intelektualnych z procesami emocjonalnymi, które zwykle im towarzyszą; obecnie rzadko stosowana.
Lezja (lesion). Zniszczenie części mózgu (lub innej tkanki) przypadkowo, w wyniku choroby lub podczas operacji o charakterze eksperymentalnym lub medycznym.
Lęk niezwiązany z określoną przyczyną (free-floating anxiety). Lęk, którego nie można powiązać z żadną konkretną przyczyną czy sytuacją; występuje w nerwicy lękowej.
Lęk obiektywny (objective anxiety). Zobacz Strach.
Libido (libido). Szeroko pojęte siły seksualne; energia twórczego popędu zwanego przez Freuda Erosem.
Lobotomia przedczołowa. Zobacz Leukotomia przedczołowa.
Logoterapia (logotherapy). Szkoła terapii egzystencjalnej zapoczątkowana przez Frankla, której zwolennicy koncentrują się na potrzebie dostrzegania sensu we własnym życiu; kładzie nacisk na wartości duchowe i etyczne, odwołuje się do pojęć wykraczających poza materialne aspekty środowiska życiowego pacjenta. 
Losowe pobieranie próbki (random sampling). Metoda pobierania próbki w taki sposób, aby każdy członek danej populacji miał takie same szanse znalezienia się w tej próbce i aby prawdopodobieństwo wybrania każdego z nich było niezależne od tego, czy jakiś inny członek został wybrany, czy nie. Warunek prawidłowego przydzielenia osób badanych do grup eksperymentalnych.
LSD (lysergic acid diethylamide). Środek halucynogenny, który może powodować występowanie niezwykle plastycznych wyobrażeń, halucynacji, może powodować dezorganizację procesów myślowych i wywoływać objawy zaburzeń psychicznych; stosowany także w psychoterapii i w przypadku nieuleczalnych chorób.


Łaknienie z niedostatku (deficiency cravings). Odczuwanie głodu określonego rodzaju pokarmu, wynikające z biologicznych potrzeb i niedoborów.
Łuk czuciowo-ruchowy (sensory-motor arc). Jednostka funkcjonalna, a zarazem podstawowa struktura układu nerwowego; łańcuch składający się z neuronu czuciowego odbierającego bodźce zmysłowe, z jednego lub więcej neuronów pośredniczących w rdzeniu kręgowym lub w mózgu oraz z neuronu ruchowego, który inicjuje reakcje behawioralne.


Magazyn informacji sensorycznej (sensory information store). System pamięciowy, który przechowuje informacje sensoryczne przez bardzo krótki czas, zwykle krócej niż przez pół sekundy.
Makiaweliści (machiavellians). Jednostki, które podzielają zbiór przekonań Machiavellego dotyczących taktyki manipulacji ludźmi i względności norm moralnych; osoby, które uzyskują wysokie wyniki na skali makiawelizmu.
Maltretowane dzieci (battered children). Dzieci mocno bite, torturowane i okaleczane przez swych rodziców, rodzeństwo lub innych krewnych.
Mantra (mantra). Układ dźwięków, nad którym można medytować; w medytacji transcendentalnej, sylaby zaczerpnięte ze świętych ksiąg hinduskich, powtarzane cicho przez medytujących, po to, by usunąć ze świadomości wszelkie inne myśli.
Mapy poznawcze (cognitive maps). Wiedza o związkach między bodźcami (S-S), która pomaga danej jednostce ustrukturalizować zachowanie i nadać mu celowy charakter; pojęcie stosowane przez Tolmana dla wyjaśnienia oczekiwań i uczenia się bez reagowania.
Masochizm (masochizm). Dewiacyjne zastosowanie motywacji bólowej; pragnienie zadawania bólu sobie samemu lub doznawania bólu z rąk innych; postać bólu jako przyjemności.
Mechanistyczne podejście (mechanistic approach). W ujęciu kartezjańskim, sposób badania procesów fizjologicznych oparty na założeniu, że percepcja i inne procesy organiczne są zdeterminowane w sposób mechanistyczny, to znaczy, że można je całkowicie wyjaśnić za pomocą naukowych praw fizycznych i chemicznych.
Mechanizm obronny; mechanizm obronny ja (defense mechanism; 
„ego-defense mechanism). Nieświadomy sposób radzenia sobie z sytuacjami, które wzbudzają lęk lub zagrażają samoocenie; do mechanizmów obronnych należą między innymi: przemieszczenie, projekcja, racjonalizacja, regresja i sublimacja.
Mediana (median). Jedna z miar tendencji centralnej; gdy wszystkie wyniki uporządkuje się według ich wartości liczbowej, to środkowy wynik jest medianą (tak więc tyle samo wyników będzie wyższych, co i niższych od mediany).
Medytacja (meditation). Świadome skoncentrowanie uwagi i świadomości na jednym, niezmiennym źródle bodźców (przez dość długi okres); często praktykowane w nadziei, że ułatwi osiągnięcie zmienionego stanu świadomości, w którym można obserwować u siebie spontaniczne ciągi doznań.
Medytacja transcendentalna (transcendental meditation; TM). Forma medytacji polegająca na wielokrotnym recytowaniu mantry i koncentrowaniu na niej uwagi (w oderwaniu od zewnętrznego materialnego świata).
Meskalina (mescaline). Środek halucynogenny otrzymywany z pewnych odmian kaktusa (o działaniu podobnym do adrenaliny); badania wykazały, że środek ten może wywoływać stan podobny do schizofrenii; stosowany do celów terapeutycznych.
Mesmeryzm (mesmerism). Wywoływanie stanu hipnotycznego metodą Mesmera; wierzono, że wchodzi tu w grę magnetyzm zwierzęcy: rzekoma energia duchowa pochodząca z planet, którą można gromadzić i przekazywać innym ludziom w celach terapeutycznych.
Metabolizm (metabolism). Procesy chemiczne, które zachodzą we wszystkich żywych tkankach; procesy te polegają między innymi na rozpadzie substancji odżywczych, w wyniku czego powstaje energia niezbędna dla przebiegu procesów życiowych.
Metafora; przenośnia (metaphor). Figura stylistyczna w której słowo oznaczające pewien przedmiot lub działanie użyte jest zamiast innego tak, by sugerować między nimi podobieństwo; jest to porównanie pośrednie (np.  „Jestem maszyną lub komputerowy umysł). 
Metoda eksperymentalna (experimental method). Wysoce sformalizowana odmiana metody naukowej, za pomocą której dąży się do ustalenia związku przyczynowego między zmienną niezależną a zmienną zależną. Hipotezę sprawdza się w ściśle określonych warunkach, kontrolowanych w celu wyeliminowania wpływu wszelkich nieprzewidzianych zmiennych. Metoda Mutta i Jeffa (Mutt-and-Jeff approach). Taktyka stosowana w przesłuchaniach policyjnych: sympatyczny funkcjonariusz śldczy prowadzi przesłuchanie na zmianę z funkcjonariuszem okrutnym i bezlitosnym (którego zadaniem jest zwiększenie zaufania osoby przesłuchiwanej do przyjaznego policjanta i wywołanie u niej gotowości do przyznania się wobec niego do winy).
Metoda potencjałów wywołanych (evoked potential). Metoda badania czynności mózgu polegająca na podawaniu bodźca w celu wywołania impulsów nerwowych, które wędrują do mózgu. Pojawienie się impulsu jest rejestrowane za pomocą elektrod umieszczonych na powierzchni głowy lub wprowadzonych do mózgu.
Metoda prób i błędów (trial and error). Metoda rozwiązywania problemu polegająca na wypróbowywaniu różnych możliwości i odrzucaniu tych, które okazują się niezadawalające.
Miara zmienności (measure of variability). Statystyka określająca, jak bardzo rozciągnięty jest dany rozkład, jak dalece wyniki odbiegają od przeciętnego, typowego wyniku.
Mikroskopowy poziom analizy (microscoic level). W psychologii, poziom analizy, w wypadku którego uwaga badacza skupia się na najdrobniejszych wykrywalnych elementach i zjawiskach występujących w organizmie (na przykład badania reakcji biochemicznych w komórce mózgu).
Mnemometr (memory drum). Aparat używany w badaniach nad pamięcią do kolejnego prezentowania (przez określony czas) poszczególnych elementów zapamiętywanego materiału.
Mnemoniczne strategie (mnemonic strategies). Techniki kodowania materiału, który ma być przyswojony, w sposób umożliwiający bardziej skuteczne zapamiętywanie.
Modalna (mode). Jedna z miar tendencji centralnej; wynik najczęściej występujący w danym rozkładzie wyników.
Model (model). Struktura teoretyczna, opracowana w jednej dziedzinie wiedzy, lecz zastosowana w innej, w celu przedstawienia danego zjawiska czy procesu w sposób jaśniejszy i bardziej zrozumiały; model ułatwia zrozumienie, aczkolwiek sam w sobie nie jest wyjaśnieniem.
Model medyczny (medical model). Model psychopatologii, w którym zaburzenia zachowania natury psychologicznej czy psychiatrycznej rozpatruje się jako objawy stanu chorobowego.
Modelowanie zasad (rule modeling). Proces modelowania, dzięki któremu jednostki uczą się kierować swym zachowaniem za pomocą tych samych podstawowych zasad, którymi kierował się obserwowany przez nie model, nawet jeśli mają do czynienia z odmienną na pozór sytuacją.
Modyfikacja zachowania (behavior modification). Terapia behawioralna polegająca na stosowaniu procedur warunkowania sprawczego, w której nacisk kładzie się na obserwację zachowania, ustalanie kontrolujących je zmiennych oraz odpowiednie stosowanie wzmocnień.
Molarny poziom analizy (molar level). W psychologii, poziom analizy, w wypadku którego przedmiotem zainteresowania badacza jest funkcjonowanie całego organizmu lub całych systemów w obrębie organizmu (na przykład badanie zaburzeń emocjonalnych lub wandalizmu).
Molekularny poziom analizy (molecular level). W psychologii, pośredni poziom analizy; zainteresowanie badacza skupia się tu na procesach mniej szczegółowych, niż w wypadku procesów badanych na poziomie mikroskopowym, aczkolwiek nadal bada się małe, policzalne jednostki (na przykład badanie specyficznego wzorca fal mózgowych, występujących w czasie wzbudzenia, lub czasów reakcji na bodźce).
Morfem (morpheme). Najmniejsza jednostka mowy, która ma określone znaczenie; składa się z pewnej kombinacji fonemów, może, lecz nie musi, być słowem. 
Morfologia (morphology). Analiza i opis tworzenia słów w języku; przedmiotem zainteresowania są w niej jednostki znaczenia (morfemy).
Motyw (motive). Stan, zwykle o charakterze społecznym lub psychicznym, który służy ukierunkowaniu zachowania jednostki ku pewnemu celowi.
Motywacja wynikająca z niedoboru (deficiency motivation). Motywacja, w przypadku której dążeniem jednostki nie jest własny rozwój, ale przywrócenie swej fizycznej lub psychicznej równowagi.
Motywacja wzrostu (growth motivation). Motywacja, w przypadku której jednostka stara się wyjść poza poziom osiągnięty w przeszłości, próbuje rozwijać swe potencjalne możliwości.
Motywacja związana z podnietą (incentive motivation). Pobudzenie organizmu do działania przez oczekiwanie nagrody lub kary.
Motywacyjna teoria zapominania (motivational theory of forgetting).  Teoria głosząca, że zapominanie może być intencjonalne, że dana jednostka zapomina lub zapamiętuje poszczególne informacje w zależności od tego, jaką wartość i znaczenie mają one dla niej.
Móżdżek (cerebellum). Część mózgu, która zawiaduje koordynacją ruchów niezbędnych dla utrzymania równowagi i postawy ciała oraz innymi mechanizmami regulacyjnymi w niewielkim stopniu związanymi z funkcjami psychicznymi.
Mutacje (mutations). Zmiany w zasadach tworzących cząsteczkę DNA, które powodują przekształcenie się odpowiadającej im sekwencji aminokwasów w białkach formowanych przez tę cząsteczkę; mogą być pożyteczne, szkodliwe lub wręcz śmiertelne dla samej jednostki lub jej potomstwa.
Myślenie (thinking). Zachowanie polegające na operowaniu pojęciami; obejmuje procesy symboliczne, przedstawieniowe i transformacyjne.
Myślenie autystyczne (autistic thinking). Myślenie jako cel sam w sobie, a nie jako środek prowadzący do celu; zdeterminowane głównie przez potrzeby czy pragnienia danej jednostki, jak w marzeniach na jawie.
Myślenie grupowe (groupthink). Sposób podejmowania decyzji występujących w grupach o dużej spójności, w których troska o jednomyślność ogranicza zdolności krytycznego myślenia i realistycznej oceny możliwych sposobów działania.
Myślenie przedoperacyjne (preoperational thought). Drugie z wyodrębnionych przez Piageta stadiów rozwoju poznawczego (od 2 do 7 roku życia); charakterystyczne dla tego stadium jest rozumowanie transdukcyjne, egocentryzm i rozwój zdolności do przedstawiania świata zewnętrznego za pomocą symboli.
Myślenie realistyczne (realistic thinking). Myślenie ściśle związane z rzeczywistością; liczące się z cechami i wymaganiami obiektywnej, zewnętrznej sytuacji.
Myślenie twórcze (creative thinking). Nieskrępowane, nacechowane wyobraźnią myślenie; wykorzystywane do rozwiązywania rzeczywistych problemów.


Nadużywanie środka psychotropowego (drug abuse). Zażywanie go w takich ilościach, że przynosi to szkodę zdrowiu danej jednostki lub jej przystosowaniu ekonomicznemu czy społecznemu; trzecie stadium nałogu.
Nadzieja (hope). Pojęcie poznawcze dotyczące oczekiwania, iż własne zachowanie wywoła zmiany w środowisku.
Nagrody wewnętrzne (intrinsic rewards). Przyjemne następstwa pojawiające się wewnątrz danej jednostki w wyniku jej zachowania; zwiększają prawdopodobieństwo wystąpienia tego zachowania w przyszłości bez konieczności stosowania wzmocnienia zewnętrznego.
Nagrody zewnętrzne (extrinsic rewards). Dostarczone z zewnątrz wzmocnienie (pieniądze, pochwała itd.), które może być przyznane danej jednostce i które początkowo wpływa na wzmożenie poprzedzającego je zachowania; jak jednak wykazano, zewnętrzne nagrody obniżają wewnętrzną motywację do wykonywania zadania ze względu na jego własną wartość.
Naiwne (ukryte) teorie osobowości (naive personality theories).  Nieformalne, potoczne opinie, które są pochopnymi ocenami osobowości, oparte głównie na intuicji, zdrowym rozsądku i nie kontrolowanej obserwacji siebie samego i innych ludzi.
Naiwny realizm (naive realism). Stadium rozwoju poznawczego, w którym jednostka do tego stopnia polega na spostrzeżeniach, że ufa pozorom i uznaje je za jedyną rzeczywistość.
Nałóg (addiction). Fizyczne lub psychiczne uzależnienie od takich substancji, jak narkotyki, alkohol, tytoń lub pokarmy; prowadzące do kompulsywnego zachowania, nad którym dana jednostka nie ma wystarczającej, dowolnej kontroli.
Napięcie wspierające (promotive tension). Napięcie powiązane z dążeniem innej osoby do celu; wzbudzone napięcie wspierające może być wyjaśnieniem altruizmu.
Napiętnowanie (stigmatization). Określenie kogoś jako odbiegającego od normy; wyróżnienie danej jednostki lub grupy jako obiektu dyskryminacji przez przypisanie jej niepożądanej cechy lub przeszłości, jak na przykład w przypadku byłych więźniów lub pacjentów szpitali psychiatrycznych.
Narkomania (drug addiction). Uzależnienie od któregoś z wielu środków psychotropowych; często występuje zarówno uzależnienie fizyczne, jak i uzależnienie psychiczne.
Narząd Cortiego (organ of Corti). Receptor słuchowy, mieszczący się w ślimaku; zawiera komórki włoskowe, z których biorą początek włókna nerwu słuchowego.
Nastawienie (set). Gotowość do reagowania na daną sytuację bodźcową w pewien określony sposób.
Nastawienie realistyczne (reality orientation). Sposób patrzenia na świat, który uwzględnia naszą potrzebę zrozumienia przewidywalnych reakcji (tak, aby nadać stabilność i sens naszemu życiu); zakładane przez teorię atrybucji.
Nastawienie regulacyjne (control orientation). Sposób patrzenia na świat, który uwzględnia naszą potrzebę przewidywania ważnych zdarzeń w życiu i wpływanie na nie; zakładane przez teorię atrybucji.
Naśladowanie modeli (imitation of models). Może być formą terapii behawioralnej, w której dana jednostka przyswaja sobie nowe zachowania przez obserwację i naśladowanie modela.
Natręctwa myślowe; obsesje (obsessions). Uporczywe i irracjonalne myśli, zwykle nieprzyjemne, które pojawiają się w świadomości i których nie można z niej dowolnie usunąć. Zobacz także Nerwica natręctw.
Natywiści (nativists). Psychologowie, którzy utrzymują, że natura ludzka jest zdeterminowana przez wrodzone, dziedziczne czynniki; są oni przekonani, że jedynie środowisko rozwija naturę, która jest zdeterminowana genetycznie.
Negatywny czynnik wzmacniający (negative reinforcer). Czynnik wzmacniający, którego usunięcie zwiększa prawdopodobieństwo, iż reakcja, po jakiej następuje, wystąpi znowu w podobnych okolicznościach.
Nerwica (neurosis). Zaburzenie emocjonalne, dla którego charakterystyczne są utrata radości życia i silny lęk. Pacjent nie zdaje sobie sprawy z prawdziwych uwarunkowań lęku ani z nadużywania mechanizmów obronnych przeciw lękowi.
Nerwica depresyjna (depressive neurosis). Typ nerwicy, dla którego charakterystyczne jest reagowanie przesadnym smutkiem i depresją na stratę lub zagrażającą stratę; reakcja będąca przejawem bezradności i poczucia poniesionej klęski.
Nerwica eksperymentalna (experimental neurosis). Nerwica rozwijająca się u zwierząt, gdy proces warunkowania wiąże się z długotrwałym stresem i nie dającymi się uniknąć konfliktami.
Nerwica histeryczna (hysterical neurosis). Typ nerwicy, dla którego charakterystyczna jest niedowolna, psychogenna utrata funkcji ruchowej lub sensorycznej, na przykład paraliż lub utrata pamięci. Zobacz także Reakcja konwersyjna.
Nerwica lękowa (anxiety neurosis). Typ nerwicy, dla której charakterystyczne są chroniczny lęk i niepokój; odczuwany lęk z niczym się nie wiąże, to jest nie można go przypisać jakiejś określonej przyczynie czy czemuś, co inne osoby w tej samej sytuacji uważałyby za zagrażające.
Nerwica natręctw; n. obsesyjno-kompulsywna; n. anankastyczna (obsessive-compulsive neurosis). Forma nerwicy, dla której charakterystyczne jest występowanie lęku, z towarzyszącymi mu uporczywymi niepożądanymi myślami i (lub) poczuciem przymusu ciągłego powtarzania czynności o charakterze rytualnym.Nerwica półgłodowa (semistarvation neurosis). Objawy psychiczne, które występują w wyniku długotrwałego, znacznego niedożywienia; charakterystyczne są tu: apatia i drażiwość.
Nerw słuchowy (auditory nerve). Nerw, który przenosi impulsy z receptorów słuchowych znajdujących się w uchu wewnętrznym do mózgu.
Neuroglej (neuroglia). Sieć komórek, które otaczają, odżywiają i chronią neurony; zwana także komórkami glejowymi.
Neurologia (neurology). Dziedzina medycyny zajmująca się funkcjonowaniem mózgu i całego układu nerwowego oraz ich schorzeniami.
Neuron (neuron). Pojedyncza komórka nerwowa; podstawowy element układu nerwowego.
Neurony pośredniczące (interneurons). Komórki nerwowe z wieloma krótkimi dendrytami i krótkim aksonem; który często ma rozgałęzienia zwane kolateralami; w obrębie ośrodkowego układu nerwowego wiążą ze sobą wejściowe drogi czuciowe i wyjściowe drogi ruchowe; zwane są także neuronami asocjacyjnymi.
Niepamięć wsteczna (retrograde amnestia). Defekt pamięci, na który cierpią pacjenci z uszkodzeniem hipokampa; polega na tym, że stare nawyki i wydarzenia pamięta się dobrze; natomiast nowsze zdarzenia są zapamiętywane gorzej; może być spowodowany urazem głowy lub elektrowstrząsami.
Niepoczytalność (insanity). Pojęcie prawne, stosowane w odniesieniu do każdego stanu psychicznego, który czyni daną jednostkę niezdolną do dokonywania ocen moralnych, wskutek czego nie może ona odpowiadać przed prawem za swe czyny.
Nieśmiałość (shyness). Świadomość własnej niezdolności do podjęcia działań o charakterze społecznym (które pragnie się podjąć i których sposób wykonania jest nam znany); subiektywny stan zależny od tego, w jaki sposób dana jednostka określa występujący u siebie zbiór reakcji.
Nieświadome (unconscious). To, z czego człowiek nie zdaje sobie sprawy w racjonalny sposób; w teorii freudowskiej, ta część psychiki, która jest składnicą wypartych konfliktów i pragnień niedostępnych bezpośrednio świadomości.
Nieświadomość zbiorowa (collective unconscius). W teorii Junga, ta część nieświadomości jednostki, która jest odziedziczona, ukształtowana ewolucyjnie oraz wspólna dla wszystkich osobników należących do danego gatunku; rodzaj gatunkowego magazynu pamięci, leżącego głębiej niż nieświadomość jednostkowa.
Niewyrażalność (ineffability). Często opisywana cecha charakteryzująca zmieniony stan świadomości; niemożność ujęcia w słowa, przekazania, opisania swych doznań.
Niezmienniki funkcjonalne (functional invariants). Pojęcie stosowane w teorii rozwoju poznawczego Piageta; główne wyznaczniki rozwoju intelektualnego. Są to podstawowe sposoby wchodzenia w interakcje ze środowiskiem, dzięki którym można dostosować zachowanie do uprzednich doświadczeń, jak również poddać je modyfikacjom tak, aby mogło sprostać nowym zadaniom intelektualnym. Najważniejszymi niezmiennikami funkcjonalnymi są asymilacja i akomodacja. 
Nomotetyczne podejście (nomothetic approach). W psychologii, sposób wyjaśniania natury ludzkiej polegający na ustalaniu ogólnych zależności między zachowaniem a jego uwarunkowaniami; zakłada się, że zależności te dotyczą wszystkich osobników.
Noradrenalina, norepinefryna (noradrenmaline, norepinephryne). Hormon wydzielany przede wszystkim przez wewnętrzną część gruczołów nadnerczy (rdzeń nadnerczy), zwłaszcza podczas występowania silnych emocji (związanych na przykład z reakcjami gniewu); powoduje szereg zmian fizjologicznych, między innymi skurcz podskórnych naczyń krwionośnych.
Normalizacja narzędzia pomiarowego (standardized measuring device).  Procedura stosowana w celu uzyskania użytecznego narzędzia pomiarowego, polegająca na zbadaniu nim dużej grupy osób reprezentatywnych dla populacji, dla której narzędzie to jest przeznaczone; później stosuje się je w ten sam sposób wobec wszystkich osób badanych i w tych samych warunkach, tak aby można było dokonywać porównań.
Normalny (normal). Zgodny (pod względem oczekiwanych reakcji czy uznawanych wartości) z tym, co ogólnie przyjęte - czyli z normą; słowo używane również dla określenia zdrowego, właściwego przystosowania.
Norma odpowiedzialności społecznej (social responsibility norm). Norma, zgodnie z którą ludzie powinni pomagać osobom zależnym od nich i potrzebującym ich pomocy.
Norma wzajemności (reciprocity norm). Norma głosząca, że człowiek powinien postępować wobec innej osoby tak, jak ona wobec niego postępuje.
Normy (norms). Standardy oparte na wynikach pomiarów przeprowadzonych na dużej grupie ludzi; stosowane dla porównywania wyniku standaryzowanego, uzyskanego przez daną jednostkę, z uzyskanymi przez inne osoby w określonej grupie. Zobacz także Normy społeczne.
Normy społeczne (social norms). Ustalone przez daną grupę standardy określające, które zachowania w danej sytuacji można zaakceptować, a które są niewłaściwe.
Nozologia (nosology). Usystematyzowane nazewnictwo i klasyfikacja chorób; umożliwia bardziej rzetelną diagnozę i ujednolicone leczenie.


Objaw (symptom). Dowód lub oznaka choroby.
Obrona percepcyjna (perceptual defense). Selektywność spostrzegania spowodowana czynnikami emocjonalnymi i motywacyjnymi; nieświadome „odsiewanie lub błędne spostrzeganie bodźców nieprzyjemnych, zagrażających lub stanowiących społeczne tabu.
Obsesja. Zobacz Natręctwa myślowe.
Obszar zmienności (range). Najprostrza miara zmienności; różnica między najniższym a najwyższym wynikiem pomiaru.
Obwodowy układ nerwowy (peripheral nervous system). System włókien nerwowych łączących receptory z ośrodkowym układem nerwowym lub też łączących ośrodkowy układ nerwowy z mięśniami i gruczołami (efektorami).
Ocena (appraisal). Oszacowanie znaczenia bodźca; może pobudzić organizm do działania; ocena pierwotna określa potencjalne zagrożenie, ocena wtórna polega na oszacowaniu możliwych sposobów poradzenia sobie ze spostrzeganym zagrożeniem.
Oczekiwanie (expectancy). Przewidywanie przyszłych zdarzeń na podstawie przyszłych doświadczeń i obecnych warunków bodźcowych; Tolman uważał oczekiwanie osiągnięcia celu za warunek konieczny każdej czynności dowolnej.
Odchylenie standardowe (standard deviation). Miara przeciętnego w danej grupie odchylenia wyników od średniej; równa pierwiastkowi kwadratowemu z wariancji.
Odkorowanie (decortication). (W niektórych przypadkach) chirurgiczne usunięcie mózgu lub oddzielenie do od rdzenia kręgowego.
Odporność na wygaszanie (resistance to extinction). Miara siły warunkowania oparta na trwałości reakcji warunkowej w czasie wygaszania, czyli na liczbie prób potrzebnych do wygaszania tej reakcji.Odprogramowanie (deprogramming). Systematyczne działanie mające zmusić daną jednostkę do wyrzeczenia się przez nią przekonań, zwykle nowo nabytych, które uważa się za wpojone (zaprogramowane) pod przymusem.
Odruch (reflex). Swoista, automatyczna reakcja angażująca jedynie część organizmu, taka jak ślinienie się lub odruch chwytania u niemowlęcia; niewyuczone reakcje wywoływane przez bodźce, ważne dla przetrwania organizmu.
Odwrażliwianie (desensitization). Proces wygaszania zachodzący podczas terapii behawioralnej, w którym bodźce tracą swą zdolność wywoływania lęku dzięki temu, że pacjenta niejako oswaja się z nimi, podając najpierw bodźce najsłabsze i stopniowo przechodząc do bodźców coraz silniejszych.
Ogólny zespół adaptacyjny (general adaptation syndrome). Koncepcja teoretyczna stworzona przez Selyego dla wyjaśnienia reakcji organizmu na długotrwały stres. Składa się ona z trzech stadiów: reakcji alarmowej (alarm reaction), którą obejmuje szereg złożonych zmian fizjologicznych będących odpowiedzią organizmu na działanie stresora; stadium odporności (stage of reistance), w którym organizm jest w stanie przez pewien czas opierać się stresorowi (bez występowania zabuzeń), czemu sprzyja wzmożone wydzielanie gruczołów nadnerczy; wreszcie stadium wyczerpania (stagge of exhaustion), w którym organizm nie jest w stanie dłużej opierać się działaniu stresora i może zginąć, jeśli stres nie ustanie.
Okienko owalne (oval window). Błona znajdująca się między uchem środkowym i wewnętrznym.
Okres dorastania (adolescence). U ludzi stadium przejściowe między okresem pokwitania a dojrzałością; klasyfikacja arbitralna.
Okres prelingwistyczny (prelinguistic period). Okres rozwoju języka poprzedzający pojawienie się początków prawdziwej mowy; obejmuje w przybliżeniu pierwszy rok życia.
Okres refrakcji bewzględnej (absolute refractory period). Okres następujący po pobudzeniu aksonu (trwający kilka milisekund), w czasie którego błona komórkowa jest chwilowo niepobudliwa i akson nie może być ponownie pobudzony (bez względu na poziom energii bodźca).
Okres refrakcji względnej (relative refractory period). Krótki okres, w którym, aby wywołać następny impuls, bodziec musi być silniejszy niż zwykle. Następuje po okresie refrakcji bezwzględnej i bezpośrednio poprzedza powrót błony komórkowej do stanu normalnej wrażliwości.
Okres sensomotoryczny (sensory-motor-period). Pierwsze z wyodrębnionych przez Piageta studiów rozwoju poznawczego (mniej więcej od urodzenia do drugiego roku życia); charakterystyczny dla tego okresu jest rozwój poczucia własnej tożsamości, skuteczności swych działań i istnienia związków przyczynowych.
Operacje formalne (formal operations). Czwarte z wyodrębnionych przez Piageta stadiów rozwoju poznawczego (powyżej jedenastego roku życia); dla tego stadium charakterystyczne jest myślenie abstrakcyjne i operowanie pojęciami.
Operacje konkretne (concrete operations). Trzecie z wyodrębnionych przez Piageta stadiów rozwoju poznawczego (od siódmego do jedenastego roku życia); charakterystyczne dla tego stadium jest opanowanie operacji matematyczno-logicznych oraz przyswojenie zasady zachowania ilości.
Operacjonizm (operationism). Metoda naukowa polegająca na definiowaniu abstrakcyjnych pojęć, takich jak głód, lub zjawisk wewnętrznych, takich jak sen, w kategoriach operacji stosowanych przy ich mierzeniu lub obserwowaniu. Głód można zdefiniować operacyjnie jako x godzin bez pożywienia. Definicje takie są ważnym środkiem pozwalającym zmniejszyć wieloznaczność pojęć naukowych, co umożliwia powtarzanie eksperymentów.
Opory (resistances). W psychoanalizie, niezdolność lub niechęć do omawiania pewnych myśli, pragnień czy doznań, występująca zwłaszcza w czasie swobodnego kojarzenia; uważane za barierę psychiczną zapobiegającą powrotowi do świadomości przykrego, wypartego materiału i konfliktów.
Opóźnienie wzmocnienia (delay of re inforcement). Zasada, zgodnie z którą reakcje mniej oddalone w czasie lub przestrzeni od podawanego wzmocnienia są nabywane szybciej niż reakcje odległe od wzmocnienia.
Opracowanie marzenia sennego (dream work). Nieświadomy proces, podczas którego następuje przekształcenie przykrej emocjonalnie, utajonej treści marzenia sennego w mniej przykrą treść jawną.
Oralne stadium (oral stage). W teorii freudowskiej, pierwsze stadium rozwoju psychoseksualnego, w którym głównym źródłem przyjemności są doznania z okolicy ust.
Ortogeneza (orthogenesis). Teoria rozwoju człowieka, która głosi, że ewolucja jest stopniowym ujawnianiem utajonych form życia, przy czym wszystkie te formy były uprzednio zawarte w pierwotnej komórce.
Oscyloskop (oscilloscope). Przyrząd stosowany między innymi do badania czynności mózgu; nagła zmiana napięcia, występująca przy pobudzeniu neuronów, jest widoczna na ekranie fluorescencyjnym w postaci stromej iglicy.
Osłonka mielinowa (myelin sheath). Biaława substancja tłuszczowa, która otacza aksony i rozgałęzienia nerwowe o dużej średnicy; mielinizowanymi drogami impulsy nerwowe przebiegają szybciej i przy mniejszym zużyciu energii.
Osmoreceptory (osmoreceptors). Zgodnie z hipotetycznym wyjaśnieniem homeostatycznej regulacji pragnienia, są to specjalne komórki receptorowe, prawdopodobnie zlokalizowane w podwzgórzu, które reagują na sygnały informujące o wzroście ciśnienia osmotycznego w ten sposób, że wywołują czynność picia.
Osmoza (osmosis). Proces, dzięki któremu wyrównuje się stężenie roztworów po obu stronach półprzepuszczalnej błony; przepływ czy przenikanie wody przez błonę komórkową, to jest z komórki do płynów pozakomórkowych lub na odwrót; przebiega w takim kierunku, że powoduje rozcieńczenie bardziej stężonego roztworu i w ten sposób wyrównuje stężenie obu płynów.
Osobowość (personality). To, co charakteryzuje daną jednostkę; ogólna suma tych sposobów reagowania na innych ludzi i wchodzenia z nimi w interakcje, które są charakterystyczne dla danej jednostki.
Osobowość autorytarna (authoritarian personality). Jeden z typów osobowości; zaliczane do niego jednostki odznaczają się wysokim stopniem sztywności myślenia, uprzedzeniami, politycznym i ekonomicznym konserwatyzmem oraz cechami określanymi jako faszystowskie. 
Osobowość wielokrotna; naprzemienne rozszczepienie osobowości (multiple personality). Skrajna forma neurotycznego stanu dysocjacji, w którym dana jednostka wytwarza dwie (lub więcej) odrębne osobowości występujące w świadomości na zmianę; każda z tych osobowości oparta jest na zbiorze motywów pozostających w konflikcie z motywami drugiej z nich; osobowość wielokrotna jest przypadkiem dramatycznym, aczkolwiek bardzo rzadkim.
Ostrożność wobec przynęty (bait shyness). Unikanie skażonej przynęty.  Jeśli zwierzę zachoruje po zjedzeniu jakiegoś pokarmu, to w przyszłości będzie ono tego pokarmu unikać; jest to niezwykłe, ponieważ, po pierwsze, reakcja ta jest nabywana bardzo szybko (często po jednej próbie), a po drugie, negatywne wzmocnienie jest odległe od bodźca i reakcji.
Oszczędność (savings). W metodzie ponownego uczenia się, służącej do pomiaru stopnia zapamiętywania materiału, różnica między czasem ćwiczenia potrzebnego pierwotnie do wyuczenia się danego materiału, a czasem ćwiczenia potrzebnym do wyuczenia się go ponownie.
Ośrodki przyjemności (pleasure centers). Miejsca w mózgu, których drażnienie prądem elektrycznym odgrywa rolę pozytywnego wzmocnienia dla organizmu.
Ośrodkowy układ nerwowy; OUN (central nervous system, CSN). Mózg i rdzeń kręgowy, w odróżnieniu od obwodowego układu nerwowego.
Otępienie wczesne (dementia praecox). Dawna nazwa schizofrenii.
Otyłość (obesity). Nadmierna waga ciała; nałóg jedzenia; choroba społeczna powszechna w społeczeństwach dostatku, mająca poważne następstwa psychiczne i fizyczne.
Otyłość utajona (latent fat). Skłonność do otyłości występująca u osób mających dużą liczbę adipocytów (komórek tłuszczowych), nawet jeśli są szczupłe w wyniku zachowywania diety.
Owładnięcie (opętanie) przez demony (demonic possession). Archaiczna koncepcja choroby psychicznej oparta na przekonaniu, że choroby fizyczne i zaburzenia psychiczne są spowodowane owładnięciem ciała pacjenta przez złe duchy.


Pamięć długotrwała (long-term memory). System pamięciowy (o teoretycznie nieograniczonej pojemności) przechowujący informacje w sposób względnie trwały; zawarte w nim informacje nie zawsze są łatwo dostępne.
Pamięć krótkotrwała (short-term memory). System pamięciowy, w którym informacja jest przechowywana tylko przez krótki czas i jest łatwo dostępna.
Pamięć odtwórcza (reproductive memory). Teoria pamięci jako procesu odtwórczego polegającego na odszukiwaniu materiału poprzednio wyuczonego i zmagazynowanego w mózgu.
Pamięć wytwórcza (productive memory). Teoria pamięci jako procesu aktywnej rekonstrukcji, a nie po prostu odszukiwania.
Paradygmat (paradigm). Przykład lub wzór; w badaniach jest to pewna podstawowa procedura lub schemat badawczy, za pomocą którego odwzorowuje się istotne cechy badanego procesu.
Parajęzyk (paralanguage). Forma ekspresji niewerbalnej, obejmująca głosowe, lecz niewerbalne aspekty porozumiewania się; takie jak natężenie głosu czy śmiech.
Paranoja (paranoia). Psychoza, w której charakterystycznymi objawami są usystematyzowane, złożone urojenia.
Paraprofesjonaliści (paraprofessionals). Osoby, które zostały przeszkolone w pewnym zakresie w dziedzinie terapii zaburzeń psychicznych; chociaż przygotowanie to nie stoi na tak zaawansowanym poziomie zawodowym, jak w przypadku dyplomowanych terapeutów posiadających stopień doktora medycyny czy kwalifikacje psychologa klinicznego, niemniej jednak osoby te mogą świadczyć wiele usług ludziom potrzebującym pomocy.
Parapsychologia (parapsychology). Naukowe badanie zjawisk pozazmysłowych.
Patologia (pathology). Chorobliwy czy anormalny stan fizyczny, umysłowy, emocjonalny lub społeczny.
Patologia społeczna (social pathology). Anormalne warunki społeczne w instytucjach, środowiskach lub w systemach wytwarzające, ułatwiające lub podtrzymujące patologiczne reakcje u jednostek żyjących w tych warunkach.
Personifikacja (personification). W teorii Sullivana, wyobrażenie, jakie dana osoba ma o kimś innym, w dużej mierze determinuje ono jej reakcje wobec tej osoby.
Perspektywa liniowa (linear perspective). Zjawisko percepcyjne polegające na tym, że przedmioty w miarę oddalania się wydają się coraz mniejsze i bliższe siebie.
Perspektywa powietrzna (atmospheric perspective). Sygnał pomocny przy spostrzeganiu głębi, oparty na różnicy wyrazistości przedmiotów bliskich i odległych.
Perswazja (perusuasion). Systematyczne próby wpłynięcia na myśl, uczucia i działania innej osoby za pomocą przekazywanych argumentów.
Pień mózgu (brain stern). Zbiór struktur położonych między nowym mózgowiem a rdzeniem kręgowym; obejmuje wzgórze, podwzgórze i twór siatkowaty.
Pierwsze wrażenie (first impression). Ocena danej jednostki dokonana przy pierwszym kontakcie czy na pierwszy rzut oka, często oparta na bardzo słabych sygnałach; może mieć znaczny wpływ na późniejsze oceny.
Placebo (placebo). Substancja chemiczna nieczynna podawana w taki sposób, że pacjenci lub osoby badane sądzą, iż otrzymują aktywny środek farmakologiczny. W niektórych przypadkach reakcje na placebo są podobne do sposoby reagowania na aktywny środek farmakologiczny.
Plemnik (sperm). Męska gameta (komórka rozrodcza).
Płat potyliczny (occipital lobe). Część nowego mózgowia znajdująca się w tyle mózgu; mieści się w nim wzrokowe pole projekcyjne.
Płat skroniowy (temporal lobe). Część nowego mózgowia oddzielona od płatu czołowego i ciemieniowego bruzdą Sylwiusza; leży tuż od skronią; w płacie tym są zlokalizowane słuchowe pola projekcyjne.
Pobieranie próbek zachowania (behavior sampling). Technika pomiaru osobowości, w której badacz obserwuje zachowanie badanej osoby w określonej sytuacji.
Poczucie skuteczności swych działań (efficacy). Poczucie własnej kompetencji, własnej efektywności, własnej wartości, posiadania wpływu na bieg rzeczy.
Poczucie wykroczenia poza granice własnego ja (ego transcendence).  Doznanie, które często jest charakterystyczne dla zmienionych stanów świadomości; poczucie oderwania się od siebie samego i swych osobistych potrzeb, dzięki czemu ma się wrażenie, że patrzy się na rzeczywistość w obiektywny i bezstronny sposób.
Podatność na hipnozę (hypnotizability). Łatwość, z jaką dana jednostka zostaje zahipnotyzowana; mierzy się ją za pomocą skali podatności hipnotycznej.
Podstawowe zdolności umysłowe (primary mental abilities). Względnie niezależne zdolności (zidentyfikowane za pomocą analizy czynnikowej), które składają się na ogólną inteligencję. Należą do nich między innymi zdolności werbalne, wyobraźnia przestrzenna, zdolność posługiwania się liczbami oraz zdolność rozumowania.
Podwójnie ślepa próba (double blind test). Metoda kontroli polegająca na organizowaniu badań w taki sposób, by zarówno osoby badane, jak i badacze nie wiedzieli, które z osób badanych zostały poddane eksperymentalnemu oddziaływaniu. Sposób obrony przed wpływem oczekiwania czy nastawienia stosowany zwłaszcza przy ocenianiu skuteczności działania środków farmakologicznych.
Podwzgórze (hypothalamus). Struktura podkorowa o kluczowym znaczeniu, odgrywająca ważną rolę w regulacji metabolizmu, temperatury, odczuwania głodu i pragnienia oraz zachowania emocjonalnego; ośrodek sterujący, dzięki połączeniom z przysadką mózgową, większą częścią układu wydzielania wewnętrznego.
Pojęcie o sobie (self-concept). Zgodnie z teorią własnego ja Rogersa, posiadana przez daną jednostkę świadomość ciągłości własnej tożsamości; rozwija się stopniowo od chwili odkrycia przez niemowlę części własnego ciała do momentu, gdy obejmuje wreszcie wszystkie myśli, uczucia, postawy, wartości i aspiracje danej osoby; odrębna część pola fenomenologicznego jednostki.
Pola kojarzeniowe (asociation areas). Pola kory mózgowej, które służą do wiązania i integrowania prostszych funkcji pól czuciowych i ruchowych.
Pole fenomenologiczne (phenomenal field). W teorii osobowości Carla Rogersa, prywatny świat doznań jednostki, który jest dla niej specyficznym układem odniesienia.
Pole rercepcyjne (receptive field). Obszar siatkówki, z którego dany neuron otrzymuje impulsy.
Poparcie społeczne (social support). Główne źródło wpływu grupy, dzięki któremu decyzje indywidualne dotyczące podjęcia działania zostają umocnione, gdy inne osoby z grupy zgadzają się z nimi.
Popęd (drive). Motyw; stany wewnętrzne ukierunkowujące dany organizm ku określonemu celowi; związane zwykle z procesami biologicznymi.
Popęd seksualny (sex drive). Motyw, który prowadzi do zadowolenia jednostki (dzięki redukcji napięcia) i do przedłużenia trwania gatunku (dzięki skutecznej reprodukcji), zwiększając receptywność seksualną i wzmagając dążenie do osiągnięcia różnych celów związanych z płcią.
Populacja (population). Cała grupa, z której pobiera się próbki do badania.
Porcjowanie (chunking). Organizowanie materiału, który ma być wyuczony i zapamiętany, w mniejsze, znajome jednostki; odpowiednie porcjowanie zwiększa zdolność zapamiętywania.
Porównanie (simile). Figura stylistyczna polegająca na porównywaniu dwóch rzeczy, na przykład stwierdzenie Czuję się jak maszyna.
Porównywanie społeczne (social comparison). Proces, dzięki któremu ludzie odczuwający potrzebę oceniania swych opinii, emocji i zdolności, mogą tego dokonać porównując swe reakcje z reakcjami innych ludzi; badanie rzeczywistości społecznej; teoria opracowana przez Festingera.
Potrzeba (need). Biologiczny lub psychiczny stan motywacyjny, który ukierunkowuje zachowania jednostki na pewien cel.
Potrzeba osiągnięć (need for achievement). Odczuwana potrzeba uzyskiwania dobrych wyników lub przynajmniej unikania porażki; ogólna skłonność do osiągania sukcesu, której siła zależy od wiary w sukces, wartości wchodzącego w grę sukcesu oraz percepcji osobistego wpływu na jego osiągnięcie.
Pozbawienie snu (sleep deprivation). Pozostawanie przez długi czas bez snu, co może zmieniać różne fizjologiczne i psychiczne reakcje, powoduje zmęczenie, zaburzenia orientacji, anomalie w zapisie czynności bioelektrycznej mózgu, myśli paranoidalne, zniekształcenia percepcyjne oraz różne inne zaburzenia zachowania (zależne od wielu czynników).
Poziom fonologiczny (phonological level). Poziom analizy lingwistycznej, na którym przedmiotem zainteresowania są jednostki dźwiękowe (fonemy), z jakich składa się język.
Poziom sprawczy (operant level). Tempo, w jakim występuje dana reakcja (zachowanie sprawcze), gdy nic nie ogranicza jej wykonywania, jej konsekwencje zaś nie są ani pozytywne, ani negatywne.
Poziom wyjściowy (set point level). Poziom podstawowy lub początkowy, stały poziom stosowany jako punkt odniesienia.
Pozorowanie reakcji (reaction formation). Mechanizm obronny, w którym świadome postawy i zachowanie danej jednostki są sprzeczne z jej nieświadomymi pragnieniami, które zostały wyparte; przejawianie przeciwnych postaw i zachowań jest swego rodzaju barierą chroniącą przed wyrażaniem niebezpiecznych pragnień.
Pozytywna ocena (positive regard). Aprobata uzyskiwana przez daną osobę zarówno od siebie samej, jak i od innych ludzi; potrzeba uzyskiwania pozytywnej oceny - jeśli powoduje nadmierne uzależnienie od opinii otoczenia - może być w konflikcie z dążeniem jednostki do samorealizacji.
Pozytywny czynnik wzmacniający (positive reinforcer). Czynnik wzmacniający; którego podanie po jakiejś reakcji zwiększa prawdopodobieństwo, że reakcja ta wystąpi znowu w podobnych okolicznościach.
Półkule mózgowe (cerebral hemispheres). Dwie połowy nowego mózgowia.
Pranie mózgu (brainwashing). Forma intensywnej propagandy realizowanej w warunkach stresowych, mającej wywołać poważne zmiany w sposobie myślenia; termin ukuty przez dziennikarzy w okresie wojny koreańskiej.
Prawo efektu (law of effect). Teoria sformułowana przez Thorndikea, zgodnie z którą związki S-R są wzmacniane przez osiągnięte zadowolenie, osłabiane zaś przez przykre następstwa lub niepowodzenia.
Prawo przewodzenia jednokierunkowego (law of forward conduction).  Kierunek przebiegu impulsów nerwowych: informacja jest przekazywana przez neurony i synapsy tylko w jednym kierunku, od dendrytów przez ciało komórki i akson do stopek końcowych, a następnie przez synapsę do następnych dendrytów.
Prawo Webera-Fechnera (Weber-Fechner law). Prawo psychofizyczne głoszące, że przyrost wielkości bodźca, który powoduje Idr (ledwo dostrzegalną różnicę) stanowi całą część pierwotnej jego wielkości (odnosi się to do większej części zakresu wielkości bodźców).
Prawowity autorytet (legitimate authority). Osoba uważana za prawowitego reprezentanta społeczeństwa, które ma prawo wymagać posłuszeństwa i kontroluje ważne wzmocnienia; jej obecność może sprzyjać ślepemu posłuszeństwu wobec autorytetu.
Predyspozycja (predisposition). Prawdopodobieństwo, że u danej jednostki w pewnych stresowych warunkach wystąpią określone objawy (np.  reakcje schizofreniczne) spowodowane wcześniej działającymi czynnikami, takimi jak czynniki dziedziczne lub doświadczenia wczesnego okresu życia.
Pręciki (rods). Komórki receptorowe w siatkówce, niezwykle wrażliwe na bodźce świetlne, umożliwiające spostrzeganie bieli, czerni i szarości (ale nie innych barw).
Procesy odtwarzania motorycznego (motoric reproduction processes).  Czynnik wpływający na uczenie się przez obserwację; wykonywanie wyuczonej czynności zależy bowiem od posiadanej przez daną jednostkę zdolności czy umiejętności wykonywania wzorcowego działania.
Procesy poznawcze (cognitive processes). Procesy, dzięki którym jednostki myślą o przedmiotach i zdarzeniach, poznają je i uświadamiają je sobie; procesy te obejmują uczenie się, rozumowanie, zapamiętywanie, podejmowanie decyzji, twórczość itd.
Procesy przechowywania w pamięci (retention proceses). Czynnik wpływający na uczenie się przez obserwację - jako że wpływ modela zależy od zdolności danej jednostki do zapamiętywania jego działań.
Proksemika (proxemics). Badania nad ekspresją niewerbalną, której elementami (przejawiającymi się w kontakcie dotykowym i wzrokowym) są: odległość między ludźmi wchodzącymi ze sobą w interakcje oraz ich ustawienie względem siebie.
Propaganda (propaganda). Systematyczne rozpowszechnianie określonych idei, doktryn czy sposobów działania dla poparcia własnego stanowiska lub zdyskredytowania stanowiska przeciwnika; często prawdziwy cel lub źródło tej formy perswazji są ukryte przed jej zamierzonymi adresatami; zwykle ma doprowadzić do zmiany przekonań politycznych.
Protokół (protocol). Znormalizowany zapis wywiadu, posiedzenia badawczego lub serii obserwacji eksperymentalnych.
Prowokacja (provocation). Podniecenie do działania, pierwsza faza agresywnej interakcji; agresja interpersonalna często bywa inicjowana przez wzajemną prowokację, nierzadko niezamierzoną.
Próbka (sample). Określona grupa, na której przeprowadza się pomiary; powinna być reprezentatywna dla populacji, w odniesieniu do której ma być wyciągnięty wniosek.
Próg absolutny (limen). Wielkość bodźca, który jest dostatecznie silny, aby receptory czuciowe mogły go poprawnie wykryć w 50% przypadków.
Próg pobudzenia (stimulation threshold). Punkt graniczny, w którym poziom energii przychodzącego bodźca jest wystarczający do pobudzenia neuronu czuciowego.
Przechodzenie do dorosłości (transadulthood). Zaproponowane ostatnio stadium psychospołeczne (trwające od końca drugiego dziesiątka lat życia do końca trzeciego lub początku czwartego dziesiątka), które określa się jako okres eksperymentowania z różnymi stylami życiowymi, poszukiwania drogi kariery życiowej i wypróbowywania różnych kierunków kształcenia; okres, w którym często dąży się do zmniejszenia obowiązków i maksymalnego zwiększenia osobistej swobody.
Przeciążenie sensoryczne (sensory overload). Zwiększenie liczby odbieranych bodźców sensorycznych spowodowane nadmierną aktywnością ruchową i (lub) innym pobudzeniem emocjonalnym; może prowadzić do wystąpienia zmienionych stanów świadomości.
Przeciwwarunkowanie (counterconditioning). Wyeliminowanie określonej reakcji na bodziec przez ukształtowanie innej, często całkiem odmiennej reakcji; stosowane w terapii behawioralnej dla wyeliminowania nieakceptowanego zachowania i zastąpienia go bardziej pożądaną reakcją.
Przedświadome (preconscious). W teorii freudowskiej, idee, myśli i wyobrażenia, których jednostka nie uświadamia sobie w danym momencie, lecz z których może zdać sobie sprawę, które może uczynić świadomymi (bez wielkich lub żadnych trudności).
Przegroda (septal area). Część układu limbicznego; lezje w tej okolicy mogą powodować reakcje wściekłości u oswojonego zwierzęcia (lezje dokonywane w zakręcie obręczy układu limbicznego mogą dzikie zwierzę uczynić łagodnym).
Przekaz (message). Przekazywanie treści i myśli; zmienna w badaniach nad zmianą postaw.
Przekazywanie przez sygnały (synaptic transmission). Przekazywanie impulsu nerwowego z neurona na neuron, przy czym chemiczna substancja przekaźnikowa przechodzi przez szczelinę synaptyczną między neuronem aktywnym a neuronami przyległymi; pobudzenie lub hamowanie neuronów postsynaptycznych odgrywa decydującą rolę w przetwarzaniu informacji.
Przekonania (beliefs). Komponent postaw; twierdzenia dotyczące tego, jaki jest lub jaki powinien być obiekt postawy.
Przemieszczenie (displacement). Mechanizm obronny, dzięki któremu uczucia, na przykład wrogości, zostają wyładowane na obiekcie zastępczym; także proces zachodzący w marzeniu sennym. Dzięki któremu niezaakceptowany materiał zostaje zamaskowany w te sposób, że to, co ważne w tym życiu realnym, jest nieważne we śnie lub na odwrót.
Przemieszczenie agresji (displaced aggression). Przeniesienie wrogości z obiektu lub osoby rzeczywiście powodujących frustrację na jakiś inny obiekt, osobę lub siebie samego.
Przeniesienie (transference). Proces zachodzący podczas terapii psychoanalitycznej, w którym pacjent skierowuje na terapeutę uczucia, jakie uprzednio żywił wobec osoby odgrywającej ważną rolę w jakimś dawnym konflikcie emocjonalnym (często jest to któreś z rodziców lub partner seksualny); uczucia te mogą być negatywne, pozytywne lub ambiwalentne.
Przeniesienie negatywne (negative transference). Przypadek przeniesienia, w którym uczucia wobec analityka są uczuciami negatywnymi, takimi jak wrogość czy zawiść.
Przeniesienie pozytywne (positive transference). Przypadek przeniesienia, w którym uczucia wobec analityka są uczuciami pozytywnymi, takimi jak miłość lub podziw.
Przesądy dające poczucie sprawowania kontroli nad środowiskiem (superstitious control). Fałszywe, oparte na przesądach przekonanie, że ma się kontrolę nad swym środowiskiem; ma ono zapobiegać wytworzeniu się wyuczonej bezradności.
Przetwarzanie informacji (information processing). W psychologii, procesy poznawcze; w badaniu tych procesów za precyzyjny, ścisły model myślenia przyjmuje się programy komputerowe.
Przeuczanie się (overlearning). Technika służąca lepszemu zapamiętywaniu, która polega na dodatkowym ćwiczeniu po opanowaniu materiału.
Przewężenia Ranviera (nodes of Ranvier). Występujące w stałych odstępach przerwy osłonki mielinowej; umożliwiają one zwiększenie niezawodności i szybkości przewodzenia sygnałów przez aksony dzięki temu, że impulsy nerwowe przeskakują od jednego przewężenia do drugiego.
Przewidywalność (predictability). Znajomość prawdopodobieństwa wystąpienia przyszłych zdarzeń; zapobiega wyuczonej bezradności zmniejszając niepewność i służy zwiększeniu percepcyjnej kontroli nad środowiskiem.
Przewidywanie statystyczne (statistical prediction). Przewidywanie przyszłego zachowania danej jednostki na podstawie obiektywnych testów oraz różnych procedur i reguł statystycznych, a nie na podstawie oceny klinicznej.
Przewodzenie przez aksony (axonal conduction). Przekazywanie impulsów nerwowych polegające na tym, że depolaryzacja błony komórkowej nerwu wyzwala impuls (zgodnie z zasadą wszystko lub nic), który szybko przemieszcza się wzdłuż aksonu.
Przyjemność wynikająca z kontaktu fizycznego (contact comfort). Ważny aspekt związku matki z dzieckiem; po raz pierwszy badana i obserwowana w eksperymentach nad odłączonymi od matek małpkami, wychowywanymi z różnego rodzaju sztucznymi matkami z włochatej tkaniny.
Przynęty (incentive stimuli). Przedmioty lub zdarzenia bodźcowe w otoczeniu, które w interakcji z odpowiednim stanem fizjologicznym mogą wywoływać pewne sekwencje reakcji.
Przypominanie (recall). Metoda pomiaru stopnia zapamiętania materiału; za pomocą minimum sygnałów osoba badana musi odtworzyć wyuczoną wcześniej reakcję.
Przypominanie mechaniczne (rote recall). Dosłowne odtworzenie wyuczonego materiału, bez uwzględniania jego znaczenia.
Przysadka mózgowa (pituitary gland). Gruczoł wydzielania wewnętrznego, z którym bezpośrednio związane są, między innymi, procesy wzrostu.  Aktywowany przez podwzgórze wydziela hormon wzrostowy, który z kolei powoduje aktywację wielu innych gruczołów wydzielania wewnętrznego.
Przywódcy społeczno-emocjonalni (social-emotion leaders). Przywódcy, którzy kładą nacisk raczej na stwarzanie i utrzymywanie dobrego klimatu psychologicznego w grupie niż na jej efektywności; bardziej zainteresowani procesem niż wytworami.
Przywódcy zadaniowi (task leaders). Przywódcy nastawieni na możliwie najsprawniejsze wykonanie danego zadania czy racy; zainteresowanie głównie wytworami.
Przywódcze zdolności (leadership). Właściwość posiadana przez jednostki, które wywierają większy wpływ na grupę niż inni jej członkowie; do cech efektywnego przywódcy należą inteligencja, wysokie osiągnięcia, odpowiedzialność, aktywność i popularność.
Przywództwo przyzwalające; p. w stylu laissez-faire (laisses-faire style of leadership). Niedyrektywny i nieuczestniczący styl kierowania, w którym przywódca służy pomocą tylko wtedy, gdy się tego od niego zażąda.
Pseudowarunkowanie (pseudoconditioning). Zjawisko polegające na uzyskiwaniu zachowania podobnego do reakcji warunkowej bez odpowiedniego zestawienia ze sobą bodźców - co jest istotą prawdziwego warunkowania.
Psychiatra (psychiatrist). Lekarz specjalizujący się w leczeniu schorzeń umysłowych, emocjonalnych i w pewnym stopniu neurologicznych; oprócz werbalno-behawioralnych form terapii może stosować fizykalno-medyczne metody leczenia, takie jak psychochirurgia, wstrząsy, środki farmakologiczne itd.
Psychiatria (psychiatry). Dziedzina medycyny zajmująca się badaniem, rozpatrywaniem, leczeniem, jak również zapobieganiem zaburzeniom psychicznym i niektórym schorzeniom neurologicznym.
Psychoanalityk (psychoanalyst). W USA psychoterapeuta, który ukończył studia podyplomowe przygotowujące specjalistów w zakresie stosowania freudowskiego sposobu podejścia przy interpretacji i leczeniu nerwic oraz innych problemów natury psychologicznej.
Psychoanaliza (psychoanalytic movement). Szkoła psychologiczna zapoczątkowana przez Freuda, której zwolennicy kładą nacisk na badanie nieświadomych procesów psychicznych; również teoria osobowości i metoda psychoterapii, w której dąży się do wprowadzenia nieświadomych pragnień do świadomości pacjenta, by w ten sposób umożliwić rozwiązanie konfliktów biorących zwykle swój początek we wczesnych doświadczeniach okresu dzieciństwa.
Psychochirurgia (psychosurgery). Forma terapii biologicznej, czyli somatycznej, która obejmuje operacje mózgu; stosowana w leczeniu poważnych zaburzeń emocjonalnych, a polegająca na przecinaniu włókien nerwowych łączących różne okolice mózgu, na usuwaniu substancji korowej i na lezjach w określonych miejscach mózgu. Toczące się długotrwałe dyskusje nad stosowaniem tych metod wobec osób stosujących akty przemocy.
Psychodeliczny (psychedelic). Termin oznaczający dosłownie „przejawiający się w psychice, początkowo neutralny termin stosowany na określenie wszelkich środków psychotropowych, obecnie oznacza środki halucynogenne.
Psychofizjolog (physiological psychologist). Psycholog zajmujący się zawodowo ustalaniem związków między biologicznym i fizjologicznym funkcjonowaniem organizmu a jego doznaniami i zachowaniem.
Psychogenny (psychogenic). Spowodowany czynnikami psychiczno-emocjonalnymi, a nie czynnikami organizmu a jego doznaniami organicznymi czy fizjologicznymi.
Psychokineza (psychokinesis; PK). Forma spostrzegania pozazmysłowego, w której przedmioty i zdarzenia są rzekomo sterowane za pomocą aktu myśli czy woli.

Psycholingwistyczne podejście (psycholinguistic approach). Teoria nabywania języka głoszona przez Chomskyego, zgodnie z którą dzieci uczą się nie sekwencji słów, lecz systemu reguł pozwalających tworzyć zdarzania.
Psycholingwistyka (psycholinguistic). Psychologiczne badania nad językiem i procesem jego nabywania.
Psychologia (psychology). Naukowe badanie zachowania organizmów.  Badanie interakcji między organizmami biologicznymi a ich środowiskiem fizycznym i społecznym.
Psychologia ekologiczna (ecological psychology). Nowe podejście do psychologii, w którym chodzi o zrozumienie wzajemnej psychospołecznej zależności między jednostkami w danej społeczności a ich fizycznym i biologicznym środowiskiem.
Psychologia międzykulturowa (cross-cultural psychology). Dziedzina nauki zajmująca się empirycznym badaniem członków różnych grup kulturowych, w których zachowaniu (pod względem różnych doświadczeń) występują przewidywalne i istotne różnice.
Psychologia postaci (gestalt psychology). Szkoła psychologiczna głosząca, że psychologia powinna badać całokształt zachowania zamiast rozkładać je na elementy, ponieważ całość jest czymś więcej niż sumą swych części.
Psychologia społeczna (social psychology). Dziedzina psychologii badająca wpływ zmiennych społecznych na zachowanie, postawy, motywy i spostrzeżenia jednostek; badanie wpływu innych osób i środowisk społecznych na reakcje jednostki. 
Psychologia S-R (S-R psychology). Koncepcja, w której związek między bodźcem a reakcją przyjmuje się za jednostkę stosowaną przy badaniu uzewnętrznianego zachowania organizmu. Zakłada się, że wzmacniane ćwiczenie wytwarza i utrwala związki S-R. Zobacz także Behawioryści.
Psycholog kliniczny (clinical psychologist). W USA psycholog mający doktorat, którego przygotowanie obejmuje praktykę i staż w szpitalu lub klinice; może prowadzić psychoterapię przy zastosowaniu metod werbalno-behawioralnych; specjalista przystosowany zawodowo do dokonywania diagnozy za pomocą metod testowych, wywiadu i badań o charakterze eksperymentalnym.
Psychoterapia (psychotherapy). Termin stosowany dla określenia wszelkich form psychologicznego leczenia zaburzeń psychicznych oraz anomalii myślenia, emocji czy zachowania.
Psychoterapia dynamiczna (psychodynamic psychotherapy). Koncepcja psychoterapii, w której zasadnicze znaczenie przypisuje się wewnętrznym przyczynom zaburzeń, lecz w odróżnieniu od koncepcji biologicznej, kładzie się nacisk nie na fizyczne niedobory, nadmiary czy brak równowagi, lecz na zachodzące w danej chwili intensywne procesy psychiczne.
Psychoterapia egzystencjalno-humanistyczna (existential-humanistic psychotherapy). Typ terapii, w którym kładzie się nacisk na jednostkę (taką, jaką jest ona tu i teraz), której trzeba poświęcić uwagę i troskę, zrozumieć ją i leczyć; za podstawową rzeczywistość uznaje się doznania jednostki, a nie zjawiska czy procesy fizyczne; a terapia ta koncentruje się na całym organizmie, jako złożonym systemie, a nie tylko na jego stronie biologicznej, zachowaniu czy nieświadomości; zalea się w niej również bardziej troskliwy, serdeczny stosunek terapeuty do pacjenta.
Psychoterapia grupowa (group therapy). Każda forma psychoterapii, w przypadku której w danym miejscu lecz się jednocześnie więcej niż jedną osobę; zwykle prowadzona przez terapeutę stosującego niedyrektywne metody.


Psychoterapia uwrażliwiająca (experiential psychotherapy). Proces terapeutyczny wprowadzony przez Grendina, oparty na koncepcji spotkania interpersonalnego, w którym terapeuta przyjmuje aktywną, autoekspresyjną postawę, ujawniając swe doznania, a jednocześnie pomaga pacjentowi osiągnąć zaufanie do jego własnych uczuć i doznań.
Psychoza czynnościowa (functional psychosis). Poważne zaburzenie psychiczne, które jest spowodowane przede wszystkim stresem psychicznym i którego nie można przypisać organicznym, fizycznym przyczynom.
Psychoza organiczna (organic psychosis). Zaburzenie psychiczne spowodowane uszkodzeniami układu nerwowego lub takimi stanami, jak niedoczynność gruczołów wydzielania wewnętrznego czy zatrucie.
Psychozomimetyczny (psychotomimetic). Właściwości pewnych środków psychotropowych mogących wywołać wystąpienie anormalnych form myślenia i pobudzenia.
Pułapka społeczna (social trap). Sytuacja występująca w systemach społecznych, w których ludzie zdając sobie z tego sprawę zachowują się w sposób, który na dalszą metę będzie dla nich szkodliwy, lecz w danej chwili nie wiedzą, jak przerwać to zachowanie, ani jak nad nim zapanować (np.  wyścig zbrojeń nuklearnych).


Rasizm zinstytucjonalizowany (institutionalized racism). Uprzedzenia i działania dyskryminujące członków grup mniejszościowych (np. ze względu na ich rasę) istniejące w pewnej społeczności i znajdujące w niej społeczno-polityczno-ekonomiczne poparcie.
Rdzeń kręgowy (spinal cord). Część ośrodkowego układy nerwowego. 
Wydłużony słup tkanki nerwowej łączącej mózg z obwodowym układem nerwowym.
Reakcja alarmowa. Zobacz Ogólny zespół adaptacyjny.
Reakcja bezwarunkowa; Rb (unconditioned response UCR). Reakcja na bodziec bezwarunkowy; często jest nią odruch wrodzony, jak w przypadku ślinienia się w reakcji na pokarm.
Reakcja instrumentalna (instrumental response). Reakcja umożliwiająca uzyskanie wzmocnienia; zachowanie organizmu, który pod wpływem określonej motywacji działa w taki sposób (poszukiwanie, praca), aby osiągnąć cel lub otrzymać nagrodę.
Reakcja konsumpcyjna (consummatory response). Czynność, która stanowi zakończenie aktywności ukierunkowanej na cel, na przykład jedzenie.
Reakcja konwersyjna (conversion hysteria). Neurotyczna reakcja na stres lub lęk, w której cierpienia psychiczne zostają przekształcone w objawy organiczne. Zobacz także Nerwica histeryczna.
Reakcja mimowolna (involuntary response). Niewyuczona, automatyczna reakcja organizmu na bodziec wywołujący.
Reakcja orientacyjna (orienting reaction). Mechanizm umożliwiający zwracanie uwagi na nowe bodźce środowiskowe; obejmuje wzrost wrażliwości, zmiany w narządach wewnętrznych, zmiany w mięśniach i w czynności bioelektrycznej mózgu; wszelkie reakcje, które sprzyjają maksymalizacji wrażliwości na napływającą informację i przygotowują organizm do natychmiastowego działania.
Reakcja skórno-galwaniczna; RSG (galvanic skin response; GSR).  Niewielkie zmiany w elektrycznej przewodności skóry, lub aktywności elektrycznej w skórze, wykrywane przez czuły galwanometr. Reakcje te są powszechnie stosowane jako wskaźnik reaktywności emocjonalnej.
Reakcja warunkowa; Rw (conditioned response; CR). Wyuczona czy nabyta reakcja na bodziec warunkowy.
Reakcje afektywne (affective reactions). Kategoria zaburzeń psychotycznych, dla której charakterystyczne są silne fluktuacje nastroju lub emocji.
Reakcje lub okresy depresyjne (depressive episodes or reactions).  Reakcje psychotyczne, dla których charakterystyczne są okresy niezwykle silnej depresji; mogą one występować na zmianę z okresami maniakalnymi.
Reakcje lub okresy maniakalne (manic reactions or episodes). Reakcje psychotyczne, dla których charakterystyczne są okresy silnego podniecenia i niepohamowanej euforii - nie mającej zwykle dostatecznego uzasadnienia; mogą one występować na przemian z okresami depresji.
Reakcje paranoiczne (paranoid reactions). Psychotyczny wzorzec reakcji, dla którego charakterystyczne są uporczywe urojenia.
Reaktancja (reactance). Potrzeba swobody działania; gdy swoboda działania jest zagrożona, to u danej jednostki występują nieprzyjazne uczucia wobec osoby czy osób ograniczających tę swobodę i reaguje ona w ten sposób, by ją przywrócić; teoria sformułowana przez Brehma.
Receptory (receptors). Struktury w układzie nerwowym wrażliwe na pewne rodzaje bodźców (światło, dźwięk, nacisk itd.); wytwarzają impulsy nerwowe w czuciowych włóknach nerwowych.
Recydywa (recidivism). Powrót do pierwotnej postawy, zachowania lub stanu po okresie terapii lub postępowania rehabilitacyjnego; miara nieskuteczności interwencji.
Redukcja popędu (drive reduction). Centralne pojęcie teorii uczenia się głoszącej, że motywowaną sekwencję zachowania najlepiej można wyjaśnić jako przejście od przykrego stanu napięcia (popędu) do pewnego stanu stanowiącego cel, kiedy to popęd zostaje zredukowany.
Redukcjonizm (reductionism). Pogląd, zgodnie z którym zrozumienie złożonych procesów i zjawisk może nastąpić przez badanie składających się na nie prostych elementów i składników. Często stosowany przez psychofizjologów dążących do wyjaśnienia zasad, na których opiera się zachowanie ludzkie i funkcjonowanie mózgu (badają oni liczne, odrębne neurologiczne i biochemiczne zjawiska i substancje występujące w mózgu).
Redundacja (redundancy). W teorii informacji, pojęcie oznaczające, że komunikat składa się z większej liczby sygnałów, niż to jest niezbędne do przekazywania danej informacji.
Regresja (age regression). Szczególny przypadek zniekształcenia pamięciowego występującego u zahipnotyzowanych osób badanych, które zostają nakłonione do ponownego przeżycia zdarzeń, jakie wystąpiły w jakimś wcześniejszym okresie ich życia.
Reguły przekształcenia (transformational rules). Reguły przy użyciu których zdaniu jądrowemu można nadać różne znaczenie i osiągnąć zróżnicowaną ekspresję; według teorii języka sformułowanego przez Chomskyego służą one do przetwarzania struktury głębokiej znaczenia wypowiadanego zdania w jego strukturę powierzchniową.
Rekonstruowanie (reconstruction). Forma przypominania, w której jedynie część informacji jest zmagazynowana i zostaje przypomniana, reszta zaś jest rekonstruowana na podstawie sygnałów dostarczonych przez zmagazynowaną informację.
Relacja ról (role relation). Zależność między wzorcami zachowań oczekiwanych od jednostek ze względu na ich miejsce w strukturach społecznych; istnienie relacji ról, w której jedna osoba podporządkowana jest drugiej, może sprzyjać ślepemu posłuszeństwu wobec autorytetu.
Relacje między figurą a tłem (figure-ground relations). Tendencja do spostrzegania bodźców jako przedmiotów lub zdarzeń (figur) na pewnym tle, nawet gdy bodźce są niejednoznaczne, a relacje między pierwszym planem a tłem - odwracalne.
Remisja (remission). Termin stosowany w medycznym modelu psychopatologii dla określenia stanu poprawy, czyli ustąpienia objawów choroby psychicznej; choroba trwa w zasadzie nadal w postaci utajonej.
Replikacja (replication). Powtórzenie eksperymentu w tych samych warunkach po to, by sprawdzić, czy uzyska się ponownie takie same  wyniki - zwykle dokonuje tego inny badacz.
Reprezentacja ikoniczna (iconic reprezentation). Odwzorowanie bodźców, które są zmagazynowane w postaci obrazów percepcyjnych lub sensorycznych.
Retynina (retinine). Jeden z produktów rozkładu rodopsyny na części składowe (pod wpływem światła).
Rezerpina (reserpine). Środek uspokajający stosowany powszechnie w leczeniu pacjentów psychiatrycznych.
Rodopsyna (rhodopsine). Fotopigment znajdujący się w pręcikach oka.
Rozhamowanie (disinhibition). Ponowne pojawienie się na pewien czas wygaszonej reakcji warunkowej - w odpowiedzi na bodziec zewnętrzny inny niż bodziec warunkowy; zahamowanie hamowania.
Rozkład częstości (frequency distribution). Szereg indywidualnych wyników uporządkowanych od najwyższego do najniższego; częstość, z jaką każdy wynik jest reprezentowany w danym rozkładzie.
Rozkład normalny (normal distribution). Tendencja, zgodnie z którą wyniki uzyskiwane przez większość członków dużej populacji skupiają się wokół pewnego punktu centralnego, czyli średniej, a wyniki pozostałych rozłożone są ku obu krańcom wykresu w postaci symetrycznej krzywej o kształcie dzwonu.
Rozkład wzmacniania (reinforcement scheduling). Plan podawania wzmocnienia - regularny lub losowy.
Rozkład wzmacniania o stałych odstępach czasowych (FI - fixed interval schedule). Rozkład wzmacniania sporadycznego, w którym wzmocnienie podaje się regularnie, co pewien czas, na przykład co dwie minuty.
Rozkład wzmacniania o zmiennych odstępach czasowych (VI - variable interval schedule). Rozkład wzmacniania sporadycznego, w którym wzmocnienie podaje się w różnych odstępach czasu, bez względu na liczbę wykonanych w tym czasie poprawnych reakcji.
Rozkład wzmacniania według stałych proporcji (FR - fixed ratio schedule). Rozkład wzmacniania sporadycznego, w którym wzmocnienie podaje się regularnie po pewnej liczbie poprawnych reakcji.
Rozkład wzmacniania według zmiennych proporcji (VR - variable ratio schedule). Rozkład wzmacniania sporadycznego, w którym wzmocnienie podaje się po zmiennej liczbie reakcji.
Rozmnażanie płciowe (sexual reproduction). Połączenie się gamet dwojga rodziców przeciwnej płci, które daje początek nowej istocie (posiadającej cechy genetyczne odziedziczone o obojgu rodzicach).
Rozpoznawanie (recognition). Metoda pomiaru stopnia zapamiętania materiału, w której od osoby badanej wymaga się wykrycia wyuczonego uprzednio elementu wśród różnych odpowiedzi przedstawionych do wyboru.
Rozumowanie (reasoning). Realistyczne myślenie ukierunkowane na rozwiązanie problemu.
Rozumowanie dedukcyjne (deductive reasoning). Typ rozumowania, w którym z przesłanek wyprowadza się wnioski wynikające z nich w sposób konieczny.
Rozumowanie indukcyjne (inductive reasoning). Metoda rozumowania, w której na podstawie obserwacji poszczególnych przypadków wyciąga się wniosek dotyczący pewnego stanu lub pojęcia abstrakcyjnego, organizującego te odrębne elementy i nadającego im znaczenie.
Rozumowanie oceniające; r. ewaluacyjne (evaluative reasoning). Myślenie krytyczne, które polega na ocenianiu słuszności, poprawności, stanu lub znaczenia jakiejś idei czy wytworu.
Rozumowanie transdukcyjne (transductive reasoning). Typ rozumowania, w którym dziecko, opierając się na podobieństwie, porównuje szczególne przypadki i dochodzi do wniosku, że przypadki podobne pod jednym względem są podobne pod wszystkimi względami.
Rozwiązywanie problemów (problem solving). Typ reagowania, w którym osiąga się cel przez eliminowanie przeszkód.
Różnica istotna (significant difference). Różnica odpowiadająca pewnej ustalonej z góry ocenie prawdopodobieństwa, uważanego za statystycznie wiarygodną gwarancję, że różnica ta jest prawdziwa i nie wynika tylko z przypadku; zwykle za różnicę istotną przyjmuje się taką, dla której p < 0,05 (prawdopodobieństwo mniejsze niż 5 na 100, że różnica taka mogła wystąpić przypadkowo).
Różnica siatkówkowa (retinal disparity). Niewielka różnica między obrazami tego samego przedmiotu na siatkówkach obu oczu; pomaga w spostrzeganiu głębi.
Różnicowanie (discrimination). Zdolność wykrywania różnic między dwoma bodźcami; w warunkowaniu zdolność wyszukiwania istotnych bodźców i reagowania na nie oraz hamowania reakcji na bodźce nieistotne.
Ruchowe włókno nerwowe. Zobacz Eferentne włókno nerwowe.
Ruchy skokowe (saccadic movements). Nieregularne, nagłe ruchy oka.
Rytm alfa; fale alfa (alpha waves). Częstotliwość uwidoczniona w EEG, typowa dla czynności bioelektrycznej mózgu w stanie odprężenia.
Rytm beta; fale beta (beta waves). Częstotliwość uwidoczniona w EEG, związana z okresami rozwiązywania problemów i ze stanem napięcia.
Rytm dobowy (circadian rhytms). Biologiczny cykl aktywności i snu, właściwy danemu gatunkowi. Jest dostosowany do wymagań energetycznych jednostki oraz charakteru jej środowiska.
Rytm theta; fale theta (theta waves). Częstotliwość uwidoczniona w EEG; prawdopodobnie przejaw procesu hamowania.
Rzeczywistość obiektywna (objective reality). Świat fizyczny, który poddaje się pomiarom i weryfikacji.
Rzeczywistość spostrzegana (perceived realisty). Obiektywna rzeczywistość spostrzegana przez jednostkę.
Rzetelność (reliability). Właściwość narzędzia pomiarowego; określa stopień zgodności między wynikami uzyskiwanymi przy kolejnych pomiarach dokonywanych za pomocą tego narzędzia.


Sadyzm (sadism). Dewiacyjne zastosowanie motywacji bólowej; motywskłaniający do zadawania bólu innym; postać bólu jako przyjemności.
Samokształtowanie (autoshaping). Proces uczenia się, w którym częstość reakcji wzrasta bardziej dzięki wytwarzanym przez dany organizm czynnikom wzmacniającym, niż dzięki dostarczanym przez tę reakcję wzmocnieniom zewnętrznym.
Samorealizacja (self-actualization). Stałe dążenie do pełnego zrealizowania swych wrodzonych możliwości; uznane (przez Goldsteina, Rogersa, Maslowa i innych) za najbardziej podstawowy cel człowieka.
Samoregulacja (self-regulatory process). Zdolność umożliwiająca jednostce kierowanie własnymi działaniami, dzięki której ocenia ona swe zachowanie stosownie do osobistych norm i dostarcza sobie własnych wzmocnień; pojęcie odgrywające ważną rolę w teoriach uczenia się społecznego.
Schemat działań; algorytm (flow chart, algorithm). Graficzne przedstawienie kolejności kroków, wyborów i czynności w pewnym procesie lub działaniu.
Schematy (schemata). W teorii Piageta, wzorce czy struktury poznawcze ukształtowane w wyniku akomodacji, wiążące działania jednostki z celami, do których ona dąży.
Schizofrenia (schizophrenia). Psychoza, dla której charakterystyczne są: dezintegracja funkcjonowania osobowości, oderwanie się od rzeczywistości, otępienie uczuciowe oraz zaburzenia emocji i procesów myślowych.
Schizofrenia paranoidalna (paranoid schizophrenia). Typ schizofrenii, w którym występują słabo usystematyzowane urojenia; urojenia często są nacechowane wrogością, podejrzliwością i agresywnością, występują także urojenia wielkościowe, jak również dezorganizacja osobowości.
Schizofrenia prosta (simple schizophrenia). Typ schizofrenii, dla którego charakterystyczne jest redukowanie stosunków z innymi ludźmi, apatia, zamknięcie się w sobie, dezintegracja procesów myślowych oraz trudne do zauważenia urojenia lub halucynacje.
Schizokineza (schizokinesis). Rozdwojenie reakcji, w którym wewnętrzne, fizjologiczne składniki reakcji warunkowej utrzymują się po wygaszeniu zewnętrznej reakcji behawioralnej. 
Seksizm Zobacz Szowinizm płci.
Selektywna przepuszczalność (selective permeability). Właściwość błony komórkowej neuronu, dzięki której pewne jony łatwiej przechodzą przez nią niż inne, co powoduje zmianę polaryzacji neuronu i umożliwia przekazywanie impulsów nerwowych.
Semantyka (semantics). Nauka o znaczeniu.
Sen REM (rapid eye movement sleep; REM). Faza snu, w której występują szybkie ruchy oczu; cechuje ją zahamowanie dowolnej aktywności mięśniowej, znaczne zmiany w funkcjonowaniu autonomicznego układu nerwowego, tak zwana aktywność okresowa oraz występowanie wzorca czynności bioelektrycznej mózgu charakterystycznego dla stanu pobudzenia; w fazie tej bardziej prawdopodobne jest występowanie marzeń sennych.
Serotonina (serotonin). Substancja przekaźnikowa wytwarzana w mózgu; odgrywa ważną rolę w wywoływaniu snu nocnego i ma pewien związek z zachowaniem schizofrenicznym. Badania na kotach wykazały, że jeśli zahamuje się jej wytwarzanie, to występują wzorce czynności bioelektrycznej mózgu podobne do tych, które są charakterystyczne dla zwierząt pozbawionych snu w fazie REM. 
Serwomechanizm (servomechanism). Ukierunkowana na cel, wrażliwa na błędy, samokorygująca się maszyna, w której dokonują się cztery podstawowe procesy: wejście, przetwarzanie, wyjście i sprzężeniezwrotne.
Siatkowaty układ aktywujący (reticular activating system, RAS).  Włókna nerwowe biegnące z tworu siatkowatego do wyższych ośrodków mózgowych, działające jako ogólny system wzbudzenia i mobilizujące organizm do działania.
Siatkówka (retina). Wewnętrzna warstwa oka zawierająca wrażliwe na światło pręciki i czopki.
Sigma; (sigma). Litera grecka stosowana zamiast słowa „suma.
Siła nawyku (habit strength). W teorii uczenia się Hulla, wyuczony związek między bodźcem a reakcją; jednostka uczenia się i zmienna pośrednicząca.
Skala ilorazowa (ratio scale). Skala pomiarowa, która ma wszystkie właściwości skal nominalnych, porządkowych i przedziałowych, a ponadto ma tę właściwość, że jej początkiem jest zero bezwględne. Skale takie stosuje się najczęściej do pomiarów fizycznych, na przykład przy określaniu ciężaru i długości.
Skala Inteligencji dla Dorosłych Wechslera; Test Wechslera (WAIS; 
„Wechsler Adult Intelligence Scale). Zestaw testów inteligencji do badania dorosłych zawierający zarówno podtesty wykonaniowe, jak i podtesty werbalne; stosowany także do diagnozowania defektów poznawczych na podstawie rozmaitych układów wyników poszczególnych podtestów. Dostępna jest także wersja dla dzieci (WISC).
Skala Makiawelizmu (Mach scale). Skala pomiarowa pozwalająca określić, w jakim stopniu dana jednostka akceptuje zasady postępowania głoszone przez Machiavelliego; osoby o niskim poziomie makiawelizmu uznają absolutne normy postępowania, podczas gdy osoby o wysokim poziomie makiawelizmu uznają normy relatywne i akceptują manipulację.
Skala nominalna (nominal scale). Skala pomiarowa, w której liczby stosuje się jedynie dla odróżnienia jednej osoby lub kategorii osób od innych; liczby te nie reprezentują ilości czegoś; klasyfikacja jakościowa, nazywanie.
Skala ocen (rating scale). Narzędzie służące do rejestrowania sądów osoby oceniającej siebie lub innych ludzi pod względem określonych cech. W wypadku relatywnych skal ocen oceniający porządkuje osoby w danej grupie ze względu na daną cechę (od najlepszej do najgorszej). W wypadku absolutnych skal ocen sędzia, uwzględniając każdą z ocenianych cech, przypisuje danej osobie pewną bewzględną wartość czy wynik.
Skala porządkowa (ordinal scale). Skala pomiarowa, która służy do odróżnienia jednej osoby lub wyniku od pozostałych; wskazuje także, czy dana osoba posiada mierzoną cechę w większym, czy w mniejszym stopniu niż inne osoby w grupie.
Skala przedziałowa; s. interwałowa (interval scale). Skala pomiarowa mająca wszystkie właściwości skal nominalnych i porządkowych, a ponadto charakteryzująca się równymi jednostkami; to znaczy jednakowe różnice wyników reprezentują równej wielkości różnice pod względem mierzonej właściwości.
Skala zmian życiowych (life change rating). Skala skonstruowana w celu mierzenia stopnia przystosowania, jakiego wymagają różnego rodzaju zmiany życiowe, zarówno negatywne, jak i pozytywne.
Skalowanie psychofizyczne (psychophysical scalling). Techniki pomiaru reakcji psychicznej na bodźce fizyczne.
Składnia (syntax). Gałąź analizy lingwistycznej, w której przedmiotem zainteresowania jest kolejność i wzajemne relacje słów oraz zwrotów tworzących zdania.
Skrzynka Skinnera (Skinner box). Proste urządzenie stosowane w eksperymentach nad warunkowaniem sprawczym. Skrzynka zawierająca dźwignię lub inny mechanizm, którym osobnik biorący udział w eksperymencie manipuluje (reakcja sprawcza), aby otrzymać pokarm lub jakąś inną nagrodę.
Skutki odległe (remote effects). Skutki interwencji ujawniające się w jakiejś części systemu odległej od tej, która jest właśnie badana.
Skutki odroczone (delayed effects). Skutki interwencji, które ujawniają się nie od razu, lecz po upływie pewnego czasu.
Słowo osiowe (pivot words). Niewielka grupa słów, które można łączyć z wieloma innymi słowami, tworząc w ten sposób sensowne zdania złożone z dwóch słów; stosowane przez dzieci między osiemnastym a dwudziestym czwartym miesiącem życia.
Socjalizacja (socialization). Proces uczenia się społecznego, dzięki któremu jednostka (zwykle dziecko) zaczyna poznawać i realizować system wartości, postaw i podstawową strukturę przekonań pochodzących od dominujących instytucji i reprezentantów społeczeństwa, a także identyfikować się z nimi.
Soczewka (lens). Przezroczysta struktura w oku skupiająca promienie świetlne na wrażliwej (światłoczułej) siatkówce.
Somatyczne pola czuciowe (somatosensory areas). Pola kory mózgowej zawiadujące kinestezją i zmysłami skórnymi; główne pole czuciowe znajdujące się tuż za bruzdą Rolanda, rzutowane są na nie informacje z powierzchni ciała.
Somnabulizm; lunatyzm (somnabulism). Chodzenie we śnie; może być, między innymi, jedną z odmian stanu dysocjacji.
Specjalizacja (specialization). Przystosowanie danej struktury do wykonywania jakiejś szczególnej funkcji. U organizmów wielokomórkowych struktury komórkowe osiągnęły wysoki poziom specjalizacji pod względem wypełnianych przez nie funkcji.
Specjalizacja lateralna (lateral specialization). Dwustronność funkcji mózgu występująca tylko u ludzi i polegająca na tym, że dwie półkule mózgowe są wyspecjalizowane w wypełnianiu odmiennych funkcji.
Specjalizacja półkul mózgowych (cerebral specialization). Swego rodzaju podział pracy między dwiema półkulami mózgowymi - specjalizacja ich funkcji: półkula dominująca zawiaduje mową, pisaniem oraz operacjami matematycznymi, podczas gdy półkula podporządkowana steruje wykonywaniem zadań percepcyjnych; określany także jako lateralizacja funkcji.
Spektogram dźwięków (sound spectogram). Graficzny zapis wymawianych dźwięków; na otrzymanym wykresie oś pozioma przedstawia czas, pionowa - częstotliwość dźwięków; jego natężenie jest zaznaczone różnym stopniem zaciemnienia pola tego wykresu.
Społeczność terapeutyczna (therapeutic community). Środowisko szpitalne lub zakładowe, w którym w celach terapeutycznych dąży się do wytworzenia poczucia wspólnoty społecznej między pacjentami a personelem.
Spontaniczne odnowienie (spontaneous recovery). Ponowne pojawienie się wygaszonej uprzednio reakcji warunkowej po upływie pewnego czasu, bez podawania bodźców.
Spostrzeganie pozazmysłowe (extrasensory perception; ESP).  Spostrzeganie lub doznawanie bez pośrednictwa jakiegokolwiek (znanego nam) pobudzenia czy aktywności narządów zmysłowych.
Spostrzeganie prawdziwe (veridical perception). Spostrzeganie, w przypadku którego subiektywne doświadczenie percepcyjne danej osoby zgodne jest z obiektywnymi cechami fizycznymi określonego przedmiotu (cechami, które można mierzyć i weryfikować).
Spostrzeżenie (percept). To, co jest spostrzegane, doświadczenie percepcyjne; zwane także doświadczeniem fenomenologicznym.
Sprzężenie zwrotne (feedback). Proces, w którym informacja o poprawności poprzednich reakcji, będących pod kontrolą danej jednostki, wraca do jej ośrodka sterowania, dzięki czemu może ona dokonać poprawek niezbędnych dla pokierowania późniejszymi reakcjami; znajomość wyników.
Stadia rozwoju psychospołecznego (psychosocial stages). Stadia rozwoju ego wyodrębnionego przez Eriksona, uwzględniające zarówno aspekty seksualne, jak i społeczne.
Stadium odporności. Zobacz Ogólny zespół adaptacyjny.
Stadium wyczerpania. Zobacz Ogólny zespół adaptacyjny.
Stałość spostrzegania przedmiotów (object constancy). Spostrzeganie ciągłego istnienia przedmiotu jako tego samego przedmiotu, pomimo zmian wielkości, kształtu i pozycji obrazu na siatkówce.
Stałość wielkości (size constancy). Tendencja do spostrzegania rzeczywistej wielkości znajomego przedmiotu, niezależnie od jego odległości od obserwatora.
Stan popędu (drive state). Termin wprowadzony przez Thorndikea na określenie silnych bodźców wewnętrznych, które skłaniają organizm do działania.
Stany afektywne (affective states). Stany lub doznania emocjonalne - bez względu na to, czy wchodzące w grę emocje są słabe czy silne, przyjemne czy nieprzyjemne.
Stany dysocjacji (dissociated states). Neurotyczne reakcje na silny stres, w którym całe epizody życia bywają wypierane ze świadomości; procesy psychiczne mogą ulec odłączeniu od zasadniczej osobowości, a mogą także zaniknąć występujące w nich zwykle powiązania między myślami a emocjami, jak w przypadku amnezji, fugi i osobowości wielokrotnej.
Statystyka opisowa (descriptive statistic). Pojedyncza liczba, która reprezentuje, czyli opisuje, szereg pomiarów dokonanych w pewnej grupie; na przykład miara tendencji centralnej, miara zmienności, współczynnik korelacji.
Stereotyp (stereotype). 1. Według Sullivana, personifikacja wspólna dla pewnej grupy ludzi. 2. Z góry przyjęte często tendencyjne, wyobrażenie o tym, jak ludzie danej rasy, narodowości czy zawodu wyglądają lub się zachowują.
Stopki końcowe (end feet). Struktury znajdujące się na końcu aksonu, które łączą się z inną komórką nerwową za pośrednictwem synapsy; zwane są także kolbkami synaptycznymi (synaptic knobs).
Strach (fear). Racjonalna reakcja na obiektywne, rozpoznawalne, zewnętrzne zagrożenie (odróżniana od nie związanego z określoną przyczyną lęku neurotycznego), konsekwencje społeczne zależą zwykle od jej adekwatności do danej sytuacji.
Strategie radzenia sobie z sytuacją (coping strategies). Możliwe sposoby uporania się z sytuacją, którą dana jednostka spostrzega jako zagrażającą; różne strategie radzenia sobie, jakie można zastosować w danej sytuacji, są oceniane w procesie oceny wtórnej.
Stres (stress). Niespecyficzna reakcja fizjologiczna i psychiczna jednostki na wszelkie wymagania środowiskowe lub zagrożenie jej integralności.
Stresor (stressor). Każdy czynnik potencjalnie szkodliwy dla organizmu, czy to fizycznie czy psychicznie, wystawiający na próbę jego adaptacyjne zdolności.
Struktura głęboka (deep structure). Podstawowe znaczenie zdania; ta sama struktura głęboka może posłużyć do wytworzenia - za pomocą reguł transformacji - kilku różnych struktur powierzchniowych.
Struktura intelektu (structure of intellect). Usystematyzowany układ odniesienia zastosowany przez Guilforda dla sklasyfikowania czynników intelektualnych zgodnie z ich treścią, rodzajem dokonywanych operacji i wytworami.
Struktura powierzchniowa (surface structure). Części składowe zdania i ich powiązania.
Styczność (contiguity). Relacja między bodźcem warunkowym a reakcją, które występują blisko siebie w czasie i przestrzeni. Zgodnie ze współczesnymi teoriami psychologicznymi, jest warunkiem koniecznym, lecz nie wystarczającym, aby wyjaśnić uczenie się skojarzeń.
Sublimacja (sublimation). Mechanizm obronny, dzięki któremu nieakceptowane motywy czy instynktowne popędy są zastępowane aprobowanymi społecznie formami aktywności.
Substancje przekaźnikowe (transmitter substances). Substancje chemiczne, które umożliwiają przejście impulsu nerwowego z jednego neuronu na drugi; wydzielane w zakończeniach neuronu dyfundują przez szczelinę synaptyczną, oddziałują na specyficzne części receptorowe znajdujące się na błonie postsynaptycznej przyległych neuronów i albo pobudzają, albo hamują te neurony; jedną z takich substancji jest acetylocholina.
Sugestia posthipnotyczna (posthynostic sugesstion). Polecenie dane osobie zahipnotyzowanej, które ma ono wykonać po jakimś czasie od zakończenia seansu hipnotycznego jako reakcję na określony sygnał.
Sumienie (conscience). Wewnętrznie funkcjonujące (społecznie wyuczone) normy dobra i zła, za pomocą których jednostka ocenia swe własne zachowanie; odpowiada superego.
Sumowanie czasowe (temporal summation). Zjawisko polegające na tym, że impulsy nerwowe docierają do neuronu postsynaptycznego w krótkich odstępach czasu, jedne po drugich, a ich oddziaływania sumuje się.
Sumowanie przestrzenne (spatial summation). Zjawisko polegające na tym, że impulsy nerwowe z kilku różnych aksonów lub zakończeń jednego aksonu docierają do neuronu postsynaptycznego w tym samym czasie, a ich oddziaływania sumują się.
Superego (Superego). Zgodnie z freudowską teorią psychoanalityczną, część osobowości obejmująca zinternalizowane wartości moralne przyswojone przez daną jednostkę w dzieciństwie; składa się z dwóch elementów: sumienia i ja idealnego.
Swobodne skojarzenia (free association). Podstawowa metoda psychoanalityczna stosowana do sondowania nieświadomości; pacjent pozwalając błądzić myślom, opisuje wszystkie pojawiające się kolejno myśli i uczucia.
Sygnały lokalizacji dźwięku (sound localization cues). Sygnały umożliwiające organizmowi zlokalizowanie położenia (odległości i kierunku) źródeł dźwięku; należą do nich różne fazy, czasu i natężenia fal dźwiękowych odbieranych przez uszy.
Sylaba bezsensowna (nonsense syllable). Sylaba składająca się z dwóch spółgłosek rozdzielonych samogłoską, nie mająca żadnego znaczenia; wynaleziona przez Ebbinghausa i zastosowana w badaniach nad pamięcią.
Sylogizm (syllogism). Analiza dedukcyjna formalnego problemu składającego się z dwóch przesłanek i wniosku.
Symbole (symbols). Najbardziej wyrafinowany środek myślowego odwzorowania, w którym obraz lub słowo służą do przedstawienia jakiegoś obiektu.
Symulacja (symulation). Sposób wyjaśnienia zachowania polegający na sztucznym odwzorowaniu istotnych elementów danego systemu; często wykorzystuje się tu komputer, który przetwarza informacje w sposób określony przez model (to jest program opracowany przez psychologów w celu symulowania rzeczywistych zachowań człowieka).
Synapsa (synapse). Szczelina między stopką końcową jednego neuronu lub innych neuronów.
System ja (self-system). W teorii osobowości Sullivana, tak zwany dynamizm, który rozwija się, gdy dana jednostka uczy się unikać zagrożenia swego bezpieczeństwa, często koliduje to z umiejętnością efektywnego postępowania z innymi ludźmi, ponieważ czynnik ten jest odizolowany od reszty osobowości.
Szlak nerwowy (nerve tract). Droga nerwowa; wiązka włókien nerwowych, które wychodzą z tego samego punktu i biegną do wspólnego przeznaczenia.
Szowinizm płci; seksizm (sexizm). Uprzedzenie i dyskryminacja stosowane jedynie ze względu na płeć danej jednostki.Szufladkowanie. Zobacz „Izolowanie.
Szum (noise). W fizjologii, występująca w otoczeniu energia o niskim natężeniu, wychwytywana przez komórki receptorowe, lecz zbyt słaba, aby spowodować pobudzenie neuronów czuciowych. W detekcji sygnałów, uboczne źródło energii, która zakłóca lub maskuje właściwy sygnał.
Szyszynka (pineal gland). Mały gruczoł wydzielania wewnętrznego mieszczący się w pniu mózgu; działa jako biologiczny system pomiaru czasu, jest wrażliwy na cykl światła i ciemności (nocy i dnia); wydziela między innymi melatoninę, wpływającą z kolei na sekrecję hormonów płciowych.  Uważany przez Descartesa za jedyny punkt interakcji między ciałem a duszą.


Ślepa plamka (blind spot). Miejsce siatkówki, w którym nerw wzrokowy wychodzi z oka i które dlatego właśnie nie zawiera komórek receptorowych.
Ślepe posłuszeństwo wobec autorytetu (blind obedience to authority).  Uległość wobec życzeń czy rozkazów innych ludzi, nawet z pogwałceniem własnych przekonań oraz powszechnie uznawanych wartości moralnych; posłuszeństwu takiemu może sprzyjać obecność prawowitego autorytetu, istnienie norm społecznych zalecających uległość oraz ustanowienie relacji ról zwierzchnik-podwładny.
Ślimak (cochlea). Część ucha wewnętrznego zawierająca płyn wprawiany w ruch przez drgania okienka owalnego; ruchy tego płynu stymulują z kolei błonę podstawową.
Śmierć voodoo (voodoo death). Przypadki nagłej śmierci, które zdarzają się wtedy, gdy osoba wierząca w czary, voodoo itp. ma poczucie, iż wykroczyła przeciw siłom nadprzyrodzonym lub została przez nie nawiedzona.
Średnia (mean). Jedna z miar tendencji centralnej; otrzymuje się ją dodając do siebie pewien zbiór wyników i dzieląc uzyskaną sumę przez liczbę tych wyników; zwana także średnią arytmetyczną.
Środki antydepresyjne (antidepressant drugs). Środki podnoszące nastrój i usuwające depresję; stosowane w chemioterapii.
Środki halucynogenne (hallucinogens). Grupa środków psychotropowych zwanych także psychodelicznymi; należą do nich między innymi LSD-25, psylocybina i meskalina; mogą powodować głębokie zmiany w percepcji.
Środki narkotyczne o działaniu przeciwbólowym (narcotic analgesics).  Grupa środków psychotropowych obejmująca opium i jego pochodne (takie, jak heroina) oraz pewne środki syntetyczne. Są to środki przeciwbólowe, które dają ponadto poczucie ogólnej euforii; szybko rozwija się tolerancja i wytwarza się silne uzależnienie fizjologiczne, które powoduje, że odstawienie tych środków jest trudne i traumatyczne.
Środki nasenne (hypnotics). Grupa środków psychotropowych obejmująca głównie barbiturany (środki uspokajające, które działają hamująco na ośrodkowy układ nerwowy); mają one znaczną zdolność wywoływania uzależnienia psychicznego u zażywających je osób.
Środki pobudzające (stimulants). Grupa środków psychotropowych, które pobudzają ośrodkowy układ nerwowy i początkowo podnoszą nastrój; należą do nich amfetamina, metamfetamina (zwana przyspieszaczem), kokaina i kofeina (znajdująca się w kawie, herbacie i orzeszkach kola); szybko rozwija się tolerancja i wytwarza się silne uzależnienie psychiczne od tych środków.
Środki pobudzające (energizers). Środki farmakologiczne o działaniu pobudzającym stosowane w chemioterapii po to, aby pacjent czuł się bardziej energiczny; przykładem takiego środka jest imipramina.
Środki przeciwlękowe; ś. atarktyczne (antianxiety drugs). Środki farmakologiczne stosowane dla złagodzenia lub wyeliminowania lęku; używane w chemioterapii.
Środki psychotropowe (psychoactive drugs). Środki farmakologiczne, które wpływają na procesy psychiczne.
Środki uspokajające; trankwilizatory (tranquilizers). Środki farmakologiczne stosowane w chemioterapii do zwalczania psychoz; służą do redukowania lęku i napięcia.
Świadome (conscious). W teorii freudowskiej, myśli, idee, uczucia i pragnienia, z których jednostka zdaje sobie sprawę w danym momencie.
Świadomość (consciousness). Stan, w którym jednostka zdaje sobie sprawę ze zjawisk wewnętrznych (takich, jak własne procesy myślowe) oraz zjawisk zachodzących w środowisku zewnętrznym; zwykły stan czuwania.


Tachistoskop (tachistoscope). Urządzenie stosowane w badaniach eksperymentalnych do krótkotrwałego eksponowania słów, symboli, obrazków i innych bodźców wzrokowych.
Tanatos (Thanatos). Zgodnie z teorią freudowską instynkt agresji, czyli instynkt śmierci, jeden z dwóch popędów obecnych od urodzenia; obejmuje wszelkie dążenia do samozagłady i niszczenia porządku.
Techniki projekcyjne (projective techniques). Metody pomiaru cech osobowości, w których osobie badanej przedstawia się znormalizowany zbiór wieloznacznych lub neutralnych bodźców i zachęca się ją do swobodnego interpretowania tego, co widzi.
Telepatia (telepathy). Forma spostrzegania pozazmysłowego, w której spostrzeżenia są rzekomo oparte na bezpośrednim przekazywaniu myśli przez jedną osobę - drugiej.
Tendencja instynktowna (instinctual drift). Tendencja organizmu do odrzucania zachowania wzmacnianego w trakcie ćwiczenia na rzecz reakcji nieproduktywnych, lecz przypominających mu reakcje, które wykonywał w swym naturalnym środowisku.
Tendencja do zgadzania się (acquiescence set). Skłonność do odpowiadania tak na pytania testowe, nawet gdy nie byłoby stosowniejsze.
Teoria (theory). Usystematyzowane zestawienie związków między założeniami, regułami postępowania, różnymi obserwowanymi faktami oraz wyprowadzonymi z nich wnioskami. Teorie wyjaśniają znane fakty, ujawniają związki między zjawiskami i pomagają przewidywać to, co jeszcze nie jest znane.
Teoria atrybucji (attribution theory). Sformułowana rzez Heidera teoria, zgodnie z którą zdarzeniom zachodzącym w naszym życiu nadajemy sens i umożliwiamy ich przewidywanie, kształtując w sobie realistyczne i regulacyjne nastawienie wobec świata, a to przez przypisywanie przyczyn spostrzeganym działaniom i zdarzeniom.
Teoria częstotliwości (frequency theory). Teoria kodowania dźwięków, która głosi, że częstość impulsów przebiegających w nerwie słuchowym jest bezpośrednio skorelowana z częstotliwością fal dźwiękowych.
Teoria dysonansu poznawczego (cognitive dissonance theory). Zasada, zgodnie z którą będące w dysonansie (niespójne czy niezgodne ze sobą) elementy poznawcze motywują daną jednostkę do zredukowania spostrzeganej niespójności i osiągnięcia większego konsonansu (zgodności). Może to nastąpić wtedy, gdy jeden z tych elementów ulegnie zmianie lub gdy zostaną dodane nowe elementy; teoria sformułowana przez Festingera.
Teoria interferencji (interference theory). Teoria, zgodnie z którą zapominanie jest powodowane przez nowe informacje, kolidujące z wcześniej przyswojonym materiałem.
Teoria Jamesa-Langego (James-Lange theory). Teoria głosząca, że emocja polega na zmianach fizjologicznych, które są reakcją na pobudzające zdarzenie; stwierdza ona, że odczuwamy smutek, ponieważ płaczemy, a nie na odwrót; w teorii tej po raz pierwszy poddano w wątpliwość pogląd, iż procesy psychiczne rządzą reakcjami organizmu.
Teoria języka jako formy (mold theory of language). Teoria, zgodnie z którą wzorce językowe grupy kulturowej kształtują wzorce myślenia i spostrzeżenia jednostek w danej kulturze; znana także jako hipoteza Whorfa.
Teoria języka jako „osłonki (cloak theory of language). Teoria, zgodnie z którą struktura języka odzwierciedla wzorce myślenia danej grupy kulturowej i jest przez nie determinowana.
Teoria kontroli wejściowej (gate-control theory of pain). Opracowana przez Melzacka teoria bólu postulująca istnienie systemu kontrolnego, który nieustannie moduluje przychodzące sygnały bólowe; wiąże się to z regulacją wejścia aferentnego przez procesy eferentne.
Teoria miejsca (place theory). Teoria słyszenia opracowana przez Helmholtza, który utrzymywał, że błona podstawowa składa się z wielu rezonujących włókien, z których każde jest dostrojone do innej częstotliwości.
Teorie neofreudowskie (neo-Freudian theories). Grupa teorii osobowości głoszonych przez współczesnych psychologów, którzy zmodyfikowali na różne sposoby podstawową teorię Freuda; należą do nich między innymi teoria Junga i teoria Adlera.
Teoria organizmu jako całości (organismic theory). Teoria osobowości, w której kładzie się nacisk na zdolność do organizowania się jako naturalną właściwość organizmu; zwraca się w niej uwagę na harmonijny rozwój jego wrodzonych, potencjalnych możliwości oraz na jego jedność; opiera się na teorii pola.
Teoria percepcji Eleonory Gibson (Gibsons perception theory). Teoria, zgodnie z którą spostrzeganie jest procesem redukowania wejścia sensorycznego polegającym na odfiltrowywaniu istotnych elementów sygnału od nadmiaru szumu bodźcowego.
Teoria pola (field theory). Model psychologiczny skonstruowany przez analogię do pól sił w fizyce; w modelu tym zjawiska psychiczne reprezentują wypadkową interakcji wielu sił.
Teoria psychoanalityczna (psychoanalytic theory). Teoria osobowości stworzona przez Freuda; kładzie nacisk na wczesne doświadczenia z okresu dzieciństwa, seksualność oraz procesy nieświadome, które mają być czynnikami wpływającymi na rozwój osobowości i jego wypaczenia.
Teoria salwy (volley theory). Teoria słyszenia, która głosi, że włókna nerwowe działają w grupach, przy czym różne włókna wysyłają salwy impulsów w różnych momentach, dzięki czemu wiązka włókien może odtwarzać wysokie częstotliwości.
Teoria selekcji społecznej (social selection theory of pathology).  Teoria dotycząca związku między przynależnością do klasy społecznej a częstością zapadania na choroby psychiczne, zgodnie z którą większa część występowania powyższych zaburzeń psychicznych w klasach niższych jest spowodowana czynnikami genetycznymi.
Teoria słuszności (equity theory). Teoria odnosząca się do stosunków międzyludzkich, która między innymi głosi, że ludzie starają się maksymalizować osiągane wyniki, uzyskując możliwie największe nagrody przy minimum kosztów.
Teoria stresu społecznego (social stress theories of pathology). Teoria dotycząca związku między przynależnością do klasy społecznej a częstością zapadania na choroby psychiczne, zgodnie z którą stres środowiskowy oddziaływujący z większą siłą na ludzi ubogich prowadzi do częstszego występowania u nich patologicznych zaburzeń osobowości i patologicznego funkcjonowania społecznego.
Teoria telefoniczna (telephone theory). Jedna z teorii wyjaśniających zasadę odbierania dźwięków; zgodnie z którą, błona podstawowa spełnia rolę mikrofonu w telefonie, wysyłając do mózgu impulsy o różnych częstotliwościach.
Teoria uczenia się społecznego (social learning theory). Teoria głosząca, że funkcjonowanie psychiczne najlepiej można zrozumieć rozpatrując je jako ciągłą wzajemną interakcję między zachowaniem i oddziałującymi nań warunkami, to jest wpływami środowiskowymi, które obejmują bodźce społeczne i doznawane wzmocnienia, jak również historię uczenia się.
Teoria usuwania (displacement theory). Teoria zapominania, zgodnie z którą pojemność magazynu pamięciowego jednostki jest ograniczona, a po przekroczeniu pewnej granicznej wartości nowe informacje mogą znaleźć się w tym magazynie tylko wówczas, jeśli wypchną czy usuną informacje już się w nim znajdujące.
Teoria utraty dostępu (loss of access theory). Teoria, według której zapominanie jest procesem polegającym na utracie dostępu do informacji ze względu na brak odpowiednich sygnałów umożliwiających ich odszukanie.
Teoria zanikania śladów (decay theory). Teoria zapominania głosząca, że wyuczony materiał pozostawia w mózgu ślad, który zanika, jeśli nie czyni się z niego użytku.
Teoria zyskiwania i utraty (gain-loss theory of attraction). Model atrakcyjności interpersonalnej, zgodnie z którym zmiany pozytywnej bądź negatywnej oceny ze strony innej osoby mają większy wpływ na jej atrakcyjność interpersonalną niż stała, niezmienna ocena; teoria sformułowana przez Aronsona.
Terapia atrybucyjna (attribution therapy). Teoria oparta na przekonaniu, że problem acjenta często polega nie tyle na doznawaniu pewnych objawów i uczuć, ile na przypisywanym im znaczeniu i przyczynom; w terapii tej dostarcza się pacjentowi nowych czy odmiennych interpretacji jego doznań oraz informacji o czynnikach będących przyczyną tych doznań. 
Terapia behawioralna (behavioristic therapy). Typ psychoterapii, w której terapeuci koncentrują się na obserwowalnym zachowaniu, wykorzystując zasady uczenia się (takie jak stosowanie wzmocnienia) do wykrywania warunków bodźcowych podtrzymujących patologiczne zachowania oraz zmieniając te warunki tak, aby zmodyfikować dane zachowanie.
Terapia implozyjna (implosive therapy). Forma terapii behawioralnej, stworzona przez Stampfla; wygaszanie następuje w niej dzięki wyobrażeniu sobie wzbudzających lęk bodźców, które to przywołanie nie przynosi żadnej szkody; terapia nazywa się implozyjną, ponieważ przerażające bodźce wywołują eksplozję wewnętrzną - czyli implozję - panicznego lęku.
Terapia niedyrektywna (nondirective therapy). Typ psychoterapii humanistycznej, w której terapeuta powstrzymuje się od udzielania rad i kierowania przebiegiem terapii, odzwierciedlając jedynie myśli, troski i uczucia pacjenta. Zobacz także Terapia skoncentrowana na pacjencie.
Terapia psychobiologiczna (psychobiological therapy). Terapia oparta na elektycznym podejściu do terapii, wprowadzona przez Meyera, w której celem ma być zrozumienie wszelkich czynników - biologicznych, psychologicznych i społecznych - które mogłyby przyczynić się do powstania danego zaburzenia.
Terapia retroaktywna (retroactive therapy). Postępowanie terapeutyczne mające załagodzić pewien stan (np. wyuczonej bezradności), gdy stan ten już wystąpił lub został wytworzony. 
Terapia skoncentrowana na pacjencie (client-centered therapy).  Niedyrektywna technika psychoterapii humanistycznej oparta na teorii, że wiele osób może rozwiązać swe problemy dzięki wygadaniu się w przyzwalającej i zapewniającej oparcie atmosferze. Zobacz także Terapia niedyrektywna.
Terapia wstrząsowa (shock therapy). Forma biologicznej, czyli somatycznej psychoterapii; jest to metoda leczenia poważnych zaburzeń psychicznych przez wywołanie (zwykle za pomocą prądu elektrycznego lub wstrzyknięcia insuliny) drgawek, po których następuje utrata świadomości.
Terapia zintegrowana (integrated therapy). Psychoterapia oparta na podejściu elektycznym, w którym nie kładzie się nacisku na żadną szczególną teorię czy procedurę, lecz stosuje się wszelkie metody terapeutyczne, które wydają się odpowiednie w danym, indywidualnym przypadku.
Test Apercepcji Tematycznej; TAT (Thematic Apperception Test). Technika projekcyjna, w której osobę badaną prosi się, aby wymyśliła opowiadanie o każdym z pokazywanych jej obrazków; następnie analizuje się tematy tych opowiadań, wyprowadzając wnioski co do istnienia u badanego różnych źródeł motywacji.
Test chi-kwadrat; („chi-square test). Test wnioskowania statystycznego; test służący do porównywania częstości otrzymanych różnych możliwych zdarzeń z częstościami przewidywanymi na zasadzie losowej.
Test F (F-test). Test wnioskowania statystycznego, znany także jako test analizy wariancji, służy do porównywania zróżnicowania między grupami (dwiema i więcej) ze zróżnicowaniem wewnątrzgrupowym.
Test Rorschacha (Rorschach test). Test projekcyjny, w którym jako bodziec stosuje się szereg symetrycznych plam atramentowych.
Test Stanford-Bineta (Stanford-Binet Test). Stanfordzka wersja testu Bineta; jest to test indywidualny, składający się z podtestów przeznaczonych dla poszczególnych poziomów wieku; test inteligencji najpowszechniej stosowany do badania dzieci.
Test t (t-test). Test wnioskowania statystycznego stosowany w celu ustalenia prawdopodobieństwa, że różne zbiory wyników pochodzą z tej samej populacji.
Test Wechslera Zobacz Skala Inteligencji dla Dorosłych Wechslera.
Test wykonaniowy (performance test). Test, w którym wymagane są reakcje ruchowe, a nie słowne; może być stosowany do badania inteligencji.
Tolerancja (tolerance). Proces fizjologiczny, w wyniku którego wpływ danego środowiska zostaje zredukowany na skutek tego, że był on już zażywany uprzednio; powoduje to konieczność brania coraz większych ilości danego środka, aby osiągnąć te same efekty, które poprzednio wywoływała mniejsza dawka.
Tolerancja krzyżowa (cross-tolerance). Tolerancja wytworzona pod wpływem jednego środka farmakologicznego, która generalizuje się tłumiąc działanie innego, podobnego pod względem chemicznym środka.
Trafność (validity). Stopień, w jakim dane narzędzie rzeczywiście mierzy to, co ma mierzyć; stosowność danego pojęcia, idei, narzędzia pomiarowego. Trafność może być oceniana na podstawie kryteriów zewnętrznych lub spójności wewnętrznej.
Transakcyjne podejście do spostrzegania (transactional approach to perception). Teoria, która stwierdza, że spostrzeżenie jest wynikiem naszych wyuczonych relacji z podmiotami i zdarzeniami zachodzącymi w środowisku; rzeczywistość jest więc konstruowana z naszych przypuszczeń i hipotez dotyczących związków między rzeczami, ludźmi i czynnościami, a ukształtowanych na podstawie uprzednich stosunków z nimi.
Transdukcja (transduction). Proces, dzięki któremu organizm otrzymuje informacje o natężeniu bodźca.
Traumatyczne zdarzenie (traumatic events). Zdarzenie fizyczne lub psychiczne przynoszące szkodę, stresujące lub szokujące; zdarzenia takie, występujące we wczesnym okresie życia, mogą być źródłem lęków lub nerwicy w wieku dojrzałym.
Treść jawna (manifest content). We freudowskiej analizie snów, powierzchowna treść marzenia sennego, taka, jaką pamiętamy; maskuje niemożliwą do zaakceptowania, przykrą emocjonalnie treść utajoną.
Treść utajona (latent content). We freudowskiej analizie snów, ukryta treść marzenia sennego, która mówi o prawdziwych pragnieniach danej jednostki, przekształcana w symboliczną, lecz bardziej możliwą do zaakceptowania treść jawną.
Twór siatkowaty (reticular formation). Masa jąder i włókien nerwowych w pniu mózgu, nieco powyżej rdzenia kręgowego; odgrywa ważną rolę w pobudzaniu i aktywacji organizmu, a także w sterowaniu uwagą i w różnicowaniu percepcyjnym.
Tymina (thymine). Jedna z czterech zasad nukleotydowych, z których składa się cząsteczka DNA; wiąże się z adeniną.


Ubytek (dekrement) generalizacji (generalization decrement). Proces, w wyniku którego reakcje na bodźce nie poddane bezpośrednio wygaszaniu również zostają wygaszone, proporcjonalnie do podobieństwa tych bodźców do bodźca warunkowego; przeciwieństwo generalizacji bodźca.
Uczenie się awersyjne (aversive learning). Forma kontrwarunkowania (przeciwwarunkowania) przez stosowanie kary, używana niekiedy podczas leczenia takich zaburzeń, jak homoseksualizm, jąkanie i alkoholizm.
Uczenie się skojarzeń parami (paired-associate learning). Uczenie się, w którym badanemu przedstawia się najpierw pary elementów do zapamiętania, a następnie podaje mu się kolejno po jednym słowie czy sylabie z poszczególnych par, na co powinien zareagować wymieniając  drugie słowo czy sylabę z danej pary.
Uczenie się ponowne (relearning). Metoda pomiaru stopnia zapamiętania materiału; osoba badana uczy się ponownie tego samego materiału co uprzednio, w takich samych warunkach; miarę stopnia zapamiętania stanowi różnica czasu ćwiczenia niezbędnego dla osiągnięcia pierwotnego poziomu opanowania materiału.
Uczenie się przez obserwację (observational learning). Uczenie się przez obserwowanie modela i identyfikowanie się z nim; odgrywa ważną rolę w okresie dzieciństwa, zdeterminowane przez procesy uwagi, przechowywania w pamięci, odtwarzania motorycznego oraz procesy wzmacniania i procesy motywacyjne. Pojęcie ważne w teoriach uczenia się społecznego.
Uczenie się sygnału (signal learning). Nabyte, wyuczone oczekiwanie, że po jednym bodźcu (sygnale) nastąpi określony inny bodziec.
Układ limbiczny; u. rąbkowy (limbic system). Struktura oznaczająca górny kraniec pnia mózgu, aktywna w procesach uwagi, emocji, motywacji i pamięci.
Układ parasympatyczny; u. przywspółczulny (parasympathetic division).  Część autonomicznego układu nerwowego, która zawiaduje większością podstawowych funkcji życiowych, takich jak na przykład trawienie. Działanie tego układu jest w większości wypadków przeciwstawne (antagonistyczne) do działania układu sympatycznego; jego włókna nerwowe wychodzą z niższych segmentów rdzenia kręgowego i z pnia mózgu.
Układ sympatyczny; u. współczulny (sympathetic division). Część autonomicznego układu nerwowego, która jest aktywna w warunkach moblilizacji organizmu, takich jak bardzo niska temperatura, wytężony wysiłek lub intensywne ćwiczenia, stan strachu lub gniewu; włókna nerwowe tego układu biorą początek w segmentach rdzenia kręgowego znajdujących się między pniem mózgu a dolnym odcinkiem kręgosłupa.
Układ wydzielania wewnętrznego (endocrine system). Układ złożony z gruczołów wydzielających hormony, które regulują przemianę materii, koordynują różne procesy przebiegające w organizmie i mogą wpływać na emocje.
Ukryte (covert). To, czego nie można obserwować bezpośrednio, co jest utajone, wewnętrzne, niedostępne dla innych ludzi, jak na przykład czyjeś myśli.
Umysł (mind). Zdolność myślenia, przy czym myślenie pojmowane jest jako integracja aktywności mózgu.
Uodpornienie, emocjonalne (emotional inoculation). Proces przygotowawczy umożliwiający jednostkom złagodzenie lęku i planowanie przyszłych reakcji na zagrażające zdarzenie.
Upośledzenie umysłowe (mental retardation). Inteligencja znacznie niższa od normy (I.I. poniżej 68) z powodu chronicznych defektów zdolności poznawczych, przez co wiek umysłowy pozostaje daleko w tyle za wiekiem życia.
Uprzedzenie (prejudice). Zespół wyuczonych przekonań, postaw i wartości (zwykle negatywnych), które nastawiają daną jednostkę niechętnie wobec członków określonej grupy i prowadzą do dyskryminacyjnych zachowań; oparte jest to zwykle na niekompletnej informacji i względnej niewrażliwości na informacje niezgodne z uprzedzeniem.
Uraz psychiczny (psychic trauma). Doświadczenie stresowe o silnie  traumatycznym czy zaburzającym charakterze; skutki urazów psychicznych doznawanych we wczesnym okresie życia przejawia się niekiedy dopiero po wielu latach. 
Urojenie (delusion). Silne przekonanie niezgodne z rzeczywistością i utrzymujące się wbrew logicznej perswazji i zaprzeczającym mu dowodom; objawów stanów pranaoidalnych. Trzy zasadnicze typy urojeń: urojenia wielkościowe (przekonanie, że jest się jakąś wybitną postacią), urojenia prześladowcze (przekonanie, że jest się śledzonym i prześladowanym) oraz urojenia odniesienia, czyli urojenia ksobne (egocentryczne przekonanie danej osoby, że przypadkowe zdarzenia i rozmowy odnoszą się do niej.
Utajone (latent). To, co istnieje w postaci ukrytej, w stanie zawieszenia czy uśpienia, lecz może być wzbudzone czy wywołane w późniejszym czasie.
Uwaga selektywna (selective attention). Komponent procesu motywacyjnego; dany organizm zwraca uwagę na bodźce istotne czy ważne dla jego ukierunkowanego na cel zachowania, lecz wykazuje zmniejszoną wrażliwość na bodźce nieistotne czy uboczne z punktu widzenia tego celu.
Uwrażliwienie (sensitizing). Specyficzna funkcja motywacji, dzięki której organizm jest wrażliwy na sygnały wyzwalające określone sekwencje reakcji.
Uzależnienie fizjologiczne (physiological dependence). Zjawisko wywoływane przez pewne środki farmakologiczne, polega ono na tym, że na skutek długotrwałego zażywania danego środka dalsze normalne funkcjonowanie organizmu staje się fizycznie zależne od jego przyjmowania.
Uzależnienie psychologiczne (psychological dependence). Silna, emocjonalna potrzeba doznawania przyjemności lub ulgi od cierpienia, stresu czy lęku; często rozwija się w związku z nałogowym zażywaniem pewnych substancji, takich jak na przykład narkotyki.


Wandalizm (vandalism). Pozornie bezsensowne akty niszczenia własności; wandalizm może jednak służyć określonym celom: zaborczym, taktycznym, ideologicznym, związanym z zemstą, wyładowaniem złości lub zabawą.
Wariancja (variance). Miara zmienności, którą oblicza się dodając podniesione do kwadratu różnice między każdym pomiarem a średnią i dzieląc tę sumę przez liczbę pomiarów; kwadrat odchylenia standardowego.
Warunkowanie apetytywne (appetitive conditioning). Forma warunkowania reaktywnego, w której reakcją warunkową jest zachowanie wyrażające dążenie  czy pożądanie; przykładem może być ślinienie się.
Warunkowanie awersyjne (aversive conditioning). Forma warunkowania reaktywnego, w której reakcją warunkową jest próba uniknięcia bodźca awersyjnego lub ucieczki od niego.
Warunkowanie instrumentalne (instrumental conditioning).  Typwarunkowania behawioralnego, w którym dana jednostka uczy się wykonywać reakcję prowadzącą do nagrody lub pozwalającą uniknąć kary; w przeciwieństwie do warunkowania sprawczego nie podaje się tu bodźca wywołującego.
Warunkowanie na czas (temporal conditioning). Forma warunkowania reaktywnego, w której odstęp czasowy między kolejnymi ekspozycjami bodźca bezwarunkowego staje się bodźcem warunkowym. Odstęp ten zaczyna zatem wywoływać reakcję warunkową tuż przed momentem, w którym powinien pojawić się bodziec bezwarunkowy.
Warunkowanie przy użyciu nagród (reward conditioning). Forma warunkowania sprawczego, w której pozytywny bodziec wzmacniający występuje wtedy, jeśli dany organizm wykona odpowiednie reakcje.
Warunkowanie unikania (avoidance conditioning). Forma warunkowania sprawczego, w której organizm może zapobiec pojawieniu się bodźca awersyjnego (uniknąć go), jeśli wykona odpowiednią reakcję.
Warunkowanie ucieczki (escape conditioning). Forma warunkowania sprawczego, w której działanie negatywnego, awersyjnego bodźca może zostać zakończone, jeśli organizm wykona odpowiednią reakcję.
Warunkowanie wyższego rzędu (higher-order conditioning). Proces, dzięki któremu po wytworzeniu reakcji warunkowej bodziec warunkowy może funkcjonować jako bodziec bezwarunkowy przy wytwarzaniu reakcji warunkowej na trzeci bodziec (czyli bodziec wyższego rzędu).
Wdrukowanie (imprinting). Rodzaj uczenia się, który występuje w bardzo wczesnej fazie życia, w krytycznym okresie rozwoju, i decyduje o tym, jaką formę przyjmą niektóre zachowania (np. kaczęta podążąją za pierwszym poruszającym się przedmiotem, jaki zobaczą, i wykazują potem wobec niego trwałe przywiązanie).
Wewnętrznie kierowana osoba (inner-directed person). Jednostka sterowana przez wartości i cele zaszczepione jej we wczesnym okresie życia; jednostki takie mają poczucie, iż sprawują większą kontrolę nad swym środowiskiem, niż osoby kierowane zewnętrznie.
Węchomózgowie (rhinencephalon). Stara część mózgu zawierająca zarówno ośrodki węchowe, jak i ośrodki emocji.
Wgląd (insight). Nagłe uświadomienie sobie, odkrycie czy rozpoznanie poprawnego rozwiązania problemu.
Wiązanie zachowań (chaining). Typ warunkowania sprawczego, w którym   dana jednostka uczy się wykonywać pewną sekwencję reakcji w celu otrzymania wzmocnienia.
Wiek umysłowy; wiek inteligencji; W.I. (mental age; M A). Stopień rozwoju umysłowego, mierzony znormalizowanymi testami inteligencji; określany na podstawie wieku, w jakim dzieci przeciętnie uzyskują dany wynik; stosowany przy obliczaniu ilorazu inteligencji.
Wiek życia; W Ż. (chronological age). Wiek danej jednostki w latach.
Wkładanka (form board). Deska z otworami, do których osoba badana musi dopasować klocki właściwej wielkości i kształtu, tak szybko, jak potrafi; stosowana jako test wykonaniowy do mierzenia inteligencji.
Włókno nerwowe. Zobacz Akson.
Wniosek (inference). Konkluzja lub decyzja wyprowadzona na drodze rozumowania ze znanych faktów czy też materiału dowodowego. Wniosek często wykracza poza obserwację, jest szerszy, bardziej ogólny niż materiał dowodowy, na którym się opiera.
Wnioskowanie statystyczne (statistical inference). Procedura wyciągania ogólnych wniosków (o charakterze probabilistycznym) na podstawie badania próbek zachowania.
Wpływ miejsca w szeregu (serial postition effect). Termin używany w badaniach nad pamięcią; tendencja do łatwiejszego przypominania sobie pierwszych i ostatnich elementów w szeregu niż jego elementów środkowych.
Wrażenie (sensation). Uświadomienie sobie faktu pobudzenia receptora zmysłowego; pierwsze stadium spostrzegania.
Wskaźnik zgodności (concordance rate). Prawdopodobieństwo, że u drugiego z bliźniąt z danej pary wystąpi określona cecha (np. reakcja schizofreniczna), jeśli jedno z bliźniąt już ją wykazuje.
Współuczestnictwo (shared participation). Poważne źródło oddziaływania grupy, w której każdy z jej członków jest aktywnym uczestnikiem procesu podejmowania decyzji i ustanawiania celów.Wstępne napełnienie (preloading). Technika eksperymentalna stosowana w badaniach nad pragnieniem, która polega na wstrzykiwaniu do żołądka zwierzęcia dużej ilości wody.
Wygaszanie (extinction). Stopniowe zanikanie reakcji warunkowej, gdy po podaniu bodźca warunkowego wielokrotnie nie następuje wzmocnienie ani bodziec bezwarunkowy. Może być stosowane jako forma modyfikującej zachowanie psychoterapii w celu zredukowania lub wyeliminowania niepożądanych reakcji.
Wynik standaryzowany (standard score). Wynik wyrażony w jednostkach odchylenia standardowego od średniej.
Wyobraźnia ejdetyczna (eidetic imagery). Zdolność przechowywania w pamięci wyobrażenia (zwykle wzrokowego) z wielką wyrazistością i dokładnością przez dość długi czas.
Wyobrażenia (images). Obrazy psychiczne rzeczywistych doznań sensorycznych występujące pod nieobecność bodźca zewnętrznego.
Wypieranie; represja (repression). Mechanizm obronny, w którym przykre (wywołujące poczucie winy), myśli, uczucia czy wspomnienia są usuwane ze świadomości; taki wyparty materiał może pozostać aktywny na poziomie nieświadomym powodując dziwaczne zachowania.
Wyuczona bezradność (learned helplessness). Poczucie bezradności powstające wtedy, gdy dany organizm uczy się w wyniku uprzednich doświadczeń, że jego reakcje nie mają żadnego wpływu na szkodliwe, awersyjne, traumatyczne oddziaływania środowiska; ma ujemny wpływ na procesy motywacyjne, uczenie się i osiągnięcia.
Wzbudzenie (arousal). Stan ogólnej aktywacji organizmu (komponent uwagi i motywacji); dotyczy narządów kontrolowanych zarówno przez ośrodkowy, jak i autonomiczny układ nerwowy.
Wzbudzenie energii (energy arousal). Komponent procesu motywacyjnego, dzięki któremu organizm przygotowuje się do działania.
Wzgórze (thalamus). Struktura mózgowa, która jest częścią pnia mózgu i stanowi stację przekaźnikową dla informacji czuciowych przychodzących ze wszystkich części ciała; odgrywa ważną rolę w odczuwaniu bólu.
Wzmacnianie ciągłe (continuos reinforcement). Wzmacnianie podawane regularnie po każdej poprawnej reakcji.
Wzmacnianie częściowe (partial reinforcement). Sporadyczne wzmacnianie reakcji; reakcje nabywane w tych warunkach są bardziej odporne na wygaszanie niż reakcje przyswajane przy zastosowaniu rozkładów wzmacniania ciągłego.
Wzmocnienie (reinforcement). Bodźce, które służą do zwiększenia siły reakcji. W warunkowaniu klasycznym, procedura polegająca na tym, że po bodźcu bezwarunkowym następuje bodziec warunkowy; w warunkowaniu instrumentalnym - nagradzanie uczącej się jednostki za właściwe reakcje.
Wzmocnienie wtórne; w. warunkowe (secondary reinforcement; „conditioned reinforcement). Wzmocnienie dostarczane przez bodziec, który uzyskał wartość nagrody dzięki uprzedniemu kojarzeniu z pierwotnym bodźcem wzmacniającym, chociaż nie zaspokaja bezpośrednio żadnej potrzeby.
Zachowanie anormalne (abnormal behavior). Zachowanie uznawane za nieprzystosowawcze czy dewiacyjne przez daną jednostkę lub grupę społeczną, której ta jednostka jest członkiem.
Zachowanie emitowane; z. wytwarzane (emitted behavior). Zachowanie spowodowane przez stany wewnętrzne, które pojawiają się bez zastosowania bodźca zewnętrznego; podstawa warunkowania instrumentalnego.
Zachowanie instrumentalne (instrumental behavior). Termin często stosowany zamiennie z terminem zachowanie sprawcze dla określenia dowolnie wykonywanych (emitowanych) reakcji, które są środkiem do osiągnięcia pewnego celu czy nagrody. W ujęciu Thorndikea, termin ten oznacza reakcję wyuczoną, a nie taką, którą dany organizm wykonywał już przedtem.
Zachowanie przesądne; z. magiczne (superstitious behavior). Zachowanie oparte na przypadkowym związku między daną reakcją a wzmacniającym zdarzeniem bodźcowym: jednostka spostrzega związek przyczynowy tam, gdzie w rzeczywistości wcale go nie ma.
Zachowanie reaktywne (respondent behavior). Zachowanie, które jest wyuczoną, mimowolną reakcją na bodziec. Działanie to, w istocie swej odruchowe, zmienia organizm w taki sposób, aby lepiej przystosował się do środowiska, nie wpływa natomiast na zmianę samego środowiska.
Zachowanie społeczne (social behavior). Reakcja społeczna; zachowanie indywidualne związane z innymi osobami lub podejmowane z uwagi na nie; reakcja na bodźce społeczne.
Zachowanie sprawcze (operant behavior). Reakcja wykonywana dowolnie (emitowana), znajdująca się już w repertuarze zachowań danego organizmu; za jej pomocą oddziałuje on na swoje otoczenie. Zobacz także Zachowanie instrumentalne.
Zachowanie wywołane (elicited behavior). W warunkowaniu, reakcja należąca już do repertuaru danego organizmu, którą zapoczątkowuje jakiś rozpoznawalny, zewnętrzny, fizyczny bodziec.
Zależność behawioralna (behavior continguity). Swoisty związek między daną reakcją a rozkładem wzmocnienia w czasie lub jego częstością.
Zależność między dawką a reakcją (dose-response function). Zależność - empirycznie ustalona dla danej jednostki - pomiędzy przyjętą przez nią dawką określonego środka farmakologicznego a skutkami jego działania.
Zapis kumulatywny (cumulative record). Sposób mierzenia tempa reagowania; wykres rejestrujący wszystkie występujące reakcje i przedstawiający ich sumę w danym okresie.
Zaprzeczenie (denial). Mechanizm obronny, za pomocą którego dana jednostka broni się przed zagrożeniem zewnętrznym, odmawiając dostrzeżenia go i myślenia o nim; nieadekwatność wynikającego stąd poziomu strachu może mieć ujemne skutki.
Zasada nieoznaczoności (principle of uncertainty). Ważna dla zrozumienia eksperymentów i pomiarów psychologicznych, aczkolwiek sformułowano ją w dziedzinie fizyki. Głosi, że akt mierzenia pewnego procesu może zmienić sam ów proces. Znana także jako zasada nieoznaczoności Heisenberga, od nazwiska fizyka, który był jej twórcą.
Zasada więcej lub mniej (more-or-less principle). Zasada, zgodnie z którą przekazywanie synaptyczne ma charakter stopniowy: impulsy o różnej sile wywołują różne odpowiedzi. Przeciwieństwo aktywności typu wszystko lub nic występującej w przewodzeniu impulsów wzdłuż aksonu. 
Zasada „wszystko lub nic (all-or-none principle). Zasada głosząca, że jeśli włókno nerwowe w ogóle reaguje, to reaguje z całą intensywnością.  Oznacza to, że jeśli tylko siła bodźców jest większa od progu pobudzenia, to impuls nerwowy w neuronie ma zawsze tę samą amplitudę.
Zasada zachowania ilości (conservation). Zasada, zgodnie z którą dany obiekt czy właściwość (taka jak objętość lub powierzchnia) pozostają bez zmiany, pomimo przekształceń, które mogą zmienić ich wygląd.
Zasady nukleotydowe (nucleotide bases). Powiązane parami elementy w strukturze cząsteczki DNA. Geny składają się z długich łańcuchów zasad nukleotydowych; ich uporządkowanie i kolejność dostarczają instrukcji przy przekazywaniu cech dziedzicznych.
Zdanie jądrowe (kernel sentence). Proste zdanie oznajmujące w stronie czynnej, które według teorii analizy lingwistycznej Chomskyego stanowi podstawowy element języka.
Zdrowie psychiczne społeczności (community mental health). Centralne pojęcie takiego podejścia do zdrowia psychicznego, w którym zwraca się uwagę przede wszystkim na zapobieganie chorobom psychicznym oraz na potrzebę szerszej i bardziej skutecznej opieki nad zdrowiem psychicznym w danej społeczności; w koncepcji tej nacisk kładzie się na lokalne potrzeby i środki.
Zen (zen). Japońska szkoła buddyzmu, która nawołuje do autodyscypliny, głębokiej medytacji i osiągnięcia w ten sposób stanu oświecenia.
Zespół abstynencyjny (abstinence syndrome). Szereg objawów występujących wtedy, gdy jednostkę uzależnioną fizjologicznie od pewnej substancji pozbawi się możliwości dalszego jej przyjmowania.
Zespół braku kontroli (dyscontrol syndrome). Przejawianie bezsensownej brutalności lub wielokrotne dokonywanie przestępstw; przyjmuje się, że wynika to ze schorzeń układu limbicznego lub płata skroniowego mózgu.
Zewnętrzne (overt). To, co widoczne jest dla wszystkich, nie ukryte, bezpośrednio obserwowalne.
Zewnętrznie kierowane jednostki (other-directed individuals).  Jednostki, które są bardziej wrażliwe na wpływ społeczny ze strony swego otoczenia niż osoby kierowane wewnętrznie.
Zjawisko fi (phi phenomenon). Spostrzeganie jednego poruszającego się punktu świetlnego, gdy w rzeczywistości bodźcem są dwa nieruchome źródła światła kolejno zapalające się i gasnące.
Zjednoczenie i zespolenie (unity and fusion). Zjawisko często występujące w zmienionych stanach świadomości; poczucie odrębności swego ja zdaje się zanikać i zostaje zastąpione poczuciem tożsamości zbiorowej.
Zło (evil). Współczesna definicja odnosi ten termin do sytuacji, w których siła, przemoc i inne formy przymusu przekraczają granice uzasadnione instytucjonalnie lub moralnie.
Złudzenie (illusion). Błędna interpretacja relacji między pojawiającymi się bodźcami, w wyniku której spostrzeżenie nie odpowiada rzeczywistości fizycznej, która daje mu początek.
Złudzenie odporności (invulnerability). Fałszywe przekonanie, że jest się zabezpieczonym przed poniesieniem szkody, czy to fizycznej, czy psychicznej; złudzenie takie może doprowadzić jednostkę do niedoceniania oddziaływań zewnętrznych i może być przyczyną niepowodzeń we właściwym radzeniu sobie z nimi.
Zmiana jakościowa (qualitative change). Zmiana charakteru, zasadniczej natury lub szczególnej, wyróżniającej cechy; zmiana rodzaju, a nie tylko ilości czy wielkości.
Zmienione stany świadomości (altered states of consciousness). Stany świadomości, w których dana jednostka odczuwa, że w strukturze jej funkcjonowania psychicznego nastąpiła jakościowa zmiana powodująca, iż różni się ono znacznie od normalnego, typowego dla czuwania stanu świadomości.
Zmienna (variable). Każda wielkość lub właściwość podlegająca zmianom.
Zmienna niezależna (independent variable). Czynnik, którego wpływ (na zmienną zależną) bada się, i którym manipuluje się w sposób systematyczny, podczas gdy inne zmienne utrzymuje się na stałym poziomie; w eksperymentach psychologicznych jest nim często pewien warunek bodźców (S), przy czym bada się jego wpływ na reakcję ®. Zmienna niezależna jest także zmienną predykcyjną, służącą do przewidywania wyników lub zachowań.
Zmienna pośrednicząca (mediating variable). Nieobserwowalny, wewnętrzny proces, o którego istnieniu jedynie się wnioskuje, a który ma wpływ na zależność między obserwowalnymi bodźcami a obserwowalną reakcją; zwany także konstruktem hipotetycznym.
Zmienność zachowania (behavioral variablity). Powszechnie obserwowanezjawisko polegające na tym, że różne jednostki reagują odmiennie na tę samą sytuację zewnętrzną; analiza motywacyjna jest próbą wyjaśnienia tego zjawiska.
Zmysł błędnikowy (labyrinthine sense). Zmysł somatyczny informujący o położeniu (pozycji) ciała.
Zmysł kinestetyczny (kinesthetic sense). Zmysł somatyczny informujący o ruchach ciała.
Zmysły skórne (cutaneous senses). Zmysły: dotyku, bólu, ciepła i zimna, których receptory znajdują się przede wszystkim w skórze.
Zniekształcenie obrazu ciała (body image distortion). Zniekształcenie percepcyjne, które często jest charakterystyczne dla zmienionych stanów świadomości; stan, w którym świadomość istnienia własnego ciała lub jego części może być znacznie zmieniona. Może na przykład występować poczucie oddzielenia od własnego ciała lub poczucie, że pewne części ciała są powiększone lub nieważkie.
Zniekształcenie poczucia czasu (time distortion). Zniekształcenie percepcyjne charakterystyczne dla pewnych zmienionych stanów świadomości; może powodować, że godzina wydaje się sekundą, a sekunda - godziną; zniekształceniu może też ulegać nastawienie danej osoby wobec przeszłości, teraźniejszości lub przyszłości.
Znormalizowany plan wywiadu (standardized interview schedule). Sposób przeprowadzania wywiadu polegający na tym, że ustalone z góry pytania zadaje się w określonej kolejności; metoda pozwalająca uczynić z wywiadu bardziej obiektywną technikę pobierania próbek zachowania.
Związek przyczynowy (causation). Zależność między zachowaniem a warunkami bodźcowymi, dzięki której wystąpienie danego bodźca zawsze prowadzi do równoczesnego lub późniejszego wystąpienia tego zachowania i jest jego warunkiem koniecznym.
Związek R-S (R-S relationship). Związek, którym wyraża się wpływ reakcji na zdarzenia bodźcowe (środowisko fizyczne i społeczne); charakteryzuje uczenie się konsekwencji.
Związek S-R (S-R relationship). Związek między pewnym warunkiem bodźcowym a reakcją.
Związek S-S (S-S relationship). Związek między dwoma zdarzeniami bodźcowymi w danym środowisku.
Zwój nerwowy (ganglion). Skupisko ciał komórkowych neuronów zlokalizowane poza ośrodkowym układem nerwowym.
Zygota (zygote). Komórka utworzona w wyniku połączenia dwóch gamet - męskiej i żeńskiej; rozwija się z niej nowy organizm.
Zysk uboczny (secondary gain). Wzmocnienie, jakie dana jednostka otrzymuje od innych osób za demonstrowanie pewnych anormalnych objawów; pozytywne skutki uboczne negatywnych reakcji - takie jak zainteresowanie i troska otoczenia.


Źródło (source). Nadawca przekazu; osoba lub instytucja, od której pochodzi dany przekaz; zmienna, od której zależy perswazyjne oddziaływanie przekazu.

Bibliografia




Abelson R. P., Aronson  E., McGuire W. J., Newcomb T. M., 
Rosenberg M. J., Tannenbaum P. H. (Eds). Theories of cognitive consistency: A sourcebook. Chicago 1968, Rand McNally.
Abelson R. P., Carroll J. D. Computer stimulation of individual belief systems. American Behavioral Scientist 1965, 8, 24-30.
Adamson R. E. Functional fixedness as related to problem solving; A repetition of theere experiments. Journal of Exerimental Psychology 1952, 44, 288-91.
Adolph E. Regulation of body water content through water ingestion. In: 
M. Wayner (Ed) Thirst. New York 1964, Macmillian.
Adorno T. W., Frenkel-Brunswick E., Levinsons D. J., Sanford
R. N. The authoritarian personality. New York 1950, Harper and Row.
Akishige Y. A historical survey of the psychological studies on Zen. In: 
Y. Akishige (Ed.) Psychological studies on Zen. Fukuoka 1970, Kyushu 
University,
Akishal H. S., McKinney W. T., Jr. Depressive disorders: Toward a unified hypothesis. Science 1973, 182, 20-29.
Allopprt F. H. Theories of perception and the concept of structure. New York 1955, Wiley.
Allport G W. Personality and social encounter. Berkeley, Calif. 1960, Beacon Press.
Almond R. The therapeutic community. Scientific American 1971, 224, 34-42.
Altman D., Levine M., Nadien J. Unpublished research cited in: S. Milgram The experience of living in cities. Science 1970, 167, 1561-68.
Amarel S. On the mechanization of creative processes. IEEE Spectrum 1966, 3(4), 112-14.
American Psychological Association Ethical standards of psychologists. 
„American Psychologist Jan. 1963, 18(1).
American Psychological Association Ad Hoc Committee on Ethical Standards in Psychological Research. Proposed ethical pronciples submitted to the American Psychological Association membershi for criticism and modification, 1971, p.10.
American Psychological Asscociation A resolution concerning behavior and heredity. American Psychologist July 1972, 27(7), 660. Excerpt reprinted by permission on the American Psychological Association.
American Psychological Association Ethical pronciples in the conduct of research with human participants. American Psychologist Jan. 1973, 28 (1), 79-80.
American Psychological Association Task Force Repoprt On issues of sexual bias in graduate education (Jan Birk, Chairerson), 1974.
Ames A. Visual percetion and the rotating trapezoidal window. 
„Psychological Monographs 1951, 65 (7, Whole No. 234).
Ammons R. B Effects of knowledge of performance: A survey and tentative theoretical formulation. Journal of Genetic Psychology 1965, 54, 279-90.
Anand B. K. Chhina G. S., Singh B. Some asects of electroencephalographic studies in Yogis. EEG Clinical Neurophysiology 1961, 13, 452-56.
Arendt H. Eichmann in Jerusalem: A report on the banality of evil. New York 1965, Viking.
Argyle M., Little R. Do personality traits apply to social behavior? 
„Journal of the Theory of Social Behavior 1972, 2, 1-35.
Arling G. L. Effects of social deprivation on maternal behavior of Wisconsin, 1966.
Arnold M. B. Emotion and ersonality. New York 1960, Columbia University Press.
Aronfreed J. The socialization of altruistic and sympathetic behavior: 
Some theoretical and experimental analyses. In: J. Macauley, L. Berkowitz (Eds.) Altruism and helping behavior: Social sychological studies of some antecedents and consequences, New York 1970, Academic Press.
Aronson E. Some antecedents of interpersonal atraction. In: W. J. Arnold, D. Levine (Eds.) Nebraska symposium on motivation. Lincoln 1969, University of Nebraska Press.
Aronson E., Carlsmith M. J. Experimentation in social psychology. In: G.  Lindzey, E. Aronson (Eds.) Handbook of Social Psychology. Vol.2. Reading, Mass, 1969, Addison-Wesley. 
Aronson E., Linder D. Gain and loss of esteem ad determinants of interpersonal attraciveness. Journal of Experimental and Social Psychology 1965, 1, 156-71.
Asch S. E. Opinions and socjal pressure. Scientific American 1955, 193(5), 31-35.
Aserinsky E., Kleitman N. Regularly occurring periods of eye mobility and concomitant phenomena during sleep. Science 1953, 118, 273-74.
Ashley W. R., Harper R. S., Runyon D. L. The perceived size of coins in normal and hypnotically inducet economis states. American Journal od Psychology 1951, 64, 564-72.
Asimov I. The intelligent mans guide to science. Vol. 2. New York 1960, Basic Books.
Asimov I. Twentieth century discovery. Garden City, N. Y. 1969, Doubleday.
Associated Press. Excerpt from Solution for a burning issue from The Associated Press Aug. 16, 1971, Reprinted by permission.
Atkinson J. W. (Ed.) Motives in fantasy, action, and society. Princeton, N. J. 1958, Van Nostrand.
Atkinson J. W. An introduction to motivation. ronceton 1964, Van Nostrand.
Atkinson R. C. Teaching children to read using a computer. American Psychologist, 1974, 29, 169-178.
Axelrod J., Wurtman R. Biological rhytms and the pineal gland. Mental Health Program Reports, No. 4. Chewy Chase, Md. 1970, National Institute of Mental Health.
Ayllon T., Azrin N. H. The measurement and reinforcement of behavior of psychotics. Journal of the Experimental Analysis of Behavior 1965, 8, 357-83.
Ayllon T., Michael J. The psychiatric nurse as a behavioral engineer. 
„Journal of the Experimental Analysis of Behavior 1959, 2, 232-34.
Azrin N. H., Holtz W. C. unishment. In: W. K. Honig (Ed.) Operant behavior. New York 1966, Apleton-Century-Crofts.


Bachrach A. J., Erwin W. J., Mohr J. P. The control of eating behavior in an anoretic by operant conditioning techniques. In: L .P. Ullmann, L.  Krasner (Eds.) Case studies in behavior modification. New York 1965, Holt, Rinehart and Winston.
Back K. Intervention techniques: Small groups. In P. H. Mussen, M. R. R.  Rosenzweig (Eds.) Annual review of psychology. 1974. Vol. 25. Palo Alto, Cali. 1974.
Badia P., Culbertson S., Harch J. Choice of longer or stronger signalled shock over or weaker unsignalled shock. Journal of the Experimental Analysis of Behavior Jan. 1973, 19 (1), 25-32.
Baer D. M. A case for the selective reinforcement of punishment. In: C.  Neuringer, J. L. Michael (Eds.) Behavior modifiaction in clinical psychology. New York 1970, Appleton-Century-Crofts.
Balagura S. Influence of osmotic and caloric loads upon lateral hypothalamic self-stimulation. Journal of Comparative and Physiological Psychology 1968 a, 66, 325-28.
Balagura S. Cinditioned glyceric responses in the control of food intake. 
„Journal of Compparative and Physiological Psychology 1968 b, 65, 30-32.
Bandura A. Influence of models reinforcement contingencies on the acquistition of imitative responses. Journal of Personality and Social Psychology 1965, 1, 589-95.
Bandura A. Principles of behavior modification. New York 1969, Holt, Rinehart and Winston.
Bandura A. Modeling therapy. In: W. S. Sahakian (Ed.) Psychopathology today; Experimentation, theory, and research, Itaska, III, 1970, F. E.  Peacock.
Bandura A. Social learning theory. (Module) Morristown, N. J. 1971, General Learning Corp.
Bandura A. Aggression: A social learning analysis. Englewood Cliffs, N. 
J. 1973, Prentice-Hall.
Bandura A., Ross D., Ross S. A. Imitation of film-mediated aggressive models. Journal of Abnormal and Social Psychology 1963, 66, 3-11. 
Bandura A., Walters R. H. Adolescent aggression. New York 1959, Ronald.
Banks W. C. Determinants of interpersonal influence strategies. 
Unpublished dissertation. Stanford University, 1973.
Banks W. C., Zimbardo P. G., Phillips S. Variables related to the choice of positive wersus negative means of interpersonal influence. Unpublished manuscrit. Stanford Univeristy, 1974.
Barber T. X. LSD, marihuana, yoga and hypnosis. Chicago 1970, Aldine.
Barefoot J. C., Girodo M. The misattribution of smoking cessation symptoms. Canadian Journal of Behavioral Science Oct. 1972, 4(4), 358-63.
Barfield R., Geyer L. Sexual behavior: Ultrasonic postejaculatory song of the male rat. Sciene June 23, 1972, 176, 1349-90).
Barker R. G. The stream of behavior as an emiprical problem. In: R. G.  Barker (Ed.) The stream of behavior. New York 1963, Appleton-Century-Crofts.
Barlow H. B. Action potentials from the frogs retina ans Summation and inhibition in the frogs retina. Journal of Physiology 1953, 119 (1), 58-68, 69-88.
Barlow H. B. Single units and senssation: A neuron doctrine for perceptual psychology? Perception 1972, 1, 371-94.
Barnett S. A. Attack and defence in animal societies. IN: C. D. Clemente, D. B. Lindsley (Eds.) Aggression and defence. Los Angeles 1967, University of California Press.
Barron F. X. Creativity and psychological health: Origins of personal vitality and creative freedom. Princeton, N. J. 1963, Van Nostrand.
Barta R. The representation of Poles, Italians, Latinas and blacks in the execuitive suies of Chicagos largest corporations. Report of The Institute for Urban Life, Chicago, 1974.
Bartlett F. C. Remembering: A study in experimental and social psychology. New York 1932, Macmillan.
Bash K. W. Contribution to a theory of the hunger drive. Journal of Comparative Psychology 1939, 28, 137-60.
Baetson G., Jackson D. D., Haley J., Weakland J. Toward a theory of schizophrenia. Behavioral Sciences 1965, 1, 251-64.
Bavelas A., Hastorf A. H., Gross A. E., Kite W. R. Exeriments on the alternation of grup structure. Journal of Exerimental and Social Psyhology 1965, 1, 55-70.
Bayley N. Behavioral correlates of mental growth; Birth to thirty-six years. American Psychologist 1968, 23, 1-17.
Bazelon D. L. Untitled mimeograph from addres to the American Association of Correctional Psychologists Conferences on Psychologys role and corrections. Lake Wales, Florida, Jan. 20, 1972. Cited in: N. Calan, S.  Nelson On being useful. American Psychologist 1973, 28 (3), 199-211.
Beadle G. W. The new genetics: The threads of life. In: 1964 Britannica book of the year. Cicago 1964, Britannica.
Beck A. T. Deression. New York 1967, Harer and Row.
Becka A. T., Kovacs M., Weissman A. Hopelessness and suicidal behavior. 
„Journal of the American Medical Association 1975, 234, 1146-49.
Becker H. S. Outsiders: Studies in them socjology of deviance. New York 1963, The Free Press.
Becker H. S. History, culture and subjective experience: An exloration on the social bases of drug-induced experiences. Journal of Health and Social Behavior 1967, 8, 163-76.
Beecher H. K. Generalization from ain of various tyes and diverse origins. Science 1959, 130, 267-68.
Bellugi-Klima U. Linguistic mechanism underlying child speech. In: E. M. 
Zale (Ed.) Proceedings of the conference on language and language behavior. 
New York 1968, Appleton-Century-Crofts.
Bem D. J. An experimental analysis of self-ersuasion. Journal of Experimental social Psychology 1965, 1, 199-218.
Bem D. J. Self-percetion theory. In.: Berkowitz (Ed.) Advances in experimental social psychology. Vol. 6. New York 1972, Academisc Press.
Bem D. J., Allen A. On predicting some of the people some of the time.  The search for cross-situational consistencies in behavior. „Psychological Review.
Bem S. L., Bem D. J. Homogenizing the American woman: The power of an unconscious ideology. In: P. Zmibardo, C. Maslach (Eds.) Psychology for our times: Readings. Glenview III. 1973, Scott, Foresman.
Berger E. The pyshcology of gambling. New York 1957, Hill and Wang.
Bergin A. E. Some implications of psychotherapy research for therapeutic practice. Journal of Abnormal Psychology 1966, 71, 235-46.
Berko J. The childs learning of English morphology. Word 1958, 14, 150-77.
Berkowitz L. The concept of aggressive drive: Some additional considerations. In: L. Berkowitz (Ed.) Advances in experimental social psychology. Vol. 2. New York 1965, Academic Press.
Berkowitz L. Social norms, fellings, and other factors affecting helping and altruism. In: L. Berkowitz (Ed.) Advance in experimental social psychology. Vol. 6. New York 1972, Academic Press.
Berkowitz L., LePlage A. Weapons as aggression-eliciting stimuli. 
„Journal of Personality and Social Psychology 1967, 7, 202-7.
Berkum M. M., Bialek H. M., Kern R. P., Yagi K. Experimental studies od psychological stress in man. Psychological Monographs 1962, 76 (15, Whole No, 534).
Berlyne D. E. Conflict, arousal, and curiosity. New York 1960, McGraw-Hill.
Bernard L. L. Instinct. New New York 1924, Holt, Rinehart and Winston.
Bernstein D. A. Modification of smoking behavior. An evaluative review.  „Psychological Bulletin 1969, 71, 418-20.Bernstein I. S. Alternatives to violence. Mental Health Program Reports, No, 4. Publication No, 5026. Chewy Chase, Md. 1970, National Institute of Mental Health.
Bernstein I. S. Personal communication, April, 22, 1974.
Berscheid E., Walster E. Physical attractiveness. In: L. Berkowitz(Ed).  Advances in experimental social psychology. Vol. 7. New York 1974, Academic Press. 
Bettelheim B. Individual and mass behavior in extreme situations. 
„Journal of Abnormal and Social Psyhology 1943, 38, 417-52.
Bettelheim B. Individual and mas behavior in extreme situations. In: E. 
E. Maccoby, T. Newcomb, E. Hartley (Eds.) Readings in social psychology. 
New York 1958, Holt, Rinehart and Winston.
Bettelheim B. The informed heart. New York 1960. The Free Press.
Bichat X. Physiological researches upon life and death. Philadelphia 1809, Smith and Maxwell.
Bierbrauer G. A Attribution and perspective: Effect of time set and role on interpersonal inference. Unpublished doctoral disseration. Stanford University, 1973.
Bindra D. B. Interrelated mechanism of reinforcement and motivation, and the nature of their influence on response. In: W. J. Arnold, D. Levine (Eds). Nebraska symposium on motivation. Lincoln 1969, University of Nebraska Press.
Binet A., Simon T. La mesure du developpement de lintelligence chez les jeunes enfants. Bulletin de la Societe Libre pour LEtude Psychologique de LEnfant 1911, 11, 187-248. 
Bingham C. C. A study of American intelligence to insightful problem-solving. Journal of Comparative Psychology 1945, 38, 367-83.
Birch H. G. Sources of order in the maternal behavior of animals. 
„American Journal of Orthopsychiatry 1956, 26, 279-84).
Bjorntrop P. Disturbances in the regulation of food intake, Advances in sychosomatic Medicine 1972, 7, 116-27.
Blake A. Coin collectors. California Living Magazine Jan. 23, 1972. 
Reprinte with permission from California Living, the magazine of the San 
Francisco Sunday Examiner and Chronicle
Blake B. G. A follow-up of alcoholics treated by behavior therapy, „Behavior Research and Therapy 1967, 5, 89-94.
Blakemore C., Cooper G. F. Development of the brain depens on the visual environment. Nature 1970, 228, 477-78.
Blanchard E. B., Uoung L. D. Self-control of cardiac functioning: A promise as yet unfulfielld. Psychological Bulletin 1973, 79, 145-63.
Bloom B. L. Community mental health: A historical and critical analysis. 
(Module) Morristown, N. J. 1973, General Learning Corp.
Blum R. H. I. Society and drugs; II. Students and drugs. San Francisco 1969, Jossey-Bass.
Blumenthal M. Predicting attitudes toward violence. Science 1972, 176, 1296-1303.
Bolles R. Theory of motivation. New Yok 1967, Harper and Row.
Boring E. G. A history of experimental psychology. New York 1950, Appleton-Century-Crofts.
Boulding K. E. The social system and the energy crisis. Science April 19, 1974, 184, 225-57. Copyright © 1974 by the American Association fot the Advancement of Science. Experpt reprinted by permission.
Bower G. H., Clark M. C. Narrative stories as mediators for serial learning. Psychonomic Science 1969, 14, 181-82.
Bower G. H., Trabasso T. Reverals prior to solution in concept identyfication. Journal of Experimental Psychology 1963, 66, 409-18.
Bower T. G. R. Slant perception and shape constancy in infants. „Science 1966, 151, 832-34, (a).
Bower T. G. R. The visual world of infants. Scientific American 1966, 215, 85-92 (b).
Brady J. V., Levitt E. E. Hypnotically induced visual hallucinating. 
„Psychosomatic Medicine 1966, 28, 351-63.
Brady J. V. Emotion and the sensitivy of psychoendocrine systems. In: D.  C. Glass (Ed.) Neurophysiology and emotion. New York 1967, Rockefeller University Press.
Brady J. V., Porter R. W., Conrad D. G., Mason J. W. Avoidance behavior and the development of gastroduodenal ulcers. Journal of the Experimental Analysis of Behavior 1959, 1, 69-73.
Braine M. S. D. The ontogeny of English phrase structure: The first phase. Language 1963, 39, 1-13.
Bransford J. D., Franks J. J. The abstraction of linguistic ideas. 
„Cognitive Psychology 1971, 2, 331-50.
Breger L. C., McGaugh J. L. Critique and reformulation of learning theory approaches to psychotherapy and neurosis. Psychological Bulletin 1965, 63, 338-58).
Brehm J. W. A theory of psychological reactance. New York 1966, Academic Press. 
Brehm J. W., Cohen A. R. Explorations in cognitive dissonance. New York 1962, Wiley.
Breland K., Breland M. Animal behavior. New York 1966, Macmillan.
Brenner M. Caring, love, and selective memory. Paper presented at the Annula Convention of American sychological Association, Washington, D. C., 1971.
Brenner M. The next-in-line effect. Journal of Verbal Learning and Verbal Bevavior 1973, 12, 320-23.
Brenner M. H. Mental illnes and the economy. Cambridge. Mass. 1973, Harvard University Press.
Bridgman P. W. The logic of modern physics. New York 1927, Macmillan.
Brislin R. W., Lonner W. J., Thorndike R. M. Cross-cultural research methods. New York 1973, Wiley.
Broadbent D. E. Cognitive psychology: Introduction. British Medical Bulletin 1971, 27, 191-94.
Brodeur D. W. The effects of stimulant and tranquilizer placebos on healthy subjects in a real life situation. Psychophmarcologia 1965, 7, 444-52.
Brody J. E. When illness follows a giving u. The New York Times April, 7 1968, p. 11.
Brodsky S. L. Psychologists in the criminal justice system. Urbana, III. 
1973, University of Illinois Press.
Brodzinsky D. M., Jackson J. O., Overton W. F. Effects of perceptual shielding in the development of spatial perspectives. Child Development 1972, 43, 1041-46.
Brower L. P., Cranston P. Courtship of the Queen Butterfly, Danaus Gillppus Berenice, 16 mm sound film, serial number PCR 2123K. Psychological Cinema Register, Pennsylvania State University, 1962.
Brown C. Manchild in the promised land. New York 1965. Macmillan, Copyright © Claude Brown 1965. Excerpt reprinted by permission of Macmillan Publishing Co., Inc., and Jonathan Cape Ltd.
Brown J. S. A proposed program of research on psychological feedback (knowledge of results) in the performance of psychomotor tasks. Conference Report 49-2, USAF Air Training Command Human Resources Research Center, 1949, 81-87.
Brown P. L., Jenkins H. M. Auto-shaping of the pigeons key peck. 
„Journal of Experimental Analysis of Behavior 1968, 11, 1-8.
Brown R. W. Language and categories. In: J. S. Bruner, J. J. Goodnow, G. 
A. Austin (Eds.) A study of thinking. New York 1956, Wiley.
Brown R. W. The first sentences of child and chimpanzee. Unpublished mimeo report, Harvard Univeristy, 1970.
Brown R. W., Cazden C. B., Bellugi-Klima U. The childs grammar from I to III. In: J. P. Hill (Ed.) Minnesota symposia on child psychology. Vol. 2.  Minneapolis 1969, Univeristy of Minnesota Press.
Brown R. W., McNeil D. The tip-of-the-tongue phenomenon. Journal of Veber Learning and Verbal Behavior 1966, 5, 325-37.
Brozek J. Experimental investigation on nutrition and human behavior: A postscript. American Scientist June 1963, 51, 139-63.
Bruch H. Eating disorders in adolescence. In: J. Zubin, A. M. Freedman (Eds.) The psychopathology of adolescence. New York, 1971, Grune and Stratton.
Bruner J. S. The course of cognitive growth. American Psychologist 1964, 19, 1-15.
Bruner J. S. Beyond the information given. New York 1973, Norton.
Bruner J. S., Goodman C. C. Value and need as organizing factors in perception. Journal of Abnormal and Sociaty Psychology 1947, 42, 33-44.
Bruber J. S., Olver R. R., Greenfield P. M., et. al. Studies in cognitive growth. New York 1966, Wiley.
Bryan J. H., Schwartz T. The effects of film material upon childrens behavior. Psychological Bulletin 1971, 75, 50-59.
Bryan J. H., Test M. Models and helping: Naturalistic studies in aiding behavior. Journal of Personality and Social Psychology 1967, 6, 400-407.
Buber M. Pointing the way. New York 1957, Harper and Row.
Burger R. E. Who cares for the aged? Saturday Review 1969, 52(4), 14-17.
Burks B. S. The realitve influence of nature and nurture upon mental develompent: A comparative study of foster parent-foster child resemblance and true parent-true child resemblance. In: National Society for the Study of Education. 27 th Yearbook Part 1, 1928.
Burnham J. Beyond modern sculpture. New York 1968, George Braziller.
Burt C. The evidence for the concept of inteligence. ,British Journal of Educational Psychology 1955, 25, 158-77.
Burt C. The genetic determination of differences in intelligence: A study of monozygotic twins reared together and apart. British Journal of Psychology 1966, 57, 137-53.
Burt C., Howard M. The relative influence of heredity and environment on assessments of inteligence. British Journal of Statistical Psychology 1957, 10, 99-104.
Bykov K. M. The cerebral cortex and the internal organs. New York 1957, Chemical Publishing Co.
Byrne D. The attraction paradigm. New York 1971. Academic Press.


Caldwell D. K., Caldwell M. C. Dolphins communicate - but they dont talk. Naval Reviews June-July 1972, 23-27.
Calhoun J. B. A behavioral sink. In: E. L. Bliss (Ed.) Roots of behavior. New York 1962, Harper and Row.
Calhoun J. B. How the social organization of animal communities can lead to a population crisis which destroys them. Reported by M. Pines Mental Healt Program Reports, No. 5. (DHEW) Publication No. (HSM) 72 - 9042. Chevy Chase , Md., National Institute of Mental Health, Dec. 1971. 
Campbell B. A., Sheffield F. D. Relation of random activity to food deprivation. Journal of Comparative nad Physiological Psychology 1953, 46, 320-22.
Campbell D. Ethnocentrism and other altruistic motives. In: D. Levine (Ed.) Nebraska symposium on motivation. Lincoln 1965, University of Nebraska Press.
Campbell D., Snaderson R. E., Lavertz S. G. Charakteristic of a conditional response in human subject during exinction trials following a single traumatic conditioning trial. Journal of Abnormal nad Social Psychology 1964, 68, 627-39.
Campbell L. S. Letter to the Editor. The New York Tomes Feb. 4, 1972. 
© 1972 by The New York Times Company. Reprinted by permission of the author and The New York Times Company.

Cannon W. B. Bodily changes in pain, hunger, fear and rage. (2 nd. ed). 
New York 1929, Appleton-Century-Crofts.
Cannon W. B. Hunger and thirst. In: C. Murchison (Ed.) A handbook of general experimental psychology. Worcester, Mass, 1934, Clark University Press.
Cannon W. B. Voodoo death. Psychosomatic Mediciene 1957, 19, 182-90.
Calan N., Nelson S. D. On being useful: The nature and consequences of psychological research on social problems. American Psychologist 1973, 28, 199-211.
Caporael L. R. Ergotism: the satan loosed in Salem? Science 1976, 192, 21-26.
Carlson E. R. The affective tone of psychology. Journal of General Psychology 1966, 75, 65-78.
Carlson J. G., Wood R. D. Need the final solution be justifield? 
Unpublished manuscrit, University of Hawaii, 1974.
Carmichael L. Ontogenetic development. In. S. S. Stevens (Ed.) Handbook of experimental psychology. New York 1951, Wiley.
Carmichael L., Hogan H. P., Walter A. A. An exerimental study of the effect of language on the reproduction of visually perceived form. „Journal of Exerimental Psychology 1932, 15, 73-86.
Cartwright D., Zander A. (Eds.) Group dynamics: Research and theory. New York 1968, Harper and Row. 
Castaneda C. The teachings of Don Juan: A Yagui way of knowledge. New York 1968, Ballantine Books. Copyright © 1968 by The Regents of the University of California. Excerpt reprinted by permissin of The Regents of The Univeristy of California.
Castaneda C. A separate reality: Further conversation with Don Juan. New York 1971, Simon and Schuster.
Castaneda C. Journey to Ixtlan. New York 1972, Simon and Schuster.
Castiglione B. The book of the courtier. Baltimore 1967, Penguin Books. 
(Originally published, 1528).
Cattel R. B. Personality and motivation: Structure and meaning. New York 1957, Harcourt Brace Jovanovich.
CavalliSforza L. L., Bodmer F. Genetisc of human opulations. San Francisco 1971, Freeman.
Charatan F. Personal communication to the author, Spring 1973.
Chase M. H. The matriculating brain. Psychology Today 1973, 7, 82-87.
Chomsky N. Syntatic structures. SGravenhage, 1957, Mouton.
Chomsky N. Language and mind. New York 1968, Harcourt Brace Jovanovich.
Chomsky N. Language and the mind. Readings in psychology today. Del Mar, Calif, 1969, CRM Books.
Christie R., Jahoda M (Eds.) Studies in the scope and menthod of the authoritarian ersonality. New York 1954, Free Press. 
Christie P. R., Gelfand D. M., Hartmann D. P. Effect of cometition-induced frustration on two classes of modeled behavior.  „Developmental Psychology 1971, 5, 104-11.
Cisler L. Unfinished business: Birth control and womens liberation. In. 
R. Morgan (Ed.) Sisterhood is powerful. New York 1970, Random House.
Clark K. B., Clark M. P. Racial identification and preference in Negro children. In: E. E. Maccoby, T.M. Newcomb, E. L. Hartley (Eds.) Readings in social psychology. New York 1958, Holt, Rinehart and Winston. 
Clausen J. A. Drug use. In: R. Merton, R. Nisbet (Eds.) Contemporary social problems. New York 1971, Harcourt Brace Jovanisch.
Clauser G., Klein H. Munchner Medizinische Wochenschrift 1957, 99, 896. 
Cited in Haas et al., 1959.
Cline V. B., Croft R. G., Courrier S. The desensiization of children to television violence. Unpublished manuscript, Univeristy of Utah, 1972.
Coch L., French J. R. P., Jr Overcoming reistance to change. „Human Realtions 1948, 11, 512-32.
Cofer C. N. Constructive process in memory. American Scientist 1973, 61, 537-43.
Cofer C. N., Appley M. H. Motivation: Theory and research. New York, 1964, Wiley.
Cohen F. Psychological factors in the etiology of somatic illness. 
Unpublished report, Stanford Univeristy 1975.
Cohen H. L., Filipczak J. A new learning environment. San Francisco 1971, Jossey-Bass.
Cohen S. Property destruction: Motives and meanings. In: R. Ward (Ed.) 
Vandalism. London 1973, Architectural Press.
Colby K. M. Computer stimulation of neurotic procesess. In: R. W. Stacey.  B. D. Waxman (Eds.) Computers in biomedical research. New York 1965, Academic Press.
Colby K. M., Watt J., Gilbert J. P. A computer method of psychoteraphy. 
„Journal of Nervous and Mental Diseases 1966, 142, 148-52.
Coleman J. C. Abnormal psychology and modern life. (5th ed.). Glenview, III. 1976, Scott, Forrsman.
Collier G. Consummatory and Instrumental responding as functions of deprivation. Journal of Experymential Psychology 1962, 64, 410-14.
Collins B. E., Martin J. C., Ashore R. D., Ross L. Some dimenesions of the Internal-external metaphor in theories of personality. „Journal of Personality 1973, 41, 471-92.
Congressional Hearings on Worker Alienation. Hearings before the Subcommittee on Employment, Manpower, and Powerty, Waschington, D. C.: U.  S. Goverment Printing Office, 1972.
Conklin J. E. Dimensiona of community response to the crime problem. 
„Scocial Problems 1971, 18, 373-85.
Conrad R. Acoustic confusions and immedetiate memory. British Journal of Psychology 1964, 55, 77-84.
Cooley C. H. Human nature and the social order. New York 1902, Scribner.
Cooper L. A,. Shepard R. N. The time required to prepare to prepare for a rotated stimulus. Memory and Cogniton 1973, 1, 246-50.
Cooper L. M. Hypnotic amnesia. In: E. Fromm, R. E. Shor (Eds.) Hynosic: 
Research and developments. Chicago 1972, Aldine.
Cowen E. L. Stress reduction and problem-solving rigidity. Journal of Consulting Psychology 1952, 16, 425-28.
Cowen E. L., Beier E. S. Threat-expectancy, word frequencies, and perceptual prerecogniotion hypotheses. Journal of Abnormal and Society Psychology., 1954, 49, 172-82.
Craddick R. A. Size of with drawings as a function of time before, on and after Halloween. American Psychologist 1967, 17, 307.
Craik K. J. W. The nature of explanation, Cambridge, Mass. 1943, Cambridge Univeristy Press.
Crandall V. C. Sex differences in expectancy of intellektual and academic reinforcement. In: C. P. Smith (Ed.) Achievement related motives in children. New York 1969 Russell Sage Foundation.
Cranston R. The miracle of Lourdes. New York 1955, McGraw-Hill.
Crocket R., Sandison R., Walk A. (Eds.). Hallucinogenic drugs and their psychotheraeutic use. London 1963, J. Q. Lewis.
Crombie A. D. Early concepts of the senses and the mind. Scientific American 1964, 215, 108-16.
Cross P. G., Cattel R. B., Butcher H. J. The ersonality patterns of creative artists. British Journal of Educational Psychology 1967, 37, 292-99.
DAndrade R. G., Quinn N. R., Nerlove S. B., Romney A. I. Categories of disease in American-English and Mexican-Spanish. Unpublished paper, Stanford University, 1969.
Danzinger C., Greenwald M. Alternatives: A look at unmarried couples and communes. New York 1974, Institute of Life Insurance, Research Services.
Darley J. M., Batson C. O. From Jerusalem to Jericho: A study of situational variables in helping behavior. Journal of Personality and Social Psychology 1973, 27, 100-108.

Darley J. M., Latane B. Bystander intervention in emergencies: Diffusion of responsibilities. Journal of Personality and Social Psychology 1968, 8(4), 377-83.
Darnton R. Mesmerism and the end of enlightenment in France. Cambridge 1968, Harvard University Press.
Darwin C. The experssion on the emotions in man and animals. London 1872, Murray.
Davenport W. Sexual patterns and their regulation in a society of the Southwest Pacific. In: F. Beach (Ed.) Sex and behavior. New York 1965, Wiley.
Davis C. M. Self-selection of diet by newly weaned infants. American Journal of Diesases od Children 1928, 36, 651-79.
Davis J. M. Efficacy of transquilizing and antidepressant drugs. 
„Archives of General Psychiatry 1965, 13, 552-72.
Davison G. C., Valins S. Maintenance of self-attributed and drug-attributed behavior change. Journal of Personality and Social Psychology 1969, 11, 25-33.
Day R. S., Cutting J. E. Percetual cometition between speech and nonspeech. Paper presented at the eighteenth annual meeting of the Acoustical Society of America, Houston, 1970.
Deci E. L. Intrinsic motivation, extrinsic reinforcement, and inequity. 
„Journal of Personality and Social Psychology 1972, 22, 113-20.
Dekker E., Groen J. Reproducible psychogenic attacks of astma. In: C. F. 
Reed, I. E. Alexander, S. S. Tomkins (Eds.) Psychopathology: A source book. 
Cambridge, Mass. 1958, Harvard University Press. 
Dellas M., Gaier E. L. Identyfication of creativity: The individual. 
„Psychological Bulletin 1970, 73, 55-73.
Dement W. C. The effect of dream derivation. Science 1960, 131, 1705-7.
Dement W. C. A new look at the third state of existence. Stanford M. D. 
1969, 8, 2-8.
Dement W. C., Kleitman N. Cyclic variation in EEG during sleep and their relations to eye movement, body mobility and dreaming.  „Electroencephalograhy and Clinical Neurophysiology 1957, 9, 673-90.
Dement W. C., Mitler M. M. An overview of sleep research: Past, present and future. In: D. Hamburt, H. Brodie (Eds.) American handbook of psychiatry. Vol. 6. New York 1975, Basic Books.
Deutsch M., Deutsch D. Physiological psychology. Homewood, III. 1966, Dorsey Press.
Deutsch M., Gerard H. B. A study of normative and informational social influence upon individual judgment. Journal of Abnormal and Society Psychology 1955, 51, 629-36.
De Vos G., Wagatsuma H. Japans invisible race. Berkeley 1966, University of California Press.
Diamond M. J. The use of observationally resentes information to modify hypnotic susceptibility. Journal of Abnormal Psychology 1972, 79, 174-80.
Di Cara L. V., Miller N. E. Instumental learning of vasomotor responses by rats: Learning to respond differentially in the two ears. „Science 1968, 159, 1485-86.
Dillard J. L. Negro childrens dialect in the inner city. The Florida FL Reporter Fall 1967.
Dillard J. L. Non-standard Negro dialects - convergence or divergence? 
„The Florida FL Reporter Fall 1968.
Dillard J. L. Blacka English. New York 1972, Random House.
Dobzhansky  T. On methods of evolutionary biology and anthropology. Part 
1. Biology. American Scientist 1957, 45(5), 381-92.

Dohrenwend B.P., Dohrenwend B. S. Social and cultural influences on psychopathology, 1974. Vol. 25. Palo Alto, Calif. 1974, Annual Reviews.
Dolinar L. Creationists issue a new challenge. Learning April 1973, 52-55.
Dollrad J., Doob L. W., Miller N., Mowrer O. H., Sears R. R. Frustration and aggression. New Haven 1939, Yale University Press.
Dollard J., Miller N. E. Personality and psychotherapy. New York 1950, McGraw-Hill.
Dreyfus E. A. Humannes: A therapeutic variable. Personnel and Guidance Journal 1967, 45, 573-78.
Duffy E. Activation and behavior. New York 1962, Wiley.
Dugdale R. The Jukes: A study in crime, pauperism, disease, and heredity. 
New York 1877, G. P. Putnams Sons.
Duncan S. When dieting goes berserk. New York Magazine Jan. 29, 1973, 44-47.
Duncker K. On problem-solving. Psychological Monograhs 1945, 58(55).
Dunnette M. D., Campbell J., Jaastad K. The effects of group particiation on brainstorming effectiveness for two industrial samples. „Journal of Applied Psychology 1963, 47, 30-37.
DuPont R. L., Greene M. H. The dynamisc of a heroin addiction „Science Aug. 1973, 181 (4101), 716-22.
Dwornicka B., Jasienska A., Smolarz W., Wawryk R. Attempt of determining the fetal reaction to acoustic stimulation. Acta Oto-Laryngologica Stockholm, 1964, 57, 571-74.


Ebbinghaus H. Memory. New York 1913, Teachers College, Columbia University. (Originally published: Leipzig: Altenberg, 1885).
Edwards A. E., Acker L. E. A demonstration of the long-term retention of a conditioned galvanic skin response. Psychosomatic Medicine 1962, 24, 459-63.
Edwards D. A. Neonatal administration of androstenedione, testosterone, or testosterone propionate: Effects on ovulation, sexual receptivity,  and aggressive behavior in female mice. Psychological Behavior 1971, 6, 223-28).
Egbert L., Battit G., Welch C., Bartlett M. Redusction of postoperative pain by encouragement and instruction of patiens. New England Journal of Medicine 1964, 270, 825-27.
Eisner B. G. Notes on the use drugs to facilitate group psychotherapy research. Psychiatric Quarterly 1968, 3, 310-28.
Ekman P., Friesen W. V. Nonverbal behavior in psychotherapy research. 
„Research in Psychotherapy 1968, 3, 179-216.
Ekman P., Freiesen W. V. The repertoire of noverbal behavior categories, origins, usage, and coding. Semiotica 1969, 1, 49-98.
Ekman P., Sorenson E. R., Friesen W. V. Pancultural elements in facial dispays of emotion. Science 1969, 164, 86-88.
Elliot J. ersonal communication to the authors, Oct. 1970.
Ellison R. The invisible man. New York 1952, Random House.
Ellsworth P. C., Carlsmith J. M. Effects of eye contact and verbal contact on affective response to a dyadic interaction. Journal of Personality and Social Psychology 1968, 10, 15-20. 
Ellsworth P.C., Carlsmith J., Henson A. The stare as a stimulus to flight in human subject: A series of field experiments. Journal of ersonality and Social Psychology 1972, 21(3), 302-11.
Elmer E. Children in jeopardy. ittsburgh 1967, University of Pittsburgh Press.
Elmer E. Studies of child abuse nad infant accidents. Mental Health Program Reports, No. 5. (DHEW) Publication No. (HSM) 72-9042. Chevy Chase, Md., National Institute of Mental Health, 1971.
Engel G. Sudden and rapid death during psychological stress: Folklore or folk medicine? Annals of Internal Medicine 1971, 74, 771-82.
Engen T., Lipsitt L. P., Kaye H. Olfactory responses in the human neonate. Journal of Comparative and Physiological Psychology 1963, 56, 73-77.
Erikson M. Experimental demonstrations of the psychoathology of everyday life. The Psychoanalityc Quarterly 1939, 8, 338-53.
Erikson M. H. A special inquiry with Aldous Huxley into the nature and character of various states of consciousness. In: American Journal of Cliniacl Hypnosis 1965, 8, 14-33.
Erikson E. Childhood and society. New York 1950, Norton.
Erikson K. T Wayward puritans: A study in the socjology of deviance. New York 1966, Wiley.
Eron L. D., Huesmann L. R., Lefkowitz M. M., Walder L. O. Does television violence cause aggresion? Ameerican Psychologist 1972, 27, 253-63.
Evans F. J., Kihlstrom J. F. Posthypnotic amnestia as disrupted retrieval. Journal of Abnormal Psychology 1973, 82, 317-23.
Evans J. R., Rodnick E. H., Goldstein M. J., Judd L. L. Premorbild adjustment, phenothiazine treatment and remission in acute schizophrenic.  „Archives of General Psychiatry 1972, 27, 486-90.
Exline R. V., Winters L. Affective relations and mutual glances in dyads.  In: S. Tomkins, C. Izard (Eds.) Affect, cognition, and personality. New York 1965, Springer. 
Eysenck H. J. The effects of psychotherapy: An evaluation. Journal of Consulting Psychology 1952, 16, 319-24.
Eysenck H. J., Eysenck S. Eysenck personality. San Diego 1968, Educational and Industrial Testing Service.
Eysenck H. J., Rachman S. The cauces and cures of neurosis. San Diego, Calif. 1965. Knapp.


Fairweather G. W., et al. Relative effectiveness of psychotherapeutic programs: A multicriteria comparison of four programs  for theree different patient groups. Psychological Monograhs 1960, 74 (5 Whole No. 492.). 
Fairweather G. W., Snaders D. H., Maynard R.F., Cressler D. 
L. Community life for the mentally ill: Alternative to institutional care. Chicago 1969, Aldine.

Fantz R. L. Pattern vision in newborn infants. Science 1963, 140, 296-97).
Farber M. L. Theory of suicide. New York 1968, Funk and Wagnalls.
Farberow N. L., Schneidman E. F. The cry for hel. New York 1965, McGraw-Hill.
Farina A., Gilha D., Boudreau L. A., Allen J. G., Sherman M. Mental illness and the impact of believing others knowabout it. Journal of Abnormal Psychology 1971, 77, 1-5.
Farina A., Holland C. H., Ring K. The role of stigma and set in interpersonal interaction. Journal of Abnormal Psychology 1966, 71, 421-28.
Farina A., Ring K. The influence of perceived mental illness on interpersonal relations. Journal of Abnormal Psychology 1965, 70, 47-51.
Faucheux C., Moscovici S. Le style de comportement dune minorite et son influence sur les reponses dune majorite. Bulletin du Centre dEtudes et Recherches sychologiques 1967, 16, 337-60.
Feather N. Valence of outcome and expectation of success in relation to task difficulty and perceived locus of control. Journal of Personality and Social Psychology 1967 7, 372-86).
Fechner G. T. In Sachen der Psychophysik. Leizig 1887.
Feldman M. J., Hersen M. Attitudes toward death in nightmare subjects. 
„Journal of Abnormal Psychology 1967, 72, 421-25.
Feldstein A., Hoagland H., Oktem M. R., Freeman H. Mao inhibition and anti-depressant activites. International Journal of Neuropsychiatry 1965, 1, 384.
Fenichel O. The psychoanalytic theory of neurosis. New York 1945, Norton.
Fenz W. D. Conflict and stress as related to physiological astivation and sensory, perceptual, and cognitive functioning. Psychological Monographs 1964, 78 (8, Whole No. 585).
Ferguson L. R. Personality development. Belmont, Calif, 1970, Brooks8Cole.
Ferguson P. C., Gowan J. C. Psychological findings on transcendental mediation. Journal of Humanistic Psychology 1976, 16(3).
Ferrare N. A.  Institutionalization and attitude change in an aged population. Unpublished doctoral dissertation, Western Reserve Univeristy, 1962.
Ferriera A. J., Winter W. W. Information exchange and silence in normal and abnormal families. In: W. W. Winter, A. J. Ferriera (Eds.) Research in family interaction. Palo Alto, Calif. 1964, Science and Behavior Books.
Feshbach S., Singer R. D. Television and aggression: An experimental field study. San Francisco 1971, Jossey-Bass.
Festinger L. A theory of social comparison processes. Human Relations 1954, 7, 117-40.
Festinger L. A. A theory of cognitive dissonance. Stanford 1957, Stanford Univeristy Press.
Festinger L., Carlsmith J. M. Cognitive consequences of forced comliance. 
„Journal of Abnormal and Social Psychology 1959, 58, 202-11.
Fiedler F. E. A contingency model of leadershi effectiveness. In: L.  Berkowitz (Ed.) Advances in experimental social psychology. Vol. 1. New York 1964, Academic Press.
Fiedler F. E. A theory of leadership effectiveness. New York 1967, McGraw-Hill.
Fine R. The psychology of blindfold chess: An introsective account. „Acta Psychologica 1965, 24, 352-70.
Firth R. Suicide and risk-taking in Tikopia society. Psychiatry 1961, 24(1), 1-17.
Fischer C., Byrne J. V., Edwards A., Kahn E. REM and NREM nightmares. In: 
E. Hartman (Ed.) Sleep and dreaming. Boston 1970, Little, Brown.

Fiske D. W., Luborsky L., Parloff M. B., Hunt H. F., Orne 
M. T., Reiser M. F., Tuma A. H. Planning of research on effectiveness of psychotherapy. American Psychologist 1970, 25, 727-37.

Fitzsimmons J., Oatley K. Additivity of simuli for drinking in rats. 
„Journal of Comparative and Physiological Psychology 1968, 66, 450-55.
Flavell J. H. The development of inferences about others. In: T. Misbet (Ed). Unterstanding other persons. Oxford. Eng. 1973, Blackwell Basil and Mott.
Fleming J. D. Field report: The state of the apes. sychology Today 1974, 7(8), 31-46.
Fletcher C. R. Attributing responsibility to the deviant: A factor in psychiatric referrals by the general ublic. Journal of Health and Social Behavior 1967, 8, 185-96.
Fodor J. A. Psychological explanation: An introduction to the philosophy of psychology. New York 1968, Random House.
Folkins C. H., Lawson K. D., Opton E. M., Jr., Lazarus R. S.  Desensitization and the experimental reduction of threat. Journal of Abnormal Psychology 1968,, 73, 100-13.Fortune A good man ist hard to find. 1946, 33(3), 92-95  ff.
Frank J. D. Persuasion and healing: A comparative study of psychotherapy. 
Baltimore 1961, Johns Hopkins Press. 
Frank J. D. Persuasion and healing. New York 1963, Schocken Books.
Frankl V. E. Mans search for meaning. Boston 1963, Beacon Press. 
(Originally published, 1959).
Frankl V. E. Logotherapy. In: W. S. Sahiakan (Ed). Psychopathology today. 
Itasca, III. 1970, F.E. Peacock.
Fraser S. C. Deindividuation: Effects of anonymity on aggression in children. Unpublished mimeograph report, University of Southern Calofornia, 1974.
Fraser S. C., Kelem R., Diener E., Beaman A. The Halloween caper: The effects deindividuation variables on stealing. Journal of Personality and Social Psychology 1974.
Fredman J. L., Fraser S. C. Compliance without pressure: The foot-in-the-door technique. Journal of Personality and Social Psychology 1966, 4, 195-202.
Freedman J., Levy A., Buchana R., Price J. Crowding and human aggressiveness. Journal of Experimental and Social Psychology 1972, 8, 528-48.
Freeman F. N., Holzinger K. J., Mitchell B. C. The influence of environment on the intelligence achievement and conduct of foster children.  In: National Society for the Study of Education. 27 th Yearbook, Part 1, 1928.
Freeman W., Watts J. W. Psychosurgery. Springfield, III. 1927, Charles C. 
Thomas.
Freemon F.R. Sleep research: A critical review. Sringfield, III. 1972, Charles C. Thomas.
Freud S. The interpretation of dreams. Vol. 5 The standard edition of the complete psychological works of Sigmunt Freud. London 1900, Hogarth Press.
Freud S. Recommendations for physicians on the psycho-analytic methody of treatment. In: Collected papers. Vol. 2. London 1956, Hogarth Press.
Freud S. Psychopathology of everyday life. In: J. Strachey (Ed). The standard edition of the complete psychological works of Sigmund Freud .  London 1960, Hogarth Press. (First German edition, 1901).
Freud S. Introductory lectures on psycho-analysis. In: J. Strachey (Ed.) 
The standard edition of the complete psychological works of Sigmund Freud. 
London 1963, Hogarth Press. (First German edition, 1917).


Friedman M., Rosenman R. F. Overt behavior pattern in coronary disease. 
„Journal of the American Medical Association 1960, 173, 1320-25.
Friedman M., Rosenman R. F. Type A behavior and your heart. New York 1974, Knopf.
Freidman S. B., Ader R., Glasgow L. A. Effects of psychological stress in adult mice inoculated with coxackie B viruses. Psychosomatic Medicine 1965, 27, 361-68.
Friedman S. B., Glasgow L. A. Psychologic factors and reistance to infectious diseae. Pediatric Clinic of North America 1966, 13, 315-35.
Frijda N. H. Emotion and recognition of emotnion. IN: M. Arnold (Ed). 
Feelings and emotions. New York 1970. Academic Press.
Funkenstein D. H. The physiology of fear and anger. Scientific American 1955, 192(5), 74-80.
Funkestein D. H., King S. H., Dorolette M. E. Mastery of tress. 
Cambridge, Mass, 1957, Harvard Univesity Press.


Gage N. Q., heritability, race differences, and educational research. 
„Phi Delta Kappan Jan 1972, 308-12.
Galin D., Ornstein R. Lateral specialization of cognitive mode: An EEG study. Psychophysiology 1972, 412-18.
Galton F. Inquires into human faculty and is development, London 1907. J. 
M. Dent and Sons. (Originally published: London: Macmillian, 1883).

Gnatt W. H. Reflexology, schizokinesis, and autokinesis. Conditional Reflex 1966, 1, 57-68.
Garcia J., McGowan B. K., Green K. F. Sensory quality and integration: 
Constraints on conditioning. In: A. H. Black, W. F. Prokasy (Eds.) Classical conditions II: Current research and theory. New York 1972, Appleton-Contury-Crofts.
Gardner L. Deprivation dwarfism. Scientific American 1972, 227-76-82.
Gardner M. Fads and fallacies in the name of science. New York 1957, Dover.
Garndner R., Gardner B. T. Teaching sign language to a chimpanzee. 
„Science 1969, 165, 664-72.
Gardner R., Heider K. A. Gardens of war: Life and death in the New Guinea stone age. New York 1969, Random House.
Gasset J. O. The dehumanization of art. Princeton, N. J. 1969, Princeton University Press. (Originally published, 1925).
Gastaut H., Bert J. Electroencephalographic detection of sleep by repetitive sensory stimuli. In: G. E. W. Wolstenholme, M. OConnor (Eds.) The nature of sleep. London 1961, Churchill.
Gatland K. Paranormal: Extrasensory perception: Party or tricks... Or hidden forces? The Daily Telegraph Magazine Dec 7, 1973, 475, 62-63, 65.
Gazzaniga M. S. The bisected brain. New York 1970, Appleton-Century-Crofts.
Gebhard P. H. Situational factors affecting hyman sexual behavior. In: F. 
Beach (Ed). Sex and behavior. New York 1965, Wiley.
Geen R., Berkowitz L. Name-mediated aggressive cue properties. „Journal of Personality 1966, 34, 456-65.
Gelernter H. Realization of a geometry theorem roving machine. 
Proccedings of the International Conference on Information Processing. 
Paris 1960, UNESCO.
Gandlin E. Experimental psychotherapy. In: R. Corsini (Ed) Current psychotherapies. Itasca, III. 1973, F.E. Peacock.Gergen K. J. The concept of self. New York 1971, Holt, Rinehart and Winston. 
Gewirtz J. L., Bear D. M. Deprivation and satiation of social reinforcers as drive conditions. Journal of Abnormal and Social Psychology 1958, 57, 165-72.
Gibbon J. Discriminatecd punishment: Avoidable and unavoidable shock. 
„Jourmal of the Experimental Analysis of Behavior 1967, 10, 451-60.
Gibson E. J. Principles of perpectual learning and development. New York 1969, Appleton-Century-Crofts.
Gibson E. J. The development of perception as an adaptive process. 
„American Scientist 1970, 58, 98-107.
Gibson E. J., Walk R. D. The visual cliff. Scincific American 1960, 202 (4), 67-71.
Gilbert G. M. Stereotype persistence and change among college students. 
„Journal af Abnormal and Social Psychology 1951, 46, 245-54.
Glass B. C., Singer J. E. Urban stress: Experiments on noise and social stressors. New York 1972, Academic Press.
Gloop P. Autonomic functions of the diencephalon: A summary of the experimental work of professor W. R. Hess. Archives of Neurology and Psychiarty 1954, 71, 773-90.
Glover E. The technique of psychoanalysis. New York 1966, International Univeristes Press.
Goddard H. H. The Binet test in relation to immigration. Journal of Psycho-Asthenics 1913, 18, 105-7.
Goddard H. H. Mental tests and the immigrant. Journal of Delinguency 1917, 2, 243-77. 
Goddard H. H. The Kallikak family. New York 1973, Arno Press. (Originaly published: New York 1912, Macmillan).
Goffman E. Asylums: Essays on the social situation of mental patients and other inmates. Garden City, N. Y. 1961, Doubleday.
Goldberg P. Are woman prejudiced against women? Transaction 1968, 5(5), 28-30.
Goldfarb W. The effects of early institutional care on adolescent personality. Journal of Experimental Education 1943, 12, 106-29.
Goldiamoond I. Fluent and nonfluend speech (stuttering): Analysis and operant techniques for control. In: L. Krasner, L. P. Ullman (Eds.) Research in behavior modification. New York 1965, Holt, Rinehart und Winston.
Goldstein A. P., Heller K., Sechrest L. B. Psychotherapy and the psychology of behavior change. New York 1966, Wiley.
Goldstein K. The organism. Boston 1963, Beacon Press.
Gough H. G. Techniques for identyfing the creative research scientist.  In: Conference in the creative person. Berkeley 1961, University of California, Institute od Personality Assessment and Research.
Gouldner A. The norm of recirocity: A reliminary statement. American Sociological Review 1960, 25, 161-78.
Graham K. R. Eye movements during walking imagery and hynotic halucinations. Unpublished doctoral disseration, Stanford University, 1969.
Granit R. The basis of motor control. New York 1970, Academic Press.
Gray F., Graubard P. S., Rosenberg H. Little brother is changing you. 
„Psychology Today March 1974, 7, 42-46. 
Green E. E., Green A., Walter E. D. A demonstration of voluntary control of bleeding and  pain. Unublished manuscript. The Menninger Foundation, 1972.
Greenblatt G., Eastlake D., Crocker S. The Greenblat chess program.  Proceedings of the Fall Joint Computer Conference. Washington, D. C. 1967, Thompson.
Greenfield P. M. On culture and conservation. In: J. S. Bruner, R. R. 
Olver, P. M. Greenfield Studies in cognitive growth. New York 1966, Wiley.
Greenfield P. M., Bruner J. S. Culture and cognitive growth. In: J. S. 
Bruner (Ed.) Beyond the information given. New York 1973, Norton.
Greenwald A. G., Brock T. C., Ostrom T. M. Psychological foundations of attitude. New York 1968, Academic Press.
Gregory R. L. Eye and brain: The psychology of seeing. New York 1966. 
McGrwa-Hill.
Grimmett H. Personal communication to the authors, Oct. 1970.
Grollman E. A. Suicide. Boston 1971. Beacon Press.
Gross C. G. Visual functions of interotemporal cortex. In: R. Jung (Ed).  Handbook of sensory physiology. Vol. 7. Part 3b. Berlin 1973, Springer-Verlag. 
Gross C. G., Rocha-Miranda C. E., Bender D. B. Visual properties of neurons in interotemporal cortex of the macaque. Journal of Neurophysiology 1972, 35, 96-111.
Gross L. Scarcity, unpredictability and eating behavior in rats. 
Unpublished doctoral disseration, Columbia University, 1968.
Grossberg J. M. Behavior therapy: A review. Psychological Bulletin 1964, 109, 73-88.
Grossman S. P. Neuropharmacology of central mechanism contributing to control of food and water intake. In: C. Code (Ed.) Handbook of physiology.  Baltimore 1967, Williams and Wilkins.
Grossman S. P. Physiological basis of specific and nonspecific motivational processes. In: W. J. Arnold (Ed.) Nebraska symposium on motivation. Lincoln 1968, University of Nebraska Press.
Gruber R. P. Behavior therapy: Problems in generalization. Behavior Therapy 1971, s, 361-68.
Gruen W. Emotional encapsulations as a predicor of outcime in therapeutic discussion groups. International Journal of Group Psychotherapeuty 1966, 16, 93-97.
Gruces J. Demand characteristic of the modeling experiment: Altruizm as a function of age and aggression. Journal of Personality and Social Psychology 1972, 22, 139-48.
Gruver G. G. College students as theraeutic agents. Psychological Bulletin 1971, 76, 111-27.
Guetzkow H. S., Bowman P. H. Men and hunger. Elgin, III. 1946, Brethren.
Guilford J.S. Theories of intelligence. In: B. B. Wolman (Ed.) Handbook of general psychology. Englewood Cliffs, N. Y. 1973, Prentice-Hall.
Gunter R., Feigeson L., Blakeslee P. Color vision in the cebus monkey. 
„Journal of Comparative and Physiological Psychology 1965, 60, 107-13.
Gustavson C. R., Garcia J., Hankins W. G., Rusiniak K. W. Coyote predation control by aversiwe cinditioning. Scince 1974, 184, 581-83.
Haas H., Fink., H., Hartfedler G. Das Placeboproblem. Fortschritte der Arzneimittleforschung 1959, 1, 279-454. Translated in „Psychoharmacology Service Center Bulletin 1959, 2(8), 1-65. U. S. Department of Health, Education and Welfare, Public Health Service.
Haber R. N. (Ed.) Contemoprary theory and research in visual perception. 
New York 1968, Holt, Rinehart and Winston.
Haldeman-Julius E. First hundret million. New York 1928, Simon and Schuster.
Hall C., Van de Castle R. The content analysis of dreams. New York 1966, Appleton-Century-Crofts.
Hall E. T. The hidden dimension. Garden City, N. Y. 1966, Doubleday.
Hammer E. F. Creativity and feminine ingredients in young male artists. 
„Perceptual and Motor Skills 1964, 19, 414.
Hammond A. L. Individual self-suffiency in energy, Science 1974, 184, 278-82.
Hampson S.L. Determinants of psychosexual orientation. In: F. Beach (Ed.) 
Sex and behavior. New York 1965, Wiley.
Hansel C. E. M. ESP: A scientificevaluation. New York 1966, Scribners.
Harlow H. F. Sexual behavior in the rhesus monkey. In: F. Beach (Ed.) Sex and behavior. New York 1965, Wiley.
Harlow H. F. Learning to love. San Francisco 1971, Albion.
Harlow H. F., Harlow M. K. Learning to love. American Scientist 1966, 54, 244-72.
Harlow H. F., Zimmerman R. R. The development of affectional responses in infant monkeys. Proceedings of the American Philosophical Society 1958, 102, 501-9.
Harriman A. E. The effect of a preoperative preference for suger over salt upon compensatory salt selection by adrealectomized rats. Journal of Nutrition 1955, 57, 271-76.
Harris S. J. Exerpt from Strictly Personal by Sydney J. Harris. San Francisco Sunday Examiner8Chronicle Jan. 20, 1974, Sec. B, p. 3.  Courtesy of Publishers-Hall Syndicate.
Hart J. T. Memory and the memory-monitoring process. Journal of Verbal Learning and Verbal Behavior 1967, 6, 685-91.
Hartry A. L., Keith-Lee P., Morton W. D. lanaria: Memory transfer through cannibalism reexamined. Science 1964, 146, 274-75.
Hartshorne H., May M. A. Studies in the nature of character. Vol. 1.  Studies in deceit. New York 1928, Macmillan. Harvard Educational Review The rihgt of children. Parts I, II, Nov. 1973, 43(4) and Feb. 1974, 44(1).
Harvey J. A. Behavioral tolerance. In: J. A. Harvey (Ed.) Behavioral analysis of drug action. Glenview, III. 1971, Scott, Foresman.
Hashim S. A., Van Itallie T. B. Studies on normal and obese subjects with a monitored food dispensing device. Annals of the New York Academy of Sciences 1965, 131, 654-61.
Hatano G. Personal communication, August 1975.
Hauserman N., Walen S. R., Behling M. Reinforced racial integration in the first grade: A study in generalization. Journal of Applied Behavior Analysis Summer 1973, 6(2), 193-200.
Hawkins G. Stonehenge decoded: An astronomer examines one of the great puzzles of the ancient world. Garden City, N. Y. 1965, Doubleday.
Hayes K. J., Hayes C. Imitation in a home-raised chimpanzee. „Journal of Comparative and Physiological Psychology 1952, 45, 450-59.
Heath R. G., Mickle W. A. Evaluation of seven years experience with depth electrode studies in human patients. In: E. R. Ramey, D. S. ODoherty Electrical studies of the unanesthetized brain. New York 1960, Holber.
Hebb D. O. A textbookof psychology. Philadelphia 1958, Saunders.
Hebb D. O. What psychology is about. American Psychologist 1974, 29, 71-79.
Hebb D. O. The psychology of interpersonal relations. New York 1958, Wiley.
Heider F., Simmel M. An experimental study of apparent behavior. 
„American Journal of Psychology 1944, 57, 243-59.
Held R. Plasticity in sensory-motor systems. Scientific American 1965, 213(5), 84-94.
Helfer R. E., Kempe C. H. The battered child. Chicago 1968, University of Chicago Press.
Heller C. S. Mexican-American youth: Forgotten youth at the crossroads. 
New York 1966, Random House.
Helson R. Sex differences in creative style. Journal of Personality 1967, 35, 214-33.
Heron W. Perception as a function of retinal locus. American Journal of Psychology 1957, 70, 38-48.
Heron W. Cognitive and physiological effects of perceptual isolation. In: 
P. Solomon et al. (Eds.) Sensory derivation. Cambridge 1961, Harvard University Press.
Hersen M. Nightmare behavior: A review. Psychological Bulletin 1972, 78, 37-48.
Hershenson M., Munsinger H., Kessen W. Preference for shapes of intermediate variability in the newborn human. Science 1965, 147, 630-31.
Hershkowitz A. Personal communication to the authors, Nov. 1970.
Hess E. H. Space perception in the chick. Scientific American 1956, 195(1), 71-80.
Hess E. H. Impriting. Science 1959, 130, 133-41.
Hess E. H. Pupillometrics: A method of studying mental emotional and sensory processes. In: N. E. Grenfield, R. A. Steinbach (Eds.) Handbook of psychophysiology. New York 1972, Holt, Rinerhat and Winston.
Hicks D. J. Effects of co-observers sanctions and adult presence on imitative aggression. Child Development 1968, 39, 303-9.
Hilgard E. R. Hynotic susceptilibity. New York 1965, Harcourt Brace Jovanovich.
Hilgard E. R. Pain as a puzzle for psychology and hysiology. American Psychologist 1969, 24, 103-13.
Hilgard E. R. Personality and hypnosis: A study of imaginative involvement. Chicago 1970-, University of Chicago Press.
Hilgard E. R. The domain of hypnosis. With some comments on alternative paradigsm. American Psychologist 1973, 28, 972-82.
Hilgard E. R., Nowlis D. P. The contenst of hypnotic dreams and nihgt dreams: An exercise in method. In: E, Fromm, R. E. Shor (Eds.) Hypnosis: 
Research developments and persectives. Chicago 1972, Aldine.
Hinkle L. E., Jr., Plummer N. Life stress and industrial absenteeism. 
„Industrial Medicine and Surgery 1952, 21, 363-75.
Hinkle L. E., Wolff H. Communist interrogation and indoctrination of „Enemies of the state. Archives of Neurology and Psychiatry 1956, 76, 115-74.
Hiroto D. S. Locus of control and learned helplessness. Journal of Experimental Psychology 1974, 102(2), 187-93.
Hirsch H. V. B. Visual perception in cats after environmental surgery. 
„Experimental Brain Research 1972, 15, 405-23.
Hirsch H. V. B., Jacobson M. The perfectible brain. Principles of neuronal development. In: M. S. Gazzaninga, C. Blakemore (Eds.) Handbook of psychobiology. New York 1974, Academic Press.
Hirsch H. V. B., Spinelli D .N. Visual experience modifes distribution of horizontally and vertically oriented receptive fields of cats. Science 1970, 168, 869-71.
Hirsch H. V. B., Sinelli D. N. Modyfication of the distribution of receptive field orientation in cats by selective visual exposure during development. Experimental Brain Research 1971, 13, 509-27.
Hirscch J. Behavior - genetic analysis and its biosocial consequences. 
In: Seminars in psychiatry. February 1970, 2(1), 89 - 105.  
Hirsch J., Han D. W. Cellularity of rat adipose tissue: Effect of growth, starvation, and obesity. Journal of Lipid Research 1969, 10, 77-82.
Hitler A. (Mein Kampf) My battle. E. T. S. Dugdale (Trans). New York 1933, Huoghton Mifflin.
Hitt W. D. Two models of man. American Psychologist 1969, 24(7), 651-58.
Hoebel B., Teitelbaum P. Hypothalamic control of feeding and self-stimulation. Science 1962, 135, 375-77.
Hogan R. A., Kirchner J. H. Imlosive, ecletic, verbal and bibliotherapy in the treatment of fears of snakes. Behavior Research and Therapy 1968, 6, 167-71.
Hogarty G. E., Guy W., Gross M., Gross G. An evaluation of community based mental health programs. Medical Care 1969, 7, 271-80. 
Hokanson J. E., Burgess M. The effects of three types of aggression on vascular processes. Journal of Abnormal and Social Psychology 1962, 64, 446-49. (a).
Hokanson J. E., DeGood D. E., Forrest M. S., Brittain T. M. Availablity of avoidance behaviors in modulating cascularstress responses. „Journal of Personality and Social Psychology July 1971, 19(1), 60-68.
Hollander E. P. Some futur potentials in ledership research. Paper presented at the meeting of the American Psychological Association, Honolulu, Sept, 3, 1972. 
Hollander E. P., Julian J. W. Contemporary trends in the analysis of ledership processes. Psychological Bulletin, 1969, 71, 387-97.
Hollingshead A. B., Redlich F. S. Social class and mental illnes: A community study. New York 1958, Wiley.
Holmes T. H., Masuda M. Life change and illness sucseptibility. In: B. S.  Dohrenwend, B. P. Dohrenwend (Eds.) Stressful life events; their nature and effects. New York 1974, Wiley.
Holmes T. H., Holmes T. H. Short-term intrusions into life-style routine. 
„Journal of Psychosomatic Research June 1970, 14, 121-32.
Holt H. Is psychoanalysis launguage obsolete? Journal of Contemporary Psychotherapy 1970, 3, 35-40.
Holt R. R. Assessing personality. New York 1971, Harcourt Brace Jovanovich.
Holzberg J. D. The historical traditionis of the state hosital as a force of resistance to the team. American Journal of Othopsychiatry 1960, 30, 87-94.
Honzik M. P. The develoment of intelligence. In: B. B. Wolman (Ed.) Handbook of general psychology. Englewood Cliffs, N. J. 1973, Prentice-Hall.
Hoover J. E. Crime in the United States: Uniform crime reports - 1970. 
Washington, D. C. 1971, U. S. Government Printing Office.
Horner M. S. Fail: Bright women. Psychology Today November 1969, 3, 36-38.
Horstein H. A. Promotive tension: The bais of prosocial behavior from a Lewinian perspective. Journal of Social Issues 1972, 28, 191-218.
Hovland C. I., Janis I. L., Kelley H. H. Communication and persuasion. 
New Haven 1953, Yale University Press.
Howard I. P. Perceptual learning and adaptation. British Medical Bulletin 1971, 27, 248-52.
Hraba J., Grant G. Black is beautiful: A reexamination of racial preference and identyfication. Journal of Personality and Social Psychology 1970, 16, 398-402.
Hubel D. H., Wiesel T. N. Receptive fields of single neurones in the cars striate cortex. Journal of Physiology London, 1959, 148, 574-91.
Hull C. L. Principles of behavior: An introduction to behavior theory. 
New York 1943, Appleton-Century-Crofts.
Hull C. L. A behavior system: An introduction to behavior theory concerning the individual organism. New Haven 1952, Yale University Press.
Im Late. Words by Bob Hilliard and music Sammy Fain. Copyright 1949 by Walt Disney Music Company. Excerpt reprinted by permission.Inbau F., Reid J. E. Criminal interrogations and confessions. (2 nd ed.) Baltimore 1967, Williams and Wilkins.
Irwin O. C. The effect on speech soundt frequency of systematic reading of stories  to infants. Unpublished study by the Iowa Child Welfare Research Station, 1958. Reported in. P. H. Mussen (Ed.) Handbook of research mithods in child development. New York 1960, Wiley.
Irwin S. Drugs of abouse: An introduction to their actions and potencjal hazadrs. Journal of Psychedelic Drugs 1971, 2, 1-16.
Isaacs W., Thomas J., Goldiamond I. Application of operant contitioning to reinstate verbal behavior in psychotics. Journal of Speech and Hearing Discordes 1960, 25, 8-12.
Itard J. M. G. The wild boy of Aveyron. New York 1962, Appleton-Century-Crofts.
Ivey A. E. Microcouseling Innovations in interview training. 
Springfield, III. 1971, Charles C. Thomas.
Izard C. E. The face of emotion. New York 1971, Appleton-Century-Crofts.


Jackson G. Soledad brother: The prison letters of George Jackson. New Jork 1971, Bantam.
Jacobs E., Winter P. M., Alvis H. J., Small S. M. Hyperbaric oxygen: 
Temporary aid for senile minds. Journal of the American Medical Association 1969, 209, 1435-38.
Jacobs H. L., Sharma K. N. Taste versus calories: Sensory and metabolic signals in the control of food intake. Annals of the New York Academy of Sciences 1968, 134.
Jacobs J. Death and life of great American cities. New York 1961, Vintage Books. Coyright ©. 1961 by Jane Jacobs. Exerpt reprinted by persmission of Random House, Inc.
James W. What is an emotion? Mind 1884, 9, 188-205.
James W. The principles of psychology. Vol. 1. New York 1890, Holt.
James W. The varieties of religious experience. New York 1902, Logmans, Green.
James W. An analysis of esophageal feeding as form of operant reinforcement in the dog. Psychological Reports 1963, 12, 31-39.
Janis I. L. Psychological stress. New York 1958, Wiley.
Janis I. L. Victims of groupthink: A psychological study of foreign-policy decisions and fiascoes. Boston 1972, Houghton Mifflin.
Jellinck E. M. The diseace-concept of alcoholism. New Haven, Conn. 1960, Hillhouse Press.
Jenkins D. C., Rosenman R. H., Friedman M. Development of an objective psychological test for the determination of the coronary-prone behavior pattern in employed men. Journal of Chronic Diseases 1967, 20, 371-79.
Jemnkins J. G., Dallenbach K. M. Oblivescence during sleep and waking. 
„The American Journal of Psychology 1924, 35, 605-12.
Jensen A. R. How much can we boost I. Q. and scholastic achievement? 
„Harvard Educational Review 1969, 39, 1-123.
Jensen A. R. I. Q.s of identical twins reared appart. Behavior Genetics 1970, 1, 133-46.
Jensen A. R. The heritability of intelligence. Saturday Evening Post Summer 1972, 149.
Jensen D. D. Paramecia, planaria and pseudo-learning. Learning and associated phenomena in invertebrates. Animal Behavior Supplement 1965, 1, 9-20.
Johnson F. G. LSD in the treatment of alcofolism. Paper presented at the American Psychiatric Meeting, Boston, June 1968.
Johnson J. M. Punishment of human behavior. American Psychologist 1972, 27, 1033-54.
Johnson K. R. Black kinesics: Some non-verbal communication patterns in the black culture. The Florida FL Reporter Spring8Fall 1971.
Joint Commission on Mental Illnes and Health Action for mental health. 
New York 1961, Basic Books.
Jones D., Davis K. From acts to dispositions: The attribution rocess in person percetion. In: L. Berkowitz (Ed.) Advances in experimental social psychology. Vol. 2. New York 1965, Academic Press.
Jones E. E., Nisbett R. E. The actor and the observer: Divergent erceptions on the causes of behavior. (Module) In: E. E. Jones te al.  (Eds.) Attribution: Perceiving the causes of behavior. Morristown, N.J. 
1972, General Learning Corp.
Julez B. Foundations of cyclopean parception. Chicago 1971, University of Chicago Press.


Kahn M. The physiology of catharsis. Journal of Personality and Social Psychology 1966, 3, 278-86.
Kamin L. The science and polotics of IQ. Potomac, Md. 1974, L. Erlbaum Associates.
Kandel D. Adolescent marijuana use: Role of parents and peers. „Science 1973, 181, 1067-70.
Konellakos D. P., Ferguson P. The psychobiology of transcendental mediation. Los Angeles 1973, Maharishi International University.
Kaplan B. (Ed.) The inner word of mental illnes. New York 1964, Harper and Row, pp. 191-92. Excerpt reprinted by permission.
Kaplan E. L., Kaplan G. A. Is there such a thing as a prelinguistic child? In: J. Eliot (Ed.) Human Development and cognitive processes. New York 1970, Holt, Rinehart and Winston.
Karlins M., Coffman T. L., Walters G. On the fading of social stereotypes: Studies in three generations of college students. Journal of Personality and Social Psychology 1969, 13, 1-16. 
Kasamatsu A., Hirai T. An EEG study on the Zen meditation. Folia Psychiatria Neurologica Japonica 1966, 20, 315-36.
Katchadourian H., Lunde D.I. Fundamentals of human sexuality. New York 1972, Holt, Rinehart and Winston.
Katz D., Braly K.W. Racial stereotypes of one hundred college students. 
„Journal of Abnormal and Social Psychology 1933, 28, 280-90.
Katz I. Experimental studies of negro-white relationship. In: L.  Berkowitz (Ed.) Advences in experimental social psychology. Vol. 5. New York 1970, Academic Press.
Katz M.P. The assessment and treatment of mental atients as a function of their attructiveness. Unpublished dissertation, Stanford Univeristy, 1974.
Kaufman I., Rock I. The moon illusion. Scientific American 1962, 204, 120-30.
Kaufmann W. Existentialism form Dostoevsky to Sartre. New York 1956. 
Meridian.
Kelley H.H. The warm-cold variable in first impressions of persons. 
„Journal of Personality 1950, 18, 431-39.
Keley H.H. Attribution theory in social psychology. In: D. Levine (Ed.) Nebraska symposium on motivation. Lincoln 1967, University of Nebraska Press.
Keley H.H. Attribution in social psychology. (Module) In: E.E. Jones et al. (Eds,) Attribution: Perceiving the causes of behavior. Morristown, N.J.  1972. General Learning Corp.
Kellogg W.N., Kellogg L.A. The ae and the child: A study of environmental influence on early behavior. New York 1967, Hafner (Originally published: 
New York 1933, McGraw-Hill.
Kelly G.A. Mans construction of his alternatives. In: G. Lindzey (Ed.) 
Assessment of human motives. New York 1958, Holt, Reinhart and Winston.
Kelman H.C. Human use of human volues and social research. (1st ed.) San Francisco 1968, Jossey-Bass.
Kelman H.C., Lawrence L.H. Assignment of responsibility in the case of Lt. Calley: Preliminary report on a national survey. Journal of Social Issues 1972, 28, 177-212.
Kendler H.H., Kendler T.S. Mediation and conceptual behavior. In: K. W. 
Spence, J.T. Spence (Eds.) Yhe psychology of learning and motivation: 
Advances in research and theory. Vol. 2. New York: 1968, Academic Press.
Kerckfoff A.C., Davis K.E. Value consencus and need complementarity in mate selection. American Sociological Review 1962, 27, 295-303.
Kessen W. The child. New York 1965, Wikey.
Kessler J.W. Psychopathology of childhood. Englewood Cliffs, N.J. 1966, Prentice-Hall.
Kety S.S. Psychoendocrine systems and emotions: Biological aspects. In: 
D.C. Glass (Ed.) Neurophysiology and emotion. New York 1967 a, Rockefeller Univeristy Press.
Kety S.S. Relationship between energy metabolism of the brain and functional activity. In: S.S. Kety, E.V. Evarts, H.L. Williams (Eds.) Sleep and altered states of consciousness. Baltimore 1967 b, Williams and Wilkins.
Keys A., Brozek J., Henschel A., Mickelson O., Taylor H.L. The biology of human starvation. Minneapolis 1950,, University of Minnesota Press.
Kiesler C. The psychology of commitment: Experiments linking behavior to belief. New York 1971, Academic Press.
King J.H. Brief account of the sufferings of a detachment of United States Cavalry, from derivation of water, during a period of eighty-six hours while scouting in the Llano Estacado, or Staked Plains. Texas.  „American Journal of Medical Science 1878, 75, 404-8. 
Kinsey A.C., Martin C.E., Pomeroy W.B. Sexual behavior in the human male. 
Philadelhia 1948, Saunders.
Kinsey A.C., Pomeroy W.B., Martin C.E., Gebhard R.H. Sexual behavior in the human female. Philadelhia 1953, Saunders.
Kirtner W.L., Cartwright D.S. Success and failure in clientcentered therapy as a function of client personality variables. Journal of Consulting Psychology 1958, 22, 259-64.
Kitsuse J.I. Societal reactions to deviant behavior: Problems of theory and methods. In: H.S. Becker (Ed.) The other side. Perspectives on deviance. New York 1964, The Free Press.
Klee G.D., Bertino J., Weintraub W., Calloway E. The influence of varying dosage on the effects of lysergic acid diethylamide (LSD-25) in humans.  „Journal of Nervous and Mental Diseases 1961, 132, 404-9.
Klerman G.L., Cole J.O. Pharmacological Review 1965, 17, 101.
Klimova (Klimowa) V.I. The properties of the components of some orientation reactions. In: The orientation reaction and orientating-investigation of activity. Moscow 1958, Academy of pedagogical Sciences.
Knapp R., Kause R., Perkins C. Immediate vs. delayed shock in t-maze performance. Journal of Experimental Psychology 1959, 58, 357-62.
Kohlberg L. Moral and religious education and the public schools: A developmental view. In: T. Sizer (Ed). Religion and Public Education.  Boston 1967, Houghton Mifflin.
Kohlberg L. State and sequence: The cognitive-developmental approach to socialization. In: D.A. Goslin (Ed.) Handbook of socialization theory and research. Chicago 1969, Rand McNally.
Kohlberg L., Kramer R. Continuities and discontinuities in childhood and adult moral development. Human Development 1969, 12, 93-120.
Kohler L. Experiments with goggles. Scientific American 1962, 206, 62-86.
Kohler W. The mentality of apes. New York 1926, Harcourt Brace Jovanovich.
Kollar E.J., et at. Psychological, psychophysiological, and biochemical correlates of prolonged sleep deprivation. American Journal of Psychiatry 1969, 126, 488-97.
Kopp S. The Zaddik. Psychology Today May 1969, 2, 26-31.
Koriat A., Melkman R., Averill J.R., Lazarus R.S. The self-control of emotional reactions to a stressful film. Journal of Personality 1972, 40, 601-19.
Krafft-Ebing R.V. Psychopathia sexualis. New York 1932, Physicians and Surgeons Book Comany.
Kringlen E. Schizophrenia in twins. Schizophrenia Bulletin Dec. 1969, 1, 27-39.
Krippner S. Psychedelic experience and the language process. Journal of Psychedelic Drugs September 1970, 3(1), 41-51.
Krueger W.C.F. The effect of overlearning on retention. Journal of Experimental Psychology 1929, 12, 71-78.
Kuhn M.H., McPartland T.S. An emirical investigation of self attiudes. 
„American Social Review 1954, 19, 68-76.
Kupalov (Kupałow) P.S. Some normal and pathological properties of nervous processes in the brain. In: N.S. Kline (Ed.) Pavlovian conference on higer nervous activity. Annals of the New York Academy of Sciences 1961, 92, 1046-53.
Kutschinsky B. The effect of pornography: A pilot experiment on perception, behavior and attitudes. Technical Report of the Commission on Obscenity and Pornograhy. Vol. 8. Washington, D.C.: U.S. Government Printing Office, 1971.


Labov W. The logic of non-standard English. The Florida FL Reporter Spring8Summer 1969, 60-169.
Labov W., Cohen ., Robins C., Lewis J. A study of the non-standard English of Negro and Puerto Rican speakers in New York City. Vol. 1 and 2.  Columbia University Cooperative Research Project No. 3288, 1968, U.S. 
Office of Education.
Lachman S.J. A behavioristic rationale for the development of psychosomatic phenomen. Journal of Psychology 1963, 56, 239-48.
Laing R.D. The politics of experience. New York 1967, Pantheon.
Lakin M. Experimential groups: The uses of interpersonal encounter, psychotherapy groups, and sensitiving training. (Module) Morristown, N.J.  1972, General Learning Corp.
Landis C., Cushman J.F. The relation of national prohibition to the incidence of mental disease. Quarterly Journal of Studies on Alcohol 1945, 5, 527-34.
Landreth C., Johnson B.C. Young childrens responses to a ictuer inset test designet to reveal reactions to presence of different skin color.  „Child Develoment Monographs 1953, 24, 63-80.
Lane R.C., Singer J.L. Familial attitudes in aranoid schizophrenia and normals from two socioeconomic classes. Journal of Abnormal and Social Psychology 1959, 59, 328-39.
Langner T.S., et al. Reported in The New York Times March 2, 1970, p.28.
Larsen K.S., Coleman D., Forebs J., Johnson R. Is the subjects personality or the experimental situatin a better predictor of a subjects willingness to administer shock to a victim? Journal of Personality and Social Psychology 1972, 22, 287-95.
Lasagna L., Mosteller F., von Felsinger J.M., Beecher H.K. A study of the placebo response. American Journal of Medicine 1954, 16, 770-79.
Lashley K.S. Brain mechanisms and intelligence. Chicago 1929, University of Chicago Press.
Lashley K.S. In search of the engram. In: Physiological mechanisms in animal behavior: Symposium of the Society for Experimental Biology. New York, 1950, Academic Press.
Latane B (Ed.) Studies in social comparison: Introduction and overiview. 
„Journal of Experimental Social Psychology 1966, 2, Supplement No. 1.
Lazarus R.S. Emotions and adaptation: Conceptual and empirical realtions.  In: W.J. Arnold (Ed.) Nebraska symopsium on motivation. Lincoln 1968, University of Nebraska Press.
Leahy A.M. Nature-nurture and intelligence. Genetic Psychology Monographs 1935, 17, 23-308.
Lederberg J. Genetic engineering, or the amelioration of genetic defect. 
„The Pharos of Aplha Omega Alpha 1972, 34, 9-12.
Leeper R.W. A study of a neglected ortion of the field of learning: The development of sensory organization. Pedagogical Seminary and Journal of Genetic Psychology 1935, 46, 41-75.
Leepee R.W. A motivational theory of emotion to replace emotion as disorganized response. Psychological Review 1948, 55, 5-21.
Lefcourt H.M. Internal versus external control of reinforcement: A review. Psychological Bulletin 1966, 65, 206-20.
Lefcourt H.M. Recent development in the study of locus of control. In: 
B.A. Maher (Ed.) Progress in experimental personality research. Vol. 6. New York 1972, Academic Press.
Lefford A. The influence of emotional subject matter on logical reasoning. Journal of General Psychology 1946, 34, 127-51.
Lenneberg E.H. On explaining language. Science 1969, 164, 635-43.
Leo J. Women are said to be infringing on another mens prerogative The freedom to curse. The New York Times Oct. 20, 1968, p. 49.
Lepper M.R., Grenne D. Turning Play into work; Effects of adult surveillance and extrinsic rewards on childrens intrinsic motivation.  „Journal of Personality and Social Psychology 1975, 31, 479-486.
Lepper M.R., Grenne D., Nisbett R.E. Undermining childrens intrinsic interest with extrinsic reward: A test of the overjustifycation hypnothesis. Journal of Personality and Social Psychology 1973, 28(1), 129-37.
LeShan L. An emotional life-history pattern associated with neoplastic disease. Annals of the New York Academy of Sciences 1966, 125, 780-93.
Leslie J. Ethics and practice of placebo therapy. American Journal of Medicine 1954, 16, 854.
Leukel F. A comarison of the effects of ECS and anesthesia on acquisition of the maze habit. Journal of Comparative and Psysiological Psychology 1957, 50, 300-306.
Leventhal H. Fear communications in the acceptance of preventive health practices. Bulletin of the New York Academy of Sciences 1965 41, 1144-68.
Levi L. Occuational stress: A psychophysiological overview. „Occupational Mental Health 1972, 2, 6-9.
Levingood R., Lowinger P., Schoof K. Heroin addiction in the suburbs: An epidemiologic study. Paper presented at the meeting of the American Public Health Association, 1971.
Levy S., Kennrad M. A study of electroencehalogram as related to personality structure in a group of inmates in a state penitentiary.  „American Journal of Psychiatry 1953, 109, 382-89.
Lewin K. Group decision and social change. In: T.M. Newcomb, E.L. Hartley (Eds.) Reading in social psychology. New York 1947, Holt, Reinhard and Winston.
Lewin K., Lippitt R., White R.K. Patterns of aggressive behavior in experimentally created social climates. Journal of Social Psychology 1939, 10, 271-99.
Lichtenstein E. How to quit smoking. Psychology Today 1971, 4(8), 42-45. 
Liddel H.S. The conditioned reflex. In: F.A. Moss (Ed.) Comparative psychology. New York 1934, Prentice-Hall.
Liddel H.S. Emotional hazards in animals and man. Springfield, III. 1956, Charles C. Thomas.
Lieberman M.A., Yalom I.D., Miles M.D. Encounter groups: First facts. New York 1973, Basic Books.
Lief H.I., Fox R.C. Trainving for detached concern in medical students.  In: H.I. Lief, V.F. Lief and N.R. Lief (Eds.) The psychological basis of medical practice. New York 1963, Harper and Row.
Lifton R.J. Existential evil. In: N. Sanford (Ed.) Sanctions for evil. 
San Francisco 1971, Jossey-Bass.
Lindauer M.S. Pleasant and unpleasant emotions in literature: A comparison with the affective tone of psychology. Journal of Psychology 1968, 70, 55-67.
Lindsay P.H., Norman D.A. Human information processing. New York 1972, Academic Press.
Linton H.B., Langs R.J. Empirical dimension of LSD-25 reactions. 
„Archives of General Psychiatry 1964, 10, 469-85.
Lipsitt L..P. Learning processes of human newbors. Merrill-Palmer Quarterly of Behavior and Development 1966, 12, 45-71.
Lipsitt L.P., Engen T., Kaye H. Development changes in the olfactory thereshold of the neonate. Child Development 1963, 34, 371-76.
Lockard J.S. Choice of a waring signal or no waring signal in a unavoidable shock situation. Journal of Comparative and Physiological Psychology 1963, 56, 526-30.
Logan F.A. Incentive. New Haven 1960, Yale University Press.
Logan F.A. Experimental psychology of animal learning and now. „American Psychologist Nov. 1972, 27(11), 1055-62.
Loo C.M. The effects of spatial density on the social behavior of children. Journal of Applied Social Psychology 1972, 2, 372-82.
Loomis A.L., Harvey E.N., Hobard G.A. Cerebral status during sleep as studied by human brain potentials. Journal of Experimental Psychology 1937, 21, 127-44.
Lorenz K. Der Kumpan in der Umvelt des Vogels. Der Atrgenosse als austosendes Moment sozialer Vorhaltungsweisen. Journal of Ornithology 1935, 83, 137-213.
Lorenz K. On aggression. New York 1966, Harcourt Brace Jovanovich.
Lovas O.I. Learning theory approach to the treatment of childhood schizophrenia. In: California Mental Health Research Symposium, No. 2.  Behavior theory and therapy. Sacramento, Calif, 1968, Dept. of Mental Hygiene.
Lowen A. A ractical guide to psychotherapy. New York 1968, Harper and Row.
Luce G.G. Current research on sleep and dreams. Public Health Service ublication No. 1389. Bethesda, Md. 1965, National Institutes of Health.
Luce G.G. Biological rhythms in psychiatry and medicine. Mental Health program Reports, No. 4. (PHS) Publication No. 2088. Chevy Chase, Md.: 1970, National Institute of Mental Health.
Luchins A.S. Mechanization on roblem solving - The effect of Einstellung. 
„Psychological Monographs 1942, 54 (6, Whole No, 248).
Luchins A.S. An aproach to evaluating the achievement of group psychotherapy. Journal of Social Psychology 1960, 52, 345-53.
Luchins A.S., Luchins E. H. Rigidity of behavior. Portland 1959, University of Oregon Press. 
Luckkhardt A.B., Carlson A.J. Contributions to the physiology of the stomach. XVII. On the chemical control of the gastric hunger contractions.  „American Journal of Physiology 1915, 36, 37-46.
Ludwi A.M. Altered states of consciousness. Archives of General Psychiatry 1966, 15, 225-34.
Lundin R.W. Personality: An experimental approach. New York 1961, Macmillan.
Luria (Łuria) A.R. The mind of a mnemonist. New York 1968, Basic Books.
Luria (Łuria) A.R. The functional organization of the brain. „Scientific American 1970, 222(3), 66-78.


Maccoby E.E., Jacklin C.N. The psychology of sex differences. Palo Alto, Calif. 1974, Stanford Univeristy Press.
MacKinnon D.W. The study of creativity and creativity in arctives. In: 
Conference on the creative person. Berkeley: University of California, Institute of personality Assessment and Research, 1961.
MacLean P.D. Contrasting functions of limbic and neocortical systems of the brain and their revelance to psychophysiological aspects of medicine.  „American Journal of Medicine 1958, 25, 611-26.
Magoun H.W. The ascending reticular system and wakeufulness. In: J.F.  Delafresnaye (Ed.) Brain mechanisms and consciousness, Oxford 1954, Blackwell.
Maher B.A.. Principles of psychopathology: An experimental approach. New York 1966, McGraw-Hill.
Maller O., Clark J.M., Kare M.R. Short-term caloric regulation in the adult opossum. Proceedings of the Society for Experimental Bilogy and Medicine 1965, 118, 275-77.
Mallick S.K., McCandless B.R. A study of catharis of aggression. „Journal of Personality and Social Psychology 1966, 4, 591-96.
Maltzman I. On the training of originality. Psychological Review 1960, 67, 229-42.
Magnes A.L., Helnyk P. Televised models of female achievement. „Journal of Applied Social Psychology 1974, 4, 365-374.
Manis M. An introduction to cognitive psychology. Belmont, Calif. 1971, Wadsworth.
Mann J., Starr S. Effects of erotic films on sexual behavior of married couples. Technical report of the Commission on Obscenity and Pornograhy Vol. 8. Washington, D.C.: U.S. Government Printing Office, 1971.
Mann T. Mario and the magician. In: H.T. Lowe-Porter (Trans.) Death in  Venice and seven other stories by Thomas Mann. New York 1957, Vintage Books.
Mansson H.H. Justifying the final solution. Omega 3(2), 1972, 79-87.
Maranon G. Contributin a letude de laction emotive de ladrenaline. 
„Revue Fr. Endocrinal 1924, 2, 301-25.
Margotta R. Nervous and mental diseases. In: . Lewis (Ed.) The story of medicine. New York 1967. Golden Press.
Mark V., Ervin F.R. Violence and the brain. New York 1970, Harper and Row.
Marks I.M., Gelder M.G. Transvetism and fetisism: Clinical and psychological changes during faradic aversion. British Journal of Psychiatry 1967, 113, 711-29.
Marks L.E., Miller G.A. The role of semantic and syntatic constraints in the memorization of English sentences. Journal of Verbal Learning and Verbal Behavior 1964, 3, 1-5.
Marler P. Acoustical influences in bird song development. The Rockefeller Univeristy Review Sept.8Oct. 1967, 8-13.
Marshall G. Affective consequences of inadequately explained physiological arousal. Unpublished doctoral dissertation, Stanford Univeristy, 1976.
Martindale D. Torment in the tower. Chicago April 1976, 96-101.
Masangkay Z.S., McCluskey K.A., McIntyre C.W., Sims-Knight 
J., Vaughn B.E., Flavell J.H. The development of inferences about the visual perceptions of others. Child Development 1974.
Maslach C. Social and personal bases of individuation. Journal of Personality and Social Psychology March 1974, 29(3), 411-25.
Maslach C., Maslach G., Zimbardo P.G. Hypnotic control of peripheral skin temperature: A case report. Psychophysiology 1972, 2, 600-605.
Maslach C., Zimbardo .G. Dehumanization in institutional settings. Paper presented at the American Psychological Association Convention, Montreal, Canada, 1973.
Maslow A.H. Motivation and personality. New York 1954, Harper and Row.
Maslow A.H. Psychological data and valute theory. In: A.H. Maslow (Ed.) 
New knowledge in human values. New York 1959, Harper and Row.
Masters R.E., Houston J. The varieties of psychedelic experience. New York 1966, Holt, Rinehart and Winston.
Masters W.H., Johnson V.E. Human sexual response. Boston 1966, Little, Brown.
Masters W.H., Johnson V.E. Human sexual inadequancy. Boston 1970, Little, Brown.
Masterton R.B., Berkley M.A. Brain functions: Changing ideas on the role of sensory, motor, and association cortex in behavior. In: P.H. Mussen, M.R.M. Rosenzweig (Eds.) Annual review of psychology, 1974. Vol. 25. Palo Alto, Calif, 1974. Annual Review.
Matson F.W. Humanistic theory: The third foul in psycholog. The Humanist March8April 1971, 7-11.
Mayer J. Overweight: Causes, cost and control. Englewood Clifts, N.J. 
1968, Prentice-Hall.
McClelland D.C. The achieving society. Princeton 1961, Van Nostrad.
McClelland D.C. Do I.Q. testes measure intelligence? Saturday Evening Post Summer 1972.
McConnell J. V. Memory transfer trought cannibalism in planaria. „Journal of Neuropsychiatry 1962, 3, 45.
McConnell J. V., Jacobson A. L., Kimble D. P. The effects of regeneration upon retention of a conditioned response in the planarian. „Journal of Comarative and Physiological Psychology 1959, 52, 1-5.
McConnell R. A. ESP curriculum guide. New York 1971, Simon and Schuster.
McGinnies E. Emotionality and perceptual defence. Psychological Review 1949, 56, 244-51.
McGinnies E., Sherman H. Generalization of perceptual defence. „Journal of Abnormal and Society Psychology 1952, 47, 81-85.
McGlashin T. H., Evans F. J., Orne M. T. The nature of hypnotic analgesic and placebo response to exerimental pain. Psychosomatic Medicine 1969, 31, 227-46.
McGlothlin W., Cohen S., McGlothlin M. S. Long lasting effects of LSD on normals. Archives of General Psychiatry 1967, 17, 521-32.
McGregor D. The human side of enterprise. New York 19600, McGraw-Hill.
McGuigan F. J. Electrical measurement of covert rocesses as an explication of higher mental events. In: J. McGuigan, R. A. Schoonover (Eds.) The psychophysiology of Thinking: Studies of covert processes. New York 1873, Academic Press.
McGuigan F. J., Keller B., Stanton E. Covert language responses during silent reading. Journal of Educational Psychology 1964, 55, 339-43.
McGuigan F. J., Schoonover R. A. The psychohysiology of thinking. New York 1973, Academic Press.
McGuigan F. J., Tanner R. G. Covert oral behavior during conversational and visual dreams. Psychonomic Science 1971, 23, 263-64.
McNeil D. Developmental psycholinguistic. In: F. Smith, G. A. Miller (Eds.) The genesis of language: A psycholinguistic approach. Cambridge, Mass. 1966, M. I. T. Press.
McNemar Q. The revision of the Stanford-Binet Scale. Boston 1942, Houghton Mifflin.
Mead M. Coming of age in Samoa. New York 1961, Morrow. (Originally published, 1938).
Meader B. D., Rogers C. R. Client-centered therapy. In: R. Corsini (Ed.) 
Current psychotherapies. Itasca, III. 1973, F. E. Peacock.
Meehl P. E. Clinical versus statistical prediction. Minneapolis 1954, Univeristy of Minneapolis Press.
Meehl P. E. Seer over sign: The first good example. Journal of Experimental Research in Personality 1965, 1, 27-32.
Megargee E. I. Undercontrolled and overcontrolled personality types in extreme antisocial aggression. Psychological Monographs 1966., 80 (Whole No. 611).
Mehrabian A. Significance of posture and position in the communication of attitude and status relationshis. Psychological Bulletin 1969, 71, 359-72.
Mehrabian A. Silent messages. Belmont, Calif. 1971 a, Wadsworth.
Mehrabian A. Verbal and noverbal interaction of strangers in a waiting situation. Journal of Experimental Research in Personality 1971 b, 5, 127-38.
Melzack R. How acupuncture works: A sophisticated Western theory takes the mystery out. sychology Today June 1973, 7, 28-37.
Melzack R., Scott T. H. The effects of early experience on the response to ain. Journal of Comparative and Physiological Psychology 1957, 50, 155-61.
Melzack R., Wall P. D. Pain mechanism: A new theory. Science 1965, 150, 971-79.
Mendel W. M. Effect of lenght of hositalization on rate and quality of remission from acute psychotic episodes. Journal of Nervous and Mental Diseses 1966, 143, 226-33.
Mendels J. Concepts of deression. New York 1970, Wiley.
Metzler J., Shepard R. N. Transformational studies of the internal representation of three-dimensional object. In: R. L. Solso (Ed.) Theories of cognitive sychology: The Loyola symposium. Potomac, Md. 1974, Lawrence Erlbaum Associates.
Meyer J. The case for a national commission on advertisting. In: S.  Divita (Ed.) Advertising in the Public Interest. Chicago 1974, American Marketing Association.
Meyer M. M., Ekstein R. The psychotic pursuit of reality. Journal of Contemporary Psychotherapy 1970, 3, 3-12.
Meyer P. M. Recovery from neocortical domage. In: G. M. French (Ed.) 
Cortical functioning in behavior. Glenview, III. 1973, Scott Foresman.
Meyer P. M., Horel J. A., Meyer D. R. Effects of DL Amphetamine upon placing responses in neodecorticate cats. Journal of Comparative and Physiological Psychology 1963, 56, 402-4.
Meyer W. U. Reported in: W. J. Arnold (Ed.) Nebraska symposium on motivation. Lincoln 1968, University of Nebraska Press.
Michelet J. Satanism and witchcraft: A study in medieval supersition. New York 1962, Citadel.
Middlebrook P. Social psychology and modern life. New York 1973, Knopf.
Milgram S. Issues in the study of obedience: A reply to Baumrind. 
„American Psychologist 1964, 19, 848-52.
Milgram S. Some conditions of obedience and disobedience to authority. 
„Human Relations 1965, 18(1), 57-76.
Milgram S. Obedience to authority. New York 1974, Harper and Row.
Miller G. A. The magical number seven plus or minus two: Some limits on our capacity for processing information. Psychological Review 1956, 63, 81-97.
Miller G. A. The psychology of communication: Seven essaysa. New York 1967, Basic Books.
Miller G. A. Psychology as a means of promoting human welfare, „American Psychologist Dec. 1969, 24(12), 1063-75.
Miller G. A., Galanter E., Pribram K. H. Plants and the structure of behavior. New York 1960, Holt, Rinehart and Winston.
Miller G. A., Isard S. Some ercetual cosequences of linguistic rules. 
„Journal of Verbal Learning and Verbal Behavior 1963, 2, 217-28.
Miller J. M., Sutton D., Pfingst B., Ryan A., Beaton R., 
Gourevitch G. Single call activity in the auditory cortex of Rhesus monkeys: Behavior dependency. Science 1972, 177, 449-51.
Miller N. E. The frustration-aggression hypothesis. Psychological Review 1941, 48, 337-42.
Miller N. E. Experimental studies of conflict. In: McV. Hunt (Ed.) 
Personality and the behavior disordes. Vol. 1. New York 1944, Ronald Press.
Miller N. E. Experiments on motivation. Science 1957, 126 1271-78.
Miller N. E. Learning of visceral and glandular responses. Science 1969, 163, 434-45.
Miller N. E. Applications of learning and biofeedback to psychiatry and medicine. In: A. M. Freedman, H. I. Kaplan, B. J. Sadock (Eds.) Comprehensive textbook of psychiatry. (2 nd ed.) Baltimore 1974, Williams and Wilkins.
Miller N. E., Di Cara L. V. Instrumental training of visceral functions. 
Mental Health Program Reports, No. 6. (DHEW) Publication No. (HSM) 73-9139. 
Chevy Chase, Md. 1973, National Institute of Mental Health.
Miller N. E., Di Cara L. V., Solomon H., Weiss J., Dworkin 
B. Learned modifications of autonomic functions: A review and some new data. Circulation Research 1970, 27, 3-11 (Supplement 1).
Miller W. Violent crime in city gangs. The American Academy of Political and Social Science March 1966.
Miller W. R., Ervin S. M. The development of grammar in child language. 
In: U. Bellugi-Klima, R. Brown (Eds.) The asquisition of language.  „Monographs of the Society for Research in Child Development 1964, 29(1), 9-13.
Milner B., Penfield W. The effect of hippocampal lesion on recent memory. 
„Transactions of the American Neurological Association 1955, 80, 42-48.
Mischel W. Personality and assessment. New York 1968, Wiley.
Mishkin M., Gorgays D. G. Word recognition as a funtion of retinal locus. 
„Journal of Experimental Psychology 1952, 43, 43-48.
Mogar R. E. Current status and fucture trends in psychodelic (LSD) research. In: C. Tart (Ed.) Altered states of consciounsess. New York 1969, Wiley.
Mohsin S. M. Effect of frustration on problem-solving behavior. „Journal of Abnormal and Social Psychology 1954, 49, 152-55.
Money J., Ehrhardt A. A. Man and woman, boy and girl. Baltimore 1972, Johns Hopkins Univeristy Press.
Moniz E. Prefrontal leucotomy in the treatment of mental disorders. 
„American Journal of Psychiatry 1973, 93, 1379-85.
Montgomery J., McBurney R. D. Operant conditioning token economy. Report of the Child Health and Human Develompment Center. Camarillo, Calif 1970.
Montor K. Brain-wave research. Naval Research Reviews April 1973, 7-11.
Morre B. R. The role of directed Pavlowian reactions in simle instrumental learning in the pigeon. In: R. A. Hind, J. S. Hinde (Eds.) Constrains on learning: Limitations and redispositions. London 1973, Academic Press.
Moore S. C. Editioral. Parachutist 1963, 4, 5-7.
Moos R. H. Concetualizations of human environments. American Psychologist 1973, 28, 652-65.
Morgan A. H. The heritability of hypnotic suscetibility in twins. 
„Journal of Abnormal Psychology 1973, 82, 55-61.
Mortiz A. P., Zamchen N. Sudden and unexpected deaths of young soldiers. 
„American Medical Association Archives of Pathology 1946, 42, 459-94.
Morland J. K. A comparisson race awarennes in northern and southern children. American Journal of Orthopsychiatry 1966, 36, 22-31.
Mosak H., Dreikers R. Adlerian psychotherapy. In: R. Corsini (Ed.) 
Current Psychotherapies. Itasca, III. 1973, F.E. Peacock.
Moscovici S., Lange E., Naffrechoux M. Influence of a consistent minority on the responses of a majority in a color perception task. „Sociometry 1969, 32, 365-80.
Mosher L. R., Feinsilver D. Special report on schizophrenia. Chevy Chase. 
Md. April 1970, National Institute of Mental Health.
Mosher L. R., Feinsilver D. Special report: Schizophrenia. Chevy Chase, Md. 1971, National Institute of Mental Health.
Moskowitz M. The big profits in tension relief. San Fransisco Chronicle Sept. 17, 1973.
Mowrer O. H. Learning theory and behavior. New York 1960, Wiley.
Mowrer O. H., Viek P. An experimental analogue of fear from a sense of helplessness. Journal of Abnormal and Social Psychology 1948, 43, 193-200.
Moyer K. E. Kinds of aggression and their psychological basis. 
„Communications in Behavior Biology 1968, 2, 65-87.
Munn N. L. The effect of the knowledge of the situation upon judgment of emotion from facial expressions. Journal of Abnormal and Social Psychology 1940 35, 324-38.
Munsterberg H. On the witness stand: Essays on psychology and crime. Newy York 1927, Clark Boardman. (Originally published: New York: Doubleday, 1908.)
Murray J. R., Minor M. J., Bradburn N. M., Cotterman R. F., 
Frandel M., Pisarski A. E. Evolution of public response to the energy crisis. Science 1974, 184,, 257-63.
Meyrson A. The attitude of neurologists, psychiatrists, and psychologists toward psychoanalysis. American Journal of Psychiatry 1939, 96, 623-41.


Nardini J. E. Survival factors in American prisoners of war of the Japanese. American Journal of Psychiatry 1952, 109, 241-47.
National Clearinghouse for Health Information Publication No. 5027, March 1970.
Neisser U. Cognitive psychology. New York 1967, Appleton-Century-Crofts.
Nelson K. Accomodation of visual-tracking patterns in human infants to object movement patterns. Unpublished doctoral dissertation, Yale University, 1970.
Newcomb T. M. Attitude development as a function of reference groups. In: 
E. E. Maccoby, T. M. Newcomb, E. L. Hartley (Eds.) Readings in social psychology. New York 1958, Holt, Rinehart and Winston.
Newcomb T. M. Persistence and regression of changed attitudes: Long-range studies. Journal of Social Issues 1963, 19, 3-14.
Newell A., Shaw J. C., Simon H. A. Elements of a theory of human problem solving. Psychological Review 1958, 65, 151-66.
Newell A., Shaw J. C., Simon H. A. Report on a general problem-solving program. In: Proceedings of the International Conference on Information Processing Paris 1960, UNESCO.Newsweek Quote from Drinking Like a ig from „Newsweek July 30, 1973. Coyright Newsweek, Inc. 1973, reprinted by permission.
Nichols R. C. The National Merit twin study. In: S. G. Vandenberg (Ed.) Methods and goals in human behavior genetics. New York 1965, Academic Press.
Niebuhr R. In: F. S. Mead (Ed.) The encyclopedia of religious quotations. 
Westwood, N. J. 1965, Fleming H. Revell Co.
Nievergeld J., Farrar J. C. What machines can and cannot do „American Scientist 1973, 61, 309-15.
Nisbett R. E. Hunger, obeisty, and the ventromedial hypothalamus. 
„Psychological Review 1972, 79, 433-53.
Nisbett R. R., Schachter S. The cognitive maniulation of pain. „Journal of Experimental Social Psychology 1966, 2, 227-36.
Nissen H. W., Chow K. L., Semmes J. Effects of restricted opportunity for tactual, kinesthetic, and manipulative experience on the behavior of a chimpanzee. American Journal of Psychology 1951, 64, 485-507.
Nizer L. My life in court. New York 1961, Pyramid.
Nyswander M. The drug addict as a patient. New York 1965, Grune and Stratton.


OConnell D. N., Shore R. E., Orne M. T. Hypnotic age regression: An empirical and methodological analysis. Journal of Abnormal Psychology 1970, 76, 32.
OConnor R. D. Modiification of social withdrawal trought symbolic modeling. Journal of Aplied Behavioral Analysis 1969, 2, 15-22.
Olcott R. C. Personal correspondence to the author in letter dated Jan. 
15, 1974, from speech delivered to Toastmasters Club, Just a Spoonful. 
Excerpt reprinted by permission of the author.
Olds J. Commentary on positive reinforcement produced by electrical stimulations of septal areas and other regions of rat brain. In: E. S.  Valenstein (Ed.) Brain stimulation and motivation: Research and commentary. 
Glenview, III. 1973, Scott, Foresman. 
Olds J., Milner P. Positive reinforcement produced by electrical stimulation of septal area and other regions of the rat brain. Journal of Comarative and Physiological Psychology 1954, 47 419-27.
OLeary K. D., Kaufman K. F., Kass R. E., Drabran R. S. The effects of loud and soft reprimands on the behavior of discrutive students.  „Exeptional Children 1970, 37, 145-55.
Oppenheimer R. Analogy in science. American Psychologist 1956, 11, 126-35.
Opton N. Lessonsy of My Lai. In: R. Buckhout (Ed.) Toward social change. 
New York 1971, Haper and Row.
Orlando N. J. The mock ward: A study in simulation. In: O Milton, R. G.  Wahler (Eds.) Behavior disordes: Perspectives and trends. Philadelhia 1973, Lippincott.
Orne M. T. Mechanisms of post-hypnotic amnestia. International Journal of Clinical and Experimental Hypnosis 1966, 14, 121-34.
Orne M. T. Hypnosis, motivation and the ecological validity of the psychological experiment. In: W. J. Arnold, M. M. Page (Eds.) Nebraska symposium on motivation. Lincoln 1970, Univeristy of Nebraska Press.
Orne M. T., Hammer A. G. Hypnosis. Encyclopaedia Britannica Chicago 1974, William Benton.
Ornstein R. E. The psychology of consciousness. San Francisco 1972, Freeman.
Osborn A. F. Applied imagination: Principles and procedures of creative thinking. (2nd ed.) New York 1957, Scribners.
Osborn D. K., Endsley R. C. Emotional reactions of young children to TV violence. Child Development 1971, 42, 321-31.
Osgood C. Method and theory in experimental psychology. New York, 1953, Oxford University Press.
Osler S. F., Fivel M. W. Concept attainment. I. The role of age and intelligence in concept attainment by induction. Journal of Experimental Psychology 1961, 62,, 1-8.
Osmond H., Smythies J. Schizophrenia: New approach. Journal of Mental Science 1952, 98, 300-315.
Ostwald P. F., Peltzman . The cry the human infant. Scientific American 1974, 230, 84-90.
Overmier J. B., Seligman M. E. Effect ofinescapable shock upon subsequent escape and avoidance responding. Journal of Comparative and Physiological Psychology 1967, 63(1), 28-33.


Pahnke W. N. Drugs and mysticism: An analysis of the relationship between psychedelic drugs and mystical consciousness. Unpublished doctoral dissertation, Harvard University, 1963.
Pahnke W. N. LSD, and religious experience. In: R. C. DeBold, R. C. Leaf (Eds.) LSD, man and society. Middletown, Conn, 1967, Wesleyan University Press.
Parke R. D., Berkowitz L., Leysens J., West S., Sebastian R. The effects of repeated exposure to movie violence on aggressive behavior in juvenile delinquent boys: A field experimental approach. Unpublished manuscript, University od Wisconsin, 1972.
arke R. D., Walters R. H. Some factors influencing the efficacy of punishemnt training for inducing response inhibition. Monographs of the Society for Research in Child Development 1967, 32(1, Whole No. 109).
Parkes A. S., Bruce H.M. Olfactory stimuli in mammalian reproduction.  Odor excites neurohumoral responses affecting olstrus, pseudopregnancy and pregnancy in the mouse. Science 1961, 134, 1049-54.
Paul G. L. Ouctome of systematic desensitization. II. Controlled investigation of indyvidual treatment technique variations, and current status. In: C. M. Franks (Ed.) Behavior theray: Appraisal and status. New York 1969, McGraw-Hill.
Pearson K., Moul M. The problem of alien immigration into Great Britain, illustrated by an examination of Russian and Polish Jewish children.  „Annals of Eugenics 1925, 1, 50127.
Pelletier K. R. Neurological psychophysical, and clinical differentation of the aplha and theta altered states of consciousness. Unpublished doctoral dissertation, University of California, Berkeley, 1974.
Penfield W. The excitable cortex in conscious man. Liverpool 1958, Liverpool Univeristy Press.
Penfield W., Baldwin M. Temporal lobe sezuires and the technique of subtotal temporal lobectomy. Annals of Surgery 1952, 136, 625-34.
Penick S., Smith G., Wienske K., Hinkle L. An experimental evaluation of the relationship between hunger and gastric motility. „American Journal of Psychology 1963, 205, 421-26.
Peterson G, B., Ackil J. E., Frommer G. P., Hearst E. S. Conditioned approach and contact behavior toward signals for food or brain-stimulation reinforcement. Science 1972, 177, 1009-11.
Pfungst O. Clever Hans (thehosrse of Mr. Von Osten).R. Rosenhtal (Trans.) New York 1911, Holt, Rinehardt and Wnston. Copyright © 1865 by Holt, Rinehart and Winston. Excerpt reprinted by permission of Holt, Rinehart and Winston Inc.
Phares E. J. Locus of control in personality. Moristwn, N. J. 1976, Genereal Learning Press.
Piaget J. Genetic epistemology. New York 1970, Columbia University Press.
Pick H. L., Warren D.H., Hay J. Sensory conflict in judgments of spatial direction. Perception and Psychophysis 1969, 6(4), 203-95.
Pirrel R., Sherman J. G. Train your pet the Branabus way. Brown Alumni Monthly Feb. 1963, 8-14.
Piliavan I. M., Rodin J., Piliavan J. A. Good Samaritanism: An underground phenomen? Journal of Personality and Social Psychology 1969, 13, 189-300.
Piliavan J. A., Piliavan I. M. Effect of blood on reaction to a victim. 
„Journal of Personality and Social Psychology 1972, 23, 353-61.
Pinkerton J. (Ed.) A general collection of the best and most interesting voages and travels in all parts of the word. London 1808-14, Longman, Hurst, Rees and Orne.
Pitts F. N. The biochemistry of anxiety. Scientific American 1969, 220, 69-75.
Pllat J. Social traps. American Psychologist 1973, 28, 641-51.Playboy 1969, 16(2), 46.
Posner E. G. The effect of therapists traing on grou therapeutic outcome. Journal of Consulting Psychology 1966, 30, 283-89.
Postman L., R. Retention as a function of the method of measurement. 
„University of California Publications in Psychology 1957, 8(3).
Potter V. R. Bioethits: Bridge to the future. Englewood Cliffs, N. J. 
1971, Prentice-Hall.
Powledge T. M. The new ghetto hustle. Saturday Review of the Sciences Jan. 27, 1973, 1(1).
Premack D. A functional analysis of language. Paper presented at the meeting of the American Psychological Association, Washington, D. C., 1969.
Premack D. The education of Sarah. Psychology Today 1970, 4(4), 54-58.
Pribram K. H. A review of theory in psychological psychology. „American   Review of Psychology 1960, 11, 1-40.
Pribram K. H. Emotion: Steps toward a newurophysiological theory. In: D.  C. Glass (Ed.) Neurophysiology and emotion. New York 1967, Rockefeller University Press.
Pribram K. H. Languages of the brain: Experimental paradoxes and principles in neuropsychology. Englewood Cliffs, N. J. 1971, Prentice-Hall.
Price C. R. New directions in the work. Kalazamoo, Mich. March 1972, UpJohn Institute for Exployment Research.
Price-Williams D. R. A study concerning concepts of conservation of quantities among primitive children. Acta Psychologica 1961, 18, 297-305.
Price-Williams D. R., Gordon W., Ramirez M. Skill and conservation. 
„Development Psychology 1969, 1, 769.
Prien R. F., Caffey E. M., Klett C. J. Pharmacotherapy in chronic schizophrenia. Washington, D. C. May 1973, Dept. of Medicine     and Surgery, Veterans Administration.
Piern R. F., Levine J., Switalski R. W. Discontinuation of chemotherapy for chronic schizophrenics. Hospital and Community Psychiatry 1971, 22, 20.
Prytulak L. S. Natural language mediation. Cognitive Psychology 1971, 2, 1-56.
Rahe R. H. The pathway between subjects recent life changes and their near-future illnes reports: reresentative results and methodological issues. In: B. S. Dohrenwend, B. P. Dohrenwend (Eds.) Stressful life events: their nature and effects. New York 1974, Wiley.
Rahe R. H., Holmes T. H. Life crisis and major health change. 
„Psychosomatic Medicine 1966, 28, 774.
Rand C., Wapner S. Postural status as a factor in memory. Journal of Vernbal Learning Behavior 1967, 6, 268-71.
Rand Corporation A million random digist with 100 000 normal deviates. 
New York 1955, The Free Press.
Rapaport M., Silverman J. A sensor for schizophrenics. Behavior Today 1970, 1(21) 1.
Raush H. L., Raush C. l. The halfway house movement: A search for sanity. 
New York 1968, Appleton-Century-Crofts.
Rawlings W. Reactive guilt and anticipatory guilt in altruistic behavior.  In: J. Macauley, L. Berkowitz (Eds.) Altruism and helping behavior: Social psychological studies of some antecedents and consequences. New York 1970, Academic Press.
Razran G. Introductory remarks. In: N. S. Klinic (Ed.) Pavlovian conference in higher nervous activity. Annals of the New York Academy of Sciences 1961, 92, 816-17.
Rechtschaffen A., Kales A. (Eds.) A manual of standardized terminology, techniques and scoring system for sleep stages of human subjects.  Publication No. 204. Bethesda, Md. 1968, National Institutes of Health.
Regan D., Williams M., Sparling S. Voluntary exiation of guilt: A field experiment. Journal of Personality and Social Psychology 1972, 24, 42-45.
Reisman D., Glazer N., Denney R. The lonely crowd: A study of the changig American character. New Haven 1950, Yale Unieversity Press.
Reitman J. S. Mechanisms of forgetting in short-term memory. „Cognitive Psychology 1971, 2, 185-95.
Reitman W. R. Cognition and trought. New York 1965, Wiley.
Reuben D. Letter to Dr. David Reuben. San Francisco 
Examiner8Chronicle Dec. 16, 1973. Copyright 1973 Chicago Tribune-New York News Syndicate, Inc. Excerpt reprinted by permission.
Reynolds G. S. The effect of stress upon problem solving. Journal of General Psychology 1960, 62, 83-88.
Rheingold H. L., Gewirtz J. L., Ross H. Social conditioning of vocalization in the infant. Journal of Compparative and Physiological Psychology 1959, 52, 68-73.
Rhine J. B. New world of the mind. London 1954, Faber and Faber.
Ribble M. A. Infantile experience in relation to personality development.  In: J. McV, Hunt (Eds) Personality and the behavior disordes. New York 1944, Ronald Press.
Richards W., Grof S., Goodman L., Kurland A. LSD-assisted psychotherapy and the human encounter with death. Journal of Transpersonal Psychology 1972, 4, 121-50.
Richter C. P. The self-selection of diets. In: Essays in biology Berkley 1943, University of California Press.
Richter C. P. On the phenomenon of sudden death in animals and man. 
„Psychosomatic Medicine 1957, 19, 191-98.
Rickles K. Non-specific factors in drug therapy of neurotic patients. In: 
K. Rickles (Ed.) Non-specific factors in drug therapy. Springfield, III. 
1968, Charles C Thomas.
Riesen A. H. Arrested vision. Sciencific American 1950, 183(1), 16-19.
Riesen A. H. Stimulations as a requirement for growth and function in behavioral development. In: D. W. Fiske, S. R. Maddi (Eds.) Functions of varied experience. Homewood, III. 1961, Dors ey.
Rivlin A. M. Social experiments: Promise and problems. Science January 1974, 183(4120), 35.
Robertson J. Uncontainable joy. In: R. Metzner (Ed.) The ecstatic adventure. New York 1968, Macmillan.
Robinson M. F., Freeman W. J. Psychosurgery and the self. New York 1955, Grune and Stratton.
Roffwarg H. P., Muzi J. N., Dement W. C. Ontogenetic development of the human sleep-dream cycle. Science April 1966, 152(29).
Rogers C. R. Significant asects of client-centered therapy. American Psychologist 1946, 1, 415-22.
Rogers C. R. The case of Mary Jane Tolden. In: W. U. Snyder (Ed.) 
Casebook of non-directive counseling. Boston 1947, Houghton Mifflin. 
Copyright 1947 by Hought Mifflin Company. Excert reprinted by permission. 
Rogers C. R. On becoming a person: A therapists view of psychotherapy. 
Boston 1961, Houghton Mifflin.
Rohrer J. H., Baron S. H., Hoffman E. L., Swander D. V. The stability of autokinetic judgments. Journal of Abnormal Psychology 1954, 49, 595-97.
Rorvik D. M. Jack Schwartz feel no pain. Esquire December 1972, 209-64.
Rosenhan D. Some origins of concert for others. In: P. H. Mussen, J. 
Langer, M. Covington (Eds.) Trends and issues in developmental psychology. 
New York 1969, Holt, Rinehart and Winston.
Rosenhan D. L. On being sane in insance placers. Science 1973, 179, 250-58.
Rosenzweig M. R., Bennet E. L., Diamond D. C., Wu Su-Yu, 
Slagle R. W., Saffran E. Influence of environmental complexity and visual stimulation on develoment of occipital cortex in rats. Brain Research 1969, 14, 427-45.
Ross L., Bierbrauer G., Polly S. Attributin of educational outcomes by professional and non-professional instructors. Journal of Personality and Social Psychology 1974, 29, 609-618.
Ross L., Lepper M. R., Hubbard M. Persevernace in self-percetion and social perception: Biased attributional instructors. Journal of Personality and Social Psychology 1975, 32, 880-892.
Ross L., Rodin J., Zimbardo .G. Toward an attribution therapy. The reduction of fear trought inducet cognitive-emotional misattribution.  „Journal of Personality and Social Psychology 1969, 12, 279-88.
Rothblat L., Pribram K. H. Selective attention: Input filter or responses selection? Brain Research 1972, 39, 427-36.
Rothman D. J. The discovery of the asylum: Social order and disorder in the new republic. Boston 1971, Little, Brown.
Rothman M. A. Response to McConnell. American Psychologist 1970, 25, 280-81.
Rotter J. B. Social learning and clinical psychology. New York 1954, Prentice-Hall.
Rotter J. B. Generalized expectancies for internal versus external controls of reinforcement. Psychological Monograhs 1966, 80 (1, Whole No.  609).
Rotter J. B. External control and internal control. Psychology Today 1971, 5(1), 37-42, 58-59.
Rouse L., Reilly S. Proposal for continued develoment of a treatment program for chronic patients. Unpublished mimeo report. Veterans Hospital, Palo Alto, Calif. 1974.
Routh D. K. Conditioning of vocal response differentation in infants. 
„Journal of Development Psychology 1969, 1, 219-26.
Rozin P. Specific hunger for thiamine: Recovery from defiency and thiamine preference. Journal of Comparative and Physiological Psychology 1965, 59, 98-101.
Rozin P., Kalat J. Adaptive specialization in learning and memory.  Salience: A factor which can override temporal contiguity in taste-aversion learning. Journal of Comparative and Physiological Psychology 1970, 7(2), 192-97.
Rubel A. J. Across the tracks: Mexican-Americans in a Texas city. Austin 1966, University of Texas.
Rubin E. Figure and ground. In: D.C. Beardslee, Wertheimer (Eds.) Readings in perception. Princeton 1958, Van Nostrand. (Originally published, 1921).
Rubin J. Do it.: A revolutionary menifesto. New York 1970, Simon and Shuster. Copyright © 1970 by the Social Education Foundation. Excerpt reprinted by permission of Simon and Schuster, Inc., and Jonathan Cape Ltd.
Rubin R. T., Miller R. G., Arthur R. J., Clark B. R. Differential adrenocortical stress responses in naval aviators during aircraft landing ractice. Navy Medical Neuropsychiatric Research Unit Report No. 12. San Diego, Calif. 1969.
Rubin Z. Measurement of romantic love. Journal of Personality and Social Psychology 1970, 16, 265-73.
Rubin Z. Liking and loving. New York 1973, Holt, Rinehart and Winston.
Ruma S. J. Easier said than done... Paper presented at the Conference on Applications of Social Psychology, Majorca, April 1973.
Rumbaugh D. M., Gill T. V., von Glasersfeld E. C. Reading and sentence completion by a chimpanzee. Science 1973, 182, 731-33.
Russel B. Human knowledge: Its scope and limits. New York 1948, Simon and Schuster.
Rustin S. L. Therapist authenticity in group and individual psychotherapy with college students. Journal of Contemporary Psychology 1970, 3, 45-50.
Ryan W. Blaming the victim. New York 1971, Pantheon.

Saario T. N., Jacklin C. N.,Tittle C. K. Sex role stereotyping in the public schools. Harvard Educational Review 1973, 43, 386-416.
Sacerdote P. Hypnosis in cancer patients. American Journal of Clinical Hypnosis 1966, 9, 100-108.
Sachs J. S. Recognition memory for syntactic and semantic aspects of connected discourse. Perception and Psychophysics 1967, 2(9), 441.San Francisco Chronicle Excerpt from The Hangroups of Bored Animals by Michael Grieg from San Francisco Chronicle Friday, Nov. 2, 1973. © 1973, Chronicle Publishing Co. Reprinted by persmission.
Sarbin T. R. O the futility of the proposition that some people be labeled mentally ill. Journal of Consulting Psychology 1967, 31, 445-53.
Sarnoff I. Psychoanalytic theory and social attitudes. Public Opinion Quarterly 1960, 24, 251-79.
Sarnoff I. Society with tears. New York 1966, Citadel.
Sartre J. P. Existentialism and human emotions. New York 1957, Philosophical Library.
Sawyer J. Measurement and prediction, clinical and statistical. 
„Psychological Bulletin 1966, 66, 178-200.
Schachter S. The psychology of affiliation. Stanford 1959, Stanford Univeristy Press.
Schachter S., Freedman J. Effects of work and cue prominence. In: S.  Schachter, J. Rodin (Eds.) Obese humans and rats. Potomac, Md. 1974, Erlbaum Associates.
Schachter S., Singer J. Cognitive, social and physiological determinants of emotional state. Psychological Review 1962, 69, 379-99.
Schein E. H. Reaction patterns to severe, chronic stress in American Army prisoners of war of the Chinese. Journal of Social Issues 1957 13(3), 21-30.
Schein E. H., Schneier I., Barker C. H. Coercive persuasions: A socio-psychological analysis of the brainwashing of America civilian prisoners by the Chinese Communists. New York 1961, Norton.
Schein M. W., Hale E. B. Stimuli elicting sexual behavior. In: F. Beach (Ed.) Sex and behavior. New York  1965, Wiley.
Schildkrau J. J., Kety S. S. Biogenic amines and emotion. Science 1967, 156, 21-30.
Schlosberg H. The description on facial expressions in terms of two dimensions. Journal of Experimental Psychology 1952, 44, 229-37.
Schlosber H. Three dimensions of emotion. Psychological Review 1954, 61, 81-88.
Schoen E. Lawrence Halprin: Humanizing the city environment. The America Way Nov. 1972, 13-23.
Schutz F. Differences between, the imprinting of the following and sexual reactions in mallards. Paper presented at the meeting of the XIXth International Congress of Psychology, London, 1969.
Schwartz C. G. Perspectives on deviance: Wives definitions of their husbands mental illnes. Psychiatry 1957, 20, 275-91.
Schwartz G. E. The facts on transcendental mediations: Part II. TM relaxes some people and makes them feel good. Psychology Today April 1974, 7, 39-44.
Scott J. P. Aggression. Chicago 1958, University of Chicago Press.
Scott R. A. A proposed framework analyzing deviance as a property of social order. In: R. A. Scott, J. D. Douglas (Eds.) Theoretical perspectives on deviance. New York 1972, Basic Books.
Scott W. A. Research of mental health and mental illnes. „Psychological Bulletin 1958, 55, 29-45.
Sears R. R. Relation  of early socialization experiences to aggresion in middle childhood. Journal of Abnormal and Social Psychology 1961, 63, 466-92.
Sears R. R., Maccoby E. E., Levin H. Patterns of child rearing. New York 1957, Harper and Row.
Seeman M., Evans J. W. Alienation and learning in a hosital setting. 
„American Sociological Review 1962, 27, 772-83.
Segall M. H., Campbell D. T., Herskowitz M. J. The influence of culture on perception. New York 1966, Bobbs-Merrill.
Seiden L. S. Neurochemical basis of drug action: Introduction, In: J. A.  Harvey (Ed.) Behavioral analysis of drug action. Glenview, III. 1970, Scott, Foresman.
Sekuler R., Tynan P., Levinson E. Visual temporal order: A new illusion. 
„Science 1973, 180, 210-12.
Seligman M. E. P. Chronic fear produced by unpredictable eletric shock. 
„Journal of Comarative and Physiological Psychology 1968, 66, 402-11.
Seligman  M. E. P. Fall into helplessness. Psychology Today June 1973, 7(1), 43-48.
Seligman M. E. P. Depression and learned helplessness. In: R. J.  Friedman, M. M Katz (Eds.) The psychology of depression: Contemporary theory and research. Washington, D. C. 1974, V. H. Winston and Sons.
Seligman M. E. P. Helplessness: On depression, development and death. San Francisco 1975, W. H. Freeman.
Seligman M. E. P., Maier S. F. Failure to escape traumatic shock. 
„Journal of Exerimental Psychology 1967, 74(1), 1-9.
Selye H. The stress of life. New York 1956, McGraw-Hill.
Selye H. The evolution of the tress concept. American Scientist 1973, 61, 692-99.
Semmes J. Protopathic and empiric sensation: A reppraisal. In: A. L.  Benton (Ed.) Contribution to clinical neuropsychology. Chicago 1969, Aldine.
Senden M. Raum-und Gestaltauffassung bei operierten Blindge-borenen vor und nach der Operation. Leipzig 1932, Barth. Cited in: D. O. Hebb The organization of behavior. New York 1949, Wiley.
Shapiro J. L., Diamond M. J. Increases in hypnotizability as a function of encounter group training. Journal of Abnormal Psychology 1972, 79(1), 112-15.
Sheffield F. D., Campbell B. A. The role of experience in the „spontaneus activity  of hungry rats. Journal of Comparative and Physiological Psychology 1954, 47, 97-100.
Shepard R. N., Feng C. A chronometric study of three-dimensinal objects. 
„Science 1971, 171, 701-3.
Sheridan C. L., King R. G. Obedience to authority with an authentic victim. Proceedings of the 80th Annual Convention American Psychological Assocation, Part 1, 1972, 7, 165-66.
Sherif M. A study of some social factors in perception. Archives of Psychology 1935, 27(187). 
Sherif M., Sherif C. W. An outline of social psychology. (2nd ed.) New York 1956, Harper and Row.
Sherman J. A. Reinstatement of verbal behavior in a psychotic by reinforcement methods. Journal of Speech and Hearing Disorders 1963, 28, 398-401.
Shettlesworth S. J. Constraints on learning. In: D. S. Lehrman, R. A.  Hinde, E. Shaw (Eds.) Advances in the study of behavior. Vol. 4. New York 1972, Academic Press.
Shields J. Monozygotic twins brought up appart or brought up together. 
London 1962, Oxford University Press.
Shockley W. Dysgenics, geneticity, receology: A challenge to the intellectual responsibility of educators. Phi Delta Kappan Jan. 1972, 297-307.
Shockley W. The nature of heritability of IQ and it social, economic, and olitical imlications. Predebate band-out for Stanford Psychology Department Colloquim Jan. 23, 1973.
Shor R. The fundamental problem in hypnoses research as viewed from historic prespectives. In: E. Fromm, R. Shor (Eds.) Hypnosis: Research development and perspectives. Chicago 1972, ALdine.
Shulgin A. Psychotomimetic agents related to the  research catecholamines „Journal od sychedelic Drugs Fall 1969, 2, 17-29.
Sidman M., Stoddard L. T. Programming percetion and learning for retarded children. In: N. R. Ellis (Ed.) International review of research on mental retardation. Vol. 2. New York 1969, Academic Press.
Sigusch V., Schmidt G., Reinfeld A., Wiedemann-Sutor I. Psychological stimulation: Sex differences. Journal of Sex Research 1970, 6, 10-24.
Silver L. B., Dublin C. C. Lourie R. S. Does violence breed violence?  Contributions from a study of the child abuse syndrome. American Journal of Psychiatry 1969, 126, 404-7.
Simmel E. C., Hoppe R. A., Milton G. A. (Eds.) Social faciliation and imitative behavior. Boston 1968, Allyn and Bacon.
Simon H. A. Motivational and emotional controls of cognition. 
„Psychological Review 1967, 74, 29-39.
Simpson M. E., Evans H. M. Occurence of faint bleeding on a definite intermenstrual day in man. Science Vol. 68. New York 1928, The Science Press.
Sims J. H., Baumann D. D. The tornado threat: Coping styles of the north and south. Science 1972, 176, 1386-91.
Singh D., Sikes S. Role of past experience on food-motivated behavior of obese humans. Journal of Comparative and Physiological Psychology 1974, 83, 503-508.
Skinner B. F. Walden II. New York 1948, Macmillan.
Skinner B. F. Verbal behavior. New York 1957, Appleton-Century-Crofts.
Skinner B. F. Pigeons in a pelican. American Psychologist 1960, 15, 28-37.
Skinner B. F. Teaching machines. Scientific American 1961, 205(5), 90-102.
Skinner B. F. What is the experimental analysis of behavior? Journal of the Experimental Analysis of Behavior? 1966, 9, 213-18.
Skinner B. F. Beyond freedom and dignity. New York 1971, Knopf.
Skinner B. F., Solomon H. C., Lindsley O. R. A new method for the experimental analysis of the behavior of psychotic patients. Journal of Nervous and Mental Diseases 1954, 120, 403-6.
Slater P. E., Morimoto K., Hyde R. W. The effects of group administration upon symptom formation under LSD. Journal of Nervous and Mental Diseases 1957, 125, 312-15.
Slobin D. I. Psycholinguistics. Glenview, III. 1971, Scott, Foresman.
Smelser N. J. Some determinants of destructive behavior. In: N. Sanford (Ed.) Sanctions for evil. San Francisco 1971, Jossey-Bass.
Smith D. E. Drugs use and abouse. In: F. L. Ruch, P. G. Zimbardo psychology and life. (8th Ed.) Glenview, III. 1971, Scott, Foresman.  Excerpt reprinted by permission of the author.
Smith D. E., Gay G. R. Editors note. Journal od Psychedelic Drugs Fall 
1971, 4(2), 5-14
Smith D. E., King M. B., Hoebel B. C. Lateral hypothalamic control of killing: Evidence for a cholinoceptive mechanism. Science 1970, 167, 900-901.
Smith D. E., Mehl C. An analysis of marijuana toxicity. In: D. E. Smith (Ed.) The new social drug: Cultural, medical and legal perspectives on marijuana. Englewood Cliffs, N.J. 1970, Prentice-Hall. © 1970, p. 71. 
Excerpt reprinted by permission of Prentice-Hall, Inc., Englewood Cliffs, 
N. J.

Smith K. V. Delayed sensory feedback and behavior. Philadelphia 1962, Saunders.
Smith M. B. Review of authoritarian personality. In: T. W. Adorno, E.  Frenkel-Brunswik, D. L. Levision, R. N. Sanford (Eds.) Journal of Abnormal and Social Psychology 1950, 45, 775-79.
Snow C. P. Either-or. Progressive 1961, 25(2), 24-25.
Sobey F. The nonprofessional revolution in mental health. New York 1970, Columbia University.
Sokolov (Sokołow) E.N. Neuronal models and the orienting reflex. In: M.  A. Brazier (Ed.) The central nervous system and behavior. New York 1960, Josiah University.
Solley C.M., Haigh G.A. A note to Santa Claus. Troical research papers, The Menninger Foundation 1957, 18, 4-5.
Solomans G. Drug therapy: Initation and follow-u. Annals: New York Academy of Sciences 1973, 205, 335-44.
Solomon R.L. Punishment. American Psychologist 1964, 19, 239-53.
Solomon R.L., Kamin L., Wynne L.C. Traumatic avoidance learning The outcome of several extinction procedures with dogs. Journal of Abnormal Social Psychology 1953, 48, 291-302.
Solomon R.W., Wheeler R.G. Peer reinforcement control of classroom problem behavior. Journal of Applied Behavior Analysis 1973, 6, 49-56.
Sontag L.W., Baker C.T., Nelson V.L. Mental growth and personality develoment: A longitudinal study. Monographs of the Society for Research in Child Development 1958, 23(2), 11-85.
Spanner F.E. The psychotherapy as an activist in social change: A proponent. In: F.E. Korten, S.W. Cook, J.L. Lancey (Eds.) Psychology and the problems of society. Washingtoin, D.C. 1970, American Psychological Association.
Spears W.C. Assessment of visual preference and discrimination in the four-month-old infant. Journal of Comarative and Physiological Psychology 1964, 57, 381-86.
Speisman J.C., Lazarus R.S., Mordkof A.M., Davison L.A. The experimental reduction of stress based on ego-defence theory. Journal of Abnormal and Social Psychology 1964, 68, 367-80.
Spence K.W. Behavior theory and conditioning. New Haven 1956, Yale University Press.
Sperry R.W. Restoriation of vision after crossing of optical nerves and after contralateral transposition of the eye. Journal of Neurophysiology 1945, 8, 15-28.
Sperry R.W. Mental unity following surgical disconnection of the cerebral hemispheres. The Harvey Lectures, Series 62. New York 1968 Academic Press.
Sperry R.W., Gassaninga M.S., Bogen J.E. Interhemispheric relationships: 
The neocortical commissures - syndromes of heispheric disconnection. 
Handbook of clinical neurology. Vol. 4. New York 1969, Wiley.
Spitz R.A., Wolf K. Anaclitic depression. Psychoanalytical Study of Children 1946, 2, 313-42.
Stace W. (Ed.) The teachings of the mystics. New York 1960, New American Library.
Stampfl T.G., Levis D.J. Essentials of imlosive therapy: A learning theory-based psychodynamic behavioral therapy. Journal of Abnormal Psychology 1967, 72, 496-503.
Stayton S.E., Weiner M. Value, magnitude, and accentuation. Journal of Abnormal and Sociecy Psychology 1961, 62, 145-47.
Sterman M.B. Learning to control brain functions trought biological feedback techniques. Reported by G. Luce, Mental Health Program Reports, No. 5. (DHEW) Publication No. (HSM) 72-9042. Chevy-Chase, Md. 1971, National Institute of Mental Health.
Sternbach R.A. ain: A psychophysiological analysis. New York 1968, Academic Press.
Sternbach R.A., Tursky B. Ethnic differences among housewives in psychophysical and skin potential responses to electric shock.  „Psychophysiology 1965, 1, 241-46.
Stevens S.S. Psychophysics and social scaling. Morristown, N.J. 1972, General Learning Press.
Stevenson H., Stewart E. A development study of racial awareness in young children. Child Develompent, 1966” 61, 37-75.
Stogdill R.M. Personality factors associated with leadership: A survey of the literature. Journal of Psychology 1948, 25, 35-71.
Stone C.P., Bathtiari A.B. Effects of electrocovulsive shock on maze relearning by albino rats. Journal of Comaparative and Physiological Psychology 1956, 49, 318-20.
Stoppard T. Rosencrantz and Guildenstern are dead. London 1967, Faber.
Strayer J., Bigelow A., Ames E.W. I, you, and point of view. 
Unpublished study, Simon Fraser University, 1973.
Strickland L. Surveillance and trust. Journal of Personality 1958, 26, 200-215.
Stromeyer C.F., Psotka J. The detailed texture of eidetic images. 
„Nature 1970, 225, 346-49.
Stuart R.B. Trick or treatment: How and why psychotherapy fails. 
Champaign, III. 1970, Research Press.
Stunkard A. New therapies for the eating disordes behavior modification of obeisty and anorexia nervosa. Archives of General Psychology May 1972, 26(5), 391-98.
Stunkard A., Koch C. The interpretation of gastric motility: Apparent bias in the report of hunger by obese persons. Archives of General Psychology 1964, 11, 74-82.
Suffolk P. The Eyewitness. From A Big Bowl of Punch, 1964, Simon and Schuster. © Punch London. Poem reprinted by permission of Rothco Cartoons, Inc.
Sullivan H.S. The interpersonal theory of psychiatry. New York 1953, Norton.
Suppes P. Mathematical concept formation in children. American Psychologist 1966, 21, 139-50.
Surgeon Generals Report The health consequences of smoking. Public Health Srevice Publication No. (HSM) 72-7516. Washington, D.C. 1972, U.S.  Department of Health, Education and Welfafe.
Surgeon Generals Report by the Scientific Advisory Committee on 
Television and Social Behavior: Television and growing u: The impact of televised violence. Hearings before Subcommittee on Communications, 92nd Congres, 2nd session, March 21-24, 1972.
Sutherland E.H. White-collar crime. New York 1949, Holt, Rinehart and Winston.
Sutherland E.H. Crime of corporations. In: G Geis (Ed.) White-collar criminal. New York 1968, Atherton.
Sweet W.H., Ervin F., Mark V.H. The relationship of violent behavior to focal cerebral desease. In: S. Garattini, E. Sigg (Eds.) Aggressive behavior. New York 1969, Wiley.
Szasz T.S. The myth of mental illness. New York 1961, Harper and Row.
Szasz T.S. Psychiatric justice. New York 1965, Macmillan.
Szasz T.S. The age of madness. Garden City. N.Y. 1973, Anchor Press.

Tapp J., Mathewson D., DEncarnacas P., Long C. The effect of the onset of stimuli on reactivity in the rat. Psychonomic Science 1970, 19, 61-62.
Tart C. Altered states of consciousness. New York 1969, Wiley.
Tasaki I. Nervous transmission. Springfild, III. 1953, Charles C. Thomas.
Taylor D.W., Berry P.C., Block C.H. Does group participation when using brainstorming facilitate or inhibit creative thinking? „Administrative Science Quartely 1958, 3, 23-47.
Teitelbaum P. The use of operant methods in the assessment and control motivational states. In: W.K. Honig (Ed). Operant behavior. New York 1966, Appleton-Century-Crofts.
Teitalbaum P., Epstein A. The lateral hypothalamic syndrome: Recovery of feeding and drinking after lateral hypothalamic lesions. Psychological Review 1962, 69, 74-90.
Terkel S. Working: People talk about what they do all day and how they feel about what they do. New York 1974, Pantheon Books.
Terman L.M. The measurement of intelligence. Boston 1916, Houghton Mifflin.
Terman L.M. Feeble-minded children in the public schools of California. 
„School and Society 1917, 5, 161-65.
Terman L.M., Merrill M.A. Measuring intelligence. Boston 1937, Houghton Mifflin.
Terman L.M., Merrill M.A. The Stanford-Binet intelligence scale. Boston 1960, Houghton Mifflin.
Terrace H.S. Errorless transfer of a discrimination across two continua. 
„Journal of the Experimental Analysis of Behavior 1963, 6, 224-32.
Thigpem C.H., Cleckley H.A. A case of multiple personality. „Journal of Abnormal and Social Psychology 1954, 49(1), 135-44).
Tigpem C.H., Cleckley H.A. The three faces of Eve. New York 1957, McGraw-Hill.
Thompson R., McConnell J.V. Classical conditioning in the Planarian, Dugesia Dorotocephala. Journal of Comparative and Physiological Psychology 1955, 48, 65-68.
Thompson R.F., Robertson R.T., Mayers K.S. Commentatory on cortical association response areas. In: G.M. French (Ed.) Cortical functioning in behavior. Glenview, III. 1973, Scott, Foresman.
Thorndike El.L. Animal intelligence. Psychological Review Monograph Supplement 1898, 2(4, Whole No 8).
Thorndike E.L. The elements of psychology. New York 1905, Seiler.
Tillich P. The courage to be. New Haven, Conn. 1952, Yale Univeristy Press.
Tilly C. Collective violence in European perspective. In: H.D. Graham, T.R. Gurr (Eds.) Violence in America: Historical and comparative perspectives. New York 1969, New American Library.
Tinklepaugh O.L. An experimental study of representational factors in monkeys. Journal of Comparative Psychology 1928, 8, 197-236.
Toch H. Violent men. Chicago 1969, Aldine.
Tolman E.C. Operational behaviorism and current trends in psychology.  Collected papers in psychology. Berkeley 1950, University of California Press. (Originally published, 1936).
Trauax C.B. Effective ingredients in psychotherapy. Journal of Counseling Psychology 1963, 16, 256-63.
Triandis H.C. Attitude and attitude change. New York 1971, Wiley.
Triplett N. The dynamogenic factors in pacemaking and competition. 
„American Journal of Psychology 1897, 9, 507-33.
Trotter R.J. Psychosurgery, the courts and Congress. Science News May 1973,, 103, 310-11.
Trotter W. Instincts of the heard i pace and war. London 1916, T. Fisher Unwin.
Tschukitschew. Contributions of the Timiriazer Institute, 1929, 36. Cited in: R.D. Templeton, J.. Quigley, The action of insulin on the motility of the gastrointestinal tract. American Journal of Physiology 1930, 91,, 467-74.
Turing A.M. Computing machinery and intelligence. Mind 1950, 59, 433-60.
Turnbull C.M. Some observations regarding the experiences and behavior of BaMbuti Pygmes. American Journal of Psychology 1961, 74, 304-08.

Unger S.M. Mescaline, LSD, silocybin, and personality change. 
„Psychiatry 1963, 26, 11-25.
Valenstein E., Cox V., Kakolewski J. Modification of motivated behavior elicited by eletrical stimulation of the hypothalamus. Science 1968, 159, 1119-21. (a).
Valenstein E., Cox V., Kakolewski J. The motivation underlying eating elicted by lateral hypothalamic stimulation. Physiology and Behavior 1968, 3, 969-71. (b).
Valenstein E., Cox V., Kakolewski J. Reexamination of the role of the hypothalamicus in motivation. Psychological Review 1970, 77, 16-31.
Van de Castle R.L. The psychology of dreams. (Module) Morristown, N.J. 
1971, General Learning Corp.
Verhave T. The pigeon as a quality-control inspector. In: R. Ulrich, T.  Stachnik, J. Mabry (Eds.) Control of human behavior. Glenview, III. 1966, Scott, Foresman.
Verville E. Behavior problems of children. Philadelphia 1967, Saunders.
Vidmar N., Rokeach M. Archie Bunkers bigotry: A study on selective perception and exposure. Journal of Communication Winter 1974, 24(1), 36-47.
Von Bekesy G. The ear. Scientific American 1957, 197(2), 66-78.

Wallace B., Garret J.B. Reduced felt arm sensation effects on visual adaptation. Perception and Psychophysics 1973, 14(3), 597-600.
Wallace R.K., Benson H. The physiology of mediation. Scientific American 1972, 226, 84-90.
Wallach M.A., Kogan N. Modes of thinking in young children: A study of the creativity-intelligence distinction. New York 1965,, Holt, Rinehart and Winston.
Walster E., Berscheid E., Walster G.W. New directions in equity research. 
„Journal of Personality and Social Psychology 1973, 25, 151-76.
Ward W.C., Kogan N. Motivation and ablity in childrens creativity. 
Unpublished manuscript, University of Nevada, Reno, 1972.
Warden C.J. Animal motivation: Experimental studies on the albono rat. 
New York 1931, Columbia University Press.
Warden D.M. The bystander phenomenon: A critical review of the research. 
Unpublished report, 1970.
Wason P.C. Problem solving and reasoning. British Medical Bulletin 1971, 27(3), 206-10. Exerpt reproduced by permission of the Medical Department, The British Council.
Watson G., Hohnson D. Social psychology: Issues and insights. New York 1972, Lippincott.
Watson J.B. Experimental studies on the growth of emotions. In: C.  Murchison (Ed.) Psychologies of 1925. Worcester, Mass, 1926, Clark University Press.
Watson J.B., Rayner R. Conditioned emotional reactions. Journal of Experimental Psychology 1920, 3, 1-14.
Watson J.D. The double helix. New York 1968, Atheneum.
Watson R.I., Jr. Investigation into deindividuation using a cross-cultural survey technique. Journal of Personality and Social Psychology 1973, 25, 342-45.
Watts A.W. The way of Zen. New York 1957, Vintage Books.
Waugh N.C., Norman D.A. Primary memory. Psychological Review 1965, 72, 89-104.
Webb W.B. Sleep behavior as a biorhythm. In: P. Coloquohon (Ed.) 
Biological rhythms and human performance. London 1971, Academic Press.
Weschler D. Wechsler intelligence scale for children. New York 1949, Psychological Corp.
Weschler D. Wechsler adult intelligence scale. New York 1955, Psychological Corp.
Wechsler h., Grosser G.H., Greenblatt M. Research evaluating antidepressant medications on hospitalized mental patients: A syrvery of publisched reports during a 5-years period. Journal of Nervous and Mental Disease 1965, 141, 231-39. 
Wegrocki H.J. A critique of cultural and statistical concepts of abnormality. Journal of Abnormal and Social Pschyjology 1939, 34, 166-78.
Weiss J.M. Effects of coping response on stress. Journal of Comparative and Physiological Psychology 1968, 65, 251-60.
Weiss J.M. Effects of coping behavior in different warning signal conditions on stress pathology in raits. Journal of Comparative and physiological Psychology 1971, 77, 1-13.
Weiss R.F., Buchanan W., Alstatt L., Lombardo J.P. Altruism is rewarding. 
„Science 1971, 171, 1262-63.
Weiss T., Engel B. Operant conditioning of heart rate in patiens with premature vebntricular contractions. Psychosomatic Medicine 1971, 33, 301-21.
Weisskopf-Joelson E. Some comments on a Viennese school of psychiatry. 
Journal of Abnormal and Social Psychology 1955, 51, 701-3.
Weitzman B. Behavior therapy and psychotherapy. Psychological Review 1967, 74, 300-17.
Welker W.I. An analysis of exploratory and play behavior in animals. In: 
D.W. Fiske, S.R. Maddi (Eds.) Functions of varied experience. Homewood, III. 1961, Dorsey.
Wells D.T. Large magnitude voluntary heart rate changes. 
„Psychopshysiology 1973, 10, 260-69.
Wells W.D. Television and aggression: Replication of an experimental field study. Unpublished manuscript, University of Chicago, 1971.
Wertheimer M. Fundamental issues in psychology. New York 1972, Holt, Rinehart and Winston.
Wever E.G. Theory of hearing. New York 1949, Wiley.
Wever E.G., Bray C.W. Present possibilitiesfor auditory theory. 
„Psychological Review 1930, 37, 365-80.
White B.L., Held R. Plasticity of sensorimotor development in the human infant. In: J.F. Rosenbilth, W. Allinsmith (Eds.) The causes of behavior.  Viol. 1. (2nd ed.) Boston 1966, Allyn and Bacon.
White R.W. Motivation recoinsidered: The concept of cometence. 
„Psychological Review 1959, 66, 297-33.
Whiting J.W.M., Kluckhohn R., Anthony A. The function of male initiation ceremonies at puberty. In: E.E. Maccoby, T. Newcomb, E.D. Hartley (Eds.) Readings in social psychology. New York 1958, Holt, Rinehart and Winston.
Whorf B.L. Language, thought, and reality. J.B. Carroll (Ed.) New York 1956, Wiley.
Wiener N. The human use of human beings. Boston 1954, Houghton Mifflin.
Willems E.P. Go ye into all the world and modify behavior: An ecologists view. Reresentative Research in Social Psychology 1973, 4, 93-105.
Williams D.R., Williams H. Auto-maintenance in pigeons: Sustained pecking desipte contingent nonreinforcement. Journal of Experimental Analysis of Bevarior 1969, 12, 511-20.
Williams H.L., Holloway F., Griffiths W.J. Physiological psychology: 
Sleep. Annual Review of Psychology 1973, Palo Alto, Calif. 1973, Annual Reviews.
Williams R.J. Biochemical individuality. New York 1956, Wiley.
Williams T.A., Friedman R.J., Secunda S.K. Special report: The depressive illnesses. Chevy Chase, Md. 1970. National Institute of Mental Health.
Wilson M. Rituals of kinship among the Nyakusa. Oxford 1970, Oxford University Press.
Wilson M. Cortical function in somesthesis. In: G.M. Freench (Ed.) 
Cortical functioning  in behavior, Glenview, III. 1973, Scott, Foresman.
Winick M., Meyer K.K., Harris R.C. Malnutrition and environmental enrichment by early adoption. Science 1975, 190, 1173-75.
Winokur G. The typpes of affective disordes. Journal of Nervous and Mentral Diseases Feb. 1973, 156(2), 82-96.
Winterbottom M.R. The relation of childhood training in indenpedence to achievement motivation. Unpublished doctoral dissertation, Univeristy of Michigan, 1953.
Witkin H.A., et al. Personality trought perception. New York 1954, Harper and Row.
Wolf A.V. Thirst: Physiology of the urge to drink and problems of water lack. Springfield, III. 1958, Charles C. Thomas.
Wolf M., Risley T., Mees H. Application of operant contitioning procedures to the behavior problems of an austic child. Behavior Research and Therapy 1964. 1, 303-12.
Wolf S., Wolf H.G. Human gastric function. (2nd ed.) New York 1947, Oxford Univeristy Press.
Wolpe J. Psychotherapy by reciprocal inhibitions. Stanford 1958, Stanford University Press.
Wolpe J. Reciprocal inhibition as the main basis of psychotherapeutic effects. In: H.J. Eysenck (Ed.) Behavior therapy and the neuroses. New York 1960, Pergamon Press. 
Wolpe J. The practice of behavior therapy. New York 1969, Pergamon Press.
Woods J. The yoga-system of pantanjali. Cambridge, Mass. 1914, Harvard University Press.
Worchel S., Brehm J. Direct and implied social restoration of freedom. 
„Journal of Personality and Social Psychology 1971, 18, 294-304.
Wurtman R.J., Axelrod J., Kelly D.E. The pineal. New York 1968, Academic Press.


Yablonsky L. The violent gang. In: S. Endleman. (Ed.) Violence in the streets. Chicago 1968, Quadrangle Books.
Yamaoka T. Psychological study of mental self-control. In: Y. Akishige (Ed.) Psychological studies in Zen. Fukuoka 1968, Kyushu University.
Yarrow M.R., Schwartz C.G., Murphy G.S., Deasy L.C. The psychological meaning of mental illnes in the family. Journal of Social Issues 1955, 11, 12-24.
Yates A.J. Develayed auditory feedback. Psychological Bulletin 1963, 60, 213-32.
Young P.T. Motivation and emotion. New York 1961, Wiley.
Young P.T. Evolution and preference in behavioral development. 
„Psychological Review 1968, 75, 222-41.


Zajonc R.B. Social facilitation. Science 1965, 149, 269-74.
Zajonc R.B. Social facilitation in cockroaches. In: E.C. Simmel, R.A. 
Hoppe, G.A. Milton (Eds.) Social facilitation and imitative behavior. 
Boston 1968, Allyn and Bacon.
Zarcone V., Gulevick G., Pivik T., Dement W. Partial REM phase deprivation and schizophrenia. Archives of General Psychiatry 1968, 18, 194-202.
Zborowski M. People in pain. San Francisco 1969, Jossey-Bass.
Zeaman D., Smith R.W. Review and analysis of some recent findings in human cardiac conditioning. In: W.F. Prokasky (Ed.) Classical conditioning.  New York 1965, Appleton-Century-Crofts.
Zeigarnik B. Uber das Behalten von erledigten und unerledigten Handlungen. Psychologische Forschung 1927, 9, 1-85.
Zimbardo P.G. The effects of early avoidance training and rearing conditions upon the sexual behavior of the male rat. Journal of Comparative and Physiological Psychology 1958, 51, 764-69.
Zimbardo P.G. The cognitive control of motivation. Glenview, III. 1969  a, Scott, Foresman.
Zimbardo P.G. The human choice: Individuation, reason, and order versus deindyviduation, impulse, and chaos. In: W.J. Arnold, D. Levine (Eds.) Nebraska symposium on motivation. Lincoln 1969 b, University of Nebraska Press.
Zimbardo P.G. A field experiment in auto-shaping. In: C. Ward (Eds.) 
Vandalism. London 1973, Architectual Press.
Zimbardo P.G., Formica R. Emotional comparison and self-esteem as determinants of affiliation. Journal of Personality 1963, 31, 141-62.
Zimbardo P.G., Haney C., Banks W.C., Jaffe D. The mind is a formidable jailer: A Pirandellian prison. The New York Times April 8, 1973, 38-60.
Zimbardo P.G., Marshall G., Maslach C. Liberating behavior from time-bound control: Expanding the present trought hypnosis. Journal of Applied Social Psychology 1971, 4, 305-23.
Zimbardo P.G., Meadow W. Sexism in the Readers Digest, or Laugh and the world laughs at you. Paper presented at the meeting of the Western Psychological Association, San Francisco, April 1974.
Zimbardo P.G., Miller N.E. Faciliation of exploration by hunger in rats. 
„Journal of Comparative and Physiological Psychology 1958, 51, 43-46.
Zimbardo P.G., Pilkonis P.A., Norwood R.M. The social disease called shyness. Psychology Today May 1975, 8(12), 69-71.
Zimbardo P.G., Rapaport C., Baron J. Pain control by hypnotic induction of motivational states. In: P. Zimbardo (Ed.) The cognitive control of motivation. Glenview, III. 1969, Scott, Foresman.
Zimbardo P.G. Weisenberg M., Firestone I., Levy B. Communicator effectiveness in producing publicing public conformity and private attitude change Journal of Personality 1965, 33, 233-55.
Zobrist A.L., Carlson F.R. An advice-taking chess computer. „Scientific American 1973, 228(6), 92-105.
Zubeck J.P., Pushkar D., Sansom W., Gowing J. Perceptual changes after prolonged sensory isolation (darkness and silence). Canadian Journal of Psychology 1961, 15, 83-100.
Zurcher L.A. The mutable self. The Futurist Oct. 1972, 181-85.






2


